In-and-Out: Algorithmic Diffusion for Sampling Convex Bodies
Yunbum Kookâˆ— Santosh S. Vempalaâ€  Matthew S. Zhangâ€¡
May 3, 2024
Abstract
We present a new random walk for uniformly sampling high-dimensional convex bodies.
It achieves state-of-the-art runtime complexity with stronger guarantees on the output than
previously known, namely in RÃ©nyi divergence (which implies TV, W , KL, Ï‡2). The proof
2
departsfromknownapproachesforpolytimealgorithmsfortheproblemâ€”weutilizeastochastic
diffusion perspective to show contraction to the target distribution with the rate of convergence
determined by functional isoperimetric constants of the stationary density.
1 Introduction
Generating random samples from a high-dimensional convex body is a basic algorithmic problem
with myriad connections and applications. The core of the celebrated result of [DFK91], giving a
randomized polynomial-time algorithm for computing the volume of a convex body, was the first
polynomial-time algorithm for uniformly sampling convex bodies. In the decades since, the study
of sampling has led to a long series of improvements in its algorithmic complexity [LS90; LS93;
KLS97; LV06; CV18], oftenbasedonuncoveringnewmathematical/geometricstructure, establishing
connections to other fields (e.g., functional analysis, matrix concentration) and developing new tools
for proving isoperimetric inequalities and analyzing Markov chains. With the proliferation of data
andtheincreasingimportanceofmachinelearning,samplinghasalsobecomeanessentialalgorithmic
tool, with applications needing samplers in very high dimension, e.g., scientific computing [CV16;
Har+17; Koo+22], systems biology [LNP12; Thi+13], differential privacy [MT07; Mir17] and
machine learning [Bin+19; Sta20].
Samplers for convex bodies are based on Markov chains (see Appendix A for a summary). Their
analysis is based on bounding the conductance of the associated Markov chain, which in turn bounds
the mixing rate. Analyzing the conductance requires combining delicate geometric arguments with
(Cheeger) isoperimetric inequalities for convex bodies. An archetypal example of the latter is the
following: for any measurable partition S ,S ,S of a convex body K âŠ‚ Rd, we have
1 2 3
d(S ,S )
vol(S ) â‰¥ 1 2 min{vol(S ),vol(S )},
3 1 2
C
K
where d(Â·,Â·) is the (minimum) Euclidean distance, and C is an isoperimetric constant of the
K
uniform distribution over K. (The KLS conjecture posits that C = O(1) for any convex body K in
K
isotropic position, i.e., under the normalization that a random point from K has identity covariance).
âˆ—School of Computer Science, Georgia Institute of Technology, yb.kook@gatech.edu
â€ School of Computer Science, Georgia Institute of Technology, vempala@gatech.edu
â€¡DepartmentofComputerScience,UniversityofToronto,andVectorInstitute,matthew.zhang@mail.utoronto.ca
1
4202
yaM
2
]SD.sc[
1v52410.5042:viXraThe coefficient C2 is bounded by the PoincarÃ© constant of the uniform distribution over K (and
K
they are in fact asymptotically equal). The classical proof of conductance uses geometric properties
of the random walk at hand to reduce the analysis to a suitable isoperimetric inequality (see e.g.,
[LS93; Vem05]). The end result is a guarantee on the number of steps after which the total variation
distance (TV distance) between the current distribution and the target is bounded by a desired error
parameter. This framework has been widely used and effective in analyzing an array of candidate
samplers, e.g., Ball walk [KLS97], Hit-and-Run [Lov99; LV06], Riemannian Hamiltonian Monte Carlo
[LV18] etc.
One successful approach, studied intensively over the past decade, is based on diffusion. The
basic idea is to first analyze a continuous-time diffusion process, typically modeled by a stochastic
differential equation (SDE), and then show that a suitable time-discretization of the process,
sometimes together with a Metropolis filter, converges to the desired distribution efficiently. A
major success along this line is the Unadjusted Langevin Algorithm and its variants [Bes+95; DT12;
Dal17; DMM19; VW19]. These algorithms have strong guarantees for sampling â€œniceâ€ distributions,
such as ones that are strongly log-concave, or more generally distributions satisfying isoperimetric
inequalities, while also obeying some smoothness conditions. The analysis of these algorithms is
markedly different from the conductance approach, and typically yields guarantees in stronger
metrics such as the KL-divergence.
Our starting point is the following question:
Can diffusion-based approaches be used for the problem of sampling convex bodies?
Despite remarkable progress, thus far, constrained sampling problems have evaded the diffusion
approach, except as a high-level analogy (e.g., the Ball walk can be viewed as a discretization of
Brownian motion, but this alone does not suggest a route for analysis) or with significantly worse
convergence rates (e.g., [Bro+17; BEL18]).
Our main finding is a simple diffusion-based algorithm that can be mapped to a stochastic
process (and, importantly, to a pair of forward and backward processes), such that the rate of
convergence is bounded directly by an appropriate functional inequality for the target distribution.
As a consequence, for the first time, we obtain clean end-to-end guarantees in the RÃ©nyi divergence
(which implies guarantees in other well known quantities such as W ,TV,KL,Ï‡2 etc.), while giving
2
state-of-the-art runtime complexity for sampling convex bodies (e.g., Ball walk or Speedy walk [LS93;
KLS97]). Besides being a stronger guarantee on the output, RÃ©nyi divergence is of particular interest
for differential privacy [Mir17]. Perhaps most interesting is that our proof approach is completely
different from prior work on convex body sampling. In summary,
â€¢ The guarantees hold for the q-RÃ©nyi divergences while matching the rates of previous work
(prior work only had guarantees in the TV distance).
â€¢ The analysis is simple, modular, and easily extendable to several other settings.
1.1 Diffusion for uniform sampling
WeproposethefollowingIn-and-Out1 samplerforuniformlysamplingfromK. Eachiterationconsists
of two steps, one that might leave the body and the second accepted only if it is (back) in the body.
1This name reflects the â€œgeometryâ€ of how the iterates are moving. As we elaborate in Remark 1, the name
â€˜proximal samplerâ€™ may be more familiar to those from an optimization background.
2ğ‘¦
ğ‘§(reject) "
ğ‘¥
!
ğ‘¥ !,ğ‘¥ " ğ‘¥ ! ğ‘¥ "
ğ‘¥ ğ‘¥
# "
Ball walk Speedy walk In-and-Out
Figure 1.1: Description of uniform samplers: (i) Ball walk: proposes a uniform random point z from
B (x ), but z âˆˆ/ K so it stays at x = x . (ii) Speedy walk: moves to x drawn uniformly at random
Î´ 1 1 2 2
from Kâˆ©B (x ). (iii) In-and-Out: first moves to y obtained by taking a Gaussian step from x ,
Î´ 1 2 1
and then to x obtained by sampling the truncated Gaussian N(y ,hI )| .
2 2 d K
Algorithm 1 In-and-Out
Input: initial point x âˆ¼ Ï€ , convex body K âŠ‚ Rd, iterations T, threshold N, and h > 0.
0 0
Output: x .
T+1
1: for i = 0,...,T do
2: Sample y i+1 âˆ¼ N(x i,hI d).
3: Repeat: Sample x i+1 âˆ¼ N(y i+1,hI d) until x i+1 âˆˆ K or #attempts i â‰¥ N (declare Failure).
4: end for
It might be illuminating for the reader to compare this algorithm to the well-studied Ball walk
(Algorithm 2); each proposed step is a uniform random point in a fixed-radius ball around the
current point, and is accepted only if the proposed point is in the body K. In contrast, each iteration
of In-and-Out is a two-step process, where the first step (Line 2) ignores the boundary of the body,
and the second step (Line 3) is accepted only if a proposal x is a feasible point in K. We will
i+1
presently elaborate on the benefits of this variation.
Each successful iteration of the algorithm, i.e., one that is not declared â€œFailureâ€, can be called
a proper step. We will see that the number of proper steps is directly bounded by isoperimetric
constants (such as PoincarÃ© and log-Sobolev) of the target distribution. In fact, this holds quite
generally without assuming the convexity of K. The implementation of an iteration is based on
rejection sampling (Line 3), and our analysis of the efficiency of this step relies crucially on the
convexity of K. This is reminiscent of the Speedy walk in the literature on convex body sampling
(Algorithm 3), which is used as a tool to analyze proper steps of the Ball walk. We refer the reader
to Appendix B for a brief survey on these and related walks.
This simple algorithm can be interpreted as a composition of â€œflowsâ€ in the space of measures.
This view will allow us to use tools from stochastic analysis. In particular, we shall demonstrate
how to interpret the two steps of one iteration of In-and-Out as alternating forward and backward
heat flows.
We begin by defining an augmented probability measure on RdÃ—Rd by
1
Ï€(x,y) âˆ exp(cid:0) âˆ’ âˆ¥xâˆ’yâˆ¥2(cid:1)1 (x).
2h K
3Forward flow Backward flow
SDE dZ = dB dZâ† = âˆ‡log(Ï€XP )(Zâ†)dt+dB
t t t hâˆ’t t t
Fokker-Planck âˆ‚ Âµ = 1âˆ†Âµ âˆ‚ Âµâ† = âˆ’div(cid:0) Âµâ†âˆ‡log(Ï€XP )(cid:1)+ 1âˆ†Âµâ†
t t 2 t t t t hâˆ’t 2 t
Table 1: The Fokker-Planck equations for the forward and backward heat flow describe how the
laws of Z and Zâ† in (FH) and (BH) evolve over time. See Section 3.2 for details.
t t
We denote by Ï€X,Ï€X|Y(Â·|y) the marginal distribution of its first component (resp. conditional
distribution given the second component), and similarly denote by Ï€Y,Ï€Y|X(Â·|x) for the second
component. In particular, the marginal in the first component Ï€X is the uniform distribution over
K. Sampling from such a joint distribution to obtain the marginal on X (say), can be more efficient
than directly working only with Ï€X. This idea was utilized in Gaussian Cooling [CV18] and later as
the restricted Gaussian Oracle (RGO) [LST21; Che+22].
Underthisnotation,Algorithm1correspondstoaGibbssamplingschemefromthetwomarginals
of Ï€(x,y). To be precise, Line 2 and Line 3 correspond to sampling from
y âˆ¼ Ï€Y|X(Â·|x ) = N(x ,hI ) and x âˆ¼ Ï€X|Y(Â·|y ) = N(y ,hI )| .
i+1 i i d i+1 i+1 i+1 d K
We implement the latter step through rejection sampling; if the number of trials in Line 3 hits the
threshold N, then we halt and declare failure of the algorithm. It is well known that such a Gibbs
sampling procedure will ensure the desired stationarity of Ï€(x,y).
Stochastic perspective: forward and backward heat flows. Our algorithm can be viewed
through the lens of stochastic analysis, due to an improved analysis for the proximal sampling
[Che+22]. This view provides an interpolation in continuous-time, which is simple and powerful. To
make this concrete, we borrow an exposition from [Che24, Chapter 8.3]. Let us denote the successive
laws of x and y by ÂµX and ÂµY, respectively. Recall that the first step of sampling from Ï€Y|X(Â·|x )
i i i i i
(Line 2) yields ÂµY = R Ï€Y|X=xdÂµX(x). This is the result of evolving a probability measure under
i+1 i
(forward) heat flow of ÂµX for some time h, given precisely by the following stochastic differential
i
equation: for Z âˆ¼ ÂµX,
0 i
dZ = dB (FH)
t t
where B is the standard Brownian process. We write law(Z ) = ÂµXP . In particular, Z = Z +Î¶ âˆ¼
t t i t h 0
ÂµX âˆ—N(0,hI ) = ÂµY for Î¶ âˆ¼ N(0,hI ). When ÂµX = Ï€X, the first step of Algorithm 1 gives
i d i+1 d i
1 Z 1
Ï€Y(y) = [Ï€X âˆ—N(0,hI )](y) = exp(cid:0) âˆ’ âˆ¥yâˆ’xâˆ¥2(cid:1)dx. (1.1)
d vol(K)(2Ï€h)d/2 2h
K
The second step of sampling from Ï€X|Y(Â·|y ) can be represented by ÂµX = R Ï€X|Y=ydÂµY (y)
i+1 i+1 i+1
(Line 3). The continuous-time process corresponding to this step might not be obvious. However,
let us consider (FH) with Z âˆ¼ Ï€X. Then, Z âˆ¼ Ï€Y, so the joint distribution of (Z ,Z ) is simply Ï€.
0 h 0 h
This implies that (Z |Z = y) âˆ¼ Ï€X|Y=y. Imagine there is an SDE reversing the forward heat flow
0 h
in a sense that if we are initialized deterministically at Z âˆ¼ Î´ at time 0, then the law of the SDE
h y
at time h would be law(Z |Z = y) = Ï€X|Y=y. Then, this SDE would serve as a continuous-time
0 h
interpolation of the second step.
Such a time reversal SDE is indeed possible! The following SDE on (Zâ†) initialized at
t tâˆˆ[0,h]
Zâ† âˆ¼ Ï€Y = Ï€XP ensures Z âˆ¼ law(Zâ†) = Ï€XP :
0 h hâˆ’t t hâˆ’t
dZâ† = âˆ‡log(Ï€XP )(Zâ†)dt+dB for t âˆˆ [0,h]. (BH)
t hâˆ’t t t
4Although this is designed to reverse (FH) initialized by Z âˆ¼ Ï€X (so Z = Zâ† âˆ¼ Ï€Y), its
0 h 0
constructionalsoensuresthatifZâ† âˆ¼ Î´ ,apointmass,thenZâ† âˆ¼ law(Z |Z = y) = Ï€X|Y=y. Thus,
0 y h 0 h
if we initialize (BH) with Zâ† âˆ¼ ÂµY , then the law of Zâ† corresponds to R Ï€X|Y=ydÂµY (y) = ÂµX .
0 i+1 h i+1 i+1
Remark 1. We note that In-and-Out is exactly the proximal sampling scheme [LST21; Che+22;
FYC23] for uniform distributions. The proximal sampler with a target density proportional to
exp(âˆ’V(x)) considers an augmented distribution Ï€(x,y) âˆ exp(âˆ’V(x)âˆ’ 1 âˆ¥xâˆ’yâˆ¥2) and then
2h
repeats the following two steps: (1) y
i+1
âˆ¼ Ï€Y|X=xi = N(x i,hI d) and then (2) x
i+1
âˆ¼ Ï€X|Y=yi+1.
1.2 Results
Our model of computation is the classical general model for convex bodies [GLS88]. We assume
vol(K) > 0 throughout this paper. Below, B (x) denotes the d-dimensional ball of radius r centered
r
at x.
Definition 1 (Convex body oracle). A well-defined membership oracle for a convex body K âŠ‚ Rd
is given by a point x âˆˆ K, a number D > 0, with the guarantee that B (x ) âŠ† K âŠ† B (x ), and
0 1 0 D 0
an oracle that correctly answers YES or NO to any query of the form â€œx âˆˆ K?â€
Definition 2 (Warmness). A distribution Âµ is M-warm with respect to another distribution Ï€, i.e.,
for every x in the support of Ï€, we have dÂµ(x) â‰¤ M dÏ€(x).
We now summarize our main result which is further elaborated in Section 3.4 (Theorem 27).
Below, Ï€K is the uniform distribution over K, and R is the RÃ©nyi-divergence of order q (see
q
Definition 6).
Theorem 3. For any given Î·,Îµ âˆˆ (0,1), q â‰¥ 1, and any convex body K given by a well-defined
membership oracle, there exist choices of parameters h,N such that In-and-Out, starting from an
M-warm distribution, with probability at least 1âˆ’Î·, returns X âˆ¼ Âµ such that R (Âµâˆ¥Ï€K) â‰¤ Îµ. The
q
number of proper steps is Oe(qd2Î›log M), and the expected total number of membership queries is
Î·Îµ
Oe(qMd2Î›log5(1/Î·Îµ)), where Î› is the largest eigenvalue of the covariance of Ï€K.
We note that for X âˆ¼ Ï€K,
âˆ¥Cov(Ï€K)âˆ¥ â‰¤ tr(Cov(Ï€K)) = E(cid:2) âˆ¥X âˆ’E[X]âˆ¥2(cid:3) â‰¤ D2.
op
TheaboveguaranteeintheRÃ©nyidivergenceimmediatelyprovidesW ,TV,KL,andÏ‡2guarantees
2
as special cases. Previous guarantees for uniformly sampling convex bodies were only in the TV-
distance. For two distributions Âµ and Ï€, we have
1. KL(Âµâˆ¥Ï€) = lim R (Âµâˆ¥Ï€) â‰¤ R (Âµâˆ¥Ï€) â‰¤ R (Âµâˆ¥Ï€) â‰¤ R (Âµâˆ¥Ï€) = logsup dÂµ for 1 < q â‰¤ qâ€².
qâ†’1 q q qâ€² âˆ dÏ€
2. 2âˆ¥Âµâˆ’Ï€âˆ¥2 â‰¤ KL(Âµâˆ¥Ï€) â‰¤ log(Ï‡2(Âµâˆ¥Ï€)+1) = R (Âµâˆ¥Ï€).
TV 2
3. W2(Âµ,Ï€) â‰¤ 2C (Ï€)KL(Âµâˆ¥Ï€) (Talagrandâ€™s T -inequality) and C (Ï€K) â‰² D2.
2 LSI 2 LSI
4. W2(Âµ,Ï€) â‰¤ 2C (Ï€)Ï‡2(Âµâˆ¥Ï€) [Liu20] and C (Ï€K) â‰² âˆ¥Cov(Ï€K)âˆ¥ logd.
2 PI PI op
Thequerycomplexityisbetteriftheconvexbodyis(near-)isotropic,i.e.,theuniformdistribution
over the body has (near-)identity covariance. This relies on recent estimates of the worst-case
PoincarÃ© constant for isotropic log-concave distributions [KLS95; Kla23].
5Corollary 4. Assume that Ï€K is isotropic. Under the same setting as above, In-and-Out succeeds
with probability 1âˆ’Î·, returning X âˆ¼ Âµ such that R (Âµâˆ¥Ï€K) â‰¤ Îµ. The number of proper steps is
q
Oe(qd2log M), and the expected total number of membership queries is Oe(qMd2log5(1/Î·Îµ)).
Î·Îµ
Ouranalysiswillinfactshowthattheboundonthenumberofproperstepsholdsforgeneralnon-
convex bodies and any feasible start in K. This is deduced under an M-warm start in Corollaries 28
and 29. We remark that such a bound for non-convex uniform sampling is not known for the
Ball walk or the Speedy walk.
Theorem 5. For any given Îµ âˆˆ (0,1) and set K âŠ‚ B (0) with vol(K) > 0, In-and-Out with variance
D
h and M-warm initial distribution achieves R (ÂµXâˆ¥Ï€X) â‰¤ Îµ after the following number of iterations:
q m
( O(cid:0) qhâˆ’1C (Ï€X)log M(cid:1) for q â‰¥ 2,
m = min PI Îµ
O(cid:0) qhâˆ’1C (Ï€X)log logM(cid:1) for q â‰¥ 1.
LSI Îµ
We have two different convergence results above under (LSI-I) and (PI). Under (LSI-I) we have
a doubly-logarithmic dependence on the warmness parameter M. On the other hand, using (PI),
which is weaker than (LSI-I) (in general, C â‰¤ C ), the dependence on M is logarithmic. We
PI LSI
discuss our results further in Section 1.3.
Outline of analysis. We summarize our proof strategy below, which consists of two steps: (i)
The current distribution should converge to the uniform distribution, (ii) within each iteration of
the algorithm, the failure probability and the expected number of rejections should be small enough.
â€¢ We need to demonstrate that the corresponding Markov chain is rapidly mixing. Here, we
use the heat flow perspective to derive mixing rates under any suitable divergence measure
(such as KL, Ï‡2, or R ), extending known results for the unconstrained setting [Che+22]. As a
q
result, the mixing analysis reduces to a suitable functional inequality of the target distribution
alone.
â€¢ We show that the number of rejections in Line 3 over the entire execution of the algorithm
is bounded with high probability. To do this, we apply a detailed argument involving local
conductance and the convexity of K, which relies on techniques from [BNN06]. For this step,
we show that with the appropriate choice of variance h = Î˜ e(dâˆ’2) and threshold N = Î˜ e(TÎ·âˆ’1),
the entire algorithm succeeds with probability 1âˆ’Î·. The expected number of rejections is
polylogarithmic.
While each individual component resembles pre-existing work in the literature, in their synthesis
we will demonstrate how to interleave past developments in theoretical computer science, optimal
transport, and functional analysis. The combination of these in this domain yields elegant and
surprisingly simple proofs, as well as stronger results.
1.3 Discussion
Here we make a few remarks, contrasting our results with known ones.
No need to be lazy. Previous uniform samplers like the Ball walk are made lazy (i.e., with
probability 1/2, the Markov chain does nothing), to ensure convergence to the target stationary
distribution. However, our algorithm does not need this, since we directly show that our sampler
contracts towards a uniform distribution.
6Unified framework. We remark that these two different bounds also place the previously known
mixing guarantees for Ball walk,Speedy walk in a unified framework. Existing tight guarantees for
Speedy walk are in TV distance and based on the log-Sobolev constant, assuming an oracle for
implementing each step [LV17]. The known convergence guarantees of Ball walk (see Appendix B
for details), namely the mixing time of Oe(Md2D2log 1) for TV distance, are for the composite
Îµ
algorithm [Speedy walk+rejection sampling]. Here Speedy walk records only the accepted steps of
Ball walk, so its stationary distribution differs slightly from the uniform distribution (and can be
corrected with a post-processing step). On the other hand, In-and-Out actually converges to Ï€K
without any adjustments and achieves stronger RÃ©nyi divergence bounds in the same asymptotic
complexity. Our analysis shows that the mixing guarantee is determined by isoperimetric constants
of the target (PoincarÃ© or log-Sobolev).
âˆš
Effective step size. The Ball walkâ€™s largest possible step size is of order 1/ d (see Appendix B)
to keep the rejection probability bounded by a constant. This bound could also be viewed as an
â€œeffectiveâ€ step size of In-and-Out. This follows from the fact that the â„“ -norm of the Gaussian
âˆš 2
N(0,hI) âˆšis concen âˆštrated around hd, and we will set the variance h of In-and-Out to Oe(1/d2), so
we have hd â‰ˆ 1/ d.
What has really changed? In-and-Out has clear similarities to both Ball walk and Speedy walk.
What then are the changes that allow us to use continuous-time interpolation? One step of Ball walk
is [random step (y âˆˆ B (x)) + Metropolis-filter (accept if y âˆˆ K)]. This filtering is an abrupt discrete
Î´
step, and it is unclear how to control contraction. It could be replaced by a step of Speedy walk
(x âˆ¼ Unif(B (y)âˆ©K)). Then, each iteration of In-and-Out can be viewed as a Gaussian version of a
Î´
Ball walkâ€²s proposal+Speedy walk algorithm.
How can we compare In-and-Out with Speedy walk? Iterating speedy steps leads to a biased
distribution (one that is proportional to the local conductance). As clarified in Remark 2, one step of
(a Gaussian version of) Speedy walk can be understood as a step of backward heat flow. Therefore,
if one can control the isoperimetric constants of the biased distribution along the trajectory of the
backward flow, then contraction of Speedy walk toward the biased distribution will follow from the
simultaneous backward analysis.
2 Preliminaries
Unless otherwise specified, we will use âˆ¥Â·âˆ¥ for the 2-norm on Rd, and operator norm on RdÃ—d.
We write a = O(b), a â‰² b to mean that a â‰¤ cb for some universal constant c > 0. Similarly,
a â‰³ b,a = â„¦(b) for a â‰¥ cb, while a = Î˜(b) means that a â‰² b,b â‰² a simultaneously. We will also use
a = Oe(b) to denote a = O(bpolylog(b)). Lastly, we will use measure and density interchangeably
when there is no confusion.
To quantify the convergence rate, we introduce some common divergences between distributions.
Definition 6 (Distance and divergence). For two measures Âµ,Î½ on Rd, the total variation distance
between them is defined by
âˆ¥Âµâˆ’Î½âˆ¥ := sup|Âµ(B)âˆ’Î½(B)|,
TV
BâˆˆF
where F is the collection of all measurable subsets of Rd. The 2-Wasserstein distance is given by
W2(Âµ,Î½) := inf E [âˆ¥X âˆ’Yâˆ¥2],
2 (X,Y)âˆ¼Î³
Î³âˆˆÎ“(Âµ,Î½)
7where Î“ is the set of all couplings between Âµ,Î½. Next, we define the f-divergence of Âµ towards Î½ with
Âµ â‰ª Î½ (i.e., Âµ is absolutely continuous with respect to Î½) as, for some convex function f : R â†’ R
+
with f(1) = 0 and fâ€²(âˆ) = âˆ,
Z (cid:16)dÂµ(cid:17)
D (Âµâˆ¥Î½) := f dÎ½.
f dÎ½
The KL-divergence arises when taking f(x) = xlogx, the Ï‡q-divergence when taking f(x) = xq âˆ’1,
and the q-RÃ©nyi divergence is given by
1
R (Âµâˆ¥Î½) := log(cid:0) Ï‡q(Âµâˆ¥Î½)+1(cid:1) .
q qâˆ’1
Werecalltwoimportantfunctionalinequalitiesofadistribution. WeuseÎ½ todenoteaprobability
measure over Rd.
Definition 7. We say that Î½ satisfies a PoincarÃ© inequality (PI) with parameter C (Î½) if for all
PI
smooth functions f : Rd â†’ R,
Var f â‰¤ C (Î½)E [âˆ¥âˆ‡fâˆ¥2], (PI)
Î½ PI Î½
where Var f := E |f âˆ’E f|2.
Î½ Î½ Î½
The PoincarÃ© inequality is implied by the log-Sobolev inequality.
Definition 8. We say that Î½ satisfies a log-Sobolev inequality (LSI) with parameter C (Î½) if for
LSI
all smooth functions f : Rd â†’ R,
Ent (f2) â‰¤ 2C (Î½)E [âˆ¥âˆ‡fâˆ¥2], (LSI-I)
Î½ LSI Î½
where Ent (f2) := E [f2logf2]âˆ’E [f2]log(E [f2]). Equivalently, for any probability measure Âµ
Î½ Î½ Î½ Î½
over Rd with Âµ â‰ª Î½,
C (Î½)
KL(Âµâˆ¥Î½) â‰¤ LSI FI(Âµâˆ¥Î½), (LSI-II)
2
where FI(Âµâˆ¥Î½) := E [âˆ¥âˆ‡log dÂµâˆ¥2] is the Fisher information of Âµ with respect to Î½.
Âµ dÎ½
We recall the data-processing inequality for RÃ©nyi divergence and f-divergence.
Lemma 9 (Data-processing inequality). For measures Âµ,Î½, Markov kernel P, f-divergence D ,
f
and q â‰¥ 1, it holds that
D (ÂµP âˆ¥Î½P) â‰¤ D (Âµâˆ¥Î½), and R (ÂµP âˆ¥Î½P) â‰¤ R (Âµâˆ¥Î½).
f f q q
The aforementioned functional inequalities allow us to show exponential contraction of various
divergences, through the following helpful inequality.
Lemma 10 (GrÃ¶nwall). Suppose that u,g : [0,T] â†’ R are two continuous functions, with u being
differentiable on [0,T] and satisfying
uâ€²(t) â‰¤ g(t)u(t) for all t âˆˆ [0,T].
Then,
(cid:16)Z t (cid:17)
u(t) â‰¤ exp g(s)ds u(0) for all t âˆˆ [0,T].
0
83 Analysis
We begin this section by proving some introductory lemmas, which will streamline our later
exposition.
We first record two fundamental lemmas, which introduce the mathematical formalism for our
analysis. The first is the existence of forward and backward heat flows (Lemma 22), which will
interpolate each line in Algorithm 1. These flow equations describe how the laws of Z and Zâ† in
t t
(FH) and (BH) evolve respectively over time.
Lemma 11. The forward heat flow equation with initial distribution Âµ is given by
0
1
âˆ‚ Âµ = âˆ†Âµ ,
t t 2 t
and its backward heat flow equation is given by
1
âˆ‚ Âµâ† = âˆ’div(cid:0) Âµâ†âˆ‡log(Ï€XP )(cid:1)+ âˆ†Âµâ† with Âµâ† = Âµ .
t t t hâˆ’t 2 t 0 h
These admit (weak) solutions on [0,h] for any initial distribution Âµ with dÂµ0 â‰¤ M < âˆ.
0 dÏ€X
One successful iteration of In-and-Out is exactly the same as the composition of running the
forwardheatflowandthenbackwardheatflow, bothfortimeh. ItsvalidityisjustifiedinSection1.1,
and we give its proof below.
Lemma 12. Let ÂµX be the law of the k-th iterate x of In-and-Out. If (FH) is initialized with
k k
law(Z ) = ÂµX, then law(Z ) = ÂµY . If (BH) is initialized with law(Zâ†) = ÂµY , then law(Zâ†) =
0 k h k+1 0 k+1 h
ÂµX .
k+1
Proof. We explicitly show that the forward and backward heat flows indeed interpolate the two
discrete steps given in Algorithm 1. For the forward part, we have Z = Z +Î¶ for Î¶ âˆ¼ N(0,hI ), so
h 0 d
law(Z ) = law(Z )âˆ—N(0,hI ) = ÂµX âˆ—N(0,hI ) = ÂµY .
h 0 d k d k+1
Regarding the backward part, it is known from [Che+22, Lemma 14] that the construction of the
time-reversal SDE ensures that (Zâ†,Zâ†) and (Z ,Z ) have the same joint distribution, when
h 0 0 h
Z âˆ¼ Ï€X (and so Z âˆ¼ Ï€Y). Hence, law(Zâ†|Zâ† = y) = law(Z |Z = y) = Ï€X|Y=y, where the last
0 h h 0 0 h
equality follows from (Z ,Z ) âˆ¼ Ï€. Since we initialize (BH) with Zâ† = y âˆ¼ ÂµY , we have
0 h 0 k+1
Z Z
law(Zâ†) = law(Zâ†|Zâ† = y)ÂµY (dy) = Ï€X|Y(Â·|y)ÂµY (dy) = ÂµX ,
h h 0 k+1 k+1 k+1
where the last follows from the definition of Line 3.
Our analysis of these objects consists of two parts: (1) demonstrating the mixing of In-and-Out,
i.e., how many outer iterations are needed to be sufficiently close to the uniform distribution, and
(2) quantifying the failure probability and wasted steps in Line 3.
For (1), we collect in Section 3.1 some important implications of functional inequalities, e.g. the
PoincarÃ© and log-Sobolev inequalities, for the uniform distribution. Then in Section 3.2, we exploit
the flow perspective of the algorithm to obtain the mixing guarantees. To this end, we revisit the
proofs for the contraction results of forward and backward heat flows, and then extend them to our
constrained setting:
9Theorem 13 (Adapted for uniform distributions, [Che+22]). Let ÂµX be the law of the k-th output of
k
In-and-Out with initial distribution ÂµX. Let C be the (LSI-I) constant of the uniform distribution
0 LSI
Ï€X over K. Then, for any q â‰¥ 1,
R (ÂµX âˆ¥Ï€X)
R (ÂµX âˆ¥Ï€X) â‰¤ q 0 .
q k (1+h/C )2k/q
LSI
For C the (PI) constant of Ï€X and any q â‰¥ 2,
PI
ï£±
R (ÂµX âˆ¥Ï€X) â‰¤
ï£²R q(ÂµX
0
âˆ¥Ï€X)âˆ’ 2klog(1 q+h/C PI) if k â‰¤ 2log(1+q
h/C PI)
(cid:0)R q(ÂµX
0
âˆ¥Ï€X)âˆ’1(cid:1) ,
q k ï£³(1+h/C PI)âˆ’2(kâˆ’k0)/q if k â‰¥ k
0
:= âŒˆ 2log(1+q
h/C )
(cid:0)R q(ÂµX
0
âˆ¥Ï€X)âˆ’1(cid:1) âŒ‰.
PI
This reduces the problem of obtaining a mixing guarantee to that of demonstrating a functional
inequality on the target distribution. For this, it is not strictly necessary that K be convex.
On the other hand, convexity of K is crucial for the proof of (2). We show in Section 3.3 that
the failure probability remains under control by taking a suitable variance h and threshold N. We
then show that the expected number of trials per iteration is of order logN, not N:
Lemma 14 (Per-iteration guarantees). Let K be any convex body in Rd presented by a well-defined
membership oracle, Ï€X the uniform distribution over K, and Âµ an M-warm initial distribution
with respect to Ï€X. For any given m âˆˆ N and Î· âˆˆ (0,1), set Z = 9mM(â‰¥ 9), h = loglogZ and
Î· 2d2logZ
N = Z(logZ)4 = Oe(mM). Then, the failure probability of one iteration of In-and-Out is at most
Î·
Î·/m. Moreover, the expected number of membership queries needed per iteration is O(cid:0) M(log mM)4(cid:1) .
Î·
3.1 Functional inequalities
The contraction of an outer loop of our algorithm is controlled by isoperimetry of the uniform
distribution Ï€X, which is described precisely by a functional inequality. The most natural ones
to consider in this setting are the PoincarÃ© inequality (PI) and log-Sobolev inequality (LSI-I). In
Appendix C, we provide a more detailed discussion of how these are related to other important
notions of isoperimetry, such as the Cheeger and log-Cheeger inequalities.
Below, we use Âµ,Î½ to denote two arbitrary probability measures over Rd. The relationship
between a PoincarÃ© inequality and the Ï‡2-divergence is derived by substituting f = dÎ½ into (PI).
dÂµ
Lemma 15. Assume that Î½ satisfies (PI) with parameter C (Î½). For any probability measure Âµ
PI
over Rd with Âµ â‰ª Î½, it holds that
C (Î½) dÂµ
Ï‡2(Âµâˆ¥Î½) â‰¤ P 2I E Î½(cid:2)(cid:13) (cid:13)âˆ‡ dÎ½(cid:13) (cid:13)2(cid:3) .
The PoincarÃ© inequality implies functional inequalities for the RÃ©nyi divergence.
Lemma 16 ([VW19, Lemma 9]). Assume that Î½ satisfies (PI) with parameter C (Î½). For any
PI
q â‰¥ 2 and probability measure Âµ over Rd, it holds that
qC (Î½)
1âˆ’exp(âˆ’R (Âµâˆ¥Î½)) â‰¤ PI RF (Âµâˆ¥Î½),
q 4 q
where RF (Âµâˆ¥Î½) := qE (cid:2)(cid:0)dÂµ(cid:1)q âˆ¥âˆ‡log dÂµâˆ¥2(cid:3) /E (cid:2)(cid:0)dÂµ(cid:1)q(cid:3) is the RÃ©nyi Fisher information of order q
q Î½ dÎ½ dÎ½ Î½ dÎ½
of Âµ with respect to Î½.
10The log-Sobolev inequality paired with the KL-divergence (LSI-II) can be understood as a special
case of the following inequality2 paired with the q-RÃ©nyi divergence for q â‰¥ 1.
Lemma 17 ([VW19, Lemma 5]). Assume that Î½ satisfies (LSI-II) with parameter C (Î½). For any
LSI
q â‰¥ 1 and probability measure Âµ over Rd, it holds that
qC (Î½)
R (Âµâˆ¥Î½) â‰¤ LSI RF (Âµâˆ¥Î½).
q 2 q
Note that lim R = KL and RF = FI.
qâ†’1 q 1
We have collected below the functional inequalities used to establish the mixing of our algorithm
(see Appendix C for a detailed presentation).
Lemma 18. Let K âŠ‚ Rd be a convex body with diameter D, and Ï€ be the uniform distribution over
K. Then, C (Ï€) â‰² âˆ¥Cov(Ï€)âˆ¥ logd and C (Ï€) â‰² D2. If Ï€ is isotropic, then C (Ï€) â‰² logd and
PI op LSI PI
C (Ï€) â‰² D.
LSI
3.2 Contraction and mixing
We start by analyzing how many outer iterations of In-and-Out are required to be Îµ-close to Ï€X,
the uniform distribution over K. The contraction of Algorithm 1 comes from analyzing Lines 2
and 3 through the perspective of heat flows (see Section 1.1). To exploit this view, we first revisit
the previous contraction analysis in [Che+22], which is carried out for distributions with smooth
densities. Although the uniform distribution is not even continuous, we prove a technical lemma
(Lemma 22) that enables us to extend previously known results to the uniform distribution. Lastly,
combining the previous results with our technical lemma, we obtain clean contraction results of
Algorithm 1 toward the uniform distribution Ï€X in Theorem 23.
Part I: Contraction analysis for smooth distributions. Inthispart,wereviewthecontraction
results for heat flow and its time-reversal [Che+22], which are intimately connected with our
algorithm. We also provide key technical ingredients needed for its proof, such as the computations
for measures evolving under simultaneous forward/backward heat flows. We refer interested readers
to Appendix D for additional details. Only in Part I, we assume that Î½ denotes a probability
measure with smooth density.
Forward heat flow. We begin by introducing the â€œheat flowâ€ equation (or also known as the
Fokker-Planck equation), which describes the evolution of the law of Z under (FH),
t
1 1
âˆ‚ Âµ = âˆ†Âµ = div(Âµ âˆ‡logÂµ ). (FP-FH)
t t 2 t 2 t t
It is well known that one can realize this equation in discrete time through a Gaussian transition
density, in the sense that, for Âµ (the solution at time h > 0 to (FP-FH) with initial condition Âµ ),
h 0
and for any smooth function f : Rd â†’ R,
E [f(x)] = E [P f(x)],
Âµ h Âµ0 h
where P f(x) = E [f].3 By this we can formally identify Âµ = Âµ P , and also write Âµ for
h N(x,hI ) h 0 h h
d
the law of Z , where {Z } solves (FH).
h h hâ‰¥0
2Such inequalities are often called Polyak-Åojasiewicz inequalities, which say for f :Rd â†’R, and all yâˆˆRd that
f(y)â‰¤câˆ¥âˆ‡f(y)âˆ¥2 for some constant c, if minf(x)=0.
3{P } is often called the heat semigroup.
h hâ‰¥0
11Backward heat flow. Although there are many ways to define a â€œreversalâ€ of P , we will use
h
the notion of adjoint introduced by [KP21], which is the most immediately useful.
Given some initial measure Î½ and some time horizon h, the adjoint corresponds to reversing (FH)
for times in [0,h] when the initial distribution under consideration is Z âˆ¼ Î½. For other measures,
0
it must be interpreted more carefully, and is given by the following partial differential equation
starting from some measure Âµâ† (see (D.1) and its derivation):
0
1
âˆ‚ Âµâ† = âˆ’div(cid:0) Âµâ†âˆ‡log(Î½P )(cid:1)+ âˆ†Âµâ† for t âˆˆ [0,h]. (FP-BH)
t t t hâˆ’t 2 t
Write Âµâ† = Âµâ†QÎ½,h, where {QÎ½,h} is a family of transition densities. Write P for the
t 0 t t tâˆˆ[0,h] 0,h
joint distribution of the (Z ,Z )-marginals of (FH), when Z âˆ¼ Î½, and P for the conditional.
0 h 0 0|h
Note that P (Â·|x) = N(x,hI ). It is also known that (FP-BH) gives a time-reversal of the heat
h|0 d
equation at the SDE level, in the sense that we can interpret Î´ QÎ½,h = P (Â·|Z = x). Thus
x h 0|h h
Âµâ†QÎ½,h = R P (Â·|Z = x)Âµâ†(dx), and Î½P QÎ½,h = Î½P for all t âˆˆ [0,h].
0 h 0|h h 0 h t hâˆ’t
The ultimate purpose of this machinery is to affirm our earlier description of the Gibbs sampling
procedure as alternating forward and backward heat flows. Indeed, notice that, if ÂµX is the law of
i
the iterate at some iteration i, then ÂµXP is precisely ÂµY under our scheme, while (ÂµXP )QÏ€X,h
i h i+1 i h h
is ÂµX , assuming QÏ€X,h is well defined for non-smooth measures Ï€X. Thus, while Algorithm 1 is
i+1 h
implemented via discrete steps, it can be exactly analyzed through arguments in continuous time.
We shall see the benefits of this shortly.
Instead of considering the change in metrics along the evolution of ÂµP with respect to â€œfixedâ€
t
Î½, it will be useful to consider the simultaneous evolution of ÂµP ,Î½P (and similarly ÂµQ ,(Î½P )Q ).
t t t h t
This type of computation was carried out for specific metrics in earlier work [VW19; Che+22]. The
following is a more generalized form of one appearing in [Yua+23, Lemma 2]. In the lemma below,
we consider an arbitrary diffusion equation with corresponding Fokker-Planck equation:
1
dX = b (X )dt+ dB and âˆ‚ Âµ = âˆ’âˆ‡Â·(b Âµ )+ âˆ†Âµ (3.1)
t t t t t t t t 2 t
where b : Rd â†’ Rd is smooth, X âˆˆ Rd, and Âµ = Law(X ) if X âˆ¼ Âµ .
t t t t 0 0
Lemma 19 (Decay along forward/backward heat flows). Let (Âµ ) ,(Î½ ) denote the laws of the
t tâ‰¥0 t tâ‰¥0
solutions to (3.1) starting at Âµ ,Î½ respectively. Then, for any differentiable function g,
0 0
âˆ‚ g(cid:0) D (Âµ âˆ¥Î½ )(cid:1) = âˆ’1 gâ€²(cid:0) D (Âµ âˆ¥Î½ )(cid:1) Ã—E D âˆ‡(cid:0) fâ€²â—¦ Âµ t(cid:1) ,âˆ‡log Âµ tE .
t f t t 2 f t t Âµt Î½ Î½
t t
Proof. The case where g =Ì¸ id is an application of the chain rule, so it suffices to take g = id and
simply differentiate an f-divergence.
For brevity, we drop the variable x of functions involved, and proceed as follows:
âˆ‚ D (Âµ âˆ¥Î½ ) = Z n(cid:0) f â—¦ Âµ t(cid:1) âˆ‚ Î½ +(cid:0) fâ€²â—¦ Âµ t(cid:1)(cid:0)Âµ t(cid:1)â€² Î½ o dx
t f t t t t t
Î½ Î½ Î½
t t t
= Z n âˆ‚ Î½ (cid:16)(cid:0) f â—¦ Âµ t(cid:1) âˆ’(cid:0) fâ€²â—¦ Âµ t(cid:1)Âµ t(cid:17) +(cid:0) fâ€²â—¦ Âµ t(cid:1) âˆ‚ Âµ o dx
t t t t
Î½ Î½ Î½ Î½
t t t t
= Z (cid:2) âˆ’âˆ‡Â·(b Î½ )+ 1 âˆ†Î½ (cid:3)(cid:16)(cid:0) f â—¦ Âµ t(cid:1) âˆ’(cid:0) fâ€²â—¦ Âµ t(cid:1)Âµ t(cid:17) dx
(i) t t 2 t Î½ t Î½ t Î½ t
Z 1 Âµ
+ (cid:2) âˆ’âˆ‡Â·(b Âµ )+ âˆ†Âµ (cid:3)(cid:0) fâ€²â—¦ t(cid:1)dx,
t t 2 t Î½
t
12where in (i) we substitute the F-P equation from (3.1). Integrating by parts (i.e., R fdiv(G) =
âˆ’R âŸ¨âˆ‡f,GâŸ© for a real-valued function f and vector-valued function G), we have that
Z (cid:2) âˆ’âˆ‡Â·(b Î½ )(cid:3)(cid:0) f â—¦ Âµ t(cid:1)dx = Z D b Î½ ,(cid:0) fâ€²â—¦ Âµ t(cid:1) âˆ‡Âµ tE dx. (3.2)
t t t t
Î½ Î½ Î½
t t t
On the other hand, we have that
âˆ’Z (cid:2) âˆ’âˆ‡Â·(b Î½ )(cid:3)(cid:0) fâ€²â—¦ Âµ t(cid:1)Âµ t dx = âˆ’Z D b Î½ , Âµ t âˆ‡(cid:0) fâ€²â—¦ Âµ t(cid:1)+(cid:0) fâ€²â—¦ Âµ t(cid:1) âˆ‡Âµ tE dx.
t t t t
Î½ Î½ Î½ Î½ Î½ Î½
t t t t t t
The second term cancels with the RHS of (3.2). We have a similar cancellation for the 1âˆ†Î½ term:
2 t
Z 1 âˆ†Î½ (cid:0) f â—¦ Âµ t(cid:1)dx = âˆ’Z 1 D âˆ‡Î½ ,(cid:0) fâ€²â—¦ Âµ t(cid:1) âˆ‡Âµ tE dx,
2 t Î½ 2 t Î½ Î½
t t t
and
âˆ’Z 1 âˆ†Î½ (cid:0) fâ€²â—¦ Âµ t(cid:1)Âµ t dx = Z 1 D âˆ‡Î½ , Âµ t âˆ‡(cid:0) fâ€²â—¦ Âµ t(cid:1)+(cid:0) fâ€²â—¦ Âµ t(cid:1) âˆ‡Âµ tE dx.
2 t Î½ Î½ 2 t Î½ Î½ Î½ Î½
t t t t t t
Combining these, we are left with
Z (cid:2) âˆ’âˆ‡Â·(b Î½ )+ 1 âˆ†Î½ (cid:3)(cid:16)(cid:0) f â—¦ Âµ t(cid:1) âˆ’(cid:0) fâ€²â—¦ Âµ t(cid:1)Âµ t(cid:17) dx = âˆ’Z D b Î½ âˆ’ 1 âˆ‡Î½ ,âˆ‡(cid:0) fâ€²â—¦ Âµ t(cid:1)Âµ tE dx
t t 2 t Î½ Î½ Î½ t t 2 t Î½ Î½
t t t t t
= âˆ’Z D b Âµ âˆ’ 1 Âµ âˆ‡logÎ½ ,âˆ‡(cid:0) fâ€²â—¦ Âµ t(cid:1)E dx.
t t 2 t t Î½
t
Finally, we note that
Z (cid:2) âˆ’âˆ‡Â·(b Âµ )+ 1 âˆ†Âµ (cid:3)(cid:0) fâ€²â—¦ Âµ t(cid:1)dx = Z D b Âµ âˆ’ 1 âˆ‡Âµ ,âˆ‡(cid:0) fâ€²â—¦ Âµ t(cid:1)E dx
t t 2 t Î½ t t 2 t Î½
t t
= Z D b Âµ âˆ’ 1 Âµ âˆ‡logÂµ ,âˆ‡(cid:0) fâ€²â—¦ Âµ t(cid:1)E dx.
t t 2 t t Î½
t
Putting it all together, noticing that the drift terms cancel, we are left with
âˆ‚ D (Âµ âˆ¥Î½ ) = âˆ’Z 1 D Âµ âˆ‡log Âµ t ,âˆ‡(cid:0) fâ€²â—¦ Âµ t(cid:1)E dx = âˆ’1 E D âˆ‡log Âµ t ,âˆ‡(cid:0) fâ€²â—¦ Âµ t(cid:1)E ,
t f t t 2 t Î½ Î½ 2 Âµt Î½ Î½
t t t t
which completes the proof.
To recover the decay result for the q-RÃ©nyi divergence, one can substitute g(x) = 1 logx and
qâˆ’1
f(x) = xq âˆ’1. For the Ï‡2-divergence, instead substitute g(x) = x and f(x) = x2âˆ’1. From this,
we can obtain a single step of decay for the RÃ©nyi and Ï‡2-divergences under different functional
inequalities.
Before proceeding, we need a standard lemma on functional inequalities under (FH).
Lemma 20 (Functional inequalities under Gaussian convolutions, [Cha04, Corollary 13]). The
following inequality holds for any Ï€ with finite log-Sobolev and PoincarÃ© constants,
C (Ï€P ) â‰¤ C (Ï€)+t, and C (Ï€P ) â‰¤ C (Ï€)+t.
PI t PI LSI t LSI
Combining the previous two lemmas, we can establish contraction between ÂµP Q and Î½ after
h h
one forward/backward iteration.
13Theorem 21 ([Che+22, Theorem 3 and 4]). Assume Î½, a measure with smooth density, satisfies
(LSI-I) with constant C . For any q â‰¥ 1 and initial distribution Âµ with a smooth density, denoting
LSI
again Q := QÎ½,h,
h h
R (Âµâˆ¥Î½)
R (ÂµP Q âˆ¥Î½) â‰¤ q .
q h h (1+h/C )2/q
LSI
If Î½ satisfies (PI) with constant C , then it follows that
PI
Ï‡2(Âµâˆ¥Î½)
Ï‡2(ÂµP Q âˆ¥Î½) â‰¤ .
h h (1+h/C )2
PI
Moreover, for all q â‰¥ 2,
ï£±
R (ÂµP Q âˆ¥Î½) â‰¤
ï£²R q(Âµâˆ¥Î½)âˆ’ 2log(1+ qh/C PI) if R q(Âµâˆ¥Î½) â‰¥ 1,
q h h ï£³ (1R +q h( /Âµ Câˆ¥Î½)
)2
if R q(Âµâˆ¥Î½) â‰¤ 1.
PI
Proof. Since the SDE in (3.1) captures the forward heat flow (FH), we set Âµ and Î½ in Lemma 19
0 0
to Âµ and Î½, respectively, obtaining contraction along the forward heat flow as follows: Substituting
the q-RÃ©nyi into Lemma 19, we have, from the definition of the RÃ©nyi divergence as R (Âµâˆ¥Î½) :=
q
1 log(D (Âµâˆ¥Î½)+1), with f(x) = xq âˆ’1 and g(x) = 1 log(x+1),
qâˆ’1 f qâˆ’1
hD (cid:16) (cid:17)qâˆ’1 Ei h(cid:16) (cid:17)qâˆ’2 i
E âˆ‡ ÂµPt ,âˆ‡log ÂµPt E ÂµPt âŸ¨âˆ‡ÂµPt,âˆ‡log ÂµPtâŸ©
âˆ‚ R (ÂµP âˆ¥Î½P ) = âˆ’q ÂµPt Î½Pt Î½Pt = âˆ’q ÂµPt Î½Pt Î½Pt Î½Pt
t q t t 2 h(cid:16) (cid:17)qi 2 h(cid:16) (cid:17)qi
(qâˆ’1)E ÂµPt (i) E ÂµPt
Î½Pt Î½Pt Î½Pt Î½Pt
h(cid:16) (cid:17)q i
=
âˆ’q E Î½Pt Âµ Î½PP tt âˆ¥âˆ‡log Âµ Î½PP ttâˆ¥2
=
âˆ’1
RF (ÂµP âˆ¥Î½P ),
(ii)
2
E
h(cid:16) ÂµPt(cid:17)qi 2 q t t
Î½Pt Î½Pt
where in (i), we use again that âˆ‡(cid:2) fâ€²(cid:0)Âµt(cid:1)Âµt(cid:3) = âˆ‡(cid:0) fâ€² â—¦ Âµt(cid:1) Â· Âµt + fâ€²(cid:0)Âµt(cid:1) âˆ‡Âµt, and (ii) uses that
Î½t Î½t Î½t Î½t Î½t Î½t
âˆ‡ÂµPt = ÂµPtâˆ‡log ÂµPt, and the last equality recalls the definition of the RÃ©nyi Fisher information.
ThÎ½ iP styieldÎ½P st Î½Pt
1 1R (ÂµP âˆ¥Î½P ) 1R (ÂµP âˆ¥Î½P )
âˆ‚ R (ÂµP âˆ¥Î½P ) = âˆ’ RF (ÂµP âˆ¥Î½P ) â‰¤ âˆ’ q t t â‰¤ âˆ’ q t t ,
t q t t 2 q t t q C (Î½P ) q C +t
(i) LSI t (ii) LSI
where we used Lemma 17 in (i) and Lemma 20 in (ii). Applying GrÃ¶nwallâ€™s inequality (Lemma 10),
(cid:16) 1 Z h 1 (cid:17) R (Âµâˆ¥Î½)
R (ÂµP âˆ¥Î½P ) â‰¤ exp âˆ’ dt R (Âµâˆ¥Î½) â‰¤ q .
q h h q C +t q (1+h/C )1/q
0 LSI LSI
Since the SDE (3.1) also captures the backward equation (BH), we set Âµ and Î½ in Lemma 19
0 0
to ÂµP and Î½Ëœ := Î½P respectively, obtaining contraction along the backward heat flow:
h h
1 1 R (ÂµP Q âˆ¥Î½ËœQ ) 1 R (ÂµP Q âˆ¥Î½ËœQ )
âˆ‚ R (ÂµP Q âˆ¥Î½ËœQ ) = âˆ’ RF (ÂµP Q âˆ¥Î½ËœQ ) â‰¤ âˆ’ q h t t â‰¤ âˆ’ q h t t ,
t q h t t 2 q h t t q C (Î½ËœQ ) q C +hâˆ’t
LSI t (i) LSI
where (i) follows from that Î½ËœQ = Î½P Q = Î½P and C (Î½ËœQ ) â‰¤ C +hâˆ’t due to Lemma 20.
t h t hâˆ’t LSI t LSI
Applying Lemma 10 again yields
R (ÂµP âˆ¥Î½Ëœ)
R (ÂµP Q âˆ¥Î½) â‰¤ q h .
q h h (1+h/C )1/q
LSI
14Composing these two inequalities leads to the decay rate claimed in the theorem.
The result in the Ï‡2-divergence can be derived entirely analogously. For instance, the decay
from the forward part can be shown as follows:
1 h(cid:13) ÂµP (cid:13)2i Ï‡2(ÂµP âˆ¥Î½P ) Ï‡2(ÂµP âˆ¥Î½P )
âˆ‚ Ï‡2(ÂµP âˆ¥Î½P ) = âˆ’ E (cid:13)âˆ‡ t(cid:13) â‰¤ âˆ’ t t â‰¤ âˆ’ t t ,
t t t 2 Î½Pt (cid:13) Î½P (cid:13) C (Î½P ) C +t
t (i) PI t PI
where (i) follows from Lemma 15. Applying GrÃ¶nwallâ€™s inequality then gives
(cid:16) Z h 1 (cid:17) Ï‡2(Âµâˆ¥Î½)
Ï‡2(ÂµP âˆ¥Î½P ) â‰¤ exp âˆ’ dt Ï‡2(Âµâˆ¥Î½) â‰¤ .
h h C +t 1+h/C
0 PI PI
The decay along the backward heat flow in Ï‡2 is entirely analogous to the RÃ©nyi case. Then we
combine two contraction results from the forward and backward flows, completing the proof.
The result in the R under (PI) can be shown in a similar manner. Only difference is that in
q
forward and backward computations, one should use the functional inequality in Lemma 16 and the
following standard inequalities:
(1 if R (Âµâˆ¥Î½) â‰¥ 1,
1âˆ’exp(cid:0) âˆ’R (Âµâˆ¥Î½)(cid:1) â‰¥ 2 q
q 1R (Âµâˆ¥Î½) if R (Âµâˆ¥Î½) â‰¤ 1.
2 q q
Part II: Extension to constrained distributions. We now prove a technical lemma that
extends the contraction results to constrained distributions. This lemma guarantees the existence of
weak solutions to two stochastic processes that describe the evolution of distributions involved in
Line 2 and 3 in In-and-Out, in addition to lower-semicontinuity of f-divergence. We shall prove it
for any measure that is absolutely continuous with respect to Ï€X, since this imposes no additional
technical hurdles.
Lemma 22. Let Î½ be a measure, absolutely continuous with respect to the uniform measure Ï€X.
The forward and backward heat flow equations given by
1
âˆ‚ Âµ = âˆ†Âµ ,
t t 2 t
1
âˆ‚ Âµâ† = âˆ’div(cid:0) Âµâ†âˆ‡log(Î½P )(cid:1)+ âˆ†Âµâ† with Âµâ† = Âµ ,
t t t hâˆ’t 2 t 0 h
admit solutions on (0,h], and the weak limit lim Âµâ† = Âµâ† exists for any initial measure Âµ with
tâ†’h t h 0
bounded support. Moreover, for any f-divergence with f lower semi-continuous,
D (Âµâ†âˆ¥Î½) â‰¤ limD (Âµâ† âˆ¥Î½ ).
f h f hâˆ’t t
tâ†“0
Proof. The existence of weak solutions for the forward equation is well-known, since Âµ can be
0
weakly approximated by measures with continuous density, for which the heat equation admits a
unique solution for all time. In particular, the weak solution is Câˆ for t > 0.
The reverse SDE is more subtle, since âˆ‡logÎ½P will in general cease to be Lipschitz as t â†’ 0.
t
On the other hand, for any h > 0, we can write explicitly
1 Z âˆ¥xâˆ’yâˆ¥2
Âµ (x) = exp(cid:0) âˆ’ (cid:1)dÂµ (y).
h (2Ï€h)d/2 2h 0
15If one considers the system started at ÂµËœ = Âµ = Î½P and solve the forward-backward Fokker-Planck
0 Ïµ Ïµ
equations on times [0,hâˆ’Ïµ], then ÂµËœ = Âµ = Âµâ† = ÂµËœâ† and
hâˆ’Ïµ h 0 0
Z exp(cid:0) âˆ’âˆ¥xâˆ’yâˆ¥2(cid:1) Î½P (x)
Âµâ† (x) = ÂµËœâ† (x) = 2(hâˆ’Ïµ) Ïµ dÂµ (y).
hâˆ’Ïµ hâˆ’Ïµ R exp(cid:0) âˆ’âˆ¥zâˆ’yâˆ¥2(cid:1) Î½P (z)dz h
2(hâˆ’Ïµ) Ïµ
This follows from that if we consider system started at time Ïµ > 0, with initial distribution Âµ , then
Ïµ
we obtain the above through the Bayesian perspective on the forward and reverse heat semigroups,
elaborated in Appendix D.
We now show that the following integral is indeed integrable, so ÂµËœâ† is well-defined:
h
Z exp(cid:0) âˆ’âˆ¥xâˆ’yâˆ¥2(cid:1) Î½(x)
ÂµËœâ†(x) := 2h dÂµ (y).
h R exp(cid:0) âˆ’âˆ¥zâˆ’yâˆ¥2(cid:1) Î½(z)dz h
2h
For fixed x and Ïµ < h/2,
Z âˆ¥zâˆ’yâˆ¥2 (âˆ¥yâˆ’x âˆ¥+D)2
exp(cid:0) âˆ’ (cid:1) Î½(z)dz â‰³ exp(cid:0) âˆ’ 0 (cid:1) ,
2(hâˆ’Ïµ) 2(hâˆ’Ïµ)
asthesupportofÎ½ isconstrainedtoK âŠ‚ B (x ). SinceÂµ hasboundedsupport,Âµ (y) â‰² exp(âˆ’âˆ¥yâˆ¥2)
D 0 0 h a
for some constant a > 0. Thus,
exp(cid:0) âˆ’âˆ¥ 2x (hâˆ’ âˆ’yâˆ¥ Ïµ)2(cid:1) Âµ h(y)
â‰²
exp(cid:0) âˆ’âˆ¥ 2x (hâˆ’ âˆ’yâˆ¥ Ïµ)2(cid:1) Âµ h(y)
â‰²
exp(cid:16)âŸ¨2(xâˆ’x 0),yâŸ©+2Dâˆ¥yâˆ’x 0âˆ¥
âˆ’
âˆ¥yâˆ¥2(cid:17)
,
R exp(cid:0) âˆ’âˆ¥zâˆ’yâˆ¥2(cid:1) Î½P (z)dz exp(âˆ’(âˆ¥yâˆ’x0âˆ¥+D)2) h a
2(hâˆ’Ïµ) Ïµ 2(hâˆ’Ïµ)
and the last bound is integrable in y.
We then show the pointwise convergence of ÂµËœâ† to ÂµËœâ† as Ïµ â†’ 0. Note that Î½P â†’ Î½, as Î½ has
hâˆ’Ïµ h Ïµ
a bounded support. Also, the denominator is independent of Ïµ due to
1 Z âˆ¥zâˆ’yâˆ¥2
exp(cid:0) âˆ’ (cid:1) Î½P (z)dz = N(0,(hâˆ’Ïµ)I)âˆ—Î½P = Î½ âˆ—N(0,hI).
(2Ï€(hâˆ’Ïµ))d/2 2(hâˆ’Ïµ) Ïµ Ïµ
Hence, for Ïµ â‰¤ dâˆ’1,
exp(cid:0) âˆ’âˆ¥ 2x (hâˆ’ âˆ’yâˆ¥ Ïµ)2(cid:1)
â‰¤
(cid:16) h (cid:17)d/2
exp(cid:0) âˆ’âˆ¥xâˆ’ 2hyâˆ¥2(cid:1)
â‰²
exp(cid:0) âˆ’âˆ¥xâˆ’ 2hyâˆ¥2(cid:1)
.
R exp(cid:0) âˆ’âˆ¥zâˆ’yâˆ¥2(cid:1) Î½P (z)dz hâˆ’Ïµ R exp(cid:0) âˆ’âˆ¥zâˆ’yâˆ¥2(cid:1) Î½(z)dz R exp(cid:0) âˆ’âˆ¥zâˆ’yâˆ¥2(cid:1) Î½(z)dz
2(hâˆ’Ïµ) Ïµ 2h 2h
As shown above, the last bound is integrable with respect to Âµ , so the dominated convergence
h
theorem implies
Z exp(cid:0) âˆ’âˆ¥xâˆ’yâˆ¥2(cid:1) Z exp(cid:0) âˆ’âˆ¥xâˆ’yâˆ¥2(cid:1)
lim 2(hâˆ’Ïµ) dÂµ (y) = 2h dÂµ (y),
Ïµâ†’0 R exp(cid:0) âˆ’âˆ¥zâˆ’yâˆ¥2(cid:1) Î½P (z)dz h R exp(cid:0) âˆ’âˆ¥zâˆ’yâˆ¥2(cid:1) Î½(z)dz h
2(hâˆ’Ïµ) Ïµ 2h
Thus, the pointwise convergence follows. Note that if we take Î½(x) = Ï€X(x) = 1 K(x), then ÂµËœâ† is
vol(K) h
the distribution of the backwards step of our algorithm. In particular, this corresponds to first
sampling x âˆ¼ Âµ , then y âˆ¼ QÎ½,h(Â·|x), which is precisely the law of Âµâ† given by (FP-BH).
h h h
As for the second statement, it follows from ScheffÃ©â€™s lemma [Bil95, Theorem 16.12] that the
pointwise convergence of Âµâ† â†’ Âµâ† leads to its TV-convergence, which in turn implies the weak
hâˆ’Îµ h
convergence. It follows from lower semicontinuity of D [AFP00, Theorem 2.34] that the weak
f
convergence ensures D (Âµâ†âˆ¥Î½) â‰¤ lim D (Âµâ† âˆ¥Î½â† ).
f h tâ†“0 f hâˆ’t hâˆ’t
16In the sequel, we will only consider Î½ = Ï€X. Since the RÃ©nyi divergence is a continuous
function of the Ï‡q divergence (see Definition 6), which itself is an f-divergence, it enjoys the same
lower-semicontinuity properties. Using this lower-semicontinuity together with the decay results in
Theorem 21, we can easily derive the contraction results of In-and-Out in R and Ï‡q for any q â‰¥ 1.
q
We remark that this result does not require convexity of K.
Theorem 23. Let ÂµX be the law of the k-th output of In-and-Out with initial distribution ÂµX. Let
k 0
C be the (LSI-I) constant of the uniform distribution Ï€X over K. Then, for any q â‰¥ 1,
LSI
R (ÂµX âˆ¥Ï€X)
R (ÂµX âˆ¥Ï€X) â‰¤ q 0 .
q k (1+h/C )2k/q
LSI
For C the (PI) constant of Ï€X,
PI
Ï‡2(ÂµX âˆ¥Ï€X)
Ï‡2(ÂµX âˆ¥Ï€X) â‰¤ 0 .
k (1+h/C )2k
PI
Furthermore, for any q â‰¥ 2,
ï£±
R (ÂµX âˆ¥Ï€X) â‰¤
ï£²R q(ÂµX
0
âˆ¥Ï€X)âˆ’ 2klog(1 q+h/C PI) if k â‰¤ 2log(1+q
h/C PI)
(cid:0)R q(ÂµX
0
âˆ¥Ï€X)âˆ’1(cid:1) ,
q k ï£³(1+h/C PI)âˆ’2(kâˆ’k0)/q if k â‰¥ k
0
:= âŒˆ 2log(1+q
h/C )
(cid:0)R q(ÂµX
0
âˆ¥Ï€X)âˆ’1(cid:1) âŒ‰.
PI
Proof. Let us set Âµ = ÂµX and Ï€ = Ï€X. Then, Âµ = Âµâ† = ÂµY, Ï€ = Ï€â† = Ï€Y, and Âµâ† = ÂµX,
0 0 0 h 0 1 h 0 h 1
Ï€â† = Ï€X. For small Ïµ > 0, as Âµ = (ÂµX) = ÂµX âˆ—N(0,ÏµI ) is Câˆ-smooth, we can now invoke the
h Ïµ 0 Ïµ 0 d
decayresultswithstepsizehâˆ’ÏµinTheorem21. Thus,forcontractionconstantsC = (1+ hâˆ’Ïµ )âˆ’2/q
Ïµ C +Ïµ
LSI
and C = (1+ hâˆ’Ïµ )âˆ’2 respectively when Î¦ = R and Î¦ = Ï‡2,
Ïµ C +Ïµ q
PI
Î¦(Âµâ† âˆ¥Ï€ ) â‰¤ C Â·Î¦(Âµ âˆ¥Ï€ ) â‰¤ C Â·Î¦(Âµ âˆ¥Ï€ ),
hâˆ’Ïµ Ïµ Ïµ Ïµ Ïµ Ïµ 0 0
where we used the data-processing inequality for the last inequality. By the second result of
Lemma 22, sending Ïµ â†’ 0 leads to
Î¦(ÂµX âˆ¥Ï€X) = Î¦(Âµâ†âˆ¥Ï€ ) â‰¤ C Â·Î¦(Âµ âˆ¥Ï€ ) = C Â·Î¦(ÂµX âˆ¥Ï€X).
1 h 0 0 0 0
Repeating this argument k times completes the proof.
3.3 Failure probability and wasted steps
We begin by defining a suitable version of local conductance [KLS97].
Definition 24 (Local conductance). The local conductance â„“ on Rd is defined by
R exp(âˆ’ 1 âˆ¥xâˆ’yâˆ¥2)dy R exp(âˆ’ 1 âˆ¥xâˆ’yâˆ¥2)dy
â„“(x) d=ef K 2h = K 2h .
R exp(âˆ’ 1 âˆ¥xâˆ’yâˆ¥2)dy (2Ï€h)d/2
Rd 2h
The local conductance at y quantifies the success probability of the proposal at y in Line 3.
Then the expected number of trials until the first success of Line 3 is 1/â„“(y). Revisiting (1.1), we
can notice Ï€Y(y) = â„“(y)/vol(K).
17NaÃ¯ve analysis for expected number of trials. Starting from Ï€X, when we just naÃ¯vely sample
from Ï€Y|X(Â·|x) for all x without imposing any failure condition, the expected number of trials for
one iteration is that for the probability density p of N(x,hI ),
x d
Z Z 1 Z 1 Z 1 â„“(y)
p (dy)Ï€X(dx) = Ï€Y(dy) = dy = âˆ.
K Rd
â„“(y) x
Rd
â„“(y)
Rd
â„“(y) vol(K)
This suggests that one should consider the algorithm as having â€œfailedâ€ if the number of trials
exceeds some threshold.
Refined analysis under a failure condition. Going forward, we assume an M-warm start as
in previous work for uniform sampling algorithms. By induction we have dÂµX i â‰¤ M for all i.
dÏ€X
Lemma 25 (Propagation of warm-start). From an M-warm start, we have dÂµX
i
/dÏ€X â‰¤ M for all i.
Proof. Assume that ÂµX satisfies the M-warm start. Then, for any measurable S and the transition
i
kernel T of Algorithm 1 at x,
x
Z Z
ÂµX (S) = T (S)dÂµX(x) â‰¤ M T (S)dÏ€X(x) = MÏ€X(S),
i+1 x i x
K K
where the last equality follows from the stationarity of Ï€. Hence, dÂµX /dÏ€X â‰¤ M.
i+1
We now establish a lemma that comes in handy when analyzing the failure probability of the
algorithm. In essence, this lemma bounds the probability that taking a Gaussian step from Ï€X in
Line2getsÎ´-distanceawayfromK. LetusdenotetheÎ´-blowupofKbyK := {x âˆˆ Rd : d(x,K) â‰¤ Î´}.
Î´
Lemma 26. Ï€Y(K Î´c) â‰¤ ec2 1exp(âˆ’t2/8c2 1) for Î´ = t/d and variance h = c2 1/d2, where c
1
is some
constant and t â‰¥ 2c (c +1).
1 1
Proof. For y âˆˆ âˆ‚K , we can take the supporting half-space H at proj (y) containing K, due to
Î´ K
convexity of K. Then,
1 Z Z exp(cid:0) âˆ’ 1 âˆ¥yâˆ’xâˆ¥2(cid:1) 1 Z Z exp(cid:0) âˆ’ 1 âˆ¥yâˆ’xâˆ¥2(cid:1)
Ï€Y(Kc) = 2h dxdy â‰¤ 2h dxdy
Î´ vol(K)
Kc K
(2Ï€h)d/2 vol(K)
Kc H
(2Ï€h)d/2
Î´ Î´
1 Z Z âˆ exp(cid:0) âˆ’ 1 z2(cid:1)
= âˆš 2h dzdy. (3.3)
vol(K)
Kc d(y,K)
2Ï€h
Î´
Let us denote the tail probability of the 1-dimensional Gaussian with variance h by
1 Z âˆ 1
T(s) := P (Z â‰¥ s) = âˆš exp(cid:0) âˆ’ z2(cid:1)dz.
Zâˆ¼N(0,h) 2Ï€h
s
2h
By the co-area formula and integration by parts,
Z Z âˆ exp(cid:0) âˆ’ 1 z2(cid:1) Z âˆ
âˆš 2h dzdy = T(s)vol(âˆ‚K )ds
Kc d(y,K)
2Ï€h
Î´
s
Î´
= h T(s)Z s vol(âˆ‚K )dziâˆ +Z âˆ âˆš1 exp(cid:0) âˆ’s2 (cid:1)Z s vol(âˆ‚K )dzds. (3.4)
0
z
Î´ Î´
2Ï€h 2h
0
z
| {z }
=:F
18Recall that T(s) â‰¤ 1 exp(âˆ’1(shâˆ’1/2)2) for s â‰¥ Î´ = t/d due to a standard tail bound on a Gaussian
2 2
distribution. This tail bound, combined with
Z s
vol(âˆ‚K )dz = vol(K )âˆ’vol(K) â‰¤ vol(cid:0)(1+s)K(cid:1) âˆ’vol(K) = (cid:0)(1+s)dâˆ’1(cid:1)vol(K),
z s
0
ensures that F vanishes at s = âˆ. Hence, bounding the first term in (3.4) by 0 results in
Z Z âˆ exp(cid:0) âˆ’ 1 z2(cid:1) 1 Z âˆ s2
âˆš 2h dzdy â‰¤ âˆš exp(cid:0) âˆ’ (cid:1)(cid:0)(1+s)dâˆ’1(cid:1)vol(K)ds
Kc d(y,K)
2Ï€h 2Ï€h
Î´
2h
| {z }
Î´
â‰¤exp(sd)
vol(K) Z âˆ (cid:16) 1 (cid:17)
â‰¤ âˆš exp(hd2/2) exp âˆ’ (sâˆ’hd)2 ds
2Ï€h
Î´
2h
1
â‰¤
vol(K)exp(hd2/2)exp(cid:0)
âˆ’
(Î´hâˆ’1/2âˆ’dh1/2)2(cid:1)
2
(i)
t2
â‰¤
vol(K)exp(c2/2)exp(cid:0)
âˆ’
(cid:1)
,
1 8c2
(ii) 1
where in (i) we used the tail bound of a Gaussian, and (ii) follows from that in the regime of
h = c2 1dâˆ’2, we have Î´hâˆ’1/2âˆ’dh1/2âˆ’1 â‰¥ t/c 1âˆ’(c 1+1) â‰¥ t/2c1 for t â‰¥ 2c 1(c 1+1). Putting the last
bound into (3.3) completes the proof of the claim.
Now we choose a suitable threshold N for bounding the failure probability. Following (3.3) in
the proof, one can notice that for y âˆˆ Kc, Î´ = â„¦(1/d), and h = Î˜(dâˆ’2),
Î´
Z âˆ exp(cid:0) âˆ’ 1 z2(cid:1)
â„“(y) â‰¤ âˆš 2h dz = P (Z â‰¥ Î´) â‰¤ exp(âˆ’â„¦(t2)).
d(y,K)
2Ï€h Zâˆ¼N(0,h)
Thus, the expected number of trials from Kc for the rejection sampling in Line 3 is â„“(y)âˆ’1 â‰¥
Î´
exp(â„¦(t2)). Intuitively, one can ignore whatever happens in Kc, since K takes up most of measure
Î´ Î´
ofÏ€Y. AsthenumberoftrialsfromKc isatleastexp(â„¦(t2))inexpectation,themoststraightforward
Î´
way to ignore algorithmic behaviors from Kc is simply to set the threshold to N = Oe(exp(t2)). Even
Î´
though the threshold is N, the expected number of trials is much lower.
Lemma 14 bounds the failure probability and expected number of trials per iteration.
Proof of Lemma 14. ForÂµ := Âµâˆ—N(0,hI ),thefailureprobabilityisE [(1âˆ’â„“)N]. SincedÂµ/dÏ€X â‰¤
h d Âµ h
M implies dÂµ /d(Ï€X) = dÂµ /dÏ€Y â‰¤ M, it follows that
h h h
E [(1âˆ’â„“)N] â‰¤ M E [(1âˆ’â„“)N].
Âµ h Ï€Y
Then,
Z Z Z Z
(1âˆ’â„“)N dÏ€Y = A+ A+ A
Rd| {z } K Î´c K Î´âˆ©[â„“â‰¥Nâˆ’1log(3mM/Î·)] K Î´âˆ©[â„“<Nâˆ’1log(3mM/Î·)]
=:A
Z Z â„“(y)
â‰¤ Ï€Y(Kc)+ exp(âˆ’â„“N)dÏ€Y + dy
Î´ vol(K)
[â„“â‰¥Nâˆ’1log(3mM/Î·)] K âˆ©[â„“<Nâˆ’1log(3mM/Î·)]
Î´
t2 Î· log(3mM/Î·) vol(K )
â‰¤ ec2 1exp(âˆ’ )+ + Î´
8c2 3mM N vol(K)
1
t2 Î· et 3mM
â‰¤ ec2 1exp(âˆ’ )+ + log ,
8c2 3mM N Î·
1
19where we used vol(K ) âŠ‚ vol(cid:0)(1 + Î´)K(cid:1) = (1 + Î´)dvol(K) â‰¤ etvol(K). Taking c2 = loglogZ,
âˆš Î´ 1 2logZ
t = 8loglogZ, and N = Z(logZ)4, we can bound the last line by Î· . Therefore,
mM
Î·
E [(1âˆ’â„“(Â·))N] â‰¤ M E [(1âˆ’â„“(Â·))N] â‰¤ .
Âµ h Ï€Y m
We now bound the expected number of trials per iteration. Let X be the minimum of the
threshold N and the number of trials until the first success. Then the expected number of trials per
step is bounded by ME [X] due to dÂµ /dÏ€Y â‰¤ M. Thus,
Ï€Y h
Z (cid:16)1 (cid:17) Z 1 vol(K )
âˆ§N dÏ€Y â‰¤ dÏ€Y +NÏ€Y(Kc) = Î´ +NÏ€Y(Kc)
Rd â„“ K â„“ Î´ vol(K) Î´
Î´
â‰¤ et+N exp(âˆ’â„¦(t2)) â‰¤ (logZ)3+3(logZ)4 =
O(cid:16)(cid:0)log mM (cid:1)4(cid:17)
.
Î·
Therefore, the expected number of trials per step is O(cid:0) M(log mM)4(cid:1), and the claim follows since
Î·
each trial uses one query to the membership oracle of K.
3.4 Putting it together
WecannowshowthatIn-and-Outsubsumespreviousresultsonuniformsamplingfromconvexbodies
(such as Ball walk and Speedy walk), providing detailed versions of the main results in Section 1.2.
We first establish that the query complexity of In-and-Out matches that of the Ball walk under
stronger divergences. Recall that 2âˆ¥Â·âˆ¥2 â‰¤ KL â‰¤ log(1+Ï‡2) â‰¤ Ï‡2.
TV
Theorem 27. For any given Î·,Îµ âˆˆ (0,1), q â‰¥ 1, m âˆˆ N defined below and any convex body K given
by a well-defined membership oracle, consider In-and-Out (Algorithm 1) with an M-warm initial
distribution ÂµX, h = (2d2log 9mM)âˆ’1, and N = Oe(mM). For Ï€X the uniform distribution over K,
0 Î· Î·
â€¢ It achieves R q(ÂµX mâˆ¥Ï€X) â‰¤ Îµ after m = Oe(qd2âˆ¥Cov(Ï€X)âˆ¥ oplog M Î·Îµ) iterations. With probability
1âˆ’Î·, thealgorithmiteratesthismanytimeswithoutfailure, usingOe(qMd2âˆ¥Cov(Ï€X)âˆ¥ op(log Î·1 Îµ)5)
expected number of membership queries in total.
â€¢ For isotropic Ï€X, with probability 1 âˆ’ Î·, the algorithm achieves R (ÂµX âˆ¥ Ï€X) â‰¤ Îµ with
q m
m = Oe(qd2log M) iterations, using Oe(qMd2(log 1 )5) membership queries in expectation.
Î·Îµ Î·Îµ
Proof. We just put together Lemma 14 and Theorem 23. For target accuracy Îµ > 0, we use
the R -decay under (PI) for q â‰¥ 2 in Theorem 23. The M-warm start assumption guarantees
q
R (ÂµX âˆ¥ Ï€X) â‰² logM. Due to C (Ï€X) = O(âˆ¥Cov(Ï€X)âˆ¥ logd) (Lemma 18), In-and-Out can
q 0 PI op
achieve R q(ÂµX
m
âˆ¥Ï€X) â‰¤ Îµ after m = Oe(qd2âˆ¥Cov(Ï€X)âˆ¥ oplog M Î·Îµ) iterations. Since each iteration has
Î·/m-failure probability by Lemma 14, the union bound ensures that the total failure probability is at
most Î· throughout m iterations. Lastly, each iteration requires Oe(M(log 1 )4) membership queries
Î·Îµ
in expectation by Lemma 14. Therefore, In-and-Out uses Oe(qMd2min(D2,âˆ¥Cov(Ï€X)âˆ¥ op)(log Î·1 Îµ)5)
expected number of membership queries over m iterations. Since R is non-decreasing in q, we can
q
obtain the desired bound on R for q âˆˆ [1,2).
q
For isotropic Ï€X, we have Cov(Ï€X) = I , so the claim immediately follows from C (Ï€X) =
d PI
O(logd) (see Lemma 18).
We now show that the number of proper steps is bounded as claimed for general non-convex
bodies and any feasible start in K. We first establish this result under an M-warm start (Theorem 5).
20Proof of Theorem 5. By the RÃ©nyi-decay under (LSI-I) in Theorem 23, In-and-Out can achieve
Îµ-distance to Ï€X after O(cid:0) qhâˆ’1C (Ï€X)log R q(ÂµX 1 âˆ¥Ï€X)(cid:1) iterations for q â‰¥ 1.
LSI Îµ
For q â‰¥ 2, we use the decay result under (PI). In this case, In-and-Out decays under two different
rates depending on the value of R (Â·âˆ¥Ï€X). It first needs O(qhâˆ’1C (Ï€X)R (ÂµX âˆ¥Ï€X)) iterations
q PI q 0
until R (Â·âˆ¥Ï€X) reaches 1. Then, In-and-Out additionally needs O(qhâˆ’1C (Ï€X)log 1) iterations,
q PI Îµ
and thus it needs O(qhâˆ’1C (Ï€X)(cid:0)R (ÂµX âˆ¥ Ï€X) + log 1(cid:1)) iterations in total. By substituting
PI q 0 Îµ
R (ÂµX âˆ¥Ï€X) â‰² logM, we complete the proof.
q 0
Next, we show that In-and-Out mixes from any start.
Corollary 28. For any given Îµ âˆˆ (0,1) and set K âŠ‚ B (0), In-and-Out with variance h and any
D
feasible start x
0
âˆˆ K achieves R q(ÂµX
m
âˆ¥Ï€X) â‰¤ Îµ after m = Oe(qhâˆ’1C LSI(Ï€X)log d+D Îµ2/h) iterations.
Proof. We first bound the warmness of ÂµX w.r.t. Ï€X when ÂµX = Î´ . One can readily check that
1 0 x0
Z exp(cid:0) âˆ’ 1 âˆ¥yâˆ’xâˆ¥2(cid:1)exp(cid:0) âˆ’ 1 âˆ¥yâˆ’x âˆ¥2(cid:1)
ÂµX(x) = 1 (x)Â· 2h 2h 0 dy.
1 K (2Ï€h)d/2R exp(cid:0) âˆ’ 1 âˆ¥yâˆ’xâˆ¥2(cid:1)dx
K 2h
By Youngâ€™s inequality, âˆ¥yâˆ’xâˆ¥2 â‰¤ (âˆ¥yâˆ¥+D)2 â‰¤ 3âˆ¥yâˆ¥2+3D2 for x âˆˆ K. Hence,
2
Z exp(cid:0) âˆ’ 1 âˆ¥yâˆ’xâˆ¥2(cid:1)exp(cid:0) âˆ’ 1 âˆ¥yâˆ’x âˆ¥2(cid:1)
2h 2h 0 dy
R exp(cid:0) âˆ’ 1 âˆ¥yâˆ’xâˆ¥2(cid:1)dx
K 2h
â‰¤exp(2hâˆ’1D2) Z exp(cid:16) âˆ’ 1 (cid:0) âˆ¥yâˆ’xâˆ¥2+âˆ¥yâˆ’x âˆ¥2âˆ’ 3 âˆ¥yâˆ¥2(cid:1)(cid:17) dy
vol(K) 2h 0 2
=exp(2hâˆ’1D2) Z exp(cid:16)
âˆ’
1 (cid:0)1
âˆ¥yâˆ’2(x+x )âˆ¥2+(âˆ¥xâˆ¥2+âˆ¥x âˆ¥2âˆ’2âˆ¥x+x
âˆ¥2)(cid:1)(cid:17)
dy
vol(K) 2h 2 0 0 0
exp(5hâˆ’1D2) Z (cid:16) 1 (cid:17)
â‰¤ exp âˆ’ âˆ¥yâˆ’2(x+x )âˆ¥2 dy
vol(K) 4h 0
exp(5hâˆ’1D2)
= (4Ï€h)d/2.
vol(K)
Therefore, M = esssup ÂµX 1 â‰¤ 2d/2exp(5hâˆ’1D2). By Theorem 5 under (LSI-I), In-and-Out needs
Ï€X
Oe(qhâˆ’1C LSI(Ï€X)log d+D Îµ2/h) iterations.
We then obtain the following corollary for a convex body K.
Corollary 29. For any given Îµ âˆˆ (0,1) and convex body K âŠ‚ B (0), In-and-Out with variance h
D
and an M-warm initial distribution achieves R q(ÂµX mâˆ¥Ï€X) â‰¤ Îµ after m = Oe(qhâˆ’1D2log 1 Îµ) iterations.
If Ï€X is isotropic, then In-and-Out only needs Oe(qhâˆ’1Dlog d+d2/h) iterations.
Îµ
Proof. For convex K, it follows from Lemma 18 that C (Ï€X) = O(D2) and C (Ï€X) = O(D) for
LSI LSI
isotropic K. The rest of the proof can be completed in a similar way.
For h = Î˜Ëœ(dâˆ’2), In-and-Out requires Oe(qd2D2) iterations and in particular Oe(qd2D) iteration
for isotropic uniform distributions. These results match those of Speedy walk [KLM06; LV17] (see
Theorem 31).
Acknowledgements. We are deeply grateful to Andre Wibisono and Sinho Chewi for helpful
comments and pointers to the literature for Lemma 19. This work was supported in part by NSF
award 210644, NSERC through the CGS-D award, and a Simons Investigator award.
21References
[AC21] K.AhnandS.Chewi.â€œEfficientconstrainedsamplingviathemirror-Langevinalgorithmâ€.
In: Advances in Neural Information Processing Systems (NeurIPS) 34 (2021), pp. 28405â€“
28418.
[AFP00] L. Ambrosio, N. Fusco, and D. Pallara. Functions of bounded variation and free discon-
tinuity problems. Oxford University Press, 2000.
[AGS05] L. Ambrosio, N. Gigli, and G. SavarÃ©. Gradient flows: in metric spaces and in the space
of probability measures. Springer Science & Business Media, 2005.
[BNN06] M. Belkin, H. Narayanan, and P. Niyogi. â€œHeat flow and a faster algorithm to compute
the surface area of a convex bodyâ€. In: Foundations of Computer Science (FOCS). IEEE.
2006, pp. 47â€“56.
[Bes+95] J.Besag,P.Green,D.Higdon,andK.Mengersen.â€œBayesiancomputationandstochastic
systemsâ€. In: Statistical Science (1995), pp. 3â€“41.
[Bil95] P. Billingsley. Probability and measure. John Wiley & Sons, 1995.
[Bin+19] E. Bingham, J. P. Chen, M. Jankowiak, F. Obermeyer, N. Pradhan, T. Karaletsos, R.
Singh,P.A.Szerlip,P.Horsfall,andN.D.Goodman.â€œPyro:Deepuniversalprobabilistic
programmingâ€. In: The Journal of Machine Learning Research (JMLR) 20 (2019), 28:1â€“
28:6.
[Bro+17] N. Brosse, A. Durmus, Ãƒ. Moulines, and M. Pereyra. â€œSampling from a log-concave
distributionwithcompactsupportwithproximalLangevinMonteCarloâ€.In:Conference
on Learning Theory (COLT). Vol. 65. PMLR, 2017, pp. 319â€“342.
[BEL15] S. Bubeck, R. Eldan, and J. Lehec. â€œFinite-time analysis of projected Langevin Monte
Carloâ€. In: Advances in Neural Information Processing Systems (NeurIPS). Vol. 28.
2015.
[BEL18] S. Bubeck, R. Eldan, and J. Lehec. â€œSampling from a log-concave distribution with
projected Langevin Monte Carloâ€. In: Discrete & Computational Geometry (DCG) 59
(2018), pp. 757â€“783.
[Cha04] D. ChafaÃ¯. â€œEntropies, convexity, and functional inequalities, On Phi-entropies and
Phi-Sobolev inequalitiesâ€. In: Journal of Mathematics of Kyoto University 44.2 (2004),
pp. 325â€“363.
[Che70] J. Cheeger. â€œA lower bound for the smallest eigenvalue of the Laplacianâ€. In: Problems
in analysis 625.195-199 (1970), p. 110.
[Che+22] Y. Chen, S. Chewi, A. Salim, and A. Wibisono. â€œImproved analysis for a proximal
algorithm for samplingâ€. In: Conference on Learning Theory (COLT). PMLR. 2022,
pp. 2984â€“3014.
[Che21] Y. Chen. â€œAn almost constant lower bound of the isoperimetric coefficient in the KLS
conjectureâ€. In: Geometric and Functional Analysis (GAFA) 31 (2021), pp. 34â€“61.
[Che24] S. Chewi. Log-concave sampling. Book draft available at https://chewisinho.github.
io, 2024.
[CV16] B. Cousins and S. S. Vempala. â€œA practical volume algorithmâ€. In: Mathematical
Programming Computation 8.2 (2016), pp. 133â€“160.
22[CV18] B. Cousins and S. S. Vempala. â€œGaussian Cooling and Oâˆ—(n3) algorithms for volume and
Gaussian volumeâ€. In: SIAM Journal on Computing (SICOMP) 47.3 (2018), pp. 1237â€“
1273.
[Dal17] A.Dalalyan.â€œFurtherandstrongeranalogybetweensamplingandoptimization:Langevin
Monte Carlo and gradient descentâ€. In: Conference on Learning Theory (COLT). PMLR.
2017, pp. 678â€“689.
[DT12] A. S. Dalalyan and A. B. Tsybakov. â€œSparse regression learning by aggregation and
Langevin Monte-Carloâ€. In: Journal of Computer and System Sciences 78.5 (2012),
pp. 1423â€“1443.
[DMM19] A. Durmus, S. Majewski, and B. Miasojedow. â€œAnalysis of Langevin Monte Carlo via
convex optimizationâ€. In: The Journal of Machine Learning Research (JMLR) 20.1
(2019), pp. 2666â€“2711.
[DFK91] M. Dyer, A. Frieze, and R. Kannan. â€œA random polynomial-time algorithm for approx-
imating the volume of convex bodiesâ€. In: Journal of the ACM (JACM) 38.1 (1991),
pp. 1â€“17.
[Eld13] R. Eldan. â€œThin shell implies spectral gap up to polylog via a stochastic localization
schemeâ€. In: Geometric and Functional Analysis (GAFA) 23.2 (2013), pp. 532â€“569.
[FYC23] J. Fan, B. Yuan, and Y. Chen. â€œImproved dimension dependence of a proximal algorithm
for samplingâ€. In: Conference on Learning Theory (COLT). PMLR. 2023, pp. 1473â€“1521.
[GKV23] K. Gatmiry, J. Kelner, and S. S. Vempala. â€œSampling with barriers: Faster mixing via
Lewis weightsâ€. In: arXiv preprint arXiv:2303.00480 (2023).
[GC11] M. Girolami and B. Calderhead. â€œRiemann manifold Langevin and Hamiltonian Monte
Carlo methodsâ€. In: Journal of the Royal Statistical Society: Series B (Statistical
Methodology) 73.2 (2011), pp. 123â€“214.
[Gop+23] S. Gopi, Y. T. Lee, D. Liu, R. Shen, and K. Tian. â€œAlgorithmic aspects of the Log-
Laplace transform and a non-Euclidean proximal samplerâ€. In: Conference on Learning
Theory (COLT). Vol. 195. PMLR, 2023, pp. 2399â€“2439.
[GLS88] M. GrÃ¶tschel, L. LovÃ¡sz, and A. Schrijver. Geometric algorithms and combinatorial
optimization. Vol. 2. Springer, 1988.
[GHZ22] M. GÃ¼rbÃ¼zbalaban, Y. Hu, and L. Zhu. â€œPenalized Langevin and Hamiltonian Monte
Carlo algorithms for constrained samplingâ€. In: arXiv preprint arXiv:2212.00570 (2022).
[Har+17] H. S. HaraldsdÃ³ttir, B. Cousins, I. Thiele, R. M. Fleming, and S. S. Vempala. â€œCHRR:
coordinate hit-and-run with rounding for uniform sampling of constraint-based modelsâ€.
In: Bioinformatics 33.11 (2017), pp. 1741â€“1743.
[Jia+21] H. Jia, A. Laddha, Y. T. Lee, and S. S. Vempala. â€œReducing isotropy and volume to
KLS: an Oâˆ—(n3Ïˆ2) volume algorithmâ€. In: Symposium on Theory of Computing (STOC).
2021, pp. 961â€“974.
[Jia21] Q. Jiang. â€œMirror Langevin Monte Carlo: the case under isoperimetryâ€. In: Advances in
Neural Information Processing Systems (NeurIPS) 34 (2021), pp. 715â€“725.
[KLM06] R.Kannan,L.LovÃ¡sz,andR.Montenegro.â€œBlockingconductanceandmixinginrandom
walksâ€. In: Combinatorics, Probability and Computing 15.4 (2006), pp. 541â€“570.
[KLS95] R.Kannan,L.LovÃ¡sz,andM.Simonovits.â€œIsoperimetricproblemsforconvexbodiesand
a localization lemmaâ€. In: Discrete & Computational Geometry 13.3 (1995), pp. 541â€“559.
23[KLS97] R. Kannan, L. LovÃ¡sz, and M. Simonovits. â€œRandom walks and an Oâˆ—(n5) volume
algorithm for convex bodiesâ€. In: Random Structures & Algorithms (RS&A) 11.1 (1997),
pp. 1â€“50.
[KN12] R. Kannan and H. Narayanan. â€œRandom walks on polytopes and an affine interior point
method for linear programmingâ€. In: Mathematics of Operations Research 37.1 (2012),
pp. 1â€“20.
[KP21] B. Klartag and E. Putterman. â€œSpectral monotonicity under Gaussian convolutionâ€. In:
arXiv preprint arXiv:2107.09496 (2021).
[Kla23] B. Klartag. â€œLogarithmic bounds for isoperimetry and slices of convex setsâ€. In: Ars
Inveniendi Analytica (2023).
[KL22] B. Klartag and J. Lehec. â€œBourgainâ€™s slicing problem and KLS isoperimetry up to
polylogâ€. In: Geometric and Functional Analysis (GAFA) 32.5 (2022), pp. 1134â€“1159.
[Koo+22] Y.Kook,Y.T.Lee,R.Shen,andS.S.Vempala.â€œSamplingwithRiemannianHamiltonian
Monte Carlo in a constrained spaceâ€. In: vol. 35. 2022, pp. 31684â€“31696.
[Koo+23] Y. Kook, Y. T. Lee, R. Shen, and S. S. Vempala. â€œCondition-number-independent
convergence rate of Riemannian Hamiltonian Monte Carlo with numerical integratorsâ€.
In: Conference on Learning Theory (COLT). Vol. 195. PMLR, 2023, pp. 4504â€“4569.
[KV23] Y. Kook and S. S. Vempala. â€œGaussian Cooling and Dikin walks: The Interior-Point
Method for logconcave samplingâ€. In: arXiv preprint arXiv:2307.12943 (2023).
[Led94] M. Ledoux. â€œA simple analytic proof of an inequality by P. Buserâ€. In: Proceedings of
the American Mathematical Society 121.3 (1994), pp. 951â€“959.
[LST21] Y. T. Lee, R. Shen, and K. Tian. â€œStructured logconcave sampling with a restricted
Gaussian oracleâ€. In: Conference on Learning Theory (COLT). PMLR. 2021, pp. 2993â€“
3050.
[LV18] Y. T. Lee and S. S. Vempala. â€œConvergence rate of Riemannian Hamiltonian Monte
Carloandfasterpolytopevolumecomputationâ€.In:Symposium on Theory of Computing
(STOC). 2018, pp. 1115â€“1121.
[LV17] Y. T. Lee and S. S. Vempala. â€œEldanâ€™s stochastic localization and the KLS hyperplane
conjecture: An improved lower bound for expansionâ€. In: Foundations of Computer
Science (FOCS). IEEE. 2017, pp. 998â€“1007.
[Leh23] J. Lehec. â€œThe Langevin Monte Carlo algorithm in the non-smooth log-concave caseâ€.
In: The Annals of Applied Probability 33.6A (2023), pp. 4858â€“4874.
[LNP12] N. E. Lewis, H. Nagarajan, and B. O. Palsson. â€œConstraining the metabolic genotypeâ€“
phenotype relationship using a phylogeny of in silico methodsâ€. In: Nature Reviews
Microbiology 10.4 (2012), pp. 291â€“305.
[Li+22] R. Li, M. Tao, S. S. Vempala, and A. Wibisono. â€œThe mirror Langevin algorithm
converges with vanishing biasâ€. In: International Conference on Algorithmic Learning
Theory (ALT). PMLR. 2022, pp. 718â€“742.
[Liu20] Y. Liu. â€œThe PoincarÃ© inequality and quadratic transportation-variance inequalitiesâ€.
In: Electronic Journal of Probability 25.1 (2020), pp. 1â€“16.
[Lov99] L. LovÃ¡sz. â€œHit-and-run mixes fastâ€. In: Mathematical Programming 86 (1999), pp. 443â€“
461.
24[LS90] L. LovÃ¡sz and M. Simonovits. â€œThe mixing rate of Markov chains, an isoperimetric
inequality, and computing the volumeâ€. In: Foundations of Computer Science (FOCS).
IEEE. 1990, pp. 346â€“354.
[LS93] L. LovÃ¡sz and M. Simonovits. â€œRandom walks in a convex body and an improved volume
algorithmâ€. In: Random Structures & Algorithms (RS&A) 4.4 (1993), pp. 359â€“412.
[LV03] L. LovÃ¡sz and S. S. Vempala. â€œHit-and-run is fast and funâ€. In: preprint, Microsoft
Research (2003).
[LV06] L. LovÃ¡sz and S. S. Vempala. â€œHit-and-run from a cornerâ€. In: SIAM Journal on
Computing (SICOMP) 35.4 (2006), pp. 985â€“1005.
[MT07] F.McSherryandK.Talwar.â€œMechanismdesignviadifferentialprivacyâ€.In:Foundations
of Computer Science (FOCS). IEEE. 2007, pp. 94â€“103.
[Mil09] E. Milman. â€œOn the role of convexity in isoperimetry, spectral gap and concentrationâ€.
In: Inventiones Mathematicae 177.1 (2009), pp. 1â€“43.
[Mir17] I. Mironov. â€œRÃ©nyi differential privacyâ€. In: Computer Security Foundations Symposium
(CSF). IEEE. 2017, pp. 263â€“275.
[Smi84] R. L. Smith. â€œEfficient Monte Carlo procedures for generating points uniformly dis-
tributed over bounded regionsâ€. In: Operations Research 32.6 (1984), pp. 1296â€“1308.
[SWW23] V.Srinivasan,A.Wibisono,andA.Wilson.â€œFastsamplingfromconstrainedspacesusing
theMetropolis-adjustedmirrorLangevinalgorithmâ€.In:arXivpreprintarXiv:2312.08823
(2023).
[Sta20] Stan Development Team. RStan: the R interface to Stan. R package version 2.21.2. 2020.
url: http://mc-stan.org/.
[Thi+13] I. Thiele, N. Swainston, R. M. Fleming, A. Hoppe, S. Sahoo, M. K. Aurich, H. Har-
aldsdottir, M. L. Mo, O. Rolfsson, M. D. Stobbe, et al. â€œA community-driven global
reconstruction of human metabolismâ€. In: Nature Biotechnology 31.5 (2013), pp. 419â€“
425.
[Vem05] S. S. Vempala. â€œGeometric random walks: a surveyâ€. In: Combinatorial and Computa-
tional Geometry 52.573-612 (2005), p. 2.
[VW19] S. S. Vempala and A. Wibisono. â€œRapid convergence of the unadjusted Langevin
algorithm:Isoperimetrysufficesâ€.In:Advances in Neural Information Processing Systems
(NeurIPS) 32 (2019).
[Vil09] C. Villani. Optimal transport: old and new. Vol. 338. Springer, 2009.
[Yua+23] B. Yuan, J. Fan, J. Liang, A. Wibisono, and Y. Chen. â€œOn a classof Gibbs sampling over
networksâ€. In: Conference on Learning Theory (COLT). PMLR. 2023, pp. 5754â€“5780.
[Zha+20] K.S.Zhang,G.PeyrÃ©,J.Fadili,andM.Pereyra.â€œWassersteincontrolofmirrorLangevin
Monte Carloâ€. In: Conference on Learning Theory (COLT). PMLR. 2020, pp. 3814â€“3841.
25A Related work
Sampling from constrained log-concave distributions is a fundamental task arising in many fields.
Uniform sampling with convex constraints is its simplest manifestation, which was first studied
as a core subroutine for a randomized volume-computation algorithm [DFK91]. Since then, this
fundamental problem has been studied for over three decades [LS90; LS93; KLS97; LV03; LV06;
BEL18; Bro+17]. We review these algorithms, grouping them under three categories â€” geometric
random walks, structured samplers, and diffusion-type samplers. Below, K is convex.
Geometric random walk. We discuss two geometric random walks â€“ Ball walk [LS93; KLS97]
and Hit-and-Run [Smi84; Lov99].
Ball walk is a simple metropolized random walk; it draws y uniformly at random from a ball of
radius Î´ centered at a current point x, and moves to y if y âˆˆ K and stays at x otherwise. In the
literature, Ball walk actually refers to a composite algorithm consisting of [Speedy walk+ rejection
sampling], where Speedy walk records only the accepted steps of Ball walk (see Appendix B for
details). The step size Î´ should be set to O(dâˆ’1/2) to avoid stepping outside of K. [KLS97] showed
that Ball walk needs Oe(Md2D2log 1) membership queries to be Îµ-close to Ï€K in TV, where D is
Îµ
the diameter of K, and the warmness parameter M measures the closeness of the initial distribution
to the target uniform distribution Ï€K.
Hit-and-Run is another zeroth-order algorithm that needs no step size; it picks a uniform random
lineâ„“passinga current point, andmovetoauniform randompointonâ„“âˆ©K. [LV06]showsthat, ifwe
define the second moment as R2 := E [âˆ¥Xâˆ’E[X]âˆ¥2], then Hit-and-Run requires O(d2R2log M)
Xâˆ¼Ï€K Îµ
queries. Notably, this algorithm has a poly-logarithmic dependence on M as opposed to Ball walk.
Both algorithm are affected by skewed shape of K (i.e., large D or R), so these samplers are
combined with pre-processing step called rounding. This procedure finds a linear transformation that
makes the geometry of K less skewed and so more amenable to sampling. In literature, there exists
a randomized algorithm [Jia+21] that rounds K and generates a good warm start (i.e., M = O(1)),
with Ball walk used as a core subroutine. This algorithm takes up Oe(d3) queries in total, and in
such position with the good warm start, Ball walk only needs Oe(d2log 1) queries to sample from Ï€K.
Îµ
Structured samplers. The aforementioned samplers based on geometric random walks require
only access to the membership oracle of the convex body without any additional structural assump-
tions. The alternate paradigm of geometry-aware sampling attempts to exploit the structure of
convex constraints, with the aim of expediting the convergence of the resultant sampling schemes.
One common assumption is to make available a self-concordant barrier function Ï• which has regu-
larity on its high-order derivatives and blows up when approaching the boundary âˆ‚K. The Hessian
of Ï• encodes the local geometry of the constraint, and the samplers often work directly with âˆ‡2Ï•.
The first canonical example of such a zeroth-order sampler is Dikin walk used when K is given
by m linear constraints [KN12]; it draws a uniform sample from an ellipsoid (characterized by âˆ‡2Ï•)
of fixed radius around a current point, and is often combined with a Metropolis adjustment. [KN12]
shows that Dikin walk mixes in O(mdlog M) steps, although each iteration is slightly more expensive
Îµ
than one membership query. This algorithm requires no rounding, but still needs a good warm-start,
which can be achieved by an annealing-type algorithm using Oe(md) iterations of Dikin walk [KV23].
Riemannian Hamiltonian Monte Carloisastructuredsamplerthatexploitsthefirst-orderinforma-
tion of the potential (i.e., âˆ‡log(1/Ï€)) [GC11]; its proposal is given as the solution to the Hamiltonâ€™s
ODE equation, followed by the Metropolis-filter. In the linear-constraint setting above, this sampler
requires O(md2/3log M) many iterations to achieve Îµ-close distance to Ï€K [LV18]. This sampler is
Îµ
further analyzed for practical ODE solvers [Koo+23] and for more sophisticated self-concordant
barriers [GKV23].
26Similarly, Mirror Langevin [Zha+20; Jia21; AC21; Li+22] is a class of algorithms which converts
the constrained problem into an unconstrained one obtained by considering the pushforward of the
constrained space by âˆ‡Ï•. The algorithm can also be metropolized [SWW23]. The best known rates
for this algorithm are Oe(dlog 1) under some strong assumptions on Ï•.
Îµ
Diffusion-type samplers. Samplers based on discretizations of ItÃ´ diffusions, stochastic pro-
cesses which rapidly mix to Ï€ in continuous time, have long been used for sampling without
constraints [Bes+95; DT12; Dal17; Che24]. While the underlying stochastic processes generalize
easily to constrained settings, the discretization analysis relies crucially on the smoothness of the
target distribution. This is clearly impossible to achieve in the constrained setting, and so some
techniques are required to circumvent this difficulty. These algorithms, however, generalize easily to
the more general problem of sampling from distributions of the form Ï€ËœX âˆ eâˆ’f1 , by naturally
K
incorporating first order information from f.
The first approach for adapting diffusion-based samplers [BEL15; BEL18; Leh23] iterates a
two-stepprocedure. First, arandomstepistaken, withx âˆ¼ N(x ,2hI )forsomeappropriately
k+1/2 k d
chosen step h,4 and then project it to K, i.e., x = proj (x ). The complexity is given in
k+1 K k+1/2
terms of queries to a projection oracle, each call to which can be implemented with a polynomial
number of membership oracle queries; a total of OËœ(d2D3) queries are needed to be Îµ-close in W to
Îµ4 2
Ï€X. Another approach, which uses an algorithmically designed â€œsoftâ€ penalty instead of a projection,
was proposed in [GHZ22], and achieves a rate estimate of OËœ(d/Îµ10).
Asecondapproach,suggestedby[Bro+17],considersadifferentproximalscheme,whichperforms
a â€œsoft projectionâ€ onto K, by taking steps like N((1âˆ’hÎ»âˆ’1)x +hproj (x ),2hI ). It is called
k K k d
Moreau-YosidaregularizedLangevin,namedafterananalogousregularizationschemeforconstrained
optimization. This scheme also relies on access to a projection oracle for K, and quantifies their
query complexity accordingly. Their final rate estimate is OËœ(d5) to be Îµ-close in TV distance to Ï€X.
Îµ6
Observing the prior work integrating diffusion-based sampling with convex constraints, the
dependence on the key parameters d,Îµ, while polynomial, are many orders worse than the rates for
zeroth-order samplers such as Ball walk,Hit-and-Run. In contrast, our analysis not only recovers but
in some sense surpasses the known rates for Ball walk,Hit-and-Run, while harmonizing well with the
continuous-time perspective of diffusions.
Proximal schemes for sampling. TheGibbssamplingschemeusedinthispaperwasinspiredby
the restricted Gaussian oracle introduced in [LST21] (in turn inspired by Gaussian Cooling [CV18]),
which alternately iterates between a pure Gaussian step, and a â€œproximalâ€ step (which we elaborate
in our exposition). This scheme was given novel interpretations by [Che+22], which showed that it
interpolates the forward and backward heat flows, in the sense defined by [KP21]. The backward
heat flow itself is intimately related to stochastic localization schemes, invented and popularized
in [Eld13; Che21].
This formulation proved surprisingly powerful, allowing many existing rates in unconstrained
sampling to be recovered from a relatively simple analysis. This was further extended by [FYC23] to
achieve the current state-of-the-art rate in unconstrained sampling. Finally, [Gop+23] suggest that
this could be applied to tackle some constrained problems. However, the assumptions in this final
mentioned work are not compatible with the uniform sampling problem on general convex bodies.
4A gradient step can be added in the more general case, for sampling from Ï€ËœX
27B Ball walk and Speedy walk
We restate the previously known guarantees for uniform sampling by Ball walk and Speedy walk.
Below, let B (x) denote the d-dimensional ball of radius r centered at x.
r
Algorithm 2 Ball walk
Input: initial distribution Ï€ , convex body K âŠ‚ Rd, iterations T, step size Î´ > 0.
0
1: Sample x 0 âˆ¼ Ï€ 0.
2: for i = 1,...,T do
3: Sample y âˆ¼ Unif(B Î´(x iâˆ’1)).
4: If y âˆˆ K, then x i â† y. Else, x i â† x iâˆ’1.
5: end for
Ball walk is particularly simple; draw a uniform random point from B around the current point,
Î´
and go there if the drawn point is inside of K and stay at the current point otherwise. Its stationary
distribution can be easily seen to be Ï€ âˆ 1 , the uniform distribution over K.
K
In the literature, there are two approaches to analyzing the convergence rate of this sampler: (i)
a direct analysis via the s-conductance of Ball walk and (ii) an indirect approach which first passes
through Speedy walk.
Direct analysis. The following TV-guarantee is obtained by lower bounding the s-conductance
of Ball walk, which requires a one-step coupling argument and the Cheeger inequality for Ï€. We
refer interested readers to [Vem05, Section 5].
Theorem 30 (Convergence of Ball walk). For any Îµ âˆˆ (0,1) and convex body K âŠ‚ Rd presented by a
well-defined membership oracle, let Ï€ be the distribution after t steps of Ball walk with an M-warm
t
initial distribution Ï€ . Then, Ball walk with step size Î´ = Î˜( Îµâˆš ) achieves âˆ¥Ï€ âˆ’Ï€âˆ¥ â‰¤ Îµ for
0 t TV
M d
t â‰³ d2D2M2 log M. If Ï€ is isotropic, then Ball walk only needs O(d2logdM2 log M) iterations.
Îµ2 Îµ Îµ2 Îµ
The mixing time of Ball walk under this approach has a polynomial dependence on 1/Îµ, rather
than a polylogarithmic dependence.
Indirect analysis through Speedy walk. [KLS97]introducedSpeedy walk, whichcouldbeviewed
as a version of Ball walk and converges to a speedy distribution (see Proposition 1), which is slightly
biased from Ï€. Then, Speedy walk is used together with another algorithmic component (rejection
sampling) [KLS97, Algorithm 4.15] that converts the speedy distribution to the uniform distribution.
In the literature, Ball walk often refers to â€˜Speedy walk combined with the conversion stepâ€™, rather
than a direct implementation of Algorithm 2. Strictly speaking, a mixing guarantee of this combined
algorithm should not be referred to as a provable guarantee of Ball walk.
Algorithm 3 Speedy walk
Input: initial distribution Ï€ , convex body K âŠ‚ Rd, iterations T, step size Î´ > 0.
0
1: Sample x 0 âˆ¼ Ï€ 0.
2: for i = 1,...,T do
3: Sample x i âˆ¼ Unif(Kâˆ©B Î´(x iâˆ’1)).
4: end for
As opposed to Ball walk, Speedy walk always takes some step at each iteration. However, the
problem of sampling from x âˆ¼ Unif(Kâˆ©B (x )) in Line 3 is not straightforward. This step
i Î´ iâˆ’1
admits the following implementation based on rejection sampling, via a procedure denoted by (âˆ—):
28â€¢ Propose y âˆ¼ Unif(B (x )).
Î´ iâˆ’1
â€¢ Set x â† y if y âˆˆ K. Otherwise, repeat the proposal.
i+1
Each actual step (indexed by i) in Speedy walk is called a proper step, and rejected steps during
(âˆ—) are called improper steps. For example, if x ,x ,x ,x ,x ,x ,x ,... are the positions produced
1 1 2 3 3 3 4
by Ball walk, then only proper steps x ,x ,x ,x ,... are recorded by Speedy walk.
1 2 3 4
To describe the theoretical guarantees of Speedy walk, we define the local conductance â„“(x) at
x âˆˆ K, which measures the success probability of the rejection sampling scheme in (âˆ—):
vol(Kâˆ©B (x))
â„“(x) := Î´ ,
vol(B (x))
Î´
and define the average conductance:
1 Z
Î» := E [â„“] = â„“(x)dx.
Ï€ vol(K)
K
Proposition 1 ([KLS97]). The stationary distribution Î½ of Speedy walk has density
â„“(x)1 (x)
Î½(x) = K .
R â„“(x)dx
K
ThespeedydistributionÎ½ isindeeddifferentfromtheuniformdistributionÏ€,andthisdiscrepancy
is quantified in terms of the average conductance.
Proposition 2 ([KLS97, Page 22]). âˆ¥Î½ âˆ’Ï€âˆ¥ â‰¤ 1âˆ’Î».
TV Î»
One can relate the step size Î´ to the average conductance.
âˆš
Proposition 3 (Bound on average conductance, [KLS97, Corollary 4.5]). Î» â‰¥ 1âˆ’ Î´ d.
2
The best known result for Speedy walkâ€™s mixing is due to [KLM06] devising the blocking conduc-
tance and using the log-Cheeger inequality. When Î½ is isotropic (i.e., it has covariance proportional
to the identity matrix), [LV17] improves the mixing bound via the log-Cheeger constant.
Theorem 31 (Mixing of Speedy walk). For any Îµ âˆˆ (0,1) and convex body K âŠ‚ Rd presented by a
well-defined membership oracle, let Î½ be the distribution after t proper steps of Speedy walk started
t
at any feasible point x âˆˆ K. Then, Speedy walk with step size Î´ = Î˜(dâˆ’1/2) achieves âˆ¥Î½ âˆ’Î½âˆ¥ â‰¤ Îµ
âˆš0 t TV
for t â‰³ (D2+log(D d))d2log 1. From an M-warm start, the expected number of improper steps
Îµ
during t iterations is Oe(tM). When Î½ is isotropic, Speedy walk needs O(d2Dlog 1 loglogD) proper
Îµ
steps to achieve Îµ-TV distance to Î½.
Then, [KLS97] uses the following post-processing step to obtain an approximately uniform
distribution on K, with a provable guarantee.
A: Call Speedy walk to obtain a sample X âˆ¼ Î½ until 2d X âˆˆ K. If so, return XÂ¯ = 2d X.
t 2dâˆ’1 2dâˆ’1
Proposition 4 ([KLS97, Theorem 4.16]). Under the same setting above, assume âˆ¥Î½ âˆ’Î½âˆ¥ â‰¤ Îµ for
t TV
step size Î´ â‰¤ (8dlog d)âˆ’1/2 and fixed t âˆˆ N. For Î½Â¯ = law(XÂ¯) given by A, it holds that âˆ¥Î½Â¯âˆ’Ï€âˆ¥ â‰¤ Îµ,
Îµ TV
and the expected number of calls on the conversion algorithm is at most 2.
Combining the previous two results, we conclude that the total expected number of membership
queries to obtain a sample Îµ-close to Ï€ in TV is Oe(Md2D2log 1), which now has a poly-logarithmic
Îµ
dependence on 1/Îµ.
29Remark2(BackwardheatflowanalysisofSpeedy walk). ConsideraGaussianversionofSpeedy walk,
whose one-step corresponds to x âˆ¼ N(x ,hI )| , and this transition kernel exactly matches
i+1 i d K
integrating (BH) for time h. Thus, Î½QÏ€X,h = Î½ due to the stationarity of Î½ under Speedy walk,
h
where QÏ€X,h is the transition kernel defined by the backward heat flow for time h that reverses
h
Ï€X âˆ—N(0,hI ) to Ï€X. Hence, if we can control the LSI/PI constants of Î½ along the backward
d
heat-flowâ€™s trajectory, then we could directly analyze Speedy walk by emulating computations in
Lemma 21.
C Functional inequalities
We provide full details on functional inequalities omitted in Section 3.1. We use Âµ and Âµ to denote
LC
a probability measure and log-concave probability measure over Rd, respectively.
Cheeger and PI constants. The Cheeger isoperimetric constant C (Âµ) measures how large
Ch
surface area a measurable subset with larger volume has, defined by
Âµ+(S)
C (Âµ) := inf ,
Ch
SâŠ‚Rd
min(Âµ(S),Âµ(Sc))
where the infimum is taken over all measurable subsets S, and Âµ+(S) is the Minkowski content of S
under Âµ defined as, for SÎµ := {x âˆˆ X : d(x,S) < Îµ},
Âµ(SÎµ)âˆ’Âµ(S)
Âµ+(S) := liminf .
Îµâ†’0 Îµ
[Che70] established C (Âµ) â‰² Câˆ’2(Âµ)5, and then [KLS95] showed that for covariance matrix
PI Ch
Î£ := E [(Â·âˆ’E X)(Â·âˆ’E X)T],
Âµ Âµ Âµ Âµ
1 1
C (Âµ ) â‰³ = . (C.1)
Ch LC (E [âˆ¥X âˆ’E Xâˆ¥2])1/2 (tr(Î£ ))1/2
Âµ Âµ Âµ
LC LC LC
This immediately leads to C (Ï€) â‰² (E [âˆ¥X âˆ’E Xâˆ¥2])1/2 â‰¤ D2 for the uniform distribution Ï€ over
PI Ï€ Ï€
a convex body K with diameter D > 0.
Kannan et al. proposed the KLS conjecture in the same paper, which says that for the spectral
norm âˆ¥Â·âˆ¥ ,
2
1
C (Âµ ) â‰³ .
Ch LS âˆ¥Î£ âˆ¥1/2
Âµ LS 2
While the original result in [KLS95] ensures C â‰³ dâˆ’1/2 for an isotropic log-concave distribution
Ch
(due to Î£ = I ), this conjecture indeed claims C â‰³ 1 for such case. Following a line of work [LV17;
d Ch
Che21; KL22; Kla23], the current bound is
(logd)âˆ’1/2
C (Âµ ) â‰³ ,
Ch LS âˆ¥Î£ âˆ¥1/2
Âµ LS 2
which implies that C (Ï€) â‰² logd when Ï€ is isotropic for convex K.
PI
5The opposite direction C (Âµ ) â‰³ Câˆ’2(Âµ ) also holds for log-concave distributions due to [Mil09], while
PI LC Ch LC
C (Âµ)â‰³Câˆ’2(Âµ)/d for general distributions due to [Led94].
PI Ch
30Log-Cheeger and LSI constants. Just as the Cheeger and PI constants are related above, there
are known connections between LSI and log-Cheeger constants. The log-Cheeger constant C (Âµ)
logCh
of a distribution Âµ âˆˆ P(Rd) is defined as
Âµ+(S)
C (Âµ) := inf .
logCh q
SâŠ‚Rd:Âµ(S)â‰¤1 Âµ(S) log 1
2 Âµ(S)
[Led94] established that C (Âµ) â‰² Câˆ’2 (Âµ)6, and [KLM06] showed that any log-concave
LSI logCh
distributions with support of diameter D > 0 satisfy C (Âµ ) â‰³ Dâˆ’1. Later in 2016, [LV17]
logCh LS
improved this to C (Âµ ) â‰³ Dâˆ’1/2 under isotropy. Therefore, for convex K, it follows that
logCh LS
C (Ï€) â‰² D2 and that C (Ï€) â‰² D if Ï€ is isotropic.
LSI LSI
D The Wasserstein geometry
We present additional technical background on the Wasserstein geometry and Markov semigroup
theory. Interested readers can refer to [Vil09; AGS05; Che24] for standard references on Wasserstein
spaces and applications to sampling.
Wasserstein gradient. Let P (Rd) be the space of probability measures admitting densities on
2,ac
Rd with finite second moment. Although there are many ways to metrize P (Rd), the geometry
2,ac
induced by the Wasserstein-2 distance W is a particularly useful structure for analysis.
2
Under the W -geometry, one can define a â€œgradientâ€ of a functional defined over P (Rd).
2 2,ac
Specifically,forafunctionalF : P (Rd) â†’ Râˆª{âˆ},theWasserstein gradient ofF atÂµ âˆˆ P (Rd)
2,ac 2,ac
is defined as âˆ‡ F(Âµ) = âˆ‡(Î´F)(Âµ) âˆˆ L2(Âµ), where âˆ‡ is the standard gradient and Î´F is the first
W2
variation of F7. Equipped with this W -gradient, one can define the Wasserstein gradient flow of F
2
that describes the evolution of a measure {Âµ } , from some initial measure Âµ , as follows:
t tâ‰¥0 0
âˆ‚ Âµ = div(cid:0) Âµ âˆ‡ F(Âµ )(cid:1) .
t t t W2 t
More generally, we can identify the Wasserstein â€œvelocityâ€ for some measure Âµ as v if the time
t t
derivative of Âµ can be written in the form
t
âˆ‚ Âµ = âˆ’div(Âµ v ).
t t t t
Under this identification, the time derivative of a functional F on P (Rd) with smooth Wasserstein
2,ac
gradient under these dynamics can be written as
âˆ‚ F(Âµ ) = E âŸ¨âˆ‡ F(Âµ ),v âŸ©,
t t Âµt W2 t t
when v âˆˆ {âˆ‡Ïˆ : Ïˆ âˆˆ
Câˆ(Rd)}L2(Âµt)
, where
{Â·}L2(Âµt)
denotes the closure of a set with respect to
t c
L2(Âµ ). This is the appropriate notion of tangent space in this geometry.
t
For instance, when we take the functional to be the entropy of the measure, H(Âµ) := 1 R ÂµlogÂµ,
2
one can verify âˆ‡ H(Âµ) = 1âˆ‡logÂµ. The heat flow equation can be written as âˆ‚ Âµ = 1âˆ†Âµ =
W2 2 t t 2 t
1 div(âˆ‡Âµ ) = 1 div(Âµ âˆ‡logÂµ ), which indicates that the velocity of measures Âµ under the heat flow
2 t 2 t t t
is v = âˆ’1âˆ‡logÂµ . Hence, we can notice that âˆ‡ H(Âµ ) = âˆ’v , and thus recover the heat flow as
t 2 t W2 t t
the Wasserstein gradient flow of the entropy of the measure.
6The opposite direction holds under dimension-scaling due to [Led94]: C (Âµ)â‰³Câˆ’2 (Âµ)/d.
LSI logCh
7The first variation can be defined, for any measures Î½ ,Î½ âˆˆ P (Rd), as lim F((1âˆ’t)Î½0+tÎ½1)âˆ’F(Î½0) =
0 1 2,ac tâ†“0 t
âŸ¨Î´F(Î½ ),Î½ âˆ’Î½ âŸ©. This definition is unique up to an additive constant, which is irrelevant as we are only con-
0 1 0
cerned with its gradient.
31Fokker-Planckequationandtime-reversalofSDE. Considerastochasticdifferentialequation
(X ) given by
t
dX = âˆ’a (X )dt+ dB with X âˆ¼ Âµ . (D.1)
t t t t 0 0
It is well known that measures Âµ described by
t
1
âˆ‚ Âµ = div(Âµ a )+ âˆ†Âµ , (D.2)
t t t t 2 t
correspond to law(X ). In this context, (D.2) is referred to as the Fokker-Planck equation corre-
t
sponding to (D.1).
From this equation, one can deduce the Fokker-Planck equation of the time reversal Âµâ† := Âµ :
t Tâˆ’t
1 1
âˆ‚ Âµâ† = âˆ’div(Âµâ†a )âˆ’ âˆ†Âµâ† = âˆ’div(cid:0) Âµâ†(a +âˆ‡logÂµ )(cid:1)+ âˆ†Âµâ†
t t t Tâˆ’t 2 t t Tâˆ’t Tâˆ’t 2 t
In particular, this describes the evolution of law(X ) of the stochastic differential equation:
t
dX = (cid:0) a (X )+âˆ‡logÂµ (X )(cid:1)dt+ dB with X âˆ¼ Âµâ† = Âµ . (D.3)
t Tâˆ’t t Tâˆ’t t t 0 0 T
While the law of this process will give Âµâ† = Âµ at time T, it is also true that it will give Âµ (Â·|z) if
T 0 0|T
one starts (D.3) at X = z. This is a subtle fact, whose justification requires the introduction of a
0
tool called Doobâ€™s h-transform. The presentation of this subject is beyond the scope of this paper,
and we refer interested readers to [KP21] as a reference to its application in this context.
32