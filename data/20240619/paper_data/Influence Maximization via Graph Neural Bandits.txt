Influence Maximization via Graph Neural Bandits
YutingFeng VincentY.F.Tan BogdanCautis
DepartmentofElectricalandComputer DepartmentofMathematics, UniversityofParis-Saclay,
Engineering(ECE) DepartmentofECE, CNRSLISN
NationalUniversityofSingapore NationalUniversityofSingapore bogdan.cautis@universite-paris-saclay.fr
yt.f@nus.edu.sg vtan@nus.edu.sg
ABSTRACT researchdirectlymirrorstheincreasinglyprevalentandsuccessful
WeconsideraubiquitousscenariointhestudyofInfluenceMax- marketingstrategyoftargetingkeyindividuals(influencers).
imization (IM), in which there is limited knowledge about the TheobjectiveofIMistypicallyformulatedbymaximizingthe
topology of the diffusion network. We set the IM problem in a expectedspreadunderastochasticdiffusionmodel,whichcharac-
multi-rounddiffusioncampaign,aimingtomaximizethenumberof terizestheinformationdisseminationprocess.Theworkof[18]laid
distinctusersthatareinfluenced.Leveragingthecapabilityofban- thefoundationsfortheIMliterature,byintroducingtwoprominent
ditalgorithmstoeffectivelybalancetheobjectivesofexploration models:LinearThreshold(LT)andIndependentCascade(IC).These
andexploitation,aswellastheexpressivityofneuralnetworks, models,widelyadoptedinsubsequentresearch,representdiffusion
ourstudyexplorestheapplicationofneuralbanditalgorithmsto networksasprobabilisticgraphs,wheretheedgesareweightedby
theIMproblem.WeproposetheframeworkIM-GNB(Influence probabilitiesofinformationtransmission.
MaximizationwithGraphNeuralBandits),whereweprovideanes- SelectingtheseednodesmaximizingtheexpectedspreadisNP-
timateoftheusersâ€™probabilitiesofbeinginfluencedbyinfluencers hardundercommondiffusionmodels[18].Despitethedevelopment
(alsoknownasdiffusionseeds).Thisinitialestimateformsthebasis ofapproximatealgorithms,exploitingthemonotonicityandsub-
forconstructingbothanexploitationgraphandanexploration modularityofthespread,scalingIMalgorithmstolargenetworks
one.Subsequently,IM-GNBhandlestheexploration-exploitation remainschallenging.Acquiringmeaningfulinfluenceprobabilities
tradeoff,byselectingseednodesinreal-timeusingGraphCon- isequallychallenging,aslearningthemfrompastinformationcas-
volutional Networks (GCN), in which the pre-estimated graphs cades(e.g.,asin[11,13])canbedata-intensiveandthusimpractical.
areemployedtorefinetheinfluencersâ€™estimatedrewardsineach Moreover,theapplicabilityofsuchmodelsislimitedinscenarios
contextualsetting.Throughextensiveexperimentsontwolarge wherehistoricalcascadesarenotavailable.
real-worlddatasets,wedemonstratetheeffectivenessofIM-GNB Inthefaceofthesechallenges,sinceeventhemostefficientIM
comparedwithotherbaselinemethods,significantlyimprovingthe algorithmssuchas[16,30]relyonassumptionsandparameters
spreadoutcomeofsuchdiffusioncampaigns,whentheunderlying thatoftenfailtocapturethecomplexrealityofhowinformation
networkisunknown. spreadsonline,achangeinresearchdirectionhasbeenfollowed
recently.Itconsistsofapproachesthatneitherrelyonpre-defined
CCSCONCEPTS
diffusionmodelsnorrequireupfrontknowledgeofthediffusion
â€¢Informationsystemsâ†’Socialrecommendation;Socialad-
network.Instead,theseonlinemethods,suchas[17,20,33],learnto
vertising;â€¢Human-centeredcomputingâ†’Socialmedia;So-
spreadonthefly.Moreprecisely,theyinvolveasequentiallearning
cialrecommendation;â€¢Networksâ†’Socialmedianetworks.
agentthatactivelygathersinformationthroughamulti-roundinflu-
encecampaign.Ineachround,theagentselectsso-calledseednodes,
KEYWORDS
observestheresultinginformationspread,andusesthisfeedback
Informationdiffusion,influence,influencermarketing,contextual tomakebetterchoicesinsubsequentrounds,withthecampaignâ€™s
bandits,graphneuralnetworks. totalrewardbeingtheobjectivethatistobeoptimized.Sucha
learningframeworkleadsnaturallytoapolicythatbalancesexplor-
1 INTRODUCTION ingunknownaspects(i.e.,thediffusiondynamics)withexploiting
knownandsuccessfulchoices(i.e.,thehigh-performingspreadseed
Motivatedbytheriseofâ€œinfluencermarketingâ€insocialmedia
nodes),usingmulti-armedbandits[21].
advertising,aclassofalgorithmicproblemstermedInfluenceMax-
WeconsiderinthispapersuchananonlineIMscenariowith
imization (IM) has emerged, starting with the pioneering work
limitednetworkinformation.Specifically,thediffusiongraphis
of[10,18].Thesealgorithmsaimtoidentifythemostinfluential
largelyunknown,exceptforasetofpredefinedinfluencers,repre-
nodeswithinadiffusionnetworkforinitiatingthespreadofspe-
sentingthepotentialseedsforinformationdisseminationateach
cificinformation,therebymaximizingitsreach.Inmanyways,this
roundofamulti-rounddiffusioncampaign.Additionally,weincor-
poratecontextualfeaturesofbothinfluencersandtheinformation
Permissiontomakedigitalorhardcopiesofpartorallofthisworkforpersonalor
beingdiffused.Regardingthelatter,therationaleisthatwithina
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation campaignaimingtomaximizethereachofaspecificmessage,its
onthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored. framingandpresentationcansignificantlyimpactitsspread.For
Forallotheruses,contacttheowner/author(s).
instance,apoliticalcampaignmayusevariousformatslikenews
KDDâ€™24,August25â€“29,2024,Barcelona,Spain
Â©2024Copyrightheldbytheowner/author(s). articles,opinionpieces,datavisualizations,ormultimediacontent,
ACMISBN979-8-4007-0490-1/24/08. eachleadingtodistinctdiffusionpatterns.
https://doi.org/10.1145/3637528.3671983
4202
nuJ
81
]GL.sc[
1v53821.6042:viXraKDDâ€™24,August25â€“29,2024,Barcelona,Spain Feng,Tan,andCautis
Weleveragesuchcontextualinformationthroughtheformal extensiveexperiments,weshowthatouralgorithmoutperforms
frameworkofContextualMulti-ArmedBandits(CMABs)[21].Fur- baseline methods, highlighting the utility of GNBs as a prin-
thermore,recognizingthatsignificantcorrelationsbetweenthefea- cipledapproachtooptimizeinfluencecampaignsinuncertain
turesofthebasic(to-be-influenced)usersmayexist,albeitunknown environments.
totheagent,andthatbyimplicationtheiractivationprobabilities
maybecorrelated,weenhancethelearningframeworkwithmech- 2 RELATEDWORK
anismsbywhicheachactivationcanprovideusefulinformation InfluenceMaximization(IM)addressesthechallengeofidentify-
aboutneighbouringusersinthenetworkaswell,allowingtorefine ingasetofseeds(influencers)withinasocialnetworktomaximize
theagentâ€™spredictions.WeachievethisbyadaptingtoourIMprob- informationspread.Researchersfirstexploredthisproblemin[10].
lemsettingtheGraphNeuralBandits(GNB)frameworkof[26](a Later,[18]providedaclearformulationoftheproblem,including
banditalgorithmforrecommendersystems).Correlationgraphs howinfluencespreadsthroughstochasticmodelslikeIndependent
areconstructedbasedonthesimilarityofuserstobeinfluenced Cascade(IC)andLinearThreshold(LT).Theyalsodescribedthe
bythesameinfluencer,andGNBsarethenemployedtohandlethe importantpropertiesofthespreadobjective,itsapproximationguar-
challengesassociatedwithgraph-basedbanditalgorithm.Indoing anteesandhardnessresults.Sincethen,suchstochasticmodelshave
so,ourworkisthefirsttoleveragetheimplicitrelationshipsthat becomewidelyadoptedintheliterature,andmostworksfocused
mayexistbetweenbasicusersintheunknowndiffusionmedium. onfindingapproximatesolutionsthatcanbecomputedefficiently.
In essence, we dynamically model these relationships based on Akeybreakthroughwastheconceptofreverseinfluencesampling,
theobservedcampaignfeedback,andweusethemasinputfora introducedin[6]andmadepracticalin[23,30,31].Diffusionmodel-
graphneuralnetwork(GNN)-basedlearningalgorithmguidingthe basedIMapproachesrelyondiffusiongraphswheretheedgesare
seedselectionprocessateachround,optimizingchoicesunderthe labeledbyweights(spreadprobabilities).Inempiricalevaluations,
exploit-exploreparadigm. theseweightsmaybedata-based[14,15](computedfromdiffusion
OverviewofourIMscenario.AsusualinIMscenarios,werun cascades),degreebased,orsimplyassumedrandom.Somerecent
campaignsunderbudgetconstraints(limitedseedingsandrounds), studies[12,24]employrepresentationlearningtoinferinfluence
withthegoaltomaximizethenumberofdistinctusersactivated, probabilitiesfromground-truthdiffusioncascades,aresourcethat
startingfromknowninfluencers.Thelearningagentchoosesseeds maynotbereadilyavailableinmanyapplicationscenarios.(See
sequentially,i.e.,ateachround,withpotentialre-seeding,andfeed- therecentsurvey[22]forareviewoftheIMliterature.)
backconsistssolelyoftheactivatednodesaftereachround,without BanditsforInfluenceMaximizationByvirtueoftheirversa-
additionaldetailsonthetriggeringcauses.Thefeedbackisused tilityandsequentialnature,banditalgorithmsareapttobeused
torefineestimatesofinfluencerpotential,guidingfutureseeding in IM problems, especially in uncertain diffusion environments
choices.Aligningwiththeoverallobjective,eachroundâ€™sreward withwhichalearningagentmayinteractrepeatedly[17,29,34,37].
isthenumberofnewlyactivatedusers,andthecampaignaimsto A multi-round, sequential setting allows to spread information
maximizethecumulativerewardacrossrounds.Inthisscenario, andgatherfeedback,strikingabalancebetweeninfluencing/ac-
wemimicreal-worldinfluencermarketing,whereaccessislimited tivatingnodesineachroundandlearninginfluenceparameters
toafewinfluencers,feedbackisrestrictedtouseractions(likepur- foruncertainorunexplorednetworkfacets.Thisstrategyclosely
chasesorsubscriptions),andthegoalistoreachasmanyunique mirrorsreal-worldinfluencermarketingscenarios,inwhichcam-
usersaspossible. paignsoftenunfoldovertime.[34]isoneoftheearliestworksthat
Ourcontributions.Wedetailourcontributionsinthefollowing: mapanIMproblemformulationtoacombinatorialmulti-armed
â€¢ ByintroducingtheIM-GNBframework,weconnectGNBsand bandit (CMAB) paradigm, where diffusions are assumed to fol-
theIMproblem.Thisintegrationisnon-trivialduetotheinherent lowtheICmodel.IMLinUCB[35]learnstheoptimalinfluencers
challengesoflearningfromgraph-structureddataandmaking dynamically,whilerepeatedlyinteractingwithanetworkunder
sequentialdecisionsunderuncertainenvironmentsinthecontext the IC assumption as well. Vaswani et al. [33] introduces a dif-
ofdiffusioncampaigns. fusionmodel-agnosticframework,basedonapairwise-influence
â€¢ Wetacklethechallengeofbalancingexplorationandexploitation semi-banditfeedbackmodelandtheLinUCB-basedalgorithm,ad-
indynamicinfluencepropagationbyincorporatingcontextual dressingscenariosinvolvingnewmarketersthatexploitexisting
banditsintotheIM-GNBframework.Thisenablesustoeffec- networks.Sincetheaforementionedapproachesleverageagiven
tivelyexplorethepotentialrewardswhileexploitingavailable diffusiongraphtopology,theinherentdifficultyofobtainingsuch
information,resultinginenhancedinfluencespreadinreal-world datalimitstheirpracticalinterest.
scenarios. Operatinginhighlyuncertaindiffusionscenariosthat(i)make
â€¢ Weconstructuser-usercorrelationgraphsforexploitationand noassumptiononthediffusionmodeland(ii)lackknowledgeof
exploration purposes, capturing intricate interactions among thediffusiontopologyandhistoricalactivations(cascades),[20]
usersandinfluencersineachroundofthediffusioncampaign. proposesFAT-GT-UCB,whereaGoodâ€“Turingestimatorisused
Thisgraph-basedapproachisscalabletovariousnetworkset- tocapturetheutility(calledremainingpotential)ofaninfluencer,
tings,evenwithoutpriorknowledgeofthenetworkâ€™stopology throughoutthemultipleroundsofadiffusioncampaign.Theyalso
structure. considerafatigue effectforinfluencers,sincethesemaybeare
â€¢ Wedevelopanovelalgorithmthatoptimallyselectsseednodes repeatedly chosen in the sequential rounds. GLM-GT-UCB [17]
inreal-time,withcontextualbanditsintegratedwithGNNsto considersthesamesettingas[20],whileexploitingcontextualin-
refinetherewardestimatesineachcontextualsetting.Through formation(e.g.,featurespertainingtoinfluencersortheinformationInfluenceMaximizationviaGraphNeuralBandits KDDâ€™24,August25â€“29,2024,Barcelona,Spain
beingconveyed).Ourworksharesasimilarsetting,wherethenet- (whichhascardinality|ğ¼ ğ‘¡|=ğ¿)thesetofactivatedseeds,ğ‘†(ğ¼ ğ‘¡,ğ¶ ğ‘¡)
worktopologyisunknownandnoassumptionsaremadeaboutthe istheroundâ€™sspread(allactivatedusers)startingfromthechosen
diffusionmodel.Inamulti-rounddiffusioncampaign,weselectat seedsetğ¼ ğ‘¡.Ourobjectiveistomaximizethecumulativeanddistinct
eachrounddiffusionseeds,withoutfactoringininfluencerfatigue. spreadoftheğ‘‡ rounds,i.e.,find
BanditswithdeeplearningEarlyworks[1,9,28]inthecon- (cid:20)(cid:12)
(cid:216)
(cid:12)(cid:21)
textualbanditliteraturefocusedonlinearmodels,assumingthe argmax E (cid:12)
(cid:12)
ğ‘†(ğ¼ ğ‘¡,ğ¶ ğ‘¡)(cid:12)
(cid:12)
. (1)
expectedrewardateachroundislinearinthefeaturevector.This ğ¼ğ‘¡âŠ†ğ¾,|ğ¼ğ‘¡|=ğ¿,âˆ€1â‰¤ğ‘¡â‰¤ğ‘‡ 1â‰¤ğ‘¡â‰¤ğ‘‡
assumption,however,oftenfailstoholdinpractice,promptingex- AdaptationtothebanditsettingToadapttheIMproblemtoa
plorationintononlinearornonparametriccontextualbandits[7,32]. contextualbanditsetting,thesetofinfluencersğ¾canbeconsidered
However,thesemorecomplexmodelsimposerestrictiveassump- thesetofarmstobepulledinğ‘‡ rounds.Ateachroundğ‘¡,withthe
tionsontherewardfunction,suchasLipschitzcontinuity[7],orare- providedmessageğ¶ ğ‘¡ asthecontext,thesetofarmsğ¼ ğ‘¡ = {ğ‘˜ ğ‘–} ğ‘–ğ¿
=1
wardfunctionfromareproducingkernelHilbertspace(RKHS)[32]. is chosen. For each chosen armğ‘˜ ğ‘–,ğ´ ğ‘˜ğ‘– is the set of basic users
Toovercometheselimitations,severalrecentstudies[27,38,41] activated or influenced by seed (arm)ğ‘˜ ğ‘–. For each basic userğ‘¢,
leveragetheexpressivityofdeepneuralnetworks(DNNs)toin- letğ‘ ğ‘¢ğ‘¡ denotethetotalnumberoftimesithasbeeninfluencedor
corporatenonlinearmodels,whichrequirelessdomainknowledge. activateduntilroundğ‘¡.Withthesetofactivatedusers(influence
Theworksof[27,38]employDNNsforeffectivecontexttransfor- spread)asthenodesemi-banditfeedback,therewardisthenumber
mationwithalinearexplorationpolicy,showingnotableempirical ofnewactivations[17]as
s inu tc rc oe ds us cd ee ss Npi et ue rt ah lUe Cab Bs ,e an pc re oo vf abre lygr ee ffit cg iu ea nr ta nn et ue re as l. cT oh ne tew xo turk alo bf a[ n4 d1 i] t ğ‘… ğ‘¡ = âˆ‘ï¸ 1{ğ‘ ğ‘¢ğ‘¡ >0}âˆ’ğ‘… ğ‘¡âˆ’1; ğ‘… 0=0, (2)
algorithmusingDNN-basedrandomfeaturemappingstoconstruct
ğ‘¢âˆˆ(cid:208) ğ‘˜ğ‘–âˆˆğ¼ğ‘¡ğ´ğ‘˜ğ‘–
theUCB,withanear-optimalregretguarantee.Theconstructof Notethatdistinctactivationsareusedforthecumulativereward,
theUCBisbasedonthepastgradientoftheexploitationfunction. i.e.,agivenuserwillbecountedonlyonceinthetotalreward,even
Theworkof[40]assignsanormaldistributionasthedistribution ifithasbeeninfluencedseveraltimes.
oftherewardofeacharm,similarlytothedeviationcomputed ModelingwithgraphbanditsWearemainlymotivatedbyappli-
onthegradientoftheestimationfunction.Similartosomeother cationscenariosinsocialmedia(e.g.,informationcampaignsfor
studies, EE-Net [2] has an exploitation network to estimate re- elections,onlineadvertising,publicawarenesscampaigns,crisis
wardsforeacharm.Itadditionallybuildsanexplorationnetwork informationdiffusion,etc.),whereusersmayexhibitsimilarprefer-
topredictthepotentialgainforeacharm,relativetothecurrentes- encesandinfluencesusceptibilityforcertaindiffusiontopics(e.g.,
timate,wheretheinputoftheexplorationnetworkaretheprevious sharingthesamepoliticalviews)initiatedbycertaininfluencers
gradientsoftheexploitationfunction.TheworkofQietal.[26] (arms),whiletheymayreactdifferentlyandbemoresusceptibleto
employscontextualneuralbanditsinrecommendersystems,to otherinfluencersforothertopics(e.g.,entertainmentorsports).
buildagraphneuralbanditframeworkwhereeacharmisinduced Thus, instead of representing the social graph uniformly, in
withanexploitationgraphandanexplorationone,withtheweights the bandit setting, we allow each armğ‘˜ ğ‘– at each roundğ‘¡ to in-
ofedgesrepresentingusersâ€™correlationsregardingtheexploitation duceadistinctgraphğº ğ‘–,ğ‘¡(U,ğ¸,ğ‘Š ğ‘–,ğ‘¡)torepresentuserconnectivity.
andexplorationperformed.Theeffectivenessof[26]intherecom- Withğ’Œğ‘– theğ‘‘ 1-dimensionalfeaturevectorofarmğ‘˜ ğ‘– andğ‘ªğ‘¡ theğ‘‘ 2-
mendationsettingservesasourinitialmotivationforleveragingits dimensionalcontextvector,theexpectedreward1ateachround
neuralbanditsframeworkinourIMproblem.Giventhesimilarities ğ‘¡ âˆˆ [ğ‘‡]broughtbyarmğ‘˜ ğ‘– isdefinedas
inpredictinguserpreferences(user-iteminrecommendersystems
ğ‘Ÿ ğ‘–,ğ‘¡ =ğ‘“(ğ’Œğ‘–,ğ‘ªğ‘¡,ğº ğ‘–,ğ‘¡). (3)
oruser-influencersusceptibilityinIM),weexploitagraphneural
contextualbanditalgorithmtomaximizetheinfluencespreadin Inğº ğ‘–,ğ‘¡,eachuserğ‘¢ âˆˆ U = {1,2,...,ğ‘š} correspondstoanode,
multi-rounddiffusioncampaigns. ğ¸ is the set of edges connecting users, andğ‘Š ğ‘–,ğ‘¡ = {ğ‘¤ ğ‘–,ğ‘¡(ğ‘¢,ğ‘¢â€²) :
ğ‘¢,ğ‘¢â€² âˆˆU}isthesetofweightscorrespondingtoeachedgeğ‘’ âˆˆğ¸.
3 PROBLEMFORMULATION
Modelingrealapplications,weassumethattheweightsoftheedges
We formulate the Influence Maximization (IM) problem with a connectingnodesinğº ğ‘–,ğ‘¡ representusersâ€™similarityw.r.t.thesame
discrete-timediffusionmodel[18],adoptingacombinatorialmulti- influencer(armğ‘˜ ğ‘–),i.e.,theprobabilitytobesimilarlyinfluenced
armedbanditparadigmtoestimatetheinfluencespread. byarmğ‘˜ ğ‘– inroundğ‘¡,whichisdefinedas
I teM rizP er do bb yle sm tocW hai st th icin ot rh ee pc ido en mte ix ct ino ff oi rn mfo ar tm ionat dio iffn us sc ie on na pr hio es nc oh ma er nac a- , ğ‘¤ ğ‘–,ğ‘¡(ğ‘¢,ğ‘¢â€²)=Î¦(1)(cid:16) E(cid:2)ğ‘ ğ‘–ğ‘¡ ,ğ‘¢|ğ’Œğ‘–,ğ‘ªğ‘¡(cid:3),E(cid:2)ğ‘ ğ‘–ğ‘¡ ,ğ‘¢â€²|ğ’Œğ‘–,ğ‘ªğ‘¡(cid:3)(cid:17) , (4)
p sea er dtic uu sl ea rr sly (ino fln us eo nc ci ea rl sm )ae nd dia a, mth pe lii fin efo dr tm ha roti uo gn hs sp hr ae ra id ngis ai nn diti ra et te wd eb ey
t-
whereğ‘ ğ‘–ğ‘¡
,ğ‘¢
=â„ ğ‘¢(ğ’Œğ‘–,ğ‘ªğ‘¡) âˆˆ [0,1]theexpecteddiffusionprobabil-
itybetweeninfluencer(armğ‘˜ ğ‘–)anduserğ‘¢underthecontextğ‘ªğ‘¡,
ingviauserinteractions.Foracampaignofinformationspread
consistingofğ‘‡ rounds(trials),weselecttheinfluencersateach
andÎ¦(1) :RÃ—Râ†’Rmapstheexpecteddiffusionprobabilityof
usersw.r.t.influencerğ‘˜ ğ‘– totheweightsamongusersinğº ğ‘–,ğ‘¡.
roundtomaximizetheoverallinformationspread.
seeW dse ,aar be ug di gv ee tn ofa ğ‘‡kn roo uw nn dsb (a ts re ias lse )t .Aof ti en afl cu he rn oc ue nr ds ğ‘¡ğ¾ âˆˆ= {1{ ,ğ‘˜ 2ğ‘–} .ğ‘› ğ‘– .= .1 ,ğ‘‡a }s
,
knoH wo nw ie nve or u, rth pe ros bi lm emila sr eit ty ting gr .a Tph huğº sğ‘–, wğ‘¡ ean pd rot ph oe sefu an nct ei so tn imâ„ ağ‘¢ tear ge rau pn h-
theenvironmentprovidesuswiththemessageğ¶ ğ‘¡ todiffuse,and 1Notethatthisexpectedrewardğ‘Ÿğ‘–,ğ‘¡isassessingthedistinctactivationsbyarmğ‘˜ğ‘–at
thereareğ¿ âˆˆ {1,2,...,ğ‘›}seedstobeactivatedinitially.Withğ¼ ğ‘¡ roundğ‘¡,inalignmentwiththerewardbroughtbyeacharminğ¼ğ‘¡,asdefinedinEq.(2).KDDâ€™24,August25â€“29,2024,Barcelona,Spain Feng,Tan,andCautis
ğº ğ‘–( ,1 ğ‘¡) =(U,ğ¸,ğ‘Š ğ‘–,( ğ‘¡1) )toapproximateğº ğ‘–,ğ‘¡ byexploitingthecurrent probabilities([Pğ‘¢(1) ]ğ‘¡âˆ’1aretheupdatedparametersofthenetwork
observations.Thisisknownastheexploitationgraph.Wealsocon- fromroundğ‘¡âˆ’1).Theweightsinğº ğ‘–( ,1 ğ‘¡) are
s thid ee er xa pp er ce t- ed defi dn iffe ud sh ioy npo pt rh oe bs ais bif lu itn yct ğ‘i ğ‘–o ğ‘¡ ,ğ‘¢n ,â„ sğ‘¢( o1) a( sğ’Œ tğ‘– o,ğ‘ª eğ‘¡ s) tit mo aa tp ep ğ‘Šro ğ‘–,x ğ‘¡im wa itt he ğ‘¤ ğ‘–( ,1 ğ‘¡) (ğ‘¢,ğ‘¢â€²)=Î¦(1)(cid:0)â„ ğ‘¢(1) (ğ’Œğ‘–,ğ‘ªğ‘¡),â„ ğ‘¢(1 â€²) (ğ’Œğ‘–,ğ‘ªğ‘¡)(cid:1), (7)
ğ‘Š ğ‘–,( ğ‘¡1) inthegraphğº ğ‘–( ,1 ğ‘¡) .Withthepre-estimatedgraphğº ğ‘–( ,1 ğ‘¡) ,the whereÎ¦(1) isthesamefunctioninEq.(4).Foreachuserğ‘¢,â„ ğ‘¢(1) will
estimaterewardofarmğ‘˜ ğ‘– acrossallusersisthenexpressedas betrainedbygradientdescent(GD)withthegivencontextandthe
chosenarmasinputandtherewardaslabel.Thelossisdefinedas
Toquantifytheestimağ‘ŸË†ğ‘– t, iğ‘¡ on= gğ‘“ a( p1) (u(cid:0) ğ’Œ nğ‘– c, eğ‘ª rğ‘¡ t, ağº inğ‘–( t,1 ğ‘¡ y)(cid:1) o. festimation)betwe( e5 n) Lğ‘¢(1) = (cid:16) â„ ğ‘¢(1)(cid:0) ğ’Œğ‘–,ğ‘ªğ‘¡;Pğ‘¢(1)(cid:1)âˆ’ğ‘‘ ğ‘¢ğ‘¡(cid:17)2 , (8)
ğº ğ‘–( ,1 ğ‘¡) andğº ğ‘–,ğ‘¡ (ortomeasurethepotentialgainontheestimated whereğ‘‘ ğ‘¢ğ‘¡ =1ifğ‘ ğ‘¢ğ‘¡ >0andğ‘ ğ‘¢ğ‘¡âˆ’1=0,elseğ‘‘ ğ‘¢ğ‘¡ =0.Recallthatweuse
diffusionprobabilityforeachuser-influencerpair),wealsopropose ğ‘ ğ‘¢ğ‘¡ todenotethetotalnumberoftimesuserğ‘¢hasbeenactivated
anexplorationgraph,denotedbyğº ğ‘–( ,2 ğ‘¡) =(U,ğ¸,ğ‘Š ğ‘–,( ğ‘¡2) ),whereanalo- (influenced)uptoandincludingroundğ‘¡,andweonlycountthe
gouslytheweightsamongusersğ‘¤ ğ‘–( ,2 ğ‘¡) (ğ‘¢,ğ‘¢â€²) âˆˆğ‘Š ğ‘–,( ğ‘¡2) indicateusersâ€™ newlyactivatednodesateachround.
correlationsw.r.t.potentialgains,expressedas 4.1.2 Userexplorationgraph. Recentworksonneuralbandits[2â€“
ğ‘¤(2) (ğ‘¢,ğ‘¢â€²) 4,40,41]takeadvantageoftherepresentationpowerofneural
ğ‘–,ğ‘¡
networkstolearntheuncertaintyofestimation(potentialgain).
=Î¦(2)(cid:0)â„ ğ‘¢(ğ’Œğ‘–,ğ‘ªğ‘¡)âˆ’â„ ğ‘¢(1) (ğ’Œğ‘–,ğ‘ªğ‘¡),â„ ğ‘¢â€²(ğ’Œğ‘–,ğ‘ªğ‘¡)âˆ’â„ ğ‘¢(1 â€²) (ğ’Œğ‘–,ğ‘ªğ‘¡)(cid:1) (6) Theseworksusethepastgradienttoincorporatethefeatureofarms
andthelearneddiscriminativeinformationofestimationfunction
for Wso im the tf hu en ec xti po ln orÎ¦ a( t2 io) n:R grÃ— apR hâ†’
ğº ğ‘–( ,2
ğ‘¡R
)
,w thh eic ph oi ts ensi tm iai lla gr at io nÎ¦ of(1 a) r.
mğ‘˜
ğ‘–
(â„ ğ‘¢( Q1) i(ğ’Œ eğ‘– t, ağ‘ª lğ‘¡ .) [i 2n 6]ou ar ppw lio er dk) t.
his paradigm in collaborative filtering
acrossalltheusersisdefinedasğ‘Ë† ğ‘–,ğ‘¡ = ğ‘“(2)(ğ’Œğ‘–,ğ‘ªğ‘¡,ğº ğ‘–( ,2 ğ‘¡) ).Ateach foruser-itempairpredictioninonlinerecommendationscenarios
roundğ‘¡,thearmsetğ¼ ğ‘¡ isselectedasargmaxğ¼ğ‘¡âŠ‚ğ¾:|ğ¼ğ‘¡|=ğ¿(ğ‘ŸË†ğ‘–,ğ‘¡ +ğ‘Ë† ğ‘–,ğ‘¡). a sin md ild ae rm ityon ws it tr hat pe rd edit is cte iff ngec uti sv ee rn pe rs es f. eS rein nc ce esth toe wIM ardp sro itb el mem s(s ih na or ues
r
Thismaximizestheoverallinfluencespreadinthecampaign.
casesusceptibilitytoinfluencers),especiallywhentheconnections
Thedetailsoftheconstructionsoftheexploitationandexplo-
(correlations)amongusersarereinforcedbysocialties,weapply
rationgraphsaregiveninSec.4below.
thepastgradienttoquantifytheâ€œexplorationbonusâ€[21].
4 PROPOSEDFRAMEWORK Forauserğ‘¢ âˆˆ U,weuseaneuralnetworkâ„ ğ‘¢(2) tolearnthe
Manyrecentworks[17,35]ontheIMproblemthatexploitbandits uncertainty of the estimated diffusion probability between arm
fortheexploration-exploitationtrade-offassumethattherewardis ğ‘˜ ğ‘– anduserğ‘¢,i.e.,E[ğ‘ ğ‘–,ğ‘¡|ğ‘¢,ğ’Œğ‘–,ğ‘ªğ‘¡]âˆ’â„ ğ‘¢(1) (ğ’Œğ‘–,ğ‘ªğ‘¡),similartoEq.(6).
alinearorgeneralizedlinearfunctionofarmvectors.Considering Asin[2],weapplyâ„ ğ‘¢(2) directlyonthepreviousgradientofâ„ ğ‘¢(1) .
thehighcomplexityanddynamicityofsocialnetwork-relateddata, Analogously,theexplorationgraphğº ğ‘–( ,2 ğ‘¡) = (U,ğ¸,ğ‘Š ğ‘–,( ğ‘¡2) ) iscon-
weusetherepresentationpowerofneuralnetworkstofirstly,learn
usersâ€™connectivitytobuildexploitationandexplorationgraphsand
structedwithğ‘Š ğ‘–,( ğ‘¡2) =(cid:8)ğ‘¤ ğ‘–( ,2 ğ‘¡) (ğ‘¢,ğ‘¢â€²):ğ‘¢,ğ‘¢â€² âˆˆU(cid:9) ,andğ‘¤ ğ‘–( ,2 ğ‘¡) (ğ‘¢,ğ‘¢â€²)is
secondly,learntheunderlyingrewardfunctionandthepotential theexplorationcorrelationamongusers,definedas
gainsontheestimatedreward.Theoverallframeworkofourmodel ğ‘¤ ğ‘–( ,2 ğ‘¡) (ğ‘¢,ğ‘¢â€²)=Î¦(2)(cid:16) â„ ğ‘¢(2)(cid:0)âˆ‡â„ ğ‘¢(1)(cid:1),â„ ğ‘¢(2 â€²)(cid:0)âˆ‡â„ ğ‘¢(1 â€²)(cid:1)(cid:17) . (9)
isillustratedinFig.1.
Thepreviousgradientâˆ‡â„ ğ‘¢(1) (ğ’Œğ‘–,ğ‘ªğ‘¡) =âˆ‡ Pâ„ ğ‘¢(1) (ğ’Œğ‘–,ğ‘ªğ‘¡;[Pğ‘¢(1) ]ğ‘¡âˆ’1)
4.1 EstimatingtheUserGraphs isthenetworkgradientatroundğ‘¡âˆ’1,with[Pğ‘¢(1) ]ğ‘¡âˆ’1thelastup-
Inthissection,wefirstprovideastrategytoestimatetheusersâ€™ datedparametersofâ„ ğ‘¢(1) .Inaddition,Î¦(2) isthefunctiondefined
correlationstobeinfluencedbythesamearm,formingthebasis inEq.(6)andâ„ ğ‘¢(2) willbetrainedwithGD,wheretheprevious
fortheexploration-exploitationstrategyinSec.4.2. gradientofâ„ ğ‘¢(1) iscomputedbasedontheinputsamples,andthe
4.1.1 Userexploitationgraph. Webridgetheusersinthesocial residualdiffusionprobability(potentialgainontheestimateddiffu-
graphwithdiffusionprobabilitiesbetweeninfluencersandusers. sionprobability)isthelabel,withthelossgivenas
Theintuitionisthatgiventhesamemessagetobediffused(context
ğ¶ ğ‘¡),userswhoexhibithighcorrelationsinthisgrapharemorelikely Lğ‘¢(2) = (cid:16) â„ ğ‘¢(2)(cid:0)âˆ‡â„ ğ‘¢(1) (ğ’Œğ‘–,ğ‘ªğ‘¡)(cid:1)âˆ’(cid:0)ğ‘‘ ğ‘¢ğ‘¡ âˆ’â„ ğ‘¢(1) (ğ’Œğ‘–,ğ‘ªğ‘¡)(cid:1)(cid:17)2 . (10)
tobeinfluencedbythesameinfluencer.Asthecontextchanges,an Regardingthenetworkstructureofâ„(1) andâ„(2),sincethere
influencermaynotexertthesameinfluenceonusers.Thus,ateach
arenodatacharacteristicsrequiringspecificmodelssuchasRNNs
roundğ‘¡ andforeachinfluencer(arm)ğ‘˜ ğ‘–,weinduceanexploitation
forsequentialdependenciesorCNNsforvisualcontent,wesimply
graphğº ğ‘–( ,1 ğ‘¡) torepresenttheusersâ€™correlations. employanğ½-layerfullyconnected(FC)neuralnetworkatthisstage
In the exploitation graphğº ğ‘–( ,1 ğ‘¡) , the weights among users are forinitialgraphestimation.
referredtoasusersâ€™correlationsw.r.t.thediffusionprobabilityfrom Tosummarise,weuseâ„ ğ‘¢(1) ,denotinguserğ‘¢,toobtainthees-
armğ‘˜ ğ‘– (hencelikelihoodtoinfluencedbythesameinfluencerğ‘˜ ğ‘–). timated diffusion probability from influencer (arm)ğ‘˜ ğ‘– toğ‘¢ (the
Foreachuserğ‘¢ âˆˆU,weuseaneuralnetworkasthepre-defined estimationfunctionisbuiltforeachuserindividually,i.e.,thereare
hypothesisfunctionâ„ ğ‘¢(1) =â„ ğ‘¢(1) (ğ’Œğ‘–,ğ‘ªğ‘¡;[Pğ‘¢(1) ]ğ‘¡âˆ’1)tolearnthese ğ‘šestimationfunctionsâ„ ğ‘¢(1) intotal),andtheexploitationgraphInfluenceMaximizationviaGraphNeuralBandits KDDâ€™24,August25â€“29,2024,Barcelona,Spain
Exploitation
Graph estimation Reward and potential gain estimation Arm selection
&F e coa ntu tere
x
tv ve ect co tor
r Exploitation graphğº ğ‘–(cid:4666) ,ğ‘¡1(cid:4667) GCN FC Network Reward
ğ‘¤ 1(cid:4666) 21(cid:4667) ğ‘“(cid:4666)1(cid:4667)
â„ğ‘¢(cid:4666)1 1(cid:4667)
â„ğ‘¢(cid:4666)1 2(cid:4667) â„ğ‘¢(cid:4666)1(cid:4667)(cid:3435)ğ’Œğ’Š,ğ’•,ğ‘ªğ’•(cid:3439)
ğ‘¤ 1(cid:4666) 31(cid:4667) ğ‘¤ 2(cid:4666) 31(cid:4667)
Input Output
ğ‘Ì‚ğ‘–ğ‘¢1
ğ‘Ì‚. ğ‘–ğ‘¢.
2
.
ğ‘Ì‚ğ‘–ğ‘¢ğ‘š
ğ‘Ÿğ‘–Ì‚,ğ‘¡(cid:3404)(cid:3496)(cid:3533) ğ‘–âˆˆğ’°(cid:3435)ğ‘Ì‚ ğ‘–ğ‘¡ ,ğ‘¢(cid:3439)2
â„ğ‘¢(cid:4666)1 3(cid:4667)
âˆ‡â„ğ‘¢(cid:4666)1(cid:4667)
ğ‘¤ğ‘¢(cid:4666)1 1,(cid:4667) ğ‘¢2(cid:3404)Î¦(cid:4666)1(cid:4667)(cid:3435)hu(cid:4666)1 1(cid:4667),hu(cid:4666)1 2(cid:4667)(cid:3439)
âˆ‡ğ‘“(cid:4666)1(cid:4667) argmax(cid:4666)ğ‘Ÿ ğ‘–Ì‚ ,ğ‘¡(cid:3397)ğ‘(cid:3552) ğ‘–,ğ‘¡(cid:4667)
ğ‘¤ğ‘¢(cid:4666)2 1,(cid:4667) ğ‘¢2(cid:3404)Î¦(cid:4666)2(cid:4667)(cid:3435)hu(cid:4666)2 1(cid:4667),hu(cid:4666)2 2(cid:4667)(cid:3439)
ğ¼ğ‘¡âŠ‚ğ¾,|ğ¼ğ‘¡|(cid:3404)ğ¿
ğ‘¤(cid:4666)2(cid:4667) ğ‘“(cid:4666)2(cid:4667)
12 ...
â„ğ‘¢(cid:4666)2 1(cid:4667) â„ â„ğ‘¢(cid:4666) ğ‘¢(cid:4666)2 2
2
3(cid:4667)
(cid:4667)
â„ğ‘¢(cid:4666)2(cid:4667)(cid:3435)âˆ‡â„ğ‘¢(cid:4666)1(cid:4667)(cid:3439) Eğ‘¤ x1(cid:4666) p32 l(cid:4667)
o ration
grğ‘¤ ap2(cid:4666) 32 h(cid:4667) ğºIn (cid:4666)2p (cid:4667)u t
GCN FC Network
Output ğ‘§ Pğ‘–Ì‚ğ‘¢ o1
t e
nğ‘§ğ‘–Ì‚ tğ‘¢ ia2
l gain
ğ‘§ğ‘–Ì‚ğ‘¢ğ‘š ğ‘(cid:3552) ğ‘–,ğ‘¡(cid:3404)(cid:3496)(cid:3533) ğ‘–âˆˆğ’°(cid:3435)ğ‘§ ğ‘–Ì‚ğ‘¡ ,ğ‘¢(cid:3439)2
ğ‘–,ğ‘¡
Exploration
Figure1:TheframeworkofIM-GNB.Foreacharm,weinitiallytakethearmfeaturevectorandthecurrentcontextvector
(ğ’Œğ‘–,ğ‘ªğ‘¡)asinputstoestimatethediffusionprobabilityforeachuser-armpairwithâ„ ğ‘¢(1) .Subsequently,weassessthepotential
gainonthediffusionprobabilitywiththepastgradientofâ„ ğ‘¢(1) ,yieldingbothexploitationandexplorationgraphs.Withthe
pre-estimatedgraphs,werefinetheestimateofthediffusionprobabilityforeachuser-armpairwithğ‘“(1)andğ‘“(2).Theaggregate
rewardofthearmacrossallusersisderivedfromthesumofalltherefinedindividualdiffusionprobabilities.Thepotential
gainismeasuredsimilarly.Finally,weselectthearmwiththehighestsumofestimatedrewardanditspotentialgain.
ğº ğ‘–( ,1 ğ‘¡) forarmğ‘˜ ğ‘– isbuiltsuchthatthebasicusersarecorrelated We adopt a simplified Graph Convolutional Network (GCN)
basedonestimateddiffusionprobabilities.Wealsoapplyâ„ ğ‘¢(2) to model[36]tolearntheaggregatedrepresentationoftheexploita-
representtheuncertaintyoftheestimateddiffusionprobability, tiongraph.Withğ‘† ğ‘–( ,1 ğ‘¡) andğ‘¿ğ‘–( ,1 ğ‘¡) asinputs,thefeaturerepresentation
andtheexplorationgraphğº ğ‘–( ,2 ğ‘¡) correspondingtoarmğ‘˜ ğ‘– isbuilt matrixisexpressedas
suchthattheusersarecorrelatedbasedonthepotentialgains.The ğ» G =ğœ(cid:16) (cid:0)ğ‘† ğ‘–( ,1 ğ‘¡)(cid:1)ğ›¾ ğ‘¿ğ‘–( ,1 ğ‘¡) ;P G(1)(cid:17) , (11)
graphestimationprocessisgiveninLines13â€“17ofAlgorithm1.
where ğœ is the activation function, P(1) âˆˆ Rğ‘š(ğ‘‘ 1+ğ‘‘ 2)Ã—ğ‘ is the
G
trainableweightmatrixintheGCNmodel,andğ›¾ isthenumberof
4.2 Exploitation-ExplorationwithGNNs
hopstheinformationpropagatingovertheusergraph,indicating
Withtheusercorrelationgraphsğº ğ‘–( ,1 ğ‘¡) andğº ğ‘–( ,2 ğ‘¡) forexploitation thatafterğ‘˜layersanodeobtainsthefeatureinformationfromall
andexplorationrespectively,wenowhavearefinedestimateofthe nodesfoundğ›¾ hopsawayinthegraph.IntheGCNmodel,ğ‘¿ğ‘–( ,1 ğ‘¡) is
diffusionprobabilitiesbetweeninfluencersandusers,aswellasthe appliedtothecorrespondingweightmatrixP(1) sothatP(1)
is
expectedtotalspread(newlyactivatedusers),i.e.,thereward. G G
partitionedforeachuserğ‘¢ âˆˆUtogettheğ‘-dimensionalarm-user
4.2.1 GNNforexploitation. Inroundğ‘¡,foreacharmğ‘˜ ğ‘–,withthe diff Tu osi fo un rtr he ep rr re es fien nt ea tt hio en ğ‘, -c do ir mre es np so in ond ain lg art moe -ua sc eh rr po aw iro rf eğ» prG esâˆˆ enR tağ‘š tiÃ— oğ‘ n.
pre-estimatedexploitationgraphğº ğ‘–( ,1 ğ‘¡) forarmğ‘˜ ğ‘– asinput,weuse inğ» G,weaddan ğ½-layerFCneuralnetworktotheGCNmodel,
aGNNmodel ğ‘“(1)(ğ’Œğ‘–,ğ‘ªğ‘¡,ğº ğ‘–( ,1 ğ‘¡) ;P(1)) toestimatetherewardde- andforğ‘™ âˆˆ{1,2,...,ğ½ âˆ’1}therepresentationforeachlayeris
scribedinEq.(3),withP(1) representingtheparametersofğ‘“(1). ğ» ğ‘™ =ğœ(cid:0)ğ» ğ‘™âˆ’1Â·P ğ‘™(1)(cid:1), and ğ» 0=ğ» G, (12)
Rğ‘šW Ã—ğ‘šed fre ofi mne thfo er ee xa pc loh ita ar tm iona gs ry am phm ğºet ğ‘–(r ,1 ğ‘¡ic ) ,a wd ij ta hce en acc hy em lea mtr eix ntğ´ iğ‘– n( ,1 ğ‘¡) thâˆˆ
e
w lai yt eh rğ» inğ‘™ tâˆˆ heR Fğ‘š CÃ—ğ‘ n, ea twnd orP kğ‘™ .(1 F) orbe thin eg lath ste lt ar ya ein r,a wbl ee hp aa vr eametersineach
matrixcorrespondingtothecorrelationsweightsğ‘¤ ğ‘¢,ğ‘¢â€² between ğ‘ƒË† ğ‘–,ğ‘¡ =ğ» ğ½âˆ’1Â·P ğ½(1), (13)
userğ‘¢anduserğ‘¢â€²inğº ğ‘–( ,1 ğ‘¡) ,andthenormalizedadjacencymatrix[19] wheretheP ğ½(1) aretheparametersinthelastlayer,andğ‘ƒË† ğ‘–,ğ‘¡ âˆˆRğ‘š is
beingğ‘† ğ‘–( ,1 ğ‘¡) =ğ·âˆ’1 2ğ´ ğ‘–( ,1 ğ‘¡)ğ·âˆ’1 2,withğ·thedegreematrix.Weconcate- theğ‘š-dimensionalvectorwitheachelementtherefinedestimated
natethearmfeaturevectorğ’Œğ‘– withthecontextvectorğ‘ªğ‘¡ tobuild diffusionprobabilityğ‘Ë† ğ‘–ğ‘¡ ,ğ‘¢ âˆˆRbetweenarmğ‘˜ ğ‘– anduserğ‘¢ âˆˆU.
the feature matrix ğ‘¿ğ‘–,ğ‘¡ = diag([ğ’Œğ‘–,ğ‘ªğ‘¡],[ğ’Œğ‘–,ğ‘ªğ‘¡],...,[ğ’Œğ‘–,ğ‘ªğ‘¡]) âˆˆ Withtherefinedestimateddiffusionprobabilitybetweenarm
Rğ‘šÃ—ğ‘š(ğ‘‘ 1+ğ‘‘ 2). ğ‘˜ ğ‘– andalltheusers,theestimatedrewardforarmğ‘˜ ğ‘– acrossalltheKDDâ€™24,August25â€“29,2024,Barcelona,Spain Feng,Tan,andCautis
usersiscomputedasthenormoftheoutputlayer: Algorithm1:IM-GNB
ğ‘ŸË†ğ‘–,ğ‘¡ =âˆ¥ğ‘ƒË† ğ‘–,ğ‘¡âˆ¥=âˆšï¸„ âˆ‘ï¸ (cid:0)ğ‘Ë† ğ‘–ğ‘¡ ,ğ‘¢(cid:1)2. (14) I On up tu pt u: t:In Afl ru men rc ee cr omse mtğ¾ en, dn au tm iob ne fr oo rf es ae cl hec tt ii mon es sğ¿ teppe ğ‘¡rround
ğ‘¢âˆˆU
1 Initializationofallthetrainableparameters
TheexploitationnetworkwillbetrainedwithGDbasedonthe 2 forğ‘¡ =1,2,3,...,ğ‘‡ do
influencespreadfromarmğ‘˜ ğ‘–,wherethepredictedoutputarethe 3 Receivefromenvironmentthecontextğ‘ªğ‘¡
diffusionprobabilitiesacrossallusers,withthelabel(reward) 4 forğ‘˜ ğ‘– âˆˆğ¾ do
ğ‘Ÿ ğ‘–,ğ‘¡ = âˆ‘ï¸ ğ‘‘ ğ‘¢ğ‘¡. (15) 5 constructtwousergraphsğº ğ‘–( ,1 ğ‘¡) andğº ğ‘–( ,2 ğ‘¡) from
ğ‘¢âˆˆğ´ğ‘˜ğ‘–
ProcedureEstimatinggraphsforarmğ‘˜
ğ‘–
R atec roal ul nth da ğ‘¡t ,ğ´ ağ‘˜ nğ‘– di ğ‘‘s ğ‘¢ğ‘¡th ie ss de et fio nf eu dse ar ss ta hc eti dv ia st te id nco tr ai cn tfl ivu ae tn ioce nd sb iny Ear qm .(ğ‘˜ 8)ğ‘–
.
6 C ğ‘ŸË†o ğ‘–,m
ğ‘¡
p =u ğ‘“te (1e )s (t ğ’Œim ğ‘–,a ğ‘ªt ğ‘¡e ,ğºof ğ‘–( ,1 ğ‘¡re ) ;w [a Prd (1)]ğ‘¡âˆ’1)
Forarefinedlearningoneachuser-armdiffusionpair,wecalculate 7 and,potentialgain
thequadraticlossw.r.t.eachuserindividually,as ğ‘Ë† ğ‘–,ğ‘¡ =ğ‘“(2)(âˆ‡[ğ‘“(1)]ğ‘–,ğ‘¡,ğº ğ‘–( ,2 ğ‘¡) ;[P(2)]ğ‘¡âˆ’1)
L(1) = âˆ‘ï¸ (cid:0)ğ‘Ë†ğ‘–ğ‘¡ ,ğ‘¢âˆ’ğ‘‘ ğ‘¢ğ‘¡(cid:1)2. (16) 8 choosearmsetğ¼ ğ‘¡ =argmaxğ¼ğ‘¡âŠ‚ğ¾,|ğ¼ğ‘¡|=ğ¿(ğ‘ŸË†ğ‘–,ğ‘¡ +ğ‘Ë† ğ‘–,ğ‘¡)and
ğ‘¢âˆˆğ´ğ‘˜ğ‘– observethetruereward(spread)ğ‘… ğ‘¡ inEq.(2),which
representsthenewlyactivatedusers.
4.2.2 GNNforexploration. Similartotheusergraphpre-estimation
9
forğ‘¢ âˆˆUdo
describedinSec.4.1,wefollowtheexploration-exploitationstrat-
egybyapplyingagradient-basedexplorationfunctionw.r.t.the 10
traintheusernetworksâ„ ğ‘¢(1) (Â·;Pğ‘¢(1) ),â„ ğ‘¢(2) (Â·;Pğ‘¢(2) )
exploitationfunction;alsosee[2,26,40,41]forsimilarstrategies. 11 forğ‘˜ âˆˆKdo
Inroundğ‘¡,foreacharmğ‘˜ ğ‘–,withtheinducedexplorationgraph 12 traintheGNNmodelsğ‘“(1)(Â·;P(1)),ğ‘“(2)(Â·;P(2))
ğº ğ‘–( ,2 ğ‘¡) wherethepre-estimatedweightsinSec.4.1.2representtheex-
13 Procedure,Estimating graphs for arm(ğ‘˜ ğ‘–,ğ‘¡)
p tğ‘“ wl (o 2 er ) ea ( nt âˆ‡io eğ‘“n x( p1c ) eo , cr ğº tr eğ‘–e ( , d2l ğ‘¡a ) rt ;i ePo wn ( as 2 r)a d)m t aoo nn e dg v eau sls tu ie a mr ts e a, ttw eh de e ra p ep o wp tel ay n rdta i )n a flo ot g rh ae ainr rmG (tN h ğ‘˜eN ğ‘–,g wm ap ho ed b re e el - 1 14 5 for Fea oc rh eu ds ge er wpa ei ir gh(ğ‘¢ t, ğ‘¤ğ‘¢ ğ‘–â€² ( ,) 1 ğ‘¡)âˆˆ (ğ‘¢U ,ğ‘¢Ã— â€²)U âˆˆğ‘Šd ğ‘–o ,( ğ‘¡1) ,update
âˆ‡ğ‘“(1) = âˆ‡ Pğ‘“(1)(ğ’Œğ‘–,ğ‘ªğ‘¡;[P(1)]ğ‘¡âˆ’1), and P(1) and P(2) are the ğ‘¤ ğ‘–( ,1 ğ‘¡) (ğ‘¢,ğ‘¢â€²)=Î¦(1)(â„ ğ‘¢(1) (ğ‘˜ ğ‘–,ğ‘¡),â„ ğ‘¢(1 â€²) (ğ‘˜ ğ‘–,ğ‘¡))
parametersofğ‘“(1) andğ‘“(2) respectively. 16 Foredgeweightğ‘¤ ğ‘–( ,1 ğ‘¡) (ğ‘¢,ğ‘¢â€²) âˆˆğ‘Š ğ‘–,( ğ‘¡1) ,update
netW we ora kd to op lt eath rne ts ha em re epn re et sw eno tr ak tia or nc mhi ate trc it xu fr oe ra ths ein exth ple oe rax tp iolo nit ga rt aio pn
h
ğ‘¤ ğ‘–( ,2 ğ‘¡) (ğ‘¢,ğ‘¢â€²)=Î¦(2)(â„ ğ‘¢(2) (âˆ‡â„ ğ‘¢(1) ),â„ ğ‘¢(2 â€²) (âˆ‡â„ ğ‘¢(1 â€²) ))
withağ‘˜-hopsimplifiedGCN,andtopredictthepotentialgainwith 17 returnğº ğ‘–( ,1 ğ‘¡) andğº ğ‘–( ,2 ğ‘¡)
an ğ½-layer FC neural network. The architecture of ğ‘“(2) can be
alsoimplementedviaEqs.(11)â€“(13),withtheinputfeaturevector
ğ‘¿ğ‘–( ,2 ğ‘¡) âˆˆ Rğ‘šÃ—ğ‘šğ‘ andtrainablematrixP G(2) âˆˆ Rğ‘šğ‘Ã—ğ‘ intheGCN 4.2.3 IM-GNBarmselection. WesummarizetheIM-GNBframe-
model,whereğ‘isthedimensionofinputgradient.IntheGCNof workinAlgorithm1.Foraninformationdiffusioncampaignwith
ğ‘“(2),theinputgradientmatrixğ‘¿ğ‘–( ,2 ğ‘¡)
issimilarlyappliedtopartition
ğ‘‡ rounds,weselectğ¿influencers(arms)fromaknowninfluencers
theweightmatrixP
G(2)
,sothateachuser-armpairisrepresented
b roa use ndğ¾ ğ‘¡a ft oe ra ec ah chro au rn md ğ‘˜ğ‘¡ ğ‘–,to wedi fiff ru ss te lyt ch oe ng si tv re un ctm the ess ta wg oe uğ‘ª sğ‘¡ e. rA gt rae pac hh
s
byağ‘-dimensionalvectorforthepurposeofexploration.
i.e.,theexploitationgraphandtheexplorationgraphviaaprocedure
In the output layer we obtain anğ‘š-dimensional vector ğ‘Ë† ğ‘–,ğ‘¡,
(Lines13â€“17)ofpre-estimationongraphweights,whichcapture
whereeachelementrepresentstheestimatedpotentialgainğ‘§Ë†ğ‘–ğ‘¡
,ğ‘¢
âˆˆ
usersâ€™correlationsintermsofexploitationandexplorationrespec-
R,ğ‘¢ âˆˆ U (with |U| = ğ‘š)foreachuser-armpair.Withtheesti- tively.Withthederivedgraphs,wecomputetheoverallexpected
matedpotentialgainsfromtheoutputlayer,theoverallestimated rewardğ‘ŸË†ğ‘–,ğ‘¡ andpotentialgainğ‘Ë† ğ‘–,ğ‘¡ foreacharminEqs.(14)and(17),
potentialgainforarmğ‘˜ ğ‘– isobtainedasthenormofoutputğ‘Ë† ğ‘–,ğ‘¡,i.e., asthenormsoftheoutputvectorsfromğ‘“(1) andğ‘“(2).Next,we
ğ‘Ë† ğ‘–,ğ‘¡ =âˆ¥ğ‘Ë† ğ‘–,ğ‘¡âˆ¥=âˆšï¸„ âˆ‘ï¸ (cid:0)ğ‘§Ë† ğ‘–ğ‘¡ ,ğ‘¢(cid:1)2. (17) s ee stle imct att ih oe na ar nm dps oe tt eb na tis ae ld gao in nğ‘Ÿt Ë†h ğ‘–,ğ‘¡e +m ğ‘Ë† ğ‘–a ,ğ‘¡xi (m Liu nm e8o ).f Ft ih nae lls yu ,m foro ef ar ce hw ua sr ed r
ğ‘¢âˆˆU ğ‘¢ âˆˆU,wetraintheuserâ€™sneuralnetworksfrompre-estimation,
Whentraining ğ‘“(2) withGD,thequadraticlossiscomputed andwetrainforeacharmğ‘˜ ğ‘– âˆˆğ¾ theGNNmodels(Lines9â€“12).
betweentheestimatedpotentialgainandtheresidualgain(thegap Weobservefromtheabovethatateachroundğ‘¡,â„ ğ‘¢(1) willtakeas
betweentherewardinEq.(15)andtheestimatedreward),as inputthefeaturevectorofacertainarmğ‘˜ ğ‘–,alongwiththecontext
L(2) = âˆ‘ï¸ (cid:16) ğ‘§Ë†ğ‘–ğ‘¡ ,ğ‘¢âˆ’(cid:0)ğ‘‘ ğ‘¢ğ‘¡ âˆ’ğ‘Ë†ğ‘–ğ‘¡ ,ğ‘¢(cid:1)(cid:17)2 . (18) v foe rct uo sr eğ‘ª rğ‘¡ ğ‘¢t bo ep inro gv ii nd fle ua en ni cn ei dtia bl ye ast ri mma ğ‘˜t ğ‘–e .So un bt sh ee qd ui eff nu ts lyio ,n thp ero gb raa db ii eli nty t
ğ‘¢âˆˆğ´ğ‘˜ğ‘– ofâ„ ğ‘¢(1) isemployedasinputtoestimatethepotentialgainindiffu-
Thecomputationsoftherewardandpotentialgainaresumma- sionprobability.Parametersinâ„ ğ‘¢(1) andâ„ ğ‘¢(2) undergocontinuous
rizedinLines5â€“7inAlgorithm1. trainingandupdatingateachroundtorefinetheapproximationInfluenceMaximizationviaGraphNeuralBandits KDDâ€™24,August25â€“29,2024,Barcelona,Spain
functionsforuserğ‘¢,predictingtheprobabilityofbeinginfluenced challengesduetotheirpotentiallylargevalues.Thisisparticu-
byanyarmwithinvariouscontexts.Similarly,fortherewardesti- larlyrelevantinSec.4.2.2,wheretheinputgradientdimensionis
mationforeacharmwithğ‘“(1)andğ‘“(2),ğ‘“(1)takesasinputthearm ğ‘š(ğ‘‘ 1+ğ‘‘ 2)ğ‘+(ğ½ âˆ’1)ğ‘2+ğ‘.Toaddressthisissue,andinspiredby
featurevectorandcontextvector,aswellasthepre-estimatedgraph approachescommonlyemployedinCNN-relatedworks,weusethe
ğº ğ‘–( ,1 ğ‘¡) torefinetheinitialestimationonthediffusionprobability,al- averagepoolingtechniquetoeffectivelyreducetheinputdimension
lowingtoestimatetherewardacrossallusers,andthegradientof andimproveefficiency.
ğ‘“(1) servesastheinputofexplorationfunctionğ‘“(2).Bothğ‘“(1) and 5 EXPERIMENTS
ğ‘“(2) undergocontinuoustrainingtorefinetherewardestimation
Inthissection,weevaluateourmodelIM-GNBondatasetsfrom
function(exploitation)andpotentialgain(exploration).Thisitera-
TwitterandSinaWeibo.Wecompareitwithbaselinesalsodesigned
tiveprocessensuresthatğ‘“(1) andğ‘“(2) adapteffectivelytodiverse formulti-rounddiffusioncampaigns,andweanalyzethecompar-
contextsandusercorrelationgraphs. isonresultsintheend.Forreproducibility,theIM-GNBcodeis
availableathttps://github.com/goldenretriever-5423/IM_GNB.
4.2.4 ComplexityAnalysis. Recallfromthepreviousnotationcon- DatasetsTwitterandWeiboaretwoofthelargestsocialmedia
ventionsthatwehave|ğ¾|=ğ‘›arms,ğ‘šusers,andthedimensions
platforms.WecollectedtheTwitterdatasetthroughitsAPI.Inour
ofthefeaturevectorsandcontextinformationareğ‘‘ 1andğ‘‘ 2respec- contextanalysisforTwitter,weapplyğ¾-meansclusteringonthe
tively.Forsimplicity,weuseğ‘‘ ğ‘”todenotethedimensionofallthe publicvocabularyglove-twitter-200[25],availablefromtheGen-
inputgradients,andweassumethatthesamestructureisusedfor simwordembeddingopen-sourcelibrary2.Theresultingclusters
alltheFCneuralnetworksinourmodel.Inparticular,eachneural providecentroidsthatserveasrepresentativethemeswithinthe
networkhasğ½ layersandeachlayerhasğ‘›neurons.
dataset.Subsequently,werepresentthemasadistributionacross
Forthepre-estimationofuserexploitationandexplorationgraphs, thesecentroids(10inourexperiments)toencodetweets.Eachword
ateachround,thecomplexityofthepre-definedhypothesisfunc- inatweetisassignedtoitsnearestcentroid,resultingintheoverall
tionsâ„ ğ‘¢(1) andâ„ ğ‘¢(2) (FCneuralnetworks)isğ‘‚(cid:0)|ğ¾|ğ‘šğ½(ğ‘‘ 1+ğ‘‘ 2)ğ‘›(cid:1) for distribution.Thefeaturevectoroftheinfluenceristhenormalized
exploitationandğ‘‚(|ğ¾|ğ‘šğ½ğ‘‘ ğ‘”ğ‘›)forexploration. aggregationofallitshistoricaltweets.TheWeibodataset[39]is
FortherefinedestimationprocedurewhereweuseGCNs,aswe apubliclyavailableonebuiltforinformationdiffusionstudies.In
predictcorrelationsamongallusers,thegraphscanbeseenascom- thisdataset,eachpostisencodedwithadistributionoverthe100
plete.Assumingthattheexploration/exploitationGCNssharethe topics[39]usinglatentDirichletallocation[5].SimilartotheTwit-
sameNNstructure,thetimeandspacecomplexitiesforexploitation terdataset,thefeaturevectoroftheinfluenceristhenormalized
areğ‘‚(cid:0)|ğ¾|ğ½(ğ‘š2(ğ‘‘ 1+ğ‘‘ 2)+ğ‘š(ğ‘‘ 1+ğ‘‘ 2)2)(cid:1) andğ‘‚(cid:0)|ğ¾|ğ½(ğ‘š2+(ğ‘‘ 1+ğ‘‘ 2)2+ aggregateofthetopicdistributionofallhistoricaltweets.
ğ‘š(ğ‘‘ 1+ğ‘‘ 2))(cid:1) respectively,andforexplorationğ‘‚(cid:0)|ğ¾|ğ½(ğ‘š2ğ‘‘ ğ‘”+ğ‘šğ‘‘ ğ‘”2)(cid:1) To simulate campaigns on social media, we assume that the
andğ‘‚(cid:0)|ğ¾|ğ½(ğ‘š2+ğ‘‘ ğ‘”2+ğ‘šğ‘‘ ğ‘”)(cid:1) . marketerhasaccesstoonlyafewmostimportantinfluencersto
Fromtheabovediscussion,wecanobservethatthenumberof diffusethemessageinthecampaigns.Hence,wefixthesizeofthe
usersandthedimensionoftheinputgradientarethemostcritical influencersetğ¾ byselectingtheuserswiththehighestnumber
parametersindeterminingthetimecomplexity.Weconsiderthe of reposts in our Twitter and Weibo logs, and we keep all the
followingmethodstoreducethecomputationalcomplexity. tweetsrelatedtothem.Thestatisticsofthedatasetsbeforeandafter
filteringaregiveninTables1and2.Ineachcampaign,werandomly
Userclustering. Inapplicationswithbillionsofusersonsocial chosethecontexts(tweets),referredtoastopicdistributions,for
media,itisimpracticalandexcessivelycostlytopredictdiffusion eachroundfromthepoolofavailablecontextswithinthedataset.
probabilitiesandcorrelationsatthegranularityofindividualusers.
Table1:Descriptionoforiginaldatasets.
Inresponsetothischallenge,wecanleveragethepostingactivity
(e.g.,retweetinghistory)ofuserstoconstructatopicdistribution
#users #originaltweets #retweets
vectorforeachuser.Wecanthenclusterusersintoaspecificnum-
berofgroups,witheachusergrouprepresentingamacro-node Twitter 11.6M 242M 341.8M
inasmallersocialgraph.Notably,thetheoreticalunderpinnings Weibo 1.8M 300K 23.8M
outlinedearlierremainapplicabletotheseclusteredusergroups,
anduserğ‘¢becomesğ‘¢ ğ‘ğ‘–,ğ‘– =1,2,...,ğ‘šâ€²andâˆªğ‘š ğ‘–=â€² 1ğ‘¢
ğ‘ğ‘–
=U,withğ‘šâ€²
denotingthenumberofclusteredgroups.Despitethisadjustment, Table2:Descriptionoffiltereddatasets.
wecontinuetorefertotheusergroupğ‘¢
ğ‘ğ‘–
asuserğ‘¢forsimplicity.
#users #originaltweets #retweets
Theintroductionofclusteringcansignificantlyreducecompu-
tationalcost,transformingthespacecomplexityoftheadjacency Twitter 31.6k 19k 1M
matrixintheGCNfromğ‘šÃ—ğ‘štoamorecomputationallyefficient Weibo 54.4k 6K 1M
scale. Experiments are carried out on the number of clustering
groupsinSec.5toshowtheimpactofthenumberofclusterson
BaselinesWecompareIM-GNBtoasetofbanditmodelsdesigned
theperformanceofthemodel.
fortheIMproblemunderthesamemulti-roundcampaignsscenario,
wheretheunderlyingnetworkisunknownandnoassumptions
Inputgradients. InSec.4.1.2andSec.4.2.2,wesawthatthein-
putdimensionsforthepreviousgradientscanposecomputational 2https://pypi.org/project/gensim/KDDâ€™24,August25â€“29,2024,Barcelona,Spain Feng,Tan,andCautis
aboutthediffusionmodelsaremade.LogNorm-LinUCB[17]and issurpassedbycertainbaselinemethods,notablyGLM-GT-UCB,
GLM-GT-UCB[17]aretherecent,state-of-the-artapproachesto whichexhibitmorerapidlearningcapabilities.Weattributethis
maximizeinformationdiffusionduringsuchIMcampaigns.LogNorm- phenomenontothenatureofIM-GNBasadata-drivenmodel,typ-
LinUCBdirectlyadaptstheLinUCBalgorithmbyusinglogarith- icalofmoderndeeplearning-basedapproaches.Theefficiencyof
micnormalizationandcontextualinformationtomakesequential IM-GNBimprovesrapidlywiththeaccumulationofdata(i.e.,as
selectionsofspreadseeds,whileGLM-GT-UCBemploysagener- moreroundspassby),indicatingpotentialslowerconvergenceini-
alizedlinearmodelandtheGoodâ€“Turingestimatortodetermine tially,butyieldingbetterresultsasthenumberofroundsincreases.
theremainingpotentialofinfluencers.WealsocomparewithFAT- Additionally,theWeibodatasetisapubliclyavailabledatasetthat
GT-UCB[20],acontext-freemodelwhichhastheparticularityto consistsofartificiallyextracteddatafromdiffusioncascades,while
considerthefatigue,i.e.,aninfluencersâ€™diminishingtendencyto theTwitterdataset,albeitsparserthanWeibo,offersinsightscloser
activatebasicusersastheyarere-seededthroughoutthecampaign. toreal-worldIMscenarios.
Wealsogeneralizeseveralstate-of-the-artneuralbanditmethodsâ€“ Inbothdatasets,Lognorm-LinUCBgenerallyoutperformsthe
NeuralUCB [40] and NeuralTS [41], as well as the well-known otherbaselines.WhilethereareinstanceswhereGLM-GT-UCB
LinUCB[8]toourmulti-roundIMcampaign.Finally,wealsoim- brieflyoutperformsLognorm-LinUCBintheinitialstages,thelat-
plementareferencemodelthatrandomlychoosestheinfluencer(s) terdemonstratesstableperformancewithsmallererrorbars.This
ateachround,asin[17]. underscorestherobustnessofthelog-normalassumptiononthe
ExperimentalSettingInourexperiments,toreducethecompu- rewarddistribution.NeuralUCBandNeuralTS,asscalarizationsof
tationcost,wefirstclusteralltheusersinto50groups.Forthe thegeneralneuralbanditmodel,exhibitcomparableperformances
pre-estimationofthegraphweights,weusea3-layerFCneural acrossbothdatasets.Notably,theireffectivenesslagsbehindmod-
networkasthehypothesisclassforbothâ„ ğ‘¢(1) andâ„ ğ‘¢(2) ,toestimate elstailoredformulti-rounddiffusioncampaignswhenğ¿issmall.
thediffusionprobabilityandpotentialgain.ThefunctionsÎ¦(1) and However,whenğ¿increases,themodelsareempoweredwithmore
Î¦(2) thatmaptheusersâ€™correlationstotheweightsinthegraphs data,showingmarkedperformanceimprovements.
HyperparameterAnalysis
areradialbasisfunctions(RBFs),withtheirbandwidthssetto5.For
theGCNmodel,weexploretheuseof3hops(i.e.,ğ›¾ =3)tocapture Number of clusters: We conduct experiments on the number of
multi-levelrelationshipswithintheusergraphs,witha3-layerFC
clustersintheTwitterdatasetwithğ¿ =2,andtheresultsonthe
neuralnetworkconnectedattheend.Thepoolingstepsizesto lastround(finalaccumulatedspread)areshowninFig.4ofthe
reducedimensions[26]fortheinputgradientsinğ‘“(2) aresetto appendix.WeobservefromFig.4thatthecampaignperformance
1,000and10,000respectivelyfortheTwitterandWeibodatasets. improvesasthenumberofclustersincreasesfrom2to150atthe
beginning.However,beyond200clusters,performancebeginsto
EmpiricalResultsForadiffusioncampaign,ateachround,the
decline.Thisdeclinecanbelikelyattributedtoinsufficientdata
environmentfirstprovidesthecontext,analgorithmthenselects
withineachclusterforeffectivelearningwiththeconstraintsof
theroundâ€™sinfluencer(s),andfinally,atweetissampledforthe
alimitedbudgetonthenumberofrounds.Additionally,compu-
specificpairofinfluencer(s)andcontextfromthedataset.Thenew
tationalcostsescalateexponentiallyastheclustersizegoesup.
activations are determined by discounting the users previously
Throughtheanalysis,aclustersizeof20to50seemstostrikethe
encountered from the set of users associated with the sampled
rightbalancebetweenperformanceandcomputationalefficiency.
tweet.Allourempiricalresultsareaveragedover100independent
Thisobservationnotonlyvalidatestheinitialrationaleforcluster-
runs(themeansandstandarddeviationsarereported),andthe
ingusers,butalsounderscoresthesignificanceofcomputational
diffusionbudgetissetto500rounds.
efficiencyinoptimizingsocialcampaignsunderbudgetconstraints.
Comparisonwithbaselines:Weconductedcomparisonswithvarious
BoostedExplorationScores:Banditalgorithmsaimtostrikeadelicate
baselinesontheTwitterandWeibodatasets,varyingthenumber
ofchosenseeds(ğ¿)perroundwithin{1,2,...,5}.Theresultsare balancebetweenexploitingknowninformationtomaximizeshort-
termgainsandexploringunknownoptionstoimprovelong-term
showninFig.2andFig.3respectively.Fromthetwofigures,wecan
performance.Inthisspirit,wealsoconsiderintheexperiments
observethat,acrossbothdatasets,ourmodelIM-GNBgenerally
avariantofexploration,inwhichweboosttheexplorationscore
outperformsthebaselines.Notably,ontheTwitterdataset,IM-GNB
ofunchosenarmshavingzerorewardoutcomes,toincreasethe
exhibitsasignificantlyincreasedadvantageoverthebaselines,as
thenumberofseedsincreasesuptoğ¿=3.However,thisadvantage likelihoodofexploringalternativearms.Werunexperimentson
diminishesasğ¿continuestogrow,astheprobabilityofselecting
theTwitterdatasetwithğ¿=2comparingtheuseofsuchartificially
boostedexplorationagainstitsabsence.Theresultsarepresented
thecorrectarmsincreasesforallmodels.Infact,fortheextreme
scenariowhereğ¿=|ğ¾|=10,thisresultsinthesameperformances in Fig. 5 in the appendix, and confirm the effectiveness of this
approach;thisfurthersupportstheimportanceofexplorationto
acrossallmodelsduetotheselectionoftheentirebasesetofseeds.
uncovervaluableinsightsandoptimizeonlinedecisionmaking.
Similarly,fortheWeibodataset,IM-GNBdemonstratesitslargest
advantageatğ¿=4.Theseresultsvalidateourmotivationtoleverage
6 CONCLUSION
theexpressivityofbothneuralnetworksandbanditalgorithmsin
Insummary,ourIM-GNBframeworkseamlesslyleveragestheex-
IMcampaigns,enablingustoeffectivelycapturedynamicuser-user
pressivityofGNBstotacklethechallengesofmulti-roundIMin
anduser-influencerinteractionsusingGNBs.
uncertainenvironments.Ournovelapproachtackleskeyissuesin
Itisworthnotingthat,intheWeibodataset,particularlywhen
ğ¿ is small (e.g.,ğ¿ = 1,2), the performance in the initial rounds learningfromgraph-structureddataandmakessequentialdecisions
inuncertainenvironments.Byincorporatingcontextualbandits,InfluenceMaximizationviaGraphNeuralBandits KDDâ€™24,August25â€“29,2024,Barcelona,Spain
Figure2:ComparisonofIM-GNBwithbaselinesontheTwitterdataset.
Figure3:ComparisonofIM-GNBwithbaselinesontheWeibodataset.
weobtaininitialestimatesofdiffusionprobabilitiestoconstruct Acknowledgements. ThisworkisfundedbytheSingaporeMinistry
exploitationandexplorationgraphs.Subsequently,theseestimates ofEducationAcRFTier2(A-8000423-00-00).Thisresearchispart
arerefinedwithGCNs,toenhancetheinfluencespread.Theframe- of the programme DesCartes and is supported by the National
workâ€™sscalability,evenwithoutpriorknowledgeofthenetwork Research Foundation, Prime Ministerâ€™s Office, Singapore under
topology,makesitavaluableandversatiletoolforoptimizingdif- itsCampusforResearchExcellenceandTechnologicalEnterprise
fusioncampaigns. (CREATE)programme.TheauthorsthankFengzhuoZhangand
JunwenYang(bothNUS)forvaluablediscussions.KDDâ€™24,August25â€“29,2024,Barcelona,Spain Feng,Tan,andCautis
REFERENCES
[28] PaatRusmevichientongandJohnNTsitsiklis.2010. Linearlyparameterized
[1] NaokiAbe,AlanWBiermann,andPhilipMLong.2003.Reinforcementlearning bandits.MathematicsofOperationsResearch35,2(2010),395â€“411.
withimmediaterewardsandlinearhypotheses.Algorithmica37(2003),263â€“293. [29] LichaoSun,WeiranHuang,PhilipSYu,andWeiChen.2018. Multi-round
[2] Yikun an, Yuchen Yan, Arindam Banerjee, and Jingrui He. 2022. EE-Net: influencemaximization.InProceedingsofthe24thACMSIGKDDInternational
Exploitation-ExplorationNeuralNetworksinContextualBandits.InProceedings ConferenceonKnowledgeDiscovery&DataMining.2249â€“2258.
ofInternationalConferenceonLearningRepresentations. [30] YouzeTang,YanchenShi,andXiaokuiXiao.2015. InfluenceMaximization
[3] YikunBanandJingruiHe.2021. Localclusteringincontextualmulti-armed inNear-LinearTime:AMartingaleApproach.InProceedingsofthe2015ACM
bandits.InProceedingsoftheWebConference2021.2335â€“2346. SIGMODInternationalConferenceonManagementofData.1539â€“1554.
[4] YikunBan,JingruiHe,andCurtissBCook.2021.Multi-facetcontextualbandits: [31] YouzeTang,XiaokuiXiao,andYanchenShi.2014.Influencemaximization:Near-
Aneuralnetworkperspective.InProceedingsofthe27thACMSIGKDDConference optimaltimecomplexitymeetspracticalefficiency.InProceedingsofthe2014
onKnowledgeDiscovery&DataMining.35â€“45. ACMSIGMODInternationalConferenceonManagementofData.75â€“86.
[5] DavidMBlei,AndrewYNg,andMichaelIJordan.2003.LatentDirichletalloca- [32] MichalValko,NathanielKorda,RÃ©miMunos,IliasFlaounas,andNeloCristian-
tion.JournalofMachineLearningResearch3,Jan(2003),993â€“1022. ini.2013. Finite-timeanalysisofkernelisedcontextualbandits.InProc.ofthe
[6] ChristianBorgs,MichaelBrautbar,JenniferChayes,andBrendanLucier.2014. UncertaintyinArtificialIntelligence(UAI).
Maximizingsocialinfluenceinnearlyoptimaltime.InProceedingsoftheTwenty- [33] SharanVaswani,BranislavKveton,ZhengWen,MohammadGhavamzadeh,Laks
FifthAnnualACM-SIAMSymposiumonDiscreteAlgorithms.SIAM,946â€“957. V.S.Lakshmanan,andMarkSchmidt.2017.Model-IndependentOnlineLearn-
[7] SÃ©bastienBubeck,RÃ©miMunos,GillesStoltz,andCsabaSzepesvÃ¡ri.2011. X- ingforInfluenceMaximization.InProc.ofthe34thInternationalConferenceon
ArmedBandits.JournalofMachineLearningResearch12,5(2011). MachineLearning.3530â€“3539.
[8] WeiChu,LihongLi,LevReyzin,andRobertSchapire.2011.Contextualbandits [34] SharanVaswani,LaksLakshmanan,andMarkSchmidt.2015.Influencemaxi-
withlinearpayofffunctions.InProc.oftheFourteenthInternationalConference mizationwithbandits.arXivpreprintarXiv:1503.00024(2015).
onArtificialIntelligenceandStatistics.208â€“214. [35] ZhengWen,BranislavKveton,MichalValko,andSharanVaswani.2017.Online
[9] VarshaDani,ThomasPHayes,andShamMKakade.2008. Stochasticlinear influencemaximizationunderindependentcascademodelwithsemi-bandit
optimizationunderbanditfeedback.InProceedingsoftheConferenceonLearning feedback.AdvancesinNeuralInformationProcessingSystems30(2017).
Theory.355â€“366. [36] FelixWu,AmauriSouza,TianyiZhang,ChristopherFifty,TaoYu,andKilian
[10] PedroM.DomingosandMatthewRichardson.2001.Miningthenetworkvalue Weinberger.2019. Simplifyinggraphconvolutionalnetworks.InProc.ofthe
ofcustomers.InProceedingsoftheseventhACMSIGKDDinternationalconference InternationalConferenceonMachineLearning.PMLR,6861â€“6871.
onKnowledgediscoveryanddatamining,SanFrancisco,CA,USA,August26-29, [37] QingyunWu,ZhigeLi,HuazhengWang,WeiChen,andHongningWang.2019.
2001.57â€“66. Factorizationbanditsforonlineinfluencemaximization.InProceedingsofthe25th
[11] NanDu,LeSong,ManuelGomez-Rodriguez,andHongyuanZha.2013.Scalable ACMSIGKDDInternationalConferenceonKnowledgeDiscovery&DataMining.
influenceestimationincontinuous-timediffusionnetworks.InConferenceon 636â€“646.
NeuralInformationProcessingSystems.3147â€“3155. [38] TomZahavyandShieMannor.2020.Deepneurallinearbandits:Overcoming
[12] ShanshanFeng,GaoCong,ArijitKhan,XiuchengLi,YongLiu,andYeowMeng catastrophicforgettingthroughlikelihoodmatching.InInternationalConference
Chee.2018.Inf2vec:Latentrepresentationmodelforsocialinfluenceembedding. onLearningRepresentations.
In2018IEEE34thInternationalConferenceonDataEngineering(ICDE).IEEE, [39] JingZhang,BiaoLiu,JieTang,TingChen,andJuanziLi.2013.SocialInfluence
941â€“952. LocalityforModelingRetweetingBehaviors.InProc.oftheInternationalJoint
[13] ManuelGomez-RodriguezandBernhardSchÃ¶lkopf.2012.InfluenceMaximization ConferenceonArtificialIntelligence(IJCAI).
inContinuousTimeDiffusionNetworks.InProceedingsoftheInternational [40] WeitongZhang,DongruoZhou,LihongLi,andQuanquanGu.2021. Neural
ConferenceonMachineLearning. Thompsonsampling.InternationalConferenceonLearningRepresentation(2021).
[14] AmitGoyal,FrancescoBonchi,andLaksVSLakshmanan.2010.Learninginflu- [41] DongruoZhou,LihongLi,andQuanquanGu.2020.Neuralcontextualbandits
enceprobabilitiesinsocialnetworks.InProceedingsoftheThirdACMInternational withUCB-basedexploration.InProc.oftheInternationalConferenceonMachine
ConferenceonWebsearchandDataMining.241â€“250. Learning.11492â€“11502.
[15] AmitGoyal,FrancescoBonchi,andLaksVSLakshmanan.2011.AData-Based
ApproachtoSocialInfluenceMaximization.InProc.VLDBEndow.73â€“84.
[16] KekeHuang,SiboWang,GlennS.Bevilacqua,XiaokuiXiao,andLaksV.S.
Lakshmanan.2017.RevisitingtheStop-and-StareAlgorithmsforInfluenceMaxi-
mization.Proc.VLDBEndow.10,9(2017),913â€“924.
[17] AlexandraIacob,BogdanCautis,andSilviuManiu.2022.Contextualbanditsfor
advertisingcampaigns:Adiffusion-modelindependentapproach.InProceedings
ofthe2022SIAMInternationalConferenceonDataMining(SDM).SIAM,513â€“521.
[18] DavidKempe,JonKleinberg,andÃ‰vaTardos.2003.Maximizingthespreadof
influencethroughasocialnetwork.InProceedingsoftheNinthACMSIGKDD
InternationalConferenceonKnowledgeDiscoveryandDataMining.137â€“146.
[19] ThomasNKipfandMaxWelling.2016.Semi-supervisedclassificationwithgraph
convolutionalnetworks. InternationalConferenceonLearningRepresentations
(2016).
[20] PaulLagrÃ©e,OlivierCappÃ©,BogdanCautis,andSilviuManiu.2018.Algorithms
foronlineinfluencermarketing.ACMTransactionsonKnowledgeDiscoveryfrom
Data(TKDD)13,1(2018),1â€“30.
[21] TorLattimoreandCsabaSzepesvÃ¡ri.2020.BanditAlgorithms.CambridgeUni-
versityPress.
[22] YandiLi,HaoboGao,YunxuanGao,JianxiongGuo,andWeiliWu.2023.ASurvey
onInfluenceMaximization:FromanML-BasedCombinatorialOptimization.ACM
Trans.Knowl.Discov.Data17,9,Article133(Jul2023),50pages.
[23] HungTNguyen,MyTThai,andThangNDinh.2016.Stop-and-stare:Optimal
samplingalgorithmsforviralmarketinginbillion-scalenetworks.InProceedings
ofthe2016internationalconferenceonmanagementofdata.695â€“710.
[24] GeorgePanagopoulos,FragkiskosDMalliaros,andMichalisVazirgiannis.2020.
Multi-tasklearningforinfluenceestimationandmaximization.IEEETransactions
onKnowledgeandDataEngineering34,9(2020),4398â€“4409.
[25] JeffreyPennington,RichardSocher,andChristopherDManning.2014.Glove:
Globalvectorsforwordrepresentation.InProc.ofthe2014ConferenceonEmpirical
MethodsinNaturalLanguageProcessing(EMNLP).1532â€“1543.
[26] YunzheQi,YikunBan,andJingruiHe.2023.GraphNeuralBandits.InProceedings
ofthe29thACMSIGKDDConferenceonKnowledgeDiscoveryandDataMining.
1920â€“1931.
[27] CarlosRiquelme,GeorgeTucker,andJasperSnoek.2018.DeepBayesianbandits
showdown.InInternationalConferenceonLearningRepresentations,Vol.9.InfluenceMaximizationviaGraphNeuralBandits KDDâ€™24,August25â€“29,2024,Barcelona,Spain
A SUPPLEMENTARYCOMPLEXITY Theypertaintotheanalysisofthenumberofclusteringgroups
EXPERIMENTS andforartificiallyboostedexploration.
Fig.4showsthatthecampaignperformanceimprovesasthe
WeprovideinTable3acomparisononrunningtime(inhours)w.r.t.
thenumberofclusteringgroupsğ‘šâ€²whenğ¿=2.Wecanobserve numberofclustersincreasesfrom2to150atthebeginning.How-
ever,beyond200clusters,performancebeginstodecline.Thisde-
thatafinergranularity(moregroups)maynotresultinbetterper-
clinecanbelikelyattributedtoinsufficientdatawithineachcluster
formance(asshowninFig.4),whilecostgoesupexponentially.We
for effective learning under the constraints of a limited rounds
chose50groupsthatrepresentsagoodtradeoffbetweenaccuracy
budget.
andcomplexityinourexperiments.
Fig.5confirmstheeffectivenessofartificiallyaugmenting/boost-
ingtheexplorationscoreoftheunchosenarmswithzeroreward
Table3:Resultsforrunningtime.
outcomes,inordertoincreasethelikelihoodofexploringalterna-
tivearms.
ğ‘šâ€² 2 5 10 20 50 100 150 200 250
runningtime 5.35 7.02 9.71 12.35 41.43 125.49 225.67 391.54 735.35
B ANALYSISONTHENUMBEROF
CLUSTERINGGROUPSANDFOR
ARTIFICIALEXPLORATION
Twitter - L=2 - round=500
34000
33000
32000
31000
30000
2 5 10 20 50 100 150 200 250
#clusters
Figure4:Analysisonthenumberofclusteringgroups.
Twitter - L=2
explore
30000 non-artifical
artificial
25000
20000
15000
10000
5000
0
0 100 200 300 400 500
rounds
Figure5:Analysisonartificiallyboostedexploration.
Here,wepresenttheremainingfigures(Figs.4and5)thatwere
mentionedinthemaintextbutomittedduetospaceconsiderations.
daerps
evitalumuc
daerps
evitalumuc