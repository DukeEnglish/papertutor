Astructuredregressionapproachforevaluatingmodelperformanceacross
intersectionalsubgroups
CHRISTINEHERLIHYâˆ—,UniversityofMaryland,CollegePark,USA
KIMBERLYTRUONGâˆ—,OregonStateUniversity,USA
ALEXANDRACHOULDECHOVA,MicrosoftResearch,USA
MIROSLAVDUDÃK,MicrosoftResearch,USA
DisaggregatedevaluationisacentraltaskinAIfairnessassessment,withthegoaltomeasureanAIsystemâ€™sperformanceacrossdifferent
subgroupsdefinedbycombinationsofdemographicorothersensitiveattributes.Thestandardapproachistostratifytheevaluationdata
acrosssubgroupsandcomputeperformancemetricsseparatelyforeachgroup.However,evenformoderately-sizedevaluationdatasets,
samplesizesquicklygetsmallonceconsideringintersectionalsubgroups,whichgreatlylimitstheextenttowhichintersectional
groupsareconsideredinmanydisaggregatedevaluations.Inthiswork,weintroduceastructuredregressionapproachtodisaggregated
evaluationthatwedemonstratecanyieldreliablesystemperformanceestimatesevenforverysmallsubgroups.Wealsoprovide
correspondinginferencestrategiesforconstructingconfidenceintervalsandexplorehowgoodness-of-fittestingcanyieldinsight
intothestructureoffairness-relatedharmsexperiencedbyintersectionalgroups.Weevaluateourapproachontwopubliclyavailable
datasets,andseveralvariantsofsemi-syntheticdata.Theresultsshowthatourmethodisconsiderablymoreaccuratethanthestandard
approach,especiallyforsmallsubgroups,andgoodness-of-fittestinghelpsidentifythekeyfactorsthatdrivedifferencesinperformance.
1 INTRODUCTION
AcoretaskwhenassessingthefairnessofanAIsystemismeasuringitsperformanceacrossdifferentsubgroupsdefined
bycombinationsofdemographicorothersensitiveattributes.Manyofthebest-knownstudiesofalgorithmicbiasare
groundedinthistypeofanalysis.ThisincludestheBuolamwiniandGebruâ€™sGenderShadesstudy[5],whichfound
thatcommercialgenderclassifiershavemuchhighererrorratesfordarker-skinnedwomenthanothergroups,and
theObermeyeretal.â€™sstudy[27]findingbiasincommercialalgorithmsusedtoguidehealth-caredecisions,aswell
asmanyothers[1,14,22,32].
Intheirworkformalizingthistypeofanalysis,Barocasetal.[3]introducethetermdisaggregatedevaluationto
refertothistask.Theauthorsdrawattentiontothemanydecisionsthatoftenimplicitlygointoshapinganygiven
disaggregatedevaluation:fromwhowillbeinvolved,towhatdatawillbeused,tothestatisticalapproachtaken,to
drawinginferencesfromthedata.Inourwork,wefocusonthequestionofstatisticalmethodologygivenanavailable
datasetandpre-determinedsubgroupsandperformancemetricsofinterest.Specifically,weintroduceamethodfor
estimatingperformanceacrosssubgroupsthatweshow(i)ismoreaccuratethanapproachestakeninstandardpractice;
and(ii)canprovidegreaterinsightintowhichfactorsdriveobservedvariationinperformance.
Theâ€œstandardapproachâ€todisaggregatedevaluationproceedsbystratifyingtheevaluationdataacrosssubgroups
andthenconductinginference(i.e.,computingperformancemetrics,confidenceintervals,orotherstatistics)separately
foreachgroup.Theprimarychallengewhenapplyingthisapproacharesmallsamplesizes.Evenformoderately-sized
evaluationdatasets,samplesizesquicklygetsmallonceconsideringintersectionalsubgroups.Forinstance,inamedical
diabetesmellitusdatasetweuselaterinthepaper,wehavea5000-patientevaluationdataset,ofwhich2689patients
âˆ—Bothauthorscontributedequallytothisresearch.
Authorsâ€™addresses:ChristineHerlihy,cherlihy@umd.edu,UniversityofMaryland,CollegePark,USA;KimberlyTruong,truonkim@oregonstate.edu,
OregonStateUniversity,USA;AlexandraChouldechova,alexandrac@microsoft.com,MicrosoftResearch,USA;MiroslavDudÃ­k,mdudik@microsoft.com,
MicrosoftResearch,USA.
4202
naJ
62
]GL.sc[
1v39841.1042:viXra2 ChristineHerlihy,KimberlyTruong,AlexandraChouldechova,andMiroslavDudÃ­k
arefemale,620arefemaleandoverage80,butonly6arefemale,overage80,andHispanic.Indeed,ofthe32distinct
gender-age-race/ethnicitysubgroupsthatcanbeformedinthedata,8(i.e.,25%)havefewerthan10observations,and
nearlyhalfhavefewerthan25observations.Inferencebasedonsofewobservationsisoftenuninformative,andmay
beunreliable.Inpractice,subgroupsthataretoosmalltendtobeeitherexcludedfromanalysisormergedwithother
smallbutpotentiallyheterogeneoussubgroupstoformhigher-levelâ€œcatch-allâ€categories(e.g.,â€œotherâ€).Thesepractices
greatlylimittheextenttowhichintersectionalgroupsareevenconsideredinmanydisaggregatedevaluations.As
aconsequence,standardassessmentsmayfailtosurfacefairness-relatedharmsthatcoulddisproportionatelyaffect
intersectionalsubgroups[7],whichinturnmeansthatstepstomitigatethoseharmswillnotbetaken.
In this work, we introduce a structured regression approach to disaggregated evaluation that we demonstrate
can yield reliable system performance estimates even for very small subgroups (e.g., for groups with fewer than
25observations).Wealsoprovidecorrespondinginferencestrategiesforconstructingconfidenceintervalsforthe
subgroup-levelperformanceestimates.Wethendemonstratehowgoodness-of-fittestingcanprovideinsightintothe
structureoffairness-relatedharmsexperiencedbyintersectionalgroupsandalsoidentifysituationswhereobserved
variationinperformanceisattributabletobenignfactors.Lastly,wepresentresultsontwopubliclyavailabledatasets,
andseveralvariantsofsemi-syntheticdata.Theresultsshowthatourmethodisconsiderablymoreaccuratethanthe
standardapproach,especiallyforsmallsubgroups.Theyfurthershowthatourmethodoutperformsmorestatistically
sophisticatedbaselines,includingthemodel-basedmetricsmethodintroducedbyMilleretal.[25],whilealsooffering
additionaladvantages.Weconcludebydiscussinglimitationsandfuturedirections.
2 BACKGROUNDANDRELATEDWORK
Intheirtaxonomyofsociotechnicalharmsofalgorithmicsystems,Shelbyetal.[29]identifyfivehigh-levelcategories
ofharm:representational,allocative,qualityofservice,interpersonal,andsocialsystem.Ourworkcontributestothe
broaderliteraturecharacterizingandassessingallocativeandquality-of-serviceharmsthatcanresultfromtheuseof
algorithmicsystems.Allocativeharms,firstdiscussedbyBarocasetal.[2],occurwhensystemsproduceaninequitable
distributionofinformation,opportunity,orresourcesacrossgroups.Asarunningexample,weconsiderahypothetical
settinginwhichamodeltrainedtopredict30-dayhospitalreadmissionisusedtoprioritizehigh-riskpatientsfor
moreintensivepost-dischargecare.Allocativeharmsmightoccurinthissettingifcertainsubgroupsofpatientsare
disproportionatelyunder-prioritizedformoreintensivecare(i.e.,havelowselectionrates)orareunder-selectedrelative
totheirobservedrateofreadmission(i.e.,havehighfalsenegativerates).
Quality-of-serviceharmsoccurwhenalgorithmicsystemsunderperformforcertainsociallysalientgroupsofusers[29,
37].Weexaminequality-of-serviceharmsacrossraceandgendergroupsinthecontextofcommercialautomatedspeech
recognition(ASR)systemsusingdatapreviouslyanalysedbyKoeneckeetal.[22].Specifically,weassesswhetherthere
issignificantvariationintheworderrorrate(WER)oftheASRsystemsacrossintersectionalraceandgendersubgroups.
Thetermâ€œintersectionalityâ€wasintroducedbyCrenshaw[7]todescribethedistinctpatternsofdiscrimination
anddisadvantageexperiencedbyBlackwomen,whichshearguedcannotbeunderstoodintermsofraceorgender
discrimination alone. In recent years, algorithmic fairness research has examined intersectional bias from many
perspectives.Thisincludesworkintroducingquantitativemetricsintendedtocapturenotionsofintersectionalfairness,
suchassubgroupfairness[21],differentialfairness[11,12],andmulti-calibration[15],alongwithlearningalgorithms
for estimating and achieving these criteria. Wang et al. [36] study â€œpredictivity differencesâ€ across intersectional
subgroups,anddiscusslimitationsofexistingsummarystatistics(suchasthemaximumdisparityacrossallgroups)in
capturingmeaningfulnotionsofintersectionalharm.Ourworkdiffersfromthisliteraturebecausewearespecifically3
interestedinthetaskofdisaggregatedevaluation.Thisentailsestimatingandreportingsystemperformanceforeach
intersectionalsubgroup,ratherthancomputingaparticularfairnessmetricorlearningafairness-constrainedmodel.
Ourworkmostdirectlycontributestothegrowingliteratureintroducingmoresample-efficientmethodsforcon-
ductingdisaggregatedevaluations.Thisliteratureincludesmethodsthatleverageunlabelleddatainmodelevaluation
[6,19,20];methodsthatboundorapproximateperformanceforintersectionalsubgroupsusingmarginalstatistics[26];
andsyntheticdataaugmentationapproaches[34].Inworkmorecloselyrelatedtothespiritofourstructuredregression
approach,Piratlaetal.[28]introducetheAttributedAccuracyAssay(AAA)method,whichmodelstheaccuracyofa
modelasafunctionofsensitiveattributesandotherfeaturesviaaGaussianProcess(GP).WhilewedonotrelyonGPs,
wedoproceedsimilarlybymodelingtheaccuracy(orerror)ofagivenmodel.Whereaswearespecificallyconcerned
withfairnessanddisaggregatedevaluation,Piratlaetal.[28]aimtoproduceanâ€œaccuracysurfaceâ€modelthatclients
canusetoestimatetheperformanceofanexistingmodelontheirdata.
ThemostcloselyrelatedworkinrecentliteratureisthatofMilleretal.[25],whointroduceaBayesianstructuredre-
gressionapproachthattheycallmodel-basedmetrics(MBM).TheirmethodappliestoAImodelsthatproduceascore(say
topredictariskofhospitalreadmission).Bymodelingthedistributionofscoresgivenselectfeaturesandtheobservedout-
come,theyareabletomakeinferenceonanyperformancemetricofinterest,buttheapproachisnotdirectlyapplicableto
theevaluationofmodelsthatdonotproduceclassificationscores(e.g.,MBMdoesnotdirectlyapplytotheevaluationof
WERinASRsystems).UnliketheMBMapproach,wemodelthetargetmetricdirectlyandfitseparatemodelsforeachper-
formancemetricofinterest.OurexperimentsshowthatourmethodyieldsmoreaccurateestimatesthanMBM(seeÂ§5.1).
Ourapproachisalsorelatedtotheclassicallineofresearchonnormalmeansestimation,originatingwiththe
James-Stein(JS)estimator[16,30].TheJSestimatorworksbyshrinkingstandardestimatestowardszero(orsome
otherconstant),whichleadstoasubstantialdecreaseinvariance,whileonlyamoderateincreaseinbias.Thisfavorable
biasâ€“variancetrade-offinturnleadstoamoreaccurateestimator.TheempiricalBayes(EB)approach[8]alsoleadsto
aformofshrinkage,butitsmotivationisdifferent.ItpositsahierarchicalBayesianmodelandestimatesmetricvalues
byposteriormeans,whilefixingpriorhyperparameterstotheirpointestimates.Ourestimatorworksbyoptimizing
biasâ€“variancetrade-offsimilartoJS,butitenjoysadditionaladvantagescomparedwithJSandEB:availabilityof
confidenceintervalproceduresandflexibilitytoincorporateinformationintheformofcovariates.Inourexperiments
weshowthatourapproachmatchesandsometimesoutperformsJSandEB(seeÂ§5.1).
Manyimportantchallengeslieoutsidethescopeofthispaper.Wefocusonimprovingaccuracyofdisaggregated
evaluation,especiallyonsmallgroups,assumingthatrelevantsensitiveattributesandperformancemetricshavebeen
determinedandasuitableevaluationdatasetcollected.However,manykeysociotechnicalchallengesariseduringthe
evaluationconceptionanddatasetconstructionphases[3,24].Forinstance,asBarocasetal.[3]discuss,thesensitive
attributesoftenincludesociallyconstructedâ€”andpotentiallycontestedâ€”features(likeraceandgender),whichmakes
thetaskofmappingpeopletoattributesandcorrespondingsubgroupspotentiallyfraught,particularlywhenitinvolves
inferenceoruseofproxyvariables,orposesariskformembersofalready-marginalizedsubgroups.Anotherset
ofchallengesariseswhendecidingonaperformancemetric.Inmanyhigh-stakesapplications(likeeducationand
health-care),wearenotabletodirectlymeasurewhomightbenefit,soweneedtorelyonproxies.Thisstepiscritical,
sinceapoorchoiceofaproxymayfurtherexacerbateexistinginequities,asisthecase,forinstance,whenpredicting
riskofre-offensefromarrestrecords[10]orpredictinghealth-careneedsbasedonhealth-careexpenditures[27].4 ChristineHerlihy,KimberlyTruong,AlexandraChouldechova,andMiroslavDudÃ­k
3 PROBLEMSETTING
Wewouldliketoassessthefairness-relatedharmsofanAIsystembyevaluatingitsperformanceonintersectional
subgroupsofusersspecifiedbyğ‘˜ â‰¥2sensitiveattributes(likeraceandgender),takingvaluesinfinitesetsA1,...,Ağ‘˜.
Thesetofallpossibleğ‘˜-tuplesofsensitive-attributevaluesisdenotedA=A1Ã—Â·Â·Â·Ã—Ağ‘˜.
Weassumethatwehaveaccesstoanevaluationdatasetğ‘†,consistingofindividualsdescribedbytuplesoftheform
(ğ‘‹,ğ´,ğ‘Œ,ğ‘ŒË† )sampledi.i.d.fromsomeunderlyingdistributionD,whereğ‘‹ containsapplication-relevantinformation
abouttheindividual(e.g.,thehealthhistoryofapatient),ğ´âˆˆAisağ‘˜-tupleofsensitiveattributes,ğ‘Œ isanobserved
outcomevariable(e.g.,whetherthepatientwasreadmittedwithin30daysofdischarge),andğ‘ŒË† isanoutputproduced
bytheAIsystem(e.g.,ascoreusedforprioritizingpatientsintopost-dischargecare).
Foranyğ‘˜-tupleğ‘âˆˆA,wewriteğ‘[1],...,ğ‘[ğ‘˜]todenoteitscomponents.IntheASRexamplebelow,weconsider
twosensitiveattributes,raceandgender,withdomainsA1={Black,white}andA2={male,female}.Inthatcase,for
example,ifğ‘=(Black,female),thenğ‘[1] =Blackandğ‘[2] =female.Whenpossible,weusemnemonicindicesforcom-
ponentsofğ‘andwriteğ‘[race]andğ‘[gender]tomeanğ‘[1]andğ‘[2],andsimilarlyA raceandA gendertomeanA1andA2.
Foreachğ‘âˆˆA,wedefineDğ‘tobethedistributionofindividualswithğ´=ğ‘,soDğ‘istheconditionaldistribution
D(ğ‘‹,ğ´,ğ‘Œ,ğ‘ŒË† |ğ´=ğ‘),representinganintersectionalgroup.LetÎ”denotethesetofallprobabilitydistributionsover
tuples(ğ‘‹,ğ´,ğ‘Œ,ğ‘ŒË† ),soD âˆˆÎ”andalsoDğ‘ âˆˆÎ”forallğ‘âˆˆA.Aperformancemetricisafunctionğ‘š:Î”â†’Rthatmapsa
probabilitydistributionovertuples(ğ‘‹,ğ´,ğ‘Œ,ğ‘ŒË† )intoarealnumber.Forexample,iftheunderlyingAIsystemperforms
binaryclassification,soğ‘Œ,ğ‘ŒË† âˆˆ{0,1},wecouldmeasureitsperformanceusingaccuracy,defined,foranyğ‘ âˆˆÎ”,as
ACC(ğ‘)=P ğ‘[ğ‘Œ =ğ‘ŒË† ],
whereP ğ‘[Â·] istheprobabilityofaneventwithrespecttoğ‘.Theoverallsystemperformanceisthenquantifiedby
ACC(D)andtheperformanceonthegroupğ‘âˆˆAbyACC(Dğ‘).
Givenaperformancemetricğ‘š,thegoalofdisaggregatedevaluationistoestimatethevaluesğ‘š(Dğ‘)forallğ‘âˆˆA.
Wedenotethesevaluesas
ğœ‡
ğ‘
=ğ‘š(Dğ‘).
OuronlysourceofinformationaboutD istheevaluationdatasetğ‘† ofsizeğ‘› = |ğ‘†|,sampledi.i.d.fromD.The
standardapproachtodisaggregatedevaluationsplitsthedatasetğ‘†intogroups
ğ‘† ğ‘ =(cid:8) (ğ‘‹,ğ´,ğ‘Œ,ğ‘ŒË† ) âˆˆğ‘† : ğ´=ğ‘(cid:9)
ofsizeğ‘›
ğ‘
=|ğ‘† ğ‘|,andthenevaluatesğ‘šoneachğ‘† ğ‘(or,moreprecisely,ontheprobabilitydistributionthatputsanequal
probabilitymassoneachdatapointinğ‘† ğ‘).Wedenotetheresultingstandardestimatesas
ğ‘
ğ‘
=ğ‘š(ğ‘† ğ‘). (1)
Forexample,ifğ‘šisaccuracy,then
ğ‘ ğ‘ =ACC(ğ‘† ğ‘)= 1 âˆ‘ï¸ 1{ğ‘Œ =ğ‘ŒË† },
ğ‘›
ğ‘
(ğ‘‹,ğ´,ğ‘Œ,ğ‘ŒË†)âˆˆğ‘†ğ‘
where1{Â·}isanindicatorequalto1ifitsargumentistrueand0ifitisfalse.
WenextconnectthisabstractframeworktotwoconcretescenariosalreadymentionedinÂ§2.
Example1(Diabetes). WeconsideranAIsystemthatrefershigh-riskpatientsintoapost-dischargecareprogram.
Wewishtoassesstheallocativeharmsofthissystem.Toexplorethisscenario,weuseapubliclyavailabledataset5
ofdiabetespatientsdevelopedbyStracketal.[31].Thedatasetcontainsinformationaboutpatienthospitalvisits,
includingwhethereachpatientwasreadmittedwithin30daysafterdischarge.Weusethereadmissionasaproxyfor
whetherthepatientshouldberecommendedforthecareprogram.
Eachdatapointcorrespondstoapatientadmission,whereğ‘‹ describesthepatienthistoryandhospitaltests;ğ´
describesthepatientâ€™srace,gender,and(binned)age;ğ‘Œ âˆˆ{0,1}indicateswhetherthepatientwasreadmittedwithin
30daysafterdischarge;andğ‘ŒË† âˆˆ [0,1]isthescoreproducedbytheAIsystemthathasbeentrainedtopredictğ‘Œ.We
assumethatthehospitalusesathresholdğ‘Ÿ,andpatientswithğ‘ŒË† â‰¥ğ‘Ÿ areautomaticallyreferredintothecareprogram.
Onetypeofallocativeharmoccurswhenasubgroupofpatientsisdisproportionatelyunder-prioritized,i.e.,ifa
subgrouphasalowselectionrate,denotedas
SEL(Dğ‘)=P Dğ‘[ğ‘ŒË† â‰¥ğ‘Ÿ].
Wealsoconsiderasecondtypeofharm,whichoccurswhenasubgroupofpatientsexperiencesadisproportionately
largerateoffalsenegatives(i.e.,manyofthosepatientsthatshouldberecommendedarenot),measuredbythefalse
negativerate
FNR(Dğ‘)=P Dğ‘[ğ‘ŒË† <ğ‘Ÿ |ğ‘Œ =1].
Example2(ASR). Toassessquality-of-serviceharmsofanASRsystem,weuseadatasetfromKoeneckeetal.[22],
consistingofaudiosnippets(oflengthbetween5sand50s)spokenbyvariousspeakers.Inthedataset,ğ‘‹ describes
propertiesofthesnippet(likedurationinseconds),ğ´hastwocomponentscorrespondingtothespeakerâ€™sraceand
gender,ğ‘Œ istheground-truthtranscriptionofthesnippet,andğ‘ŒË† isthetranscriptionprovidedbytheAIsystem.
Thequality-of-serviceharmsoccurwhenthesystemunderperformsforasubgroupofusers.Theperformanceis
evaluatedbytheworderrorrate
WER(Dğ‘)=E Dğ‘[wer(ğ‘ŒË†,ğ‘Œ)],
wherewerisasnippet-levelworderrorratedefinedas
wer(ğ‘ŒË†,ğ‘Œ)= subst+del+ins ,
|ğ‘Œ|
wheresubst,del,andinsisthenumberofwordsubstitutions,deletions,andinsertionsinğ‘ŒË† comparedwiththeground
truthğ‘Œ,and|ğ‘Œ|isthenumberofwordsinğ‘Œ.
Toquantifytheaccuracyofanestimator,likethestandardestimatorintroducedabove,weoftenusemeansquared
error (MSE).WewilluseamodifieddefinitionofMSEthataccountsforthefactthatestimateslikeğ‘ ğ‘ =ğ‘š(ğ‘† ğ‘)are
sometimesundefined,forinstance,whenthemetricğ‘šisdefinedasaconditionalprobability,likeFNRinExample1,and
thesetğ‘† ğ‘hasnosamplesthatsatisfythecondition(e.g.,nosampleswithğ‘Œ =1incaseofFNR).Foranestimatorğœ‡Ë†ofa
quantityğœ‡,letEdenotetheeventthatğœ‡Ë†isdefined.Thebias,variance,andmeansquarederror(MSE)ofğœ‡Ë†aredefinedas
Bias(ğœ‡Ë†)=E[ğœ‡Ë† | E]âˆ’ğœ‡, Var(ğœ‡Ë†)=E(cid:2)(cid:0)ğœ‡Ë†âˆ’E[ğœ‡Ë† | E](cid:1)2(cid:12) (cid:12)E(cid:3), MSE(ğœ‡Ë†)=E(cid:2)(cid:0)ğœ‡Ë†âˆ’ğœ‡(cid:1)2(cid:12) (cid:12)E(cid:3), (2)
wheretheexpectationsarewithrespecttothedata-generatingprocessgivingrisetothedatasetusedtocalculateğœ‡Ë†
(whichisitselfarandomvariable).Anestimatorwithbiasequaltozeroiscalledunbiased.
Meansquarederrordecomposesintobiasandvariancetermsas
MSE(ğœ‡Ë†)=
(cid:2)Bias(ğœ‡Ë†)(cid:3)2
+Var(ğœ‡Ë†), (3)
soforunbiasedestimators,meansquarederrorisequaltovariance.6 ChristineHerlihy,KimberlyTruong,AlexandraChouldechova,andMiroslavDudÃ­k
1.0 method
standard
0.5 MBM
structured
regression
0.0
truth
1.0
0.5
0.0
2 3 3 5 5 6 6 9 15 18 19 20 21 23 27 28 31 34 58 66 80 94153157202244330432482525946956 group size
groups
(race: AA=African American, Wh=white, H=Hispanic, oth=other;
age: 20-39, 40-59, 60-79, 80-99; gender: M=male, F=female)
Fig.1. Pointestimatesand95%confidenceintervalsofselectionrate(SEL)andfalsenegativerate(FNR)ondiabetesdata.Confidence
intervalsofthestandardestimatorarecalculatedusingpooledvariance(seeEq.7).
Throughoutthepaper,weassumethatthestandardestimatesğ‘ areunbiased.Writingthisconditionintermsofthe
ğ‘
metricğ‘š,weassumethatforallD âˆˆÎ”andallğ‘› â‰¥1,theperformancemetricğ‘šsatisfies
E ğ‘†âˆ¼Dğ‘›[ğ‘š(ğ‘†) |ğ‘š(ğ‘†)isdefined] =ğ‘š(D), (4)
which is true for all the metrics in this paper. Substituting Dğ‘ for D andğ‘› ğ‘ forğ‘› in Eq. (4) implies that E[ğ‘ ğ‘ |
ğ‘ ğ‘isdefined] = ğœ‡ ğ‘.Intherestofthepaperwedropconditioningontheeventslikeâ€œğ‘ ğ‘ isdefined,â€andjustwrite
E[ğ‘ ğ‘] =ğœ‡ ğ‘forsimplicity.
Sincethestandardestimatesğ‘ ğ‘areunbiased,theirMSEisequaltotheirvariance,whichtypicallyscalesasğ‘‚(1/ğ‘› ğ‘).
Thus,standardestimatesareaccuratewhenğ‘› islarge,butlessaccuratewhenğ‘› issmall.Unfortunately,evenfor
ğ‘ ğ‘
moderatelysizedevaluationdatasets,thesizesofintersectionalgroupscanbequitesmall.InFigure1,weshowstandard
estimatesofSELandFNRondiabetesdata(alongsideestimatesproducedbymethodsintroducedlaterinthepaper).
Althoughtheevaluationdatasethas5000datapoints,theintersectionalgroupsareassmallassize2,andalmosthalfof
thegroupsareofsizelessthan25,leadingtosubstantialerrorsinthestandardestimates.
4 STRUCTUREDREGRESSIONAPPROACH
Wenextdevelopastructuredregression(SR)approach,whichseekstoovercomethemainshortcomingofthestandardes-
timator:itslargevarianceforsmallgroups.Ourapproachbuildsontwomainideas.First,weleverageinformationacross
alldatapoints,notjustdatapointsinğ‘† ğ‘,toestimateğœ‡ ğ‘,bypoolingthedataacrossrelatedgroups,forexample,across
intersectionalgroupsthatagreeinoneoftheirattributes(likeage),andbyusingadditionalexplanatoryvariables(likeğ‘‹).
Thisisaccomplishedbyfittingaregressionmodelforğœ‡ s,withğ‘ sviewedasobservations.Second,wemaketheregres-
ğ‘ ğ‘
sionmodelsufficientlyexpressive,sothatitcanexpressstandardestimates.Regularizationisusedtooptimizethebiasâ€“
variancetrade-offbetweenthehigh-variancestandardestimatorandahigh-bias(butlow-variance)constantestimator.
Tostart,sincethestandardestimatesareunbiased,thatis,E[ğ‘ ğ‘] =ğœ‡ ğ‘,wecanwrite
ğ‘
ğ‘
=ğœ‡ ğ‘+ğœ€
ğ‘
setamitse
LES
setamitse
RNF
M
93-02
hto
F
93-02
hto
M
99-08
H
M
99-08
hto
M
93-02
H
F
93-02
H
F
99-08
H
F
99-08
hto
F
95-04
hto
M
95-04
H
F
95-04
H
M
95-04
hto
M
08-06
H
F
08-06
H
F
08-06
hto
M
08-06
hto
M
99-08
AA
M
93-02
AA
F
93-02
AA
M
93-02
hW
F
99-08
AA
F
93-02
hW
M
95-04
AA
M
08-06
AA
F
95-04
AA
F
08-06
AA
M
99-08
hW
F
95-04
hW
M
95-04
hW
F
99-08
hW
F
08-06
hW
M
08-06
hW7
for all ğ‘ âˆˆ A, where ğœ€ ğ‘â€™s are independent random variables with E[ğœ€ ğ‘] = 0. We denote the variance of ğ‘ ğ‘ as
ğœ ğ‘2 =Var(ğ‘ ğ‘)=E[ğœ€ ğ‘2].Inordertoestimateğœ‡ ğ‘,weconsideralinearmodeloftheform
ğœ‡
ğ‘
=ğœƒ0+ğœ½ Â·ğ“ğ‘
forallğ‘âˆˆA,whereğ“ğ‘ âˆˆRğ‘‘ isthefeaturevectordescribingthegroupğ‘,andğœƒ0 âˆˆR,ğœ½ âˆˆRğ‘‘ aretheparametersofthe
linearmodel.Itremainstospecifyhowtodefineğ“ğ‘,howtofittheparametersğœƒ0andğœ½,andhowtoestimateğœ ğ‘.
Definingfeaturevectorsğ“ğ‘ . Thecoordinatesofğ“ğ‘arereferredtoasfeaturesanddenotedasğœ™ğ‘ ğ‘— forğ‘—fromsomesuitable
indexset.Weallowfeaturestobelinearlydependent.Weconsiderthefollowingtypesoffeatures:
(1) Sensitivefeatures.Thesearederiveddirectlyfromğ‘.Wealwaysincludegroup-identityindicatorsforallthe
groupsğ‘â€² âˆˆ A,yieldingfeaturesoftheformğœ™ğ‘ = 1{ğ‘ =ğ‘â€²}.Thisallowsthelinearmodeltoexpressany
ğ‘â€²
combinationofvaluesğœ‡ .Additionally,inordertopoolinformationacrossrelatedgroups,wealsodefine
ğ‘
indicatorsforindividualattributevalues,thatis,featuresoftheformğœ™ ğ‘–ğ‘
,ğ‘£
=1{ğ‘[ğ‘–] =ğ‘£}forğ‘– âˆˆ{1,...,ğ‘˜}and
ğ‘£ âˆˆ Ağ‘–.Inourdiabetesexample,therearethreesensitiveattributes:race,age,andgender,with|A race| =4,
|A |=4,and|A |=2,so|A|=4Â·4Â·2=32.Weuseatotalof42sensitivefeatures:32group-identity
age gender
indicators,4indicatorsofrace,4indicatorsofage,and2indicatorsofgender.Anexampleofagroup-identity
indicatorisğœ™ğ‘ andanexampleofasensitive-attributeindicatorisğœ™ğ‘ .
(Hispanic,80â€“99,female) race,Hispanic
(2) Explanatoryfeatures.Thesearederivedfromğ‘‹,ğ‘Œ,andpossiblyğ‘ŒË†.Wefirstfeaturizeğ‘‹ usingsomereal-valued
functionsğ‘“ ğ‘—(ğ‘‹),ğ‘— =1,...,â„“,andthendefineexplanatoryfeaturesğœ™ğ‘
ğ‘—
=E ğ‘‹âˆ¼ğ‘†ğ‘[ğ‘“ ğ‘—(ğ‘‹)].Additionally,whenğ‘Œ is
categorical,wedefinefeaturesğœ™ğ‘
ğ‘¦
=P ğ‘Œâˆ¼ğ‘†ğ‘[ğ‘Œ =ğ‘¦]measuringratesofdifferentoutcomesinthegroupğ‘.In
ourdiabetesexample,weuse7explanatoryfeatures:5arederivedfromindividual-levelfeaturesğ‘“ ,including,
ğ‘—
forexample,thenumberofinpatientdaysofagivenpatientintheprioryear;andthereare2featuresğœ™ğ‘
ğ‘¦
correspondingto2possiblevaluesofğ‘Œ.
(3) Interactionterms.Finally,itisalsopossibletoconsidervariousinteractionterms,bothamongfeaturesofthe
sametype(suchasinteractionsbetweengender andageindicators),orofdifferenttypes(likeinteractions
betweentheoutcomeğ‘Œ andage).
Fittingthelinearmodel. Wefit(ğœƒ0,ğœ½)bylassoregression[33],minimizinganâ„“1-penalizedsquareloss.Toimprovethe
statisticalefficiencyoftheestimator,lossforeachgroupğ‘isweightedinverselyproportionaltothevarianceofğ‘ .
ğ‘
Intuitively,sinceourmodelcanexpresstrueğœ‡ ,weexpectthesquarelossoneachgrouptobeontheorderofthe
ğ‘
varianceofğ‘ ,soinverseweightingâ€œequalizesthescaleâ€oflossesacrossgroups.Thepenalizedlossisthen
ğ‘
ğ¿ ğœ†(ğœƒ0,ğœ½)= âˆ‘ï¸ ğœ1 2(cid:16) ğœƒ0+ğœ½ Â·ğ“ğ‘ âˆ’ğ‘ ğ‘(cid:17)2 +ğœ†âˆ¥ğœ½âˆ¥1, (5)
ğ‘âˆˆA ğ‘
whereğœ†istheregularizationhyperparameter.Denotingtheminimizerofğ¿
ğœ†
(foragivenğœ†)as(ğœƒË† 0,ğœ½Ë†),weobtainthe
estimatesğœ‡Ë†
ğ‘
=ğœƒË† 0+ğœ½Ë†Â·ğ“ğ‘.
Tuningğœ†allowsustonavigatethebiasâ€“variancetradeoff.Whenğœ†=0,thelossisminimizedbyğœ‡Ë†
ğ‘
=ğ‘ ğ‘,whichcan
alwaysbeexpressedbysuitableğœƒË† 0andğœ½Ë†,becausesensitivefeaturesincludeindicatorsofallvaluesğ‘âˆˆA.Asğœ†â†’âˆ,
theoptimizationreturnsğœ½Ë† â‰ˆ0.Fixingğœ½Ë† =0andoptimizingonlyovertheintercepttermyieldstheconstantsolution
ğœ‡Ë† ğ‘ =ğœ‡Ë† 0, with ğœ‡Ë† 0= (cid:205) (cid:205)ğ‘ ğ‘âˆˆ âˆˆA Ağ‘ 1ğ‘ // ğœğœ ğ‘2ğ‘2 ,8 ChristineHerlihy,KimberlyTruong,AlexandraChouldechova,andMiroslavDudÃ­k
across all groups across small groups across large groups
0.008 0.015 0.0015 bias2
0.006 variance
0.010 0.0010 MSE
0.004
0.002 0.005 0.0005
0.000 0.000 0.0000
102 101 100 101 102 101 100 101 102 101 100 101
regularization parameter regularization parameter regularization parameter
Fig.2. Biasâ€“variancetrade-offofstructuredregressionestimatesofselectionrate(SEL)ondiabetesdata.Averagedacrossallgroups,small
groups(sizeatmost25),andlargegroups(sizeabove25),across100drawsofevaluationdataset.ThescaleoftheMSEisdifferent
fordifferentgroupsizes,buttheminimumMSEisattainedaroundthesamevalueofğœ†,thankstotheweightingofthetrainingloss.
correspondingtoaweightedaverageofğ‘ s.Thissolutionhasasmallvariance,butitmaysufferfromalargebias
ğ‘
whenthetruevaluesğœ‡ arefarfromidentical.Bytuningğœ†,wethusmovefromthestandardestimatetotheconstant
ğ‘
estimate,decreasingthevariancewhileincreasingthebias.Themeansquarederroristypicallyminimizedatsome
intermediatevalueofğœ†(seeFigure2).Wetuneğœ†by10-foldcross-validation,wheretheindividualfoldsareobtainedby
stratifiedsamplingofthedatasetğ‘†withrespecttothesensitiveattributetupleğ´.
Estimatingvarianceğœ ğ‘2 . Variancesğœ ğ‘2areneededtodetermineweightsinouroptimizationprocedure.Asimpleapproach
is to estimateğœ2 separately on each datasetğ‘† by using standard variance estimators (when available), or, more
ğ‘ ğ‘
generically,bybootstrap.Unfortunately,forsmallsamplesizes,thesevarianceestimatesthemselvesmightbeinaccurate.
Toovercomethislimitation,wepositaparametricmodelforvariance,namely,ğœ ğ‘2 =ğœ2/ğ‘› ğ‘,forsomeparameterğœ.
Toestimateğœ,weproceedintwostages.Wefirstusebootstraponeachsetğ‘† toobtaintheinitialestimateofğœ2,which
ğ‘ ğ‘
wedenote(ğœË† ğ‘boot)2.Thus,ğ‘› ğ‘(ğœË† ğ‘boot)2istheinitialestimateofğœ2.Weexpectthevarianceofthisestimatetobeonthe
orderğ‘‚(1/ğ‘› ğ‘).Takingaweightedaverageacrossgroups,withweightinginverselyproportionalto(1/ğ‘› ğ‘),yieldsour
finalestimatorofğœ2,whichtranslatesintoanestimatorofğœ2:
ğ‘
ğœË†2 =
(cid:205) ğ‘âˆˆAğ‘› (cid:205)ğ‘Â·(cid:2)ğ‘›
ğ‘
ğ‘›(ğœË† ğ‘boot)2(cid:3)
and ğœË† ğ‘2 =ğœË†2 /ğ‘› ğ‘forallğ‘âˆˆA. (6)
ğ‘âˆˆA ğ‘
Werefertotheseasthepooledestimatesofvariance.Inourpreliminaryexperiments,theseperformedbetterthanthe
initialestimates(ğœË† ğ‘boot)2,particularlyonsmalldatasets.
4.1 Confidenceintervals
Sofarwehavefocusedonobtainingpointestimatesğœ‡Ë† .However,inorderfortheseestimatestobeusefulinpractice,
ğ‘
wealsoneedtoquantifyouruncertaintyabouttheirvalues.Wedosobyusingconfidenceintervals.Forunbiased
estimators,likethestandardestimatorğ‘ ,confidenceintervalscanbederivedbyestimatingthevarianceandthen
ğ‘
usingnormalapproximation,whichworksquitewellforğ‘ withthepooledestimatesofvariance(seeAppendixA).
ğ‘
However,variance-basedapproachdoesnotworkwithlassoestimates,becausetheyarebiasedâ€”infact,theyachieve
theirimprovedaccuracybybeingbiasedâ€”andsoasimpleapproachofusingvariance-basedconfidenceintervalsor
bootstrappercentilesyieldsconfidenceintervalsthataretoonarrow.Fortunately,thereisarichliteratureonlasso-based
confidenceintervals[18,35,38].Weusetheresidualbootstraplasso+partialridge(rBLPR)approachofLiuetal.[23].As
ESM
,ecnairav
,2saib9
thenamesuggests,itisbasedonatwo-stagelasso+partialridge(LPR)pointestimator,whichfirstrunslassoasafeature-
selectionmethod,andthenfitsaridgeregressionmodel,whichonlypenalizesthefeaturesthatwerenotselectedby
lasso.TherBLPRmethodcalculatesconfidenceintervalsfortheLPRestimatebyresidualbootstrap(see[23]fordetails).
4.2 Goodness-of-fittesting
Whenpresentingtheresultsofdisaggregatedevaluations,themostcommonapproachistodisplaypointestimatesand
(sometimes)confidenceintervalsforeverysubgroup,aswesee,forexample,inFigure1.Whilethistypeofaplotcan
behelpfulinidentifyinggroupsthatmayexperiencepoorperformanceorallocation,itdoesnotprovideanarrativefor
understandinghowtheseharmsaccrue.Goodness-of-fittestingcancomplementdisaggregatedevaluationsbyallowing
ustoanswerquestionssuchas:
(1) Dointersectionalgroupsexperienceadditive,sub-additive,orsuper-additivefairness-relatedharms?Forexample,
whenamodelisfoundtoperformpoorlyforBlackwomen,isthisexplainedbythemodelperformingpoorly
forBlackpeopleandwomen,orarethereadditionalsourcesoferrorspecifictotheintersectionalgroupof
Blackwomen?Ananswertothisquestioncan,forexample,informfuturecollectionoftrainingdata.
(2) Aretherebenignfactorsthatexplainasignificantamountoftheobservedperformancevariationacrossgroups?For
example,areobserveddifferencesintheperformanceofanASRsystemattributabletosystematicallyworse
audioqualityintherecordingsforspeakersfromcertaingroups?Presenceofsuchbenignfactorsdoesnotlessen
theharm,buttheknowledgeofthefactorsthatdriveperformancedifferencescanbeusedtodesignmitigations
(forexample,denoisingalgorithmstargetedatspecifictypesofsensorsornoisecharacteristics).
Thesetypesofquestionscanbeframedasgoodness-of-fittests.Weconsidergoodness-of-fitteststhatcomparetwo
linearmodels:ğ‘€0,withfewerfeatures,andğ‘€1,withsomeadditionalfeatures.Suchatestaskswhethertheadditional
featuresincludedinmodelğ‘€1 improvethegoodnessoffitcomparedwithmodelğ‘€0,wherethegoodness-of-fitis
measuredusingthesquarelossasinEq.(5).Toanswerthefirstquestionabove,wecancompareamodelğ‘€0,which
includesonlyindicatorsofraceandgender,withamodelğ‘€1,whichalsoincludesinteractionterms.Toanswerthe
secondquestion,wecancompareamodelğ‘€â€²,whichonlyincludesbenignfactors,withamodelğ‘€â€²,whichadditionally
0 1
includesindicatorsofrace,gender,andage.
Whiletherearegoodness-of-fitteststhathavebeendesignedforlassoregression[17],inthispaper,weusestandard
ğ¹-testsdesignedforunregularizedlinearregression.Incontrasttotheforegoingdiscussion,wedonotincludefeatures
correspondingtotheindicatorsofğ‘(becausethesewouldtriviallyyieldstandardestimateswithperfectgoodness-of-fit,
whichinthiscasecorrespondstooverfitting).
5 EXPERIMENTS
Inthissection,weevaluatetheaccuracyofpointestimatesandcalibrationofconfidenceintervalsproducedbyour
structuredregression(SR)approach.Wealsodemonstratehowgoodness-of-fittestscanbeusedtoprovideinsights
aboutwhatdrivesthevariationofperformanceacrossgroups.
Inourevaluation,wecompareSRwithseveralbaselines.First,thereisthestandardestimatorğ‘
ğ‘
=ğ‘š(ğ‘† ğ‘).We
constructconfidenceintervalsforğ‘ ğ‘usingnormalapproximationwithpooledvarianceestimates(ğœË† ğ‘)2fromEq.(6).
Givenaconfidencelevelğ›¾ (say95%),orasignificancelevelğ›¼ =1âˆ’ğ›¾ (say5%),weusetheconfidenceinterval
[ğ‘ ğ‘+ğ‘ ğ›¼/2ğœË† ğ‘, ğ‘ ğ‘+ğ‘ 1âˆ’ğ›¼/2ğœË† ğ‘], (7)10 ChristineHerlihy,KimberlyTruong,AlexandraChouldechova,andMiroslavDudÃ­k
whereğ‘ istheğ‘-thquantileofthestandardnormaldistribution.
ğ‘
Oursecondbaselineisthemodel-basedmetrics(MBM)approach[25].AsmentionedinÂ§2,MBMisaBayesian
approachtostructuredregressionthatmodelsthescoresproducedbyanAIsystem(likeğ‘ŒË† inthediabetesexample).
However,itisnotdirectlyapplicabletoperformancemetricsthatarenotbasedonscores,sowedonotuseitinthe
ASRexperiments.SimilartoSR,MBMuseslinearmodeling,andsorequiresspecifyingfeaturesforeachdatapoint.It
comeswithaboostrappingprocedureforconstructingconfidenceintervals.
WealsocompareourpointestimateswiththeclassicalJames-Stein(JS)estimator[16,30].Theestimatorworksby
shrinkingstandardestimatestowardszero(orsomeotherconstant).WeuseavariantduetoBock[4],whichisadapted
tounequalvariances(inourcase,pooledestimatesğœË† ğ‘2 =ğœË†2/ğ‘› ğ‘),givingriseto
ğœ‡Ë† ğ‘js =ğœ‡Ë† 0+(cid:18) 1âˆ’
(cid:205)
ğ‘â€²âˆˆ( A|A
ğ‘›
ğ‘| â€²âˆ’ (ğ‘3 ğ‘) â€²ğœË† âˆ’2
ğœ‡Ë†
0)2(cid:19) +(ğ‘ ğ‘âˆ’ğœ‡Ë† 0),
whereğœ‡Ë† 0=((cid:205) ğ‘âˆˆAğ‘› ğ‘ğ‘ ğ‘)/ğ‘›isaweightedaverageofğ‘ ğ‘â€™s.ComparedwithBockâ€™soriginalestimator[4],weuse|A|
inthenumerator,asthishasbeenpreviouslyobservedtoleadtobetterperformance[9].Sinceğœ‡Ë†jsisnotanunbiased
estimator,constructionofconfidenceintervalspresentsachallengeandwearenotawareofanystandardprocedure.
Andfinally,wecompareourmethodwiththeempiricalBayes(EB)approach[8],whichpositsahierarchical
Bayesianmodel,andthenestimatesğœ‡ byposteriormeans,whilefixinghyperparameterstotheirpointestimates.In
ğ‘
AppendixBwederivethefollowingvariant,whichweuseinourexperiments:
(cid:18) ğœË†2 (cid:19)
ğœ‡Ë† ğ‘eb =ğœ‡Ë†+ 1âˆ’ ğœË†2+ğ‘
ğœË† ğ‘2
(ğ‘ ğ‘âˆ’ğœ‡Ë†),
whereğœË†2isthepooledestimateofvariance,andğœË†2andğœ‡Ë†areobtainedby
ğ‘
ğœË†2 =
(cid:18)(cid:205) ğ‘âˆˆAğ‘› ğ‘(ğ‘ ğ‘âˆ’ğœ‡Ë† 0)2âˆ’(|A|âˆ’1)ğœË†2(cid:19)
and ğœ‡Ë†=
(cid:205) ğ‘âˆˆAğ‘ ğ‘/(ğœË†2+ğœË† ğ‘2)
.
ğ‘›âˆ’(cid:205) ğ‘ğ‘› ğ‘2/ğ‘›
+
(cid:205) ğ‘âˆˆA1/(ğœË†2+ğœË† ğ‘2)
SimilartoJS,wearenotawareofanystandardprocedureforconstructionofconfidenceintervals.
5.1 Diabetesexperiments
Inourfirstsetofexperiments,weexplorethescenariofromExample1usingthedatasetdevelopedbyStracketal.[31],
andpreviouslyusedinanAIfairnesstutorial[13]andtoevaluatetheMBMapproach[25].Thedatasetcontainshospital
admissionrecordsfrom130hospitalsintheU.S.overaten-yearperiod(1998â€“2008)forpatientswhowereadmittedwith
adiabetesdiagnosisandwhosehospitalstaylastedonetofourteendays.Itisatabulardatasetwith47featuresdescribing
eachencounter,includingpatientdemographicsandclinicalinformation(seeStracketal.[31]formoredetails).
FollowingMilleretal.[25],wefilteroutrecordswithmissingdemographicinformationandthosewithagebelow20.
Wepreprocessclinicalfeaturesasin[13].ToemulateanAIsystemthatscorespatientsforapost-dischargecare
program,weuse25%ofthedatatotrainalogisticregressionmodeltopredictwhetherthepatientwillbereadmitted
intohospitalwithin30days.Theremaining75%ofthedata,consistingof73,988hospitaladmissionsacross55,157
individuals,isusedasthegroundtruthDinallofourevaluationexperiments.
Weconsiderthreesensitiveattributes,race,age,andgender,withA race={AfricanAmerican,Hispanic,white,other},
A = {20â€“39,40â€“59,60â€“79,80â€“99},andA = {male,female}.Hospitaladmissionsarerepresentedastuples
age gender
(ğ‘‹,ğ´,ğ‘Œ,ğ‘ŒË† ),whereğ‘‹ includestheclinicalfeatures,ğ´=(race,age,gender),ğ‘Œ âˆˆ{0,1}indicateswhetherthepatientwas11
AUC SEL FNR FPR ACC PPV
method
0.3
standard
MBM
0.2
JS
EB
0.1
structured
regression
0.0
allsmall large allsmall large allsmall large allsmall large allsmall large allsmall large
groups groups groups groups groups groups
Fig.3. Meanabsoluteerrorofestimatesof6metricsusing5methodsondiabetesdata.Averagedacrossallgroups,smallgroups(sizeat
most25),andlargegroups(sizeabove25),across20drawsofevaluationdataset.
readmittedwithin30daysofdischarge,andğ‘ŒË† âˆˆ [0,1]isthereadmissionprobabilitypredictedbythelogisticregression
model.Fromthegroundtruthwethensampleanevaluationdatasetğ‘†ofsize5000bystratifiedsamplingaccordingtoğ´.
AsinExample1,weassumethatthehospitalusesathresholdğ‘Ÿ,andpatientswithğ‘ŒË† â‰¥ğ‘Ÿ areautomaticallyreferred
intothecareprogram.Wesetthethresholdğ‘Ÿ sothatP D[ğ‘ŒË† â‰¥ğ‘Ÿ] =0.2,meaningthatonly20%ofpatientsarereferred,
andwriteğœ‹(ğ‘ŒË† )=1{ğ‘ŒË† â‰¥ğ‘Ÿ}todenotethisdecisionrule.Weconsider6performancemetrics(includingthosealready
introducedearlier),definedforanyğ‘ âˆˆÎ”as
SEL(ğ‘)=P ğ‘(cid:2)ğœ‹(ğ‘ŒË† )=1(cid:3), ACC(ğ‘)=P ğ‘(cid:2)ğœ‹(ğ‘ŒË† )=ğ‘Œ(cid:3),
FNR(ğ‘)=P ğ‘(cid:2)ğœ‹(ğ‘ŒË† )=0(cid:12) (cid:12)ğ‘Œ =1(cid:3), FPR(ğ‘)=P ğ‘(cid:2)ğœ‹(ğ‘ŒË† )=1(cid:12) (cid:12)ğ‘Œ =0(cid:3),
PPV(ğ‘)=P ğ‘(cid:2)ğ‘Œ =1(cid:12) (cid:12)ğœ‹(ğ‘ŒË† )=1(cid:3), AUC(ğ‘)=P (ğ‘Œ,ğ‘ŒË†)âˆ¼ğ‘,(ğ‘Œâ€²,ğ‘ŒË†â€²)âˆ¼ğ‘(cid:2)ğ‘ŒË† <ğ‘ŒË†â€² (cid:12) (cid:12)ğ‘Œ =0,ğ‘Œâ€² =1(cid:3).
Thefirstfivemetrics(selectionrate,accuracy,falsepositiverate,falsenegativerate,andpositivepredictivevalue)are
derivedfromtheconfusionmatrix.ThefinalmetricistheareaundertheROCcurve;(ğ‘Œ,ğ‘ŒË† )and(ğ‘Œâ€²,ğ‘ŒË†â€²)initsdefinition
aresampledindependentlyaccordingtoğ‘.
InordertoapplySR,weneedtospecifyfeaturesğ“ğ‘.Assensitivefeatures,weuseindicatorsofrace,age,gender,as
wellasindicatorsofthetriple(race,age,gender).Weuse7explanatoryfeatures:indicatorsfor2possiblevaluesofğ‘Œ,
and5additionalclinicalfeaturesdescribingthenumberofinpatientvisits,outpatientvisits,andemergencyvisitsinthe
precedingyear,numberofdiagnosesatadmission,andwhetheranyofthediagnoseswascongestiveheartfailure.For
MBM,weusethesamesetoffeatures,butwithoutthetripleindicators.
InFigure1fromearlier,pointestimatesobtainedbySRappeartobeclosertothegroundtruththanthoseobtained
bythestandardmethodandMBM.ConfidenceintervalsconstructedbySRareofsimilarsizeasthestandardconfidence
intervals,andoccasionallysmaller.MBMappearstoproducesmallerconfidenceintervalsthanSR,buttheyseemto
misstheground-truthmetricvaluesmoreoften.Wenextevaluatetheseanecdotalobservationsmoresystematically.
InFigure3,weevaluatethequalityofpointestimatesusingmeanabsoluteerror(MAE),whichisthemeandeviation
ofthepointestimatefromthetruth,averagedacross20drawsofevaluationdataset,andoverallgroups,orseparately
overthegroupsofsizeatmost25(whichwecallsmall)andgroupsofsizegreaterthan25(whichwecalllarge).We
seethatJS,EBandSRyieldsubstantiallymoreaccuratepointestimatesthanthestandardmethodandMBM.The
improvementisparticularlydramaticforsmallgroups.JS,EBandSRexhibitsimilarperformance,butSRtendstowork
bestonsmallgroups,andEBismarginallybetterthanJSandSRonlargegroups(seeFigure7inAppendixCfora
comparisonlimitedtothesethreemethods).WeuseMAEinsteadofMSE,becauseMAEvaluesareeasiertointerpret,
butMSEresultsarequalitativelysimilar.
rorre
etulosba
naem12 ChristineHerlihy,KimberlyTruong,AlexandraChouldechova,andMiroslavDudÃ­k
AUC SEL FNR FPR ACC PPV
1.0
method
0.8 standard
MBM
0.6
structured
0.4 regression
perfect
50 8090 9 5 50 8090 9 5 50 8090 9 5 50 8090 9 5 50 8090 9 5 50 8090 9 5
1.0
0.8
0.6
50 8090 9 5 50 8090 9 5 50 8090 9 5 50 8090 9 5 50 8090 9 5 50 8090 9 5
confidence level
Fig.4. Coverageandmeanrelativewidthofconfidenceintervalsfor6metricsconstructedby3methodsondiabetesdata.Averagedacross
allgroupsandacross20drawsofevaluationdataset.Relativewidthiswithrespecttothewidthofthestandardconfidenceinterval.
Table1. Goodness-of-fittestsondiabetesdata.Fromlefttoright,weconsiderincreasinglymorecomplexmodelswithagrowingsetof
featuresandreporttheğ‘-valuesofthecorrespondinggoodness-of-fittests;ğ‘-valuesbelow0.05areinbold.
Estimated Goodness-of-fittestğ‘-values Modelabbreviations:
metric (comparingamoreexpressivevsalessexpressivemodel) âˆ…=interceptonly
expl sens expl+sens expl+sens+ğ‘ŒÂ·sens expl=explanatoryfeatures
sens=sensitivefeatures
vsâˆ… vsâˆ… vsexpl vsexpl+sens
Â·=interactions
AUC 0.281 0.438 0.726 0.543
SEL 0.000 0.000 0.000 0.842
FNR 0.093 0.473 0.735 0.565
FPR 0.001 0.000 0.000 0.431
ACC 0.000 0.000 0.005 0.182
PPV 0.316 0.493 0.470 0.874
InFigure4,weshiftattentiontoconfidenceintervals.Inthetopplots,weevaluatecoverage,thatis,howoftenthe
groundtruthliesintheconfidenceintervals(across20drawsofevaluationdatasetandacrossallgroups).Weshow
coverageasafunctionoftheconfidencelevel.WeseethatbothstandardmethodaswellasSRarewell-calibrated,with
theircoverageclosetotheconfidencelevel,whereasMBMisover-confident,withcoveragewellbelowtheconfidence
level.Inthebottomplots,weevaluatethemeanrelativewidthofconfidenceintervals,meaningthemeanoftheratio
betweenthewidthofaconfidenceintervalandthewidthofthestandardconfidenceinterval.WeseethatMBMhasthe
narrowestintervals,butthisisattheexpenseofcoverage.Ontheotherhand,SRisabletomaintainwell-calibrated
coveragewhilestilldecreasingtheconfidenceintervalsbyupto20%comparedwiththestandardmethod.
Finally,inTable1,wedemonstratetheuseofgoodness-of-fittests.Fromlefttoright,weconsiderincreasinglymore
complexmodelswithagrowingsetoffeatures.Beginningwithjusttheintercept,addingexplanatoryfeatures,then
sensitivefeatures(justtheindicatorsofrace,age,andgender,butnotoftheircombination),andeventuallyinteraction
termsbetweentheoutcomeğ‘Œ andsensitivefeatures.Thereisnoevidencetogobeyondtheintercept-onlymodelwhen
estimatingAUC,FNR,PPV.Thisdoesnotnecessarilymeanthatthereisnodisparityinperformance,butwemightnot
haveenoughdatatotell.Indeed,forinstance,confidenceintervalsforFNRinFigure1arelargeforavastmajority
ofthegroups,sointhiscaseusingSRisnotsufficienttoreduceuncertainty,andadditionaldatacollectionmaybe
egarevoc
htdiw
evitaler
naem13
Table2. Goodnessoffittestsonsyntheticdata.Fromlefttoright,weconsiderincreasinglymorecomplexmodelswithagrowingsetof
featuresandreporttheğ‘-valuesofthecorrespondinggoodness-of-fittests;ğ‘-valuesbelow0.05areinbold.
Data-generating Goodness-of-fittestğ‘-values
model (comparingamoreexpressivevsalessexpressivemodel)
expl age expl+age expl+rc expl+age+rc expl+age+rc expl+age+rc+ageÂ·rc
vsâˆ… vsâˆ… vsexpl vsexpl vsexpl+age vsexpl+rc vsexpl+age+rc
model age 0.025 0.000 0.000 0.487 0.153 0.000 0.576
model expl 0.000 0.000 0.323 0.366 0.608 0.551 0.000
model age+rc 0.013 0.661 0.142 0.000 0.000 0.000 0.089
model ageÂ·rc 0.003 0.000 0.000 0.040 0.015 0.000 0.002
Modelabbreviations:âˆ…=interceptonly,expl=explanatoryfeatures,rc=race,Â·=interactions
required.Ontheotherhand,thetableshowsthatbothexplanatoryandsensitivefeatureshelpwithmodelingSEL,FPR,
andACC.Infact,sensitivefeaturesimprovethefitaftertheexplanatoryfeatureshavealreadybeenadded,meaning
thatdifferencesinperformanceacrossthegroupscannotbeexplainedbytheâ€œbenignâ€explanatoryfeaturesalone.
5.2 Experimentswithsyntheticdata
Wenextprovideafewmoreexamplesofgoodness-of-fitanalysisonsyntheticdata.Wecontinuetousethediabetes
datasetasdescribedintheprevioussection,butwithdifferentvaluesğ‘ŒË†.Weconsidertheperformancemetricğ‘š(ğ‘)=
E ğ‘[ğ‘ŒË† ] (thisisquitesimilartoselectionrateorworderrorrate)andgenerateğ‘ŒË† insuchawaythatground-truth
metricvaluesğœ‡ haveaspecificstructure.Weconsider4differentground-truthstructures,titledmodel ,model ,
ğ‘ age age+rc
model ageÂ·rc,andmodel expl,accordingtothevariablestheydependon,withâ€œ+â€denotinganadditivedependenceandâ€œÂ·â€
presenceofinteractions(seeAppendixDfordetails).
InTable2,movingfromlefttoright,wetestgoodness-of-fitofmoreandmorecomplexmodels.Inthefirstrow,
ground-truthdependsonlyonage,butthereisasignificantimprovementingoodness-of-fitfromâˆ…toexpl,becauseof
correlationbetweenageandexpl.Aftertheexplanatoryfeatureshavebeenincluded,agestillhelps(theimprovement
fromexpltoexpl+ageissignificant),sothevariationintheperformancemetriccannotbeexplainedbytheâ€œbenign
factorsâ€alone.Ontheotherhand,ifthedataisdrawnfrommodel ,thereisnoevidencethatageorracehelpafter
expl
explanatoryfeatureshavebeenadded.
Inthelasttworows,wedemonstratehowgoodness-of-fittestshandledatafromadditivemodelsversusmodelswith
interactiveterms.Theformercorrespondtothesituationwhenharmsexperiencedbyintersectionalgroupscombine
additively,thelatterwhenthereisanadditionalintersectionaleffect.Fortheadditivegroundtruth(model ),tests
age+rc
suggestasequenceofvariableadditionsexpl+rc+age,butthenshownosupportforincludinginteractionterms.For
thedatafrommodel ,testscorrectlyprovidesupportforaninclusionofinteractions.
ageÂ·rc
5.3 ExperimentswithASRdata
Finally,weexplorethescenariofromExample2usingthedataprovidedbyKoeneckeetal.[22]asasupplementto
theirpaperfindingracialdisparitiesincommercialASRsystems.SimilartoKoeneckeetal.[22],weusethematched
dataset,whichcontains4282snippetsacross105distinctspeakers.(Matchingensuresthatthereisthesamenumberof
snippetsfromBlackandwhitespeakersandthatthemarginaldistributionsofvariousdescriptivestatisticsmatch.)14 ChristineHerlihy,KimberlyTruong,AlexandraChouldechova,andMiroslavDudÃ­k
GOOGLE IBM AMAZON MSFT APPLE
0.6 method
standard 0.4
structured
0.2 regression
0.0
90112409721169 90112409721169 90112409721169 90112409721169 90112409721169 group size
(#snippets)
0.6
0.4
0.2
0.0
29 44 25 17 29 44 25 17 29 44 25 17 29 44 25 17 29 44 25 17 group size
(#speakers)
groups
(race: Bl=Black, Wh=white; gender: M=male, F=female)
Fig.5. Pointestimatesand95%confidenceintervalsofworderrorratesoffivedifferentASRsystems.
Foreachaudiosnippet,weareprovidedwithvariousstatistics(likedurationandwordcount),ananonymizedspeaker
id,speakerdemographics,andworderrorrates(WERs)onthatsnippetbyfiveASRsystems,developedbyGoogle,IBM,
Amazon,Microsoft,andApple.Thisinformationisencodedasatuple(ğ‘‹,ğ´,ğ‘Š1,...,ğ‘Š5),whereğ‘‹ containstheidentity
ofthespeaker,thedurationofthesnippetinseconds,andwordcount,ğ´containstwosensitiveattributes,genderand
race,withA
gender
= {male,female}andA
race
= {Black,white},andfinally,insteadofğ‘Œ (humantranscription)and
ğ‘ŒË† 1,...,ğ‘ŒË† 5(transcriptionsbyfiveASRsystems),wedirectlyhavethecorrespondingworderrorratesğ‘Š
ğ‘–
=wer(ğ‘ŒË† ğ‘–,ğ‘Œ).
Theperformancemetricforthesystemğ‘–isthusğ‘š(ğ‘)=E ğ‘[ğ‘Š ğ‘–]foranyğ‘ âˆˆÎ”.
Althoughthereappearstobealargenumberofsamples(ğ‘›=4282),thereareonly105distinctspeakers.Weexpect
theretobeasubstantialamountofcorrelationbetweenWERsofthesameindividual,soananalysisthattreatstheWERs
asindependentislikelytooverstatethestatisticalsignificanceoffindings,andmayarriveatincorrectconclusions,inpar-
ticular,whensomespeakershavemanymoresnippetsthanothers.Inourexperiments,wethereforepresentresultsboth
fromasnippet-levelanalysisthattreatstheWERsacrossallsnippetsasindependent(asdonein[22]),andaspeaker-level
analysisthatfirstreducesthedatatospeaker-levelWERsbytakinganaverageofWERsacrossthespeakerâ€™ssnippets.
WefirstcomparedisaggregatedevaluationresultsobtainedbySRversusthestandardmethod.ToapplySR,we
needtospecifyfeaturesğ“ğ‘.Assensitivefeatures,weuseindicatorsofraceandgender,aswellasindicatorsofthepair
(race,gender).Weuseonlyoneexplanatoryfeature,equaltothelogdurationofthesnippet.
InFigure5,wereporttheresults.Atthesnippetlevel,bothmethodsgenerallyreplicatetheresultsofKoenecke
etal.[22]:BlackmalespeakershavethelargestWER,followedbyBlackfemalespeakers,whitemalespeakers,and
whitefemalespeakers.ThemaindifferenceisthatSRsystematicallyshrinkstheWERvaluesoftheextremegroups
(Blackmalespeakersandwhitefemalespeakers)towardsthemean.Resultsatthespeakerlevelhavesubstantially
largerconfidenceintervalsthanthesnippet-levelresults,reflectingsmallergroupsizes.Also,duetosmallergroup
sizes,theSRpointestimatesareshrunktowardsthemeanmoreaggressively.
Wealsocarryoutthegoodness-of-fitanalysisofstructureofintersectionalharms.Atthespeakerlevel,wefindthat
thevariationofperformanceofallsystemsiswell-explainedbytheadditivemodelexpl+race+gender(theğ‘-valuesof
etar
rorre
drow
etar
rorre
drow
)level
teppins(
)level
rekaeps(
M
lB
F
lB
M
hW
F
hW
M
lB
F
lB
M
hW
F
hW
M
lB
F
lB
M
hW
F
hW
M
lB
F
lB
M
hW
F
hW
M
lB
F
lB
M
hW
F
hW15
addingeachvariableinturnarebelow0.003),butnotbyamodelwithinteractions.Thisisincontrastwiththesnippet-
levelanalysis,whichsupportsthemodelwithinteractions(withğ‘-valuesbelow0.001).Weinterpretthisconservatively
andconcludethatthereisevidenceforanadditivestructureofintersectionalharms,butnotforaninteractionterm.
Thisdoesnotmeanthattherearenointeractioneffects,justthatwecannotconcludethatfromthedataathand.
6 CONCLUSION
Wehaveintroducedastructuredregressionapproachtodisaggregatedevaluationandcompareditsperformance
withavarietyofbaselines.Wehaveseenthatthestructuredregression(SR),James-Stein(JS)andempiricalBayes
(EB)estimatorsallsubstantiallyimproveaccuracyofpointestimatescomparedwiththestandardapproachanda
moresophisticatedMBMbaseline.SR,JSandEBaresimpletoimplement,andarealsocloseintermsofperformance,
sothechoiceamongthemshouldbedrivenbytheirusability.Here,SRhassomeadvantages.Itsabilitytoinclude
application-specificfeaturesmakesitmoreflexible,andithasawell-developedinferenceprocedureslikeconstruction
ofconfidenceintervalsandgoodness-of-fittests.ExaminingJSandEBmorecloselyfrominferenceperspectiveinthe
contextofdisaggregatedevaluationisapromisingdirectionforfutureresearchandanecessityfortheirpracticaluse.
NotethatwehaveevaluatedSRonlyintwodomains,soanyapplicationsindomainswithdifferentcharacteristics(like
thenumberandtypesofexplanatoryandsensitivefeatures,ordatasetsize)requireadditionalvalidation.
InÂ§2,wementionedchallengesthatariseinconceptualizationstagesofdisaggregatedevaluation.Oncethedisaggre-
gatedresultsareproduced,acomplementarysetofchallengesarisesinhowtointerpretthem.Wehaveconspicuously
omittedanalysisofregressioncoefficients,becauseinourpreliminaryexperiments,wefoundthatlassocoefficients
exhibittoomuchvarianceforreliableinference.Instead,wesuggesttousegoodness-of-fittestsandwehavedemon-
stratedseveralwayshow.Weacknowledgethatwehavejusttakensomeinitialstepsinthisarea,andtherearemany
opportunitiestoapplymoresophisticatedstatisticaltechniques.Ourexplorationalsocompletelyleavesoutimportant
sociotechnicalquestionsabouthowtodrawactionableconclusions,andhowtobestcommunicatetheresultstorelevant
stake-holders,bothofwhicharekeyintranslatingfairnessassessmentsintoareductioninfairness-relatedharms.
ACKNOWLEDGMENTS
WewouldliketothankMishaKhodakformanyhelpfuldiscussionsandinparticularforpointingouttheconnection
betweendisaggregatedevaluationandtheJames-Steinestimator.
REFERENCES
[1] JuliaAngwin,JeffLarson,SuryaMattu,andLaurenKirchner.Machinebias:Thereâ€™ssoftwareusedacrossthecountrytopredictfuturecriminals.
anditâ€™sbiasedagainstblacks.2016.https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.
[2] SolonBarocas,KateCrawford,AaronShapiro,andHannaWallach.Theproblemwithbias:Allocativeversusrepresentationalharmsinmachine
learning.In9thAnnualconferenceofthespecialinterestgroupforcomputing,informationandsociety,2017.
[3] SolonBarocas,AnhongGuo,EceKamar,JacquelynKrones,MeredithRingelMorris,JenniferWortmanVaughan,DuncanWadsworth,andHanna
Wallach.DesigningDisaggregatedEvaluationsofAISystems:Choices,Considerations,andTradeoffs.InAIES2021.ACM,May2021.
[4] M.E.Bock.Minimaxestimatorsofthemeanofamultivariatenormaldistribution.TheAnnalsofStatistics,3(1),1975.
[5] JoyBuolamwiniandTimnitGebru.Gendershades:Intersectionalaccuracydisparitiesincommercialgenderclassification.InSorelleA.Friedler
andChristoWilson,editors,Proceedingsofthe1stConferenceonFairness,AccountabilityandTransparency,volume81ofProceedingsofMachine
LearningResearch,pages77â€“91.PMLR,23â€“24Feb2018.
[6] AlexandraChouldechova,SiqiDeng,YongxinWang,WeiXia,andPietroPerona.Unsupervisedandsemi-supervisedbiasbenchmarkinginface
recognition.InEuropeanConferenceonComputerVision,pages289â€“306.Springer,2022.
[7] KimberlÃ©Crenshaw.Demarginalizingtheintersectionofraceandsex:Ablackfeministcritiqueofantidiscriminationdoctrine,feministtheoryand
antiracistpolitics.volume1989,Article8.1989.16 ChristineHerlihy,KimberlyTruong,AlexandraChouldechova,andMiroslavDudÃ­k
[8] BradleyEfronandCarlMorris. Steinâ€™sestimationruleanditscompetitorsâ€”anempiricalBayesapproach. JournaloftheAmericanStatistical
Association,68(341):117â€“130.
[9] SergeyFeldman,MayaGupta,andBelaFrigyik.Multi-taskaveraging.InAdvancesinNeuralInformationProcessingSystems,volume25,2012.
[10] RiccardoFogliato,AlexandraChouldechova,andMaxGâ€™Sell.Fairnessevaluationinpresenceofbiasednoisylabels.InInternationalconferenceon
artificialintelligenceandstatistics,pages2325â€“2336.PMLR,2020.
[11] JamesRFoulds,RashidulIslam,KamrunNaherKeya,andShimeiPan. Bayesianmodelingofintersectionalfairness:Thevarianceofbias. In
Proceedingsofthe2020SIAMInternationalConferenceonDataMining,pages424â€“432.SIAM,2020.
[12] JamesRFoulds,RashidulIslam,KamrunNaherKeya,andShimeiPan.Anintersectionaldefinitionoffairness.In2020IEEE36thInternational
ConferenceonDataEngineering(ICDE),pages1918â€“1921.IEEE,2020.
[13] TriveniGandhi,ManojitNandi,MiroslavDudÃ­k,HannaWallach,MichaelMadaio,HildeWeerts,AdrinJalali,andLisaIbaÃ±ez. FairnessinAI
Systems:FromSocialContexttoPracticeusingFairlearn.Tutorialpresentedatthe20thannualScientificComputingwithPythonConference
(Scipy2021),VirtualEvent,2021.URLhttps://github.com/fairlearn/talks/tree/main/2021_scipy_tutorial.
[14] CanerHazirbas,JoannaBitton,BrianDolhansky,JacquelinePan,AlbertGordo,andCristianCantonFerrer.TowardsmeasuringfairnessinAI:The
casualconversationsdataset.IEEETransactionsonBiometrics,Behavior,andIdentityScience,4(3):324â€“332,2022.doi:10.1109/TBIOM.2021.3132237.
[15] UrsulaHÃ©bert-Johnson,MichaelKim,OmerReingold,andGuyRothblum. Multicalibration:Calibrationforthe(computationally-identifiable)
masses.InInternationalConferenceonMachineLearning,pages1939â€“1948.PMLR,2018.
[16] W.JamesandC.Stein.Estimationwithquadraticloss.InProc.FourthBerkeleySymposiumonMathematicalStatisticsandProbability,pages361â€“â€“379,
1961.
[17] JanaJankovÃ¡,RajenDShah,PeterBÃ¼hlmann,andRichardJSamworth.Goodness-of-fittestinginhighdimensionalgeneralizedlinearmodels.
JournaloftheRoyalStatisticalSocietySeriesB:StatisticalMethodology,82(3):773â€“795,2020.
[18] AdelJavanmardandAndreaMontanari.Confidenceintervalsandhypothesistestingforhigh-dimensionalregression.JournalofMachineLearning
Research,15(82):2869â€“2909,2014.
[19] DisiJi,RobertL.Logan,PadhraicSmyth,andMarkSteyvers.Activebayesianassessmentforblack-boxclassifiers,2020.URLhttps://arxiv.org/abs/
2002.06532.
[20] DisiJi,PadhraicSmyth,andMarkSteyvers.CanITrustMyFairnessMetric?AssessingFairnesswithUnlabeledDataandBayesianInference,2020.
URLhttps://arxiv.org/abs/2010.09851.
[21] MichaelKearns,SethNeel,AaronRoth,andZhiweiStevenWu.Preventingfairnessgerrymandering:Auditingandlearningforsubgroupfairness.
InInternationalconferenceonmachinelearning,pages2564â€“2572.PMLR,2018.
[22] AllisonKoenecke,AndrewNam,EmilyLake,JoeNudell,MinnieQuartey,ZionMengesha,ConnorToups,JohnR.Rickford,DanJurafsky,and
SharadGoel.Racialdisparitiesinautomatedspeechrecognition.ProceedingsoftheNationalAcademyofSciences,117(14):7684â€“7689,2020.doi:
10.1073/pnas.1915768117.URLhttps://www.pnas.org/doi/abs/10.1073/pnas.1915768117.
[23] HanzhongLiu,XinXu,andJingyiJessicaLi.StatisticaSinica,30(3):1333â€“1355,2020.
[24] MichaelMadaio,LisaEgede,HariharanSubramonyam,JenniferWortmanVaughan,andHannaWallach.Assessingthefairnessofaisystems:Ai
practitionersâ€™processes,challenges,andneedsforsupport.Proc.ACMHum.-Comput.Interact.,6(CSCW1),apr2022.doi:10.1145/3512899.URL
https://doi.org/10.1145/3512899.
[25] AndrewC.Miller,LeonA.Gatys,JosephFutoma,andEmilyFox.Model-basedmetrics:Sample-efficientestimatesofpredictivemodelsubpopulation
performance.InProceedingsofthe6thMachineLearningforHealthcareConference,pages308â€“336.PMLR,2021.URLhttps://proceedings.mlr.press/
v149/miller21a.html.
[26] MathieuMolinaandPatrickLoiseau.Boundingandapproximatingintersectionalfairnessthroughmarginalfairness.AdvancesinNeuralInformation
ProcessingSystems,35:16796â€“16807,2022.
[27] ZiadObermeyer,BrianPowers,ChristineVogeli,andSendhilMullainathan.Dissectingracialbiasinanalgorithmusedtomanagethehealthof
populations.Science,366(6464):447â€“453,2019.doi:10.1126/science.aax2342.URLhttps://www.science.org/doi/abs/10.1126/science.aax2342.
[28] VihariPiratla,SoumenChakrabarti,andSunitaSarawagi.Activeassessmentofpredictionservicesasaccuracysurfaceoverattributecombinations.
CoRR,abs/2108.06514,2021.URLhttps://arxiv.org/abs/2108.06514.
[29] ReneeShelby,ShalalehRismani,KathrynHenne,AJungMoon,NegarRostamzadeh,PaulNicholas,Nâ€™MahYilla-Akbari,JessGallegos,Andrew
Smart,EmilioGarcia,etal. Sociotechnicalharmsofalgorithmicsystems:Scopingataxonomyforharmreduction. InProceedingsofthe2023
AAAI/ACMConferenceonAI,Ethics,andSociety,pages723â€“741,2023.
[30] C.Stein.Inadmissibilityoftheusualestimatorforthemeanofamultivariatedistribution.InProc.ThirdBerkeleySymposiumonMathematical
StatisticsandProbability,pages197â€“206,1956.
[31] BeataStrack,JonathanDeshazo,ChrisGennings,JuanLuisOlmoOrtiz,SebastianVentura,KrzysztofCios,andJohnClore. ImpactofHbA1c
MeasurementonHospitalReadmissionRates:Analysisof70,000ClinicalDatabasePatientRecords.BioMedresearchinternational,2014:781670,04
2014.doi:10.1155/2014/781670.
[32] LatanyaSweeney.Discriminationinonlineaddelivery:Googleads,blacknamesandwhitenames,racialdiscrimination,andclickadvertising.
Queue,11(3):10â€“29,mar2013.ISSN1542-7730.doi:10.1145/2460276.2460278.URLhttps://doi.org/10.1145/2460276.2460278.
[33] RobertTibshirani.Regressionshrinkageandselectionviathelasso.JournaloftheRoyalStatisticalSociety.SeriesB(Methodological),58(1):267â€“288,
1996.17
[34] BorisvanBreugel,NabeelSeedat,FergusImrie,andMihaelavanderSchaar.Canyourelyonyourmodelevaluation?improvingmodelevaluation
withsynthetictestdata.arXivpreprintarXiv:2310.16524,2023.
[35] SaravandeGeer,PeterBÃ¼hlmann,Yaâ€™acovRitov,andRubenDezeure.Onasymptoticallyoptimalconfidenceregionsandtestsforhigh-dimensional
models.TheAnnalsofStatistics,42(3):1166â€“1202,2014.
[36] AngelinaWang,VikramVRamaswamy,andOlgaRussakovsky.Towardsintersectionalityinmachinelearning:Includingmoreidentities,handling
underrepresentation,andperformingevaluation.InProceedingsofthe2022ACMConferenceonFairness,Accountability,andTransparency,pages
336â€“349,2022.
[37] HildeWeerts,MiroslavDudÃ­k,RichardEdgar,AdrinJalali,RomanLutz,andMichaelMadaio.Fairlearn:AssessingandimprovingfairnessofAI
systems.JournalofMachineLearningResearch,24(257):1â€“8,2023.URLhttp://jmlr.org/papers/v24/23-0389.html.
[38] Cun-HuiZhangandStephanieS.Zhang.Confidenceintervalsforlowdimensionalparametersinhighdimensionallinearmodels.Journalofthe
RoyalStatisticalSociety.SeriesB(StatisticalMethodology),76(1):217â€“242,2014.18 ChristineHerlihy,KimberlyTruong,AlexandraChouldechova,andMiroslavDudÃ­k
AUC SEL FNR FPR ACC PPV
1.0
method
0.8 pooled var.
separate var.
0.6 bootstrap
percentiles
0.4 perfect
50 8090 9 5 50 8090 9 5 50 8090 9 5 50 8090 9 5 50 8090 9 5 50 8090 9 5
confidence level
Fig.6. Comparisonofmethodsforconstructingconfidenceintervalsforthestandardestimator.Showingcoverageofconfidenceintervals
constructedforsixmetricsondiabetesdata,averagedoverallgroupsandover20drawsofevaluationdataset.Confidenceintervals
constructedfrompooledvarianceareclosetotheperfectline(correspondingtocoverageequaltoconfidencelevel).Confidence
intervalsderivedfromseparatelyestimatedvariancesundercovertruevalues.
A CONFIDENCEINTERVALSFORSTANDARDESTIMATES
Weconsiderthreemethodsforconstructingconfidenceintervalsforstandardestimatorsğ‘ atagivenconfidence
ğ‘
levelğ›¾ (e.g.,95%),orequivalently,atasignificancelevelğ›¼ =1âˆ’ğ›¾ (e.g.,5%).
Twoofthemethodsarebasedonnormalapproximationandtakeform
[ğ‘ ğ‘+ğ‘ ğ›¼/2ğœË† ğ‘, ğ‘ ğ‘+ğ‘ 1âˆ’ğ›¼/2ğœË† ğ‘],
whereğ‘ istheğ‘-thquantileofthestandardnormaldistributionandğœË†2isanestimateofvarianceofğ‘ .Weconsider
ğ‘ ğ‘ ğ‘
eitherthepooledestimateofvariancederivedinEq.(6),ortheestimate(ğœË† ğ‘boot)2obtainedbyboostraponğ‘† ğ‘.Thethird
methodusesbootstrappercentilesonğ‘† .
ğ‘
InFigure6,wecomparecoveragepropertiesoftheresultingconfidenceintervalsondiabetesdata.Confidence
intervalsconstructedfrompooledvarianceestimatesarewell-calibrated,withcoveragecloselymatchingtheirconfidence
level.Theothertwomethodssubstantiallyundercovertruevalues.
B DERIVATIONOFTHEEMPIRICALBAYESESTIMATOR
WepositthefollowinghierarchicalGaussianmodel:
ğœ‡ ğ‘ âˆ¼N(ğœ‡,ğœ2 ) forallğ‘âˆˆA,
(8)
ğ‘ ğ‘ âˆ¼N(ğœ‡ ğ‘,ğœ ğ‘2 ) forallğ‘âˆˆA,
whereğœ isknownandğœ‡andğœ areunknownhyperparameters.Weobservevaluesğ‘ andneedtopredictğœ‡ .
ğ‘ ğ‘ ğ‘
Conditioningonthepriorandobservations,weobtaintheposteriordistribution
ğœ‡ ğ‘ |ğœ‡,ğœ,ğ‘ ğ‘ âˆ¼N (cid:16) ğœ‡Ë† ğ‘eb,(ğœË† ğ‘eb )2(cid:17)
wheretheposteriormeanandvarianceareequalto
ğœ2 ğœ2
ğœ‡Ë† ğ‘eb =ğœ‡+
ğœ2+ğœ ğ‘2
Â·(ğ‘ ğ‘âˆ’ğœ‡) and (ğœË† ğ‘eb )2 =
ğœ2+ğœ ğ‘2
Â·ğœ ğ‘2. (9)
TheempiricalBayesapproachtakespointestimatesofthehyperparametersğœ‡andğœ,andplugsthemintoEq.(9).
Theresultingğœ‡Ë†ebisusedasapointestimateforğœ‡ andtheresultingğœË†ebisusedtoconstructcredibleintervalsforğœ‡ .
ğ‘ ğ‘ ğ‘ ğ‘
egarevoc19
Weestimateğœ2byanalyzingasuitablesumofsquares(similarlyasintheanalysisofvariance).Tostart,notethatif
wemarginalizeoutğœ‡ fromEq.(8),wefindthatthevaluesğ‘ areconditionallyindependentgivenğœ‡andğœ,with
ğ‘ ğ‘
ğ‘ ğ‘ |ğœ‡,ğœ âˆ¼N(ğœ‡,ğœ2 +ğœ ğ‘2 ) forallğ‘âˆˆA. (10)
Foreachğ‘,weconsiderthesquare(ğ‘ ğ‘âˆ’ğœ‡Ë† 0)2,where
âˆ‘ï¸
ğœ‡Ë† 0= ğ‘¤ ğ‘ğ‘ ğ‘ with ğ‘¤ ğ‘ =ğ‘› ğ‘/ğ‘›forallğ‘âˆˆA.
ğ‘âˆˆA
Theexpectationof(ğ‘ ğ‘âˆ’ğœ‡Ë† 0)2thentakesthefollowingform:
(cid:34)(cid:32) (cid:33)2(cid:12) (cid:35)
(cid:104)(cid:16) (cid:17)2(cid:12) (cid:105) âˆ‘ï¸ (cid:12)
E ğ‘ ğ‘âˆ’ğœ‡Ë† 0 (cid:12) (cid:12)ğœ‡,ğœ =E ğ‘¤ ğ‘â€²ğ‘ ğ‘â€² âˆ’(1âˆ’ğ‘¤ ğ‘)ğ‘ ğ‘ (cid:12) (cid:12)ğœ‡,ğœ
ğ‘â€²â‰ ğ‘ (cid:12)
(cid:34)(cid:32) (cid:33)2(cid:12) (cid:35)
âˆ‘ï¸ (cid:12)
=E ğ‘¤ ğ‘â€²(ğ‘ ğ‘â€² âˆ’ğœ‡)âˆ’(1âˆ’ğ‘¤ ğ‘)(ğ‘ ğ‘âˆ’ğœ‡) (cid:12) (cid:12)ğœ‡,ğœ
ğ‘â€²â‰ ğ‘ (cid:12)
= âˆ‘ï¸ ğ‘¤ ğ‘2 â€²(ğœ2 +ğœ ğ‘2 â€²)+(1âˆ’ğ‘¤ ğ‘)2 (ğœ2 +ğœ ğ‘2 ) (11)
ğ‘â€²â‰ ğ‘
= âˆ‘ï¸ ğ‘¤ ğ‘2 â€²(ğœ2 +ğœ ğ‘2 â€²)+(1âˆ’2ğ‘¤ ğ‘)(ğœ2 +ğœ ğ‘2 ), (12)
ğ‘â€²âˆˆA
whereEq.(11)followsbyEq.(10)andconditionalindependenceofğ‘ s.MultiplyingEq.(12)byğ‘¤ andsummingacross
ğ‘ ğ‘
allğ‘,weobtain
(cid:34) (cid:12) (cid:35)
E âˆ‘ï¸ ğ‘¤ ğ‘(cid:16) ğ‘ ğ‘âˆ’ğœ‡Ë† 0(cid:17)2(cid:12) (cid:12) (cid:12)ğœ‡,ğœ = âˆ‘ï¸ ğ‘¤ ğ‘2 â€²(ğœ2 +ğœ ğ‘2 â€²)+ âˆ‘ï¸ ğ‘¤ ğ‘(1âˆ’2ğ‘¤ ğ‘)(ğœ2 +ğœ ğ‘2 )
ğ‘âˆˆA (cid:12) ğ‘â€²âˆˆA ğ‘âˆˆA
= âˆ‘ï¸ ğ‘¤ ğ‘(1âˆ’ğ‘¤ ğ‘)(ğœ2 +ğœ ğ‘2 ).
ğ‘âˆˆA
Werearrangethefinalexpressiontoobtainanunbiasedestimateofğœ2:
ğœË†2 =
(cid:205) ğ‘âˆˆAğ‘¤ ğ‘(ğ‘ ğ‘âˆ’ğœ‡Ë† 0)2âˆ’(cid:205) ğ‘âˆˆAğ‘¤ ğ‘(1âˆ’ğ‘¤ ğ‘)ğœ ğ‘2
. (13)
1âˆ’(cid:205) ğ‘âˆˆAğ‘¤ ğ‘(1âˆ’ğ‘¤ ğ‘)
SinceE[ğ‘
ğ‘
|ğœ‡,ğœ] =ğœ‡andVar[ğ‘
ğ‘
|ğœ‡,ğœ] =ğœ2+ğœ ğ‘2,weestimateğœ‡bytakingaweightedaverageofğ‘ ğ‘s,withtheweights
proportionaltotheinverseofthevariance,butwithğœË†2pluggedinforğœ2:
ğœ‡Ë†=
(cid:205) ğ‘âˆˆAğ‘ ğ‘/(ğœË†2+ğœ ğ‘2)
. (14)
(cid:205) ğ‘âˆˆA1/(ğœË†2+ğœ ğ‘2)
Thelastmissingpieceisğœ2,forwhichweusethepooledestimatefromEq.(6).
ğ‘
Combiningitalltogether,weusethepooledestimatesofvarianceğœË† ğ‘2andtheweightedmeanğœ‡Ë† 0alongsideobservations
ğ‘ ğ‘tocalculateğœË†2usingEq.(13);thenwecalculateğœ‡Ë†usingEq.(14);andfinallywecalculateğœ‡Ë† ğ‘eband(ğœË† ğ‘eb)2usingEq.(9).
C ADDITIONALDIABETESEXPERIMENTS
InFigure7,weevaluatethequalityofthepointestimatesproducedbythethreebest-performingmethods.InFigure8,
wecomparetheperformanceofthestructuredregressionapproachwithanintercept-onlymodel.20 ChristineHerlihy,KimberlyTruong,AlexandraChouldechova,andMiroslavDudÃ­k
AUC SEL FNR FPR ACC PPV
0.15
method
JS
0.10
EB
structured
0.05 regression
0.00
allsmall large allsmall large allsmall large allsmall large allsmall large allsmall large
groups groups groups groups groups groups
Fig.7. Meanabsoluteerrorofestimatesof6metricsusing3best-performingmethodsondiabetesdata.Averagedacrossallgroups,small
groups(sizeatmost25),andlargegroups(sizeabove25),across20drawsofevaluationdataset.
AUC SEL FNR FPR ACC PPV
0.15 method
intercept
0.10 only
structured
regression
0.05
0.00
allsmall large allsmall large allsmall large allsmall large allsmall large allsmall large
groups groups groups groups groups groups
Fig.8. Comparisonofstructuredregressionwiththeintercept-onlymodel.Showingmeanabsoluteerror,averagedacrossallgroups,
smallgroups(sizeatmost25),andlargegroups(sizeabove25),across20drawsofevaluationdataset.
D SYNTHETICDATAGENERATION
Togeneratesyntheticdata,weusetheground-truthdiabetesdatasetasdescribedinÂ§5.1,butwithdifferentvaluesğ‘ŒË†.
Specifically,weconsidertheperformancemetricğ‘š(ğ‘) =E ğ‘[ğ‘ŒË† ](thisisquitesimilartoselectionrateorworderror
rate)andgenerateğ‘ŒË† insuchawaythatground-truthmetricvaluesğœ‡ haveaspecificstructure.Weconsider4different
ğ‘
ground-truthstructures,whichwerefertoasmodel ,model ,model ,andmodel ,dependingwhich
age age+rc ageÂ·rc expl
variablestheydependonandhow,withâ€œ+â€denotingadditivedependenceandâ€œÂ·â€presenceofinteractions:
Modelname Ground-truthvalueofğœ‡ Data-generatingprocess
ğ‘
model age ğœ‡ ğ‘ =0.35âˆ’0.3Â·ğœ™ ağ‘ ge,40â€“60 ğ‘ŒË† =Bernoulli(ğœ‡ ğ´)
model expl ğœ‡ ğ‘ =âˆ’0.93+0.16Â·E Dğ‘[ğ‘‹ number_diagnoses] ğ‘ŒË† =N(ğœ‡ ğ´,0.1)
model age+rc ğœ‡ ğ‘ =0.65âˆ’0.15Â·ğœ™ ağ‘ ge,40â€“60âˆ’0.45Â·ğœ™ rğ‘ ace,white ğ‘ŒË† =Bernoulli(ğœ‡ ğ´)
model ageÂ·rc ğœ‡ ğ‘ =0.32âˆ’0.27Â·ğœ™ ağ‘ ge,40â€“60Â·ğœ™ rğ‘ ace,white ğ‘ŒË† =Bernoulli(ğœ‡ ğ´)
ModelcoefficientshavebeenchosentoensurethatinallcasesE [ğ‘ŒË† ] â‰ˆ0.27and(cid:0)Var [ğ‘ŒË† ](cid:1)1/2 â‰ˆ0.44.
D D
rorre
etulosba
naem
rorre
etulosba
naem