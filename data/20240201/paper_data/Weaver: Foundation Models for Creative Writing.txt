Weaver: Foundation Models for Creative Writing
Tiannan Wang Jiamin Chen Qingrui Jia Shuai Wang Ruoyu Fang Huilin Wang
Zhaowei Gao Chunzhao Xie Chuou Xu Jihong Dai Yibin Liu Jialong Wu Shengwei Ding
Long Li Zhiwei Huang Xinle Deng Teng Yu Gangan Ma Han Xiao Zixin Chen
Danjun Xiang Yunxia Wang Yuanyuan Zhu Yi Xiao Jing Wang Yiru Wang Siran Ding
Jiayang Huang Jiayi Xu Yilihamu Tayier Zhenyu Hu Yuan Gao Chengfeng Zheng
Yueshu Ye Yihang Li Lei Wan Xinyue Jiang Yujie Wang Siyu Cheng Zhule Song
Xiangru Tang Xiaohua Xu Ningyu Zhang Huajun Chen
Yuchen Eleanor Jiang* Wangchunshu Zhou*
AIWaves Inc.
Abstract
This work introduces Weaver, our first family of large language models (LLMs) dedicated to
content creation. Weaver is pre-trained on a carefully selected corpus that focuses on improving
the writing capabilities of large language models. We then fine-tune Weaver for creative and
professional writing purposes and align it to the preference of professional writers using a suit of
novel methods for instruction data synthesis and LLM alignment, making it able to produce more
human-like texts and follow more diverse instructions for content creation. The Weaver family
consists of models of Mini (1.8B), Base (6B), Pro (14B), and Ultra (34B) sizes, suitable for
different applications and can be dynamically dispatched by a routing agent according to query
complexity to balance response quality and computation cost. Evaluation on a carefully curated
benchmarkforassessingthewritingcapabilitiesofLLMsshows Weaver modelsofallsizesoutperform
generalist LLMs several times larger than them. Notably, our most-capable Weaver Ultra model
surpasses GPT-4, a state-of-the-art generalist LLM, on various writing scenarios, demonstrating the
advantage of training specialized LLMs for writing purposes. Moreover, Weaver natively supports
retrieval-augmented generation (RAG) and function calling (tool usage). We present various use
cases of these abilities on improving AI-assisted writing systems, including integration of external
knowledgebases,tools,orAPIs,andprovidingpersonalizedwritingassistance. Furthermore,wedis-
cussandsummarizeaguidelineandbestpracticesforpre-trainingandfine-tuningdomain-specificLLMs.
Weaveriscurrentlyaccessibleatwww.wawawriter.com,ourinnovativehuman-AIcollaborativewriting
platform(FortheEnglishversionof WawaWriter,seewww.wawawriter.com/en). Wediscussafew
innovationsoftheplatformfromtheperspectiveofhuman-computerinteractiontoexplainhowitwill
revolutionizetraditionalAI-assistedwritingsystems.
*Correspondingauthors:{eleanor,chunshu}@aiwaves.cn
4202
naJ
03
]LC.sc[
1v86271.1042:viXraContents
1 Introduction 4
2 Pre-training 6
2.1 Model Family . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.2 Pre-training Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
2.3 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
3 Data Synthesis 8
3.1 Abilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.1.1 Instruction Following . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.1.2 Instruction Annotation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
3.1.3 Evaluation (Literary Critic) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.1.4 Retrieval-Augmented Generation . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.1.5 Function Calling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.2 Instruction Backtranslation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.3 Constitutional DPO: Learning From Principled Negative Examples . . . . . . . . . . . 12
4 Alignment 14
4.1 Supervised Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.1.1 Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.1.2 Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.2 Preference Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.2.1 Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.2.2 Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
5 Evaluation 14
5.1 WriteBench . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
5.2 Compared Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
5.3 LLM-based Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
5.4 Human Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
5.5 User Study. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
6 Introducing WawaWriter 17
6.1 Human-AI Collaborative Writing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
6.2 Integration of External Knowledge and Tools . . . . . . . . . . . . . . . . . . . . . . . 17
6.3 Personalized Writing Assistance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
26.4 Infinite Long Text Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
7 Discussion 18
A Appendix 24
A.1 Author Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
A.2 Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
A.3 Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
31. Introduction
Large language models (LLMs) (Anthropic, 2023; Brown et al., 2020; Google, 2023; Jiang et al.,
2023a;OpenAI,2022,2023;Radfordetal.,2018,2019;Gemini Team,2023;Touvronetal.,2023a,b;
Yin et al., 2023; Zhao et al., 2023) based on Transformers (Vaswani et al., 2017) have become a
prominent pathway to Artificial General Intelligence (AGI). LLMs acquire massive world knowledge
by learning to predict the next word on large-scale web corpora. The capabilities of LLMs have been
continuously increasing by scaling model sizes, dataset sizes, and computation. After pre-training,
LLMs can be aligned to support real-world use cases by supervised fine-tuning (Chung et al., 2022;
Sanh et al., 2022) and preference optimization techniques including reinforcement learning from
human feedback (RLHF) (Ouyang et al., 2022a; Wang et al., 2024; Zheng et al., 2023b) and direct
preference optimization (DPO) (Rafailov et al., 2023). The capabilities of LLMs have empowered
various applications including ChatGPT, Claude, Bard, Microsoft Copilot, Character.AI, Notion AI, etc.
Recently, many specialized LLMs have been trained for different targeted usage scenarios. In general,
LLMs specialize according to the targeted domains (e.g., finance (Wu et al., 2023), healthcare (Yang
et al., 2022b), legal (Cui et al., 2023), etc.) and tasks (e.g., role-playing (Wang et al., 2023d),
coding (Rozi√®re et al., 2023), etc.). However, the ability of LLMs to write human-like texts and
produce creative content, which is a critical use case of LLM applications such as ChatGPT, is mostly
overlooked by the community.
In this report, we focus on the literature domain and the task of writing, or content creation,
and introduce Weaver, a family of LLMs dedicatedly pre-trained and aligned for this purpose. The
name "Weaver" symbolizes the model‚Äôs proficiency in skillfully amalgamating linguistic elements,
akin to the way a craftsman weaves threads to form a fabric. We answer four main questions in this
technical report: why we need Weaver, how we train Weaver, how Weaver performs, and what
we build with Weaver.
Whyweneed Weaver? DespitegeneralistLLMs
such as GPTs already possessing general writ-
ing skills and helping billions of users in vari-
8.6
Weaver Ultra
ous writing scenarios, they often struggle to pro-
8.4
duce human-like texts in specific writing scenar- GLM4
ios such as writing stories, fiction, social media 8.2 GPT-4
Weaver Pro
copies, blogs, papers/thesis, etc. We analyze Yi-34B 8.0
Claude2
the behavior of pre-trained base LLMs such as
7.8 Weaver BaseQwen-14B Qwen-72B
LLaMA and aligned LLMs such as ChatGPT and Weaver Mini
Yi-6B
LLaMA-chatandbelievethislimitationoriginates 7.6
from both the pre-training stage and the align- 7.4
ment stage. On one hand, generalist LLMs are
7.2 Qwen-1.8B
pre-trained on massive low-quality web texts or
11..88 66..00 1144..00 3344..00 72.0 UUUnnnkkknnnooowwwnnn
machine/AI-generated texts. Consequently, ex- Number of Model Parameters (Billions)
isting LLM backbones tend to produce seemingly
Figure 1 | Comparison between Weaver and
fluent texts that are not creative enough and lack
generalist LLMs on WriteBench.
human-like styles. On the other hand, during
the alignment stage, state-of-the-art LLMs such
as GPT-4 are instruction-tuned using instruction-response pairs annotated by crowdsource annotators
(Ji et al., 2023; Shen et al., 2023; Wang et al., 2023c). However, most of the annotators are not
professional writers or content creators and the annotation guidelines only require them to produce
helpful and harmless responses (Ouyang et al., 2022b). As a result, the crowdsourced data for
supervised fine-tuning is less stylish and lacks creativity. Furthermore, most popular preference
4
erocS
llarevO
hcneBetirWoptimization methods such as RLHF and DPO optimize the model on model-generated data pairs,
making them less suitable for enhancing the creativity of LLMs.
These factors make current generalist LLMs lack creativity and unable to produce human-style
texts despite they are super powerful in other applications such as writing codes and answering
general questions. We believe this phenomenon will continue to be amplified given that the amount
of LLM-generated texts on the internet is exponentially growing and most LLMs are aligned using
texts produced by other LLMs. Therefore, we believe it is necessary to train domain-specific LLMs
dedicatedtowritingpurposesthatarecreativeandgeneratehuman-liketextsinordertofullyexploit
the potential of AI-generated content (AIGC).
How we train Weaver? To address the aforementioned issues limiting generalist LLMs‚Äô creative
writingability,wecarefullydesignasuiteofstrategiesforautomateddatacollection,dataannotation,
anddatafilteringforpre-trainingandalignment. Thismakesusabletopre-trainandalignWeaveron
diverse, human-like, and stylish texts. To be specific, we conduct extensive pre-training data filtering
and only keep high-quality content such as books, fiction, stories, and articles in the pre-training
corpus, making the pre-trained backbones more likely to produce human-like texts.
As for the alignment stage, we propose a new instruction backtranslation framework inspired by
LongForm (K√∂ksal et al., 2023) and Humpback (Li et al., 2023) that synthesize diverse and natural
instructions that correspond to high-quality outputs written by professional writers and preferred by
human consumers. Our instruction backtranslation framework translated the work of crowdsource
annotators from writing both instructions and outputs to simply collecting high-quality content such
as stories, fiction, articles, social media copies, and blog posts. This massively reduces the cost of
instruction data annotation and the requirement for crowdsource annotators while significantly
improving the quality of annotated data.
Moreover, we also propose a novel Constitutional DPO algorithm for preference optimization to
better align Weaver to the preference of professional writers and content creators. Constitutional
DPO is inspired by and combines the advantages of a few previous works including DPO (Rafailov
et al., 2023), Constitutional AI (Bai et al., 2022), Self-Align (Sun et al., 2023), and RLCD (Yang
et al., 2023a). Specifically, Constitutional DPO exploits expert (e.g., professional editors in our case)
annotated principles to synthesize negative examples that violate certain principles based on positive
examples that are sampled from the optimal policy (e.g., texts produced by professional writers or
content creators in our case). In contrast to the common practice of using DPO that uses LLMs to
produce preference annotation on two model-generated responses such as Zephyr (Tunstall et al.,
2023),thepairwisepreferencedatasynthesizedbyourapproachcontainslessnoisesincethenegative
example are deliberately synthesized to be of lower quality compared to the positive example. The
pairwise preference data generated by Consitutional DPO also contains more principled and targeted
learningsignalsthatcanbeadjustedbyhumanexpertsaccordingtotargetdomainsandapplications.
Furthermore, we propose to transform the annotation instructions and responses used in the
instructionbacktranslationandConstitutionalDPOstagesintoannotationinstructionsandevaluation
instructions. In this way, Weaver not only possesses abilities to follow writing instructions but can
also annotate writing instructions and evaluate writing outputs. We also curate instruction data for
retrieval-augmented generation (RAG) and function calling to enable Weaver to exploit external
knowledgeandtools. ThecombinationofdifferentdatasourcesmakesWeaveraversatilefoundation
model while specializing in creative writing.
How Weaver performs? Evaluating the content creation/writing ability of LLMs remains an
open problem since existing benchmarks for LLMs such as MMLU (Hendrycks et al., 2020) or MT-
Bench (Zheng et al., 2023a) mostly focus on reasoning, math, coding, or general questions instead of
5creative writing. Moreover, it is already notoriously hard to evaluate LLMs on general instructions,
anditbecomesmuchharderforcreativewritingtaskssinceliterarycriticisnon-trivialevenforhuman
experts, not to mention LLMs. To better evaluate Weaver and help the LLM community better
measureprogressonAIGC,wecarefullycurate WriteBench,abenchmarkforassessingthecreative
writing capabilities of LLMs and collect outputs from 10+ popular LLMs covering both open-source
and proprietary models.
We then conduct both LLM-based and human evaluation of Weaver and generalist LLMs on the
benchmark. Evaluation results confirm the superiority of Weaver compared to generalist LLMs. We
findthatWeaver Ultra,themost-capablemodelintheWeaverfamily,advancesthestate-of-the-art
in creative writing despite being 10+ smaller compared to GPT-41, the previous best performing LLM.
Other models in the Weaver family also surpass competitive generalist LLMs several times larger
than them. Our analysis and case studies show that the main source of improvements is because
Weaver can generate texts that are creative and human-like while generalist LLMs tend to produce
too ‚Äúpredictable‚Äù texts. To confirm that Weaver is truly helpful in real-world applications, we also
conduct a user study where human writers are asked to write stories (fiction writing) and blog posts
(non-fictionwriting)withWeaverandGPT-4. OuruserstudyshowsthatcomparedtoGPT-4,Weaver
improves the writers‚Äô productivity by 47% and helps writer produce better stories and articles at the
same time.
What we build with Weaver? Training specialized LLMs for writing is one side of enhancing AI-
assistedwritingexperience. Webelieveitisalsoveryimportanttobuildabetterhuman-AIinterfaceto
fullyexploitthepotentialof WeaveronAI-assistedwriting. Tothisend,weintroduce WawaWriter,
our innovative human-AI collaborative writing platform. Similar to recent AI writing products such
as Notion AI, WawaWriter provides a chat interface that allows users to provide diverse writing
instructions, instead of merely suggesting the next one or few sentences based on the current context
or polishing the content as in traditional applications. WawaWriter also takes a few steps further:
(1) we enable human-AI co-editing by allowing users to customize language agents (Zhou et al.,
2023b) that acts like a human collaborator by operating inside the editor simultaneously with users;
(2) we allow users to build personal knowledge bases by saving websites or uploading documents
and build a RAG pipeline that integrates knowledge bases to Weaver; (3) we propose to provide
personalized writing assistance by analyzing users‚Äô personal writing styles using LLMs based on
theirwritinghistoryontheplatformandusingtheresultstoguide Weaver‚Äôstextgenerationprocess.
By combining these innovations, WawaWriter aims to provide next-generation AI-assisted writing
experience that is more helpful and enjoyable.
In the following sections, we first describe the architectures and sizes of the Weaver family and
their pre-training stage. We then present details on the abilities of Weaver, how we synthesize
training data to help Weaver acquire these abilities and learn to produce human-like stylish texts,
and the details for the alignment stage. We also present our benchmark for evaluating the writing
abilities of LLMs and the evaluation results. Finally, we introduce the details of WawaWriter and
present how Weaver paves the way for next-generation AI-assisted writing experiences.
2. Pre-training
2.1. Model Family
Weaver models are language models built on top of Transformer decoders. We have adopted the
recent improvements from the design of LLaMA (Touvron et al., 2023a,b), the most popular open-
1Accordingtonon-officialrumoraboutthesizeofGPT-4
6source LLM, including a Pre-Norm structure with RMSNorm (Zhang and Sennrich, 2019) function,
SwiGLU(Shazeer,2020)astheactivationfunctionfortheFeed-ForwardNetwork,RotaryEmbedding
(Su et al., 2024) for positional encoding, and Grouped-Query Attention (GQA) (Ainslie et al., 2023).
The Weaver family consists of models of four different sizes: Mini, Base, Pro, and Ultra,
rangingfrom1.8Bto34Bparameters. Wetraindifferentmodelsizestosupportdifferentapplications
as the complexity of writing tasks varies a lot across different domains and use cases. All Weaver
models are initialized from powerful open-source LLMs. We provide detailed configurations and
descriptions of Weaver models in Table 1.
2.2. Pre-training Data
We then present an overview of pre-training data selection strategies and the resulting pre-training
datamixture. SinceWeavermodelsareinitializedfrompowerfulopen-sourceLLMsandthusalready
possess adequate world knowledge, the amount of continual pre-training data does not need to be
super large. We consider the continual pre-training stage to be the process where Weaver learns to
reallocate or re-balance its capabilities: the model allocates more capabilities to writing and content
creation while reducing the capabilities on other domains such as mathematics and coding.
Therefore,weonlyincludemanuallyverifieddatasourcesincludingvariouskindsofcontentsuch
as books, fiction, stories, news articles, papers, reports, social media copies, etc., in the pre-training
data. We combine rule-based and machine-learning-based methods to filter low-quality texts. In
addition to data sources and filtering, we also carefully control the data mixture between different
domains. Specifically, we mix fiction data (i.e., fiction and stories) and non-fiction data (i.e., articles,
papers, reports, etc.) with a ratio of 1 : 1. We also mix Chinese and English data with a portion of
4 : 1 to make Weaver supports both Chinese and English.
2.3. Training Details
We train Weaver using the standard autoregressive language modeling task where the model learns
to predict the next token based on the context of previous tokens. We train Weaver models with a
contextlengthof4096. Weshuffleandmergethedocuments,andthentruncatethemtothespecified
contextlengthstocreatetrainingbatches. WeincorporateMegatron-Deepspeed(Shoeybietal.,2019)
and Flash Attention2 (Dao, 2023; Dao et al., 2022) to improve computational efficiency and reduce
memory usage. We adopt the standard optimizer AdamW (Loshchilov and Hutter, 2017) and set the
hyperparameters ùõΩ = 0.9, ùõΩ = 0.95, and ùúÄ = 10‚àí8. We use a cosine learning rate schedule with a
1 2
specified peak learning rate for each model. The learning rate is decayed to a minimum learning rate
of 10% of the peak learning rate. All models are trained with BFloat16 mixed precision for training
stability. We present detailed pre-training configurations for each model in Table 1.
Context Sequence Learning
Name Params ùëõ ùëë ùëõ Tokens
layers model heads Length Batch Size Rate
Weaver Mini 1.8B 24 2048 16 4096 512 1e-4 50B
Weaver Base 6B 32 4096 32 4096 512 1e-4 50B
Weaver Pro 14B 40 5120 40 4096 512 1e-4 40B
Weaver Ultra 34B 60 7168 56 4096 520 5e-5 18B
Table 1 | Description for the Weaver family.
73. Data Synthesis
After pre-training, Weaver models contain a large amount of world knowledge and writing skills
and can produce human-like texts conditioning on high-quality contexts. To unlock these capabilities
for real-world applications, we need to curate a high-quality dataset for alignment. The format
and quality of the dataset significantly affect the coverage of abilities and the quality of aligned
models. As discussed in the Introduction, the common practice for alignment data collection of
existinggeneralistLLMsseverelylimitstheirwritingcapabilities. Inthissection,wedescribeourdata
synthesis framework in detail. We first describe the abilities we want to unlock during the alignment
stage and then present our proposed data synthesis methods for both the supervised fine-tuning and
the preference optimization stage.
3.1. Abilities
Wefirstdescribethecategoriesofabilitieswewanttounlockfor Weaver duringthealignmentstage.
3.1.1. Instruction Following
The first obvious ability we need to unlock is the ability to follow writing instructions and produce
human-like stylish texts. We cover various domains and tasks as listed below during data collection
and alignment training.
3.1.1.1 Domains
Fiction Writing: Fictionwritingreferstotheabilitiesofmodelstowritestoriesandfiction. Wedivide
fiction writing into several subdomains with respect to the length and the genre of the fiction. We
coverfictionandstoriesoflengthsrangingfromafewhundredtoafewmillioncharacters,andfiction
types including sci-fiction, romance, fantasy, horror, mystery, and thriller.
Creative Non-Fiction Writing: Creative non-fiction writing is a genre of writing that uses literary
styles and techniques to create factually accurate narratives. We cover typical creative non-fiction
writing cases including writing memoirs, biography, travelogue, journalism, social media copy, blog
posts, news articles, commentary, etc.
Marketing Writing: We also consider marketing writing, which involves writing business plans,
advertising copies, product promoting, marketing plans, etc. Marketing writing differs from previous
categories because it is highly application-oriented and the style of generated texts is not the most
important. However, marketing writing still requires human-like creativity to attract potential users.
Technical Writing: Technical writing includes tasks such as paper writing, patent writing, report
writing, etc. Technical writing requires more accuracy compared to creativity. However, writing-
specifictrainingcanstillbehelpfulbecauseitcanhelpmodelproducetextsthataccuratelyadhereto
the style required for specific scenarios.
3.1.1.2 Tasks
Content writing: Content writing is the basic task that requires the model to generate content
(i.e.,fiction,articles,etc.) basedoncertaininstructions. Writinginstructionsvaryintermsofwhether
the previous context is provided and how fine-grained the given instructions are. The task requires
the LLM to be able to understand and adhere to specific requirements expressed in the instructions
8while also producing texts that are consistent and coherent with previous contexts. For example, a
typical content writing instruction is: ‚ÄúPlease help me write a sci-fi about what will happen after
people finally achieve AGI.‚Äù
Outlining: Outlining is the task of writing outlines, which is a common practice for writers in both
fiction and non-fiction writing. As discussed in the literature of long text generation (Sun et al.,
2022; Yang et al., 2022a, 2023b; Zhou et al., 2019, 2023a), it is often helpful to let the model first
generate an outline before generating long texts. Outlines vary according to different domains and
the granularity/length of outlines. One example for the task of outlining is ‚ÄúPlease help me write an
outline of my annual work report.‚Äù
Polishing&Editing: Polishingandeditingrequirethemodeltoimprovethequalityofaparagraphor
rewrite it following the requirements expressed in the instructions. The task is closely related to the
task of grammatical error correction (Bryant et al., 2019; Ng et al., 2014) with a key difference that
the modifications are not necessarily grammatical errors. Compared to the task of academic writing
polishing described in Diao et al. (2023), we support customized fine-grained control of polishing or
editing requirements, which is important for human-AI interaction in AI-assisted writing systems. A
typical polishing instruction may look like this: ‚ÄúPlease help me revise the following texts, keep in
mind that the revised texts should be suitable for an academic paper.‚Äù
Style Transferring: The task of text style transfering requires the model to transform texts in one
styleintoanotherstyle. Forexample,onemaywanttotransformastoryintoascriptorturnareport
into a speechwriting. We cover both template-based style transfer that uses a template to provide
target style information (Guu et al., 2018; Lewis et al., 2020) and description-based style transfer
whichuseseitherakeyword(Huetal.,2017)orashortdescription(Zhouetal.,2023c)forthetarget
style. For example, one may ask the model to ‚ÄúTransform the following book chapter into a script.‚Äù
Expanding/Simplifying: Text expanding and simplifying requires the model to revise an input
paragraph to make it longer or shorter according to certain instructions. Text summarization and
summary-to-article generation can be regarded as two extreme cases of this task. One exemplar
instruction is: ‚ÄúPlease help me summarize this paragraph into one sentence.‚Äù.
Brainstorming: Brainstorming requires the model to help users come up with creative ideas based
on the current context and user instructions. A typical brainstorming instruction is: ‚ÄúPlease give
me 5 possible character descriptions for a villain to appear in the next chapter, including his name,
appearance, occupation, and background.‚Äù
Reviewing: Reviewing refers to the task of reading and analyzing a given piece of text critically and
then producing comments or revising suggestions. For example, one may ask the model to ‚ÄúPlease
take a look at my essay and list 5 suggestions to improve it.‚Äù
3.1.2. Instruction Annotation
We also train Weaver to support the instruction annotation task. As described in Humpback (Li
et al., 2023) and LongForm (K√∂ksal et al., 2023), given a piece of text, the task requires the model
to generate an instruction to which the input texts may be the answer. However, vanilla instruction
backtranslation only supports the writing task. Therefore, for instruction annotation, we require
the model to synthesize an instruction-response pair based on a text span. The response can be the
text span, a part of the text span, or inferred from the text span. This substantially broadens the
scope for vanilla instruction backtranslation since most automatically mined text spans may not be
suitable for a certain instruction on itself while a part of the text span can be a valid response or
one may construct a high-quality instruction-response pair based on it. The instruction annotation
9ability enables Weaver to mine training data for itself on large-scale corpus, opening the possibility
of scalable self-training on web data.
3.1.3. Evaluation (Literary Critic)
ManyrecentworkexploredusingortrainingLLMstoevaluategeneralinstructionfollowingtasks(Chan
et al., 2023; Jiang et al., 2023b; Wang et al., 2023b). However, we find generalist LLMs require
extensive prompting skills to make them suitable for evaluating tasks related to creative writing.
Moreover, since almost all students majoring in creative writing are also required to take literary
critic courses, we think learning to perform literary critic may be helpful for the model to produce
better texts as well. Therefore, we also train Weaver to judge the quality of the responses to writing
instructions and do pairwise comparison of two responses.
We collect human preference between model outputs in WawaWriter, our AI-assisted writing
platform and convert the collected preference data to training data for LLM-based evaluation with
carefully curated templates.
3.1.4. Retrieval-Augmented Generation
The ability of retrieval-augmented generation (RAG) (Gao et al., 2023; Lewis et al., 2020), i.e.,
generatingresponsesbyreferringtoexternalknowledgeorreferencesascontext. RAGisanimportant
technique that helps LLMs generate more accurate and informed responses. It can be especially
helpful for writing purposes since it‚Äôs common for human writers to refer to other text samples when
writing fiction or articles. However, most existing LLMs purely rely on prompt engineering to do RAG
and do not perform RAG training during alignment. We believe this limits the ability of LLMs to
make use of retrieved contexts. Therefore, we propose to include RAG-aware training data during
alignment to enhance Weaver‚Äôs retrieval-augmented generation ability. Specifically, we augment
10% percent of training data by appending a relevant context obtained by retrieving the paragraph
most similar to the target response. In this way, Weaver learns to write by referring to external
contexts and is thus more compatible with RAG techniques compared to most existing LLMs.
3.1.5. Function Calling
TheabilitytousetoolsisalsoveryimportantforLLMs(Schicketal.,2023). Thisability,alsoreferred
to as ‚Äúfunction calling‚Äù, is also helpful for writing because the model may need to search the internet
for references or call editor APIs when doing human-AI collaborative writing. To unlock the function
calling ability, we include an open-source function calling dataset2 into supervised fine-tuning data.
We also propose a new pipeline to synthesize more diverse function calling data by first using GPT-4
to synthesize diverse environments with multiple tools and APIs, as well as their documentation.
We then randomly select one API at a time and ask GPT-4 to imagine a situation where the API can
be helpful and the plausible arguments for the API. We then reason what one may instruct an LLM
in that situation so that the API should be used with the arguments. Finally, similar to how GPTs
support function calling, we train Weaver to use tools by selecting the right API and generating the
arguments given the instructions and the contexts.
3.2. Instruction Backtranslation
We then describe our proposed improved pipeline for instruction backtranslation. The motivation
for doing instruction backtranslation instead of instruction augmentation methods such as self-
2https://huggingface.co/glaiveai
10Domain Subdomain Description Source
Fiction Writing Full Novel Web novel, over 1M Proprietary
words
Short Story Web stories, 10k-20k Proprietary
words
CreativeNon-FictionWriting Red Top liked and com- Picked
mented posts on Red
Zhihu Top upvoted posts on Picked
Zhihu
Weibo Top liked posts on Picked
Weibo
WeChat Articles Top read articles on Picked
WeChat
DouBan Top liked posts on Picked
DouBan
News & Blogs Popular news/blogs Picked
Technical Writing Papers Academic papers on Picked
CNKI
Essay Online essays Picked
Contract Contractsfromonline Picked
sources
Reports Reports for work, Proprietary
business, science, etc.
Copies Business & Govern- Proprietary
ment copies
Marketing Writing Business Plans Business plans for Proprietary
projects and startups
Industry Report Research report for Proprietary
different industries
Advertising Copy Popular copies for ad- Picked
vertisements
Marketing Plan Marketing plans for Picked
products & services
Product Overview Articles advertising Picked
products
Table 2 | Description of SFT Data sources. We combine similar subdomains in the same fields for
simplicity. Theentiretrainingsetcovers34subdomainsandaround500,000instruction-outputpairs.
‚ÄúPicked‚Äù means the raw data in the corresponding domains are manually selected.
instruct (Wang et al., 2023a) is very simple: we want to align Weaver on high-quality, stylish, and
11human-written texts. To achieve this goal, we first collect high-quality stories, fiction chapters, and
copies of different domains. We list the categories of collected texts in Table 2.
We then use a carefully designed few-shot prompt template to synthesize instruction-response
pairs for all aforementioned writing tasks. Specifically, for each subdomain-task pair, we annotate 5
cases of how one can write an instruction-response pair, including both the annotated results and the
rationales for the annotation process: we first select a text span from a case as the output (except
for outlining, brainstorming, and reviewing tasks where the output is transformed from the selected
text span with an additional prompt). We then identify or produce the context for the output. For
example, for the polishing task, the context should be a worse version of the target output, so we
can modify the wording and structure of the target output to make it look worse. Then we infer
the instruction that one may use to transform the context to the output. Taking the polishing task
as an example again, we need to reason what modifications are made and synthesize the polishing
instructions accordingly. For each unlabeled case, we use the annotated cases as few-shot exemplars
and ask GPT-4 to first generate the annotation process in the Chain-of-Thought style (Wei et al.,
2022) and then produce the synthesized instruction-response pairs. The instruction backtranslation
pipeline is illustrated in Figure 1. We synthesize 500,000 high-quality instruction-response pairs
across all domains and tasks with this pipeline. Finally, we do an instruction data selection procedure
followingthepracticedescribedin(Liuetal.,2023): wefirstscoreallinstruction-responsepairswith
GPT-3.5-turboandthenselecttop-rankeddataineachsubdomain-taskpairforsupervisedfine-tuning.
Specifically, we score each instruction-response pair based on the quality and the diversity of the
instruction and the relevance between the instruction and the response.
[Guidelines]Youareteachingstudentstheprincipleswhilewriting
[Domain]TechnicalWriting
[domain].Iwillgiveyouaninstructionanditsacceptedoutput.
[Principle1]Theargumentsshouldbeillustratedlogically‚Ä¶
Basedonthisoutput,youneedtoproposearejectedoutputwhich
[Instruction]Helpmewriteapaper‚Ä¶
violatessuchprinciple.Hereisanexample:
[Example-Accepted]Theresultswelldemonstratethe‚Ä¶.
[Example-Rejected]Asweconductedexperiments,itisgood‚Ä¶
Random [Domain]TechnicalWriting
sampling
[Domain]CreativeNon-fictionWriting [Principle]Theargumentsshouldbeillustratedlogically‚Ä¶
[Principle2]Thecontentsshouldbeeye-catching‚Ä¶ [Instruction]Helpmewriteapaper‚Ä¶
Editors [Instruction]Reportanaccidentwithblackbears‚Ä¶ [Example-Accepted]Theresultswelldemonstratethe‚Ä¶.
[Example-Accepted]Blackbearsrarelyattack.Buthere‚Äôs‚Ä¶ [Example-Rejected]Asweconductedexperiments,itisgood‚Ä¶
[Example-Rejected]Blackbearsattackinsomecases‚Ä¶
Nowwhatyouneedtodois:
SFT Datasets
Here is a rejected output regarding the Technical Writing [Domain] Technical Writing
Principlethattheargumentsshould be logically illustrated: [Instruction] Help me write a popular science article ‚Ä¶.
[Output] √†[Output-Accepted]: In the ever-evolving landscape of
artificial intelligence, the emergence of large language models
[Output-Rejected]: The accidental discovery of small language (LLMs) has sparked a revolution in how machines understand and
models (LLMs) has led to a minor shift in how machines mimic GPT-4 generate human language. These colossal algorithms, with their
and scramble human language. These tiny formulas, with their billions of parameters ‚Ä¶
handful of parameters, have stumbled beyond their intended‚Ä¶
Preference Data for Direct Preference Optimization (DPO)
Figure 2 | Illustration of the Constitutional DPO framework.
3.3. Constitutional DPO: Learning From Principled Negative Examples
Finally,weproposeConstitutionalDPO,anovelalignmentmethodthatencouragesLLMstolearnfrom
preference data consisting of samples from the optimal policy and ‚Äúprincipled‚Äù negative examples
synthesized with AI feedback. Our approach combines the advantages of Constitutional AI (Bai et al.,
2022; Sun et al., 2023), which train reward models based on principles written by human experts,
RLCD (Yang et al., 2023a), which prompt LLMs to generate positive/negative examples and train
reward models with AI-generated preference data, and DPO (Rafailov et al., 2023), which omits
12Table 3 | Examples of expert-annotated principles in four domains and sampled tasks.
Domain Task Principles
The content should be created to encourage readers to
Content Writing
Creative Non- engage in interactions, comments, etc.
fiction Writing Polishing & Editing The revised content should align with the original text.
Brainstorming The content should refrain from pre-judging ideas.
The generated content should avoid bias toward certain
Content Writing
Technical Writing genders, professions, regions, etc.
The style of the content should be consistent with the
Style Transferring
language style specified in the instructions.
The perspective should remain consistent with the out-
Content Writing
Fiction line or previous content.
The global outline should not be too brief or general,
Outlining
omitting key plot points.
Content Writing The content of the market writing should be accurate.
Marketing Writng
The summarized content should be all-encompassing,
Summarizing
leaving out no crucial points.
reward model training and does direct preference optimization.
Specifically, we first invite human experts including professional writers, editors, and content
creators to annotate principles for different writing tasks. Different from previous ‚Äúprinciple-based‚Äù
approaches that only write a short description of the principles, for each principle we also collect
one case adhering to the principle and one case violating the principle, as well as natural language
rationales explaining why the cases adhere or violate the principle. Then we sample a subset of the
instructiondatawiththehighestscoresintheaforementioneddatafilteringprocessandconsiderthem
as samples from the optimal policy as the output texts are carefully selected and instruction-output
pairs are top-ranked. For each sample, we first present the principles for the task and ask GPT to
analyze which principle can best explain why the response is of good quality. We then ask GPT to
synthesize a counterpart of the response violating the principle while adding minimal modifications
and do not affect other good aspects of the original response.
With the collected data, we consider the original-perturbed response pairs as (ùë¶ ùë§,ùë¶ ùëô) pairs and
do standard DPO training. In this way, each data pair contains critical training signals about the
corresponding principles and helps fine-tune the model to follow the principles. The preference data
synthesizedbyourapproachcontainsmuchlessnoisecomparedtostandardRLAIFpipeline,especially
in writing domains since LLMs struggles to do literary critic. Compared to RLCD, the most related
method for preference data generation, we consider high-quality SFT data instead of LLM-generated
as positive examples and use expert-written principles for negative example generation. This makes
the training signal less noisy and more principled.
134. Alignment
4.1. Supervised Fine-tuning
4.1.1. Data
To collect the dataset for supervised fine-tuning, we first collect high-quality content written by
human writers and content creators according to their metadata including their ratings, number of
reads,upvotes,andcomments. Weadopttheaforementioneddatasynthesisframeworktosynthesize
instructionfollowingdatacovering30+fine-graineddomainsandover10tasks,instructionannotation
data,textgenerationevaluationdata,retrieval-augmentedgenerationdata,andfunctioncallingdata.
Thecombinedinstructiontuningdatasetconsistsofaround1,000,000samples. Wethenrunthedata
filtering process and select 400,000 data points as the final dataset for supervised fine-tuning.
4.1.2. Training
We fine-tune the continual pre-trained models for 3 to 5 epochs. We use a cosine learning rate
scheduler with a peak learning rate of 1e-5 and 2e-5 for larger models (i.e., Weaver Ultra and
Weaver Pro)and4e-5forsmallermodels(i.e., Weaver Base and Weaver Mini)with5%warmup
steps. We train all models with a global batch size of 256. After supervised fine-tuning, we select the
best-performing checkpoint on an internal validation set for preference optimization.
4.2. Preference Optimization
4.2.1. Data
For preference optimization, we select 500 highest-rated samples in the data filtering stage for each
subdomain as positive examples for the Constitutional DPO pipeline. We collect over 200 principles
andtheircorrespondingfew-shotexemplars. Wegenerateonenegativeexampleperpositiveexample,
resulting in 25,000 preference data pairs.
4.2.2. Training
We fine-tune the supervised fine-tuned models using the conventional DPO algorithm. We train our
models for three to five epochs. We use a linear learning rate scheduler with a peak learning rate of
5e-7 and 5% warmup steps. We train Weaver Ultra using a global batch size of 40, while for the
othersweuse32andset ùõΩ =0.1. Weselectthebest-performingcheckpointontheinternalvalidation
set as the final Weaver models.
5. Evaluation
5.1. WriteBench
MostexistingbenchmarksforLLMs(Zhengetal.,2023a)andnaturallanguagegeneration(Jiangetal.,
2023c; Lin et al., 2020) focus on the reasoning ability or the general-purpose instruction following
abilityinsteadoftheabilityofLLMstoproducecreative,stylish,andhuman-liketextcontent. Tothis
end, we construct WriteBench, a new benchmark for assessing the writing capabilities of LLMs3.
Similar to how we collect training data for Weaver, WriteBench is designed to cover multiple
domainsandtasks. ToensureafaircomparisonbetweenWeaver andcomparedgeneralistLLMs,the
3WriteBenchwillbepublicallyavailableathttps://github.com/aiwaves-cn/WriteBench
14datacollectionanddataselectionprocessforinstructionsinWriteBenchisdonebyourindependent
evaluation team. The resulting WriteBench consists of over 1000 testing instructions covering
four domains including fiction writing, creative non-fiction writing, technical writing, and marketing
writing. The first release of the WriteBench benchmark is in Chinese since we want to measure the
Chinese writing capabilities of the compared models.
5.2. Compared Models
We compare Weaver with competitive Chinese LLMs including both open-sourced models and
proprietary models ofdifferent sizes, including GPT-4, GPT-3.5, GLM-4, Claude2, Gemini Pro, ERNIE-
Bot-4.0, ERNIE-Bot-3.5, Qwen-72B-Chat, Qwen-14B-Chat, Qwen-7B-Chat, Qwen-1.8B-Chat, YI-34B-
Chat,YI-6B-Chat,andChatGLM3-6B.Wedirectlyusethesameinstructionsin WriteBench asinput
prompts for all tested LLMs and collect the model outputs as responses.
Table 4 | LLM-based Evaluation Results
Models Style Relevance Creativity Overall
Weaver Ultra 8.94 8.96 7.71 8.54
GLM-4 8.83 9.55 6.58 8.32
GPT-4 8.80 9.45 6.32 8.19
Weaver Pro 8.52 8.45 7.3 8.09
YI-34B-Chat 8.70 9.17 6.26 8.04
Claude2 8.42 8.89 6.41 7.91
Qwen-72B-Chat 8.47 8.98 5.95 7.80
Weaver Base 8.61 8.81 5.89 7.77
Qwen-14B-Chat 8.51 8.85 5.89 7.75
Weaver Mini 8.41 8.38 6.35 7.71
Gemini Pro 8.39 8.79 5.88 7.69
Qwen-7B-Chat 8.40 8.80 5.81 7.67
Yi-6B-Chat 8.24 8.67 6.00 7.64
ChatGLM3-6B 8.16 8.70 5.86 7.57
GPT-3.5 8.37 8.65 5.60 7.54
ERNIE-Bot-3.5 8.24 8.22 5.71 7.39
ERNIE-Bot-4.0 8.15 8.05 5.61 7.27
Qwen-1.8B-Chat 7.97 7.86 5.66 7.16
5.3. LLM-based Evaluation
We first perform an LLM-based evaluation to do a coarse-grained evaluation of the compared models.
We use GPT-4 as the judge to score each instruction-response pair following the practice and prompt
templates in MT-Bench. The results are shown in Table 4. We find that in terms of writing style
and creativity, Weaver Ultra significantly outperforms all proprietary models including strong
competitors such as GPT-4 and GLM-4. GPT-4 and GLM-4 are better at the relevance metric because
they are at least few times larger than Weaver Ultra and thus have better instruction-following
ability. As for Weaver of other sizes, we can see that with only 14B parameters, Weaver Pro
outperforms all open-source models including those with 70B and 34B parameters, as well as most
proprietary models. Similarly, Weaver Base and Weaver Mini are also comparable with generalist
LLMs with more than two times their sizes. Overall, the results confirm the effectiveness of our data
synthesis and training framework for LLMs specialized in creative writing.
15Table 5 | Human Preference on Fiction Writing with the Elo Ranking System
Models Creativity Style Relevance Fluency Overall
Weaver Ultra 1682 1661 1689 1641 1657
GPT-4 1507 1513 1421 1534 1508
ERNIE-Bot-4.0 1404 1409 1564 1544 1477
Gemini Pro 1513 1469 1409 1360 1430
GLM-4 1391 1445 1415 1417 1425
Table 6 | Overall Human Preference with the Elo Ranking System
Models Creativity Style Relevance Fluency Overall
Weaver Ultra 1589 1590 1593 1588 1576
GLM-4 1482 1527 1491 1513 1521
GPT-4 1468 1505 1427 1501 1501
Gemini Pro 1548 1490 1434 1380 1454
ERNIE-Bot-4.0 1410 1385 1552 1515 1445
5.4. Human Evaluation
We then perform a human evaluation to compare Weaver with a few representative LLMs including
GPT-4, GLM-4, ERNIE-Bot-4.0, and Gemini-pro. We recruit 44 professional Chinese writers or editors
as human annotators in human evaluation. We adopt the practice in the ChatBot Arena4 benchmark
and let human annotators perform three-way pairwise comparisons between two model outputs
according to their creativity, stylish, relevance, and fluency. We collect 3540 comparison results
and compute the ELO rating of the compared models. The results on fiction writing and the overall
comparison are shown in Table 5 and Table 6, respectively. We can see that professional writers and
editors rates Weaver Ultra significantly better than compared models across all metrics. As for
other compared models, we find that GPT-4 and Gemini Pro are considered to produce more creative
andhuman-liketextscomparedtoGLM-4andERNIE-Bot,wesuspectthisisbecauseGLMandERNIE
are aligned using GPT distillation data, which probably harms their creativity.
5.5. User Study
A good LLM for AI-assisted writing should not only be best-performing on benchmarks but also truly
helpful in real-world writing scenarios. To evaluate how truly helpful Weaver is, we conduct a user
study where 5 professional writers are recruited as subjects. Each subject is provided with two chat
interfaces, one with Weaver Ultra and the other with GPT-4. We then let each subject write two
shortstories(withtwocarefullyselectedtopic)ofaround6,000wordswithtwosamechatinterfaces
powered by GPT-4 and Weaver Ultra respectively5. We measure the time used by the same writer
forfinishingthetwostoriesandaskaprofessionaleditortojudgetheirquality. Wefindthatcompared
to GPT-4, Weaver Ultra improves the efficiency of the writer by around 3 times. Furthermore, out
of 5 topics, the human editor prefer Weaver generated story for 4 times and can not decide the
winner for the remaining topic. Our user interview reveals that the efficiency improvement mainly
comes from the fact that Weaver is faster and generates more human-like texts that require less
4https://chat.lmsys.org/
5Toensurefaircomparison,wegiveenoughtimeandtrialsforthewriterstogetfamiliarwiththeinterfaceandthe
models.
16post-editing.
6. Introducing WawaWriter
Inthissection,wedescribe WawaWriter,anext-generationAI-assistedwritingplatformwebuildto
fully unleash the capabilities of Weaver. WawaWriter integrates key features of recent AI-assisted
writing platforms (e.g., Notion AI) including AI-assisted generation, polishment, and summarization
whilealsoimplementingafewnewinnovationsfornext-generationAI-writingexperience. Wedescribe
these innovations in the following sections.
6.1. Human-AI Collaborative Writing
One major innovation in WawaWriter is a new interface for human-AI collaborative writing, which
delivers a drastically different user experience compared to traditional AI-assisted writing platforms.
ThankstotheAgents(Zhouetal.,2023b)framework,weareabletobuildcontrollablewritingagents
that act like independent human collaborators/co-authors in standard collaborative editors such
as Google Docs or Notion. The writing agents understands the goal of the current document by
reading customized settings such as the title or a short description of the document. It then takes
actions according to the current content in the document and the recent actions of human users (or
other writing agents) that reveal their focus. Human users can also chat with the writing agents
in a chat interface to instruct them what to do. The ability of writing agents to use both external
APIs such as web search and build-in editor APIs such as bolding or adjusting the line space enables
them to accomplish tasks much more complex than what conventional AI assistants can do. With the
human-agent interaction feature in the Agents framework, WriteBench also supports collaborative
editing between multiple human writers and language agents. Users can customize their multiple
writing agents and collaborate with one or a few of them when writing stories or articles. Users can
specify tasks for each writing agent while multiple writing agents can also communicate with each
other to autonomously distribute labors.
6.2. Integration of External Knowledge and Tools
Another new feature of WawaWriter is that users can now build their own personal knowledge
bases via document uploading or saving web pages. WawaWriter automatically organizes and
summarizes the knowledge base and then uses them as references when writing stories and articles.
Specifically,wepromptanLLMtosplitdocumentsintochunksbasedontheirsemantics,embedthem
with our embedding model, and store them in a VectorDB. During writing, we dynamically retrieve
the entries of the user‚Äôs personal knowledge base using semantic search using the current context in
the user‚Äôs editor as the query. Following Socratic Models (Zeng et al., 2023), our knowledge base
also supports images in documents by using GPT-4V to do detailed captioning for each image and
then using the captions as entries representing the corresponding images. Users can also edit the
documents in their personal knowledge bases using all AI-writing features in WawaWriter. In
addition, writing agents described in the previous section can also access the personal knowledge
base of a user through function calling.
6.3. Personalized Writing Assistance
Different from current AI-assisted writing systems, WawaWriter provides personalized writing
assistance for different users that suits their writing styles and content preferences. To achieve, we
maintain a text-based user profile for each user which describes some basic writing habits and styles
17(e.g., choice of words and punctuation, preference for the length of sentences, etc.) of the user. The
userprofileisperiodicallyupdatedusinganLLMaccordingtotherecenttextswrittenbytheuserwith
a carefully a designed prompt. The user profile is then used as a prefix in the prompt for Weaver. In
addition to text-based user profiles, we also retrieve paragraphs that are most similar to the current
context in the editor and use them as references for RAG.
6.4. Infinite Long Text Generation
WawaWriteralsosupportsinfinitelongtextgenerationsinceWeavernativelysupportstherecurrent
prompting technique proposed by (Zhou et al., 2023a). Specifically, to generate a very long text, we
iteratively prompt Weaver to generate an outline based on the current context and then generate a
paragraph of text based on the generated outline. WawaWriter integrates the ‚Äústep-by-step‚Äù mode
and the ‚Äúcontinuous‚Äù mode in RecurrentGPT, where the next outline is either manually selected by
the user or automatically selected by an LLM. As discussed in Zhou et al. (2023a), this recurrent
prompting mechanism drastically improves the creativity, consistency, and relevance of the generated
long text, this is especially helpful for story/fiction writing with WawaWriter.
7. Discussion
In this technical report, we introduce Weaver, a family of LLMs specialized for writing endeavors.
Weaveriscontinuallypre-trainedoncarefullycurateddatasetsandthenalignedtothepreferencesof
professionalwritersandeditorsusinganoveldatasynthesisframework. WealsoreleaseWriteBench,
the first benchmark for evaluating the writing capabilies of LLMs. WriteBench covers multiple
domains and tasks related to writing. We compare Weaver with 10+ popular generalist LLMs
and find that Weaver Ultra is the current state-of-the-art on the benchmark. Our user study also
confirms the superiority of Weaver in real-world AI-assisted writing scenarios. The results also
confirm the effectiveness of our data synthesis pipeline for training domain-specific LLMs.
References
J. Ainslie, J. Lee-Thorp, M. de Jong, Y. Zemlyanskiy, F. Lebr√≥n, and S. Sanghai. Gqa: Train-
ing generalized multi-query transformer models from multi-head checkpoints. arXiv preprint
arXiv:2305.13245, 2023.
Anthropic. Introducing Claude, 2023. URL https://www.anthropic.com/index/introducin
g-claude.
Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen, A. Goldie, A. Mirhoseini,
C. McKinnon, C. Chen, C. Olsson, C. Olah, D. Hernandez, D. Drain, D. Ganguli, D. Li, E. Tran-
Johnson, E. Perez, J. Kerr, J. Mueller, J. Ladish, J. Landau, K. Ndousse, K. Lukosuite, L. Lovitt,
M. Sellitto, N. Elhage, N. Schiefer, N. Mercado, N. DasSarma, R. Lasenby, R. Larson, S. Ringer,
S. Johnston, S. Kravec, S. E. Showk, S. Fort, T. Lanham, T. Telleen-Lawton, T. Conerly, T. Henighan,
T.Hume,S.R.Bowman,Z.Hatfield-Dodds,B.Mann,D.Amodei,N.Joseph,S.McCandlish,T.Brown,
and J. Kaplan. Constitutional ai: Harmlessness from ai feedback, 2022.
T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,
G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh,
D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark,
C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei. Language models are few-shot
learners, 2020.
18C. Bryant, M. Felice, √ò. E. Andersen, and T. Briscoe. The BEA-2019 shared task on grammatical
error correction. In H. Yannakoudakis, E. Kochmar, C. Leacock, N. Madnani, I. Pil√°n, and T. Zesch,
editors,ProceedingsoftheFourteenthWorkshoponInnovativeUseofNLPforBuildingEducational
Applications, pages 52‚Äì75, Florence, Italy, Aug. 2019. Association for Computational Linguistics.
doi: 10.18653/v1/W19-4406. URL https://aclanthology.org/W19-4406.
C.-M. Chan, W. Chen, Y. Su, J. Yu, W. Xue, S. Zhang, J. Fu, and Z. Liu. Chateval: Towards better
llm-based evaluators through multi-agent debate, 2023.
H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, Y. Li, X. Wang, M. Dehghani, S. Brahma,
A.Webson,S.S.Gu,Z.Dai,M.Suzgun,X.Chen,A.Chowdhery,A.Castro-Ros,M.Pellat,K.Robinson,
D.Valter,S.Narang,G.Mishra,A.Yu,V.Zhao,Y.Huang,A.Dai,H.Yu,S.Petrov,E.H.Chi,J.Dean,
J. Devlin, A. Roberts, D. Zhou, Q. V. Le, and J. Wei. Scaling instruction-finetuned language models,
2022.
J. Cui, Z. Li, Y. Yan, B. Chen, and L. Yuan. Chatlaw: Open-source legal large language model with
integrated external knowledge bases, 2023.
T. Dao. FlashAttention-2: Faster attention with better parallelism and work partitioning. 2023.
T. Dao, D. Y. Fu, S. Ermon, A. Rudra, and C. R√©. FlashAttention: Fast and memory-efficient exact
attention with IO-awareness. In Advances in Neural Information Processing Systems, 2022.
S. Diao, Y. Lei, L. Pan, T. Fang, W. Zhou, S. S. Keh, M.-Y. Kan, and T. Zhang. Doolittle: Benchmarks
and corpora for academic writing formalization. 2023.
Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and H. Wang. Retrieval-augmented
generation for large language models: A survey. arXiv preprint arXiv:2312.10997, 2023.
Google. An important next step on our AI journey, 2023. URL https://blog.google/technolo
gy/ai/bard-google-ai-search-updates/.
K. Guu, T. B. Hashimoto, Y. Oren, and P. Liang. Generating sentences by editing prototypes.
Transactions of the Association for Computational Linguistics, 6:437‚Äì450, 2018. doi: 10.116
2/tacl_a_00030. URL https://aclanthology.org/Q18-1031.
D.Hendrycks,C.Burns,S.Basart,A.Zou,M.Mazeika,D.Song,andJ.Steinhardt. Measuringmassive
multitask language understanding. arXiv preprint arXiv:2009.03300, 2020.
Z. Hu, Z. Yang, X. Liang, R. Salakhutdinov, and E. P. Xing. Toward controlled generation of text. In
International conference on machine learning, pages 1587‚Äì1596. PMLR, 2017.
J.Ji,T.Qiu,B.Chen,B.Zhang,H.Lou,K.Wang,Y.Duan,Z.He,J.Zhou,Z.Zhang,etal. Aialignment:
A comprehensive survey. arXiv preprint arXiv:2310.19852, 2023.
A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. d. l. Casas, F. Bressand,
G. Lengyel, G. Lample, L. Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825, 2023a.
D.Jiang,Y.Li,G.Zhang,W.Huang,B.Y.Lin,andW.Chen. Tigerscore: Towardsbuildingexplainable
metric for all text generation tasks, 2023b.
Y.E.Jiang,T.Liu,S.Ma,D.Zhang,R.Cotterell,andM.Sachan.Discoursecentricevaluationofmachine
translation with a densely annotated parallel corpus. In Proceedings of the 2023 Conference of
theAssociationforComputationalLinguistics: HumanLanguageTechnologies,pages1550‚Äì1565,
Toronto, Canada, July 2023c. Association for Computational Linguistics. doi: 10.18653/v1/2023
.main.111. URL https://aclanthology.org/2023.acl-main.111.
19A. K√∂ksal, T. Schick, A. Korhonen, and H. Sch√ºtze. Longform: Optimizing instruction tuning for long
text generation with corpus extraction, 2023.
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. K√ºttler, M. Lewis, W.-t. Yih,
T. Rockt√§schel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances
in Neural Information Processing Systems, 33:9459‚Äì9474, 2020.
X. Li, P. Yu, C. Zhou, T. Schick, L. Zettlemoyer, O. Levy, J. Weston, and M. Lewis. Self-alignment with
instruction backtranslation, 2023.
B.Y.Lin,W.Zhou,M.Shen,P.Zhou,C.Bhagavatula,Y.Choi,andX.Ren. CommonGen: Aconstrained
text generation challenge for generative commonsense reasoning. In Findings of the Association
forComputationalLinguistics: EMNLP2020,pages1823‚Äì1840,Online,Nov.2020.Associationfor
Computational Linguistics. URL https://www.aclweb.org/anthology/2020.findings-e
mnlp.165.
W. Liu, W. Zeng, K. He, Y. Jiang, and J. He. What makes good data for alignment? a comprehensive
study of automatic data selection in instruction tuning, 2023.
I.LoshchilovandF.Hutter. Decoupledweightdecayregularization. arXivpreprintarXiv:1711.05101,
2017.
H. T. Ng, S. M. Wu, T. Briscoe, C. Hadiwinoto, R. H. Susanto, and C. Bryant. The CoNLL-2014
shared task on grammatical error correction. In H. T. Ng, S. M. Wu, T. Briscoe, C. Hadiwinoto,
R.H.Susanto,andC.Bryant,editors,ProceedingsoftheEighteenthConferenceonComputational
NaturalLanguageLearning: SharedTask,pages1‚Äì14,Baltimore,Maryland,June2014.Association
for Computational Linguistics. doi: 10.3115/v1/W14-1701. URL https://aclanthology.org
/W14-1701.
OpenAI. Introducing ChatGPT, 2022. URL https://openai.com/blog/chatgpt.
OpenAI. GPT4 technical report. arXiv preprint arXiv:2303.08774, 2023.
L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama,
A. Ray, et al. Training language models to follow instructions with human feedback. Advances in
Neural Information Processing Systems, 35:27730‚Äì27744, 2022a.
L.Ouyang,J.Wu,X.Jiang,D.Almeida,C.L.Wainwright,P.Mishkin,C.Zhang,S.Agarwal,K.Slama,
A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P. Welinder, P. Christiano,
J. Leike, and R. Lowe. Training language models to follow instructions with human feedback,
2022b.
A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al. Improving language understanding by
generative pre-training. 2018.
A.Radford,J.Wu,R.Child,D.Luan,D.Amodei,I.Sutskever,etal. Languagemodelsareunsupervised
multitask learners. OpenAI blog, 1(8):9, 2019.
R. Rafailov, A. Sharma, E. Mitchell, S. Ermon, C. D. Manning, and C. Finn. Direct preference
optimization: Your language model is secretly a reward model. 2023.
B. Rozi√®re, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin,
A. Kozhevnikov, I. Evtimov, J. Bitton, M. Bhatt, C. C. Ferrer, A. Grattafiori, W. Xiong, A. D√©fossez,
J. Copet, F. Azhar, H. Touvron, L. Martin, N. Usunier, T. Scialom, and G. Synnaeve. Code llama:
Open foundation models for code, 2023.
20V. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler, A. Raja,
M. Dey, M. S. Bari, C. Xu, U. Thakker, S. S. Sharma, E. Szczechla, T. Kim, G. Chhablani, N. Nayak,
D. Datta, J. Chang, M. T.-J. Jiang, H. Wang, M. Manica, S. Shen, Z. X. Yong, H. Pandey, R. Bawden,
T. Wang, T. Neeraj, J. Rozen, A. Sharma, A. Santilli, T. Fevry, J. A. Fries, R. Teehan, T. L. Scao,
S. Biderman, L. Gao, T. Wolf, and A. M. Rush. Multitask prompted training enables zero-shot
task generalization. In International Conference on Learning Representations, 2022. URL https:
//openreview.net/forum?id=9Vrb9D0WI4.
T. Schick, J. Dwivedi-Yu, R. Dessi, R. Raileanu, M. Lomeli, E. Hambro, L. Zettlemoyer, N. Cancedda,
andT.Scialom. Toolformer: Languagemodelscanteachthemselvestousetools. InThirty-seventh
Conference on Neural Information Processing Systems, 2023. URL https://openreview.net
/forum?id=Yacmpz84TH.
N. Shazeer. Glu variants improve transformer. arXiv preprint arXiv:2002.05202, 2020.
T.Shen,R.Jin,Y.Huang,C.Liu,W.Dong,Z.Guo,X.Wu,Y.Liu,andD.Xiong. Largelanguagemodel
alignment: A survey. arXiv preprint arXiv:2309.15025, 2023.
M. Shoeybi, M. Patwary, R. Puri, P. LeGresley, J. Casper, and B. Catanzaro. Megatron-lm: Training
multi-billionparameterlanguagemodelsusingmodelparallelism.arXivpreprintarXiv:1909.08053,
2019.
J. Su, M. Ahmed, Y. Lu, S. Pan, W. Bo, and Y. Liu. Roformer: Enhanced transformer with rotary
position embedding. Neurocomputing, 568:127063, 2024.
X. Sun, Z. Sun, Y. Meng, J. Li, and C. Fan. Summarize, outline, and elaborate: Long-text generation
via hierarchical supervision from extractive summaries. In N. Calzolari, C.-R. Huang, H. Kim,
J. Pustejovsky, L. Wanner, K.-S. Choi, P.-M. Ryu, H.-H. Chen, L. Donatelli, H. Ji, S. Kurohashi,
P. Paggio, N. Xue, S. Kim, Y. Hahm, Z. He, T. K. Lee, E. Santus, F. Bond, and S.-H. Na, editors,
Proceedingsofthe29thInternationalConferenceonComputationalLinguistics,pages6392‚Äì6402,
Gyeongju, Republic of Korea, Oct. 2022. International Committee on Computational Linguistics.
URL https://aclanthology.org/2022.coling-1.556.
Z. Sun, Y. Shen, H. Zhang, Q. Zhou, Z. Chen, D. Cox, Y. Yang, and C. Gan. Salmon: Self-alignment
with principle-following reward models, 2023.
Gemini Team. Gemini: A family of highly capable multimodal models, 2023.
H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozi√®re, N. Goyal,
E. Hambro, F. Azhar, etal. LLaMA:Open andefficientfoundationlanguagemodels. arXivpreprint
arXiv:2302.13971, 2023a.
H.Touvron,L.Martin,K.Stone,P.Albert,A.Almahairi,Y.Babaei,N.Bashlykov,S.Batra,P.Bhargava,
S. Bhosale, D. Bikel, L. Blecher, C. Canton-Ferrer, M. Chen, G. Cucurull, D. Esiobu, J. Fernandes,
J. Fu, W. Fu, B. Fuller, C. Gao, V. Goswami, N. Goyal, A. Hartshorn, S. Hosseini, R. Hou, H. Inan,
M.Kardas,V.Kerkez,M.Khabsa,I.Kloumann,A.Korenev,P.S.Koura,M.Lachaux,T.Lavril,J.Lee,
D. Liskovich, Y. Lu, Y. Mao, X. Martinet, T. Mihaylov, P. Mishra, I. Molybog, Y. Nie, A. Poulton,
J. Reizenstein, R. Rungta, K. Saladi, A. Schelten, R. Silva, E. M. Smith, R. Subramanian, X. E. Tan,
B. Tang, R. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. Yan, I. Zarov, Y. Zhang, A. Fan, M. Kambadur,
S. Narang, A. Rodriguez, R. Stojnic, S. Edunov, and T. Scialom. Llama 2: Open foundation and
fine-tuned chat models. CoRR, abs/2307.09288, 2023b. doi: 10.48550/arXiv.2307.09288. URL
https://doi.org/10.48550/arXiv.2307.09288.
21L.Tunstall,E.Beeching,N.Lambert,N.Rajani,K.Rasul,Y.Belkada,S.Huang,L.vonWerra,C.Fourrier,
N. Habib, N. Sarrazin, O. Sanseviero, A. M. Rush, and T. Wolf. Zephyr: Direct distillation of lm
alignment, 2023.
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, ≈Å. Kaiser, and I. Polosukhin.
Attention is all you need. Advances in neural information processing systems, 30, 2017.
B.Wang,R.Zheng,L.Chen,Y.Liu,S.Dou,C.Huang,W.Shen,S.Jin,E.Zhou,C.Shi,etal. Secretsof
rlhf in large language models part ii: Reward modeling. arXiv preprint arXiv:2401.06080, 2024.
Y.Wang,Y.Kordi,S.Mishra,A.Liu,N.A.Smith,D.Khashabi,andH.Hajishirzi. Self-instruct: Aligning
language models with self-generated instructions. In A. Rogers, J. Boyd-Graber, and N. Okazaki,
editors, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics
(Volume 1: Long Papers), pages 13484‚Äì13508, Toronto, Canada, July 2023a. Association for
Computational Linguistics. doi: 10.18653/v1/2023.acl-long.754. URL https://aclanthology
.org/2023.acl-long.754.
Y. Wang, Z. Yu, Z. Zeng, L. Yang, C. Wang, H. Chen, C. Jiang, R. Xie, J. Wang, X. Xie, W. Ye, S. Zhang,
andY.Zhang. Pandalm: Anautomaticevaluationbenchmarkforllminstructiontuningoptimization,
2023b.
Y. Wang, W. Zhong, L. Li, F. Mi, X. Zeng, W. Huang, L. Shang, X. Jiang, and Q. Liu. Aligning large
language models with human: A survey. arXiv preprint arXiv:2307.12966, 2023c.
Z. M. Wang, Z. Peng, H. Que, J. Liu, W. Zhou, Y. Wu, H. Guo, R. Gan, Z. Ni, M. Zhang, Z. Zhang,
W. Ouyang, K. Xu, W. Chen, J. Fu, and J. Peng. Rolellm: Benchmarking, eliciting, and enhancing
role-playing abilities of large language models, 2023d.
J. Wei, X. Wang, D. Schuurmans, M. Bosma, brian ichter, F. Xia, E. H. Chi, Q. V. Le, and D. Zhou.
Chain of thought prompting elicits reasoning in large language models. In A. H. Oh, A. Agarwal,
D. Belgrave, and K. Cho, editors, Advances in Neural Information Processing Systems, 2022. URL
https://openreview.net/forum?id=_VjQlMeSB_J.
S. Wu, O. Irsoy, S. Lu, V. Dabravolski, M. Dredze, S. Gehrmann, P. Kambadur, D. Rosenberg, and
G. Mann. Bloomberggpt: A large language model for finance, 2023.
K.Yang,Y.Tian,N.Peng,andD.Klein. Re3: Generatinglongerstorieswithrecursiverepromptingand
revision. In Y. Goldberg, Z. Kozareva, and Y. Zhang, editors, Proceedings of the 2022 Conference
onEmpiricalMethodsinNaturalLanguageProcessing,pages4393‚Äì4479,AbuDhabi,UnitedArab
Emirates, Dec. 2022a. Association for Computational Linguistics. doi: 10.18653/v1/2022.emnlp
-main.296. URL https://aclanthology.org/2022.emnlp-main.296.
K. Yang, D. Klein, A. Celikyilmaz, N. Peng, and Y. Tian. Rlcd: Reinforcement learning from contrast
distillation for language model alignment, 2023a.
K. Yang, D. Klein, N. Peng, and Y. Tian. DOC: Improving long story coherence with detailed outline
control. In A. Rogers, J. Boyd-Graber, and N. Okazaki, editors, Proceedings of the 61st Annual
Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3378‚Äì
3465, Toronto, Canada, July 2023b. Association for Computational Linguistics. doi: 10.18653/v1/
2023.acl-long.190. URL https://aclanthology.org/2023.acl-long.190.
X. Yang, A. Chen, N. PourNejatian, H. C. Shin, K. E. Smith, C. Parisien, C. Compas, C. Martin, A. B.
Costa, M. G. Flores, et al. A large language model for electronic health records. NPJ Digital
Medicine, 5(1):194, 2022b.
22S. Yin, C. Fu, S. Zhao, K. Li, X. Sun, T. Xu, and E. Chen. A survey on multimodal large language
models. arXiv preprint arXiv:2306.13549, 2023.
A. Zeng, M. Attarian, brian ichter, K. M. Choromanski, A. Wong, S. Welker, F. Tombari, A. Purohit,
M. S. Ryoo, V. Sindhwani, J. Lee, V. Vanhoucke, and P. Florence. Socratic models: Composing zero-
shot multimodal reasoning with language. In The Eleventh International Conference on Learning
Representations, 2023. URL https://openreview.net/forum?id=G2Q2Mh3avow.
B. Zhang and R. Sennrich. Root mean square layer normalization. Advances in Neural Information
Processing Systems, 32, 2019.
W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang, J. Zhang, Z. Dong, et al. A
survey of large language models. arXiv preprint arXiv:2303.18223, 2023.
L.Zheng,W.-L.Chiang,Y.Sheng,S.Zhuang,Z.Wu,Y.Zhuang,Z.Lin,Z.Li,D.Li,E.P.Xing,H.Zhang,
J. E. Gonzalez, and I. Stoica. Judging llm-as-a-judge with mt-bench and chatbot arena. 2023a.
R. Zheng, S. Dou, S. Gao, Y. Hua, W. Shen, B. Wang, Y. Liu, S. Jin, Q. Liu, Y. Zhou, et al. Secrets of
rlhf in large language models part i: Ppo. arXiv preprint arXiv:2307.04964, 2023b.
W. Zhou, T. Ge, K. Xu, F. Wei, and M. Zhou. Hierarchical summary-to-article generation, 2019. URL
https://openreview.net/forum?id=Hkl8Ia4YPH.
W. Zhou, Y. E. Jiang, P. Cui, T. Wang, Z. Xiao, Y. Hou, R. Cotterell, and M. Sachan. Recurrentgpt:
Interactive generation of (arbitrarily) long text, 2023a.
W. Zhou, Y. E. Jiang, L. Li, J. Wu, T. Wang, S. Qiu, J. Zhang, J. Chen, R. Wu, S. Wang, S. Zhu, J. Chen,
W. Zhang, N. Zhang, H. Chen, P. Cui, and M. Sachan. Agents: An open-source framework for
autonomous language agents, 2023b.
W. Zhou, Y. E. Jiang, E. Wilcox, R. Cotterell, and M. Sachan. Controlled text generation with natural
language instructions. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett,
editors, Proceedings of the 40th International Conference on Machine Learning, volume 202 of
Proceedings of Machine Learning Research, pages 42602‚Äì42613. PMLR, 23‚Äì29 Jul 2023c. URL
https://proceedings.mlr.press/v202/zhou23g.html.
23A. Appendix
A.1. Author Contributions
Tiannan Wang is the core contributor of Weaver. Tiannan is responsible for continual pre-training,
supervised fine-tuning, and preference optimization. Tiannan is also a main contributor for the data
synthesis and the benchmark/evaluation process.
Jiamin Chen is a main contributor of Weaver. Jiamin is responsible for WriteBench and is also
main contributor for data synthesis and model evaluation process.
Qingrui Jia is a main contributor for the data synthesis and supervised fine-tuning stages for fiction
writing. Qingrui also contributes to the data synthesis process for non-fiction writing.
Shuai Wang is responsible for the application and the deployment of Weaver and the prompt
engineering for WawaWriter.
Ruoyu Fang is a main contributor for the data synthesis process for continual pre-training and
supervised fine-tuning.
Huilin Wang, Chunzhao Xie, and Shengwei Ding are main contributors for the prompts inside
WawaWriter.
Zhaowei Gao, Chunzhao Xie, Jihong Dai, Jialong Wu, Long Li, Zhiwei Huang contributed to the
data synthesis process for non-fiction writing.
Chuou Xu, Yibin Liu, Xinle Deng contributed to the evaluation and benchmarking process.
Teng Yu, Jiayang Huang, Gangan Ma, Han Xiao, Zixin Chen Gangan Ma,Yiru Wang, Siran Ding
are responsible for marketing and operation of WawaWriter and contributed to the product.
Jiayi Xu, Yilihamu Tayier, Zhenyu Hu, Yuan Gao, Chegnfeng Zheng, Yueshu Ye are responsible
for the implementation of WawaWriter.
Lei Wan, Siyu Cheng, Xinyue Jiang, Siyu Cheng, and Zhule Song are responsible for the product
design of Weaver.
Xiangru Tang, Xiaohua Xu, Ningyu Zhang, Huajun Chen are academic collaborators that con-
tributed to the discussion process and the revision of the technical report.
YuchenEleanorJiangandWangchunshuZhouareprojectleadandareresponsiblefortheconceptu-
alization, division of labor, and project management for all parts of Weaver training, WriteBench
construction, and the productization of WawaWriter. They write the technical report together.
A.2. Acknowledgments
We would like to thank Canwen Xu for his insightful discussion, help on revising the draft, and
especiallyforhissuggestiononnamingthepaper. WewouldalsoliketothankAPUSfortheirsupport
oncomputationresources,ABAKA.AIfortheirsupportondatacollection,andZhejiangUniversityfor
general supports.
A.3. Case Study
We present a few case studies of content generated by Weaver Ultra and GPT-4:
24(cid:1285)(cid:1319)(cid:1707)(cid:1442)(cid:29517)(cid:1898)(cid:1365)(cid:5480)(cid:3693)(cid:30872)(cid:29287)(cid:35153)(cid:6493)(cid:5547)(cid:1707)(cid:1246)(cid:1275)(cid:30954)(cid:1609)(cid:3565)(cid:3565)(cid:7602)(cid:1472)(cid:2859)(cid:7294)(cid:5184)(cid:3238)(cid:32962)(cid:29353)(cid:30954)(cid:35094)(cid:29517)(cid:1898)(cid:29517)(cid:1898)(cid:1870)(cid:30139)(cid:30480)(cid:1645)(cid:4913)(cid:2399)(cid:5456)(cid:29287)(cid:1446)(cid:33020)(cid:29629)(cid:3401)(cid:1472)(cid:1246)(cid:29353)(cid:1863)(cid:5645)(cid:29291)
I. ÂÖ¨Âè∏Âü∫Êú¨‰ø°ÊÅØ
A. ÂÖ¨Âè∏ÁÆÄ‰ªã
1. ÂÖ¨Âè∏ÂêçÁß∞ ‰∏ãÈù¢ÊòØÊó•Êó•È°∫‰æõÂ∫îÈìæÁßëÊäÄËÇ°‰ªΩÊúâÈôêÂÖ¨Âè∏ÂÖ¨Âè∏ÂèëÂ±ïÊÉÖÂÜµÁöÑÂ§ßÁ∫≤ÁöÑÂèÇËÄÉÁ§∫‰æãÔºö
2. ÊàêÁ´ãÊó∂Èó¥
3. ÂÖ¨Âè∏Âú∞ÁÇπ I. ÂÖ¨Âè∏Ê¶ÇÂÜµ‰∏éÂèëÂ±ïÂéÜÁ®ã
4. Ê≥ï‰∫∫‰ª£Ë°® A. ÂÖ¨Âè∏ÂêçÁß∞ÂèäÊàêÁ´ãËÉåÊôØ
B. ÂÖ¨Âè∏ÊúçÂä°Âèä‰∫ßÂìÅ B. ÈáçË¶ÅÂèëÂ±ïÈáåÁ®ãÁ¢ë
1. ‰∏ªË¶ÅÊúçÂä°
2. ‰∫ßÂìÅÁâπÁÇπ II. ‰∏ªË¶Å‰∏öÂä°ËåÉÂõ¥
3. ‰∫ßÂìÅ‰∏éÊúçÂä°ÁöÑ‰∏ªË¶ÅÂÆ¢Êà∑Áæ§‰Ωì A. ÊúçÂä°È¢ÜÂüüÊ¶ÇËø∞
II. ÂÖ¨Âè∏ÂèëÂ±ïÂéÜÁ®ã B. ÁâπËâ≤ÊúçÂä°‰∏éÂàõÊñ∞Ê®°Âºè
A. ÂÖ¨Âè∏ÊàêÁ´ãÂàùÊúü
B. ‰∏ªË¶ÅÂèëÂ±ïÈò∂ÊÆµÂèäÈáçÂ§ß‰∫ã‰ª∂ III. ÂÆ¢Êà∑‰ª∑ÂÄºÂàõÈÄ†
C. ÁõÆÂâçÁöÑÂèëÂ±ïÁä∂ÂÜµ A. Âõ¥ÁªïÁî®Êà∑‰ΩìÈ™åÁöÑÊúçÂä°ÊàòÁï•
III. ÂÖ¨Âè∏‰∏öÁª©ÂíåÂ∏ÇÂú∫ËÆ§Áü•Â∫¶ B. ‰æõÂ∫îÈìæËß£ÂÜ≥ÊñπÊ°àÁöÑÊï¥Âêà‰∏é‰ºòÂåñ
A. ÂéÜÂπ¥‰∏öÁª©
B. ÊâÄËé∑Â•ñÈ°πÂíåËÆ§ËØÅ IV. ÊäÄÊúØÈ©±Âä®‰∏éÂàõÊñ∞
C. ‰∏éÂêåË°å‰∏öÁöÑÊØîËæÉ A. ÁßëÊäÄÂåñÁâ©ÊµÅÂπ≥Âè∞‰ªãÁªç
IV. ÂÖ¨Âè∏ÁöÑÊ†∏ÂøÉÁ´û‰∫â‰ºòÂäø B. ÊäÄÊúØÊúçÂä°ÁîüÊÄÅÁ≥ªÁªüÁöÑÊûÑÂª∫
A. ÊäÄÊúØ‰ºòÂäø
B. Â∏ÇÂú∫‰ΩçÁΩÆ V. Âêà‰Ωú‰ºô‰º¥‰∏éÂÆ¢Êà∑ÊúçÂä°ÁΩëÁªú
C. ‰∫ßÂìÅÊàñÊúçÂä°ÁöÑ‰ºòÂäø A. ÁîüÊÄÅÂêà‰ΩúÂπ≥Âè∞
D. Âõ¢ÈòüËµÑË¥® B. ÂÖ®ÁêÉ‰æõÂ∫îÈìæÁÆ°ÁêÜËÉΩÂäõ
V. ÂÖ¨Âè∏ÊñáÂåñ‰∏é‰ª∑ÂÄºËßÇ
A. ÂÖ¨Âè∏ÁöÑÊÑøÊôØÂíå‰ΩøÂëΩ VI. Êú™Êù•ÂèëÂ±ïÂ±ïÊúõ
B. ÂÖ¨Âè∏ÁöÑÊñáÂåñÂíå‰ª∑ÂÄºËßÇ A. Â∫îÂØπÁé∞‰ª£Áâ©ÊµÅË°å‰∏öÂèòÈù©
C. Á§æ‰ºöË¥£‰ªªÂíåË¥°ÁåÆ B. ÊèêÂçáÂÆ¢Êà∑ÂÖ®ÈìæË∑ØÁâ©ÊµÅÊúçÂä°Ë¥®Èáè
VI. ÂÖ¨Âè∏ÁöÑÊú™Êù•Â±ïÊúõ
A. ÂèëÂ±ïËßÑÂàí
B. ÁõÆÊ†áÂ∏ÇÂú∫
(cid:1285)(cid:3183)(cid:36325)(cid:2599)(cid:1246)(cid:1275)(cid:2399)(cid:5456)(cid:29287)(cid:2225)(cid:5488)(cid:1286)(cid:7628)‚Äú(cid:2504)(cid:1300)(cid:4913)(cid:32985)(cid:1912)(cid:29289)(cid:3087)(cid:32161)(cid:30834)(cid:1322)(cid:29324)(cid:4766)(cid:4186)(cid:2416)(cid:34685)‚Äù(cid:4913)(cid:29517)(cid:1404)(cid:1897)(cid:3528)(cid:5261)(cid:2439)(cid:1436)(cid:35924)(cid:29291)
I. ÂºïË®Ä
A. Â®±‰πêÁöÑÂÆö‰πâÂíå‰∏çÂêåÂΩ¢Âºè 1. ÊÇ¨ÁñëÊïÖ‰∫ãÁöÑÂºïÂÖ•
B. ÊèèËø∞Â®±‰πêË°å‰∏ö‰∏≠ÁöÑ‰∏Ä‰∫õÂ∏∏ËßÅÊÇ¨ÂøµÂíåÂ•áÈÅá -ÁÆÄÂçï‰ªãÁªçÊÇ¨ÁñëÊïÖ‰∫ãÂØπÊôÆÁΩóÂ§ß‰ºóÁöÑÂê∏ÂºïÂäõÂèäÂ®±‰πê‰ª∑ÂÄº„ÄÇ
C. ÊèêÂá∫ÊñáÁ´†ÁöÑ‰∏ªÈ¢òÔºöÊé¢ËÆ®Â®±‰πêËÉåÂêéÁöÑÊÇ¨ÁñëÊïÖ‰∫ã‰∏éÁîü -Á™ÅÂá∫ËøôÁ±ªÊïÖ‰∫ãËÉΩÂ§üÂºïÂèë‰∫∫Âº∫ÁÉàÂ•ΩÂ•áÂøÉÂíåÊé¢Á¥¢Ê¨≤ÁöÑÁâπÊÄß„ÄÇ
Ê¥ªÂ•áÈÅá
2. Â®±‰πêËÉåÂêéÁöÑÁúüË∞õ
II. Â®±‰πê‰∫ß‰∏öÁöÑÂÜÖÁßòÂíåÊÇ¨ÁñëÊïÖ‰∫ã -ÂàÜÊûêÂ®±‰πê‰∏≠Ëï¥Âê´ÁöÑÊôÆÈÅçÂøÉÁêÜÈúÄÊ±ÇÂíå‰∫∫ÊÄßÊé¢Á©∂„ÄÇ
A. ÂàÜÊûêÂ®±‰πêË°å‰∏öÁöÑËøê‰ΩúÊ®°Âºè -Êé¢ËÆ®ÊÇ¨ÁñëÊïÖ‰∫ãÂ¶Ç‰ΩïÊàê‰∏∫‰∫∫‰ª¨ÊîæÊùæÂíåÂøÉÁêÜÁñóÊÑàÁöÑÊâãÊÆµ„ÄÇ
B. Êè≠Èú≤‰∏Ä‰∫õÊú™Áü•ÊàñÈ≤ú‰∏∫‰∫∫Áü•ÁöÑË°å‰∏öÁßòÂØÜÂíåÊÇ¨ÁñëÊïÖ‰∫ã
C. ÂàÜ‰∫´‰∏Ä‰∫õÂ®±‰πêÂúà‰∫∫Â£´ÁöÑ‰∫≤Ë∫´ÁªèÂéÜÂíåÊïÖ‰∫ã 3. ÊÇ¨ÁñëÂâßÊ°à‰æãÂàÜÊûê
-ÈÄâÂèñ„Ää‰∏çÈÄüÊù•ÂÆ¢„ÄãÁ≠âÊÇ¨ÁñëÁîµÂΩ±ÔºåÊ∑±ÂÖ•ÂâñÊûêÊïÖ‰∫ãÊÉÖËäÇÂíåËßíËâ≤ÊûÑÈÄ†„ÄÇ
III. ÁîüÊ¥ª‰∏≠ÁöÑÂ•áÈÅá‰∏éÂ®±‰πêÁöÑÂÖ≥Á≥ª -ÂàÜÊûêÂâß‰∏≠ÁöÑÊÇ¨ÁñëÂÖÉÁ¥†Â¶Ç‰Ωï‰∏éËßÇ‰ºóÁöÑÂøÉÁêÜÈ¢ÑÊúüÁõ∏ÂåπÈÖç„ÄÇ
A. ËØ¶ÁªÜËß£Êûê‰∏Ä‰∫õÁîüÊ¥ª‰∏≠ÁöÑÂ•áÈÅáÊòØÂ¶Ç‰ΩïÊàê‰∏∫Â®±‰πêÈ¢òÊùê
ÁöÑ 4. ÁîüÊ¥ªÊïÖ‰∫ã‰∏éËßíËâ≤ÊâÆÊºî
B. ÂàÜ‰∫´‰∏Ä‰∫õ‰ªéÁîüÊ¥ª‰∏≠Â•áÈÅáËé∑ÂæóÁöÑÂ®±‰πêËßÇÁÇπÂíåËßÅËß£ -Â∞Ü‰∏™‰∫∫ÁîüÊ¥ª‰∏éÊÇ¨ÁñëÊïÖ‰∫ãÁõ∏ÂØπÊØîÔºåÂ±ïÁé∞‰∫∫‰ª¨Âú®Âπ≥Âá°ÁîüÊ¥ª‰∏≠ÈÅáÂà∞ÁöÑÂ•áÂ¶ôÂíå‰∏çÁ°ÆÂÆö„ÄÇ
C. ËÆ®ËÆ∫Â®±‰πêÂíåÁîüÊ¥ªÂ•áÈÅáÂØπ‰∫é‰∏™‰ΩìÂíåÁ§æ‰ºöÁöÑÈáçË¶ÅÊÑè‰πâ -ÈòêÈáäÁé∞‰ª£ÁîüÊ¥ªÊïÖ‰∫ã‰∏≠Â¶Ç‰ΩïÂÄüÈâ¥ÊÇ¨ÁñëÊïÖ‰∫ã‰∏≠ÁöÑÊÉÖËäÇÂíåÁ≠ñÁï•„ÄÇ
IV. Â®±‰πêË°å‰∏öÁöÑÂèëÂ±ïÂâçÊôØ‰∏éÂΩ±Âìç 5. Á§æ‰ºöÁé∞Ë±°‰∏éÂêØÁ§∫
A. ÂàÜÊûêÂΩìÂâçÂ®±‰πêË°å‰∏öÁöÑÂèëÂ±ïË∂ãÂäøÂíåÊú™Êù•ÂâçÊôØ -ËÄÉÂØüÁé∞‰ª£Á§æ‰ºö‰∏≠ÊÇ¨ÁñëÊïÖ‰∫ãÁöÑÊµÅË°åÔºåÊâÄÂ∏¶Êù•ÁöÑÊ≠£Èù¢ÂíåË¥üÈù¢ÂΩ±Âìç„ÄÇ
B. ËÆ®ËÆ∫Â®±‰πêË°å‰∏öÁöÑÂèëÂ±ïÂØπ‰∫éÁ§æ‰ºöÊñáÂåñÂíå‰∏™‰∫∫ÁîüÊ¥ªÁöÑ -ÊèêÂá∫ÊÇ¨ÁñëÊïÖ‰∫ã‰Ωú‰∏∫Êó•Â∏∏Â®±‰πê‰∏éËá™ÊàëÂèçÁúÅÁõ∏ÁªìÂêàÁöÑÊΩúÂäõ„ÄÇ
ÂΩ±Âìç
C. Êèê‰æõ‰∏Ä‰∫õÂÖ≥‰∫éÂ¶Ç‰ΩïÁêÜËß£ÂíåÂ∫îÂØπÂ®±‰πêË°å‰∏öÂèòÂåñÁöÑÂª∫ 6. ËØªËÄÖÂèÇ‰∏éÂíåÂàÜ‰∫´
ËÆÆ -ÈºìÂä±ËØªËÄÖÂàÜ‰∫´Ëá™Â∑±ÁªèÂéÜ‰∏≠ÁöÑ‚ÄúÊÇ¨ÁñëÊó∂Âàª‚Äù„ÄÇ
-ÁªÑÁªáËØÑËÆ∫Âå∫ÂíåÊäïÁ•®Ê¥ªÂä®ÔºåÂ¢ûÂä†ËØªËÄÖÁöÑÂèÇ‰∏éÊÑüÂíåÂáùËÅöÂäõ„ÄÇ
V. ÁªìËÆ∫
A. ÈáçÁî≥Â®±‰πêË°å‰∏öËÉåÂêéÁöÑÊÇ¨Áñë‰∏éÁîüÊ¥ªÂ•áÈÅáÁöÑÂÖ≥ËÅîÊÄß 7. ÁªìÊùüËØ≠
B. Ê¶ÇÊã¨ÊñáÁ´†ÁöÑ‰∏ªË¶ÅËßÇÁÇπÂíåÂèëÁé∞ -Ê¶ÇÊã¨ÊñáÁ´†Ë¶ÅÁÇπÔºåÊèêÂá∫‰∏Ä‰∏™Ê∑±ÂàªÁöÑÁªìËÆ∫„ÄÇ
C. ÂØπËØªËÄÖÁöÑÂêØÁ§∫ÂíåÂ∏åÊúõËØªËÄÖÂØπÂ®±‰πê‰∫ß‰∏öÊúâÊõ¥Â§öÁöÑ‰∫Ü -ÊøÄÂèëËØªËÄÖÂØπÊó•Â∏∏ÁîüÊ¥ª‰∏≠ÊÇ¨ÁñëÊïÖ‰∫ãÁöÑÂÖ¥Ë∂£ÂíåËÆ§ËØÜÔºå‰ΩøÊñáÁ´†ÂÖ∑ÊúâÂêØÂèëÊÄßÂíåÊÄùËÄÉ‰ª∑ÂÄº„ÄÇ
Ëß£ÂíåËÆ§ËØÜ
25(cid:6561)(cid:3118)(cid:1246)(cid:1275)PPT(cid:2399)(cid:5456)(cid:29287)(cid:32926)(cid:4492)(cid:33321)(cid:3726)Vision Pro(cid:1870)(cid:2802)(cid:1912)(cid:4913)(cid:1905)(cid:3548)(cid:7566)(cid:2941)(cid:2021)(cid:29349)(cid:29616)(cid:2642)(cid:3674)(cid:3702)(cid:4913)(cid:7612)(cid:4197)(cid:29287)(cid:32330)(cid:29394)(cid:1622)(cid:2619)(cid:6599)(cid:2673)(cid:2842)(cid:34642)(cid:1907)(cid:2241)(cid:1246)(cid:2251)(cid:4365)(cid:6550)(cid:1278)(cid:30139)(cid:32392)(cid:29287)(cid:3035)(cid:7597)
(cid:36382)(cid:5445)(cid:1285)19(cid:7597)(cid:29264)
ÂπªÁÅØÁâá1ÔºöÊ†áÈ¢òÈ°µ 1. ÂºïË®Ä(1-2È°µ)
-‰∏ªÈ¢òÔºöËãπÊûúVision ProÂèëÂ∏ÉÂêéÁöÑÂêÑÊñπÈù¢ÂΩ±ÂìçÂèäÂØπÊú™Êù•ÁöÑÈ¢ÑÊµã ÂπªÁÅØÁâá1: ÊºîËÆ≤ÂºÄÂú∫‰∏éÁõÆÁöÑ
-‰∏ªËÆ≤‰∫∫ÔºöÔºà‰Ω†ÁöÑÂêçÂ≠óÔºâ -‰ªãÁªçËãπÊûúVision ProÁöÑÂèëÂ∏ÉËÉåÊôØ
-Ê¶ÇËø∞Vision ProÁöÑ‰∏ªË¶ÅÁâπÁÇπ‰∏éÊΩúÂú®ÂΩ±Âìç
ÂπªÁÅØÁâá2-4ÔºöÁõÆÂΩï -ÈòêËø∞Á†îÁ©∂ËãπÊûúÊñ∞‰∫ßÂìÅÂØπ‰∏ñÁïåÂΩ±ÂìçÁöÑÈáçË¶ÅÊÄß
-ÂπªÁÅØÁâá2ÔºöËãπÊûúVision ProÁöÑÁâπÊÄßÁÆÄ‰ªã ÂπªÁÅØÁâá2: ÊäÄÊúØÂèëÂ±ïË∂ãÂäøÁÆÄËø∞
-ÂπªÁÅØÁâá3ÔºöÂØπÂ∏ÇÂú∫ÁöÑÂΩ±Âìç -ÂõûÈ°æÊäÄÊúØÂèëÂ±ïÂéÜÂè≤ÔºåÂ∞§ÂÖ∂ÊòØVR„ÄÅARÁöÑÂèëÂ±ïË∂ãÂäø
-ÂπªÁÅØÁâá4ÔºöÂØπÊ∂àË¥πËÄÖÁöÑÂΩ±Âìç -ÊèèËø∞ËãπÊûúÂú®ÊäÄÊúØÂèëÂ±ï‰∏≠ÁöÑËßíËâ≤ÂíåÂ∏ÇÂú∫Âú∞‰Ωç
ÂπªÁÅØÁâá5-6ÔºöËãπÊûúVision ProÁöÑÁâπÊÄßÁÆÄ‰ªã 2. ËãπÊûúVision ProÊ¶ÇËø∞(2-3È°µ)
-ÂπªÁÅØÁâá5ÔºöËÆæÂ§áÁâπÊÄßÂíåÊäÄÊúØËßÑÊ†º ÂπªÁÅØÁâá3: Vision ProÊäÄÊúØËßÑÊ†º
-ÂπªÁÅØÁâá6Ôºö‰∏éÂ∏ÇÂú∫‰∏äÂÖ∂‰ªñÁõ∏‰ºº‰∫ßÂìÅÁöÑÊØîËæÉ -Â±ïÁ§∫Vision ProÁöÑÊäÄÊúØËßÑÊ†ºÂíåÂàõÊñ∞ÁâπÊÄß
-‰∏éÂâç‰ª£‰∫ßÂìÅËøõË°åÊØîËæÉÔºåÁ™ÅÂá∫ÂÖ∂ËøõÊ≠•‰∏éÊîπËøõ
ÂπªÁÅØÁâá7-10ÔºöÂØπÂ∏ÇÂú∫ÁöÑÂΩ±Âìç ÂπªÁÅØÁâá4: Vision ProÁöÑËÆæËÆ°‰∏éÁî®Êà∑‰ΩìÈ™å
-ÂπªÁÅØÁâá7ÔºöÂØπÊô∫ËÉΩÊâãÊú∫ÂíåÂπ≥ÊùøÁîµËÑëÂ∏ÇÂú∫ÁöÑÂΩ±Âìç -ÈòêËø∞Vision ProÁöÑËÆæËÆ°ÁêÜÂøµÔºåÂåÖÊã¨ÂÆ°ÁæéÂíåÂäüËÉΩ‰∏äÁöÑÁâπÁÇπ
-ÂπªÁÅØÁâá8ÔºöÂØπËôöÊãüÁé∞ÂÆûÂíåÂ¢ûÂº∫Áé∞ÂÆûÂ∏ÇÂú∫ÁöÑÂΩ±Âìç -ÂàÜÊûêVision ProÂú®Áî®Êà∑‰ΩìÈ™å‰∏äÁöÑ‰ºòÂäøÂíåÊΩúÂú®ÂΩ±Âìç
-ÂπªÁÅØÁâá9ÔºöÂØπÂõæÂΩ¢ËÆæËÆ°ÂíåËßÜÈ¢ëÂà∂‰ΩúÂ∏ÇÂú∫ÁöÑÂΩ±Âìç ÂπªÁÅØÁâá5: ËãπÊûúÁîüÊÄÅÁ≥ªÁªüÂÜÖÁöÑÊï¥Âêà
-ÂπªÁÅØÁâá10ÔºöÂØπÁ´û‰∫âÂØπÊâãÁöÑÂΩ±Âìç -ËÆ®ËÆ∫Vision ProÂ¶Ç‰Ωï‰∏éËãπÊûúÂÖ∂‰ªñ‰∫ßÂìÅÂíåÊúçÂä°Êï¥Âêà
-ÂàÜÊûêÂÖ∂Êï¥ÂêàÊÄßÂØπÊ∂àË¥πËÄÖÁöÑÂê∏ÂºïÂäõ
ÂπªÁÅØÁâá11-14ÔºöÂØπÊ∂àË¥πËÄÖÁöÑÂΩ±Âìç
-ÂπªÁÅØÁâá11ÔºöÊ∂àË¥πËÄÖ‰ΩìÈ™åÂíåÊúüÊúõÁöÑÊîπÂèò 3. Vision ProÂèëÂ∏ÉÂØπÂêÑË°åÂêÑ‰∏öÁöÑÂΩ±Âìç(3-4È°µ)
-ÂπªÁÅØÁâá12ÔºöÊ∂àË¥πËÄÖË¥≠‰π∞Ë°å‰∏∫ÁöÑÊîπÂèò ÂπªÁÅØÁâá6: ÂΩ±ÂìçÊ∂àË¥πËÄÖÊäÄÊúØÊ†áÂáÜ
-ÂπªÁÅØÁâá13ÔºöÊ∂àË¥πËÄÖÂØπÂìÅÁâåÁöÑËÆ§Áü•ÂíåÂø†ËØöÂ∫¶ÁöÑÊîπÂèò -Êé¢ËÆ®Vision ProÂØπÊ∂àË¥πËÄÖÊúüÊúõÂíåÊäÄÊúØÊ†áÂáÜÁöÑÂΩ±Âìç
-ÂπªÁÅØÁâá14ÔºöÊ∂àË¥πËÄÖÊï∞ÊçÆÂíåÈöêÁßÅÁöÑÈóÆÈ¢ò -ÂàÜÊûêVision ProÂèØËÉΩÂºïÂèëÁöÑÊ∂àË¥πÂçáÁ∫ßÂíåËøûÈîÅÂèçÂ∫î
ÂπªÁÅØÁâá7: ÂΩ±ÂìçÂºÄÂèëËÄÖ‰∏éÂÜÖÂÆπÂàõÈÄ†
ÂπªÁÅØÁâá15-18ÔºöÂØπÊú™Êù•ÁöÑÈ¢ÑÊµã -ËßÇÂØüVision ProÂØπÂ∫îÁî®ÂºÄÂèëËÄÖÂíåÂÜÖÂÆπÂàõÈÄ†ËÄÖÂ∏¶Êù•ÁöÑÊú∫ÈÅá
-ÂπªÁÅØÁâá15ÔºöËãπÊûúVision ProÁöÑÊú™Êù•ÂºÄÂèëË∂ãÂäø -Êé¢ËÆ®Êñ∞‰∫ßÂìÅÂØπÁßªÂä®ÂíåÊ°åÈù¢ËΩØ‰ª∂ÂèëÂ±ïÁöÑÊΩúÂú®Êé®Âä®‰ΩúÁî®
-ÂπªÁÅØÁâá16ÔºöÂ∏ÇÂú∫Ë∂ãÂäøÂíåÁ´û‰∫âÊ†ºÂ±ÄÁöÑÈ¢ÑÊµã ÂπªÁÅØÁâá8: Á´û‰∫âÂØπÊâãÂíåË°å‰∏öÂèçÂ∫î
-ÂπªÁÅØÁâá17ÔºöÊ∂àË¥πËÄÖÈúÄÊ±ÇÂíåË°å‰∏∫ÁöÑÈ¢ÑÊµã -ÂàÜÊûêVision ProÂèëÂ∏ÉÂØπÂÖ∂‰ªñÁßëÊäÄÂÖ¨Âè∏Á≠ñÁï•ÁöÑÂΩ±Âìç
-ÂπªÁÅØÁâá18ÔºöÊäÄÊúØÂèëÂ±ïÁöÑÊú™Êù•È¢ÑÊµã[...] -È¢ÑÊµãÂ∏ÇÂú∫‰∏äÁöÑÁõ∏Â∫îÂèçÂ∫îÂíåÊΩúÂú®Êñ∞‰∫ßÂìÅ[...]
(cid:2895)(cid:30139)(cid:829)(cid:1874)(cid:2619)(cid:29289)(cid:34637)(cid:2644)(cid:5844)(cid:3183)(cid:29324)(cid:4541)(cid:4913)(cid:30834)(cid:1322)(cid:830)(cid:2652)(cid:6612)(cid:4913)(cid:3717)(cid:3023)(cid:1982)(cid:5547)(cid:35924)(cid:29287)(cid:5497)(cid:3415)(cid:29514)(cid:32560)(cid:1286)(cid:6493)(cid:37090)(cid:5494)(cid:29264)(cid:2399)(cid:5456)(cid:29289)‚Äú(cid:3183)(cid:2241)(cid:2573)(cid:3786)(cid:34711)(cid:1705)(cid:3970)(cid:29531)(cid:29287)(cid:1429)(cid:2241)(cid:5585)(cid:1252)(cid:34685)(cid:1705)(cid:1319)(cid:1246)
(cid:1275)(cid:1609)(cid:2974)(cid:3183)(cid:4913)(cid:1352)(cid:29264)(cid:3183)(cid:1285)(cid:1319)(cid:1874)(cid:31510)(cid:29341)(cid:30857)(cid:2619)(cid:29287)(cid:34685)(cid:1705)(cid:1319)(cid:1246)(cid:1275)(cid:4293)(cid:30998)(cid:4913)(cid:4779)(cid:2574)(cid:32439)(cid:3592)(cid:29287)(cid:3183)(cid:1386)(cid:2895)(cid:2468)(cid:4952)(cid:1328)(cid:4505)(cid:7606)(cid:29287)(cid:2892)(cid:32527)(cid:1319)(cid:31916)(cid:3995)(cid:4913)(cid:1609)(cid:32684)(cid:29264)(cid:31745)(cid:5650)(cid:29287)(cid:3183)(cid:2642)(cid:29346)(cid:4913)(cid:30500)
(cid:30480)(cid:1874)(cid:2961)(cid:29936)ÊùÇ(cid:29287)(cid:3183)(cid:3269)(cid:2974)(cid:29346)(cid:1407)(cid:2536)(cid:2898)(cid:3183)(cid:30857)(cid:2619)(cid:4913)(cid:1322)(cid:36150)(cid:29264)(cid:30951)(cid:5475)(cid:29287)(cid:3183)(cid:35929)(cid:2599)(cid:1982)(cid:29346)(cid:29540)(cid:3211)(cid:29287)(cid:3183)(cid:2895)(cid:2468)(cid:2241)(cid:5585)(cid:5494)(cid:1252)(cid:2399)(cid:37188)(cid:3182)(cid:1745)(cid:29287)(cid:5650)(cid:29346)(cid:2217)(cid:1285)(cid:2406)(cid:1860)(cid:3183)(cid:4913)(cid:36229)(cid:1751)(cid:5650)(cid:34651)
(cid:4281)(cid:3367)(cid:32621)(cid:29264)(cid:29346)(cid:6441)(cid:31873)(cid:32268)(cid:32621)(cid:29287)(cid:3183)(cid:30702)(cid:35191)(cid:1319)(cid:4965)(cid:4952)(cid:1912)(cid:29287)(cid:29346)(cid:2945)(cid:30344)(cid:1655)(cid:34650)(cid:29264)(cid:30951)(cid:1912)(cid:29287)(cid:3183)(cid:3182)(cid:1285)(cid:29617)(cid:3786)(cid:2222)(cid:35193)(cid:29531)(cid:6708)(cid:1897)(cid:4913)(cid:2986)(cid:30509)(cid:5647)(cid:29287)(cid:36229)(cid:1751)(cid:7054)(cid:29338)(cid:34446)(cid:1252)(cid:5495)(cid:6816)(cid:4913)(cid:2574)(cid:2556)(cid:29287)(cid:30500)
(cid:1705)(cid:5844)(cid:2793)(cid:4913)(cid:1392)(cid:43466)(cid:1982)(cid:3130)(cid:1294)(cid:29264)‚Äù(cid:6615)(cid:4147)(cid:3130)(cid:30469)(cid:1696)(cid:1442)(cid:4913)(cid:1879)(cid:1943)(cid:1982)(cid:6500)(cid:34219)(cid:2859)(cid:6598)(cid:3598)(cid:5291)(cid:1251)(cid:1352)(cid:5197)(cid:29287)(cid:1286)(cid:1352)(cid:29517)(cid:4913)(cid:1352)(cid:4564)(cid:2933)(cid:34401)(cid:1285)(cid:29289)(cid:3723)(cid:35394)(cid:29264)
ÊûóÈ¶ôÁã¨Ëá™Ëµ∞Âú®ÊûóËç´ÈÅì‰∏äÔºåÂÜ∞ÂÜ∑ÁöÑÈ£éÂàÆËøáÔºåÊí©Êã®Ëµ∑Â•πÂ§¥‰∏äÂèàÈªëÂèàÂπ≥ÁöÑÁü≠ „ÄåÂìêÂìêÔºÅ„Äç
Âèë„ÄÇÂ•πÊääË£πÂú®Ë∫´‰∏äÁöÑÂ§ßË°£Á¥ßÁ¥ßÊãâËøëÔºå‰∏ÄÂèåÁ∫§ÁªÜÂäõÈÅìÁöÑÊâãÂú®ÊÄÄÈáåÁ¥ßÁ¥ßÊè° ÂèàÊòØ‰∏§ËÆ∞Âìç‰∫ÆÁöÑËÄ≥ÂÖâÔºåÊûóÈ¶ôÂ∑≤ÁªèË¢´Ê¨∫Ë¥üÂæóËøûÁ´ôËµ∑Êù•ÁöÑÂäõÊ∞îÈÉΩÊ≤°Êúâ‰∫Ü„ÄÇ
Êã≥ÔºåÁ¥ßÂº†ÂéãÊäëÁöÑÊ∞îÊ∞õÂÉèÊòØÈ¢ÑÁ§∫ÁùÄÂç≥Â∞ÜÊù•‰∏¥ÁöÑÈ£éÊö¥„ÄÇÁ™ÅÁÑ∂Ôºå‰∏ÄÂ£∞ÂÜ∑Á¨ëÂà∫ Á®ãÊòü‰ªñ‰ª¨‰∏ÄËµ∞ÔºåÂ•π‰æøÁò´Âú®Âú∞Êùø‰∏äÔºåÁúºÁ•ûÁ©∫Ê¥ûÂú∞ÁúãÁùÄÊïôÂÆ§ÁöÑÂ§©Ëä±Êùø„ÄÇ
ÂÖ•Â•πÁöÑËÄ≥ËæπÔºåÊûóÈ¶ôÂçä‰ΩéÁùÄÂ§¥ÔºåÈöèÂç≥‰æøÁúãÂà∞ÂâçÊñπ‰∏ÄÁæ§È´òÈ´òÂú®‰∏äÁöÑÂ∞ëÂπ¥Â∞ë „ÄåÁúüÂèØÁ¨ë‚Ä¶‚Ä¶Êàë‰∏çËøáÂ∞±ÊòØ‰∏çÊÉ≥ÂèÇÂä†ÈÇ£‰∏™Ê¥ªÂä®ÔºåÂ∞±ÈÅ≠ÂèóËøôÊ†∑ÁöÑÈú∏Âáå„ÄÇ„Äç
Â•≥Â†µÂú®Â•πÁöÑÂéªË∑Ø‰∏ä„ÄÇ „Äå‰ªñ‰ª¨ÊÄé‰πàËøô‰πàÊÅ∂ÊØíÂïäÔºÅ„Äç
„ÄåÊòéÊòéÊàëÊâçÊòØÂèóÂÆ≥ËÄÖÂïäÔºÅ„Äç
ÁãÇÊ¨¢ÊÅ∂Ê∞ëÁöÑÁõÆÂÖâËêΩÂú®Â•πË∫´‰∏äÔºåËØ≠Ê∞î‰∏≠ÂÖÖÊª°‰∫ÜÊÅ∂ÊÑèÔºå‚ÄúÁúãÔºåÈÇ£‰∏çÂ∞±ÊòØÂí± ÊûóÈ¶ôÁöÑÂøÉÈáåÔºåÁ™ÅÁÑ∂ÂçáËµ∑‰∏ÄËÇ°Â•áÊÄ™ÁöÑÊÉÖÁª™„ÄÇ
‰ª¨Â≠¶Ê†°ÈÇ£ÊûóÂ∞èÈ¶ôÂòõÔºåÂ•πÈÇ£ÈöæÂ∫¶ÁúãÁöÑËÑ∏ÈÉΩËÆ©ÊàëÊ≤°ËÉÉÂè£ÂêÉÈ•≠Âï¶„ÄÇ‚ÄùÈÇ£‰∫õÂà∫ ‰ªø‰Ωõ‰∏ã‰∏ÄÁßíÔºåÂ•πÂ∞±ÂèØ‰ª•ÂéªÊ≠ª‰∫Ü„ÄÇ
ËÄ≥ÁöÑËÆ•Á¨ëÂ£∞ÔºåÂ∞ñÈîêÁöÑË¥£ÈóÆÂ£∞ÔºåÂ•πÈÉΩÊâøÂèó‰∫Ü‰∏ãÊù•ÔºåÁ°¨ÁîüÁîüÁöÑÊääÂÜÖÂøÉÁöÑÂßî Â•π‰∏çÁü•ÈÅìËá™Â∑±ÊòØÂ¶Ç‰ΩïÂõûÂà∞ÂÆ∂ÁöÑÔºåÊÄª‰πãÂà∞ÂÆ∂ÁöÑÊó∂ÂÄôÔºåÂ∑≤ÁªèÊòØÊôö‰∏ä„ÄÇ
Â±àÂíåÊó†Â•àÂêûÂíΩ‰∏ãÂéª„ÄÇÂ•πÂ∞ùËØïÁùÄÂèåÊâãÊä°ÂúÜÔºåÂéªÊå°‰ΩèÈÇ£‰∫õÊâëÈù¢ËÄåÊù•ÁöÑÁæûËæ± Âõ†‰∏∫Ë∫´‰∏äÈÉΩÊòØ‰º§ÔºåÂ•πËøûÊæ°ÈÉΩÊ≤°Ê¥óÔºåÂ∞±Ê≤âÊ≤âÂú∞Áù°ÁùÄ‰∫Ü„ÄÇ
ÔºåÁÑ∂ËÄå‰∏ÄÂàáÈÉΩÊòØÂæíÂä≥ÁöÑ„ÄÇ Ëøô‰∏ÄÁù°ÔºåÂ∞±Âà∞‰∫ÜÂáåÊô®‰∏âÁÇπ„ÄÇ
Â•πË¢´È•øÈÜíÂêéÔºåÁ™ÅÁÑ∂ÊÉ≥Ëµ∑‰∫ÜÂ•πËøòÊúâ‰∏Ä‰∏™ÁΩëÂèãÔºåÂè´„ÄåÂ≠§Êòü„ÄçÔºå‰∏Ä‰∏™ÂÖ≥ÂøÉÂ•πÂà∞È™®
ÂõûÂà∞ÂÆ∂‰∏≠ÔºåÊûóÈ¶ôÂùêÂú®ÁîµËÑëÂâçÔºå‰∫ÆÊô∂Êô∂ÁöÑÂ±èÂπïÂèçÂ∞ÑÁùÄÂ•πËãçÁôΩËÄåÂèàÊûØÈªÑÁöÑ Â≠êÈáåÁöÑ‰∫∫„ÄÇ
ËÑ∏Â∫û„ÄÇÂ•πÂèëÁé∞‰∫Ü‰∏Ä‰ΩçÂÖ≥Ê≥®Â•πÁöÑÁΩëÁªúÂ•ΩÂèã‚ÄúÂ≠§Êòü‚ÄùÔºåÈÇ£ÊòØ‰∏Ä‰∏™ÊÄªÊòØÂú®Ê∑±Êõ¥ Â•πÊâìÂºÄÊâãÊú∫ÔºåÁäπË±´‰∏ÄÈòµÂêéÔºåÁªô‰ªñÂèëÂéª‰∫ÜÊ∂àÊÅØ„ÄÇ
ÂçäÂ§úÈô™ÁùÄÂ•πËÅäÂ§©ÁöÑ‰∫∫ÔºåÂØπÂ•πÊó†ÂæÆ‰∏çËá≥ÁöÑÂÖ≥ÂøÉËÆ©Â•πÊÑüÂà∞Ê∏©Êöñ„ÄÇÊûóÈ¶ôÁªô‰ªñ „ÄåÊàë‚Ä¶‚Ä¶ÂèØ‰ª•ÈóÆ‰Ω†‰∏™ÈóÆÈ¢òÂêóÔºü„Äç
Âèë‰∫Ü‰∏ÄÂº†Ëá™Â∑±Ë¢´Ê¨∫Ë¥üÁöÑÁÖßÁâáÔºåÊ∏¥ÊúõÂæóÂà∞ÂØπÊñπÁöÑ‰∏ÄÁÇπÂêåÊÉÖÔºå‰∏ÄÁÇπÊÖ∞Ëóâ„ÄÇ Â≠§ÊòüÂá†‰πéÁßíÂõûÔºö„Äå‰ªÄ‰πàÔºü„Äç
„Äå‚Ä¶‚Ä¶Âú®ÂêóÔºü„Äç
Â•πÂèëÂÆåÁÖßÁâá‰πãÂêéÔºåÊó©Â∑≤Ê≥™ÊµÅÊª°Èù¢„ÄÇÁúãÁùÄÂ±èÂπï‰∏äÁöÑËØªËÄÖ‰ΩìÈ™å‰∫∫Êï∞Ôºå‰∏Ä‰∏™ ‰ªñÂ•ΩÂÉèÊúâ‰∫õ‰∏çËÄêÁÉ¶‰∫ÜÔºö„ÄåÂà´ÈóÆ‰∫õÊúâÁöÑÊ≤°ÁöÑÔºåÁõ¥Êé•ËØ¥‰∫ã„ÄÇ„Äç
‰∏™ÈôåÁîüÁöÑÂêçÂ≠óÔºåÂ•πÊâçÊÉ≥Ëµ∑Ëá™Â∑±Âπ∂‰∏çÊòØ‰∏Ä‰∏™‰∫∫ÔºåÂ•πÊúâ‚ÄúÂ≠§Êòü‚ÄùÔºåÊúâ‰ªñÁöÑÊîØ Â•πÁäπË±´ÂÜç‰∏âÔºåÈºìË∂≥ÂãáÊ∞îÂõûÂ§çÈÅìÔºö„Äå‰Ω†‚Ä¶‚Ä¶‰ºöÂõ†‰∏∫Âà´‰∫∫ÁöÑÂ§ñË≤åÂíåËÉåÊôØËÆ®ÂéåÂ•π
ÊåÅÂíå‰øùÊä§„ÄÇÁÑ∂ËÄåÊ≠§Êó∂Ôºå‰ªñÂç¥Âõ†‰∏∫Êúâ‰∫ãËÄåÂåÜÂøôÁ¶ªÂºÄÔºå‰ªñÁöÑÁÖßÁâáÂú®Â±èÂπï‰∏ä ÂêóÔºü„Äç
‰∏ÄÈó™ËÄåËøáÔºåÈÇ£ÂîØÁæéÁöÑÁÅµÈ≠ÇÂäõÈáèËÆ©ÊûóÈ¶ôÊó†Ê≥ïÊäµÊå°„ÄÇ[...] Ëøá‰∫ÜÂæà‰πÖÔºå‰ªñÊ≤°ÊúâÂõûÂ§ç„ÄÇ
Â•πÁ≠â‰∫ÜÂ•Ω‰πÖÔºå‰ªñÊâçÂõûÂ§çÂ•π„ÄÇ
„Äå‰∏∫‰ªÄ‰πàËøô‰πàÈóÆÔºü„Äç
Â•π‰∏ÄÂí¨ÁâôÔºåË±ÅÂá∫Âéª‰∫ÜÔºåÂ∞±ÁÆóÊòØÂàÜÊâãÔºåÂ•π‰πüË¶ÅÈóÆ‰∏™ÊòéÁôΩÔºÅ[...]
26(cid:30469)(cid:37188)(cid:2961)(cid:4913)(cid:5261)(cid:5907)(cid:1502)(cid:3059)(cid:2439)(cid:1253)(cid:29289)(cid:2395)(cid:1585)(cid:2241)(cid:2399)(cid:37469)(cid:29550)(cid:1246)(cid:2400)(cid:3616)(cid:1252)(cid:3702)(cid:3236)(cid:3183)(cid:29287)(cid:3183)(cid:1386)(cid:1870)(cid:4766)(cid:1319)(cid:1246)(cid:29338)(cid:1322)(cid:30480)(cid:29264)(cid:29346)(cid:29706)(cid:34844)(cid:1319)(cid:29287)(cid:1429)(cid:29362)(cid:1298)(cid:37461)(cid:4108)(cid:30954)(cid:31916)(cid:1702)(cid:34844)(cid:29287)(cid:29346)(cid:34446)(cid:6960)(cid:3702)(cid:3576)(cid:5278)(cid:2961)
(cid:4965)(cid:3318)(cid:29287)(cid:3183)(cid:1386)(cid:30673)(cid:1943)(cid:1319)(cid:29287)(cid:1429)(cid:3183)(cid:30500)(cid:6503)(cid:29346)(cid:29323)(cid:2401)(cid:4519)(cid:5470)(cid:29264)(cid:5291)(cid:1323)(cid:2400)(cid:29287)(cid:3183)(cid:30500)(cid:1705)(cid:34538)(cid:1435)(cid:29323)(cid:34642)(cid:29287)(cid:1429)(cid:37461)(cid:3598)(cid:1863)(cid:29324)(cid:1319)(cid:2399)(cid:37469)(cid:29264)(cid:3183)(cid:37469)(cid:1278)(cid:1319)(cid:30967)(cid:30097)(cid:4913)(cid:2543)(cid:31303)(cid:1442)(cid:1285)(cid:29345)(cid:2841)(cid:4913)(cid:32424)(cid:31303)(cid:29287)
(cid:29959)(cid:7401)(cid:4952)(cid:1278)(cid:32539)(cid:29287)(cid:1429)(cid:4541)(cid:5278)(cid:29287)(cid:5491)(cid:1352)(cid:3963)(cid:2117)(cid:4913)(cid:30500)(cid:6503)(cid:29264)(cid:2399)(cid:37469)(cid:5486)(cid:3699)(cid:1912)(cid:29287)(cid:2395)(cid:1585)(cid:3702)(cid:3236)(cid:3183)(cid:29287)(cid:3183)(cid:1386)(cid:30954)(cid:1246)(cid:4007)(cid:2642)(cid:6590)(cid:29264)(cid:29346)(cid:5197)(cid:6761)(cid:3183)(cid:34594)(cid:33306)(cid:1319)(cid:29287)(cid:3183)(cid:2215)(cid:2859)(cid:6612)(cid:30419)(cid:2440)(cid:29334)(cid:34594)(cid:33306)(cid:1319)(cid:29264)
(cid:30419)(cid:2440)(cid:3401)(cid:1705)(cid:3183)(cid:37469)(cid:1352)(cid:30404)(cid:1653)(cid:29287)(cid:3183)(cid:7407)(cid:29959)(cid:1355)(cid:1293)(cid:3130)(cid:3023)(cid:29287)(cid:29959)(cid:1833)(cid:4108)(cid:30954)(cid:2215)(cid:5308)(cid:29264)(cid:29264)(cid:4671)(cid:2241)(cid:29287)(cid:6615)(cid:2241)(cid:31278)(cid:2330)(cid:5072)(cid:1252)(cid:6960)(cid:1246)(cid:3981)(cid:3717)(cid:2892)(cid:30834)(cid:1322)(cid:29287)(cid:1609)(cid:4147)(cid:30480)(cid:5907)(cid:6963)(cid:6717)(cid:3028)(cid:29324)(cid:3528)(cid:2573)(cid:3028)(cid:6710)(cid:4913)(cid:3401)
(cid:1803)(cid:29287)(cid:32330)(cid:29394)(cid:3205)(cid:1696)(cid:1442)(cid:1622)(cid:2619)(cid:33020)(cid:2396)(cid:29637)(cid:2906)(cid:6619)(cid:5647)(cid:5504)(cid:5509)(cid:34637)(cid:6619)(cid:29264)
(cid:6615)(cid:4147)(cid:3130)(cid:30469)(cid:1696)(cid:1442)(cid:4913)(cid:1879)(cid:1943)(cid:1982)(cid:6500)(cid:34219)(cid:2859)(cid:6598)(cid:3598)(cid:5291)(cid:1251)(cid:1352)(cid:5197)(cid:29287)(cid:1653)(cid:2387)(cid:30768)(cid:35924)(cid:2906)(cid:7614)(cid:30834)(cid:1322)(cid:4913)(cid:2895)(cid:36091)(cid:29264)
ÁöáÂÆ´ÁπÅÂçéÁöÑ‰∏≠ÂøÉÔºåË¥µÂ¶ÉÂøµÂøµÁöÑÂØùÂÆ´„ÄÇÂ§úÂÖÅÔºåËøô‰ΩçÂ§©‰∏ãÊéåÊùÉÁöÑÁöáÂ∏ùÔºåÂú®ÈÄâ Â§úÂÖÅÂ§ßÈÄâÂâç‰∏ÄÂ§©Êôö‰∏äÊù•Êâæ‰∫ÜÂ•π„ÄÇ
Â´°Â¶ÉÂâç‰∏ÄÂ§úÂÖâ‰∏¥‰∫ÜÂ•πÁöÑÂçßÂÆ§„ÄÇÂ§úÊ∑±‰∫∫ÈùôÔºåÂç≥‰ΩøÊòØËøô‰Ωç‰∏á‰∫∫‰πã‰∏äÁöÑÁöáÂ∏ùÔºå Ëøô‰∏™Êó∂Èó¥ÁÇπÊù•ÂèØ‰∏ç‰∏ÄËà¨ÔºåÂ•πÁåú‰∏çÂáÜ‰ªñÊÉ≥Ê≥ïÔºå‰πüÊ≤°Â§öËØ¥‰ªÄ‰πàÔºåÂÉèÂæÄÂ∏∏ÈÇ£Ê†∑Áªô‰ªñÊñüÈÖí
Ê≠§Âàª‰πüÁ•ûËâ≤ÈÜâ‰∫∫„ÄÇ ÔºåÁªô‰ªñÂàáÊ∞¥ÊûúÔºå‰ªñÂñùÂ§ö‰∫ÜÔºå‰ΩÜ‰πüÊ≤°Â§™ÈÜâÔºåÂè™ÊòØËµ∞Ë∑ØÊôÉËç°ÔºåÁ¨ëÂæóÊúâ‰∫õÁúüÊåö„ÄÇ
‰ªñÈóÆËá™Â∑±‰∏∫‰ªÄ‰πàËøòÊòØÈÇ£‰πàÂ•ΩÁúã„ÄÇÂ•ΩÁúãÂà∞ËÆ©Â•πËßâÂæó‰ªñ‰∏çÂÉèÊòØËá™Â∑±ÁöÑ‰∏àÂ§´„ÄÇ
"ÂøµÂøµÔºå‰Ω†Ë∏èË∂≥ÂÆ´Âª∑‰πãÂàùÔºåÊàëÂ∞±Ê≥®ÊÑè‰Ω†‰∫Ü„ÄÇ"‰ªñËæπ‰ΩéÂêüËæπÊãâÁùÄÂøµÂøµÁöÑÊâã„ÄÇ ‰ªñË∫´‰∏äÊúâÈÖíÂë≥ÔºåÂ•π‰∏çÂéåÊÅ∂ÔºåÂèçËÄåËßâÂæóËøôÈÖíÂë≥Êõ¥Âãæ‰∫∫ÂøÉÂº¶Ôºå‰ªñËµ∞ËøëÂ•πÁöÑÊó∂ÂÄôÔºåÂ•πÂøÉ
Ë∑≥Â∞±‰ºöËé´ÂêçÂä†ÈÄüÔºåËøôÊòØÂ•πÂØπ‰ªñÊó†Ê≥ïÂéãÊäëÁöÑÂñúÊ¨¢„ÄÇ
"Èôõ‰∏ãÔºåÊàë‚Ä¶‚Ä¶"ÂøµÂøµÊÉ≥ËØ¥‰∫õ‰ªÄ‰πàÔºå‰ΩÜÊòØ‰ªñÊâ∂ÁùÄÂ•πÁöÑÊâãËáÇÔºåÂ•π‰æøÊîæ‰∏ã‰∫ÜÂøÉ‰∏≠ Â•πÊÉ≥Ôºå‰ªñ‰ªäÂ§©‰∏ç‰ºöÊòØÊïÖÊÑèÂØπÂ•πÂñùÈÖíÂêß„ÄÇ
ÁöÑÁñëÈóÆÔºå‰ªªÁî±‰ªñÂºïÈ¢ÜÔºåÁº†ÁªµÂú®Â•πÁöÑÊ¢¶‰∏≠„ÄÇ ‰∏çÁÑ∂‰ªñÊÄé‰πàËµ∞‰∏çÁ®≥ÁöÑ„ÄÇÊòéÊòéÔºå‰ªñÂæÄÊó•ÈáåÂñù‰∫ÜÈÇ£‰πàÂ§öÈÖíÈÉΩÂ•ΩÂ•ΩÁöÑ„ÄÇ
Â•πËßâÂæó‰ªñÁ¶ªÂ•πÂ§™Ëøë‰∫ÜÔºåÂèØÂ•π‰πüËàç‰∏çÂæóÊé®ÂºÄ‰ªñ„ÄÇ
Â§úÊ∑±ÔºåÂ§úÂÖÅÈÖíÈÖ£„ÄÅÁ•ûËâ≤Êô¥Êúó„ÄÇÂè™ÊòØ‰ªñÁöÑÊâãÊ≥ï‰∏çÂ§üÁÜüÁªÉÔºå‰ΩøÂæóËøôÂú∫‰πÖËøùÁöÑ ‰ªñË∫´‰∏äÂ•ΩÈ¶ôÔºåÂ•πÂøç‰∏ç‰ΩèÊääËÑ∏Ë¥¥Ëøë‰ªñ„ÄÇÂ•π‰ª•‰∏∫‰ªñ‰ºöÂ¶ÇÂæÄÂ∏∏ÈÇ£Ê†∑ÈÅøÂºÄÁöÑ‚Äî‚ÄîÂÖ∂ÂÆûÔºåÂ•π
‰∫≤ÊòµÂ§öÂ∞ëÊúâ‰∫õÁîüÁñèÔºå‰ΩÜÂøµÂøµÂç¥‰∏çËàçÂàÜÁ¶ªÔºåÂÆ≥ÊÄï‰∏ÄÊó¶ÈáäÊîæÔºåËøô‰ªΩÂæÆÂ¶ôÁöÑÊÉÖ ËßâÂæó‰ªñÂ∫îËØ•‰∏çÂñúÊ¨¢Âà´‰∫∫Èù†‰ªñÂ§™ËøëÔºåÂ•π‰ª•‰∏∫‰ªñÂè™ÊòØ‰∏çÂñúÊ¨¢ËøôÊ†∑ËÄåÂ∑≤„ÄÇ
ÊÑ´Â∞Ü‰ºöÊ∂àÊï£Âú®È£é‰∏≠„ÄÇ ‰ΩÜÂ•πÊÉ≥Èîô‰∫ÜÔºå‰ªñÂ•ΩÂÉèÊúâ‰∫õ‰∏çÂ§™ÁÜüÁªÉ‰ººÁöÑÔºåËÑ∏È¢äËÇâË¢´Â•πËøô‰πà‰∏ÄËπ≠ÔºåÊúâ‰∫õÁóíÁóíÁöÑÔºåËøû
‰ªñËá™Â∑±ÈÉΩ‰ΩéÂ£∞Á¨ë‰∫Ü„ÄÇ
Ê¨°Êó•ÁôΩÊòºÔºåÂ§úÂÖÅÈ°æÂèäÊúùÊîøÔºåË¥µÂ¶ÉÂøµÂøµÂç¥Âõ†Â§úÈó¥ÁöÑÁ∫†Áº†ÔºåÊÑüËßâË∫´‰ΩìÊúâ‰∫õ‰∏ç ‰πãÂêéÁöÑ‰∫ãËá™ÁÑ∂È°∫ÁêÜÊàêÁ´†„ÄÇ
ÈÄÇÔºå‰ΩÜÊòØ‰ªäÂ§©ÊòØÈÄâÂ´°Â¶ÉÁöÑÂ§ßÊó•ÔºåÂ•π‰∏çËÉΩËÄΩÊêÅ„ÄÇÂøµÂøµÊî∂ÊãæÂ•ΩËá™Â∑±ÔºåÂèÇ‰∏éËøõ ÂèØÊ¨°Êó•Â•πÈÜíÊù•ÁöÑÊó∂ÂÄôÔºåÂ§¥ÂæàÁóõ„ÄÇ
Â§ßÈÄâÁöÑË°åÂàó„ÄÇ Â•πÂèëÁé∞Ëá™Â∑±ËøòÊòØÊ≤°ËÉΩÂøç‰ΩèÔºåÂ•πÂØπÂ§úÂÖÅËøòÊòØË¥™ÂøÉÁöÑ„ÄÇ
Â•π‰∏çÊÉ≥Ë¶Å‰ªñÁöÑÂñúÊ¨¢Ôºå‰ªñÁªôÂ•πÁöÑÂ∑≤ÁªèË∂≥Â§üËÆ©Â•πÂøÉÁîòÊÉÖÊÑø‰∏ÄËæàÂ≠êÂæÖÂú®ÁöáÂÆ´‰∫Ü„ÄÇÂ•πÂè™ÊòØ
Â§ßÈÄâ‰∏äÔºåÂ•πÈÄâ‰∏≠‰∫ÜÊùéÂÆ∂ÁöÑÂ´°Â•≥ÔºåÁ¨ëÂÆπÂ¶ÇËä±ÔºåËôΩÁÑ∂ÈïøÁõ∏‰∏≠Á≠âÔºåÂç¥ËÆ©‰∫∫ÊÑüÂà∞ Â∏åÊúõÔºå‰ªñËÉΩÁ®çÂæÆ‚Ä¶‚Ä¶Á®çÂæÆÂñúÊ¨¢‰∏ÄÁÇπÂ•π„ÄÇ
ÁâπÂà´ÂñúÊ¨¢„ÄÇÊúâ‰∫õ‰∫∫ÁîüÊù•Â∞±‰ºöÊï£ÂèëÂá∫Âñú‰πêÁöÑÊ∞îÊÅØÔºå‰Ωø‰ªñ‰∫∫ÂøÉÁîüÊÑøÊÑèÔºåÂ•πÂ∞± Â•πÁü•ÈÅìËøô‰∏™ÊÉ≥Ê≥ïÂæàÂÇª‰πüÂæàÂ§©ÁúüÔºåÂèØÂ•πÂ∞±ÊòØ‰ºöÂ∏åÊúõ„ÄÇÂ•πÊÉ≥ÂÜçË¥™ÂøÉÁÇπ„ÄÇ
ÊòØËøôÊ†∑ÁöÑ‰∫∫„ÄÇ[...] Â•πÈÄâ‰∏≠‰∫ÜÊùéÂÆ∂ÁöÑÂ´°Â•≥Ôºå‰∏Ä‰∏™ÈïøÁõ∏‰∏≠Á≠âÔºå‰ΩÜÊòØÁà±Á¨ëÔºåËÆ©‰∫∫ËßâÂæóÊ¨¢ÂñúÁöÑ‰∫∫ÔºåËá≥‰∫éÂÖ∂‰ªñ
‰∫∫ÔºåÂ•πÂ∞±ÁúãÁöá‰∏äÁöÑÊÑèÊÄù‰∫Ü„ÄÇ
27