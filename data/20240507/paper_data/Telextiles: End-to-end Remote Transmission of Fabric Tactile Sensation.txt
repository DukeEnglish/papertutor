Telextiles: End-to-end Remote Transmission of
Fabric Tactile Sensation
TakekazuKitagishi YuichiHiroi YunaWatanabe
kitagishi-takekazu588@g.ecc.u- yuichi.hiroi.1@gmail.com yuna-watanabe1923@g.ecc.u-
tokyo.ac.jp TheUniversityofTokyo tokyo.ac.jp
TheUniversityofTokyo Tokyo,Japan TheUniversityofTokyo
Tokyo,Japan Tokyo,Japan
YutaItoh JunRekimoto
yuta.itoh@iii.u-tokyo.ac.jp rekimoto@acm.org
TheUniversityofTokyo TheUniversityofTokyo
Tokyo,Japan SonyCSLKyoto
Tokyo/Kyoto,Japan
User A Server User B
a b c Latent Representation d
User A‚Äôs NN Nearest
Textile Sample Query
‚Ä¶
User B‚Äôs
Fingertip
Figure1:OverviewofourTelextilessystem.(a)Ouridealofremotetactiletransmission.OurTelextilesaimstoreproducethe
tactilesensationoftextilesataremotelocationasiftheywerebeingtouchedthere.(b)Ausertransmitsthetactilesensationof
thetextiletotheserverusingtactilesensors.(c)Ontheserver,thelatentspaceislearnedinadvancefrommultipletextiles,
takingintoaccounttheirtactilecharacteristics.Theuser‚Äôsdataisconvertedintoalatentfeature,andtheclosesttextilesample
isselected.(d)Theotherremoteusertouchesaphysicalsampleoftheselectedtextileonthelatentspaceviaanactuator.
ABSTRACT distanceandapplythe16textilesamplestotherollersintheorder
Thetactilesensationoftextilesiscriticalindeterminingthecom- ofthedistance.Therollerisrotatedtoselectthetextilewiththe
fortofclothing.Forremoteuse,suchasonlineshopping,users closestfeatureifanunknowntextileisdetected.
cannotphysicallytouchthetextileofclothes,makingitdifficultto
evaluateitstactilesensation.Tactilesensingandactuationdevices CCSCONCEPTS
arerequiredtotransmitthetactilesensationoftextiles.Thesensing ‚Ä¢Human-centeredcomputing‚ÜíHapticdevices;Userstudies;
deviceneedstorecognizedifferentgarments,evenwithhand-held Virtualreality;Mixed/augmentedreality;‚Ä¢Computingmethod-
sensors.Inaddition,theexistingactuationdevicecanonlypresent ologies‚ÜíLearninglatentrepresentations;Neuralnetworks;
alimitednumberofknownpatternsandcannottransmitunknown Dimensionalityreductionandmanifoldlearning.
tactilesensationsoftextiles.Toaddresstheseissues,wepropose
Telextiles,aninterfacethatcanremotelytransmittactilesensations KEYWORDS
oftextilesbycreatingalatentspacethatreflectstheproximityof
Tactileperception;Texture;Texturerecognition;Texturepercep-
textilesthroughcontrastiveself-supervisedlearning.Weconfirm
tion;Machinelearning;Selfsupervisedlearning;Hapticfeedback;
thattextileswithsimilartactilefeaturesarelocatedclosetoeach
Passivehapticfeedback;TactileDisplay
otherinthelatentspacethroughatwo-dimensionalplot.Wethen
compressthelatentfeaturesforknowntextilesamplesintothe1D
ACMReferenceFormat:
UIST‚Äô23,October29-November1,2023,SanFrancisco,CA,USA TakekazuKitagishi,YuichiHiroi,YunaWatanabe,YutaItoh,andJunReki-
¬©2023Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM. moto.2023.Telextiles:End-to-endRemoteTransmissionofFabricTactile
Thisistheauthor‚Äôsversionofthework.Itispostedhereforyourpersonaluse.Notfor Sensation.InThe36thAnnualACMSymposiumonUserInterfaceSoftware
redistribution.ThedefinitiveVersionofRecordwaspublishedinThe36thAnnualACM
andTechnology(UIST‚Äô23),October29-November1,2023,SanFrancisco,CA,
SymposiumonUserInterfaceSoftwareandTechnology(UIST‚Äô23),October29-November
1,2023,SanFrancisco,CA,USA,https://doi.org/10.1145/3586183.3606764. USA.ACM,NewYork,NY,USA,10pages.https://doi.org/10.1145/3586183.
3606764
4202
yaM
6
]CH.sc[
1v36330.5042:viXra
‚Ä¶
‚Ä¶ ‚Ä¶
‚Ä¶UIST‚Äô23,October29-November1,2023,SanFrancisco,CA,USA TakekazuKitagishi,YuichiHiroi,YunaWatanabe,YutaItoh,andJunRekimoto
1 INTRODUCTION 2 RELATEDWORK
Thetactilesensationoftextilesiscriticaltoanindividual‚Äôsclothing Inthissection,wereviewrelatedworkontactilerecognitionap-
experience.Inaphysicalstore,customersoftenrelyontouchto proachesandactuatorsascomponentsforremotelytransmitting
evaluatethetextureofthetextile.Thistactileexperiencesignif- thetactilesensationoftextiles.
icantlyshapestheirevaluationofgarmentattributes,including
comfortandquality,andultimatelyimpactstheiroverallsatisfac- 2.1 TextileRecognition
tion.However,whenshoppingonline,customerscannotphysically
Researchontextilerecognitionismainlyaimedathelpingrobotsto
examinethefeelofthetextiles,makingitdifficultforthemtoaccu-
understandthesenseoftouch.Therefore,textilerecognitionoften
ratelyanticipatethecomfortlevelofthegarment.Thislimitation
proposesacombinationofatactilesensorattachedtotherobotand
canreducethequalityoftheshoppingexperience,asthegarments
alearningmodeltorecognizeitstexture.Duetothismotivation,
purchasedmaynotmeetthecustomer‚Äôscomfortexpectations.
mostoftherelatedresearchfocusesonsolvingtheclassification
To address the challenges, we seek to develop a system that
problemofwhichtextiletherobotistouching.Examplesoftactile
cantransmitthetactilesensationoftextilestoaremotelocation,
sensorsincluderobotfingerfriction[30],abionictactilesensor[14],
allowinguserstofeelasiftheirfingershavetouchedthetextileon-
pointclouddeformationonasiliconerubber[23],andanelastomer
site.Suchtransmissionrequiresbothtactilesensingandactuation
sensorsuchasGelSight(GelSight,Inc.)[17].Withthesesupervised
devices.
classifications, it is difficult to present a plausible tactile textile
Thesensingdevicemustbeabletodetectvarioustextiles,even
whenanunknowntextileisusedasinput.
withunstablehand-heldsensors.Anexampleofasimpletactile
Asanexampleofsupervisedlearningappliedtounderstanding
sensorisanelastomersensor[7,28]usedforthetactilesensing
unseentextiles,Yuanetal.[36]combinedGelSightanda3Dcamera
ofrobotarms.Thissensordetectsthesurfacetextureofanobject
toclassifythephysicalpropertiesoffabrics(e.g.,thickness,fuzzi-
bysensingitsunevennesswhenpressed.However,thepressing
ness,softness),whichweresettofivelevelsbasedonsubjective
forceandorientationdependontheperson,leadingtounstable
evaluation.Thismethodisbasedonasubjectiveratingscaleand
inference.Inaddition,existingtexturerecognitionmethodsmainly
doesnotallowforacomparisonofhowcloseanunknowntextile
classifyonlyknowntextiletypes[14,17,23,30],makingitdifficult
istoanexistingone.
todeterminetherelationshipbetweenknownandunknowntextiles
Severalmethodshavebeenproposedtolearnlatentrepresen-
thatarenotinthetrainingdata.
tationsoftextilesandapplythemtorobotcontrols.Takahashiet
Toreproducethesensationoftextiles,weultimatelywantan
al.[28]usedunsupervisedlearningofimagesfromuSkinsensor
actuatorthatcangenerateallthetactilesensations.However,itis
(XELARobotics)toestimatetherobot‚Äôsend-effectorsignalsfrom
currentlydifficulttoreproducethetactilesensationoftextiles.Hap-
latentfeatures.Conversely,Narangetal.[21]usedlatentfeatures
ticRevolver[33]canpresentafinitenumberofphysicaltextures
obtainedbysemi-supervisedlearningwithsimulationstoestimate
onanactuatedwheeltophysicallyconveythetactilesensation.
the 3D deformation of BioTac sensor (SynTouch Inc.) from the
However,itisdifficulttoselectanappropriatefinitepatternfroma
robot‚Äôsend-effectorsignals.Althoughthesemethodsuselatent
largenumberoftextiles.Inaddition,itisanopenquestionabout
featurestoconvertbetweendifferentmodalities,thelatentfeatures
whichpatternwillbepresentedwhenapersontouchesatextile
arenotlearnedtoreflecttheproximitybetweentextiles.
thatisnotincludedinthepatterns.
Toconvertdatabetweendifferenttactilesensors,BioTacand
WeproposeTelextiles,aninterfacethatenablesremotetrans-
RoboSkinsensor(BibopInc.),Gaoetal.[11]learnedacommon
missionoftactilesensationsoftextiles,evenwhentheinputtextile
latentspacebetweenthesensorsusingself-supervisedlearning
isunknown.Oursystemusesasensingdevicethatusescontrastive
withatwo-stagerecurrentnetwork.Althoughtheirmethodde-
self-supervisedlearningtocreatealatentspacethatreflectsthe
signsalossfunctionthatclassifiesthephysicalpropertiesofthe
proximityoftextiles.Wealsocreateanactuationdevicewith16
clothfromthelatentfeatures,thesephysicalpropertiesarealsoset
textilesamplesattachedaccordingtotheproximityobtainedby
basedonsubjectiveevaluations,similarto[36].Weinsteaduseself-
dimensionalreductionofthelatentfeatures.Whenaremoteuser
supervisedcontrastivelossfunctionsfortraining,sothattextiles
perceivesthetextureofthetextilewithatactilesensor,thedevice
withsimilarcharacteristicsareclosertogetherandtextileswith
isactuatedtotouchthephysicalsampleclosesttotheuser‚Äôsfin-
differentcharacteristicsarefurtherapart.
gertips.SinceourTelextilesinterfacecantheoreticallyacceptany
textileasinput,userscansimulatethetactileexperienceofany
2.2 TactileActuatorstoReproduceTextiles
garmentonline,whichisexpectedtoenhancetheuser‚Äôsshopping
experienceandfacilitateremotecollaborationinthefashionand Our goal is a system that presents tactile sensations as if one‚Äôs
textileindustries. ownfingerswereremotelypresentandtracingthesurfaceofa
Ourmaincontributionsincludethefollowing: textile.Topresentsuchtactilesensations,anactuatorisrequired
thatallowstheusertofeelcontactwiththesurfaceandexplore
‚Ä¢ Latentrepresentationsbasedonself-supervisedcontrastive
itstextureusingtheskinofthefingertip. Traditionalhandheld
learningconsideringtheproximityoftextiles,
VRcontrollersarelimitedtovibrotactilestimulationandarenot
‚Ä¢ Apparatus for user-independent, stable tactile sensing of
suitableforpresentingthesefinetactilesensationsoftextiles.
textiles,and
Examplesofdevicesthatprovidetactilesensationsontheskin
‚Ä¢ Aroller-typeactuationdevicethatpresentsatextilethatis
atthefingertipsincludegloveexoskeletons[2,10,18],finger-worn
intheclosestproximitytothetransmittedtextilesensation.
hapticdevices[6,22,24],robot-basedsolutions[1,12,26,27,31],Telextiles:End-to-endRemoteTransmissionofFabricTactileSensation UIST‚Äô23,October29-November1,2023,SanFrancisco,CA,USA
Server (Manufacturer)
id:11 id:14 1D 2D
(roller) (plane) 3D ‚Ä¶
Capture a large number of Train encoder to represent Attach samples to actuators
textile samples latent features
User B
User A
Visual
Feedback
id:10
Provide proximity
to other samples
Tactile Data Latent Vector Tactile id:10
Extract latent Select nearest or Feedback
feature sample Sample ID
Move the actuator to
Capture a textile touch the sample
Figure2:SystemoverviewofTelextiles.Thetrainingphaseisassumedtobeperformedbythemanufacturer,whotrains
encoderstoextractalatentvectorrepresentationofthetactilesensationfromalargesampleoftextiles.Inthetransmission
phase,userAacquirestactiledatabypressingatactilesensoragainstatextile.Thistactiledataissentoverthenetworktothe
server.Usingthelearnedencoder,theserverextractslatentrepresentationsfromthetransmittedtactiledata.Theserverthen
computestheclosesttrainingsampletothetransmitteddatainlatentspaceandsendstherawlatentvectorortheIDofthe
closestsampletoUserB.UserBcanconfirmthereceivedtactilesensationthroughvisualortactilefeedback.
andultrasound[32,35].Gloveexoskeletonsandfinger-wornhaptic wheelthatrotatestobringtheoptimalphysicaltextureintocontact
devicesareunsuitableforourapplicationswhereusersexplorethe withthefingertips.Whilethesewheel-basedactuatorsinspireus,
tactilequalitiesofsurfacesbecausethedevicesarewornonthe theydonotprovidealogictopresenttheclosesttactilesensation
fingertip.Robot-basedandultrasoundsolutionsrequireexpensive whenanunknownpatternisaninput.Weaddressthisproblemby
orlargesetupsandthereforedonotmatchourmotivationtoeasily learningthedistanceonthelatentrepresentationwithrespectto
experiencethetactilesensationoftextileswhileshoppingonline. thetactilesensationofthetextile.
Therefore,wearelookingforanactuatorwitharelativelysimple
setupthatdoesnotrequireadeviceonthefingertip.
Methodshavebeenproposedtoreproducethedelicatetactile
3 SYSTEMOVERVIEW
sensationoftextilesbyphysicallyreplicatingthemicrostructure
ofthetextilesurface,suchas3Dprintingbasedonthehairstruc- Figure2showsanoverviewofourTelextilessystem.Oursystem
ture[9]orthedigitizedreconstructionoftheelastomericsensor[7]. canbedividedintotwophases:atrainingphase,whichisperformed
Thesemethodshavereproducedtextiletactilesensationsatvery inadvance,andatactiletransmissionphase,inwhichusersactually
highresolutionasstaticmaterials.Ontheotherhand,oursystem transmitthetactilesensationofthetextile.
requiresanactuatorthatdynamicallyselectsthematerialwiththe Thetrainingphaseisassumedtobeperformedbythemanufac-
closesttactileresponsetotheinputfrommultiplematerials. turer,whotrainsencoderstoextractalatentvectorrepresentation
Wheel-basedhapticcontrollersareproposedthatconveythe ofthetactilesensationfromalargesampleoftextiles.
tactilepropertiesoffabricsbyattachingfabricsamplestotheac- Thetransmissionphaseisperformedbytworemoteusers,Aand
tuatorsurface.HapticRevolver[34]isanactuatorwheelthatrises B.UserAacquirestactiledatabypressingatactilesensoragainsta
underthefingerandmakescontactwithavirtualsurface.Haptic textile.Thistactiledataissentoverthenetworktotheserver.Using
Palette[8]extendsthiswheel-basedactuatorwithvisualenhance- thelearnedencoder,theserverextractslatentrepresentationsfrom
mentsontopofthephysicaltextureinvirtualrealityenvironments, thetransmittedtactiledata.Theserverthencomputestheclosest
allowingtheusertoexperiencemixedmaterialperception.Inthese trainingsampletothetransmitteddatainlatentspaceandsends
wheel-basedactuators,multiplephysicaltexturesareattachedtoa therawlatentvectorortheIDoftheclosestsampletoUserB.
UserBcanconfirmthereceivedtactilesensationthroughvisual
GNINIART
NOISSIMSNART
‚Ä¶UIST‚Äô23,October29-November1,2023,SanFrancisco,CA,USA TakekazuKitagishi,YuichiHiroi,YunaWatanabe,YutaItoh,andJunRekimoto
a b c
Figure3:(a)TheDIGITopticaltactilesensor.(b)Thejigstructure.Thejigfeaturesaholeforinsertingthespringandanother
holeforaccommodatingthesensorattachmentcord.(c)Insertingthesensorintothejig.Thefiguredemonstratesthecustom-
madejigtailoredtothesensor‚Äôsdimensionsandtheincorporatedspringmechanismforapplyingpressuretothesensor.
ortactilefeedback.Withthissequenceofevents,Telextileenables a b
end-to-endremotetransmissionofthetactilesensationoftextiles.
ThefollowingthreecomponentsarerequiredtorealizetheTelex-
tilessystem.Fromthenextsection,wedescribesthesethreecom-
ponents,includingimplementationdetails:
(1) Stablesensingdevice(Sec.4):Sincetactilesensorsaretypi-
callyattachedtotherobotarm,variationsinhowtheuser
measureshavenotbeenconsidered.Weimplementajigwith
amechanismthatkeepstheforceonthesensorconstant
andstabilizesthecontactanglewiththetextile.
(2) Learninggoodlatentrepresentation(Sec.5):Thelatentspace
thattheencoderlearnsshouldimplicitlylearntheproxim-
ity between the textures of each textile, e.g. smoothness,
stiffness,softness,etc.Weusecontrastiveself-supervised
Figure4:(a)Theusercapturingthetactilityoftextileswith
learningfortheencodertoobtainalatentspacethataccounts
ourtactilesensingdevice.(b)Thesensorisbeingpressed
fortheproximitybetweentactilesensationsoftextiles.
against the textile. It can be confirmed that the sensor is
(3) Tactilereproducibility(Sec.6):Thereisaneedforatactile
pressedinwithaconstantforceduetothespringforce.
devicethatcanwellreproducethetransmittedtactilesensa-
tion.Weimplementaroller-typeactuatorthatcanpresent
thephysicaltextilewiththeclosesttactilefeeltothetarget
textile. Ourdecisiontousetheproposedapproachratherthanother
texture-sensingsensorswaslargelybasedonresolution.Consider-
4 TACTILESENSINGDEVICE ingthecaseofonlineshopping,ahighresolutionthatcapturesthe
nuanceddetailsofatextile‚Äôstexture,whichaphotocan‚Äôtfullycap-
Figure3showsourtactilesensingdevice.Thisdeviceconsistsof
ture,isimportant,andinthisregard,DIGIThasanadvantageover
anopticaltactilesensor,DIGIT[16]byFacebookAI,withacustom
othermodalities,includingacoustics(microphones,ultrasonic,etc.)
jig.ThecombinationofthecustomjigandtheDIGITsensorallows
andfriction.TheDIGITsensorisalsoknownforitslightweight,
forconsistentandaccurateacquisitionoftactileinformationfrom
compactdesign,whichwasalsosuitablefortheonlineshopping
varioustextiles.
scenario.
4.1 TactileSensor 4.2 AttachedJig
TheDIGITsensorisavision-basedtactilesensor.Itconsistsof Thejigisadeviceforaccurateandconsistentdatacollection.Itis
adeformablereflectiveelastomer,RGBLEDlights,andacamera designedtoaccommodatethedimensionsofthesensorandmain-
(240√ó320pixels).Whenpressedagainstacomplexsurface,such tainaconstantangleandforcewhenpressedagainstthetextile.
asafabric,theelastomerdeformsaccordingtothetexture,the Consideringthattheforceanddirectionofthepressurevariesfrom
scatteredlightilluminatesthedeformation,andthecameracaptures persontoperson,itallowsdifferenttextilestobedetected,even
thesurfacedeformation,whichinturnrecordsthemicrostructure withunstablehand-heldsensors.Thejigconsistsofthecustom
ofthetextilesurface,providingdetailedtactileinformation.Our 3Dprintedcomponentandabuilt-inspringmechanism.Thecus-
systemusedthisimagingmodalityforinputandcreatedalatent tom3Dprintedcomponenthas2mmofclearanceonallsidesto
spaceusingself-supervisedcontrastivelearning. ensureatightfitbetweentheDIGITsensorandthejigtoreduceTelextiles:End-to-endRemoteTransmissionofFabricTactileSensation UIST‚Äô23,October29-November1,2023,SanFrancisco,CA,USA
anypotentialshiftingormovement.Italsohasaholeforinsert- imagetransformedwithdifferentdataaugmentations.Therefore,
ingaspringandanotherforthreadingacord.Thebuilt-inspring whencontrastivelearningDIGITimageswiththesemethods,itis
mechanismfunctionstoapplyaconstantforcetothesensor,which necessarytofindadataaugmentationmethodthatmatchesthe
isdeterminedbythespringcoefficientandthedimensionsofthe characteristicsoftheDIGITimages.
jig.Whentheforceexceedsacertainlevel,thejigstopspressing
againstthesensor,ensuringthattheforceappliedissufficientto 5.3 TrainingConfiguration
capturethesurfacetextureofthetextilewithoutcausingdamage.
WeimplementedtheencoderusingLightly[25],aself-supervised
Figure4showsauseractuallyusingthedevicetocapturethe
learninglibraryrunningonPyTorchLightning.Wewilldescribe
tactile image. A Styrofoam handle is attached to the top of the
thedetailofthemodelimplementationandtraining.
jigtohelptheuserapplyverticalforce.Thisfiguredemonstrates
howthejigmaintainsfullcontactwiththetextilesurfacewhile 5.3.1 NetworkArchitecture. WeusedtheResNet-18architectureas
applyingaconsistentangleandpressuretothesensor,ensuring thebackboneforourmodel.BeforeinputtingtheDIGITimageinto
sufficientforcetocapturethetextile‚Äôssurfacestructure.The3D theResNet,theimagewascroppedtoasizeof224√ó224basedon
printingdataforjigisavailable:https://drive.google.com/file/d/ thecenter.Toadaptthisnetworkforourspecifictask,wemodified
1N97winpXh05WP8o95XPEtPgdJ1QJu61o/view?usp=sharing thefinallayerofResNet-18tooutputa512-channeltensor.We
achievedthisbycombiningthelaterstagesofthenetworkwith
5 ENCODERFORTACTILEREPRESENTATION a1√ó1adaptiveaveragepoolinglayer.Finally,weobtaineda512-
OFTEXTILES dimensionalfeaturevector.
Toprocessandmodelthetactilefeaturesoftextiles,theencoder 5.3.2 TrainingData. Weassigned11participants(6malesand5
istrainedwithself-supervisedlearning.Especially,weusecon- females)tocollectdatafromall119samplesinthebook[29]and
trastivelearning,atypeofself-supervisedlearning,toreflectthe useditfortraining.Thisdatasetisacollectionofimagesacquired
proximitytothetactilityofthetextileinthelatentspace.Inthis usingtheDIGITsensor.Participantsweregivensimpleinstructions:
subsection,wefirstdescribethesetrainingmethods,thenthetrain- topressthesensoragainsteachfabricsampleuntilthejigmadecon-
ingconfigurationoftheencoder,andtheprocessingontheactual tactwiththesample.Wedidnotimposeanyadditionalrestrictions
testdata. orspecificguidelinesonhowtousethesensortoaccommodate
individualhandlingvariations,therebyfosteringmoregeneralized
5.1 Self-supervisedLearning
learningoftheself-supervisedmodel.Asaresult,someparticipants
Self-supervisedlearningisatypeofmachinelearninginwhich rotatedthesensorby90or180degrees,andtheforcesthatpartici-
an algorithm learns to predict certain features or properties of pantsappliedtothedevicevaried.Foreachfabricsample,images
datawithoutexplicitsupervisionorlabels.Bycreatingalatent werecapturedatarateof60framespersecondforadurationof
space of tactile information for textiles, it allows us to identify 2.5seconds,resultinginatotalof150imagespersample.
relationshipsbetweendifferenttextiles,includingthosenotpresent
5.3.3 DataAugmentation. Toimprovetherobustnessofourmodel,
inthetrainingdata.Thiscapabilityenablesthesystemtodisplay
we employed data augmentation techniques. We retained most
textileswithsimilarproperties,eveniftheywerenotpartofthe
ofthesettingsfromthegeneralcontrastivetrainingmodel,Sim-
originaltrainingdataset.
CLR[4].However,wemadesomeadjustmentstobettersuitthe
characteristicsoftheDIGITsensorimages.
5.2 ContrastiveLearning
First,becausetheDIGITimagedetectsmicrostructuresfrom
Contrastivelearninglearnstodistinguishbetweensimilaranddis-
threecolorsofLEDlight,weturnedoffdataenhancementsrelated
similarpairsofsamples.Incontrastivelearning,themodelistrained
tohuechange,impositionofGaussianblur,andgray-scaling.
onasetofdatapairs,whereeachpairconsistsoftwosimilaror
Next,giventhatthetexturemicrostructureofthetextileisin-
dissimilarsamples.Themodelistrainedtomaximizethesimilarity
varianttorotationandmirrorsymmetry,weadjustedtheimage
scoreofthesimilarpairsandminimizethesimilarityscoreofthe
rotationsettings:setprobabilitythatverticalfliptobe0.5,setprob-
dissimilarpairs.Thisisusuallydonebyusingacontrastiveloss
abilitythatrandomrotaiontobe1.0,andthesetrandomrotation
function. rangeto[‚àí180‚ó¶,180‚ó¶).
Whentheencoderistrainedonasetofpairsoftactileimagesof
Finally, we changed the normalization parameters to accom-
textiles,twoimagesoftextileswithsimilartactilepropertiesare
modate the unique properties of the DIGIT sensor images. We
learnedtomoveclosertogetherinlatentspace.Ontheotherhand,
calculatedthemeanandstandarddeviationforeachoftheRGB
twoimagesoftextileswithdifferenttactilepropertiesarelearned
valuesacrossallthetrainingdataandusedthesevaluesfornor-
tomovefurtherapartinlatentspace. malization.Wesetthemeanas[0.37932363,0.4131034,0.38336082]
WeemployedMoCo[13]asthecontrastiveloss.Asfarasusing andstandarddeviationas[0.11476628,0.08604312,0.16590593].
thecontrastivelosswithnegativeexamplesexplainedearlier,weob-
tainedalmostthesameaccuracywithdifferentlosschoices,suchas 5.3.4 OptimizerandEpochs. Foroptimizingournetworkduring
SimCLR[4].Ontheotherhand,whenweappliedcontrastivelearn- training,weutilizedtheStochasticGradientDescent(SGD)algo-
ingtoDIGITimages,wefoundthatcontrastlossdidnotprogress rithm.Wesetthelearningrateparameterto0.03,themomentum
atallwithoutnegativeexamples(e.g.,SimSiam[5],DINO[3],etc.). parameter to 0.9, and the weight decay parameter to 10‚àí4. We
These methods are trained on pairs of two images of the same trainedthemodelat200epochs.UIST‚Äô23,October29-November1,2023,SanFrancisco,CA,USA TakekazuKitagishi,YuichiHiroi,YunaWatanabe,YutaItoh,andJunRekimoto
6 FEEDBACKSFORTRANSMITTEDTACTILE
FEATURES
Feedbacktotheuserbasedontactilefeaturestransmittedfrom
theserverisprovidedbyvisualandtactilefeedbackmechanisms.
Toeffectivelycommunicatetherelationshipsbetweentextiles,the
originalhigh-dimensionallatentfeaturesneedtobereducedto
lower(generally,oneortwo)dimensionsforuser-friendlyvisual-
izationandinteraction.Toachievethis,UMAP(UniformManifold
ApproximationandProjection)[19]isemployedfordimensionality
reduction.UMAPisanon-lineardimensionalityreductiontech-
niquethatpreservesbothlocalandglobalstructuresinthedata,
whichiseffectiveinvisualizinghigh-dimensionaldatainalower-
dimensionalspacewhilemaintainingtherelationshipsbetween
datapoints.
Withthereduced-dimensionalfeatures,Telextilecanprovide
theuserwithvisualfeedbackthroughaninteractive2Dmap,and
tactilefeedbackthroughamotorizeddevicethatbringstheclosest
matchingtextiletotheuser‚Äôshandforcomparison.Thecombina-
tionofthetactilefeedbackandthevisualfeedbackprovidedbythe Figure5:UMAP2Dvisualizationofthefeaturevectorsofthe
2Dmapoffersusersacomprehensivewaytoexploretextileswith trainingdata(119differenttextiles).Itcanbeseenthatthe
similartextures,evenifthosetextileswerenotpartoftheoriginal majorityofthesamplesbelongtoseparateclusters.Textiles
trainingdata. withsimilarweavepatterns,ratherthansimilartactileprop-
erties,clustermorecloselyinlatentspace,suggestingthe
6.1 Visualfeedback limitationsoftheDIGITsensorincapturingdistincttactile
Thevisualfeedbackisdesignedtogiveusersawaytovisuallysee sensations.Forexample,thefabricsinthesetshavesimilar
howclosethetactileinformationsentistotheexistingtextile.It weaveandyarnthickness,butdifferentmaterialsandyarn
showstherelationshipbetweenatextiletouchedbyaremoteuser stiffness.Thethreefabricsontheleft,fromlefttoright,were
andasetoftextilespreviouslyregisteredinoursystem.Figure5 madeofwool,cotton,andsilk,withtheleftfeelingstiffer.
showsthemapping.Userscanaccessthismappingwhentheremote Thetwofabricsontheright,fromlefttoright,werecotton
userpressesthesensor.Inaddition,astheusermovesthecursor andlinen,withtheleftfeelingstiffer.
overthedots,additionalinformationisdisplayedtoassisttheuserin
imaginingthetactilefeelofthefabric,whichcouldincludeanimage
ofthetexture.Italsohastheabilitytozoombyspecifyinganarea,
distributedaroundtheplate,andconnectedtoamotor.Themotor
allowingtheusertoseetherelationshipbetweenthedotsindetail.
isprogrammedtorotatetheplatesothatthemostcompatiblefabric
Forexample,byspecifyingtheareaaroundthetestfabricdataand
comesinfrontoftheuser.Therotationofthemotoriscontrolled
zoomingin,therelationshipbetweenthetestfabricandthealready
bycalculatingthedistancebetweenthecentroidofthefeaturevec-
registeredfabriccanbeseenindetail.Wecreatedthisinteractive
torofthequerydataandthecentroidofthefeaturevectorofthe
2Dmapbyreducingtheoriginalhigh-dimensionalfeaturevectors
selectedfabricintheplate.
totwodimensionsusingUMAPandvisualizingthemusingplotly
The size of the wooden plate we used was 8 cm in diameter
[15].
and2cminthickness.Duetothelimitationsoftheplatesize,16
Inthefuture,thisvisualfeedbackwillprovideawayforusers
textileswereselectedfromthe119trainingsamplesinthisstudy.
toexploreandcomparetextilesbasedontactilecharacteristics.For
Herewedescribehowweselectedsometextilesfromthetraining
example,whenshoppingonline,userscanexploregarmentsthat
samplestoselectfabricsthatcoverdifferentareasinthelatent
feelsimilartothegarmenttheyhavealreadypurchased,orsee
space;first,weusedUMAPfordimensionalityreductionofthe
howsimilarthefeelofgarmentstheyareconsideringpurchasing
featuresofthetrainingsamplesto1D(scalarvalue)toapplyto
istothefeelofatypicaltextile.Intheseapplications,thisvisual
theone-dimensionalstructureoftheplate.Then,16ofthetraining
feedbackcanbecombinedwithtactilefeedback,discussedbelow,
sampleswereselectedfromthisnumberlinesothattheywere
toenhancetheuser‚Äôsunderstandingofthetactileexperienceofthe
equidistantfromeachother.
garment.
6.2.1 HardwareConfiguration. Figure6showsthehardwarecom-
6.2 ActuatorDesignforTactileFeedback
ponentsoftheinteractiondeviceincludinganESP32microcon-
Theactuatorisdesignedtoprovidetactilefeedbacktotheuser. troller(ESP32-WROOM-32D,EspressifSystem),asteppermotor
Theusercanphysicallycomparetheclosestmatchingtextiletothe (ST-42BYH1004-5013,MercuryMotor),andamotordriver(A4988,
receivedtactilefeaturevectorviatheactuator. KKHMF).
Weusedaroller-typeactuatorinspiredbytheHapticRevolver[34]. Afterdeterminingtheclosestmatchingtextile,themainsystem
Thesampletextileswereplacedonacircularwoodenplate,evenly calculatesthemotorrotationanglebasedonthecurrentpositionTelextiles:End-to-endRemoteTransmissionofFabricTactileSensation UIST‚Äô23,October29-November1,2023,SanFrancisco,CA,USA
WithJig Max@top1(%) Final@top1(%)
Power
Supply Wooden Plate No 82.84 81.70
with Textiles Yes 99.69 99.24
Actuator Table1:Theeffectofthejigusage.Byusingthejig,wecan
improvetheùëò =1accuracyofùëò-nearestneighborclustering.
Motor Driver Max@top1isthemaximumaccuracyduringthewholetrain-
ingepoch,andFinal@top1istheaccuracyattheendofthe
trainingepoch.
ESP32 Stepping
microcontroller Motor
7.1 LatentSpaceEvaluation
Figure 6: The hardware configuration of the actuator, in- Toexaminehowdistinctlydifferenttextileswerepositionedwithin
cludingasteppingmotor,aroller,amotordriver,anESP32 thelatentspace,weusedtheùëò-nearestneighbormethodtocluster
microcontroller,andelectroniccircuitry. thelatentspaceandmeasuredtheaccuracybycomparingthese
clusterlabelswiththeactuallabels.ùëò-nearestneighbor(kNN)is
amachinelearningalgorithmthatclassifiesanewdatapointby
findingtheùëò nearestpointsinthetrainingsetandassigningthe
andtargetpositionoftheplate.TheESP32communicateswiththe
label of the majority of those neighbors to the new data point.
systemviaBluetoothserialandreceivesthecalculatedrotation
Wetrainedtheencoderusingthetrainingdata,thendetermined
angle.Itthensendssignalstothedriver,andthedrivercontrols
theclusterofthefeaturevectorsforthetestdata.Thisdatawas
therotationofthesteppermotoraccordingtothereceivedsignals.
collectedfromamalesubjectinthesamemannerasthetraining
Themotorrotatestheplateovertheshortestpossibledistance.
data.Weappliedclusteringtothefeaturevectorsandcompared
TheESP32setsthevoltageontheDIR(direction)pinofthemotor
theresultswiththeactuallabels.
driver.IftherotationanglereadfromtheBluetoothserialispositive,
Theresultwasthatthelearnedlatentspaceclustered119types
theDIRpinissettoHIGH,causingthemotortorotateclockwise.If
oftextileswith80.44%accuracy.Fromtheresult,althoughthe
theangleisnegative,theDIRpinissettoLOW,causingthemotor
visualfeedbackfromdimensionalitycompressioninUMAPdidnot
torotatecounterclockwise.
separatesomedata(Fig.5),weconfirmedthatourlatentspaceissuf-
The stepper motor has a fixed angle of rotation per step. To
ficientlycapableofseparatingtextilefeaturesinhigherdimensional
calculatethenumberofstepsrequiredtoreachthetargetangle,
spaces.
thevaluereceivedfromtheBluetoothserialisdividedbythefixed
In addition, we evaluated the impact of using the jig on our
angle.TheESP32sendspulsesequaltothecalculatednumberof
model‚Äôscapabilitytolearnmeaningfulrepresentationsoffabric
stepstotheSTEPpinofthemotordriver.Themotordriverthen
textures.Oneparticipantcollecteddatafromall119samplesin
controlsthesteppermotortorotatetothedesiredangle.
thebook[29],withandwithoutthejig.Foreachsample,thefirst
6.2.2 SoftwareConfiguration. Thesoftwarecontrolstheactuators 120imageswereusedfortraining,whiletheremaining30images
bythefollowingsteps: werereservedfortesting.WetrainedtheMoComodelonthisdata,
keepingtheparametersconsistentwiththosespecifiedinSection
(1) CalltheAPIeverysecondtogetanumberrepresentingthe
5.3.Wethenfedthetestdataintotheencodertogenerateembed-
targetpositionaccordingtothedistanceintheembedding
dings.Theseembeddingswerethensubjectedtok-NNclustering,
space.
theresultsofwhichwerecomparedwiththeactuallabels.
(2) Calculatetheangleatwhichthemotorshouldturnbymul-
tiplyingthenumberby360/ùëÅ,whereùëÅ isthenumberof Table1showstheresults.Thedatacollectedwithourcustomized
jigwasabletoclusterwith99.69%accuracy.Incontrast,without
samplesontheactuator.
thejig,theaccuracydroppedto82.84%.Theseresultsconfirmthat
(3) Calculatetheangletorotatebasedonthestoredcurrent
thejigincreasesthestabilityoftheinputdata.
motorangleandtheanglecalculatedin(2).Settheangleto
beclockwiseifitiscloserorcounterclockwiseifitiscloser.
(4) Sendtheanglecalculatedin(3)totheESP32viaBluetooth 7.2 UserTest
serialcommunication. Todeterminewhetherthemodelcouldassessthesimilaritiesbe-
tween fabric combinations as accurately as those perceived by
7 EVALUATION
individuals,weconductedausertest.
Toevaluatewhetherthelatentspacemirrorsthetactilesensation Figure7showstheusertest.Inordertogetthesimilarityjudged
ofthetextile,weexaminedhowdistinctlydifferenttextileswere byhumans,thesubjectsperformedtwoprimarytasks.First,they
positionedwithinthelatentspace.Then,weconductedausertestto wereaskedtorandomlyselectonesamplefrom[29],whichincluded
determinewhetherthemodelcouldassessthesimilaritiesbetween thesamplesusedtotrainourmodel.Second,theywereaskedto
fabriccombinationsasaccuratelyasthoseperceivedbyindividuals. identifythefivesamplesontheboard,whichhas16samplesweUIST‚Äô23,October29-November1,2023,SanFrancisco,CA,USA TakekazuKitagishi,YuichiHiroi,YunaWatanabe,YutaItoh,andJunRekimoto
a Kmostsimilar,comparingtherandomlyselectedsampletothe
sampleontheboard.
Figure8showstheresult.WecalculatedtheTop-Kaccuracyfor
K=0,1,2,...,16.Forthesamplesusedornotusedfortraining,the
accuracythattheencoderchoseTopKforwhatthehumanchose
asTop1was16.7%,14.3%.Thisindicatesthattheperformanceof
theself-supervisedlearningmodelwasbetterthanrandom.
Fortherankcorrelationcoefficientt-test,wecomparedtheranks
assignedbyhumansandsystemstoseeiftherewasasignificant
differencebetweenthem.WecomputedtheSpearmanrankcorre-
b
lationcoefficientforeachtrial,withvaluescloseto1indicatinga
strongercorrelationandvaluescloseto0indicatingaweakercor-
relation.Thenullhypothesisofnosignificantdifferencebetween
thecorrelationofeachstudyand0wastestedusingat-test.
Theresultwasthatweobtainedp-valuesof0.518and0.9for
thetrainingandnon-trainingsamples,respectively,whichdidnot
rejectthenullhypothesis.Thismeansthatwecannotconfirma
correlationbetweentherankingmethodsofthesystemandthose
oftheusers.
Theseresultssuggestthattheencoder‚Äôschoicesdidnotmatch
thehumansubjects‚Äôchoicesenough,andthereisroomforimprove-
ment.Onepossiblereasonforthisisthathumansseemtotakethe
senseoffrictionintoaccount,whilethesystemdoesnot.During
theinputphase,wesimplypressedtheDIGITsensoragainstthe
Figure7:UserExperiment.Subjectswereaskedtoperform surfaceofthecloth.Ontheotherhand,thesubjectstendedtoslide
thefollowingproceduresthreetimes.(a)Subjectsselecta theirfingersacrossthecloth.Thissuggeststhatthepatternrecog-
patternfrom[29],whichincludesthesamplesusedtotrain nitionmethodsusedbyoursystemandhumansmaynotyetbe
ourmodel,or[20],whichincludessamplesnotusedtotrain fullyaligned,andthatslidingthesensorandcapturingthesenseof
the model, and touch it. (b) They then touch 16 different frictionmaybeeffective.
patternsthatwehaveimplementedontheactuatorandselect
thefivepatternsthatfeelclosesttotheirchosenfabric.
8 DISCUSSIONANDFUTUREWORK
Oursystemleveragesthepowerofself-supervisedlearningtocreate
acontinuouslatentspacerepresentationofmaterialproperties,
usedfortactilefeedback,thatweremostsimilartothesamplese- enablingthesystemtoadapttounknowndataandeffectivelymatch
lected.Thisprocesswasrepeatedthreetimes.Subsequently,they similartextures.Whilethisadaptabilityallowsforamoreversatile
wereaskedtorepeatthesameprocesswithasamplefrom[20], anddynamicinteractionwiththephysicalworld,thereisstillroom
whichincludedsamplesnotusedtotrainthemodel.Wehadeight forimprovementinoursystem.
participants‚Äîthreefemalesandfivemales.Twoparticipantscom- Theusertestsuggestedthatthejudgmentsmadebythehuman
pletedonetrialeach,whilesixparticipantscompletedtwotrials andthemodelwerenotinagreement.Observationsduringthe
each,givingatotalof14. experimentshowedthatwhenpeopletooktactilesensationsofthe
Ontheotherhand,wecalculatedthesimilarityjudgedbythe cloth,theyslidtheirfingersoverthecloth,notjustpressedagainst
model,betweentherandomlyselectedsamplesandthefabricson itasthesensordid.Byslidingthesensorduringdataacquisition,
theboard.Forthesamplesselectedbythesubjectsinthe42trials, wemaybeabletocaptureastrongersenseoffrictionforthecloth,
weacquiredtactiledatausingtheinputdevice.Wethenextracted providingamoreaccurateanddetailedrepresentationoffabric
thefeaturesinthelatentspaceandcalculatedtheircentroids.Simi- textures.Additionally,incorporatingamechanismtocapturetime
larly,wecalculatedthecentroidsofthefabricsontheboard.Next, serieschangesinthemodelcouldimprovethesystem‚Äôsadaptability
toassessthesimilaritybetweentheselectedsamplesandtheboard andresponsiveness.
samples,wecalculatedtheEuclideandistanceinthelatentspace Inthevisualfeedbacksystem,wefoundthattextileswithsimilar
betweentheircentroids.Weorderedtheboardsamplesbydistance weave patterns, rather than similar tactile properties, clustered
andselectedthefivemostsimilarsamples. morecloselyinthelatentspace,suggestingthelimitationsofthe
Tocomparethesimilarityjudgedbythehumanandthesimilarity DIGITsensorincapturingdistincttactilesensations.Capturing
judgedbythemodel,weevaluatedthemusingTop-Kaccuracyand additionalfeaturessuchasfrictionandthermalsensation,perhaps
at-testfortherankcorrelationcoefficient.ForTop-Kaccuracy,we throughsensorslidingortemperaturesensing,couldimprovethe
calculatedtheproportionof‚Äôcorrect‚Äôtrialsoutofall42trials.We effectivenessofthesystem.
definedatrialas‚Äôcorrect‚Äôifthesubjectjudgedittobewithinthe Inthetactilefeedbacksystem,thenumberoftypesoftactile
top1mostsimilarandthemodeljudgedittobewithinthetop informationthattherollercandisplayislimited.OurchoiceofaTelextiles:End-to-endRemoteTransmissionofFabricTactileSensation UIST‚Äô23,October29-November1,2023,SanFrancisco,CA,USA
andangleduringinteractions.Thisintegrationcouldleadtomore
reliableandaccurateresults.
Theversatilityofthejigattachmentallowsforvariousapplica-
tionsandadaptations.Inourstudy,weusedapolyesterhandle,
butthejigcouldbeattachedtodifferentpropssuchassticksor
boards.Thisflexibilityexpectstheacquisitionoftactileimpressions
oftextileswithlessforceapplication,enablingamoreconsistent
dataacquisitionprocess.
Theminiaturizationofouractuatorcouldchangethewaywe
interactwiththeworld,allowingformoreimmersiveexperiencesin
remotecommunicationandteleoperationscenarios.Ontheother
hand, miniaturization requires the development of research on
tactileactuatorsthatcanreproducethetactilesensationofmore
delicatetextiles.Ifsuchminiaturizedactuatorsaredeveloped,such
aswristwatchcommunicationdevicesandfingertipsensordevices,
theactuatorscanbeexpectedtoreplacethecurrentroller-type
actuators.
9 CONCLUSION
InthisstudyweproposeTelextiles,aninterfacethatcanremotely
transmittactilesensationsoftextiles.Usingcustomtactilesensing
devices,contrastlearninglatentspacerepresentation,androller
actuators,wedemonstratedthatoursystemiscapableofend-to-end
remotetextiletactilesensing.Oursystemistheoreticallycapableof
mappingandpresentinganinfiniteamountoftactileinformation
toafinitesample,andisexpectedtofacilitatevaluejudgmentsin
onlineshoppingandtelecommunications.
ACKNOWLEDGMENTS
WewouldliketothankHirotakaHirakiandNaokiKimurafortheir
insightfuldiscussions.WearegratefultoKiyosuMaedaforhishelp
Figure8:Comparisonofhumanjudgmentandmodelinfer-
withservercommunications,andtoShotaKiuchiforhishelpin
enceinidentifyingtheclosesttactilematchamong16textiles
developingthejig.Wealsoappreciatethecontributionsofallthose
forarandomlyselectedclothsample,forsamplesusedin
whoparticipatedinourexperimentsandprovidedadviceduringlab
trainingandsamplesnotusedintraining.Thegraphpresents
meetings.ThisworkwassupportedbyJSTMoonshotR&DGrant
thepercentageofcorrectresponseswhenthehuman-selected
Number JPMJMS2012, JST CREST Grant Number JPMJCR17A3,
textileiswithintheTopKmodel-inferredclosesttextiles,
JSPSKAKENHIGrantNumberJP20H05958,JSTFORESTGrant
comparedtotheexpectedcorrectanswerratefromrandom
NumberJPMJFR206E,thecommissionedresearchofNICTJapan,
textilechoice.
andtheUniversityofTokyoHumanAugmentationResearchInitia-
tive.
rollerasafeedbackdeviceistoverifytheproperfunctioningofthe REFERENCES
latentspace.Enhancingtheinteractiondevicetosupport2Dor3D [1] BrunoAraujo,RicardoJota,VarunPerumal,JiaXianYao,KaranSingh,and
spatialrepresentationsoffabrictactilesensationortactiledigital DanielWigdor.2016.SnakeCharmer:PhysicallyEnablingVirtualObjects.In
ProceedingsoftheTEI‚Äô16:TenthInternationalConferenceonTangible,Embedded,
fabrication,suchasacousticsandmicrostructures,couldenable andEmbodiedInteraction(Eindhoven,Netherlands)(TEI‚Äô16).Associationfor
oursystemtoconveymoredetailedinformationaboutthefabrics, ComputingMachinery,NewYork,NY,USA,218‚Äì226.
[2] MBouzit,GBurdea,GPopescu,andRBoian.2002.TheRutgersMasterII-new
furtherenrichingtheuserexperience.Theseimprovementscould
designforce-feedbackglove. IEEE/ASMETrans.Mechatron.7,2(June2002),
contributetothedevelopmentofmoreintuitiveanduser-centered 256‚Äì263.
interfacesinavarietyofapplications. [3] MathildeCaron,HugoTouvron,IshanMisra,Herv√©J√©gou,JulienMairal,Piotr
Bojanowski,andArmandJoulin.2021.EmergingPropertiesinSelf-Supervised
The16fabricsshouldbechosentocoverdifferentareasoflatent
VisionTransformers.InProceedingsoftheIEEE/CVFInternationalConferenceon
space.Thediversityofthese16fabricsmightbebettercapturedby ComputerVision(ICCV).IEEE,Piscataway,NJ,USA,9650‚Äì9660.
orderingusingthefirstprincipalcomponentofPCA,orlatentspace [4] TingChen,SimonKornblith,MohammadNorouzi,andGeoffreyHinton.2020.
ASimpleFrameworkforContrastiveLearningofVisualRepresentations.In
clustering with 16 k-means. The optimal method needs further Proceedingsofthe37thInternationalConferenceonMachineLearning(Proceedings
investigation. ofMachineLearningResearch,Vol.119),HalDaum√©IIIandAartiSingh(Eds.).
PMLR,1597‚Äì1607. https://proceedings.mlr.press/v119/chen20j.html
Integratingoursystemwithroboticplatformscouldautomate
[5] XinleiChenandKaimingHe.2021. Exploringsimplesiameserepresentation
thetactiledataacquisitionprocess,maintainingaconstantforce learning.InProceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternUIST‚Äô23,October29-November1,2023,SanFrancisco,CA,USA TakekazuKitagishi,YuichiHiroi,YunaWatanabe,YutaItoh,andJunRekimoto
recognition.IEEE,Piscataway,NJ,USA,15750‚Äì15758. [26] RyoSuzuki,EyalOfek,MikeSinclair,DanielLeithinger,andMarGonzalez-Franco.
[6] FrancescoChinello,MonicaMalvezzi,ClaudioPacchierotti,andDomenicoPrat- 2021.HapticBots:DistributedEncountered-typeHapticsforVRwithMultiple
tichizzo.2015.Designanddevelopmentofa3RRSwearablefingertipcutaneous Shape-changingMobileRobots.InThe34thAnnualACMSymposiumonUser
device.In2015IEEEInternationalConferenceonAdvancedIntelligentMechatronics InterfaceSoftwareandTechnology(VirtualEvent,USA)(UIST‚Äô21).Association
(AIM).IEEE,Piscataway,NJ,USA,293‚Äì298. forComputingMachinery,NewYork,NY,USA,1269‚Äì1281.
[7] DonaldDegraen,MichalPiovarƒçi,BerndBickel,andAntonioKr√ºger.2021.Cap- [27] RyoSuzuki,ClementZheng,YasuakiKakehi,TomYeh,EllenYi-LuenDo,MarkD
turingTactilePropertiesofRealSurfacesforHapticReproduction.InThe34th Gross,andDanielLeithinger.2019.ShapeBots:Shape-changingSwarmRobots.
AnnualACMSymposiumonUserInterfaceSoftwareandTechnology(VirtualEvent, InProceedingsofthe32ndAnnualACMSymposiumonUserInterfaceSoftware
USA)(UIST‚Äô21).AssociationforComputingMachinery,NewYork,NY,USA, andTechnology(NewOrleans,LA,USA)(UIST‚Äô19).AssociationforComputing
954‚Äì971. Machinery,NewYork,NY,USA,493‚Äì505.
[8] DonaldDegraen,AnnaReindl,AkhmajonMakhsadov,Andr√©Zenner,andAnto- [28] KuniyukiTakahashiandJethroTan.2019. DeepVisuo-TactileLearning:Esti-
nioKr√ºger.2020.EnvisioningHapticDesignforImmersiveVirtualEnvironments. mationofTactilePropertiesfromImages.In2019InternationalConferenceon
InCompanionPublicationofthe2020ACMDesigningInteractiveSystemsCon- RoboticsandAutomation(ICRA).IEEE,IEEE,Piscataway,NJ,USA,8951‚Äì8957.
ference(Eindhoven,Netherlands)(DIS‚Äô20Companion).AssociationforComput- [29] MichikazuTanaka.2009. Youfukujinojiten. MIZUSHIMAKAKOUCO.,LTD.,
ingMachinery,NewYork,NY,USA,287‚Äì291. https://doi.org/10.1145/3393914. Osaka,Japan.
3395870 [30] TasbolatTaunyazov,HuiFangKoh,YanWu,CaixiaCai,andHaroldSoh.2019.
[9] DonaldDegraen,Andr√©Zenner,andAntonioKr√ºger.2019.EnhancingTexture TowardsEffectiveTactileIdentificationofTexturesusingaHybridTouchAp-
PerceptioninVirtualRealityUsing3D-PrintedHairStructures.InProceedings proach.In2019InternationalConferenceonRoboticsandAutomation(ICRA).IEEE,
ofthe2019CHIConferenceonHumanFactorsinComputingSystems(Glasgow, Piscataway,NJ,USA,4269‚Äì4275. https://doi.org/10.1109/ICRA.2019.8793967
ScotlandUk)(CHI‚Äô19,Paper249).AssociationforComputingMachinery,New [31] EmanuelVonach,ClemensGatterer,andHannesKaufmann.2017. VRRobot:
York,NY,USA,1‚Äì12. Robotactuatedpropsinaninfinitevirtualenvironment.In2017IEEEVirtual
[10] CathyFang,YangZhang,MatthewDworman,andChrisHarrison.2020.Wireal- Reality(VR).IEEE,Piscataway,NJ,USA,74‚Äì83.
ity:EnablingComplexTangibleGeometriesinVirtualRealitywithWornMulti- [32] TWatanabeandSFukui.1995. Amethodforcontrollingtactilesensation
StringHaptics.InProceedingsofthe2020CHIConferenceonHumanFactorsin ofsurfaceroughnessusingultrasonicvibration.InProceedingsof1995IEEE
ComputingSystems(Honolulu,HI,USA)(CHI‚Äô20).AssociationforComputing InternationalConferenceonRoboticsandAutomation,Vol.1.IEEE,Piscataway,NJ,
Machinery,NewYork,NY,USA,1‚Äì10. USA,1134‚Äì1139vol.1.
[11] RuihanGao,TianTian,ZhipingLin,andYanWu.2021.OnExplainabilityand [33] EricWhitmire,HrvojeBenko,ChristianHolz,EyalOfek,andMikeSinclair.2018.
Sensor-AdaptabilityofaRobotTactileTextureRepresentationUsingaTwo-Stage HapticRevolver:Touch,Shear,Texture,andShapeRenderingonaReconfig-
RecurrentNetworks.In2021IEEE/RSJInternationalConferenceonIntelligent urableVirtualRealityController.InProceedingsofthe2018CHIConferenceon
RobotsandSystems(IROS).IEEE,Piscataway,NJ,USA,1296‚Äì1303. HumanFactorsinComputingSystems(MontrealQC,Canada)(CHI‚Äô18,Paper86).
[12] EricJGonzalez,ParastooAbtahi,andSeanFollmer.2020.REACH+:Extendingthe AssociationforComputingMachinery,NewYork,NY,USA,1‚Äì12.
ReachabilityofEncountered-typeHapticsDevicesthroughDynamicRedirection [34] EricWhitmire,HrvojeBenko,ChristianHolz,EyalOfek,andMikeSinclair.2018.
inVR.InProceedingsofthe33rdAnnualACMSymposiumonUserInterfaceSoftware HapticRevolver:Touch,Shear,Texture,andShapeRenderingonaReconfigurable
andTechnology(VirtualEvent,USA)(UIST‚Äô20).AssociationforComputing VirtualRealityController.InProceedingsofthe2018CHIConferenceonHuman
Machinery,NewYork,NY,USA,236‚Äì248. FactorsinComputingSystems(MontrealQC,Canada)(CHI‚Äô18).Association
[13] KaimingHe,HaoqiFan,YuxinWu,SainingXie,andRossGirshick.2020.Momen- forComputingMachinery,NewYork,NY,USA,1‚Äì12. https://doi.org/10.1145/
tumcontrastforunsupervisedvisualrepresentationlearning.InProceedingsofthe 3173574.3173660
IEEE/CVFconferenceoncomputervisionandpatternrecognition.IEEE,Piscataway, [35] MichaelWiertlewskiandJEdwardColgate.2015. Poweroptimizationoful-
NJ,USA,9729‚Äì9738. trasonicfriction-modulationtactileinterfaces. IEEETrans.Haptics8,1(2015),
[14] ShiyaoHuangandHaoWu.2021.Texturerecognitionbasedonperceptiondata 43‚Äì53.
fromabionictactilesensor.Sensors21,15(2021),5224. [36] WenzhenYuan,YuchenMo,ShaoxiongWang,andEdwardH.Adelson.2018.
[15] PlotlyTechnologiesInc.2015. Collaborativedatascience. PlotlyTechnologies ActiveClothingMaterialPerceptionUsingTactileSensingandDeepLearning.
Inc.,Montreal,QC. https://plot.ly In2018IEEEInternationalConferenceonRoboticsandAutomation(ICRA).IEEE,
[16] MikeLambeta,Po-WeiChou,StephenTian,BrianYang,BenjaminMaloon,Victo- Piscataway,NJ,USA,4842‚Äì4849. https://doi.org/10.1109/ICRA.2018.8461164
riaRoseMost,DaveStroud,RaymondSantos,AhmadByagowi,GreggKammerer,
DineshJayaraman,andRobertoCalandra.2020. DIGIT:ANovelDesignfor
aLow-CostCompactHigh-ResolutionTactileSensorWithApplicationtoIn-
HandManipulation.IEEERoboticsandAutomationLetters5,3(2020),3838‚Äì3845.
https://doi.org/10.1109/LRA.2020.2977257
[17] RuiLiandEdwardHAdelson.2013.Sensingandrecognizingsurfacetextures
usingagelsightsensor.InProceedingsoftheIEEEConferenceonComputerVision
andPatternRecognition.IEEE,Piscataway,NJ,USA,1241‚Äì1247.
[18] ThomasHMassie,JKennethSalisbury,andOthers.1994.Thephantomhaptic
interface:Adeviceforprobingvirtualobjects.InProceedingsoftheASMEwin-
terannualmeeting,symposiumonhapticinterfacesforvirtualenvironmentand
teleoperatorsystems,Vol.55.ASME,TwoParkAvenue,NY,USA,295‚Äì300.
[19] LelandMcInnes,JohnHealy,andJamesMelville.2018.UMAP:UniformManifold
ApproximationandProjectionforDimensionReduction. arXive-prints(Feb.
2018),arXiv‚Äì1802.arXiv:1802.03426[stat.ML]
[20] MIZUSHIMAKAKOUCO.,LTD.2012. AUENCYCLOPEDIAOFCLOTHES.
MIZUSHIMAKAKOUCO.,LTD.,Osaka,Japan.
[21] YashrajNarang,BalakumarSundaralingam,MilesMacklin,ArsalanMousavian,
andDieterFox.2021.Sim-to-RealforRoboticTactileSensingviaPhysics-Based
SimulationandLearnedLatentProjections.In2021IEEEInternationalConference
onRoboticsandAutomation(ICRA).ieeexplore.ieee.org,Piscataway,NJ,USA,
6444‚Äì6451.
[22] ClaudioPacchierotti,StephenSinclair,MassimilianoSolazzi,AntonioFrisoli,
VincentHayward,andDomenicoPrattichizzo.2017.WearableHapticSystems
fortheFingertipandtheHand:Taxonomy,Review,andPerspectives.IEEETrans.
Haptics10,4(May2017),580‚Äì600.
[23] NicholasPestellandNathanFLepora.2022. ArtificialSA-I,RA-IandRA-
II/vibrotactileafferentsfortactilesensingoftexture.JournaloftheRoyalSociety
Interface19,189(2022),20210603.
[24] DomenicoPrattichizzo,FrancescoChinello,ClaudioPacchierotti,andMonica
Malvezzi.2013.Towardswearabilityinfingertiphaptics:a3-DoFwearabledevice
forcutaneousforcefeedback.IEEETrans.Haptics6,4(2013),506‚Äì516.
[25] IgorSusmelj,MatthiasHeller,PhilippWirth,JeremyPrescott,andMalteEbner
etal.2020.Lightly.GitHub.Note:https://github.com/lightly-ai/lightly(2020).