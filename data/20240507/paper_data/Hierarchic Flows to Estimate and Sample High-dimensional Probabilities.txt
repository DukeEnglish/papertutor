HIERARCHIC FLOWS TO ESTIMATE AND SAMPLE
HIGH-DIMENSIONAL PROBABILITIES
APREPRINT
EtienneLempereur*1andSteÂ´phaneMallat2,3
1DeÂ´partementdâ€™informatique,EcolenormalesupeÂ´rieure,Paris,France
2Colle`gedeFrance,Paris,France
3FlatironInstitute,NewYork,USA
May7,2024
ABSTRACT
Findinglow-dimensionalinterpretablemodelsofcomplexphysicalfieldssuchasturbulenceremains
an open question, 80 years after the pioneer work of Kolmogorov. Estimating high-dimensional
probability distributions from data samples suffers from an optimization and an approximation
curseofdimensionality. Itmaybeavoidedbyfollowingahierarchicprobabilityflowfromcoarse
to fine scales. This inverse renormalization group is defined by conditional probabilities across
scales,renormalizedinawaveletbasis. ForaÏ†4scalarpotential,samplingthesehierarchicmodels
avoidsthecriticalslowingdownatthephasetransition. Anoutstandingissueistoalsoapproximate
non-Gaussianfieldshavinglong-rangeinteractionsinspaceandacrossscales. Weintroducelow-
dimensionalmodelswithrobustmultiscaleapproximationsofhighorderpolynomialenergies. They
arecalculatedwithasecondwavelettransform,whichdefinesinteractionsovertwohierarchiesof
scales. Weestimateandsamplethesewaveletscatteringmodelstogenerate2Dvorticityfieldsof
turbulence,andimagesofdarkmatterdensities.
1 Introduction
Estimatingmodelsofhigh-dimensionalprobabilitydistributionsfromdataisattheheartofdatascienceandstatistical
physics. Foraphysicalsystematequilibrium,theprobabilitydistributionofafieldÏ†âˆˆRd(suchasanimage)hasa
densityp(Ï†)=Zâˆ’1eâˆ’U(Ï†),whereU(Ï†)istheGibbsenergy[LL13]. Learningmeansapproximatingandoptimizing
anestimationofthehigh-dimensionalenergyfunctionU,frommdatasamples{Ï†(i)} resultingfrommeasurementsor
i
numericalsimulations. Newdatacanthenbegeneratedbysamplingtheestimatedmodelofp,whichisalsousedto
estimatesolutionsofinverseproblems[KS06,ABT18]. TheestimationofaGibbsenergyisparticularlydifficultwhen
Ï†haslongrangedependencies,anditsdimensiondislarge. Anoutstandingproblemistobuildprobabilisticmodelsof
turbulentflows,whichdatesbacktotheworkofKolmogorovin1942[kol41,Kol42].
In statistics, p is estimated by defining an approximation class p and by optimizing Î¸. These approximation and
Î¸
optimizationproblemsareplaguedbythecurseofdimensionality. Section2reviewsbothaspects. Itincludeslinear
approximationsofGibbsenergies,maximumlikelihoodestimationversusscorematching,andsamplingbyLangevin
diffusions. Onecandefinelow-dimensionalapproximationclassesifinteractionsarelocalwithinÏ†,asinMarkov
randomfields[GG84]. Theoptimizationcurseisalsoavoidedifthelog-Sobolevconstantofpremainsboundedwhend
increases[Gro75,Led00,BGL+14]. Sadlyenough,noneofthesetwopropertiesaresatisfiedbycomplexdatasuchas
turbulencefields. Addressingtheapproximationandoptimizationcurseofdimensionalityrequiresintroducingmore
flexiblemodels.
Fromacyberneticsperspective,HerbertSimonsobservedthatthearchitectureofmostcomplexsystemsishierarchic,
inphysics,biology,economic,symboliclanguages,orsocialorganizations. Hearguesthatitprobablyresultsfromtheir
dynamicevolution,whereintermediatestatesmustbestable[Sim62]. Thisattractiveideacouldexplainwhythecurse
âˆ—etienne.lempereur@ens.fr
4202
yaM
6
]LM.tats[
1v86430.5042:viXraHierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
p
J J
p
J
p
j
p
j
p
j-1
p
j-1
p
0
Figure1: Therenormalizationgroup(illustratedinblue)computestheprobabilitydistributionsp (Ï† )ofimagesÏ† at
j j j
progressivelylargerscales2j,withmarginalintegrationsofhigh-frequencydegreesoffreedom,uptoamaximumscale
2J. Ahierarchicflow(illustratedinred)isatop-downinverseMarkovchainwhichrecoverspfromp byestimating
J
eachtransitionprobabilitypÂ¯ fromp top . DifficultiesarisewhenpÂ¯ isnon-local,asinturbulentflows.
j j jâˆ’1 j
ofdimensionalitycanbeavoidedwhenanalyzingsuchsystems,butthenotionofhierarchyislooselydefined. The
coreprincipleofhierarchicorganizationsistobuildlongrangeinteractionsfromalimitednumberoflocalinteractions
betweenneighborsinthehierarchy. Butlargesystemsincludemultiplehierarchiesproducingcomplexlong-range
interactionsinmultidimensionalmatrixorganizations, asopposedtoatree. Forexample, largecorporationsoften
includehorizontalhierarchicorganizationsdedicatedtospecificprojects,ateachverticalhierarchiclevel[Tur18]. It
createslong-rangeinteractionsbetweenemployeesworkingonasameproject. Inphysics,therenormalizationgroup
theoryprovidesahierarchicanalysisofmultiplebodyinteractions. Itcomputesaflowofprobabilitiesfromafine
microscopicscaletowardslargermacroscopicscales[Kad66,Wil71,WF72,Del12].
However,majordifficultieshavebeenencounteredtotakeintoaccountnon-localinteractionsinspaceandacrossscales.
Particularlyfornon-renormalizablesystemssuchasturbulence,whosedegreesoffreedomincreasewiththedimension
dofÏ†[BJPV98].
Thispaperdefineshierarchicmodelstoestimateandsamplehigh-dimensionalnon-Gaussianprocesseshavingnon-local
interactions.Section3considersdataÏ†âˆˆRddefinedongraphs,orimages.Afirsthierarchicorganizationisconstructed
withcoarsegrainingapproximationsÏ† ofÏ†,ofprogressivelysmallersizesasthescale2j increases. Figure1givesan
j
illustrationofthevorticityfieldofa2Dturbulence. Theprobabilitydensityp(Ï†)isprogressivelymappedintodensities
p (Ï† )fromfinetocoarsescales2j.Thisrenormalizationgrouptransformationiscomputedbymarginalintegrationsof
j j
thehighfrequencydegreesoffreedom,whichprogressivelydisappearasj increases. Thereisnodifficultytoestimate
andsamplep (Ï† )ifÏ† hasalowdimension. Fromthisestimation,thehigh-dimensionalmodelofpcanbeestimated
J J J
andsampledwithareverseMarkovchain. Ittransformsp intopbyiterativelycomputingp fromp ,asshownby
J jâˆ’1 j
Figure1. EachtransitionkernelpÂ¯ ofthishierarchicflowistheconditionalprobabilityofÏ† givenÏ† . Themain
j jâˆ’1 j
difficultyistounderstandonwhatconditionsonecanestimateandsamplethesetransitionkernels,withoutsuffering
fromthecurseofdimensionality.
A hierarchic probability flow across scales is an inverse to Wilson renormalization group. If we represent high
frequenciesinwaveletbasesthenthetransitionkernelscanbewrittenasconditionalprobabilitiesofwaveletcoefficients.
Renormalizingwaveletcoefficientsisastrategytocontrollog-Sobolevconstantsoftransitionprobabilities. Forthe
Ï†4 model of ferromagnetism at phase transition, it was shown in [MOBM22] that a renormalization in a wavelet
basiseliminatestheâ€criticalslowingdownâ€ofLangevinsamplingalgorithms[ZJ21]. Thisisverifiedandanalyzed
fordifferenttypesofwaveletbasesinSection4. TheÏ†4 scalarpotentialmodelhaslocalspatialinteractions. Itis
â€renormalizable,â€whichmeansthatitcanbeapproximatedwithanumberofcouplingparameters,whichdoesnot
dependonthefielddimensiond,atallscales. Thispropertydoesnotapplytocomplexsystemssuchasfluidturbulence,
whichhaveprogressivelymoredegreesoffreedomasthedimensiondincreases[BJPV98]. Tofacethisissue, we
introducehierarchicpotentialmodels,whosedimensionsincreasewhenthescale2j decreases. Thehierarchypreserves
acouplingflowequation,whichrelatesthecouplingparametersofenergiesfromonescaletothenext.
2HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
In physics and statistics, Gibbs energies of non-Gaussian probability distributions are often approximated with
polynomialsofdegreeslargerthan2,typically3or4[LL13]. Forastationaryfieldofdimensiond,itinvolvesd2or
d3approximationterms,whoseestimationshavealargevariance. Section5introducesinteractionenergymodelsof
dimensionO(log3d),withrobustmultiscaleapproximationsofhighorderpolynomialenergies. Theyarecomputed
withasecondwavelettransform,appliedtothemodulusofthefirstwavelettransform.Itdefinesasecondhierarchy,with
asecondscaleparameter. Theresultingscatteringcoefficients[Mal12]capturelong-rangenon-Gaussianinteractions
acrossspaceandscales[CMA+23]. Theseinteractionenergymodelsprovidearenormalizationgrouprepresentation
of non-renormalizable systems, with O(log3d) degrees of freedom, which increases slowly with the dimension d.
NumericalapplicationsareshowntoestimateandsampleGibbsenergymodelsoftwo-dimensionalturbulentvorticity
fieldsanddarkmatterdensityfields.
2 ProbabilityModels,EstimationandSampling
WedenotebyÏ†âˆˆRdadatavectorofdimensiond. Wesupposethatithasaprobabilitydensityp(Ï†)=Zâˆ’1eâˆ’U(Ï†)
withrespecttotheLebesguemeasure,withaGibbsenergyU whichistwicedifferentiable. Ourgoalistoestimate
anaccuratemodelofpfrommsamples{Ï†(i)} ,andtogeneratenewdatabysamplingthismodel. Thissectionis
iâ‰¤m
abriefintroductiontosamplingofhigh-dimensionalprobabilitieswithLangevindiffusions,andtotheestimationof
parametricmodelsbymaximumlikelihoodandscorematching.
2.1 LangevinSamplingandLogSobolevInequalities
IfU(Ï†)isknown,onecansamplepwithaLangevindynamics,whichisaMarkovprocessthatiterativelyupdatesa
fieldÏ† withthestochasticdifferentialequation
t
âˆš
dÏ† =âˆ’âˆ‡ U(Ï† )dt+ 2dB ,
t Ï† t t
whereB isaBrownianmotion. Itisagradientdescentontheenergy,whichisperturbedbytheadditionofaGaussian
t
white noise. Let Ï† be a sample of a density p at time t = 0. At time t, Ï† is a sample of a density p which is
0 0 t t
guaranteedtoconvergetothedensitypofGibbsenergyU(Ï†)[LS16]. TheuniqueinvariantmeasureofthisMarkov
chainisp. WecanthussamplepbyrunningLangevinequationoversamplesofaninitialmeasurep ,forexample
0
Gaussian,buttheconvergencemaybeextremelyslow.
Theconvergenceofp towardspisdefinedwithaKLdivergence
t
(cid:90) p (Ï†)
KL(p ,p)= p (Ï†) log t dÏ†â‰¥0.
t t p(Ï†)
DeBruinidentity[BBD23]provesthat
dKL(p ,p)
t =âˆ’I(p ,p), (1)
dt t
whereI istherelativeFisherinformation
(cid:90) q(Ï†)
I(q,p)= q(Ï†)âˆ¥âˆ‡ log âˆ¥2dÏ†.
Ï† p(Ï†)
Theexponentialconvergenceofp towardspisguaranteedifpsatisfiesalog-Sobolevinequality,whichisrecalled.
t
Definition2.1. Thelog-Sobolevconstantc(p)ofpisthesmallestconstantsothatforanyprobabilitydensityq
KL(q,p)â‰¤c(p)I(q,p). (2)
Log-Sobolev constants relate entropy and gradients of smooth normalized functions f(Ï†) in the functional space
L2(pdÏ†). Indeed, f2 = q/p satisfies âˆ¥fâˆ¥ = 1 in L2(pdÏ†) because (cid:82) q(Ï†)dÏ† = 1, and one can verify that the
2
log-Sobolevinequality(2)isequivalentto
(cid:90) (cid:90)
f2(Ï†) logf2(Ï†)p(Ï†)dÏ†â‰¤4c(p) âˆ¥âˆ‡f(Ï†)âˆ¥2p(Ï†)dÏ†. (3)
IfpisanormalGaussianthenc(p) = 1/2.Thelog-Sobolevconstantgivesanexponentialrateofconvergenceofa
Langevindiffusion. Indeed,insertingthelog-Sobolevdefinition(2)in(1)provesthat
KL(p ,p)â‰¤eâˆ’t/c(p)KL(p ,p). (4)
t 0
3HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
ThetimeittakesforLangevindiffusionstoreachafixedprecisionisthusatmostproportionaltothelog-Sobolev
constantc(p). Thetroubleisthatc(p)typicallygrowsexponentiallywiththedimensiondofÏ†.
Upperboundsofthelog-Sobolevconstantcanbecomputedintwocases[BBD23]. Underindependenceconditions,if
(cid:81)
Ï†=(Ï† ) andpcanbeseparatedasatensorproductofdensitiesp(Ï†)= p (Ï† )then
k k k k k
(cid:0) (cid:1)
c(p)=max c(p ) . (5)
k k k
Inotherwords,thelog-Sobolevconstantofindependentrandomvariablesisthemaximumlog-Sobolevconstantof
eachvariable. Thesecondcase,whenU isstronglyconvex,istheBakry-Emerytheorem[BGL+14],whichprovesthat
1
âˆ€Ï† , âˆ‡2U(Ï†)â‰¥Î±Id â‡’ c(p)â‰¤ . (6)
Ï† 2Î±
ThemaximumconstantÎ±satisfyingthisequalityistheinfimumoverÏ†ofalleigenvaluesoftheHessianmatrices
âˆ‡2U(Ï†). Thefollowingpropositiongivesalowerboundofthelog-Sobolevconstantfromthecovarianceofp.
Ï†
Proposition2.1. LetÂµ bethelargesteigenvalueofthecovarianceofp. Thelog-Sobolevconstantsatisfies
max
c(p)â‰¥Âµ /2. (7)
max
ThispropositionisprovedinAppendixE.1. Itcomesfromtheinequalitybetweenlog-SobolevandPoincareÂ´ constants
[Led00].
TheLangevindiffusionisnumericallycalculatedwithanEuler-Maruyamadiscretization. Ifâˆ‡ U(Ï†)isuniformly
Ï†
Lâˆ’Lipschitz,thenthediscretizationtimestepcanbesmallerorequaltoLâˆ’1[VW22]. SinceListhesupremumofall
eigenvaluesoftheHessiansâˆ‡2U(Ï†),itresultsfrom(4)thatthenumberofLangevindiffusionstepstoachieveagiven
Ï†
precisionisproportionaltothelog-Sobolevconstantmultipliedbythiseigenvaluesupremum. Itisanormalizationof
thelog-Sobolevconstant,whichspecifiesthecomputationalcomplexityoftheLangevinsamplingalgorithm.
Numerically,theconvergencerateofaLangevindiffusionisestimatedfromtherelaxationtimeÏ„ oftheauto-correlation
A(t)=E
p
(cid:0)(cid:0) Ï†
t+t
âˆ’E[Ï†
t+t
](cid:1)T(cid:0) Ï†
t
âˆ’E[Ï†
t
](cid:1)(cid:1) âˆeâˆ’ Ï„t , (8)
t0 0 0 0 0
fort bigenough[Sok91,Sok97]. Therelaxationtimegivesanestimationofthelog-Sobolevconstant.
0
To eliminate the bias introduced by the discretization step of Langevin diffusion, synthesis are generated using a
Metropolis-AdjustedLangevinAlgorithm(MALA)[GM94]. ItiteratesoverdiscretizedLangevindynamicsproposals
thatareacceptedorrejectedusingtheMetropolis-Hastingsalgorithm.
2.2 ApproximationandLearningGibbsEnergies
TheGibbsenergyU ofaprobabilitydensitypisusuallynotknownapriori. Itisapproximatedbyaparametrizedmodel
p =Zâˆ’1eâˆ’U Î¸ whereÎ¸isoptimizedbyminimizingKL(p,p ). LearningÎ¸fromadatasetofmsamples{Ï†(i)} is
Î¸ Î¸ Î¸ iâ‰¤m
usuallydonewithamaximumlikelihoodestimation. Weshallseethatitcanbereplacedbyscorematchingestimations,
whichrequiremuchfewercalculations,butwhoseprecisiondependsuponthelog-Sobolevconstantc(p).
Exponential models We concentrate on linear approximations U of the Gibbs energy U, over a family of mâ€²
Î¸
functionsÎ¦={Ï• } weightedbyÎ¸ ={Î¸ }
k kâ‰¤mâ€² k kâ‰¤mâ€²
U (Ï†)=Î¸TÎ¦(Ï†)= (cid:88) Î¸ Ï• (Ï†). (9)
Î¸ k k
kâ‰¤mâ€²
Itdefinesanexponentialfamilyofprobabilitydensities
p
(Ï†)=Zâˆ’1eâˆ’Î¸TÎ¦(Ï†).
Î¸ Î¸
AmajorissueistofindafamilyÎ¦providinganaccurateapproximationU ofU inhighdimensiond, despitethe
Î¸
curseofdimensionality. Instatistics,eachÏ• iscalledamomentgeneratingfunctionbecausethemaximumlikelihood
k
estimatorsofÎ¸isspecifiedbythevectorofmomentsE [Î¦]asweshallsee. TheÏ• canbepolynomialsofÏ†. However,
p k
ifweuseallhighorderpolynomialsofafixeddegree,thenthedimensionofÎ¦hasapolynomialgrowthind. The
resultingestimationhasahighvariance,whichrequiresalargenumbermoftrainingsamples[CCL+20]. Markov
random fields [GG84] provide a powerful framework where all interactions are supposed to be local over native
variables,whichdefineslow-dimensionalmodels. However,itdoesnotapplytodatahavinglong-rangeinteractions,
which is the case for many image textures [PS00]. In physics, U is called an Ansatz. The Ï• are considered as
Î¸ k
interactionpotentials. PhysicalmodelsoftenrelyonmultilinearfunctionsofderivativesofÏ†. TheresultingAnsatzare
usuallylocalandlow-dimensional,butareunabletocapturecomplexsystemssuchasturbulence.
4HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
MaximumLikelihoodEstimation ThenextstepistooptimizeÎ¸inordertobestapproximatepbyp . Amaximum
Î¸
likelihood estimator Î¸ maximizes âˆ’E (logp ), which is equivalent to minimize the KL-divergence KL(p,p ). If
p Î¸ Î¸
U (Ï†)=Î¸TÎ¦(Ï†)thenthisKLdivergenceisaconvexfunctionofÎ¸. Themaximumlikelihoodestimatorcanthusbe
Î¸
calculatedwithagradient-descentalgorithmofstepsizeÏµ,whichcomputes
(cid:16) (cid:17)
Î¸ âˆ’Î¸ =Ïµ E (Î¦)âˆ’E (Î¦) . (10)
k+1 k p p
Î¸k
ThemaximumlikelihoodparameterÎ¸satisfiesE (Î¦)=E (Î¦). Theresultingp iscalledamomentprojectionofp
p p Î¸
Î¸
[Bis06]. IfthepotentialsofÎ¦arelinearlyindependent,thenitisuniquelydefinedifitexists. Onecanverifythatthis
(cid:82)
momentprojectionisthedistributionp whichmaximizestheentropyH(p )=âˆ’ p (Ï†) logp (Ï†)dÏ†subjecttothe
Î¸ Î¸ Î¸ Î¸
momentconditionE (Î¦)=E (Î¦)[Jay57].
p p
Î¸
The expected value E (Î¦) is estimated from the m samples Ï†(i) with a Monte Carlo sum mâˆ’1(cid:80) Î¦(Ï†(i)). The
p i
estimationofE (Î¦)withaMonteCarlosumrequirescomputingenoughsamplesofp . Itcanbedonewitha
p Î¸
Î¸k k
Langevindiffusion,butitrequiresaconsiderableamountofcomputationssinceitmustberunforasufficientlylong
timesothattheLangevinalgorithmconverges,anditmustberepeatedenoughsothatMonteCarlosumconverges.
ThisisunfeasibleiftheLangevinconvergencerateistoolow.
Score Matching Estimation Optimizing p = Zâˆ’1eâˆ’U Î¸ by minimizing the KL divergence is computationally
expensivebecausethegradientdescentonÎ¸ iÎ¸ ncludeÎ¸ sthetermâˆ‡ logZ = âˆ’E (cid:0) Î¦(Ï†)(cid:1) . Scorematching[HD05]
Î¸ Î¸ p
Î¸
is an appealing alternative. It eliminates the normalization constant Z by replacing the KL minimization by a
Î¸
minimizationoftherelativeFisherinformation,whichdependsonâˆ‡ logp
Ï†
I(p,p )=E (cid:0)1 âˆ¥âˆ‡ logp (Ï†)âˆ’âˆ‡ logp(Ï†)âˆ¥2(cid:1) .
Î¸ p 2 Ï† Î¸ Ï†
Withanintegrationbyparts,[HD05]provesthatitisequivalenttominimizeaquadraticlossinÎ¸:
â„“(Î¸)=E (cid:0)1 âˆ¥âˆ‡ U âˆ¥2âˆ’âˆ† U (cid:1)
p 2 Ï† Î¸ Ï† Î¸
=E (cid:0)1 âˆ¥Î¸Tâˆ‡ Î¦(Ï†)âˆ¥2âˆ’Î¸Tâˆ† Î¦(Ï†)(cid:1) , (11)
p 2 Ï† Ï†
whosesolutionisobtainedwithoutsamplingp
Î¸
Î¸ =Mâˆ’1E (cid:0) âˆ† Î¦(Ï†)(cid:1) with M =E (cid:0) âˆ‡ Î¦(Ï†)âˆ‡ Î¦(Ï†)T(cid:1) . (12)
p Ï† p Ï† Ï†
MinimizingthescorematchinglossisthusmuchfasterthanaminimizationoftheKLdivergence. Expectedvaluesare
estimatedbyenempiricalsumoverthemsamplesÏ†(i)ofp. EstimationerrorsintroducedbytheinversionofM must
oftenberegularized,whichisdonebyaddingÏµIdtoM,whereÏµdecreaseslikemâˆ’1foranestimationwithmsamples.
Scorematchingisaconsistentestimator,whichmeansthatifthereexistsauniqueÎ¸âˆ—suchthatp=p Î¸âˆ— >0thenwhen
mgoestoinfinity,theminimizerÎ¸ofthescorematchinglossconvergestoÎ¸âˆ—[HD05]. However,therelativeprecision
ofascorematchingrelativelytoamaximumlikelihoodestimationdependsoniftheKLdivergencecanbecontrolled
bytherelativeFisherinformation. Thisiscapturedbythelog-Sobolevconstantc(p)definedin(2). Forexponential
modelsp ,Theorem2in[KHR22]boundsthecovarianceofthescorematchingestimationwiththecovarianceofthe
Î¸
maximumlikelihoodestimatormultipliedbyc(p)2. Theboundinvolvesamultiplicativeconstantwhichalsodepends
upontheregularityofU . ItsamplitudecanbeapproximatedbythelargesteigenvaluesquaredoftheHessianofU .
Î¸ Î¸
SimilarlytotheLangevindiffusiontime,thelog-Sobolevconstantneedstobenormalizedbythislargesteigenvalue
amplitude. Ascorematchingthusachievesacomparableaccuracyasamaximumlikelihoodestimatorifthenumberm
ofsamplesismultipliedbythisnormalizedlog-Sobolevconstant,whichmaybeverylarge.
MultiscaleGaussianandnon-Gaussiandensities Ifp = Zâˆ’1eâˆ’U isazero-meangaussiandistribution,thenits
Gibbsenergyisquadratic
1
U(Ï†)= Ï†TKÏ† â‡’ âˆ‡2U(Ï†)=K â‰¥0. (13)
2 Ï†
The matrix K is symmetric positive and its inverse Kâˆ’1 = C is the covariance matrix of p. The variance of Ï† is
normalizedbyimposingthatTrace(C)=d.LetÂµ bethelargesteigenvalueofC. TheBakry-Emeryupperbound
max
ofthelog-Sobolevconstantin(6)togetherwiththelowerbounds(7)provesthat
1
c(p)= Âµ . (14)
2 max
5HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
WeexplainedthatthenumberofstepsofaLangevindiffusionaswellastheinefficiencyofscorematchingrelatively
to maximum likelihood estimation is proportional to the normalized Sobolev constant, which is multiplied by the
supremumoftheeigenvaluesofâˆ‡2U =K. ItisthusdividedbythesmallesteigenvalueÂµ ofC =Kâˆ’1andhence
Ï† min
proportionaltotheconditionnumberÂµ /Âµ ofthecovarianceC.
max min
Ifpisstationaryorhasstationaryincrements,thenC isdiagonalizedintheFourierbasis. Multiscalefieldshavea
covarianceeigenvalueateachfrequencyÏ‰whichistypicallyoftheorderof|Ï‰|âˆ’Î· forsomeÎ· > 0andÏ‰ Ì¸= 0. For
example,ifK =âˆ’âˆ†thenÏ†isaBrownianmotionandÎ· =2.Thegrowthofeigenvaluesatlowfrequenciesmeansthat
Ï†haslongrangecorrelations. Intwodimensions,Ï€ â‰¥|Ï‰|â‰¥Ï€dâˆ’1/2soc(p)=Âµ /2âˆdÎ·/2growswithd,whichis
max
notmodifiedbythenormalization. Ifpisnon-Gaussianthen,usingproposition2.1,westillhavec(p)â‰¥Âµ /2which
max
meansthatitgrowsatleastlikedÎ·/2.Toeliminatethegrowthduetothisbad-conditioningofthecovariance,wemust
separatedifferentfrequencybandswhereeigenvalueshavedifferentamplitudes. Thisisakeyideawhichmotivates
hierarchicalprobabilityfactorizationandtherenormalizationgroupintroducedinthenextsection.
3 Approximation,LearningandSamplingwithHierarchicFlows
SamplingaprobabilitydensitypwithaLangevindiffusionorestimatingitsGibbsenergybyscorematchingbecomes
unfeasiblewhenthelog-Sobolevconstantgrowswiththedimensiond. Thisistypicallythecaseforlargemultiscale
fieldsÏ†. Thissectionshowsthatthisdifficultymaybeavoidedifwedecomposepintoahierarchicflowofprobabilities
acrossscales,andifwerenormalizetheirtransitionprobabilitiestoboundtheirlog-Sobolevconstants.
Section3.1reviewsmultiresolutionapproximationsandwavelettransforms. Section3.2explainsthatahierarchicflow
ofprobabilitiescomputesaninverserenormalizationgroupstudiedin[MOBM22]. Sections3.3and3.4reviewsthe
estimationandsamplingoftheresultingprobabilitymodels,withscorematchingandMetropolisadjustedLangevin
diffusions. Forstationaryprobabilities,modelparameterssatisfyacouplingflowequationgiveninSection3.5. Section
3.6relateswaveletpropertiestothelog-Sobolevconstantsoftransitionprobabilities.
3.1 MultiresolutionApproximationsandWavelets
Multiresolutionsdefinecoarse-grainingapproximationswhoseevolutionsacrossscalesdependupondecomposition
coefficientsinawaveletbasis[Mal89b,Mey93]. Theycanbeextendedtoarbitrarydatadefinedonagraph. Webegin
fromtheconstructionofmultiresolutionapproximationongraphstoshowthathierarchicflowscanbeappliedtogeneral
datastructures. Wethenconcentrateonimageswhereweperformnumericalexperiments.
Multiresolutionandwaveletsongraphs WeconsiderÏ†âˆˆRddefinedbyitsdvaluesÏ†(n)onthenodesofagraph.
MultiresolutionapproximationscomputecoarsegrainingapproximationsofÏ†ofprogressivelysmallerdimensions,by
iteratingovercoarsegrainingoperators[HK22]. LetuswriteÏ† =Ï†. Foreachj >0,Ï† iscalculatedfromÏ† with
0 j jâˆ’1
acoarse-grainingaveragingoperatorG
j
Ï† =G Ï† . (15)
j j jâˆ’1
The rows of G sum to 1. It is a sparse in matrix which averages groups of neighbor coefficients of Ï† . The
j jâˆ’1
dimensionofÏ† isproportionalto2âˆ’rj whereristhedimensionofthegraph. IfÏ†isanimageandhencedefinedona
j
two-dimensionalgraph,thenr =2. Atalevelj,eachvalueofÏ† iscomputedbyaveragingvaluesofÏ† overgroups
j 0
ofneighbornodesinthegraph,whosesizesareproportionalto2rj. Itprovidesanapproximationatthescale2j. The
graphtopologyisthepriorinformationallowingtobuildthesemultiscalegroups. Inthesimplestcases,theaveraged
groupsarenon-overlappingandthecoarsegrainingdefinesacomputationaltree[GNC10]. TheoperatorG canalso
j
bedefinedasadiagonaloperatorintheorthogonalbasiswhichdiagonalizesthegraphLaplacian[HVG11]. Itcanthen
beinterpretedasaconvolutiononthegraph,whichprojectsÏ†onthelower-frequencyeigenvectors.
Thecoarsegrainingisinvertedbyalsocomputingthehigh-frequencyvariationsofÏ† whichhavebeeneliminatedby
jâˆ’1
theaveragingoperatorG . Forthispurpose,wedefineacomplementoperatorGÂ¯ whoserowsaresparsewithnearly
j j
(cid:16) (cid:17)
thesamesupportasG ,andsuchthat G j isaninvertiblesquarematrix. Waveletcoefficientsarethehighfrequencies
j GÂ¯
j
Ï†Â¯ ofÏ† computedbythiscomplement
j jâˆ’1
Ï†Â¯ =GÂ¯ Ï† . (16)
j j jâˆ’1
TheymeasurethevariationsofÏ† overlocalneighborhoodswhereG averagesÏ† .Let(H ,HÂ¯ )betheinverse
jâˆ’1 j jâˆ’1 j j
(cid:16) (cid:17)
G
matrixof j :
GÂ¯
j
H G +HÂ¯ GÂ¯ =Id, (17)
j j j j
Itresultsfrom(15)and(16)thatÏ† canberecoveredfrom(Ï† ,Ï†Â¯ )
jâˆ’1 j j
Ï† =H Ï† +HÂ¯ Ï†Â¯ . (18)
jâˆ’1 j j j j
6HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
(cid:16) (cid:17)
If G j isanorthogonalmatrixthenH =GTandHÂ¯ =GÂ¯Tandthisdecompositionisorthogonal.
GÂ¯ j j j j
j
Cascading(G ,GÂ¯ )fromÏ†computesamultiscaleaveragingÏ† =A Ï†andwaveletcoefficientsÏ†Â¯ =W Ï†with
j j j j j j
A =G G ...G and W =GÂ¯ G ...G . (19)
j j jâˆ’1 1 j j jâˆ’1 1
ThematrixW =(A ,W , ...W )isinvertibleandcomputesawavelettransformatallscales. Itisorthogonalifeach
J J 1
(cid:16) (cid:17)
G
j isorthogonal.
GÂ¯
j
MultiresolutionofImages ImagesaresampledonauniformgridwhichisaEuclideangraphofdimensionr =2.
Fastwavelettransforms[Mal89a]arecalculatedwithconvolutionalandsubsamplingoperatorsonthisgraph,whichdo
notdependonj. TheoperatorsG =GandGÂ¯ =GÂ¯ aredefinedby
j j
GÏ†(n)=Ï†âˆ—g(2n) and GÂ¯Ï†(n)=Ï†âˆ—gÂ¯(2n). (20)
The filter g is a low-pass filter which averages neighbor pixels in the image. The complement gÂ¯ = (gÂ¯ ) is
k 1â‰¤kâ‰¤3
composedof3separablehigh-passfilterswhichcomputetheimagevariationsoverthesameneighborhood. Theinverse
operators H and HÂ¯ inserts zeros between each coefficient of Ï† and Ï†Â¯ before computing convolutions with dual
j j
bi-orthogonalfiltershandhÂ¯ [Dau92]. ThisfastwavelettransformisillustratedinFigure2. AppendixAreviewsthe
(cid:16) (cid:17)
propertiesofconjugatemirrorfilters(g,gÂ¯)whichdefineanorthogonalmatrix G . Itimpliesthath(n) = g(âˆ’n)
GÂ¯
andhÂ¯(n)=gÂ¯(âˆ’n).Allnumericalapplicationsarecomputedwithconjugatemirrorfilters,butthisisnotarequired
conditiontodefineahierarchicprobabilityflow.
Coarse Grained Fields
H
H
Wavelet Fields
Length Scale
Figure2: AfastwavelettransformiterativelydecomposesanimageapproximationÏ† intoacoarserapproximation
jâˆ’1
Ï† with a sub-sampled low-pass filtering G, and 3 wavelet coefficient images Ï†Â¯ . They are calculated by GÂ¯ with
j j
subsampledconvolutionswith3band-passfiltersalongdifferentorientations. AfinerscaleimageÏ† isreconstructed
jâˆ’1
from(Ï† ,Ï†Â¯ )withtheinverseoperator(H,HÂ¯).
j j
TheoperatorsA andW in(19)areacascadeofj convolutionsandsub-samplingsby2. Theyarethusconvolutional
j j
operators,followedbyasubsamplingby2j. Coarse-grainedimagesandwaveletcoefficientscanthereforebewrittenas
convolutionswithascalingfilterÏ• andwaveletsÏˆ subsampledby2j:
j j,k
Ï†
=(cid:0)
Ï†âˆ—Ï•
(2jn)(cid:1)
and Ï†Â¯
=(cid:0)
Ï†âˆ—Ïˆ
(2jn)(cid:1)
. (21)
j j n j j,k kâ‰¤3,n
Thesescalingfiltersandwaveletsarespecifiedbythefilters(g,gÂ¯)asexplainedinAppendixA.Thesupportwidthof
Ï• andÏˆ isproportionalto2j. TheFouriertransformÏˆË† ofeachwaveletÏˆ isdilatedby2âˆ’j.TheseFourier
j j,k j,k j,k
transformsareessentiallylocalizedinfrequencyannuliillustratedinFigure3(a),aroundthelowerfrequenciescovered
byÏ•Ë† .
j
TherowsofthewavelettransformW =(A ,W , ...W )aretranslatedwaveletsatallscales,whichdefineabasis
J J 1
ofRd. ItisanorthogonalbasisifGandGÂ¯ areconjugatemirrorfilters. Tostudyasymptoticpropertiesofwavelet
coefficientswhendgoestoâˆ,weneedtocontroltheconvergenceofthesebases. IfwerenormalizethesupportofÏ†to
[0,1]2thendiscreteorthonormalwaveletbasesconvergetowaveletorthonormalbasesofL2([0,1]2). Whentheimage
sizedgoestoâˆthennormalizeddiscretewaveletsÏˆ convergetowaveletfunctionsÏˆ (x)=2âˆ’jÏˆ (2âˆ’jx),such
j,k j,k k
that{x(cid:55)â†’Ïˆ (xâˆ’2jn)} isanorthonormalbasisofL2([0,1]2)[Mal09].
j,k jâ‰¤0,nâ‰¤2âˆ’j,kâ‰¤3
7HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
ğœ“^ ğœ“^
1,1 1,2
ğœ“^ ğœ“^
2,1 2,2
ğœ“^
ğœ“^ ğœ“^ 1,3
3,1 3,2 ğœ“^
ğœ™^ ğœ“^ 2,3
3 3,3
(a) (b)
Figure3: (a): FrequencysupportsofFouriertransformsoftwo-dimensionalwaveletsÏˆË† (Ï‰ ,Ï‰ )for1â‰¤k â‰¤3over
j,k 1 2
3scales2j. (b): Frequencysubdivisionsofwaveletpacketsovera levelsateachscale2j,witha =2,a =1and
j 1 2
a =0.
3
Wavelet packets The frequency resolution of wavelets can be improved with wavelet packet bases introduced
in [CMW92]. A wavelet packets transform sub-decomposes the frequency support of each wavelet. This is done
(cid:16) (cid:17)
by iteratively applying a times the convolutions and subsampling G , after applying GÂ¯ to Ï† . It computes
j GÂ¯ jâˆ’1
Ï†Â¯ =GÂ¯ Ï† with
j j jâˆ’1
(cid:18) G(cid:19)a
j
GÂ¯ = GÂ¯. (22)
j GÂ¯
(cid:16) (cid:17) (cid:16) (cid:17)
Thematrix G isorthogonalif G isorthogonal. Itthencomputesdecompositioncoefficientsinanorthogonal
GÂ¯ GÂ¯
j
basisofwaveletpacketvectors. Thefilter(22)performsafrequencysubdivisionofeachwaveletfrequencybandinto
22a j bands,illustratedinFigure3(b). ThesewaveletpacketsthushaveaFouriertransformwhichareconcentratedon
squaredomains,whichare2a j timesmorenarrowthanforwavelets. However,thespatialsupportofthesewavelet
packetsis2a j timeslargerthanforwavelets. Propertiesofwaveletpacketsarestudiedin[CMW92].
3.2 HierarchicFlowsandRenormalizationGroup
WenowconsiderarandomvectorÏ†definedonagraphwhoseprobabilitydensityisp(Ï†). IfphasalargeSobolev
constant, we avoid estimating and sampling p directly. A hierarchic representation of p is defined as a product of
conditionalprobabilitiesofwaveletcoefficients[MOBM22],whoselog-Sobolevconstantsarerenormalizedthrough
the renormalization of the wavelet coefficients. This hierarchic representation is calculated as an inverse of the
renormalizationgrouptransformation,whichiterativelycomputestheprobabilitydensityp (Ï† )fromp (Ï† ).
j j jâˆ’1 jâˆ’1
Forwardrenormalisation TherenormalizationgroupofKadanoff[KHY76]andWilson[Wil71]computesallp (Ï† )
j j
givenp(Ï†)atthefinestscale. Ititerativelycomputesp fromp withamarginalintegrationoverthehighfrequency
j jâˆ’1
degreesoffreedom, whichwerepresentwiththewaveletvariablesÏ†Â¯ . WaveletcoefficientsÏ†Â¯ arenormalizedby
j j
dividingeachcoordinateÏ†Â¯ (n)byitsstandarddeviationÏƒ . LetD = diag(Ïƒâˆ’1) bethecorrespondingdiagonal
j j,i j j,i i
matrix. NormalizingÏ†Â¯ isequivalenttoreplaceGÂ¯ byD GÂ¯ andHÂ¯ byHÂ¯ Dâˆ’1.
j j j j j j j
SinceÏ† =H Ï† +HÂ¯ Ï†Â¯ wehavedÏ† =w dÏ† dÏ†Â¯ wherew =|det(H ,HÂ¯ )|istheJacobianmodulus,and
jâˆ’1 j j j j jâˆ’1 j j j j j j
(cid:90)
p (Ï† )=w p (Ï† )dÏ†Â¯ . (23)
j j j jâˆ’1 jâˆ’1 j
The use of an appropriate coordinate system to compute the marginal integration of high frequencies Ï†Â¯ has been
j
thoroughlystudied[Del12]. Kadanoffrenormalizationgroup[KHY76]computesÏ† fromÏ† withablockaveraging,
j jâˆ’1
whichamountstodefineÏ†Â¯ asorthogonalwaveletcoefficientsintheHaarbasis,whichhasaminimalspatialsupportbut
j
isdiscontinuous.Inhisfirstversion,Wilsonrenormalization[Wil71]iscomputedwithShannonwavelets,whoseFourier
transformshaveaminimumsupportbutarediscontinuous. Shannonwaveletsthushaveaslowspatialdecay. These
waveletpropertiesarereviewedinAppendixA.OtherwaveletbasesadaptedtospecificclassesofHamiltonianshave
beendesignedbyBattle[Bat99],whoanalyzedrelationsbetweentherenormalizationgroupandwavelettransforms.
8HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Hierarchicflowasaninverserenormalization IfÏ† isofsufficientlylowdimensionthenthereisnodifficultyto
J
estimatep (Ï† )fromdata,orsamplethisprobabilitydensity. Ahierarchicflowisaninverserenormalizationgroup
J J
transformationwhichmapsp intopwithaMarkovchain. Itcomputesp (Ï† )bymultiplyingp (Ï† )witha
J jâˆ’1 jâˆ’1 j j
conditionalprobabilityofÏ† givenÏ† ,whichisalsoequaltotheconditionaldensityofÏ†Â¯ givenÏ†
jâˆ’1 j j j
p (Ï† )=wâˆ’1p (Ï† )pÂ¯ (Ï†Â¯ |Ï† ). (24)
jâˆ’1 jâˆ’1 j j j j j j
Cascading(24)transformsp intopwithtransitionkernelsdefinedbytheseconditionalprobabilities
J
J J
p(Ï†)=wâˆ’1p (Ï† )(cid:89) pÂ¯ (Ï†Â¯ |Ï† ) with w = (cid:89) w . (25)
J J j j j j
j=1 j=1
Thisinversewaveletrenormalizationgroup[MOBM22]computespstartingfromp .
J
3.3 EstimationofaConditionalProbabilityModel
Givenmsamples{Ï†(i)} ofp,amodelofpisestimatedwiththehierarchicalfactorization(25),fromexponential
iâ‰¤m
modelsofeachconditionalprobability. Eachconditionalprobabilitymodelisestimatedfromdatabyscorematching,
whoseprecisiondependsuponitslog-Sobolevconstant.
Hierarchicmodel Anexponentialmodelp Î¸ ofpisdefinedfromexponentialmodelsp Î¸
J
andpÂ¯ Î¸Â¯
j
ofp J andpÂ¯ j:
J
p Î¸(Ï†)=wâˆ’1p Î¸ J(Ï† J)(cid:89) pÂ¯ Î¸Â¯ j(Ï†Â¯ j|Ï† j). (26)
j=1
Anexponentialmodelofp isdefinedasin(9)by
J
p (Ï† )=Zâˆ’1eâˆ’Î¸ JTÎ¦ J(Ï† J). (27)
Î¸ J J J
WechooseJ largeenoughsothatÏ† issufficientlylow-dimensionaltoeasilycomputethisestimation. Foranyj â‰¥J,
J
anexponentialmodelofpÂ¯ isdefinedby
j
pÂ¯ Î¸Â¯ (Ï†Â¯ j|Ï† j)=eF j(Ï† j)âˆ’Î¸Â¯ jTÎ¨ j(Ï† jâˆ’1), (28)
j
whereF isafreeenergywhichnormalizestheconditionalprobability:
j
(cid:90) (cid:90)
pÂ¯ Î¸Â¯ (Ï†Â¯ j|Ï† j)dÏ†Â¯ j =eF j(Ï† j) eâˆ’Î¸Â¯ jTÎ¨ j(Ï† jâˆ’1)dÏ†Â¯ j =1. (29)
j
EachfreeenergyF j isspecifiedbyÎ¸Â¯ j,butitdoesneedtobecomputedtoestimateÎ¸Â¯ j orsamplepÂ¯ Î¸Â¯ .
j
Themodelp =Zâˆ’1eâˆ’U Î¸ hasaGibbsenergy
Î¸ Î¸
J
U =Î¸TÎ¦ +(cid:88)(cid:0) Î¸Â¯TÎ¨ âˆ’F (cid:1) . (30)
Î¸ J J j j j
j=1
Section3.5explainsthatitcanbecalculatedwithacouplingflowequation,whichrequiresregressingeachF .
j
ScoreMatching AmaximumlikelihoodestimationcomputesÎ¸ =(Î¸ ,Î¸Â¯ ) byminimizingKL(p,p ). Itresults
J j jâ‰¤J Î¸
fromthefactorization(25)ofpand(26)ofp that
Î¸
J
KL(p,p Î¸)=KL(p J,p Î¸ J)+(cid:88) E p j(cid:0) KL(pÂ¯ j,pÂ¯ Î¸Â¯ j)(cid:1) . (31)
j=1
TheminimizationofKL(p,p Î¸)isthusobtainedbyminimizingeachE p j(cid:0) KL(pÂ¯ j,pÂ¯ Î¸Â¯ j)(cid:1) .
AsexplainedinSection2.2,minimizingaKLdivergencewithagradientdescentiscomputationallyexpensivebecause
itrequirescomputingnormalizationconstants. Wethusoptimize{Î¸ ,Î¸Â¯ } byscorematching,whichreplacestheKL
J j j
divergencebyarelativeFisherinformation. TheparametersÎ¸ arecalculatedbyminimizingtheFisherinformation
J
I(p ,pÂ¯ ),whichamounttominimizeaquadraticloss(11). InteractionparametersÎ¸Â¯Tarecalculatedbyminimizing
J Î¸ j
J
theaveragedFisherinformation
E p j(cid:0) I(pÂ¯ Î¸Â¯ j,pÂ¯ j)(cid:1) =E p jâˆ’1(cid:16) âˆ¥âˆ‡ Ï†Â¯ jlogpÂ¯ j(Ï†Â¯ j|Ï† j)âˆ’âˆ‡ Ï†Â¯ jlogpÂ¯ Î¸Â¯ j(Ï†Â¯ j|Ï† j)âˆ¥2(cid:17) .
ThescoregradientiscomputedonÏ†Â¯ forÏ† fixed,andtheFisherinformationdoesnotdependonthefreeenergyF .
j j j
AppendixC.1showsthatÎ¸Â¯ isalsoasolutionofaquadraticminimization.
j
9HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Conditionallog-Sobolevconstants AnupperboundofE p j(KL(pÂ¯ j,pÂ¯ Î¸Â¯ j))computedfromE p j(I(pÂ¯ j,pÂ¯ Î¸Â¯ j))depends
onalog-Sobolevconstantc(pÂ¯ )averagedoverp . Theconditionallog-Sobolevconstantc(pÂ¯ )ofpÂ¯ (Ï†Â¯ |Ï† )isdefined
j j j j j j
asthesmallestconstantsothatforanyconditionalprobabilityqÂ¯(Ï†Â¯ |Ï† )
j j
E (cid:0) KL(qÂ¯,pÂ¯ )(cid:1) â‰¤c(pÂ¯ )E (cid:0) I(qÂ¯,pÂ¯ )(cid:1) . (32)
p j j p j
j j
OnecanapplyTheorem2in[KHR22]toprovethatthenumbermofsamplesneededforascorematchingtoachievea
comparableaccuracyasaKullback-Leiblerdivergenceminimizationisasymptoticallymultipliedbythisconditional
log-Sobolevconstant. Section2.2showsthatforexponentialmodels,minimizingaKLdivergenceisequivalentto
matchmoments,andhencethatminimizingE p j(cid:0) KL(pÂ¯ j,pÂ¯ Î¸Â¯ j)(cid:1) isequivalenttofindÎ¸Â¯ j suchthat
E E (Î¨ )=E (Î¨ ).
p j pÂ¯ Î¸Â¯ j j p jâˆ’1 j
Wecanthusevaluatethenumericalprecisionofscorematchingestimatorsfromthismomentmatchingcondition.
3.4 HierarchicSampling
A sample Ï† of a hierarchic model p of p is calculated from coarse to fine scales, by first sampling p and then
Î¸ Î¸
J
iterativelysamplingeachpÂ¯ Î¸Â¯ . TheseprobabilitydensitiesaresampledwithaMetropolisAdjustedLangevindiffusion
j
[GM94,RR98],andwerelatetherateofconvergenceoftheunadjusteddynamictolog-Sobolevconstants. Thisis
furtherdevelopedinappendixF.1.
AhierarchicsamplingcomputesasampleÏ†ofp asfollows.
Î¸
â€¢ Initialization: computeasampleÏ† ofp .
J Î¸
J
â€¢ Forj fromJ to1,givenÏ† j computeasampleÏ†Â¯ j ofpÂ¯ Î¸Â¯ (Â·|Ï† j)andsetÏ† jâˆ’1 =H jÏ† j +HÂ¯ jÏ†Â¯ j.
j
ThesampleÏ† = Ï† ofp isthuscalculatedbyiteratingonastochasticequation,whichrecoversÏ† fromÏ† by
0 Î¸ jâˆ’1 j
samplingrandomhighfrequencies. TheconditionalprobabilitiespÂ¯ Î¸Â¯ (Â·|Ï† j)aresampledwithaLangevin(orMALA)
j
algorithm,whichdoesnotdependuponthenormalizationfreeenergyF .
j
Convergenceofsampling Langevindiffusionshasanexponentialconvergenceiftheirlog-Sobolevconstantsare
uniformlybounded. Tosimplifyexplanations,weneglectthemodelapproximationerror,sop Î¸
J
=p J andp Î¸Â¯
j
=pÂ¯ j.
ForafixedÏ† ,aLangevindiffusionapproximatespÂ¯ (.|Ï† )bypÂ¯ aftertimet. Theproductp =wâˆ’1p (cid:81)J pÂ¯
j j j j,t t J,t j=1 j,t
definesanapproximationofp. TheKLdivergenceerrorbetweenpandp canbedecomposedasasum
t
J
KL(p ,p)=KL(p ,p )+(cid:88) E (cid:0) KL(pÂ¯ ,pÂ¯ )(cid:1) . (33)
t J,t J p j,t j
j,t
j=1
ThedecayofKL(p ,p )isdrivenbythelog-Sobolevconstantc(p ),accordingto(4). Thesameresultappliestothe
J,t J J
conditionalprobabilitiespÂ¯ ifweincorporatetheexpectationinp .
j j
Similarlyto(4),DeBruinidentity(1)impliesanexponentialconvergenceoftheexpectedKLdivergence:
E (cid:0) KL(pÂ¯ ,pÂ¯ )(cid:1) â‰¤eâˆ’t/c(pÂ¯ j)E (cid:0) KL(p ,pÂ¯ )(cid:1) . (34)
p j,t j p j,0 j
j j
Notice that the expected value is in p and not in p as in (33) but they converge to the same value because p
j j,t j,t
convergestop whentincreases.
j
3.5 CouplingFlowEquationofStationaryEnergyModels
In some applications, the Gibbs energy model U in eq. (30) needs to be explicitly calculated. For example, to
Î¸
computehigh-dimensionalintegralswithMonteCarloreweighing[GRVE22],ortoanalyzetheinteractionproperties
ofaphysicalsystem. ItthenrequiresregressingthefreeenergiesF overpredefinedpotentialvectors. Wedefine
j
hierarchicalpotentials,allowingtobuildenergymodelswhosedimensionsincreasewiththefieldsize. Thisisneeded
toapproximatecomplexfieldshavingprogressivelymoredegreesoffreedomwhentheirresolutionincreases. For
stationaryprobabilities,weprovethatU canthenbecalculatedwithadiscretecouplingflowequation.
Î¸
10HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Energycalculation EachconditionalprobabilitymodelpÂ¯ Î¸Â¯ (Ï†Â¯ j|Ï† j) = eF j(Ï† j)âˆ’Î¸Â¯ jTÎ¨ j(Ï† jâˆ’1) involvesafreeenergy
j
F (Ï† )thatisapproximatedbyalinearregressionÎ±TÎ¦ (Ï† ). Insertingthisapproximationintheenergymodel(30)
j j j j j
gives
J
U =Î¸TÎ¦ +(cid:88)(cid:0) Î¸Â¯TÎ¨ âˆ’Î±TÎ¦ (cid:1) . (35)
Î¸ J J j j j j
j=1
ThecoefficientsÎ± arecalculatedfromtheconditionalprobabilitynormalization(29),uptoanadditiveconstant
j
(cid:90)
eÎ±T jÎ¦ j(Ï† j) eâˆ’Î¸Â¯ jTÎ¨ j(Ï† jâˆ’1)dÏ†Â¯ â‰ˆcst. (36)
j
AppendixC.2showsthatcalculatingthegradientalongÏ† allowsustocomputeÎ± byminimizingaquadraticform.
j j
Stationarymodels Ifp(Ï†)isstationaryandhencehasaGibbsenergyU(Ï†)whichisinvarianttotranslationsonthe
samplinggridofÏ†thenp (Ï† )isinvariantbytranslationonthecoarsersamplinggridofÏ† . Hierarchicmodelsin
j j j
waveletbasesarenotstrictlystationarybecauseawaveletorthonormalwaveletbasisisnotinvariantbytranslations. To
defineastationarymodel,weiterativelyprojectthehierarchicmodelovertranslationinvariantfunctions.
LetT beatranslationofÏ† byÏ„ (moduloperiodicboundaryconditions). Aprojectionoff(Ï† )overtranslation
Ï„ jâˆ’1 jâˆ’1
invariantfunctionsofÏ† iscomputedbyaveragingitsvaluesoverallthetranslationsofÏ† onitsgridG ofsize
jâˆ’1 jâˆ’1 jâˆ’1
|G |
jâˆ’1
1 (cid:88)
(Ave f)(Ï† )= f(T Ï† ). (37)
jâˆ’1 jâˆ’1 |G | Ï„ jâˆ’1
jâˆ’1 Ï„âˆˆG
jâˆ’1
Iff(Ï† )isafunctionofÏ† =GÏ† thenwewriteAve f =Ave f withf (Ï† )=f(GÏ† ). Iff(Ï† )is
j j jâˆ’1 jâˆ’1 jâˆ’1 G G jâˆ’1 jâˆ’1 j
invarianttotranslationsofÏ† onitsgridG thenthesum(37)canbereducedtothe4translationsÏ„ âˆˆG /G . The
j j jâˆ’1 j
followingtheoremprovesthatthistranslationinvariantprojectionofGibbsenergiesreducestheKullback-Leiblererror
onstationarydensities.
Proposition3.1. Letp(Ï† )beastationarydensity. Ifq(Ï† )isadensityofenergyU andifqËœ(Ï† )isthedensity
jâˆ’1 jâˆ’1 jâˆ’1
ofenergyAve U then
jâˆ’1
KL(p,qËœ)â‰¤KL(p,q). (38)
TheproofisinAppendixE.2. Thispropositionprovesthatenergymodelsofstationaryprobabilitiesareimprovedby
theprojection(37)ontranslationinvariantfunctions.
Coupling flow equation with hierarchic potentials We introduce hierarchic stationary models where coupling
parameterscanbecalculatedawithaflowequationfromcoarsetofinescales,usingdatatoestimateeachterm. It
invertstherenormalizationgroupcouplingflowequation,whichgoesfromfinetocoarsescales[Del12].
Atthelargestscale2J,wehavecomputedamodelU oftheGibbsenergyofp .Ateachscale2j,wecancomputean
Î¸ J
J
approximationU oftheGibbsenergyofp fromanapproximationU oftheGibbsenergyofp ,byaddingthe
Î¸ jâˆ’1 Î¸ j
jâˆ’1 j
interactionenergymodelÎ¸Â¯TÎ¨ âˆ’Î±TÎ¦ ofpÂ¯ =p /p . Proposition3.1provesthattheprojectionAve reduces
j j j j j jâˆ’1 j jâˆ’1
theapproximationerror. AtranslationinvariantGibbsenergymodelhavingareducederroristhus
U =Ave (U +Î¸Â¯TÎ¨ âˆ’Î±TÎ¦ ). (39)
Î¸ jâˆ’1 Î¸ j j j j
jâˆ’1 j
ThefollowingdefinitionimposesahierarchicconditiononÎ¦ sothatÎ¸ canbecalculatedfrom(Î¸ ,Î¸Â¯ ,Î± )witha
jâˆ’1 jâˆ’1 j j j
linearequation.
Definition 3.1. We say that {Î¦ } are hierarchic stationary with interactions {Î¨ } if all Î¦ (Ï† ) are
j 0â‰¤jâ‰¤J j 1â‰¤jâ‰¤J j j
invarianttotranslationsofÏ† andifthereexistsalinearoperatorQ suchthat
j j
Ave (Î¦ ,Î¨ )=Q Î¦ . (40)
jâˆ’1 j j j jâˆ’1
Thisdefinitiongeneralizesrenormalizablemodelswhichareself-similarandhavethesamedimensionatallscales.
hierarchicstationarypotentialsareconstructedbyprogressivelyincorporatingnewinteractionpotentialsÎ¨ foreach
j
j. ThedimensionofÎ¦ isthereforeincreasingasthescale2j decreases. Thisgeneralizationwillallowustobuild
j
potentialvectorsthatcanapproximateenergiesofcomplexfieldsinSection5.
Forhierarchystationarymodels,thefollowingpropositionderivesthattheparametervectorÎ¸ ofU satisfiesa
jâˆ’1 Î¸
jâˆ’1
linearequation,whichrelatesitto(Î¸ ,Î¸Â¯,Î± ).
j j
11HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Proposition3.2. If{Î¦ } arehierarchicstationarysatisfying(40)thentheGibbsenergyU in(39)isgivenby
j jâ‰¤J Î¸
jâˆ’1
U =Î¸T Î¦ with
Î¸ jâˆ’1 jâˆ’1
jâˆ’1
Î¸ =QT(Î¸ âˆ’Î± ,Î¸Â¯ ). (41)
jâˆ’1 j j j jâˆ’1
Proof. Thispropertyisprovedbyinductiononj. Itisvalidforj =J whereU =Î¸TÎ¦ .Supposethatitisvalidfor
Î¸ J J
J
j â‰¥J. InsertingU =Î¸TÎ¦ in(39)implieswith(40)that
Î¸ j j
j
U =(Î¸ âˆ’Î± , Î¸Â¯ )T(Î¦ ,Î¨ )=Î¸T Î¦ ,
Î¸ j j j j j jâˆ’1 jâˆ’1
jâˆ’1
whereÎ¸ satisfies(41).
jâˆ’1
This proposition computes energy models with a discrete coupling flow equation in a wavelet basis, from coarse
to fine scales. It inverts the renormalization group equation, which goes from fine to coarse scale. In a Fourier
basis,thisrenormalizationgroupequationcanbewrittenasadifferentialequation,whichdefinesaPolchinskiflow
[Pol84,BBD23]. Theinverseequationinvolvestheparametersofconditionalprobabilities,whichspecifiesfinescale
probabilitiesfromcoarserscales. ThedimensionofthecouplingflowvectorÎ¸ alsoincreasesasthescaledecreases,
j
whichisnecessarytoobtainaccuratemodelsofcomplexfieldswhicharenotexactlyself-similar. Atthefinestscale
j =0,weobtainatranslationinvariantGibbsenergyU =Î¸TÎ¦ ofastationarymodelp ofp=p .
Î¸ 0 0 Î¸ 0
0 0
3.6 Log-SobolevConstantsandWaveletChoice
Wewanttodecomposephavingalargelog-SobolevconstantintoconditionalprobabilitiespÂ¯ havingsmallerlog-
j
Sobolevconstants,whichcanthereforebelearnedandsampledmoreeasily. Todoso,westudythechoiceofbasisand
(cid:16) (cid:17)
ofthehierarchicalprojectorsG andGÂ¯ .Inthefollowing,wesupposethat G j isanorthogonalmatrix.
j j GÂ¯
j
Selectionofeigenvectors TheBakry-Emerytheoremgivesanupperboundofc(pÂ¯ )fromtheinverseofthesmallest
j
eigenvalue of the Hessians âˆ‡2 UÂ¯ , if it is positive. This suggests choosing G and GÂ¯ so that it maximizes this
Ï†Â¯ j j j
j
minimumeigenvalue. Intheorthogonalcase,Ï† =GÂ¯TÏ†Â¯ +GTÏ† so
jâˆ’1 j j j j
âˆ‡2 UÂ¯ =GÂ¯ (âˆ‡2 U )GÂ¯T. (42)
Ï†Â¯ j j Ï† jâˆ’1 j
j jâˆ’1
TheHessianeigenvaluesofUÂ¯ arethusobtainedbyselectingtheHessianeigenvaluesofU withtheorthogonaloper-
j jâˆ’1
atorGÂ¯ . Tominimizethelog-Sobolevconstant,GÂ¯ musteliminatesmallornegativeeigenvaluesofâˆ‡2 U (Ï† ).
j j Ï† jâˆ’1 jâˆ’1
jâˆ’1
Ifthehighamplitudeeigenvectorsofâˆ‡2 U (Ï† )areconcentratedinafixedlinearspacewithhighprobability,
Ï† jâˆ’1 jâˆ’1
jâˆ’1
thentherangeofGÂ¯Tshouldbeincludedinthisspace.
j
Renormalizedlog-Sobolevlower-bound TherenormalizationofÏ†Â¯ byD aimsatpreconditioningthecovarianceof
j j
pÂ¯ toavoidcreatingalargelog-Sobolevconstant. IfÂµÂ¯ isthelargesteigenvalueofthecovarianceCÂ¯ ofÏ†Â¯ then(7)
j max,j j j
provesthat
1
c(pÂ¯ )â‰¥ ÂµÂ¯ . (43)
j 2 max,j
IfpisGaussianthenpÂ¯ (.|Ï† )isthenalsoGaussiansoc(pÂ¯ ) = ÂµÂ¯ /2. Thelog-Sobolevnormalizationamounts
j j j max,j
to multiply by the largest eigenvalue of âˆ‡2 UÂ¯ . In the Gaussian case it divides by the smallest eigenvalue of the
Ï†Â¯ j
j
covarianceandisthusequaltothecovarianceconditionnumber. ThecovarianceC ofÏ† iscomputediterativelyfrom
j j
C with(15),whichimpliesthatC =G C GT. ThecovarianceCÂ¯ ofÏ†Â¯ iscomputedfromGÂ¯ ,whichincludesthe
0 j j jâˆ’1 j j j j
renormalization. Itgives
CÂ¯ =GÂ¯ C GÂ¯T with diag(CÂ¯ )=Id. (44)
j j jâˆ’1 j j
ThecovarianceC isprojectedandrenormalizedbyGÂ¯ ,whichsetsthediagonalvaluesofCÂ¯ to1. Themaximum
jâˆ’1 j j
eigenvalueandtheconditionnumberofCÂ¯ donotgrowwiththedimensiondifGÂ¯ representsC overabasisof
j j jâˆ’1
nearlyeigenvectors,sothatalleigenvaluesremainoftheorderof1. Thisnecessaryconditiontocontrolthelog-Sobolev
constantisnotsufficient. Non-convexGibbsenergiesmayhavemuchlargerlog-Sobolevconstants. Thisissueisstudied
numericallyinSections4.2and5.2forscalarpotentialenergiesand2dturbulencedata.
12HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Choice of wavelet and wavelet packet basis For multiscale stationary processes, we explain that the largest
eigenvalues and the condition numbers of all CÂ¯ remain bounded if the wavelet has a Fourier transform which is
j
sufficientlywelllocalized. Wedonotgivemathematicaldetailsbutquotethemainresults. Itgivesnecessaryconditions
tocontrolthegrowthofc(pÂ¯ )anditsnormalization,withthedimensiond.
j
MultiscalestationaryfieldshaveadensitypwhosecovarianceisdiagonalizedinaFourierbasis, witheigenvalues
whichgrowlike|Ï‰|âˆ’Î· atlow-frequencies. Inanimageofwidthd1/2,ifthesmallesteigenvalueisoftheorderof1then
thelargesteigenvalueisoftheorderofdÎ·/2,whichimpliesthatthelog-Sobolevconstantc(p)increasesatleastlike
dÎ·/2. AhierarchicalfactorizationtriestoavoidthisgrowthbyrenormalizingÏ†Â¯ sothatthenormalizedlog-Sobolev
j
constantremainsboundedforalld. Anecessaryconditionisthattheconditionnumberofthenormalizedcovarianceof
Ï†Â¯ doesnotgrowwithd. Computingthisconditionnumberwhendgoestoinfinityamountstostudythedecomposition
j
ofthelimitcovarianceoperatorofÏ†inawaveletorthonormalbasisofL2([0,1]2),bynormalizingthemaximumto1.
TherenormalizationsetsthediagonalofCÂ¯ to1sothatitslowestandlargesteigenvaluesremainoftheorderof1. It
j
isvalidifthecovarianceispreconditionedbyitsdiagonalinthewaveletbasis. Classesoflinearsingularoperators,
preconditionedbytheirdiagonalinawaveletbasis,havebeenthoroughlystudiedinharmonicanalysis[Mey93]. Itis
usedtoprovethatsuchbasesareunconditionalbasesofSobolev,HolderandBesovspaces. Preconditioninginwavelet
basesisalsoappliedtothefastresolutionofellipticproblems[Jaf92]. Forappropriatewavelets,itisvalidforlarge
classesofpseudo-differentialoperators,andforsingularhomogeneousoperatorsdiagonalizedinaFourierbasiswith
eigenvaluesproportionalto|Ï‰|âˆ’Î·. ItrequiresthattheFouriertransformofwaveletsaresufficientlywelllocalized.
Atlowfrequencies,eachwaveletÏˆ musthaveaFouriertransformÏˆË† satisfying|ÏˆË† (Ï‰)|=O(|Ï‰|Î·/2),toavoidbeing
k k k
contaminatedbytheexplosionofthelargesteigenvaluesatlow-frequencies. Ifawavelethasmvanishingmoments,
thenAppendixAshowsthat|ÏˆË† (Ï‰)|=O(|Ï‰|m). Wethuschooseawaveletwithmâ‰¥Î·/2vanishingmoments. At
k
highfrequencies,|ÏˆË† (Ï‰)|musthaveadecayfasterthan|Ï‰|âˆ’Î·/2,whichissatisfiedifÏˆ hasmâ‰¥Î·/2derivativesin
k k
L2([0,1]2). IftheÏˆ haveacompactsupport,morethanÎ·/2vanishingmomentsandÎ·/2boundedderivatives,then
k
onecanprove[Mey93,MOBM22]thatthemaximumeigenvalueandtheconditionnumberofthecovarianceofallÏ†Â¯
j
areuniformlyboundedforallj andd.
Abadconditioningmaybeproducedbythesmallesteigenvaluesofthecovariance,whichareproperlyrenormalized
iftheyhaveadecaywhichisfasterthanapowerlawatthehighestfrequencies. Athighfrequencies,thefrequency
resolution of wavelets is not sufficient to follow this fast decay and thus renormalize these small eigenvalues. To
ensurethattheconditionnumberofthecovariancedoesnotincreasewithd,onecanrepresentthehigh-frequencyÏ†Â¯
j
inawaveletpacketbasishavingabetterfrequencyresolution. EachwaveletpacketmusthaveaFouriertransform
concentratedinasufficientlynarrowfrequencydomain,wherethecovarianceeigenvaluesvarybyalimitedmultiplicative
factor. Thefrequencywidthofthesewaveletpacketsis2a j timesmorenarrowthanwaveletsifcomputedwithawavelet
packetfilterGÂ¯ definedin(22). Theconstanta isadjustedtodefinewaveletpacketcoefficientsÏ†Â¯ whosenormalized
j j j
covarianceCÂ¯ hasaconditionnumberoftheorderof1. Improvingwaveletpacketfrequencyresolutionsby2a j also
j
increasestheirspatialsupportbyafactor2a j. Wethuschoosea tobeassmallaspossible. ThisisappliedinSection
j
5.2toimprovetheLangevinmixingtimefor2Dturbulencevorticityfields.
4 HierarchicalModelsofLocalScalarPotentials
Scalarpotentialmodelsintroducedinthissectionarelocalinteractionmodelsoftenusedinstatisticalphysics. Westudy
theparticularcaseoftheÏ†4modeltoillustratetheestimationandsamplingpropertiesofhierarchicalprobabilityflows
atphasetransitions.
4.1 ScalarpotentialenergiesandÏ†4model
Physicalsystemsatequilibriumhaveaprobabilitydensityp=Zâˆ’1eâˆ’U withanenergyU decomposedinaquadratic
termcorrespondingtotwopointinteractionsandanon-linearpotentialV(Ï†)whichspecifiesallotherinteractions:
âˆ’Î²
U(Ï†)= Ï†Tâˆ†Ï†+V(Ï†). (45)
2
TheLaplacianâˆ†isdiscretizedoverthegridofÏ†anddefinesthekineticenergyatatemperature1/Î². Somephysical
systems[Ram20]haveapotentialV whichisreducedtoasumofscalarpotentialsatalllocationsn
(cid:88)
V(Ï†)= v(Ï†(n)). (46)
n
13HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
ItenforcesnointeractionsbetweendifferentsitesnbutfavorsvaluesofÏ†(n)wherevisnearlyminimum. Ferromag-
netismandsecondorderphasetransitionsarecapturedbytheÏ†4model[ZJ21].Itsscalarpotentialv(t)=t4âˆ’(1+2Î²)t2
isnon-convex,withadouble-wellwhichpushesthevaluesofeachÏ†(n)towards+1orâˆ’1[ZJ21].
(a) (b) (c) (d)
Figure4: TopRow: RealisationsofÏ†4 fieldsattemperature1/Î²,andsystemsized=1282. (a): ForÎ² =0.5<Î²
c
, the system is disordered with short range correlations. (b): At the phase transition, Î² = 0.68 â‰ˆ Î² , the field is
c
self-similar, withlongrangecorrelations. (c): ForÎ² = 0.76 > Î² , thesystemisinaferromagneticphase, witha
c
non-zeromean(herepositive). Bottomrow: samplesgeneratedwithahierarchicfactorizationinaHaarwaveletbasis
withthesameÎ² in(a,b,c). (d): Thegraphshowsthecovarianceeigenvalues(powerspectrum)inthese3cases,asa
functionofthetwo-dimensionalfrequencyradius|Ï‰|=(|Ï‰ |2+|Ï‰ |2)1/2. ForÎ² =Î² ,eigenvalueshaveapower-law
1 2 c
decayanddevelopasingularityatlowfrequencies,whichcorrespondtolong-rangecorrelations. Wesuperimposed
indashedlinethecovarianceeigenvaluesofahierarchicmodelestimatedbyscorematching. Forvisualization,the
spectrumatdifferenttemperaturesaremultipliedbyaconstantwhichalignstheirminimumeigenvalue.
IfÎ² =0thenU(Ï†)=(cid:80) v(Ï†(n)). EachÏ†(n)aretheni.i.dindependentrandomvariablesofdensitypËœ(t)=Î·eâˆ’v(t).
n
Thepowerspectrumisconstant. Wesawin(5)thattheindependenceimpliesthatthelog-Sobolevconstantsatisfies
c(p) = c(pËœ), and thus does not depend upon the dimension of Ï†. If Î² > 0 the Laplacian correlate pixels over
a progressively larger neighborhood as Î² increases. It increases the power spectrum at low frequencies. In the
thermodynamiclimitdâ†’âˆofinfinitesystemsize,theÏ†4energyhasaphasetransitionatÎ² â‰ˆ0.68[KMR16]. The
c
powerspectrumthenhasapower|Ï‰|âˆ’Î· withÎ· =1.75asshowninFigure4(d). Itissingularatlow-frequencies,which
correspondstoafieldhavinglongrangecorrelations. Figure4showsrealizationsofÏ†4fieldsforÎ² <Î² ,Î² =Î² and
c c
Î² >Î² . ForÎ² >Î² (low-temperature),therearetwophaseswheretheaveragefieldvalueisstrictlypositiveorstrictly
c c
negative,whichexplainsferromagnetism. Figure4(d)correspondstoonephasewheremostfieldvaluesarecloseto1.
Hessianseigenvalues Theprobabilitydensityphasanon-convexenergyU whoseHessianis
âˆ‡2U(Ï†)=âˆ’Î²âˆ†+diag(Âµ ) with Âµ =vâ€²â€²(Ï†(n)).
Ï† n n n
TheLaplacianâˆ†isdiagonalintheFourierbasiswitheigenvalues|Ï‰|2.ThescalarpotentialisdiagonalinaDirac
basiswithpositiveandnegativeeigenvalues. TheseeigenvaluesaremuchlargerthantheLaplacianeigenvaluesat
low-frequenciesandproduceeigenvectorsoftheHessianâˆ‡2U havingnegativeeigenvalues.
Ï†
TodefineahierarchicmodelwithconditionalprobabilitiespÂ¯ (Ï†Â¯ |Ï† )havingsmalllog-Sobolevconstants,Section
j j j
3.6explainsthatwemaychooseprojectorsGÂ¯ thatselecteigenvectorshavinghighamplitudepositiveeigenvalues,
j
anddiscardnegativeeigenvalues. Atthefinestscale,thiscanbedone[GLBM23]withafirsthigh-frequencyfilterGÂ¯
1
whicheliminateslowfrequenciesandselectshigh-frequencyvariablesÏ†Â¯ . TheresultinginteractionenergyUÂ¯ hasa
1 1
projectedHessian
âˆ‡2 UÂ¯ (Ï†)=âˆ’Î²GÂ¯ âˆ†GÂ¯T+GÂ¯ (diag(Âµ ) )GÂ¯T.
Ï†Â¯ 1 1 1 1 i i 1
1
14HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Figure5(a)comparesthehistogramsoftheeigenvaluesofâˆ‡2 U andtheHessianâˆ‡2 UÂ¯ (withoutnormalizationfor
Ï† 0 Ï†Â¯ 1
0 1
comparisonpurposes). ItiscomputedwithaSymlet-4waveletforÏ†4 atcriticaltemperatureÎ² = Î² . Asexpected,
c
âˆ‡2 UÂ¯ hasfewernegativeeigenvaluesthanâˆ‡2 U ,butsomestillremain. Thesenegativeeigenvaluescanbealmost
Ï†Â¯ 1 Ï† 0
eve1 rywhereeliminatedbyanorthogonalGÂ¯ se0 lectingamorenarrowhigh-frequencybandthanwavelets. Thiscan
1
bedonewithwaveletpackets[GLBM23]. SinceÏ†4hasaself-similarprobabilitydistributionatthephasetransition
Î² =Î² ,thesameresultisobtainedatallotherscales2j.
c
(a) (b)
Figure5:(a):WeconsiderimagesÏ† oftheÏ†4modelofdimensiond=1282,foracriticalÎ² =Î² .Theapproximations
0 c
Ï† arecalculatedwithaSymlet-4filteratthefinestscale21. Thegraphshowsthedistributionsofeigenvaluesofthe
1
Hessianâˆ‡2 U inblue,andofâˆ‡2 UÂ¯ =âˆ‡2 U (withoutrenormalization)inorange. Themostnegativeeigenvalues
Ï† 0 Ï†Â¯ 1 Ï†Â¯ 0
0 1 1
ofâˆ‡2 U correspondtolowfrequencyeigenvectors. Theydonotappearinâˆ‡2 UÂ¯ . (b): Distributionsofeigenvalues
Ï† 0 Ï†Â¯ 1
0 1
ofHessiansâˆ‡2 UÂ¯ atallscales2j â‰¤2J,ford=322,withJ =3,forsamplesofhierarchicalmodelsofÏ†4atphase
Ï†Â¯ Î¸
j j
transition. TheyarecomputedforHaar(blue),Symlet-4(orange)andShannonwavelets(green). Eigenvaluesaremore
concentratedwhenthewavelethasabetterfrequencylocalization.
Figure5(b)displaysthedistributionofeigenvaluesofâˆ‡2 Ï†Â¯ jUÂ¯ Î¸Â¯ j(Ï† jâˆ’1),forsamplesÏ† jâˆ’1ofahierarchicmodel,computed
at all scales 2j â‰¤ 2J. These distributions are calculated for hierarchical factorization computed with Haar (blue),
Symlet-4(orange)andShannon(green)wavelets. TheHessianeigenvaluesarenearlythesameforShannonwavelets
andSymlet-4. ForHaarwaveletstherearemuchmorehighamplitudeeigenvalues. Indeed, Haarwaveletsarenot
aswelllocalizedinfrequency. ForaHaarwavelet, |ÏˆË†(Ï‰)|2 decayslike|Ï‰|âˆ’2 athighfrequenciesbecauseÏˆ(x)is
discontinuous. Thehighamplitudeeigenvaluesareduetothisslowhigh-frequencydecay,whichslowlycompensatefor
thegrowthsoftheHessianeigenvaluesproportionalto|Ï‰|Î· forÎ· =1.75[TaÂ¨u14].
TheexistenceofnegativeHessianeigenvaluespreventsusingtheBakry-Emerytheoremtocomputeanupperbound
onthelog-Sobolevconstantofwaveletconditionalprobabilities. However,weshallseeinthenextsectionthatthese
remainingnegativeeigenvaluesdonotpreventtheLangevindiffusionfromexponentialconvergence,evenatthephase
transition. Thesenumericalresultsareanindicationthatlog-Sobolevconstantofwaveletconditionalprobabilitiesdo
notdependuponthescale.
4.2 LearningandSamplinghierarchicScalarPotentialEnergies
This section reviews the estimation of hierarchic models of scalar potentials introduced in [MOBM22], and its
applicationtotheestimationandsamplingoftheÏ†4modelatcriticaltemperature. Itisshownin[MOBM22]thatthe
criticalslowingdowndisappearswhensamplingtheconditionalprobabilitiesofahierarchicfactorization,althoughthe
HessiansstillhavenegativeeigenvaluesinFigure5. WecomparedifferentwaveletsforlearningandsamplingtheÏ†4
modelatcriticaltemperature. Weshallseethatthemodelerrorsdecreasebydecreasingthewaveletsupport. Learning
precisionversussamplingconvergenceintroducesatrade-offbetweenspatialandfrequencylocalization,whichjustifies
theuseofwaveletsasopposedtoaFourierbasis,andwhereHaarwaveletsarethewinners.
Hierarchicscalarpotentials AhierarchicmodelisdefinedwithacoarsescalemodelU =Î¸TÎ¦ andinteraction
Î¸ J J
J
energymodelsUÂ¯ Î¸Â¯ =Î¸Â¯ jTÎ¨ j ateachscale2j â‰¥2J. WedefineÎ¦ J andeachÎ¨ j forscalarpotentialenergies,andprove
j
thatitdefinesastationaryhierarchicmodel,whosecouplingparametersarecomputedwithacoarsetofinecoupling
flowequation.
15HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Atthecoarsestscale,U =Î¸TÎ¦ includesatwo-pointinteractionmatrixandaparametricscalarpotential
Î¸ J J
J
1
Î¸TÎ¦ (Ï† )= Ï†TK Ï† +V (Ï† ), (47)
J J J 2 J J J Î³ J J
(cid:80)
whereV (Ï†)hasascalarpotentialv (t)= Î³ Ï (t)decomposedoverafiniteapproximationfamily{Ï (t)} with
Î³ Î³ k k k k k
coefficientsÎ³ =(Î³ ) . Itresultsthat
k k
V (Ï†)=Î³TÎ“(Ï†) with
Î“(Ï†)=(cid:16)(cid:88)
Ï
(Ï†(n))(cid:17)
. (48)
Î³ k
k
n
Weusetranslatedsigmoidswhichdonotgrowatinfinity: Ï (t)=(1+exp((tâˆ’t )/Ïƒ ))âˆ’1. Innumericalcalculations
k â„“ k
thereare40evenlyspacedtranslationst ,onthesupportofthedistributionofeachÏ† (n),andÏƒ = 3(t âˆ’t ). To
k J k 2 k+1 k
defineamodelofp whichisstationaryisequivalenttoimposethatK isaconvolutionaloperator.
J J
TheinteractionGibbsenergyUÂ¯ Î¸Â¯ ofp j(Ï†Â¯ j|Ï† j)includestwo-pointinteractionswithinthehighfrequenciesÏ†Â¯ j,between
j
highfrequenciesÏ†Â¯ ,andthelowerfrequenciesÏ† ,withconvolutionmatricesKÂ¯ andKÂ¯â€²,plusascalarpotential
j j j j
UÂ¯ Î¸Â¯ j(Ï† jâˆ’1)=Ï†Â¯T jKÂ¯ jÏ†Â¯ j +Ï†Â¯T jKÂ¯ jâ€²Ï† j +VÂ¯ Î³Â¯ j(Ï† jâˆ’1)=Î¸Â¯ jTÎ¨ j(Ï† jâˆ’1). (49)
Itdefines
ï£« KÂ¯ ï£¶ ï£« Ï†Â¯ Ï†Â¯T ï£¶
j j j
Î¸Â¯ j =ï£­ KÂ¯ jâ€² ï£¸ and Î¨ j(Ï† jâˆ’1)=ï£­ Ï†Â¯ jÏ†T j ï£¸. (50)
Î³Â¯ Î“(Ï† )
j jâˆ’1
ThestationaryinteractionKÂ¯â€² betweenhighandlow-frequencieshasanenergycontributionwhichistypicallymuch
j
smallerthantheinteractionKÂ¯ withinhighfrequencies,becauseÏ† andÏ†Â¯ arecomputedoverfrequencydomainshaving
j j j
asmalloverlap. ThefollowingtheoremdefinesastationaryhierarchicmodelfromthisscalarpotentialinteractionsÎ¨ .
j
Withanabuseofnotation,wewriteÏ†âˆ—Ï†TtheconvolutionbetweenÏ†andÏ†T(n)=Ï†(âˆ’n). Werecallfrom(65)that
Ï† (n)=Ï†âˆ—Ï• (2jn).
j j
Theorem4.1. Foranyj â‰¥J,
(cid:18) Ï† âˆ—Ï†T (cid:19)
Î¦ (Ï† )= j j (51)
j j Î“(Ï† âˆ—Ï• )
j â„“ Jâˆ’jâ‰¥â„“â‰¥0
definesstationaryhierarchicpotentialswithinteractionsÎ¨ in(49). RegressingeachfreeenergyF overÎ¦ definesa
j j j
finescaleGibbsstationarymodelforj =0
J
U (Ï†)= 1 Ï†TKÏ†+(cid:88) V (Ï†) with V (Ï†)=Î³TÎ“(Ï†âˆ—Ï• ), (52)
Î¸ 2 j j j j
j=0
whereK isaconvolutionmatrixand(Î³ ) arescalarpotentialparameterscomputedbyacouplingflowequation.
j 0â‰¤jâ‰¤J
TheproofisinAppendixE.3. Ateachscale2j,thisGibbsenergyhasadifferentscalarpotentialV (Ï†)=Î³TÎ“(Ï†âˆ—Ï• ).
j j j
TheconvolutionwithÏ• averagesÏ†overadomainproportionalto2j. Asthescale2j increases,itbecomesmoreand
j
morenon-local. Scalarpotentialenergies(45),suchastheÏ†4model,haveasinglepotentialV (Ï†)=(cid:80) v (Ï†(n))at
0 n 0
thefinestscalej = 0andarethuslocal. TheycorrespondtoaparticularcasewhereÎ³ = 0forj < 0. However,a
j
singlefinescalescalarpotentialisnotalwayssufficient. Thisisthecaseofcosmologicalweak-lensingfields,which
canbeapproximatedbyincorporatingdifferentscalarpotentialsV atdifferentscales. Inthiscase,numericalresults
j
showthathierarchicscalarpotentialmodelsprovideaccurateapproximationsofU [GLBM23,MOBM22].
Hierarchicmodelestimationandsampling Theparameters{Î¸ ,Î¸Â¯ } areestimatedfrommsamples{Ï†(i)}
J j jâ‰¤J iâ‰¤m
ofp,withtheconditionalscorematchingalgorithmofSection3.3. SamplesÏ†ofp Î¸ =wâˆ’1p Î¸
J
(cid:81) jpÂ¯ Î¸Â¯
j
arecomputed
withthehierarchicalsamplingalgorithmofSection3.4,whichdoesnotrequiretheknowledgeofthefreeenergies,or
normalizations,ofthepÂ¯ . TheMALAalgorithmincludesarejectionofLangevindiffusionpropositions. Thescalar
Î¸
j
potentialalsorejectsproposalsoutsideahighprobabilityinterval. Figure4comparesoriginalsamplesfrompcomputed
withexactÏ†4energiesatdifferenttemperatures,andsamplesofahierarchicalmodelpÂ¯ estimatedinaHaarwavelet
Î¸
basis. Generatedimageshavetextureswhichcannotbedistinguishedvisuallyfromtheoriginalimagetextures.
ThemodelprecisioncanbeevaluatedbycomputingtheresultingstationaryenergyandbycomparingitwiththetrueÏ†4
energy. Ahierarchicstationarymodel(52)ofÏ†4iscalculatedintheHaarbasisfromtheestimatedinteractionenergy
16HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
(a) (b) (c)
Figure 6: Original and estimated energy of Ï†4 at critical temperature, for images of size d = 128 Ã— 128. (a):
Superpositionofthescalarpotentialv(t)oftheÏ†4 modelforÎ² =Î² andtheestimatedscalarpotentialv (t)ofthe
c 0
hierarchicalstationaryenergymodelU . (b): SuperpositionoftheLaplacianeigenvalues(intheFourierbasis)andthe
Î¸
eigenvalueoftheestimated2-pointinteractionmatrixK ofU . (c): EstimatedconvolutionkernelofK. Theseresult
Î¸
showthatthehierarchicalstationarymodelcalculatedinaHaarbasisgivesapreciseapproximationoftheÏ†4energy.
parametersÎ¸Â¯ andthefreeenergyparametersÎ± . Theonlynon-zeroscalarpotentialisatthefinestscalej = 0. It
j j
impliesthatthescalarpotentialofthefreeenergyF cancelsthescalarpotentialoftheenergyatthepreviousscale.
j
Figure6comparestheestimatedenergyU andoriginalÏ†4 energy. Figure6(a)comparestheestimatedv (t)and
Î¸ 0
originalscalarpotentialfunctionv(t). Figure6(b)comparestheeigenvaluesoftheestimatedtwo-pointinteraction
matrixK andofaLaplacian,whichisthetwo-pointinteractionsoftheÏ†4model. Figure6(c)showstheconvolution
kernelofK isindeedclosetoaLaplacian. ItshowsthatthehierarchicstationarymodelinaHaarwaveletbasisgives
anaccurateapproximationoftheÏ†4energymodelatthephasetransition. Weshallseeattheendofthissectionthatthe
estimationerrorbecomeslargerwithDaubechiesandShannonwavelets,whichhaveaspatialsupportlargerthanHaar
wavelets.
105
10 2
104 Haar
Daubechies Symlet
Shannon 10 3
103
Direct Sampling
102 Haar
10 4
Daubechies Symlet
Shannon
101
103 104 103 104
d d
(a) (b)
Figure7: (a): NormalizedLangevinauto-correlationrelaxationtimeoftheÏ†4modelatcriticaltemperatureandfor
hierarchicalmodelscomputedindifferentwaveletbases. InredisshownthenormalizedrelaxationtimeofaLangevin
applieddirectlyontheenergyoftheÏ†4modelgrowswiththeimagedimensiond.Itillustratesthecriticalslowingdown.
Onthecontrary,itremainsconstantforallwavelethierarchicalmodels. Thisconstantdependsuponthelog-Sobolev
constantofwaveletconditionalprobabilities,whichdependsuponthewaveletchoice. Itdecreaseswhenthewavelet
hasaFouriertransformwhichisbetterconcentrated. ItismaximumforHaarandsmallerforDaubechies-4Symletand
Shannonwavelets.
(b):Approximationerrorofhierarchicalmodelscomputedinthesamebasesasin(a).Thiserrormeasuresthedifference
betweenthemarginalandsecondordermomentsofsamplesofÏ†4andthesamemomentscomputedfromsamplesof
hierarchicalmodelsineachwaveletbasis. ItisquantifiedwithaKLdivergencecalculatedin(84). Theerrordecreases
whenthewaveletsupportdecreasesbecauseitisdominatedbytheestimationerrorofthenon-convexscalarpotential.
ItismuchsmallerforaHaarwaveletthanforSymlet-4wavelets. TheShannonwaveletwhichhasanon-compact
supportwithaslowspatialdecayyieldsamuchlargererrorthanHaarandSymletâˆ’4wavelets.
17HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Criticalslowingdownatphasetransition Samplingp = Zâˆ’1eâˆ’U withanundajustedLangevinalgorithmhas
a computational complexity proportional to the number of iterations after discretization. It is proportional to the
log-Sobolevconstantc(p)multipliedbythelargesteigenvalueoftheHessianofU,asexplainedinSection2.1. For
Î² = Î² ,itsuffersfromacriticalslowingdownduetoagrowthofthelog-Sobolevconstantwhenthesystemsized
c
increases. TheconvergenceofLangevindiffusionisestimatedbytheauto-correlationrelaxationtimedefinedin(8),
whichistypicallyproportionaltothelog-Sobolevconstantc(p). Thecomputationalcomplexityisevaluatedbythe
normalizedrelaxationÏ„ equaltoauto-correlationrelaxationtimedividedbythediscretisationtimestep. Figure7(a)
givestheevolutionofthisnormalizedhierarchicrelaxationtimeÏ„ asafunctionofthesystemsizedforÎ² = Î² . It
c
growslikedÎ· 0/2forÎ· =2[Pod96,Set21,TaÂ¨u14]. Thisbehaviorispartlyexplainedbythelog-Sobolevlower-bound
0
c(p)â‰¥Âµ /2whereÂµ isthelargesteigenvalueofthecovariance. Itgrowsliked1.75/2forÎ² =Î² ,asshownby
max max c
thepowerspectruminFigure4. However,thisexplanationisnotcompletesincethecovarianceisonlyalower-bound.
Thelog-Sobolevconstanthasafastergrowthexponentwhere1.75isreplacedby2whichgivesd. Indeed,italsosuffers
fromthenon-convexityofthescalarpotential,whichisnotcapturedbythecovariancelower-bound.
Ithasbeenshownin[MOBM22]thatahierarchicalfactorizationinawaveletbasisavoidsthiscriticalslowingdown. To
computethenormalizedauto-correlationrelaxationtimeofthehierarchicalsamplingalgorithm,wecomputeforeachj
therelaxationtimeÏ„Â¯ j ofprobabilityp Î¸Â¯ (Ï†Â¯ j|Ï† j),likein(8). Thehierarchicnormalizedauto-correlationrelaxationtime
j
Ï„,isdefinedby
Ï„
=(cid:88)J dÂ¯
j Ï„Â¯ +
d
J Ï„ , (53)
d j d J
j=1
where (dÂ¯,d ) are the dimensions of (Ï†Â¯ ,Ï† ). Appendix F.1 explains how to estimate the relaxation time of each
j j j j
conditionalprobability. EachnormalizedrelaxationtimeÏ„Â¯ isdividedbythediscretizationtime-step. Toevaluatethe
j
overallcomputationalcomplexity,eachÏ„Â¯ j ismultipliedbytherelativesizedÂ¯ j/dofthegradientâˆ‡ Ï†Â¯ jUÂ¯ Î¸Â¯ j.
Figure7(a)givesthehierarchicnormalizedauto-correlationrelaxationtime,dependingonthesystemsized,fordifferent
waveletbasis. ForHaar,DaubechiesSymletsandShannonwavelets,Figure7(a)showsthathierarchicnormalized
auto-correlationrelaxationtimesdonotincreasewiththedimensiond,whatverifiesthattheydonotsufferfromthe
phase-transitioncriticalslowingdown. Itreproducestheabsenceofcriticalslowingdownobservedin[MOBM22]with
anMetropolis-Hastingsampling,asweknowthattheMCMCmixingtimetendstoanundadjustedLangevindiffusion
inthecontinuumtimelimit[ABBL06,GGR97].
Theseexperimentsgiveastrongindicationthatlog-Sobolevconstantsofwaveletconditionalprobabilitiesareuniformly
boundedindependentlyofd,despitethefactthattheenergyHessianshavenegativeeigenvalues. Thisisamathematical
conjecturewhichhasnotbeenproved.Calculationsofthelog-SobolevconstantofÏ†4havebeencarriedfortemperatures
abovethecriticaltemperature[BD22,BBD23,CE22,BB19],buthavenotbeenextendeduptothephasetransition. As
expected,Figure7(a)alsoshowsthathierarchicnormalizedauto-correlationrelaxationtimebecomessmallerwhen
improving the frequency localization of wavelets. Shannon wavelets have more vanishing moments and are more
regularthanDaubechiesSymletswhicharethemselvesbetterlocalisedinfrequencythanHaarwavelets. Becausethe
Haarwavelethasapoorfrequencylocalization,thecoarsegrainingdoesnoteliminateallthehighfrequencyfrom
Ï† ,whichareresponsibleforbigeigenvaluesinâˆ‡2 UÂ¯ . Thistail,observedFigure5(b)requiresreducingthetime
jâˆ’1 Ï†Â¯ j
j
samplingstepoftheLangevindynamic,anditincreasesthenormalizedrelaxationtimes.
Energyestimationerror Approximatingscalarpotentialenergiesrequirestoaccuratelyapproximatethekinetic
energytermandthescalarpotential. TheHessianofthekineticenergyisaLaplacian,whichisdiagonalinaFourier
basiswithpositiveeigenvalues. Thescalarpotentialisnon-convexwithaHessianwhichisdiagonalinaDiracbasis
withnegativeeigenvalues. Itisthedifficulttermtoestimate.
Hierarchicalmodelscanbesampledwithoutestimatingthefreeenergiesofconditionalprobabilities. Toevaluatethe
modelprecisionwithoutestimatingthefreeenergies,wequantifyestimationerrorsbycomputingmodelerrorsona
sufficientsetofmoments. ThesemomentsareestimatedbyMonteCarlo,overthedatabasisofsamplesofÏ†4andby
generatingsampleswiththehierarchicsamplingalgorithmforeachhierarchicmodel. Forscalarpotentialenergies,
thesufficientstatisticsaredefinedbysecondordermomentsandbythemarginaldistributionoftheÏ†(n). Appendix
Dcomputesin(84)aKullbackdivergenceerrore(p,p )whichaddsaKullbackdivergenceerrorfromsecondorder
Î¸
momentsandfrommarginaldistributions.
Figure7(b)givesthevalueofthemomenterrorforhierarchicalmodelscomputedwithHaar,Symlet-4andShannon
wavelets. Thesemodelsarelearnedwithlargeenoughdatasetssothatthevarianceofstatisticalestimatorsbecomes
negligible. TheerrorisminimumforHaarwavelets. ItismuchlargerforaSymlets-4wavelet,whosesupportis7
timeslarger. ForaShannonwavelet,whichhasaslowspatialdecay,theestimationerrorofmarginaldensitiesbecomes
18HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
extremelylarge. Thiserrorcomesfromthemixingproducedbywaveletsofwidesupport. Thecentrallimittheorem
proves that a linear combination of a sufficiently large number of independent variables converges to a Gaussian.
Non-convexitiesthusdisappearfromthemarginalsofwaveletcoefficientsiftheirsupportistoolarge,butitstraceis
presentinhighorderinteractionsofthesewaveletvariables. Thisismuchmoredifficulttoestimate. Thisisalsowhyit
wouldbedifficulttoestimateaÏ†4modelinaFourierbasis. ThemarginaldistributionofeachFourierbasisisconvex,
whichlooksgoodandsimple,butthemodelestimationthenrequiresincorporatingthehighorderdependenciesof
Fouriercoefficients,torecoverthenon-convexityofthescalarpotential.
Waveletbasesseemtohaveanear-optimaltrade-offtoestimatetheprobabilitydistributionofÏ†4atthephasetransition
whileavoidingthecriticalslowingdown. Surprisingly,theHaarwaveletcorrespondingtoKadanoffrenormalizing
groupisthebestwaveletchoice. Itminimizesthemodelestimationerrorwhileavoidingthecriticalslowingdown.
5 RobustMultiscaleHighOrderInteractions
Non-Gaussianrandomfieldscanhavelongrangeinteractionsacrossspaceandscales. Inimages, itoftenappears
throughtheexistenceofsharptransitionswhichpropagatealongpiece-wiseregularcurvessuchasfilamentsoredges.
Non-Gaussianpropertiesmaybecapturedbyhigherorderpolynomials,butittypicallyleadstohigh-dimensionalmodels
andhighvarianceestimators. Section5.1introduceslowdimensionalmodelsofmultiscaleprobabilityinteractions.
Itdefinesrobustapproximationsofhighordermodels. Section5.2studiesnumericalapplicationstomodellingand
generationofdarkmatterdensitiesand2Dturbulentvorticities.
5.1 InteractionsoverMultipleHierarchiesbyWaveletScattering
Hierarchicmodelsdecomposepintoacascadeofconditionalprobabilitiesacrossscales,whicharerewrittenasthe
conditionalprobabilitiesofwaveletcoefficients. Inthefollowing,webuildmodelsofsuchconditionalprobabilities,
by computing a complex wavelet transform which explicitly provides a complex phase. Non-Gaussian properties
are captured with a second wavelet transform, on the complex modulus of the first wavelet transform, leading to
low-dimensionalmodelsoflong-rangespatialdependenciesanddependenciesacrossscales.
Complexwavelettransform TomodeltheprobabilitydistributionofÏ† conditionedonÏ† ,wecomputeacomplex
jâˆ’1 j
wavelettransformofÏ† . ThecomplexwaveletcoefficientscalculatedfromÏ† canalsobewrittenasconvolutions
jâˆ’1 jâˆ’1
ofÏ†withcomplexwaveletsÏˆËœ atscales2jâ€² â‰¥2j. TheyhaveQorientationsindexedbyk,sampledonthegridof
jâ€²,k
Ï† atintervals2jâˆ’1
jâˆ’1
(cid:16) (cid:17)
Ï†âˆ—ÏˆËœ (2jâˆ’1n) .
jâ€²,k
n
Letgbethelow-passfilterofthecoarse-grainingoperatorGwhichcomputesÏ† fromÏ†.AppendixAshowsthat
jâˆ’1
Ï†âˆ—ÏˆËœ iscalculatedfromÏ† withana-trousalgorithm. Itisacascadeofjâ€²âˆ’jâˆ’1convolutionsofg,followedby
jâ€²,k jâˆ’1
convolutionswithafamilyofcomplexband-passfiltergËœ=(gËœ ) . Thesefiltersaredilatedbyintroducingzerosin
k kâ‰¤Q
betweentheircoefficients. Innumericalapplications,gËœhasQ=4MorletfiltersspecifiedinAppendixA.Ateachscale
2j,theydefine4waveletsÏˆËœ whosesupportisproportionalto2j. Theyareapproximatelyrotatedby0,Ï€/4,Ï€/2and
j,k
3Ï€/4. Figure8showtherealandimaginarypartsofthewaveletsÏˆ forj =3computedwiththeseMorletfilters
j,k
andtheSymlet-4filtersg. ThesecomplexwaveletshaveaHermitiansymmetryÏˆËœ (âˆ’n)=ÏˆËœâˆ— (n). Theirrealand
j,k j,k
imaginarypartsarethereforesymmetricandantisymmetric. ThelowestfrequenciesareretainedbythescalingfilterÏ• ,
J
thatwewriteÏ• =ÏˆËœ tosimplifynotations.
J J+1,k
Figure8: ComplexwaveletÏˆËœ computedwitha2DSymlet-4low-passfilterg,and4orientedMorletfilters(gËœ ) ,
j,k k kâ‰¤4
atthescale2j = 8. TheupperandlowerrowsshowrespectivelytherealpartandtheimaginarypartsofÏˆËœ ,for
j,k
k =1,2,3,4.
19HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Scale 2jâ€™
Orientation kâ€™
(a) (b)
Scale 2jâ€™ Scale 2jâ€™
Orientation kâ€™ Orientation kâ€™
(c) (d)
Figure9: (a):Ï† isavorticityfieldofa2Dturbulence. (b):Complexwavelettransformatscales2jâ€² â‰¥2j computed
jâˆ’1
fromÏ† withoutsubsampling. Foregroundandbackgroundimagesshowrespectivelytherealandimaginaryparts
jâˆ’1
ofÏ†âˆ—ÏˆËœ ,computedwithMorlettypewavelets. Eachrowcorrespondstoascale2jâ€² â‰¥2j andeachcolumntothe
jâ€²,kâ€²
Q = 4orientationindiceskâ€². (c)Modulus|Ï†âˆ—ÏˆËœ |ofwaveletcoefficientimages. Theyhavealargeamplitude
jâ€²,kâ€²
atsharptransitions,withlong-rangedependenciesinspaceandacrossscalesandorientations. (d)Theforeground
andbackgroundimagesaretherealandimaginarypartsof|Ï†âˆ—ÏˆËœ |âˆ—ÏˆËœ fordifferentjâ€² andkâ€²,andforafixed
jâ€²,kâ€² â„“,k
â„“ = 3andk = 1. Theseimageslook-alike,whichshowsthatwaveletcoefficientmodulus|Ï†âˆ—ÏˆËœ |havestrong
jâ€²,kâ€²
dependenciesacrossscales2jâ€² andorientationskâ€².
Figure9(b)showsthewaveletcoefficientsofavorticityimageof2Dturbulencefield. Thewaveletcoefficientsofsucha
stationaryfieldarealmostnotcorrelatedacrossscales,becausewaveletshaveaFouriertransformlocalizedindifferent
frequencybands. Waveletcoefficientsindifferentfrequencybandshavephaseswhichoscillateatdifferentratesor
alongdifferentorientations,whichcancelcorrelations. However,theamplitudes|Ï†âˆ—ÏˆËœ |ofwaveletcoefficientsare
jâ€²,k
stronglycorrelatedacrossscales,asshownbyFigure9(b). Thevorticityfieldhassharpvariationswhichcreatelarge
amplitudewaveletcoefficientsatthesamepositionsovermultiplescalesandorientations.
Wavelet scattering Most wavelet modulus |Ï† âˆ— ÏˆËœ | have long range spatial dependencies. This long range
jâ€²,kâ€²
dependency is represented by local interactions with a second hierarchic decomposition, computed with a second
wavelettransformof|Ï†âˆ—ÏˆËœ |.
jâ€²,kâ€²
ThewaveletcoefficientsÏ†âˆ—Ïˆ andthesecondwavelettransformof|Ï†âˆ—Ïˆ |q forq =1orq =2areincorporated
jâ€²,kâ€² jâ€²,kâ€²
intoavectorofscatteringcoefficients:
(cid:32) (cid:33)
Ï†âˆ—ÏˆËœ (2jâˆ’1n)
S (Ï† )=
jâ€²,kâ€²
. (54)
jâ€² jâˆ’1 |Ï†âˆ—ÏˆËœ |qâˆ—ÏˆËœ (2jâˆ’1n)
jâ€²,kâ€² â„“,k â„“â‰¥jâ€²,k,kâ€²â‰¤Q,n
20HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Ifq =2thenupperandlowertermsofS arearepolynomialsofdegree1and2ofthevaluesÏ†(n). Ifq =1theneach
jâ€²
termremainsLipschitz,butthecomplexmodulusmaycreatesingularitieswhencomplexwaveletcoefficientsvanish,
whichisaddressedbyreplacing|z|by(|z|2+Ïµ)1/2,forasmallÏµ. Scatteringcoefficients|Ï†âˆ—ÏˆËœ |qâˆ—ÏˆËœ areindexed
jâ€²,kâ€² â„“,k
bytwoscales2jâ€² â‰¥2j and2â„“ â‰¥2jâ€² . Thisdoublehierarchymeasuresthevariationsof|Ï†âˆ—ÏˆËœ |q overneighborhoods
jâ€²,kâ€²
ofsizesproportionalto2â„“,inadirectionindexedbyk. Figure9(b)showsthesescatteringcoefficientsforafixed(â„“,k).
Robustscatteringinteractionenergies Weintroduceahierarchicprobabilitymodelfromscatteringcoefficients. At
thelargestscale2J,theGibbsenergymodelU = Î¸TÎ¦ ofp (Ï† )isdefinedwithaquadratictermandascalar
Î¸ J J Î¸ J
J J
potential,asin(47). Atscales2j â‰¥2J,wedefineaGibbsenergymodelUÂ¯ Î¸Â¯ ofp(Ï†Â¯ j|Ï† j)frominteractionsofscattering
j
coefficients. LetzTbethecomplexconjugatetransposeofthecomplexvaluedvectorz. Theenergymodelincludes
twopointinteractionsbetweenscatteringcoefficientsS atthescale2j withS for2jâ€² â‰¥2j,plusascalarpotential:
j jâ€²
J+1
UÂ¯ Î¸Â¯
j
= (cid:88) S jTK j,jâ€²S jâ€² +VÂ¯ Î³Â¯
j
=Î¸Â¯ jTÎ¨ j , (55)
jâ€²=j
where
Î¨ =(cid:18) S jS jT â€² (cid:19) and Î¸Â¯ =(cid:18) K j,jâ€² (cid:19) . (56)
j Î“ j Î³Â¯
jâ€²â‰¥j j jâ€²â‰¥j
Thedimensionalityofthismodelcanbereducedfromknownsymmetriesofp. Ifpisstationary,thenp (Ï† )is
jâˆ’1 jâˆ’1
invarianttotranslation. ThetranslationinvarianceofUÂ¯ Î¸Â¯
j
isequivalenttoimposingthateachK j,jâ€² isaconvolutional
operatoroverthespatialgridofÏ† . Symmetriestoactionsofothergroupscanbeenforcedwithotherconditions
jâˆ’1
discussedinthenextsection.
Ifq =2,thenthecoordinatesofeachS arepolynomialsofdegree1and2ofthevaluesÏ† (n),soeachinteraction
jâ€² jâˆ’1
term STK S is a a polynomial of degree 4. If q = 1, then the complex wavelet phase is treated similarly but
j j,jâ€² jâ€²
UÂ¯ Î¸Â¯ hasaquadraticgrowthinÏ†asopposedtoadegree4. Itisobtainedbyreplacing|z|2 by|z|. Thepolynomialof
j
degree4ischangedintoapolynomialofdegree2withphaseharmonics,whosepropertiesarestudiedin[ZM21]. It
improvesstatisticalrobustnessbecause|z|isLipschitzasopposedto|z|2. Similarlytoalinearrectifierusedinneural
networks,|z|ishomogeneousandcanbecomputedasalinearcombinationofrectifiers[ZM21]. Modelscomputed
with q = 1 have similar properties to models computed with q = 2, but are often more accurate because of their
statisticalrobustnessstudiedinthenextsection.
Localscatteringspectruminteractions Ahierarchicorganizationaimsatcreatingtheneededlong-rangeinteractions
throughlocalinteractionsinthehierarchy. Similarly,ascatteringspectrumdefineslong-rangemodelsofstationary
fieldswithlocallow-dimensionalinteractionsamongscatteringcoefficients.
Ascatteringspectruminteractionmodelisconstructedbyeliminatingtheinteractiontermsin(55)whichareapriori
negligible. Forstationaryprobabilities,theinteractionmatricesK areconvolutionoperators. ImagesofS are
j,jâ€² jâ€²
complexwaveletcoefficientcomputedwithÏˆËœ orwithÏˆËœ for2â„“ â‰¥2jâ€² . TwoimagesofS andS haveanenergy
jâ€²,kâ€² â„“,k j jâ€²
mostlyconcentratedindisjointfrequencydomainsiftheyarecomputedwithdifferentwavelets. Theirinteractionthus
hasanegligiblecontributiontotheenergyUÂ¯ Î¸Â¯
j
becauseeachK j,jâ€² in(55)isconvolutional.
TwoimagesofS andS computedwithasameÏˆËœ haveapriorianon-zerointeraction. Ascatteringspectrummodel
j jâ€² â„“,k
furtherassumesthatwaveletcoefficientinteractionsarelocalinspace. Thisassumptionisvalidformultiscalestationary
processeswhichdonotproduceoscillatoryphenomena. Ascatteringspectrummodelkeepsonlytheinteractionof
pairsofscatteringcoefficientsinS andS whichhavethesamespatialposition.
j jâ€²
Theresultingscatteringspectrummodelassumesthatinteractionsarelocalinspaceandoverthescatteringscales.
However, it defines long-range interactions in space and across the wavelet coefficients of the original image Ï†.
Appendix B shows that this scattering spectrum model reduces Î¨ to a vector of dimension O(log2d) if Ï† has a
j
dimensiond. ThefullhierarchicenergymodelU Î¸ aggregatestheinteractionmodelsUÂ¯ Î¸Â¯ atallscalesdâ‰¥2j â‰¥1. Itis
j
thusdefinedbyacouplingvectorÎ¸ofdimensionO(log3d).
21HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
StationaryScatteringEnergyModel Wegiveananalyticalformulationofthestationaryscatteringenergymodel
U Î¸ obtainedfrominteractionenergymodelsUÂ¯ Î¸Â¯ atallscales2j. Itiscalculatedwithhierarchicstationarypotentials
j
definedfromthescatteringinteractionenergiesÎ¨ in(55). LetuswritethecomplexwavelettransformofÏ†
j
(cid:16) (cid:17)
WÏ†= Ï†âˆ—ÏˆËœ (n) , (57)
j,k
0<jâ‰¤J+1,k,n
This wavelet transform without subsampling is computed with the a-trous algorithm of Appendix A. From Ï† =
j
Ï†âˆ—Ï• (2jn),AppendixAshowsthatthea-trousalgorithmcomputeswaveletcoefficientsofÏ†atscales2J â‰¥2jâ€² â‰¥2j
j
subsampledatintervals2j. Wewrite
(cid:32) (cid:33)
Ï†âˆ—Ï• (2jn)
R(Ï† )= j .
j |Ï†âˆ—ÏˆËœ (2jn)|q
jâ€²,kâ€²
jâ€²â‰¥j,kâ€²,n
Iff =(f ) isafamilyofrealvaluedfields,wealsowritef âˆ—fT =(f âˆ—fT) withfT(n)=f (âˆ’n).
k k k kâ€² k,kâ€² k k
Theorem5.1. Thepotentials
(cid:18) R(Ï† )âˆ—R(Ï† )T (cid:19)
Î¦ (Ï† )= j j (58)
j j Î“(Ï† âˆ—Ï• )
j â„“ Jâˆ’jâ‰¥â„“â‰¥0
arestationaryhierarchicwithinteractionsÎ¨ definedin(55). RegressingeachfreeenergyF overÎ¦ definesafine
j j j
scaleGibbsstationarymodel
J
U (Ï†)=
1 Ï†TKÏ†+(cid:88)
V (Ï†)+V (Ï†), (59)
Î¸ 2 j int
j=0
withV (Ï†)=Î³TÎ“(Ï†âˆ—Ï• )and
j j j
1
V (Ï†)=Ï†TL(|WÏ†|q)+ (|WÏ†|q)TM(|WÏ†|q), (60)
int 2
whereÎ³ andtheconvolutionoperators(K,L,M)arecomputedwithalinearcouplingflowequation.
j
TheproofisinAppendixE.4. Whenq = 2, theinteractionpotentialisthusasumofthirdorderandfourthorder
polynomialswhichcaptureinteractionsbetweenwaveletcoefficientsatthescale2j andlargerscales. Settingq =1
givesarobustapproximation,wherealltermshaveaquadraticgrowth. TheconvolutionalmatricesLandM have
non-localkernelsinspace. Alocalscatteringspectrummodelonlykeepsinteractioncoefficientsbetweenpairsof
scatteringcoefficientscomputedwithasamewavelet,atasameposition. ItimpliesthatK =WTKâ€²W,L=WTLâ€²W
andM = WTMâ€²W,whereKâ€² isdiagonalandLâ€² andMâ€² areblockdiagonalconvolutionalmatrix,withatotalof
O(log3d)non-zerointeractioncoefficients.
5.2 NumericalApplicationstoDarkMatterandTurbulenceFields
WeevaluatetheprecisionofhierarchicalwaveletscatteringmodelsU fortwotypesofnon-Gaussianphysicalfields
Î¸
havingcoherentgeometricstructures. WecomputetheLangevinnormalizedauto-correlationrelaxationtimeasaproxy
toevaluatetheevolutionofnormalizedlog-Sobolevconstants,afterrenormalization.
Numericalexperimentsarecarriedon2Dfieldsofdarkmatterimages,whicharethelogarithmof2Dslicesofsimulated
3Dlarge-scaledistributionofdarkmatterintheUniverse[VNHM+20]showninFigure10(a). Wealsomodel2D
turbulencevorticityfieldsofincompressible2Dfluidsstirredatthescalearound32pixels,atafixedtime,simulated
from2DNavier-Stokesequations[SZFA06],showninFigure10(a). Thetimeevolutionof2Dturbulenceisaninverse
cascadewhichtransferstheenergytowardsthelowestscales[Kra67]. The2DNavier-Stokesimulationinitializedwith
aGaussianwhitenoiseatt = 0definesatransportofthisGaussianwhitedistributionintoastationarydistribution
atafixedt. Thevorticityfieldisstationaryinspaceatafixedtime,butitdoescomefromasystematequilibriumin
time. ThereisnoclosedformulaforHamiltoniansofsuchoutofequilibriumsystems,exceptinparticular1Dcases
[DLS02,BDSG+15]. Bothdatasets(100and3000independentrealizations)haveperiodicboundaryconditionsandare
down-sampledtod=1282pixels. Theyareaugmentedwithrotationsandspatialsymmetriesbecausetheirprobability
distributionisisotropic.
22HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Original Scalar Potentials Scattering q=1 Scattering q=2
2.0
1.5
1.0
0.5
0.0
-0.5
-1.0
-1.5
2.0
1.5
1.0
0.5
0.0
-0.5
-1.0
-1.5
(a) (b) (c) (d)
Figure10: (a): Toprow: 2Dslideofa3Ddark-mattersdensitysimulation[VNHM+20]. Bottomrow: vorticityfields
ofa2Dperiodicturbulentflowatafixedtimet,generatednumericallywiththe2DNavierStokesequationfroman
initialGaussianwhitenoise[SZFA06]. (b): Samplesofthehierarchicalscalarpotentialmodeldefinedin(49). (c):
Samplesofthehierarchicwaveletscatteringmodel,withanexponentq =1. (d): Sameas(c)withanexponentq =2.
Hierarchicmodelgenerations Figure10(b,c,d)showsimagesgeneratedfromhierarchicalmodels,respectivelywith
ascalarpotential,robustwaveletscatteringinteractionswithq = 1andhigherorderwaveletscatteringwithq = 2.
Overallscales,thescalarpotentialmodelandthewaveletscatteringmodelshaverespectivelyabout300and2500
couplingparameters. Thereisnoscalarpotentialterminthescatteringmodels.
GenerationsfromscalarpotentialmodelsinFigure10(b)donotrestorerandomgeometricstructuresappearinginthe
originalfields. Fordarkmatterfields,thewaveletscatteringmodelsinFigure10(c,d)reproducewellthevisualtexture
oftheseimages. Forthevorticityfieldsof2Dturbulence,eddiesandvorticityflowsarewellreproducedonlywithq =1
butaredegradedforq =2. Indeed,asshownby(12)andinAppendixC.1,computingthecouplingflowparametersÎ¸Â¯
j
ofthehierarchicalmodelrequiresinvertingamatrixofempiricalmomentsestimatedonthetrainingdataset. Higher
orderpolynomialsamplifyoutliers. Itincreasestheestimationvarianceofhighordermoments,andthusintroduces
moreerrors. Asexpected,thescatteringmodelwithq =1ismorerobustthanthehighordermodelwithq =2. For
turbulenceimages,estimationerrorscanintroduceadivergenceoftheLangevindiffusionatthefinestscale,wherethe
spectrumhasafastdecay. Thisisavoidedbyaddingasmallconfinementtermforlargeamplitudecoefficients. Itadds
ÏµD jÏ†Â¯4 j totheenergyUÂ¯ Î¸Â¯ . ThevalueofÏµisabout10timeslargerforq =2thanforq =1,whichaffectsthegenerated
j
imagequality.
Langevinrelaxationtime Therenormalizationaimsatreducingtheamplitudeofnormalizedlog-Sobolevconstantto
estimateamodelbyscorediffusionwithasfewsamplesaspossibleandtoreducethecomputationalcomplexityof
theLangevindiffusion. Anecessaryconditionistocontrolthelargesteigenvalueofthecovarianceanditscondition
number. AsexplainedinSection3.6,ahierarchicalmodelmustusewaveletshavingenoughvanishingmomentsand
whicharesufficientlyregular. ForDarkmatterimagesandturbulencefields,werespectivelyuseSymlet-3andSymlet-4
wavelets. Thesedarkmatterand2Dturbulenceimageshaveapowerspectrumwhichdecaysfasterthanapowerlawat
thehighestfrequencies. Torenormalizethesmallesteigenvaluesofthecovarianceathighfrequencies,Section3.6also
explainsthatÏ†Â¯ canberepresentedinawaveletpacketbasishavingasufficientfrequencyresolution. Thewavelet
j
packetfiltering(22)reducesthewidthofwaveletfrequencysupportsbyafactor2a j. Innumericalexperiments,weset
a =min(a,Jâˆ’j)andweadjusta. Fora=0,thewavelet-packetbasisisawaveletbasis. Choosingawaveletpacket
j
basisasopposedtoawaveletbasisdoesnotmodifythehierarchicenergymodel. Itonlymodifiesthecoordinatesystem
representingÏ†Â¯ andhencetherenormalizationwhichmodifiesthelog-Sobolevconstant.
j
Figure11givestheevolutionoftheLangevinnormalizedauto-correlationrelaxationtimeÏ„ ofthehierarchicalmodel
in(53),asafunctionofthesystemsized. Fora=0correspondingtowavelets,therelaxationtimeÏ„ increaseswith
23HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
102
a=0 a=0
a=1 a=1
a=2 a=2
a=3 a=3
101
100
103 104
d
Figure11: Langevinnormalizedauto-correlationrelaxationtime(53)forscatteringhierarchicalmodelscomputedin
waveletorwaveletpacketbases,witha =min(a,J âˆ’j),asafunctionoftheimagesized. Langevinrelaxationtime
j
fordarkmatter,(computedwithq =2,inaSymlet-3basis)areinblueandfordark-matterfields(computedwithq =1,
inaSymlet-4basis)inred. IncreasingthewaveletpacketFourierresolutionwithaslightlyreducestherelaxationtime,
butitdoesnotavoidanexponentialgrowthwithd.
thesystemsized,bothfordark-matterandturbulencefields. Thisisdifferentfromtherelaxationtimeofhierarchical
modelsofÏ†4showninFigure7(a),whichdoesnotgrowwithd. However,afterrenormalization,therelaxationtimefor
dark-matterandturbulenceis3ordersofmagnitudebelowtheoneforÏ†4withoutanyrenormalization. Itshowsthat
thehierarchicalrenormalizationacceleratesconsiderablythesampling,althoughitstilldegradeswithd.
IncreasingthefrequencyresolutionofwaveletpacketswithahasasmalleffectontheLangevinrelaxationtimegrowth
in Figure 11. The remaining growth is due to the non-Gaussian multiscale behavior of the model. It is produced
by scaling properties of third and fourth order energy components, which are different from second order scaling
propertiesofthecovariance,andarethereforenotcompensatedbyarenormalizationbasedonthecovariance. Such
phenomenaappearinmultifractalrandomprocesses[Jaf04,AGV13]. ThescatteringmodelgeneratedinFigure10(b,c)
arecalculatedbyrenormalizingwaveletcoefficientsinawaveletpacketbasis,witha=3forturbulenceimagesand
witha=2fordarkmatterfields.
Hierarchicmodelprecision Wehavenoenergymodelforthedarkmatterandturbulencefieldsusedinnumerical
experiments. Themodelprecisionisthusevaluatednumericallyoverafamilyofstandardmomentsusedinstatisticsand
physics. Wetestthedistributionofpoint-wisemarginals,theFourierspectrum(secondordermoments),thebi-spectrum
(thirdordermoments)alsocalculatedinthefrequencydomain,andstructurefunctions. Eachmomentisestimatedwith
aMonteCarlosumovermtrainingsamplesofp. Thesemomentsarecomparedwithmomentsofhierarchicalmodels,
alsoestimatedwithaMonteCarlosumoverenoughmodelsamplesgeneratedbyMALAsampling.
Figure12(a,b)showthatscalarpotentialmodelsgeneratestationaryfieldsÏ†,whereÏ†(n)haveamarginaldistribution
nearly equal to the marginals of the original fields, since the model is optimized from these marginals. The same
resultisobtainedforthewaveletscatteringmodels,althoughtheydonotincorporateascalarpotentialwhichimposes
thesemarginalmoments. Allmodelsreproducewellthepowerspectrum,whichisonlyspecifiedinthesemodelsbya
reduceddiagonalmatrixwithlessthanlogdwaveletsecondordermoments.
Thebi-spectrumisathird-ordermomentscomputedoverFouriercoefficients,whichiszeroforaGaussianprocess.
Itisalsozeroifp(Ï†) = p(âˆ’Ï†)whichisthecaseforthe2Dturbulencevorticity. Itisthusonlycomputedforthe
dark-matterdensityimages. Thebi-spectrumcalculationisexplainedinAppendixF.2. Figure12(d)showsthatthe
bi-spectrumiswellreproducedbyawaveletscatteringmodelwithq =2,whichincorporatesthirdorderpolynomial
terms. Itisalsowellreproducedwithq =1. Thisrobustmodeldoesnotincludethirdordertermsbutalowerorder
equivalenttermwhichisalsoantisymmetric. Ontheopposite,thebi-spectrumofthescalarpotentialmodelisquite
differentfromthebi-spectrumoftheoriginaldark-matterfield.
Kolmogorovstructurefunctions[kol41]aremomentsofordermoverthefieldofincrements,indexedbythespatiallag
Î´
SF (Î´)=E (cid:0) |Ï†(n)âˆ’Ï†(nâˆ’Î´)|m(cid:1) . (61)
m p
Figures12(e,f)plotthestructurefunctionsrespectivelyform=1andm=4since2ndand3rdordermomentshave
alreadybeenevaluated. Theonlymodelprovidinganaccurateapproximationbothfortheturbulenceanddark-matter
24HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
0.7
A B 101 A
10 1 10 1 0.6 B
10 2 10 2 100 0.5
Original Original Original Original
A
10 3 q=1 10 3 q=1 q=1 0.4 q=1
10 1
q=2 q=2 q=2 q=2
10 4 10 4 B 0.3
Scalar Scalar Scalar Scalar
10 2 0.2
0 5 -5 0 5 100 101 102 100 101
| |
(a) (b) (c) (d)
0.7 5
A
0.08 Original A
q=2
0.06 0.6 4
q=1
0.04 Scalar B
0.5 3
A B
0.02
0.4 2
0.00 Original Original
q=2 q=2
-0.02 0.3 q=1 1 q=1
-0.04 Scalar Scalar
0.2 0
0 20 40 60 80 100 101 100 101
(e) (f) (g)
Figure12: Eachgraphshowsaspecificfamilyofmomentsestimatedonthetrainingdata(inblack)andonsamplesof
ahierarchicalmodel(waveletscatteringwithq = 1inred,withq = 2ingreen,andscalarpotentialmodelinblue).
Modelsarelabeled(A)fordark-matterand(B)for2Dturbulence. Grayzonesrepresenttheestimationvarianceof
theseshigherordermomentsoverthetrainingdataset. (a,b): marginalprobabilitydensitiesofÏ†(n). (c): covariance
eigenvalues(power-spectrum). (d): Structurefunctionoforderm=1asafunctionofÎ´. (e): thirdorderbi-spectrum
moments,orderedfromlowtohighfrequencies. Notshownforthe2Dturbulence(B),becausetheyallvanish. (f):
Structurefunctionoforderm=4. (g): Structurefunctionoforderm=6.
fieldsistherobustwaveletscatteringmodelforq =1. Theerrorofthewavelethigh-ordermodelforq =2overthe
turbulencefieldisduetothelargerregularizationneededtoconfinetheLangevindiffusion. Thereproductionofhigher
ordermomentsslowlydegradewhenincreasingtheorderofthemoments. Figure12(g)showsthatnoneofthemodel
faithfullyreproducesthestructurefunctionoforder6ondarkmatter,butitiswellreproducedontheturbulencewhich
ismoreGaussian.
Two-point interaction model Since the wavelet scattering model have no scalar potential, Theorem 5.1 proves
thatthestationarymodelischaracterizedby3convolutionaloperators: K,L,M in(59). Theyarecomputedfrom
thelearnedinteractionparametersÎ¸Â¯ ateachscale,withthecouplingflowequation(41). Figure13(a,b)showsthe
j
convolutionkernelK forturbulenceanddark-matterdatasets. Bothkernelsarelocalinspaceandnearlyisotropic,
whichisnotimposedbythemodel. TheyresembletoaLaplacian. Figure13(c)showstheirFouriertransformas
a function of the frequency amplitude |Ï‰|. The estimated kernel for 2D turbulence has higher eigenvalues at high
frequenciesthantheonefordarkmatter,whatiscoherentwiththefasterdecreaseofitspowerspectrum.
6 Conclusion
Hierarchicmodelsprovideaninverserenormalizationgroupdecompositionofprobabilitydistributionsintoconditional
probabilities in wavelet bases. The renormalization partly avoids the bad conditioning of learning and sampling
algorithms,byreducinglog-Sobolevconstants. FortheÏ†4model,weconjecturethatiteliminatesthecriticalslowing
down,asshownbynumericalexperiments.
25HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
3 1.5 3 6 0.8 2d Turbulence
2 2 Dark Matter
1.0
0.6
1 1 4
0 0.5 0 0.4
2
-1 -1
0.0 0.2
-2 -2
0
-3 -0.5 -3 0.0 | |
-3 -2 -1 0 1 2 3 -3 -2 -1 0 1 2 3 0 1 2 3
(a) (b) (c)
Figure13: Estimated2-pointconvolutionalkernelK ofU definedineq.(59),forq =1. (a): kernelfordarkmatter
Î¸
images. (b): kernelfor2Dturbulence. Theyarelocalandnearlyrotationinvariant. (c): Fouriertransformofeachkernel
asafunctionof|Ï‰|.
For multiscale non-Gaussian processes such as dark matter distribution or 2D turbulence, we introduced a low-
dimensionalwaveletscatteringmodel,basedonrobustmultiscalehighorderinteractions. Numericaltestsshowthat
theycanprovideanaccuratemodelofcomplexfieldsbeyondscalarpotentialmodels,butweremainfarfromasatisfying
modelofturbulence. Morecomplexstructuresappearin3Dwheretheenergycascadeisnotinverted,andwedonot
considerthetimeevolution.
Numericalexperimentsshowthatrobustmultiscalescatteringmodelsimprovetheestimationbyreducingtheamplitude
growthofhighorderpolynomials. AsopposedtoÏ†4,forturbulenceanddark-matterfields,therenormalizationreduces
butdoesnotavoidtheexponentialincreaseoflog-Sobolevconstantswiththefielddimension. Moreover,estimation
errorscancreateadivergenceofLangevindiffusions,ifnotregularized.
RegularizationissuescanbeaddressedbyreplacingtheLangevindiffusionbyascorediffusion[SSK+21,RBL+22]for
eachpÂ¯ Î¸Â¯ (Ï†Â¯ j|Ï† j),asin[GCDBM22]. Anintegratedrenormalizationgroupapproachofscorediffusionandmultiscale
j
coarsegrainingschemesisproposedin[CR23]. Thisisalsomotivatedbythespectacularresultsofscorediffusion
generations with deep neural networks, and particularly with U-Nets [RFB15] which integrate multiscale image
decompositions. Understandingthecorrespondencebetweenthesemultiscaledeepnetworkdecompositionsandrobust
highorderwaveletscatteringenergiesisyetanotherchallengingquestion.
Acknowledgments
This work was supported by a grant from the PRAIRIE 3IA Institute of the French ANR-19-P3IA-0001 program.
WethankRudyMorel,ErwanAllysandMisakiOzawaforprovidingthetrainingdatasets.WealsothankNathanaeÂ¨l
Cuvelle-MagarandJean-BaptisteHimbertforfeedbackonthemanuscript.
A WaveletTransforms
Wereviewthepropertiesofrealandcomplexwavelettransformscomputedbyiteratingoverlow-passandband-pass
filters,inoneandtwodimensions.
Conjugatemirrorfilters Orthogonalwaveletsarecomputedwithconjugatemirrorfilters. Indimensionr =1,apair
ofconjugatemirrorfilter(g,gÂ¯)includesalow-passfiltergwhoseFouriertransformgË†(Ï‰)=(cid:80) g(n)eâˆ’inÏ‰ satisfies
n
âˆš
|gË†(Ï‰)|2+|gË†(Ï‰+Ï€)|2 =2 and gË†(0)= 2. (62)
ThesecondfiltergÂ¯hasasinglehigh-passfilterdefinedbygÂ¯(n)=(âˆ’1)1âˆ’ng(1âˆ’n). Onecanverifythattheresulting
convolutionandsubsamplingoperators
GÏ†(n)=Ï†âˆ—g(2n) and GÂ¯Ï†(n)=Ï†âˆ—gÂ¯(2n) (63)
(cid:16) (cid:17)
defineanorthognalmatrix G [Mal09]. Allconvolutionsarecomputedwithperiodicboundaryconditions.
GÂ¯
Forimages(r =2),two-dimensionalconjugatemirrorfiltersarecomputedasseparableproductsofone-dimensional
conjugatemirrorfilters(g,gÂ¯)[Mal09]. Forn = (n ,n )thereisasingletwo-dimensionalseparablelow-passfilter
1 2
g(n ,n )=g(n )g(n )and3high-passfiltersingÂ¯=(gÂ¯ ) ,with
1 2 1 2 k 1â‰¤kâ‰¤3
gÂ¯ (n ,n )=g(n )gÂ¯(n ), gÂ¯ (n ,n )=gÂ¯(n )g(n ), gÂ¯ (n ,n )=gÂ¯(n )gÂ¯(n ).
1 1 2 1 2 2 1 2 1 2 3 1 2 1 2
26HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
TheconvolutionaloperatorGandGÂ¯ intwodimensionsarestilldefinedby(63)withthesetwo-dimensionalseparable
filters,andGÂ¯Ï†has3outputimages.
A-trousfilters Averagedcoefficientsandwaveletcoefficientsareiterativelycomputedforj >0with
Ï† (n)=Ï† âˆ—g(2n) and Ï†Â¯ =Ï† âˆ—gÂ¯(2n). (64)
j jâˆ’1 j jâˆ’1
These coefficients can be written as convolutions of the input Ï† = Ï† with a scaling filter Ï• and wavelets Ïˆ
0 j j,k
subsampledby2j:
Ï†
=(cid:0)
Ï†âˆ—Ï•
(2jn)(cid:1)
and Ï†Â¯
=(cid:0)
Ï†âˆ—Ïˆ
(2jn)(cid:1)
. (65)
j j n j j,k k,n
Thesescalingfiltersandwaveletssatisfyrecursiveequationscomputedwithâ€a-trousâ€filtersresultingfromthecascaded
subsampling. Inonedimension,foranyfilterhwewriteh thea-trousfiltersuchthath (2jn)=h(n)andh (n)=0
j j j
if2âˆ’jnisnotanintegerinonedimensionordoesnotbelongtothetwo-dimensionalgridN2intwodimensions. The
a-trousfilterh isadilationofhby2j,bysettingintermediatecoefficientstozero. Onecanderivefrom(64)that
j
Ï• =Ï• âˆ—g and Ïˆ =Ï• âˆ—gÂ¯ . (66)
j jâˆ’1 jâˆ’1 j,k jâˆ’1 jâˆ’1,k
Scalingfiltersandwaveletsarethusobtainedwithacascadeofa-trousfilters. Onecanverifythat
Ï† âˆ—Ï• (n)=Ï† âˆ—Ï• (2n), (67)
j â„“ jâˆ’1 â„“+1
and
Ï† âˆ—Ïˆ (n)=Ï† âˆ—Ïˆ (2n). (68)
j â„“ jâˆ’1 â„“+1
Asymptoticwaveletbases Whenj goestoâˆ,forappropriatefiltersgÂ¯andlow-passfiltersg,onecanprove[Dau92]
thatÏ• andÏˆ convergetoÏ•(x)andwaveletsÏˆ (x),uptoadilationby2j.Theselimitfunctionsaresquareintegrable,
j j,k k
(cid:82) |Ï•(x)|2dx<âˆand(cid:82) |Ïˆ (x)|2dx<âˆ. In1dimension,conjugatemirrorfiltersdefineascalingfunctionÏ•(x)and
k
asingleasymptoticwaveletÏˆ(x)whoseFouriertransformsÏ•Ë†(Ï‰)andÏˆË†(Ï‰)satisfy
ÏˆË†(Ï‰)=
âˆš1
gË†Â¯(2âˆ’1Ï‰)Ï•Ë†(2âˆ’1Ï‰) with
Ï•Ë†(Ï‰)=+ (cid:89)âˆ gË†(2 âˆšâˆ’qÏ‰)
.
2 2
q=1
IfweimposethatgË†(Ï‰)>0forÏ‰ âˆˆ[âˆ’Ï€/2,Ï€/2],thenonecanprove[Mal09]that{2âˆ’j/2Ïˆ(2âˆ’jxâˆ’n)} nâˆˆZ,jâˆˆZisan
orthonormalbasisofL2(R). Ifwelimitthemaximumscaleto1,withperiodicboundaryconditions,weobtainan
orthonormalbasisofL2([0,1]2). Waveletswithnon-periodicboundaryconditionsmayalsobedesigned[Dau92].
AHaarfilteristheconjugatemirrorfilterhavingaminimumsizespatialsupport: g(n)=1ifn=0,1andg(n)=0
otherwise. ItdefinestheHaarwaveletÏˆshowninFigure14(a). TheShannonlow-passfilterhasaFouriertransform
havingaminimumsizesupport: gË†=1 . ItdefinesaShannonwavelet,showninfigure14(c). ADaubechies
[âˆ’Ï€/2,Ï€/2]
Symletfiltergoforderm[Dau92]hasasupportofsize2mâˆ’1anddefinesacompactlysupportedwavelethavingm
vanishingmoments:
(cid:90)
âˆ€0â‰¤k <m, xkÏˆ(x)dx=0.
TheseintegralsimplythatÏˆË†anditsmâˆ’1firstderivativesvanishatthefrequencyÏ‰ = 0andhencethat|ÏˆË†(Ï‰)| =
O(|Ï‰|m). ASymletfilterisassymmetricaspossible[Dau92]. TheregularityofÏˆalsoincreaseswithm. TheSymlet-4
waveletisshowninfigure14(b).
ComplexMorletfilters ComplexwaveletsÏˆËœ aredefinedbyreplacingtherealfiltersgÂ¯= (gÂ¯ ) byafamilyof
j,k k k
complexfiltersgËœ=(gËœ ) . Similarlyto(66)
k k
Ï• =Ï• âˆ—g and ÏˆËœ =Ï• âˆ—gËœ , (69)
j jâˆ’1 jâˆ’1 j,k jâˆ’1 jâˆ’1,k
wheregËœ isthea-trousfilterdefinedfromgËœ .
j,k k
InnumericalapplicationsweuseQ=4complexMorletfiltersgËœ={gËœ } definedby
k kâ‰¤Q
gËœ (n ,n )=Î³eâˆ’Î·(n2 1+n2 2)(cid:0) eiÎ¾(n 1cosÎ± k+n 2sinÎ± k)âˆ’Î² (cid:1) , (70)
k 1 2 k
(cid:80)
Î± =kÏ€/QandeachÎ² isadjustedsothat gËœ (n ,n )=0.WechooseÎ· =1.67andÎ¾ =Ï€. Figure8shows
k k n ,n k 1 2
1 2
thetwo-dimensionalcomplexwaveletsÏˆËœ ,computedwiththe2Dseparablelow-passSymlet-4conjugatemirrorfilter
j,k
gandthesecomplexMorletfiltersgËœ.
Attheverylargescalesclosetotheimagesize,toavoidissuescreatedbyperiodicboundaryconditions,thefiltersgËœ are
k
modified. Theyareconstructedfromtheanalyticpartoftheconjugatefilters{gÂ¯ } associatedtog. Computingthe
k kâ‰¤3
analyticpartamountstorestricttheFouriertransformoverhalfoftheFourierplane[Mal09],whichdefinesacomplex
filter. Thethirddiagonalfilterisdividedintotwoanalyticfilterslocatedinthetwodiagonaldirections.
27HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Haar Symlet Shannon
1 1 1
0 0 0
-1 -1 -1
-5 0 5 -5 0 5 -5 0 5
1 1 1
0 0 0
-25 0 25 -25 0 25 -25 0 25
(a) (b) (c)
Figure14: Toprow: Graphsofdifferentone-dimensionalwaveletsÏˆ(t). Bottomrow: GraphsoftheirFouriertransform
modulus|ÏˆË†(Ï‰)|. (a)Haar(1vanishingmoment),(b)DaubechiesSymlet(4vanishingmoments),(c)ShannonWavelet.
A-trouswavelettransform Foranyj >0,Ï† (n)=Ï†âˆ—Ï• (2jn). Moreover,(69)impliesthat,forj â‰¤jâ€²,
j j
ÏˆËœ =Ï• âˆ—g âˆ—...âˆ—g âˆ—gËœ .
jâ€²,k jâˆ’1 jâˆ’1 jâ€²âˆ’2 jâ€²âˆ’1
OnecanthusverifythatÏ†âˆ—ÏˆËœ (2jâˆ’1n)iscalculatedfromÏ† byana-trousalgorithmwhichcascadesconvolutions
jâ€²,k jâˆ’1
withdilatedlow-passfiltersgandthecomplexMorletwaveletfiltergËœ
k
Ï†âˆ—ÏˆËœ (2jâˆ’1n)=Ï† âˆ—gâˆ—...âˆ—g âˆ—gËœ (n). (71)
jâ€²,k jâˆ’1 jâ€²âˆ’jâˆ’1 jâ€²âˆ’j,k
ThecomplexwavelettransformW in(57)iscomputedbyconvolutionswithÏ• andÏˆËœ withoutsubsampling. Since
j j
thesefiltersarecascadeofa-trousfiltersg andgÂ¯ in(69),theseconvolutionscanbecalculatedasacascadeofa-trous
j j
filterings,fromÏ†=Ï† :
0
Ï†âˆ—ÏˆËœ (n)=Ï†âˆ—gâˆ—..âˆ—g âˆ—gËœ (n). (72)
j,k jâˆ’2 jâˆ’1
B ScatteringSpectrumInteractions
ThisappendixspecifiesscatteringspectruminteractionmatricesK ,forthewaveletscatteringmodel(55),with
j,jâ€²
S (Ï† )=(cid:0) Ï†âˆ—ÏˆËœ (2jâˆ’1n), |Ï†âˆ—ÏˆËœ |qâˆ—ÏˆËœ (2jâˆ’1n)(cid:1) .
jâ€² jâˆ’1 jâ€²,k jâ€²,kâ€² â„“,k k,kâ€²â‰¤Q,â„“â‰¥jâ€²,n
AscatteringspectrummodelforstationaryprocessesretainsinteractionsbetweencoefficientsofS andS in(55)
j jâ€²
computedwiththesamewaveletsatasamespatialposition. ThepairsofcoefficientsofS andS whichinteractare
j jâ€²
thus
Ï†âˆ—ÏˆËœ (2jâˆ’1n) and Ï†âˆ—ÏˆËœ (2jâ€²âˆ’1n) forjâ€² =j,1â‰¤k â‰¤Q, (73)
j,k jâ€²,k
|Ï†âˆ—ÏˆËœ |qâˆ—ÏˆËœ (2jâˆ’1n) and Ï†âˆ—ÏˆËœ (2jâˆ’1n) forjâ€² =â„“,1â‰¤kâ€²,k â‰¤Q, (74)
j,kâ€² â„“,k jâ€²,k
|Ï†âˆ—ÏˆËœ |qâˆ—ÏˆËœ (2jâˆ’1n) and |Ï†âˆ—ÏˆËœ |qâˆ—Ïˆ (2jâˆ’1) forâ„“â‰¥jâ€² â‰¥j,1â‰¤k,kâ€²,kâ€²â€² â‰¤Q. (75)
j,kâ€² â„“,k jâ€²,kâ€²â€² â„“,k
For translation invariant energies, the translation invariant version of the potential Î¨ in (56) has four interaction
j
potentials:
(cid:16) (cid:17)
Î¨ = Î“, Î› , Î› , Î› . (76)
j 2,j 3,j 4,j
ThepotentialvectorÎ“definedin(48)providesanapproximationofscalarpotentials. Fortheother3potentials,we
onlykeepinteractionsbetweencoefficientscomputedwithasamewaveletatasameposition. Theinteractions(73)
givetheaverageofsquaredwaveletcoefficientsineachdirectionk:
Î› (Ï†
)=(cid:16)(cid:88)
|Ï†âˆ—ÏˆËœ
(2jâˆ’1n)|2(cid:17)
. (77)
2,j jâˆ’1 j,k
kâ‰¤Q
n
28
)t(
)
(HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
TheyprovideanestimationofthepowerspectrumoverthefrequencysupportwhereÏˆË† isconcentrated. Forprocesses
j,k
withpowerspectrumsthatdecreasefasterthanapowerlaw,weaswellincludeinÎ› shiftedtwopointsinteractions,
2,j
oftheform(cid:80) Ï†âˆ—ÏˆËœ (2jâˆ’1n)Ï†âˆ—ÏˆËœâˆ— (2jâˆ’1(n+Ï„)),withsmallÏ„.
n j,k j,k
Theinteractionterms(74)capturetheinteractionbetweenwaveletcoefficientsatthescale2jâ€²
andscatteringcoefficients
atasamescale2â„“ =2jâ€²
Î› (Ï†
)=(cid:16)(cid:88)
|Ï†âˆ—Ïˆ |qâˆ—Ïˆ (2jâˆ’1n)Ï†âˆ—Ïˆâˆ—
(2jâˆ’1n)(cid:17)
. (78)
3,j jâˆ’1 j,m jâ€²,k jâ€²,k k,mâ‰¤Q,jâ€²â‰¥j
n
ItisantisymmetricinÏ†anditcapturesphasealignmentpropertiesacrossscales. Ifq = 2thentheyarethirdorder
polynomial moments in Ï†. When q = 1 these these coefficients capture similar properties [CMA+23]. The last
interactionterms(75)givetheinteractionsbetweenwaveletmoduluscoefficientsatdifferentwaveletscales2j and2jâ€²
butatthesamescatteringscales2â„“
Î› (Ï†
)=(cid:16)(cid:88)
|Ï†âˆ—ÏˆËœ |qâˆ—ÏˆËœ (2jâˆ’1n)|Ï†âˆ—ÏˆËœ |qâˆ—ÏˆËœâˆ—
(2jâˆ’1n)(cid:17)
. (79)
4,j jâˆ’1 j,kâ€² â„“,k jâ€²,kâ€²â€² â„“,k k,kâ€²,kâ€²â€²â‰¤Q,â„“â‰¥jâ€²â‰¥j
n
Ifq =2thentheydefinefourthordermoments. Whenq =1theyhavesimilarnumericalproperties[CMA+23]. The
largestnumberofcoefficientsiswithinÎ› . ThedimensionofÎ¨ isoftheorderofQ3(jâˆ’J)2.
4,j j
Furtherdimensionalityreduction IfÏ†hasaprobabilitydistributionwhichisinvarianttorotations,thentheenergy
remainsinvarianttotheflippingoperatorwhichtransformsÏ†(n)intoÏ†(âˆ’n). SinceÏˆËœ (âˆ’n) = ÏˆËœâˆ— (n),onecan
j,k j,k
verify,similarlyto[MZR20,MRL+23],thattheimaginarypartsofÎ› andÎ› changesignwhenÏ†(n)istransformed
3,j 4,j
intoÏ†(âˆ’n). ItresultsthattheinteractioncoefficientsoftheenergyU overtheseimaginarypartsarezero. Weimpose
Î¸
thispropertyinallnumericalexamplesshowninthispaperbyeliminatingtheimaginarypartsofÎ› andÎ› from
3,j 4,j
Î¨ . Wealsopointoutthatforasymmetricalprocess,suchthatÏ†andâˆ’Ï†havethesamedistribution,onecanaswell
j
discardÎ› .
3,j
C EstimationofConditionalEnergyparameters
C.1 Interactionenergyestimationbyscorematching
InsteadofminimizingdirectlyeachtermE p j(cid:0) KL(pÂ¯ j,pÂ¯ Î¸Â¯ j)(cid:1) ,andapplyingthealgorithmin(10),whichrequiresheavy
calculations,weuseascorematchingalgorithmwhichminimizesarelativeFisherinformation. Itiscalculatedwitha
gradientrelativelytoÏ†Â¯ ,whicheliminatesthefreeenergyF (Ï† ). ThecorrespondingFisherinformationisaveraged
j j j
withp :
j
E p j(cid:0) I(pÂ¯ Î¸Â¯ j,pÂ¯ j)(cid:1) =E p jE pÂ¯ j(cid:16) âˆ¥âˆ‡ Ï†Â¯ jlogpÂ¯ j(Ï†Â¯ j|Ï† j)âˆ’âˆ‡ Ï†Â¯ jlogpÂ¯ Î¸Â¯ j(Ï†Â¯ j|Ï† j)âˆ¥2(cid:17) .
Accordingto[HD05]andsimilarlyto(11),sinceâˆ‡ Ï†Â¯ jlogpÂ¯ Î¸Â¯
j
=Î¸Â¯ jTâˆ‡Î¨ j,onecanverifythatitisequivalenttominimize
(cid:16)1 (cid:17)
â„“(Î¸Â¯ )=E âˆ¥Î¸Â¯Tâˆ‡ Î¨ (Ï† )âˆ¥2âˆ’Î¸Â¯Tâˆ† Î¨ (Ï† ) . (80)
j p jâˆ’1 2 j Ï†Â¯ j j jâˆ’1 j Ï†Â¯ j j jâˆ’1
Thiscalculationcanbedoneinparallelforallj.
Likeeq.(12),aclosedformfortheminimizingÎ¸Â¯ isgivenby
j
Î¸Â¯ =MÂ¯âˆ’1E (cid:0) âˆ† Î¨ (Ï† )(cid:1) with MÂ¯ =E (cid:0) âˆ‡ Î¨ (Ï† )âˆ‡ Î¨ (Ï† )T(cid:1) (81)
j j p Ï†Â¯ j jâˆ’1 j p Ï†Â¯ j jâˆ’1 Ï†Â¯ j jâˆ’1
jâˆ’1 j jâˆ’1 j j
Forconsidereddatasets,withthepotentialÎ¨ fromeq.(55),(80)isanill-conditionedquadraticlearningproblem. We
j
computethematrixMÂ¯ fromeq.(81),andpreconditionÎ¸,bydefiningÎ¸Ëœ =(MÂ¯ +ÏµId)1/2Î¸Â¯ ,whoseoptimalvaluecan
j j j j
becomputedbyminimizingthequadraticloss
â„“Ëœ(Î¸Ëœ)= 1 Î¸Ëœ Î¸ËœTâˆ’Î¸ËœTE (cid:0) (MÂ¯ +ÏµId)âˆ’1/2Tâˆ† Î¨ (Ï† )(cid:1) ,
2 j j j p jâˆ’1 j Ï†Â¯ j j jâˆ’1
whichhasaconditionnumberof1. Thislossfunctionisminimizedusingasinglebatchgradientdescent. Thesame
procedureappliestoÎ¸ ,atthecoarsestscale,forthequadraticlossdefinedineqs.(11)and(12). Duetothefinitesize
J
ofthedatasets,theexpectanciesarereplacedwiththeirempiricalestimations. Forapplicationsinthispaper,weused,
forÏµ,valuesnotbiggerthan10%oftheeigenvaluesofMÂ¯ .
j
29HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
C.2 Freeenergycalculation
ToderivetheGibbsenergyU (Ï†)inequation(30),wedefineandoptimizealinearapproximationF =Î±TÎ¦ ofthe
Î¸ Î± j j
j
freeenergyF j definedbythenormalizationintegral(29)ofpÂ¯ Î¸Â¯ . TakingthederivativewithrespecttoÏ† j in(29)gives
jâˆ’1
âˆ‡ F (Ï† )âˆ’E (cid:0) Î¸Â¯Tâˆ‡ Î¨ (Ï† )(cid:1) =0. (82)
Ï† j j j pÂ¯ Î¸Â¯ j(Ï†Â¯ j|Ï† j) j Ï† j j jâˆ’1
Using the previous equation, it can be proven that the free energy F is a minimizer of the quadratic function
j
f (cid:55)â†’E
(cid:0)(cid:13)
(cid:13)âˆ‡ f(Ï† )âˆ’Î¸Â¯Tâˆ‡ Î¨ (Ï†
)(cid:13) (cid:13)2(cid:1)
. TheparametersÎ± areoptimizedwiththequadraticloss
pÂ¯ Î¸Â¯ j(Ï†Â¯ j|Ï† j)p j(Ï† j) (cid:13) Ï† j j j Ï† j j jâˆ’1 (cid:13) j
â„“(Î± )=E
(cid:0)(cid:13)
(cid:13)Î±Tâˆ‡ Î¦ (Ï† )âˆ’Î¸Â¯Tâˆ‡ Î¨ (Ï†
)(cid:13) (cid:13)2(cid:1)
. (83)
j pÂ¯ Î¸Â¯ j(Ï†Â¯ j|Ï† j)p j(Ï† j) (cid:13) j Ï† j j j j Ï† j j jâˆ’1 (cid:13)
ThisexpectedvalueiscalculatedwithanempiricalaverageoverthemsamplesÏ†(i)ofp . ForeachÏ†(i)weknowa
j j j
sampleÏ†Â¯( ji)ofpÂ¯ j(Ï†Â¯ j|Ï†( ji)). WemodifythissamplewithaMALAalgorithmtoobtainasampleofpÂ¯ Î¸Â¯ j(Ï†Â¯ j|Ï†( ji)),which
approximatespÂ¯ (Ï†Â¯ |Ï†(i)).
j j j
D MomenterrorsonÏ†4
Metriconmoments Weevaluatethemodelerrorsfromgeneratedsampledoverasufficientsetofmoments. For
Ï†4,thesestatisticsaresecondordermomentsandthemarginaldistributionofÏ†(n).ThisappendixdefinesaKullback-
divergenceerrorfromthesemoments.
102
Synthesis
10 1
Original
10 2 101
10 3
100
10 4
10 5
-2 -1 0 1 2 100 101 102
| |
(a) (b)
Figure15: (a): ThemarginalprobabilitydistributionofeachÏ†(n)iscomputedfromsamplesoftheÏ†4modelatthe
phasetransition. Itissuperimposedwiththemarginalprobabilitydistributionofsamplesofthehierarchicmodelina
Haarwaveletbasis. (b): EigenvaluesofcovariancematricesintheFourierbasis. Theyarecomputedfromsamplesof
theÏ†4modelandwiththeHaarhierarchicmodel,forimagesofsized=1282. Thehierarchicmodelrecoversprecisely
bothtypesofmomentsin(a)and(b),whicharesufficientstatisticsforÏ†4.
The Ï†4 model has a Gibbs energy U(Ï†) = Î¸TÎ¦(Ï†), where Î¦ is defined in (51), with a single scalar potential
Î“(Ï†âˆ—Ï• ) = Î“(Ï†)forâ„“ = 0. Sections2.2showsthatpisequaltothemaximumentropydistributionp suchthat
â„“ Î¸
E (Î¦)=E (Î¦). ThesemomentsspecifiedbythecovarianceC ofp(Ï†)andbythemarginaldistributionpËœ(t)offield
p p
Î¸
valuest=Ï†(n).
Toevaluatetheprecisionofahierarchicmodelp ,weevaluatethecovarianceC andthemarginaldistributionpËœ (t),
Î¸ Î¸ Î¸
with a Monte Carlo average over samples generated by this model. We compute the KL divergence between the
maximum entropy distributions having covariances a C and a C . Both distributions are gaussians and their KL
Î¸
divergenceis
1 d 1
log(|C Câˆ’1|)âˆ’ + TrCCâˆ’1.
2 Î¸ 2 2 Î¸
30HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
ThemaximumentropydistributionshavingmarginalspËœandpËœ arerandomvectorswithdindependentcoordinates.
Î¸
TheirKLdivergenceisthusdKL(pËœ,pËœ ). AddingandrenormalizingtheseKLdivergencesbythedimensiondgivesan
Î¸
error:
1 1 1
e(p,p )= log(|C Câˆ’1|)âˆ’ + TrCCâˆ’1+KL(pËœ,pËœ ). (84)
Î¸ 2d Î¸ 2 2d Î¸ Î¸
Figure15showsthattheestimatedmarginaldistributionspËœandtheeigenvaluesofthecovarianceC ofpareprecisely
approximatedbythemarginalpËœ andthecovarianceC ofthehierarchicalmodelp computedinaHaarbasis.
Î¸ Î¸ Î¸
E ProofsofPropositionsandTheorems
E.1 ProofofProposition2.1
Thelog-Sobolevequation(2)impliesaPoincareÂ´ inequality[Led00]
(cid:90)
E[|f(Ï†)âˆ’E(f(Ï†))|2]â‰¤2c(p) âˆ¥âˆ‡f(Ï†)âˆ¥2p(Ï†)dÏ†.
Thisisproven,forregularenoughfunctionsf ,byapplyingthelog-Sobolevinequalitytothedensityq =p+Ïµ(pf âˆ’
E (cid:0) f(cid:1) ),andlettingÏµgotozero. Lete beanormalizedeigenvectorofthecovarianceofpcorrespondingtothe
p max
maximumeigenvalueÂµ andf(Ï†)=âŸ¨e ,Ï†âŸ©. ThePoincareÂ´ inequalityappliedtof gives
max max
(cid:90)
Âµ â‰¤2c(p) âˆ¥e âˆ¥2p(Ï†)dÏ†=2c(p),
max max
whichprovesthatc(p)â‰¥Âµ /2.
max
E.2 ProofofProposition3.1
ToprovethatKL(p,qËœ)â‰¤KL(p,q),wedecompose
(cid:90) (cid:90)
KL(p,qËœ)= p(Ï†)logp(Ï†)dÏ†âˆ’ p(Ï†)logqËœ(Ï†)dÏ†,
withqËœ=ZËœâˆ’1eâˆ’Ave jâˆ’1U. LetusverifythatthesecondtermincreaseswhenqËœisreplacedbyq =Zâˆ’1eâˆ’U.
Sincepistranslationinvariant,achangeofvariableprovesthat
(cid:90) (cid:90)
âˆ’ p(Ï†)logqËœ(Ï†)dÏ†=|G |âˆ’1 p(Ï†) (cid:88) U(T Ï†)dÏ†+logZËœ
jâˆ’1 Ï„
Ï„âˆˆG
jâˆ’1
(cid:90)
= p(Ï†)U(Ï†)dÏ†+logZËœ, (85)
where
(cid:90) (cid:90)
ZËœ= eâˆ’Ave jâˆ’1U(Ï†)dÏ†= (cid:89) (cid:0) eâˆ’U(T Ï„Ï†)(cid:1)|G jâˆ’1|âˆ’1 dÏ†.
Ï„âˆˆG
jâˆ’1
Wenowprovethat
(cid:90)
ZËœâ‰¤Z = eâˆ’U(Ï†)dÏ†, (86)
sothatwecanshowwith(85)that
(cid:90) (cid:90)
âˆ’ p(Ï†)logqËœ(Ï†)dÏ†â‰¤âˆ’ p(Ï†)q(Ï†)dÏ†,
whichprovesthetheoremresult(38).
Weprove(86)byiteratingontheHoÂ¨lderinequalitywhichprovesthat
ï£« ï£¶|G | ï£« ï£¶|G |âˆ’1
(cid:90) jâˆ’1 (cid:90) jâˆ’1 (cid:90)
ï£­ (cid:89) (cid:0) eâˆ’U(T Ï„Ï†)(cid:1)|G jâˆ’1|âˆ’1 dÏ†ï£¸ â‰¤ï£­ (cid:89) (cid:0) eâˆ’U(T Ï„Ï†)(cid:1)(|G jâˆ’1|âˆ’1)âˆ’1 dÏ†ï£¸ eâˆ’U(T Ï„1Ï†)dÏ†.
Ï„âˆˆG jâˆ’1 Ï„âˆˆG jâˆ’1âˆ’{Ï„ 1}
But(cid:82) eâˆ’U(T Ï„Ï†)dÏ†=Z soreapplying|G |âˆ’1timestheHoÂ¨lderinequalitytotheintegraltothepower|G |âˆ’1
jâˆ’1 jâˆ’1
provesthat(ZËœ)|G jâˆ’1| â‰¤(Z)|G jâˆ’1|andhenceZËœâ‰¤Z,whichfinishestheproof. â–¡
31HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
E.3 ProofofTheorem4.1
Atthecoarsestscale2J,Î¦ isdefinedin(47)byaconvolutionaloperatorwhosekerneliswrittenK andascalar
J J
potentialdefinedin(48). Onecanthusverifythat
Î¸ =(K /2,Î³ ) and Î¦ (Ï† )=(cid:0) Ï† âˆ—Ï†T, Î“(Ï† )(cid:1) . (87)
J J J J J J J J
ThepotentialÎ¦ thussatisfies(51)forj =J.
J
ToprovethattheÎ¦ defineahierarchicpotential,weshallprovethatforanyj â‰¥J,if
j
Î¦ (Ï† )=(cid:0) Ï† âˆ—Ï†T,Î“(Ï† âˆ—Ï• )(cid:1)
j j j j j â„“ Jâˆ’jâ‰¥â„“â‰¥0
andifÎ¨ isdefinedby(49)andhence
j
Î¨ (Ï† )=(cid:0) Ï†Â¯ Ï†Â¯T, Ï†Â¯ Ï†T, Î“(Ï† )(cid:1)
j jâˆ’1 j j j j jâˆ’1
thenAve (Î¦ ,Î¨ )isalinearfunctionofÎ¦ ,with
jâˆ’1 j j jâˆ’1
Î¦ (Ï† )=(cid:0) Ï† âˆ—Ï†T ,Î“(Ï† âˆ—Ï• )(cid:1) .
jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 â„“ Jâˆ’j+1â‰¥â„“â‰¥0
Let us first show that Ave (Î¨ ) is a linear function of Î¦ . We consider the first two terms of Î¨ . Since
jâˆ’1 j jâˆ’1 j
Ï†Â¯ =GÂ¯Ï† andÏ† =GÏ† ,itresultsthatÏ†Â¯ Ï†Â¯TandÏ†Â¯ Ï†TarelinearfunctionsofÏ† Ï†T . SinceÏ† Ï†T =
j jâˆ’1 j jâˆ’1 j j j j jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1
(Ï† (n)Ï† (nâ€²)) itresultsthat
jâˆ’1 jâˆ’1 n,nâ€²
Ave (Ï† Ï†T )=|G |âˆ’1(cid:16) (cid:88) Ï† (nâˆ’Ï„)Ï† (nâ€²âˆ’Ï„)(cid:17)
jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 n,nâ€²
Ï„âˆˆG
jâˆ’1
=|G |âˆ’1(cid:0) Ï† âˆ—Ï†T (nâ€²âˆ’n)(cid:1) .
jâˆ’1 jâˆ’1 jâˆ’1 n,nâ€²
It results that applying Ave to the first two terms of Î¨ is a linear function of Î¦ . For the third term of
jâˆ’1 jâˆ’1 jâˆ’1
Ave (Î¨ )wehave
jâˆ’1 j
Ave Î“(Ï† )=Î“(Ï† )=Î“(Ï† âˆ—Ï• ),
jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 0
becauseÏ• =Î´,whichalinearfunctionofthesecondtermofÎ¨ whichincludesthisterm. Itconcludestheproofthat
0 j
Ave (Î¨ )isalinearfunctionofÎ¦ .
jâˆ’1 j jâˆ’1
LetusnowprovethatAve (Î¦ )isalinearfunctionofÎ¦ . ForthefirstterminAve (Î¦ ),equation(64),which
jâˆ’1 j jâˆ’1 jâˆ’1 j
statesthatÏ† (n)=Ï† âˆ—g(2n),gives
j jâˆ’1
Ï† âˆ—Ï†T =(cid:16) (cid:88) Ï† (âˆ’Ï„)Ï† (nâˆ’Ï„)(cid:17)
j j j j
n
Ï„âˆˆG
j
(cid:16) (cid:88) (cid:17)
= (Ï† âˆ—g)(âˆ’2Ï„)(Ï† âˆ—g)(2nâˆ’2Ï„) .
jâˆ’1 jâˆ’1
n
Ï„âˆˆG
j
AveragingoverallthetranslationsonthegridG eliminatesthesubsamplingintheprevioussum,andgives
jâˆ’1
Ave (Ï† âˆ—Ï†T)= 1(cid:0) (Ï† âˆ—g)âˆ—(Ï†T âˆ—gT)(2n)(cid:1)
jâˆ’1 j j 4 jâˆ’1 jâˆ’1 n
= 1(cid:0) (gâˆ—gT)âˆ—(Ï† âˆ—Ï†T )(2n)(cid:1) ,
4 jâˆ’1 jâˆ’1 n
wheregT(n)=g(âˆ’n). Ave (Ï† âˆ—Ï†T)isthusalineartransformationofthefirsttermofÎ¦ (Ï† ).
jâˆ’1 j j jâˆ’1 jâˆ’1
TocomputethesecondtermsofAve (Î¦ ),weuse(67)whichshowsthat
jâˆ’1 j
Ï† âˆ—Ï• (n)=Ï† âˆ—Ï• (2n). (88)
j â„“ jâˆ’1 â„“+1
MoreoverÎ“computesasumonthegridG ofpointwisetransformationsÏ whichcommutewithtranslations. Itresults
j k
thattheaveragingofalltranslationsonthegridG gives
jâˆ’1
Ave (Î“(Ï† âˆ—Ï• ))=|G
|âˆ’1(cid:16) (cid:88)
Ï (Ï† âˆ—Ï•
(2nâˆ’Ï„))(cid:17)
jâˆ’1 j â„“ jâˆ’1 k jâˆ’1 â„“+1
k
Ï„âˆˆG ,nâˆˆG
jâˆ’1 j
1(cid:16) (cid:88) (cid:17)
= Ï (Ï† âˆ—Ï• (n)
4 k jâˆ’1 â„“+1 k
nâˆˆG
jâˆ’1
1
= Î“(Ï† âˆ—Ï• ).
4 jâˆ’1 â„“+1
32HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
ThisprovesthatthesecondtermsofAve (Î¦ )isalinearfunctionofthesecondtermofÎ¦ . Thisfinishesthe
jâˆ’1 j jâˆ’1
proofthattheÎ¦ defineastationaryhierarchicpotential.
j
ObservethatthescalarpotentialofeachinteractionenergyÎ¨ createsascalarpotentialateachscale,whichappears
j
in (51). If we approximate the free energies F by Î±TÎ¦ then Proposition 3.2 defines stationary energy models
j j j
U = Î¸TÎ¦ ateachscale2j. ThecouplingvectorÎ¸ iscalculatedfromÎ¸ and(Î¸Â¯ ,Î± )withtheoperatorQ . It
Î¸ j j jâˆ’1 j j j j
j
definesafinescalestationaryenergymodel
U (Ï†)=Î¸TÎ¦ (Ï†)=(K,Î³ )T (cid:0) Ï†âˆ—Ï†T,Î“(Ï†âˆ—Ï• )(cid:1) ,
Î¸ 0 0 j jâ‰¥J j Jâ‰¥jâ‰¥0
andhence
J
U (Ï†)= 1 Ï†TKÏ†+(cid:88) Î³TÎ“(Ï†âˆ—Ï† ),
Î¸ 2 j j
j=0
whichfinishesthetheoremproof.
E.4 ProofofTheorem5.1
ToverifythattheÎ¦ defineahierarchicpotentialweshallprovethatforanyj â‰¥J,if
j
Î¦ (Ï† )=(cid:0) R(Ï† )âˆ—R(Ï† )T,Î“(Ï† âˆ—Ï• )(cid:1) with R(Ï† )=(Ï† ,|Ï†âˆ—ÏˆËœ (2jn)|q) ,
j j j j j â„“ Jâˆ’jâ‰¥â„“â‰¥0 j j jâ€²,kâ€² jâ€²>j,kâ€²
and
Î¨ =(cid:0) S ST,Î“(cid:1) with S (Ï† )=(cid:16) Ï†âˆ—ÏˆËœ (2jâˆ’1n), |Ï†âˆ—ÏˆËœ |qâˆ—Ïˆ (2jâˆ’1n)(cid:17) ,
j j jâ€² J+1â‰¥jâ€²â‰¥j jâ€² jâˆ’1 jâ€²,kâ€² jâ€²,kâ€² â„“,k â„“â‰¥jâ€²,k,kâ€²â‰¤Q,n
thenAve (Î¦ )andAve (Î¨ )arelinearfunctionsofÎ¦ ,for
jâˆ’1 j jâˆ’1 j jâˆ’1
Î¦ (Ï† )=(cid:0) R(Ï† )âˆ—R(Ï† )T,Î“(Ï† âˆ—Ï• )(cid:1) .
jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 â„“ Jâˆ’j+1â‰¥â„“â‰¥0
FromtheproofofTheorem4.1,theÎ“-termsofAve (Î¦ )andAve (Î¨ )arelinearfunctionsoftheÎ“-termsof
jâˆ’1 j jâˆ’1 j
Î¦ . WeconcentratethefirsttermsinAve (Î¨ )andAve (Î¦ ).
jâˆ’1 jâˆ’1 j jâˆ’1 j
ForAve (Î¨ ),considerAve (S ST). Foranyjâ€² â‰¥j,thescatteringvectorS isalinearfunctionof
jâˆ’1 j jâˆ’1 j jâ€² jâ€²
R(Ï† ) = (Ï† ,|Ï†âˆ—ÏˆËœ (2jâˆ’1n)|q) . NonlineartermsinSâ€² areincludedinR(Ï† ),and,from(71),
jâˆ’1 jâˆ’1 jâ€²,kâ€² jâ€²>0,kâ€²â‰¤Q j jâˆ’1
Ï†âˆ—ÏˆËœ (2jâˆ’1n),isalinearfunctionofÏ† .
jâ€²,kâ€² jâˆ’1
ItresultsthatthetermsAve (S ST)arelinearfunctionsofAve (R RT ). Inthesamewaythatweprovedfor
jâˆ’1 j jâ€² jâˆ’1 jâˆ’1 jâˆ’1
Theorem4.1thatAve (Ï† Ï†T )isalinearfunctionofÏ† âˆ—Ï†T ,weprovethatAve (R(Ï† )R(Ï† )T)
jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1 jâˆ’1
isalinearfunctionofR(Ï† )âˆ—R(Ï† )T. ThetermAve (S ST)isthereforealinearfunctionofthefirsttermof
jâˆ’1 jâˆ’1 jâˆ’1 j jâ€²
Î¦ .
jâˆ’1
Let us now prove that the first term of Ave (Î¦ ), and hence Ave (R(Ï† )âˆ—R(Ï† )T), is a linear function of
jâˆ’1 j jâˆ’1 j j
R(Ï† )âˆ—R(Ï† )T.
jâˆ’1 jâˆ’1
R(Ï† )isdeducedfromR(Ï† )using,thefilterGonÏ† ,andbysubsampling(ordiscarding)thenonlinearterms.
j jâˆ’1 jâˆ’1
Ave (R(Ï† )R(Ï† )T), is a linear function of Ave (R(Ï† )R(Ï† )T), which is itself a linear transform of
jâˆ’1 j j jâˆ’1 jâˆ’1 jâˆ’1
R(Ï† )âˆ—R(Ï† )T.
jâˆ’1 jâˆ’1
ThisfinishestheproofthattheÎ¦ defineastationaryhierarchicpotential.
j
Proposition3.2impliesthatapproximatingF byÎ±TÎ¦ yieldsacouplingflowequation(41). ItcomputesÎ¸ fromÎ¸
j j j jâˆ’1 j
and(Î¸Â¯ ,Î± )withthelinearoperatorQ . Itdefines
j j j
U (Ï†)=Î¸TÎ¦ (Ï†)=Î¸T(cid:0) R(Ï†)âˆ—R(Ï†)T,Î“(Ï†âˆ—Ï• )(cid:1) .
Î¸ 0 0 0 â„“ Jâ‰¥jâ‰¥0
Since R(Ï†) = (Ï†,|WÏ†|q), for Î¸ = (K,L,M,Î³ ) where (K,L,M) are convolutional operators, this can be
0 j jâ‰¥J
rewritten
J
U (Ï†)= 1 Ï†TKÏ†+Ï†TL(|WÏ†|q)+ 1 (|WÏ†|q)TM(|WÏ†|q)+(cid:88) Î³TÎ“(Ï†âˆ—Ï• ),
Î¸ 2 2 j j
j=0
whichproves(59).
33HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
F EstimationAlgorithms
F.1 NormalizedAutocorrelationRelaxationTimeofaLangevinDiffusion
ThisappendixspecifiesthecalculationofnormalizedrelaxationtimeofLangevindiffusionsinhierarchicmodels.
Conditional auto-correlation relaxation time As in [MOBM22, GLBM23], we compute the auto-correlation
relaxationtime(8)tosampletheconditionalprobabilitiesofahierarchicmodelwithanunadjustedLangevindiffusion.
ThisconditionalprobabilityhasanenergyUÂ¯ Î¸Â¯ . TheunadjustedLangevindiffusionofÏ†Â¯ j isnumericallycomputed
j
withanEuler-MaruyamadiscretizationwithatimeintervalÎ´ . Thistimeintervalmustbesmallerthantheinverseof
j
theLipschitzconstantofâˆ‡ Ï†Â¯ jUÂ¯ Î¸Â¯
j
[VW22]. ThisLipschitzconstantisevaluatedbyestimatingthesupremumofthe
eigenvaluesoftheHessianâˆ‡2 Ï†Â¯ jUÂ¯ Î¸Â¯ j(Ï† jâˆ’1)overtypicalrealizationsÏ† jâˆ’1. WesetÎ´ j tobeafixedfractionoftheinverse
ofthissupremum.
LetÏ†Â¯ bethewaveletcoefficientsofobtainedbytheLangevindiffusion,afterÎ±stepsatintervalsÎ´ ,thuscorresponding
j,Î± j
toatimet=Î±Î´ . Anormalizedconditionalauto-correlationatÎ±is
j
E (cid:0)(cid:0) Ï†Â¯ âˆ’E (cid:0) Ï†Â¯ (cid:1)(cid:1)(cid:0) Ï†Â¯ âˆ’E (cid:0) Ï†Â¯ (cid:1)(cid:1)(cid:1)
AÂ¯ (Î±|Ï† )= pÂ¯ Î¸Â¯ j(Â·|Ï† j) j,Î± pÂ¯ Î¸Â¯ j(Â·|Ï† j) j j,0 pÂ¯ Î¸Â¯ j(Â·|Ï† j) j , (89)
j j E (cid:0)(cid:0) Ï†Â¯ âˆ’E (cid:0) Ï†Â¯ (cid:1)(cid:1)2(cid:1)
pÂ¯ Î¸Â¯ j(Â·|Ï† j) j pÂ¯ Î¸Â¯ j(Â·|Ï† j) j
Thisauto-correlationisaveragedoverthedistributionofÏ†
j
A (Î±)=E (cid:0) AÂ¯ (Î±|Ï† )(cid:1) . (90)
j p j j
j
TheexponentialdecayA (Î±)ismeasuredbythenormalizedautocorrelationrelaxationtimeÏ„Â¯ ,
j j
(cid:18) (cid:19)
Î±
A (Î±)â‰ˆA (0)exp âˆ’ . (91)
j j Ï„Â¯
j
ThisnormalizedrelaxationtimeisthenumberofLangeviniterationsneededtoreachafixedprecision.
CommentsonMALA TherejectionstepoftheMALAalgorithmmodifiesthevalueoftherelaxationtime. Whereas
Langevin and MCMC algorithm have hierarchical autocorrelation relaxation times which do not depend upon the
systemsized,theMALAalgorithmproducesahierarchicalrelaxationtimewhichhasaslowgrowthasafunctionofd,
highlightedin[GLBM23]. Indeed,MALAreliesonaglobalacceptancestep,whichdoesnottakeadvantageofthe
localityofinteractions,asopposedtoanMCMCsamplingoranunadjustedLangevindiffusion[MOBM22,MS06].
Forexample,MALAhasamixingtimethatgrowswiththedimensiond,forstronglylog-concavedistributionshavinga
log-Sobolevconstantwhichdoesnotdependond[CEL+21,LZT22,WSC22],whereasitisnotthecaseforanMCMC
samplingoraLangevinunadjusteddiffusions. However,MALAisthefastestalgorithmtocomputethehierarchic
samplingfortheimagesizesconsideredinthispaper[GLBM23]. Itisusedforthegenerationresultsbutnottoevaluate
therelaxationtimeinordertoavoidissuesrelatedtotherejection-approvalstep.
F.2 EstimationoftheBi-spectrum
Wedescribethecalculationofthebi-spectruminFigure12. Thebi-spectrumisdefinedastheexpectedvalueFourier
transform of the 3 points correlation function. We use a regularized estimation of these statistics for rotationally
invariantprobabilitydistributions,describedin[CMA+23]. Itperformsafrequencyaveraginginthinfrequencyannuli,
evenlyspacedinfrequencylog-scale,thatwewriteA .FortheFigure12(e),forimagesofsized=1282,thefrequency
k
planeisdecomposedinto9frequencyannuliA ,whichselectfrequenciesÏ‰suchthat2âˆ’7k/9Ï€ â‰¤|Ï‰|â‰¤2âˆ’7(k+1)/9Ï€.
k
Weconsiderprobabilitydistributionswhichareinvarianttorotations. Thepowerspectrumisthusestimatedwithan
averageoverfrequenciesÏ‰ineachannulusA andovermultiplesamplesÏ†(i):
k
P(k)=Ave |Ï†Ë†(i)(Ï‰)|2. (92)
i,Ï‰âˆˆA
k
For(k ,k ,k ), aregularizednormalizedbi-spectrumisdefinedasasumoverall(Ï‰ ,Ï‰ ,Ï‰ )from3frequencies
1 2 3 1 2 3
Ï‰ âˆˆ A
whichsumtozero(cid:80)3
Ï‰ = 0,bymultiplyingtheFouriertransformsatthesefrequenciesofmultiple
j k j j=1 j
samplesÏ†(i):
(cid:16)Ï†Ë†(Ï‰(i))Ï†Ë†(Ï‰(i))Ï†Ë†(i)(Ï‰ )(cid:17)
B(k ,k ,k )=Ave 1 2 3 . (93)
1 2 3 i,Ï‰ jâˆˆA kj,(cid:80)3 j=1Ï‰ j=0 (cid:112) P(k i)P(k 2)P(k 3)
34HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
References
[ABBL06] AlexeiAndreanov,GiulioBiroli,Jean-PhilippeBouchaud,andAlexandreLefevre. Fieldtheoriesandexactstochastic
equationsforinteractingparticlesystems. PhysicalReviewE,74(3):030101,2006.
[ABT18] RichardCAster,BrianBorchers,andCliffordHThurber. Parameterestimationandinverseproblems. Elsevier,2018.
[AGV13] PatriceAbry,PaoloGoncalves,andJacquesLeÂ´vyVeÂ´hel. Scaling,fractalsandwavelets. JohnWiley&Sons,2013.
[Bat99] GuyBattle. Waveletsandrenormalization,volume10. WorldScientific,1999.
[BB19] RolandBauerschmidtandThierryBodineau. Averysimpleproofofthelsiforhightemperaturespinsystems.
JournalofFunctionalAnalysis,276(8):2582â€“2588,2019.
[BBD23] RolandBauerschmidt,ThierryBodineau,andBenoitDagallier. Stochasticdynamicsandthepolchinskiequation:an
introduction. arXivpreprintarXiv:2307.07619,2023.
[BD22] RolandBauerschmidtandBenoitDagallier. Log-sobolevinequalityfornearcriticalisingmodels. arXivpreprint
arXiv:2202.02301,2022.
[BDSG+15] LorenzoBertini,AlbertoDeSole,DavideGabrielli,GiovanniJona-Lasinio,andClaudioLandim. Macroscopic
fluctuationtheory. ReviewsofModernPhysics,87(2):593,2015.
[BGL+14] DominiqueBakry,IvanGentil,MichelLedoux,etal. AnalysisandgeometryofMarkovdiffusionoperators,volume
103. Springer,2014.
[Bis06] ChristopherBishop. Patternrecognitionandmachinelearning. Springergoogleschola,2:5â€“43,2006.
[BJPV98] TomasBohr,MogensH.Jensen,GiovanniPaladin,andAngeloVulpiani.DynamicalSystemsApproachtoTurbulence.
CambridgeNonlinearScienceSeries.CambridgeUniversityPress,1998.
[CCL+20] LokHangChan,KunChen,ChunxueLi,ChungWangWong,andChunYipYau. Onhigher-ordermomentand
cumulantestimation. JournalofStatisticalComputationandSimulation,90(4):747â€“771,2020.
[CE22] YuansiChenandRonenEldan. Localizationschemes:Aframeworkforprovingmixingboundsformarkovchains.
In2022IEEE63rdAnnualSymposiumonFoundationsofComputerScience(FOCS),pages110â€“122.IEEE,2022.
[CEL+21] SinhoChewi,MuratA.Erdogdu,MufanBillLi,RuoqiShen,andMatthewZhang. Analysisoflangevinmontecarlo
frompoincareÂ´tolog-sobolev,2021.
[CMA+23] SihaoCheng,RudyMorel,ErwanAllys,BriceMeÂ´nard,andSteÂ´phaneMallat. Scatteringspectramodelsforphysics,
2023.
[CMW92] RonaldRCoifman,YvesMeyer,andVictorWickerhauser. Waveletanalysisandsignalprocessing. InInWavelets
andtheirapplications.Citeseer,1992.
[CR23] JordanCotlerandSemonRezchikov. Renormalizingdiffusionmodels. arXivpreprintarXiv:2308.12355,2023.
[Dau92] IngridDaubechies. TenLecturesonWavelets. SocietyforIndustrialandAppliedMathematics,1992.
[Del12] BertrandDelamotte. AnIntroductiontotheNonperturbativeRenormalizationGroup,page49â€“132. SpringerBerlin
Heidelberg,2012.
[DLS02] BernardDerrida,JLLebowitz,andERSpeer. Largedeviationofthedensityprofileinthesteadystateoftheopen
symmetricsimpleexclusionprocess. Journalofstatisticalphysics,107(3-4):599â€“634,2002.
[GCDBM22] FlorentinGuth,SimonCoste,ValentinDeBortoli,andSteÂ´phaneMallat. Waveletscore-basedgenerativemodeling.
AdvancesinNeuralInformationProcessingSystems,2022.
[GG84] StuartGemanandDonaldGeman. Stochasticrelaxation,gibbsdistributions,andthebayesianrestorationofimages.
IEEETransactionsonpatternanalysisandmachineintelligence,(6):721â€“741,1984.
[GGR97] AndrewGelman,WalterRGilks,andGarethORoberts. Weakconvergenceandoptimalscalingofrandomwalk
metropolisalgorithms. Theannalsofappliedprobability,7(1):110â€“120,1997.
[GLBM23] FlorentinGuth,EtienneLempereur,JoanBruna,andSteÂ´phaneMallat. Conditionallystronglylog-concavegenerative
models. InternationalConferenceonMachineLearning,2023.
[GM94] UlfGrenanderandMichaelIMiller. Representationsofknowledgeincomplexsystems. JournaloftheRoyal
StatisticalSociety:SeriesB(Methodological),56(4):549â€“581,1994.
[GNC10] MatanGavish,BoazNadler,andRonaldRCoifman. Multiscalewaveletsontrees,graphsandhighdimensionaldata:
theoryandapplicationstosemisupervisedlearning. InICML,volume10,pages367â€“74,2010.
[Gro75] LeonardGross. Logarithmicsobolevinequalities. AmericanJournalofMathematics,97(4):1061â€“1083,1975.
[GRVE22] MarylouGabrieÂ´,GrantMRotskoff,andEricVanden-Eijnden. Adaptivemontecarloaugmentedwithnormalizing
flows. ProceedingsoftheNationalAcademyofSciences,119(10):e2109420119,2022.
[HD05] AapoHyvaÂ¨rinenandPeterDayan. Estimationofnon-normalizedstatisticalmodelsbyscorematching. Journalof
MachineLearningResearch,6(4),2005.
35HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
[HK22] TruongSonHyandRisiKondor. Multiresolutionmatrixfactorizationandwaveletnetworksongraphs. InICML
20222ndAIforScienceWorkshop,2022.
[HVG11] DavidKHammond, PierreVandergheynst, andReÂ´miGribonval. Waveletsongraphsviaspectralgraphtheory.
AppliedandComputationalHarmonicAnalysis,30(2):129â€“150,2011.
[Jaf92] StephaneJaffard. Waveletmethodsforfastresolutionofellipticproblems. SIAMJournalonNumericalAnalysis,
29(4):965â€“986,1992.
[Jaf04] StephaneJaffard. Wavelettechniquesinmultifractalanalysis. InProceedingsofsymposiainpuremathematics,
volume72,pages91â€“152,2004.
[Jay57] EdwinTJaynes. Informationtheoryandstatisticalmechanics. Physicalreview,106(4):620,1957.
[Kad66] LeoPKadanoff. Scalinglawsforisingmodelsneartc. PhysicsPhysiqueFizika,2(6):263,1966.
[KHR22] FredericKoehler,AlexanderHeckett,andAndrejRisteski. Statisticalefficiencyofscorematching:Theviewfrom
isoperimetry. arXivpreprintarXiv:2210.00726,2022.
[KHY76] LeoPKadanoff,AnthonyHoughton,andMehmetCYalabik. Variationalapproximationsforrenormalizationgroup
transformations. JournalofStatisticalPhysics,14(2):171â€“203,1976.
[KMR16] J.KaupuzË‡s,R.V.N.Melnik,andJ.RimsË‡aÂ¯ns. Correctionstofinite-sizescalingintheÏ†4modelonsquarelattices.
InternationalJournalofModernPhysicsC,27(09):1650108,2016.
[kol41] Akolmogorov. Localstructureofturbulenceinanincompressiblefluidatveryhighreynoldsnumbers. CRAd.Sei.
UUSR,30:305,1941.
[Kol42] ANKolmogorov. Equationsofturbulentmotionofanincompressiblefluid,izv.acad.sci.,ussr. Physics,6(1):2,1942.
[Kra67] RobertHKraichnan. Inertialrangesintwo-dimensionalturbulence. Physicsoffluids,10(7):1417,1967.
[KS06] JariKaipioandErkkiSomersalo. Statisticalandcomputationalinverseproblems,volume160. SpringerScience&
BusinessMedia,2006.
[Led00] MichelLedoux. Thegeometryofmarkovdiffusiongenerators. InAnnalesdelaFaculteÂ´dessciencesdeToulouse:
MatheÂ´matiques,volume9,pages305â€“366,2000.
[LL13] LevDavidovichLandauandEvgeniiMikhailovichLifshitz. StatisticalPhysics:Volume5,volume5. Elsevier,2013.
[LS16] TonyLelie`vreandGabrielStoltz. Partialdifferentialequationsandstochasticmethodsinmoleculardynamics. Acta
Numerica,25:681â€“880,2016.
[LZT22] RuilinLi,HongyuanZha,andMoleiTao. Sqrt(d)dimensiondependenceoflangevinmontecarlo,2022.
[Mal89a] SteÂ´phaneMallat.Atheoryformultiresolutionsignaldecomposition:Thewaveletrepresentation.IEEETrans.Pattern
Anal.Mach.Intell.,11:674â€“693,1989.
[Mal89b] StephaneGMallat.Atheoryformultiresolutionsignaldecomposition:thewaveletrepresentation. IEEEtransactions
onpatternanalysisandmachineintelligence,11(7):674â€“693,1989.
[Mal09] SteÂ´phaneMallat. Awavelettourofsignalprocessing. AcademicPress,thirdeditionedition,2009.
[Mal12] S.Mallat. Groupinvariantscattering. CommunicationsonPureandAppliedMathematics,65(10):1331â€“1398,2012.
[Mey93] YvesMeyer. WaveletsandOperators, volume1ofCambridgeStudiesinAdvancedMathematics. Cambridge
UniversityPress,1993.
[MOBM22] TanguyMarchand,MisakiOzawa,GiulioBiroli,andSteÂ´phaneMallat. Waveletconditionalrenormalizationgroup.
arXivpreprintarXiv:2207.04941,2022.
[MRL+23] RudyMorel,GasparRochette,RobertoLeonarduzzi,Jean-PhilippeBouchaud,andSteÂ´phaneMallat. Scaledependen-
ciesandself-similarmodelswithwaveletscatteringspectra. AvailableatSSRN4516767,2023.
[MS06] AndreaMontanariandGuilhemSemerjian. Rigorousinequalitiesbetweenlengthandtimescalesinglassysystems.
Journalofstatisticalphysics,125:23â€“54,2006.
[MZR20] SteÂ´phaneMallat,SixinZhang,andGasparRochette. Phaseharmoniccorrelationsandconvolutionalneuralnetworks.
InformationandInference:AJournaloftheIMA,9(3):721â€“747,2020.
[Pod96] RudolfPodgornik. Principlesofcondensedmatterphysics.p.m.chaikinandt.c.lubensky,cambridgeuniversity
press,cambridge,england,1995. JournalofStatisticalPhysics,83:1263â€“1265,061996.
[Pol84] JosephPolchinski. Renormalizationandeffectivelagrangians. NuclearPhysicsB,231(2):269â€“295,1984.
[PS00] JavierPortillaandEeroPSimoncelli. Aparametrictexturemodelbasedonjointstatisticsofcomplexwavelet
coefficients. Internationaljournalofcomputervision,40(1):49â€“70,2000.
[Ram20] PierreRamond. Fieldtheory:amodernprimer. Routledge,2020.
[RBL+22] RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBjoÂ¨rnOmmer. High-resolutionimage
synthesiswithlatentdiffusionmodels. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPattern
Recognition,pages10684â€“10695,2022.
36HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
[RFB15] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image
segmentation. InMedicalimagecomputingandcomputer-assistedinterventionâ€“MICCAI2015:18thinternational
conference,Munich,Germany,October5-9,2015,proceedings,partIII18,pages234â€“241.Springer,2015.
[RR98] GarethORobertsandJeffreySRosenthal.Optimalscalingofdiscreteapproximationstolangevindiffusions.Journal
oftheRoyalStatisticalSociety:SeriesB(StatisticalMethodology),60(1):255â€“268,1998.
[Set21] JamesPSethna. StatisticalMechanics:Entropy,OrderParameters,andComplexity,volume14. OxfordUniversity
Press,USA,2021.
[Sim62] HerbertASimon.Thearchitectureofcomplexity.ProceedingsoftheAmericanphilosophicalsociety,106(6):467â€“482,
1962.
[Sok91] AlanD.Sokal. Howtobeatcriticalslowingdown:1990update. Nucl.Phys.BProc.Suppl.,20:55â€“67,1991.
[Sok97] AlanSokal.Montecarlomethodsinstatisticalmechanics:foundationsandnewalgorithms.InFunctionalintegration:
Basicsandapplications,pages131â€“192.Springer,1997.
[SSK+21] YangSong,JaschaSohl-Dickstein,DiederikP.Kingma,AbhishekKumar,StefanoErmon,andBenPoole. Score-
based generative modeling through stochastic differential equations. In International Conference on Learning
Representations,2021.
[SZFA06] KaiSchneider,JoÂ¨rgZiuber,MarieFarge,andAlexandreAzzalini. Coherentvortexextractionandsimulationof2d
isotropicturbulence. JournalofTurbulence,(7):N44,2006.
[TaÂ¨u14] UweCTaÂ¨uber. Criticaldynamics: afieldtheoryapproachtoequilibriumandnon-equilibriumscalingbehavior.
CambridgeUniversityPress,2014.
[Tur18] ThomasTurk. Matrixorganisation. Springer,2018.
[VNHM+20] FranciscoVillaescusa-Navarro,ChangHoonHahn,ElenaMassara,ArkaBanerjee,AnaMariaDelgado,DoogeshKodi
Ramanah,TomCharnock,ElenaGiusarma,YinLi,ErwanAllys,AntoineBrochard,CoraUhlemann,Chi-Ting
Chiang,SiyuHe,AlicePisani,AndrejObuljen,YuFeng,EmanueleCastorina,GabriellaContardo,ChristinaD.
Kreisch,AndrinaNicola,JustinAlsing,RomanScoccimarro,LiciaVerde,MatteoViel,ShirleyHo,StephaneMallat,
BenjaminWandelt,andDavidN.Spergel. Thequijotesimulations. TheAstrophysicalJournalSupplementSeries,
250(1):2,August2020.
[VW22] SantoshS.VempalaandAndreWibisono. Rapidconvergenceoftheunadjustedlangevinalgorithm:Isoperimetry
suffices,2022.
[WF72] KennethGWilsonandMichaelEFisher. Criticalexponentsin3.99dimensions. PhysicalReviewLetters,28(4):240,
1972.
[Wil71] KennethGWilson. Renormalizationgroupandcriticalphenomena.ii.phase-spacecellanalysisofcriticalbehavior.
PhysicalReviewB,4(9):3184,1971.
[WSC22] KeruWu,ScottSchmidler,andYuansiChen. Minimaxmixingtimeofthemetropolis-adjustedlangevinalgorithmfor
log-concavesampling,2022.
[ZJ21] JeanZinn-Justin. QuantumFieldTheoryandCriticalPhenomena:FifthEdition. OxfordUniversityPress,042021.
[ZM21] Sixin Zhang and SteÂ´phane Mallat. Maximum entropy models from phase harmonic covariances. Applied and
ComputationalHarmonicAnalysis,53:199â€“230,2021.
37