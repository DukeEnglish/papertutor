Improved Scene Landmark Detection for Camera Localization
TienDo* SudiptaN.Sinha
Tesla Microsoft
Abstract Learning-based localization methods [6, 7, 15, 21] can
alleviateboththestorageandprivacyissues. However,de-
Camera localization methods based on retrieval, local spitemuchprogressonlearning-basedlocalization,mostof
feature matching, and 3D structure-based pose estimation the methods are still not competitive with structure-based
areaccuratebutrequirehighstorage,areslow,andarenot methods [26, 27]. Recently, Do et al. [11] proposed SLD,
privacy-preserving. Amethodbasedonscenelandmarkde- a localization framework that involves training CNNs for
tection(SLD)wasrecentlyproposedtoaddresstheselimi- detecting pre-selected, scene landmarks (3D points) and
tations. Itinvolvestrainingaconvolutionalneuralnetwork regressing 3D bearing vectors (NBE) for the landmarks.
(CNN)todetectafewpredetermined,salient,scene-specific The 2D detections and 3D bearing predictions are jointly
3D points or landmarks and computing camera pose from used (SLD+NBE) to compute camera pose. Even though
theassociated2Dâ€“3Dcorrespondences.AlthoughSLDout- SLD+NBEoutperformslearning-basedmethods[6,15]on
performed existing learning-based approaches, it was no- the challenging INDOOR-6 dataset, it is less accurate than
tably less accurate than 3D structure-based methods. In hloc[26,27]byanotablemargin. Itisalsouncleartowhat
this paper, we show that the accuracy gap was due to in- extentthemethodcanhandlealargenumberoflandmarks.
sufficient model capacity and noisy labels during train-
In this paper, we present important insights into what
ing. To mitigate the capacity issue, we propose to split
typically hurts SLDâ€™s accuracy and scalability. Our first
the landmarks into subgroups and train a separate net-
finding is that insufficient model capacity is a key cause
work for each subgroup. To generate better training la-
foradropinperformancewhenSLDistrainedforalarger
bels, we propose using dense reconstructions to estimate
setoflandmarks. Wealsofindthattheautomaticstructure
visibility of scene landmarks. Finally, we present a com-
from motion (SfM) processing phase which generates la-
pact architecture to improve memory efficiency. Accuracy
beled training patches for landmarks from training images
wise,ourapproachisonparwithstateoftheartstructure-
can produce erroneous training labels. Such outliers can
based methods on the INDOOR-6 dataset but runs sig-
sometimesaffecttheaccuracyofmodelstrainedonthedata.
nificantly faster and uses less storage. Code and mod-
Toaddressthecapacityissue,weproposetopartitionthe
els can be found at https://github.com/microsoft/
set of scene landmarks into mutually exclusive subgroups,
SceneLandmarkLocalization.
and train an ensemble of networks, where each network is
trained on a different subgroup. Using an ensemble im-
1.Introduction provesaccuracyforsceneswherealargernumberofland-
marks are present. To reduce the amount of erroneous la-
In this paper, we study the task of estimating the 6-dof belsinthetrainingset,weproposeusingadensescenere-
camera pose with respect to a reconstructed 3D model constructiontorecovermoreaccuratevisibilityestimatesof
of a scene from a single image. This is an important the scene landmarks in the training images, especially un-
task in robotics and augmented reality applications. The der strong lighting changes. We show that better training
most common approach for solving the task is structure- labelsleadstomoreaccuratelandmarkdetections. Wealso
based[26,27,29,30],wheretypically,thelocal2Dimage proposeSLDâˆ—,avariationoftheSLDarchitecturethatim-
features are matched to 3D points in a scene model. Ge- provesmemoryefficiency,andexploreusingoutputpredic-
ometric constraints derived from the 2Dâ€“3D matches are tionscoresasaconfidencemeasureduringposeestimation.
thenusedtocomputethecamerapose. Thesemethodscan
Incorporatingalltheproposedideasleadstoadramatic
be quite accurate but the need to persistently store a lot of
improvement in pose estimation accuracy, making SLDâˆ—
features and 3D points raises privacy issues [23] and also
competitive with hloc on the INDOOR-6 dataset. At the
makesthemlesssuitableforresource-constrainedsettings.
sametime,itisalsomorethan40Ã—fasterthanhlocduring
*workdonewhileTienDowasaffiliatedwithMicrosoft. localization and 20Ã— more storage efficient. Furthermore,
4202
naJ
13
]VC.sc[
1v38081.1042:viXraPreprocessing Phase: Training Phase: Localization Phase:
Query Image
SfM 3D Points Landmark Scene Landmarks Train SLD
+ 2D Obs. Selection (3D points) model SLD (CNN) 2D Landmark Detections
params
Camera Poses Scene Landmark
Visibility Scene Landmarks Pose Camera
Images (3D points) Estimation Pose
Figure1. Keyelementsofthescenelandmarkdetection-basedlocalizationapproach[11]. Thefigureshowsasinglemodel(SLD)for
brevity,butDoetal.[11]alsoproposedpredictinglandmarkbearingsusinganadditionalmodel(NBE).Thisisdiscussedinthetext.
SLDâˆ—is20â€“30%morememoryefficientthanSLD. wasextendedforimprovedefficiencyduringinference[17],
removing the need for RGBD ground truth during train-
2.RelatedWork ing [4], and improving the accuracy and robustness of the
underlying method [6]. Other ideas have been explored,
Structure-based Localization. Classical structure-based such as, the use of ensembles to improve scalability [5],
approaches use pre-computed 3D scene point clouds to designofhierarchicalscenerepresentations[18]andscene
compute camera pose by combining efficient visual re- agnostic approaches[45], and ideas to make the models
trieval [1, 22, 30, 38, 40], feature matching [10, 19, 25, amenabletocontinualupdates[42]andfastertraining[8].
27, 29, 39], and geometric pose estimation[14]. hloc Finally,wereviewmethodsforprivacy-preservinglocal-
[26] is such a method with state-of-the-art performance ization,andstorageefficiency. Specialeetal[35]explored
on INDOOR-6 that uses learning for more accurate feature newgeometricsceneandqueryrepresentations[35,36]and
matching[10,20,25,27]. Whilecorrespondencesandpose proposed pose estimation techniques for those representa-
is usually estimated independently, jointly refining deep tions. GoMatch [47] is a storage efficient method for geo-
multiscalefeaturesandcameraposehasbeenshowntoim- metric matching of 2D keypoints and 3D points that does
prove accuracy [28]. Alternatively, retrieval-based meth- notrequirelocaldescriptors. SegLoc[21]achievesstorage
ods[1,38,39]canestimatethecameraposebyinterpolat- efficiencybyleveragingsemanticsegmentation-basedmap
ing poses of retrieved database images[40]. Efficient and and query representations. Approaches leveraging objects
scalable alternatives for large-scale location classification ofinterestsinthescene[43]havealsobeenstudied.
andplacerecognitionhavealsobeenstudied[3,12,44].
Learning-basedLocalization. Learning-basedtechniques 3.ProposedMethodology
do not require storing 3D scene models. A popular ap-
WenowpresentabriefreviewofSLDbeforedescribingour
proach is to train models to regress the camera pose di-
proposedideasforimprovements,inthefollowingsections.
rectlyfromthequeryimage, whichiscalledabsolutepose
regression (APR). PoseNet [15] first proposed end-to-end
3.1.Background: SceneLandmarkDetection
trainable CNN architectures, which have been extended
for leveraging attention mechanisms [41] and to use trans- Do et al. [11] proposed a localization approach where
formerarchitectures[33]. However, APRmethodsrelyon giventheSfMreconstructionofthemappingimages,afew
training sets with homogeneous camera pose distributions. salient, scene-specific3Dpointsarefirstselectedfromthe
Whentheposedistributionishighlyheterogeneous,perfor- SfMpointcloud. Then,twoCNNs(SLD,NBE)aretrained
mancecansufferonsuchdatasets[31],aswasreportedon usingthemappingimagesandtheirassociatedposes.While
INDOOR-6 in [11]. Unlike APR approaches, relative pose SLD detects the landmarks visible in images, NBE re-
regression(RPR)approachespredicttherelativeposewith gresses 3D bearing vectors for all the landmarks in the
respecttostoreddatabaseimages[2,16].Theyusuallygen- scene. Finally, the 2Dâ€“3D landmark constraints are used
eralizebetterbuthavehigherstoragecosts. torecoverthecamerapose. Figure1providesanoverview.
Scene Coordinate Regression. In contrast to APR and LandmarkSelection. 3Dscenepointswithdiscriminative
RPR methods, scene coordinate regression (SCR) [34] ap- appearancethatareassociatedwithpermanentscenestruc-
proaches involve training model that predict dense 3D co- tures can serve as good scene landmarks. Do et al. [11]
ordinatesforpointsinthequeryimageandcomputingpose proposed a greedy method to select landmarks, given SfM
from the dense 2Dâ€“3D correspondences. DSAC[7] was camera poses, 3D points and the associated 2D image ob-
amongst the earliest works to propose an end-to-end dif- servations. Theirmethodheuristicallyselectsgroupsof3D
ferentiableSCRarchitecture. Subsequently,theframework pointsthatarewelldistributedwithinthescene. WeusetheSLD ð‘Š 4 Xð» 4 X 128 ð‘Š 2 Xð» 2
ð‘Š X ð» ð‘Š 4 Xð» 4 X 512 ð‘Š 4 Xð» 4 X 512 .
R 1R b8aee css kN bNe ot ne et- DD CCiill ooaa nnttee vvdd
C 1
C
ox
n
1
v
HL eo aw tm-r ae ps
s
TConv
..
L
Input Image
Per-landmark Heatmaps
Feature map C Concatenation TConv Transposed Conv
SLD* ð‘Š 8 Xð» 8 X 80
ð‘Š
8
Xð»
8
ð‘Š X ð» ð‘Š 8 Xð» 8 X 320 ð‘Š 8 Xð» 8 X 320 ..
REffeicsieNnteNte-t DDiillaatteedd .
1ba8ckbone CCoonnvv C 1
C
ox
n
1
v L
Input Image
Per-landmark Heatmaps
Figure2.[Top]TheoriginalSLDarchitecture [11].[Bottom]AnillustrationoftheproposedSLDâˆ—architecture(seetextfordetails).
same method, but experiment with up to 1500 landmarks, given (R, t) and (RË†, Ë†t), the estimated and ground truth
incontrasttotheuseof200â€“400pointsinpriorwork[11]. posesrespectively. Thefinalmetricisrecallat5cm/5â—¦,the
fractionoftestimageswhereâˆ†Râ‰¤5â—¦andâˆ†tâ‰¤5cm.
Model. TheSLDarchitectureisfullyconvolutionalandin-
spiredbyexistingneuralarchitecturesforkeypointpredic-
3.2.SLDâˆ— Architecture
tioninimagesusingheatmaps. Doetal.[11]implemented
SLDusingbothResNet-18[13]andEfficientNet[37]back-
In this section, we introduce SLDâˆ—, a more compact and
bones. The features from the backbone network are then
memoryefficientarchitecture,andanimprovedposesolver.
passed into a dilated convolution layer [46] followed by a
Next,wehighlightthefourkeydifferenceswithSLD+NBE.
1Ã—1convolutionlayertoproducelow-resolutionheatmaps.
Figure2comparestheSLDandSLDâˆ—architectures.
Finally, the heatmaps are upsampled using a transposed
convolutionlayer. Thearchitectureisillustratedintheup- NBE not used. Do et al. [11] proposed using NBE to di-
perpartofFigure2. IncontrasttoSLD,theNBEnetwork rectly regress bearing vectors of the landmarks even when
usesfullyconnectedlayersafteraResNet-18backbonethat they were not visible in the image. These bearing predic-
outputthefinalbearingpredictions. SLDandNBEmodels tionswerecomplementarytoSLDâ€™sheatmapdetections.As
were trained on the same scene and the authors proposed SLDâ€™s typical budget of landmarks is quite small, some-
runninginferenceusingbothmodelsoneveryqueryimage. times enough landmarks are not visible in a test image.
However, the steps to merge the two sets of predictions is
Training. TheSLDandNBEarchitecturesaretrainedus-
adhoc.SLDâˆ—doesnotuseNBE,asitusesalargerlandmark
ing ground truth 2D landmark detections (and 3D bear-
budgettodirectlyaddresstheunderlyingissue.
ing vectors) derived from associated camera poses in the
trainingdata. TrainingSLDalsorequiresknowledgeabout Absence of an upsampling layer. SLD first predicts a
which images each landmark is visible in. The visibilities set of low-resolution heatmaps and then spatially upsam-
are recovered from 2D data association of SfM 3D points ples them using transposed convolutions to produce the fi-
in the training images. SLD is then trained using mean nalheatmaps.Incontrast,SLDâˆ—directlypredictstheoutput
squared loss with respect to the ground truth heatmaps, heatmaps using 1Ã—1 convolution without any spatial up-
whileNBEistrainedwitharobustangularloss. sampling. Without the upsampling layer, SLDâˆ— has fewer
parameters to learn and has a smaller memory footprint.
Datasets and Metrics. SLD and NBE was evaluated on
Yet, this change does not adversely affect the accuracy of
INDOOR-6 [11], a challenging indoor localization dataset
landmarkpredictioninourexperience. Thisisbecause,for
withsixscenes,whereimagescapturedovermultipledays
each detected landmark, the associated 2D position is es-
have strong lighting changes. Pseudo ground truth (pGT)
timated by computing aweighted mean of all the heatmap
cameraposeswererecoveredwithCOLMAP[32]. Given,
samplesfroma17Ã—17patchcenteredatthelocationofthe
cameraposeestimates,thestandardrotationalerrorâˆ†Rand
peak in each heatmap. We observe that the weighted av-
positionerrorâˆ†tiscomputedasfollows.
eraging step provided sufficient sub-pixel precision in the
âˆ†R=arccosTr(RâŠ¤RË†)âˆ’1, âˆ†t=âˆ¥RâŠ¤tâˆ’RË†âŠ¤Ë†tâˆ¥ . 2Dlandmarkcoordinatesandthuspredictingheatmapsata
2 2visible patches (leveraging SfM)
visible patches (leveraging SfM and dense reconstruction)
Dense reconstruction
Figure3. BetterVisibilityEstimation. [Left]Twoimagesfromscene1inthe INDOOR-6 datasettakenatdifferenttimesofdayanda
renderingofthedense3Dmeshreconstructionofthescene. [Right]Onthetopright,weshowasinglerowofpatchesdepictingascene
landmark(indicatedbythegreensquare)indifferentimageswherethelandmarkwasfoundtobevisible. Theoriginalmethodleveraged
dataassociationfromonlystructurefrommotion.Onthelowerright,weshowpatchesforthesamelandmarkbasedtheproposedvisibility
estimation approach that also uses the dense mesh reconstruction (see text for details). The high appearance diversity in the observed
patchesundervaryingilluminationmakesthetrainedlandmarkdetectormorerobust.
highoutputresolutionappearstobeunnecessary. augmentationstrategywheretheyassumedthatalandmark
isvisibleinimageswhosecameraposesestimatedbySfM
Memoryfootprintreduction. Doetal.[11]experimented
arenearbytotheposeofimageswherethepointisknown
withbothResNet-18[13]andEfficientNet[37]backbones.
tobevisible.However,thisstrategycancorruptthetraining
In our implementation, we focus only on EfficientNet, as
datawithoutliers(falsepositives)byincludingviewswhere
we aim to reduce the storage size and the memory foot-
thelandmarkisoccluded. Weproposetomitigatethisissue
print of the architecture. Furthermore, we use fewer fea-
usinggeometryandexplicitocclusionreasoning.
turemapchannelsandmoreaggressivedownsamplingthan
SLD. SLDâˆ— has 320 channels unlike SLD which has 512 Dense Reconstruction. We reconstruct a dense 3D mesh
channels. SLDâˆ—â€™s feature maps have 8Ã— downsampling in for each scene as follows. First, dense monocular depth
contrasttoSLD,wherethedownsamplingfactoris4Ã—. maps for all map images are estimated using the dense
depth vision transformer [24]. The dense 3D point clouds
Weighted pose estimation. We implemented a weighted
from these depth maps are then robustly registered to
pose estimation scheme using weights derived from the
heatmapvaluesassociatedwithSLDâˆ—â€™soutputpredictions. the sparse SfM 3D point cloud (which is computed by
COLMAP [32]). The registration involves robustly es-
Denoting peak heatmap values per detection as v, we first
timating an affine transformation from 3D point-to-point
prune detections for which v â‰¤ 0.3. Next, we compute a
per-landmark weight w = ve where e is a parameter. We matches. We first prune 3D points observed in less than
50imagesandremoveimageswhichdidnotobserveasuf-
proposeusingtheweightswintwodifferentsteps.First,for
ficientnumberof3Dpoints. Wealsocheckresidualsafter
PROSAC[9](RANSACvariant)usedforrobustestimation
aligning the depth maps to the SfM points and prune out
andalsoasweightsduringthePnPposeoptimization.
images for which the mean depth residual exceeded 5cm.
3.3.LandmarkVisibilityEstimation Finally, we use truncated signed distance function based
depth-mapfusionandisosurfaceextractiontocomputethe
In this section, we discuss a limitation of how training mesh. Figure3showsthereconstructedmeshforscene1.
data is generated for SLD [11] and propose methods for
addressing the limitation. While SfM pipelines such as Occlusion Reasoning. For every pair of a selected land-
COLMAP [32] can produce 3D points with accurate 2D markpandanimageI withitsposeT I andtheestimated
dataassociationinmultipleimages,theyoftenfailtodetect densedepthd I wedeterminewhetherthelandmarkisvisi-
all the potential observations (true positives) of the point. bleintheimagebycheckingthefollowingconditions:
Thiscanhappenwhentheilluminationvariesdramatically. â€¢ The 3D point p is in front of the camera for I (i.e.,
To alleviate this issue, Do et al. [11] proposed an ad-hoc (T p ) > 0) and the point projects within the image
I l zNum.Landmarks Num.Landmarks Num.Landmarks
100 200 300 400 100 200 300 400 100 200 300 400
scene1 34.7 39.8 41.8 17.6 scene1 0.29 0.39 0.41 0.53 scene1 0.29 0.34 0.35 0.49
scene2a 31.5 46.3 45.9 28.8 scene2a 0.24 0.25 0.34 0.43 scene2a 0.24 0.26 0.31 0.37
scene3 34.3 43.2 55.2 42.5 scene3 0.27 0.29 0.36 0.45 scene3 0.27 0.29 0.31 0.39
scene4a 46.2 63.3 65.8 42.4 scene4a 0.23 0.28 0.29 0.44 scene4a 0.23 0.26 0.28 0.41
scene5 28.5 31.4 35.1 29.7 scene5 0.25 0.39 0.40 0.53 scene5 0.25 0.32 0.35 0.41
scene6 43.3 58.2 56.4 40.3 scene6 0.25 0.28 0.30 0.46 scene6 0.25 0.29 0.34 0.45
avg. 36.4 47.0 50.0 33.6 avg. 0.26 0.31 0.35 0.47 avg. 0.26 0.29 0.32 0.42
(a)Poserecallat5cm/5â—¦(in%)â†‘ (b)angularerror(indeg.)â†“ (c)angularerror(indeg.)(first100)â†“
Table1.AnalyzingModelCapacity:(a)Thetablereportsavergecameraposeestimationaccuracyaccordingtothe5cm/5â—¦recallmetric
forfourSLDâˆ—modelstrainedwith100,200,300and400landmarksrespectivelyforallthescenesinINDOOR-6.(b)Themedianangular
errorindegreesforthesamefourmodelsaveragedacrossthesixscenes. Themedianiscomputedoverthesetofall2DSLDdetections
obtainedusingthetrainedmodelsonallthetestimages.(c)Inourimplementation,theelementsintheselectedsetoflandmarksarestored
intheordertheywereselected. Therefore, thefist100landmarksintheorderedsetsforthemodelstrainedon100, 200, 300and400
landmarksareidentical.Themedianerrorsforthefirst100landmarksaveragedonallscenes,arereportedinthetable.
(i.e.,Î (T p )) âˆˆ R(I)whereÎ (.)isthe2Dprojection on these 100 points in the four models is the best way to
I l
operatorandR(.)denotestheimageextent. comparethem. IndeedasTable1(c)shows,thepredictions
â€¢ The depth of the 2D projected point is not too far from forthefirst100landmarksgetworseasthemodelistrained
thedepthatthatpixel,computedusingthereconstructed for200,300and400landmarks. Thisconfirmsourhypoth-
mesh,i.e.,d (Î (T p))â‰ˆ(T p) . esisthatthemodelshaveinsufficientcapacity.
I I I z
â€¢ Thesurfacenormalofthe2Dprojectedpointisnottoofar
Training network ensembles. Instead of modifying the
fromthenormalvectorestimatedusingthereconstructed
architecture, we address the insufficient capacity issue by
mesh,i.e,âˆ‡d (Î (T p))â‰ˆâˆ‡(T p)
I I I z choosing a divide and conquer strategy for scaling to a
3.4.LandmarkPartitioningForScalability higher number of landmarks. We propose to simply par-
tition the set of landmarks into non-overlapping subsets
In this section, we discuss what prevents SLD from accu-
where the subsets are relatively small and their size is se-
ratelyscalingtoalargenumberoflandmarksandpresenta
lected by keeping the typical capacity of the SLDâˆ— archi-
simplesolutionthatdoesnotaddcomputationaloverhead.
tecture under consideration. Then, we independently train
Insufficient Capacity. Do et al. [11] evaluated SLD multipleidenticalnetworks,oneforeachsubset.Wereferto
(withResNet-18)modelswith200,300and400landmarks thenetworkstogetherasanensemble. Thenetworksinthe
per scene on INDOOR-6 and reported that 300 landmarks ensemble can be trained independently and each is aware
worked best. When evaluating SLDâˆ— with different num- onlyofitsownassociatedsubsetoflandmarks. Traininga
beroflandmarks,weobservedthataccuracyincreasesfrom SLDâˆ—ensembleisthustriviallyparallelizable.
100 to 300 but falls with 400 landmarks (see the recall at
Parallel vs. Sequential Inference. At test time, there are
5cm/5â—¦ metrics in Table 1(a)). It is worth noting that the
twowaystoruninferenceusingtheensemble. WhenGPU
smaller sets of landmarks are strictly contained within the
memoryisabundant,allSLDâˆ—networkscouldbeinitialized
larger landmark sets. The results imply that insufficient
in GPU memory, allowing parallel inference on multiple
modelcapacityinthenetworkcouldbehurtingaccuracy.
networks.Despitehavingmultiplenetworks,thetotalmem-
To confirm our hypothesis, we analyzed the angular er-
oryfootprintcanstillbequitereasonableaseachSLDâˆ—net-
rorsofthepredicted2DlandmarksfromtheSLDâˆ— models
workisquitememoryefficient(<0.99GB).Inthissetting,
trained on 100, 200, 300 and 400 landmarks. The median
inferencecanbeextremelyfastandreal-timeprocessingis
angularerrorsreportedinTable1(b)increasedasthenum-
quiteviable. However,onGPUswithsmallermemorybud-
beroflandmarksincreased.Theangularerrorsdependonly
gets,inferencemustbedonesequentially. Eventhough,the
onthenetwork, andarenotaffectedbyposeestimationor
processingtimegrows,localizationcanstillrunat3â€“5im-
otherfactors. Wealsoanalyzedtheangularerrorofthefirst
ages/sec for practical ensemble sizes. In this paper, all re-
100landmarks(definedwithrespecttoanorderingdefined
portedtimingsareforthesequentialinferencesetting.
bylandmarkids)forthefourSLDâˆ— modelstrainedon100,
200,300and400landmarks. Sincethefirst100landmarks Partitioning Criteria. We compare four different criteria
areidenticalinallfourcases,comparingthemedianerrors forpartitioningthelandmarksetâ€“(1)Default:sortingland-Scene1images Scene1mesh 300landmarks 1000landmarks
Figure4. Thetopviewofthemeshand3DSfMpointcloudfromscene1,shownwiththeoverlaidscenelandmarks(redpoints). Thesets
of300and1000landmarksrespectivelyarebothcomputedbytheexistingselectionmethod[11]. Theimageontherightshowsthata
highernumberoflandmarksprovidesdenserscenecoverage.Weshowlaterthatitleadstoanimprovementincameraposeaccuracy.
200Ã—1 300Ã—1 100Ã—3 100Ã—4 125Ã—6 125Ã—8 125Ã—12 4.ExperimentalResults
R@5cm/5â—¦â†‘ 46.0 50.8 61.1 63.0 66.6 70.1 69.1
Time(sec.)â†“ 0.05 0.11 0.16 0.19 0.23 0.3 0.5 In this section, we report ablation studies and a quantita-
Size(MB)â†“ 15 15 45 60 90 120 180
tivecomparisonofSLDâˆ—andothermethodsonINDOOR-6.
Table 2. Ablation study. Recall at 5cm/5â—¦ for aÃ—b ensembles Wethenstudyindetail,theaccuracyandspeedtradeoffof
where a is the number of landmarks in each subset and b is the SLDâˆ—andhloc[26]. Finally,wepresentvisualexamplesto
number of networks in the ensemble. The 125Ã—8 ensemble has showthebenefitofusingalargernumberoflandmarks.
the best performance. As expected, ensembles containing more
Ablation: Ensemble Size. Table 2 shows 5cm/5â—¦ recall
networks and dealing with more scene landmarks have slightly
foravarietyofensemblesizesthatwehaveevaluated. We
higherstoragerequirementsandrunningtimes.
empirically found that 125Ã—8 (8 networks with 125 land-
markseach)works thebeston INDOOR-6. Wealsoreport
âˆš âˆš
w w=v w=v v w=v2 w=v2 v howstorageandrunningtimesincreaseproportionaltothe
R@5cm/5â—¦â†‘ 68.0% 68.4% 69.4% 70.1% 69.6 ensemblesizeandthetotalnumberoflandmarks.
Ablation: Weighted Pose Estimation. Table 3 reports
Table3. Evaluatingweightedposeestimationschemes. Recall
at5cm/5â—¦ ofa1000landmarkSLDâˆ— ensembleonINDOOR-6for 5cm/5â—¦ recallfornon-weightedandweightedposeestima-
non-weighted(v)andweightedposeestimates. Fourschemesfor tionusinga125Ã—8SLDâˆ—ensemble. Fortheweightedcase,
derivingtheweights(w)fromheatmapvalues(v)arecompared. the effect of setting values of the parameter e to 1, 1.5, 2
and2.5isreported. Thesettinge=2gavethebestresults
andwasusedinalltheotherexperiments.
marksbythesaliencyscoreandthensplittingthesortedlist Quantitative Evaluation. In Table 4, we compare re-
into equal sized partitions; (2) Random: randomly assign- call at 5cm/5â—¦ for several methods. For DSAC* [6], Se-
ing landmarks to partitions; (3) Spatial clustering: group- gLoc [21], NBE+SLD [11] we present results reported in
inglandmarksbyk-meansclusteringandthenrebalancing prior work [11, 21]. The SLD column in the table shows
points in adjoining clusters to get equal sized partitions; theresultsofthepublicEfficientNet-basedSLDimplemen-
(4) Farthest-point sampling: iteratively selecting the point tation. The table also includes results of hloc [26]. Previ-
farthest from the points already in existing partitions and ouslyreportedresultsareshownincolumnhloc-Awhereas
adding it to the best partition until all partitioned reached our results obtained with hlocâ€™s public implementation are
the specified size. We compared the four criteria using shown in column hloc-B. Finally, hloc-lite (hloc-l) results
1000 landmarks and 8 partitions and found that the recall frompriorwork[11]arealsoincluded.
at5cm/5â—¦ posemetricwassimilar(within1-2%points)in TheaccuracymetricforSLDâˆ— andSLD(bothwith300
thefourcases. Weconcludethatthepartitioningcriteriais landmarks)is50.8%and44.9%respectively.This6%accu-
notcrucialonthedatasetandthususedthedefaultstrategy racyimprovementofSLDâˆ—canbeattributedtobettertrain-
thereafter. However, when a coarse location prior is avail- inglabelsgeneratedusingtheproposedvisibilityestimation
able in large scenes, clustering-based partitioning can im- method. However, the best results of SLDâˆ— is 70.1% ob-
prove computational efficiency by enabling locality-based tainedusinga125Ã—8ensembletrainedon1000landmarks
pruningofredundantinferencepasses. whichiscompetitivewithhloc[26]at71.4%.Scene DSAC* NBE+SLD SLD SegLoc SLDâˆ— hloc-l hloc-l hloc-A hloc-B SLDâˆ—
1000 3000
[6] [11] [11] [21] ours [11] [11] [11,26] [26] ours
#landmarks n/a 300 300 n/a 300 1000 3000 n/a n/a 1000
R@5cm/5â—¦â†‘ scene1 18.7 38.4 35.0 51.0 47.2 33.3 48.1 64.8 70.5 68.5
scene2a 28.0 â€“ 34.6 56.4 48.2 12.5 17.1 51.4 52.1 62.6
scene3 19.7 53.0 50.8 41.8 56.2 48.3 61.9 81.0 86.0 76.2
scene4a 60.8 â€“ 56.3 33.8 67.7 34.8 39.2 69.0 75.3 77.2
scene5 10.6 40.0 43.6 43.1 33.7 21.9 31.1 42.7 58.0 57.8
scene6 44.3 50.5 48.9 34.5 52.0 47.4 59.1 79.9 86.7 78.0
R@5cm/5â—¦â†‘ avg. 30.4 45.5 44.9 43.4 50.8 33.0 42.8 64.8 71.4 70.1
Size(GB)â†“ 0.027 0.135 0.020 0.161 0.015 0.17â€“0.21 0.2â€“0.5 0.7â€“2.4 0.7â€“2.4 0.120
Mem.(GB)â†“ 0.85 1.35 1.2 â€“ 0.99 1.3 1.3 1.3 1.3 0.99
Table4. QuantitativeEvaluationonINDOOR-6. Wereporttherecallat5cm/5â—¦ (in%),storageused(Size),andin-memoryfootprint
(Mem.) ofseveralmethods. FortheSLD[11]baseline,wereportpreviouslypublishedresultsinthecolumnNBE+SLDandresultsfrom
thepublicEfficientNet-basedcodeintheSLDcolumn. Forhloc[26],wefirstpresentpublishedresultsinDo etal.[11]inthecolumn
hloc-A,andthen, thebestresultsweobtainedusinghlocâ€™spubliccodebaseinthecolumnhloc-B.Finally, wepresentresultsforSLDâˆ—
(denotedâ€oursâ€)with300and1000landmarksrespectively.Thebestmethod(perrow)ishighlightedinboldandthesecond-bestinblue.
Figure5.Accuracy/speedtradeoffofSLDâˆ—andhloc.Theplotshowshowhlocâ€™sperformancevarieswiththenumberofmatchedimage
pairs. Tthenumberofpairsweresetto1,2,5,10,15and20respectively,asdenotedbythetextlabels). hlocâ€™sbestaccuracywas71.4%
with20imagepairsforwhichthetimingwas14.2seconds/image. Similarly,sevenSLDâˆ— configurationswereevaluated. Thetextlabel
aÃ—bnexttothebluedotsindicatetheSLDâˆ— configuration, whereaisthenumberoflandmarksineachpartitionandbrepresentsthe
numberofpartitions. SLDâˆ—â€™sbestresultwas70.1%using125Ã—8=1000landmarkswitharunningtimeof0.3seconds/image. Theplot
showsthataccuracywise,SLDâˆ—â€™sbestconfigurationiscompetitivewithhlocbutmorethan40Xfaster.
Accuracy Speed Trade-off. Accuracy wise, SLDâˆ— and 2,5and10matchingpairs).Moreover,eventhoughsmaller
hloc have similar performance on INDOOR-6. Thus, we ensembles are slightly worse accuracy wise, they also run
report a detailed accuracy and speed trade-off analysis for significantly faster. Note that, the reported timings are for
them. Figure 5 shows that the two hloc configurations sequentialinference.Intheparallelinferencesetting,SLDâˆ—
(where 15 and 20 matching pairs are used respectively) runs extremely fast because all the models are preloaded
beats SLDâˆ— by a small accuracy margin. However, these inGPUmemoryandallnetworksruninferenceinparallel.
twohlocconfigurationsarequiteslow. ThebestSLDâˆ— set- However,thememoryfootprintoftheensemblelinearlyin-
tingoutperformsallotherhlocconfigurations(whichuse1, crease with its size. Nonetheless, parallel inference may[L=300]âˆ†R=0.94â—¦,âˆ†t=8cm [L=1000]âˆ†R=0.25â—¦,âˆ†t=4cm [L=300]âˆ†R=1.73â—¦,âˆ†t=10cm [L=1000]âˆ†R=0.18â—¦,âˆ†t=2cm
(a) (b)
[L=300]âˆ†R=1.46â—¦,âˆ†t=5cm [L=1000]âˆ†R=0.29â—¦,âˆ†t=1cm [L=300]âˆ†R=0.81â—¦,âˆ†t=12cm [L=1000]âˆ†R=0.77â—¦,âˆ†t=4cm
(c) (d)
[L=300]âˆ†R=0.69â—¦,âˆ†t=5cm [L=1000]âˆ†R=0.28â—¦,âˆ†t=2cm [L=300]âˆ†R=2.15â—¦,âˆ†t=38cm [L=1000]âˆ†R=0.21â—¦,âˆ†t=7cm
(e) (f)
[L=300]âˆ†R=2.47â—¦,âˆ†t=6cm [L=1000]âˆ†R=0.76â—¦,âˆ†t=3cm [L=300]âˆ†R=1.51â—¦,âˆ†t=6cm [L=1000]âˆ†R=0.64â—¦,âˆ†t=2cm
(g) (h)
Figure6. QualitativeresultsonINDOOR-6. Detectedscenelandmarksareshownasgreenpointsontheimagesfromscene1,andthe
rotationandtranslationerrorsintheSLDâˆ—poseestimatearealsoreportedbeloweachimage.(a)â€“(h)Inalleightexamples,theresultonthe
leftisfor300landmarks,whereastheresultontherightisfor1000landmarks.Using1000landmarksinsteadof300landmarksproduces
more2Dâ€“3Dpointconstraintsandthe2Dlocationsarespatiallybetterdistributedinmostimages.whichlateryieldsamoreaccuratepose.
stillbepracticalwhensufficientGPUmemoryisavailable. cameralocalization. SLDâˆ— ismemoryandstorageefficient
like SLD but it shows a dramatic improvement in perfor-
Qualitative Results. Finally, we present test images from
mance (accuracy). The improvement makes SLDâˆ— com-
scene1inFigure6thatwerelocalizedusingtwoSLDâˆ—mod-
petitivewithstructure-basedmethodssuchashloc[26,27]
elstrainedon300and1000landmarksrespectivelyandalso
while being about 40X faster. The improved accuracy can
report the associated pose errors. These examples clearly
be attributed to two ideas proposed in the paper First, we
demonstrate the benefit of scaling up the number of scene
proposedanewprocessingpipelinetogeneratemoreaccu-
landmarks.Themodelfor1000landmarksconsistentlypro-
rate training labels for training the detector. Secondly, we
ducesmoreaccurateresults,duetomoreposeinliersbeing
showedthatpartitioningthelandmarksintosmallergroups
presentandabetterdistributionofthoseinliers. AllSLDâˆ—
and training independent networks for each subgroup dra-
models were trained using NVIDIA V100 GPUs whereas
matically boosts accuracy when a large number of scene
querieswereprocessedonalaptopwithaRTX2070GPU.
landmarks are present. SLDâˆ— is currently trained from
scratchforeachscenewhichistimeconsumingandexpen-
5.Conclusion
sive. Exploringideassimilartothoseproposedrecentlyfor
accelerating scene coordinate regression [8] could lead to
In this paper, we proposed SLDâˆ—, an extension of the ex-
fastertrainingandisanimportantavenueforfuturework.
isting SLDframework forscene landmark detection-basedReferences [18] Xiaotian Li, Shuzhe Wang, Yi Zhao, Jakob Verbeek, and
Juho Kannala. Hierarchical scene coordinate classification
[1] Relja Arandjelovic, Petr Gronat, Akihiko Torii, Tomas Pa-
andregressionforvisuallocalization. InCVPR,2020. 2
jdla, and Josef Sivic. NetVLAD: CNN architecture for
[19] Hyon Lim, Sudipta N Sinha, Michael F Cohen, Matt Uyt-
weaklysupervisedplacerecognition. InCVPR,2016. 2
tendaele,andHJinKim. Real-timemonocularimage-based
[2] VassileiosBalntas,ShudaLi,andVictorPrisacariu. Reloc- 6-doflocalization. IJRR,2015. 2
Net: Continuousmetriclearningrelocalisationusingneural
[20] Anastasiia Mishchuk, Dmytro Mishkin, Filip Radenovic,
nets. InECCV,2018. 2
andJiriMatas. Workinghardtoknowyourneighbor'smar-
[3] AlessandroBergamo,SudiptaNSinha,andLorenzoTorre- gins:Localdescriptorlearningloss. InNeurIPS,2017. 2
sani. Leveraging structure from motion to learn discrim-
[21] Maxime Pietrantoni, Martin Humenberger, Torsten Sattler,
inative codebooks for scalable landmark classification. In
andGabrielaCsurka. Segloc: Learningsegmentation-based
CVPR,2013. 2
representationsforprivacy-preservingvisuallocalization.In
[4] EricBrachmannandCarstenRother. Learninglessismore- CVPR,2023. 1,2,6,7
6Dcameralocalizationvia3Dsurfaceregression. InCVPR, [22] NoeÂ´ Pion, Martin Humenberger, Gabriela Csurka, Yohann
2018. 2 Cabon, and Torsten Sattler. Benchmarking image retrieval
[5] EricBrachmannandCarstenRother. Expertsampleconsen- forvisuallocalization. In3DV,2020. 2
susappliedtocamerare-localization. InICCV,2019. 2 [23] FrancescoPittaluga,SanjeevJKoppal,SingBingKang,and
[6] Eric Brachmann and Carsten Rother. Visual camera re- Sudipta N Sinha. Revealing scenes by inverting structure
localization from rgb and rgb-d images using DSAC. T- frommotionreconstructions. InCVPR,2019. 1
PAMI,2021. 1,2,6,7 [24] ReneÂ´ Ranftl, Katrin Lasinger, David Hafner, Konrad
[7] Eric Brachmann, Alexander Krull, Sebastian Nowozin, Schindler, and Vladlen Koltun. Towards robust monocular
JamieShotton,FrankMichel,StefanGumhold,andCarsten depthestimation:Mixingdatasetsforzero-shotcross-dataset
Rother. DSAC-differentiableransacforcameralocalization. transfer.IEEEtransactionsonpatternanalysisandmachine
InCVPR,2017. 1,2 intelligence,44(3):1623â€“1637,2020. 4
[8] Eric Brachmann, Tommaso Cavallari, and Victor Adrian [25] Jerome Revaud, Philippe Weinzaepfel, CeÂ´sar Roberto de
Prisacariu. Accelerated coordinate encoding: Learning to Souza,andMartinHumenberger. R2D2: repeatableandre-
relocalizeinminutesusingrgbandposes. InCVPR,2023. liabledetectoranddescriptor. InNeurIPS,2019. 2
2,8 [26] Paul-Edouard Sarlin, Cesar Cadena, Roland Siegwart, and
MarcinDymczyk. Fromcoarsetofine: Robusthierarchical
[9] OndrejChumandJiriMatas.MatchingwithPROSAC-pro-
localizationatlargescale. InCVPR,2019. 1,2,6,7,8
gressivesampleconsensus. InCVPR,2005. 4
[27] Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz,
[10] Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabi-
and Andrew Rabinovich. Superglue: Learning feature
novich. Superpoint: Self-supervisedinterestpointdetection
matching with graph neural networks. In CVPR, 2020. 1,
anddescription. InCVPRworkshops,2018. 2
2,8
[11] TienDo,OndrejMiksik,JosephDeGol,HyunSooPark,and
[28] Paul-Edouard Sarlin, Ajaykumar Unagar, MaËšns Larsson,
Sudipta N. Sinha. Learning to detect scene landmarks for
Hugo Germain, Carl Toft, Victor Larsson, Marc Pollefeys,
cameralocalization.InCVPR,pages11132â€“11142,2022.1,
Vincent Lepetit, Lars Hammarstrand, Fredrik Kahl, and
2,3,4,5,6,7
TorstenSattler. BacktotheFeature: LearningRobustCam-
[12] Petr Gronat, Guillaume Obozinski, Josef Sivic, and Tomas
eraLocalizationfromPixelstoPose. InCVPR,2021. 2
Pajdla. Learningandcalibratingper-locationclassifiersfor
[29] TorstenSattler,BastianLeibe,andLeifKobbelt. Improving
visualplacerecognition. InCVPR,2013. 2
image-based localization by active correspondence search.
[13] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun. InECCV,2012. 1,2
Deep residual learning for image recognition. In CVPR,
[30] Torsten Sattler, Tobias Weyand, B. Leibe, and Leif P.
2016. 3,4
Kobbelt. Imageretrievalforimage-basedlocalizationrevis-
[14] TongKeandStergiosI.Roumeliotis. Anefficientalgebraic ited. InBMVC,2012. 1,2
solution to the perspective-three-point problem. In CVPR, [31] Torsten Sattler, Qunjie Zhou, Marc Pollefeys, and Laura
2017. 2 Leal-Taixe. Understandingthelimitationsofcnn-basedab-
[15] Alex Kendall, Matthew Grimes, and Roberto Cipolla. solutecameraposeregression. InCVPR,2019. 2
PoseNet: Aconvolutionalnetworkforreal-time6-dofcam- [32] Johannes SchoÂ¨nberger and Jan-Michael Frahm. Structure-
erarelocalization. InICCV,2015. 1,2 from-MotionRevisited. InCVPR,2016. 3,4
[16] Zakaria Laskar, Iaroslav Melekhov, Surya Kalia, and Juho [33] Yoli Shavit, Ron Ferens, and Yosi Keller. Learning multi-
Kannala. Camerarelocalizationbycomputingpairwiserel- sceneabsoluteposeregressionwithtransformers. InICCV,
ative poses using convolutional neural network. In ICCV, 2021. 2
2017. 2 [34] Jamie Shotton, Ben Glocker, Christopher Zach, Shahram
[17] Xiaotian Li, Juha Ylioinas, and Juho Kannala. Full-frame Izadi,AntonioCriminisi,andAndrewFitzgibbon.Sceneco-
scenecoordinateregressionforimage-basedlocalization. In ordinateregressionforestsforcamerarelocalizationinRGB-
RSS,2018. 2 Dimages. InCVPR,2013. 2[35] Pablo Speciale, Johannes Schonberger, Sing Bing Kang,
Sudipta N Sinha, and Marc Pollefeys. Privacy preserving
image-basedlocalization. InCVPR,2019. 2
[36] PabloSpeciale,JohannesSchonberger,SudiptaNSinha,and
MarcPollefeys.Privacypreservingimagequeriesforcamera
localization. InICCV,2019. 2
[37] Mingxing Tan and Quoc V. Le. EfficientNet: Rethinking
model scaling for convolutional neural networks. arXiv,
2019. 3,4
[38] GiorgosTolias,YannisAvrithis,andHerveÂ´JeÂ´gou. Toaggre-
gateornottoaggregate: Selectivematchkernelsforimage
search. InICCV,2013. 2
[39] Akihiko Torii, Relja ArandjelovicÂ´, Josef Sivic, Masatoshi
Okutomi,andTomasPajdla. 24/7placerecognitionbyview
synthesis. InCVPR,2015. 2
[40] Akihiko Torii, Hajime Taira, Josef Sivic, Marc Pollefeys,
MasatoshiOkutomi,TomasPajdla,andTorstenSattler. Are
large-scale3dmodelsreallynecessaryforaccuratevisuallo-
calization? IEEEtransactionsonpatternanalysisandma-
chineintelligence,43(3):814â€“829,2019. 2
[41] Bing Wang, Changhao Chen, Chris Xiaoxuan Lu, Peijun
Zhao, Niki Trigoni, and Andrew Markham. Atloc: Atten-
tionguidedcameralocalization. InAAAI,2020. 2
[42] ShuzheWang,ZakariaLaskar,IaroslavMelekhov,Xiaotian
Li, andJuhoKannala. Continuallearningforimage-based
cameralocalization. InICCV,2021. 2
[43] Philippe Weinzaepfel, Gabriela Csurka, Yohann Cabon,
and Martin Humenberger. Visual localization by learning
objects-of-interestdensematchregression. InCVPR,2019.
2
[44] TobiasWeyand,IlyaKostrikov,andJamesPhilbin. Planet-
photo geolocation with convolutional neural networks. In
ECCV,2016. 2
[45] LuweiYang,ZiqianBai,ChengzhouTang,HonghuaLi,Ya-
sutakaFurukawa,andPingTan.SANet:Sceneagnosticnet-
workforcameralocalization. InICCV,2019. 2
[46] FisherYuandVladlenKoltun. Multi-scalecontextaggrega-
tionbydilatedconvolutions. InICLR,2015. 3
[47] Qunjie Zhou, SeÂ´rgio Agostinho, AljosË‡a OsË‡ep, and Laura
Leal-TaixeÂ´. Isgeometryenoughformatchinginvisuallo-
calization? InECCV,2022. 2