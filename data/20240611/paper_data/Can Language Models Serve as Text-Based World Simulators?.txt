Can Language Models Serve as Text-Based World Simulators?
RuoyaoWangâ€ ,GrahamToddâ€¡,ZiangXiaoâ™ ,XingdiYuanâ™¢
Marc-AlexandreCÃ´tÃ©â™¢,PeterClarkâ™£,PeterJansenâ€ â™£
â€ UniversityofArizona â™¢MicrosoftResearchMontrÃ©al
â€¡NewYorkUniversity â™ JohnsHopkinsUniversity â™£AllenInstituteforAI
{ruoyaowang,pajansen}@arizona.edu gdrtodd@nyu.edu
ziang.xiao@jhu.edu {eric.yuan,macote}@microsoft.com
PeterC@allenai.org
Abstract
[{
â€œnameâ€:â€œsinkâ€, â€œpropertiesâ€:{â€œisOnâ€: false, ...},"contains":["cup"]
},{
Virtualenvironmentsplayakeyroleinbench- â€œnameâ€:â€œcupâ€, â€œpropertiesâ€:{â€œisContainerâ€: true, ...},"contains":[]
},{
marking advances in complex planning and â€œnameâ€: â€œstoveâ€, â€œpropertiesâ€: {â€œisContainerâ€: true, ...},"contains": []
stateğ‘  ğ‘¡ }, â€¦ ]
decision-making tasks but are expensive and
actionğ‘ ğ‘¡ turnonthesink
complicated to build by hand. Can current
â€¦
language models themselves serve as world Action:turn on/off
DesOcbrijpetcito: nS:i ntukr n on/off a device
simulators, correctly predicting how actions R 1.ulD oTe nhes:s e â€¦c ori bp jt eio ctn : t oA bs ein tk u c rna en d f i oll nth /oe f fc o mn uta stin be er i an c tt ih ve a ts ai bn lk e w (ii st Ah c w tiva ate tar bif l eit ) is
changedifferentworldstates,thusbypassing 2.PI wfr hot -h ip lTe ee h ro tet ubi e rsj nse in c okt f fi is sw o nin lol tc( i ohs paO nen ng= aeT b r iltu e te o), otu ffr n on will not change its state
- The sink can be turned on or off
the need for extensive manual coding? Our 3.(isO- nPe=rF tailcske,) .i f the sink is on and there is anycontainer in the sink
game rules without water, fill itwith water.
goal is to answer this question in the context
examples { , ,â€¦ }
of text-based simulators. Our approach is to
buildanduseanewbenchmark,calledBYTE-
SIZED32-State-Prediction,containingadataset FullStatePrediction StateDifferencePrediction
oftextgamestatetransitionsandaccompany- [{ Modified:
"name":"sink", [{
inggametasks.Weusethistodirectlyquantify, "properties":{"isOn": true, ...}, "name": "sink",
"contains":["cup"] "properties": {"isOn": true, â€¦},
forthefirsttime,howwellLLMscanserveas },{ "contains": ["cup"]
"name":"cup", }, {
text-basedworldsimulators. WetestGPT-4on "properties":{"isContainer": true, ...}, "name": "cup",
"contains":["water"] "properties": {"isContainer": true, â€¦},
thisdatasetandfindthat,despiteitsimpressive },{ "contains": ["water"]
"name": "water", }]
performance,itisstillanunreliableworldsim- "properties": {â€¦}, â€contains": [] Added: },{ [{
ulatorwithoutfurtherinnovations. Thiswork "name": "stove", "name": "water", "properties: {â€¦}, "contains": []
"properties": {"isContainer": true, ...}, }]
thuscontributesbothnewinsightsintocurrent
} , â€¦
â€c ]ontains": [] ğ‘ 
ğ‘¡+1
Removed: [] Î”(ğ‘  ğ‘¡,ğ‘  ğ‘¡+1)
LLMâ€™scapabilitiesandweaknesses,aswellas
anovelbenchmarktotrackfutureprogressas
Figure1: Anoverviewofourtwoapproachesusingan
newmodelsappear.
LLMasatextgamesimulator. Theexampleshowsthe
process that a cup in the sink is filled by water after
1 IntroductionandRelatedWork
turningonthesink. Thefullstatepredictionincludes
all objects in the game including the unrelated stove,
Simulatingtheworldiscrucialforstudyingandun-
whilethestatedifferencepredictionexcludestheunre-
derstandingit. Inmanycases,however,thebreadth
latedstove. StatechangescausedbyF andF are
act env
and depth of available simulations are limited by
highlightedin yellow and green,respectively.
the fact that their implementation requires exten-
siveworkfromateamofhumanexpertsoverweeks 2023),informationextraction(Ammanabroluand
ormonths. Recentadvancesinlargelanguagemod- Hausknecht,2020;Adhikarietal.,2020),andarti-
els(LLMs)havepointedtowardsanalternateap- ficialreasoning(Wangetal.,2022).
proach by leveraging the huge amount of knowl- Broadly speaking, there are two ways to lever-
edgecontainedintheirpre-trainingdatasets. But age LLMs in the context of world modeling and
aretheyreadytobeuseddirectlyassimulators? simulation. Thefirstisneurosymbolic: anumber
Weexaminethisquestioninthedomainoftext- ofeffortsuselanguagemodelstogeneratecodein
basedgames,whichnaturallyexpresstheenviron- a symbolic representation that allows for formal
mentanditsdynamicsinnaturallanguageandhave planning or inference (Liu et al., 2023; Notting-
long been used as part of advances in decision ham et al., 2023; Wong et al., 2023; Tang et al.,
making processes (CÃ´tÃ© et al., 2018; Fan et al., 2024). REASONING VIA PLANNING (RAP) (Hao
2020;Urbaneketal.,2019;Shridharetal.,2020; et al., 2023) is one such approach â€“ it constructs
Hausknechtetal.,2020;Jansen,2022;Wangetal., aworldmodelusingLLMpriorsandthenusesa
4202
nuJ
01
]LC.sc[
1v58460.6042:viXradedicated planning algorithm to decide on agent States(avg.pergame) 2463.5
policies(LLMsthemselvescontinuetostruggleto Actionverbs(avg.pergame) 7.4
Objecttypes(avg.pergame) 5.5
actdirectlyasplanners(Valmeekametal.,2023)).
Objectinstances(avg.perstate) 10.4
Similarly,BYTESIZED32(Wangetal.,2023)tasks
Totalgames 31
LLMswithinstantiatingsimulationsofscientific Totaltransitions 76,369
reasoningconceptsintheformoflarge PYTHON
programs. Theseeffortsareincontrasttothesec- Table1: CorpusstatisticsofBYTESIZED32-SP.
ond, andcomparativelylessstudied, approachof
2.1 LLM-SimTask
directsimulation. Forinstance,AI-DUNGEONrep-
resentsagameworldpurelythroughthegenerated Weproposeapredictiontask,whichwecallLLM-
output of a language model, with inconsistent re- as-a-Simulator(LLM-Sim), asawayofquantita-
sults (Walton, 2020). In this work, we provide tively evaluating the capacity of language mod-
the first quantitative analysis of the abilities of els to serve as reliable simulators. The LLM-
LLMs to directly simulate virtual environments. Sim task is defined as implementing a function
Wemakeuseofstructuredrepresentationsinthe F : CÃ—SÃ—A â†’ SÃ—RÃ—{0,1}asaworldsim-
JSONschemaasascaffoldthatbothimprovessim- ulator that maps from a given context, state, and
ulationaccuracyandallowsforustodirectlyprobe action(i.e. c,s t,a t)tothesubsequentstate,reward,
theLLMâ€™sabilitiesacrossavarietyofconditions. andgamecompletionstatus(i.e. s t+1,r t+1,d t+1).
Inpractice,thewholestatetransitionsimulator
InasystematicanalysisofGPT-4(Achiametal.,
F should consider two types of state transitions:
2023), we find that LLMs broadly fail to capture
action-driven transitions and environment-driven
state transitions not directly related to agent ac-
transitions. For the example in Figure 1, the
tions,aswellastransitionsthatrequirearithmetic,
action-driven transition is that the sink is turned
common-sense,orscientificreasoning. Acrossava-
on (isOn=true) after taking the action turn on
rietyofconditions,modelaccuracydoesnotexceed
sink,andtheenvironment-driventransitionisthat
59.9%fortransitionsinwhichanon-trivialchange
waterfillsupthecupinthesinkwhenthesinkis
in the world state occurs. These results suggest
on. To better understand LLMâ€™s ability to model
that, while promising and useful for downstream
eachofthesetransitions,wefurtherdecomposethe
tasks, LLMs are not yet ready to act as reliable
worldsimulatorswithoutfurtherinnovation.1 simulatorfunctionF intothreesteps:
sact = F (c,s ,a )
t+1 act t t
2 Methodology s t+1 = F env(c,sa t+ct 1)
r ,d = F (c,a ,s )
t+1 t+1 R t t+1
We examine the abilities of LLMs to serve as
1. Action-driven transition simulator F :
act
world simulators in text-based virtual environ-
C Ã— S Ã— A â†’ S predicts sact given c, s ,
ments, in which an agent receives observations t+1 t
anda ,wheresact representsthedirectstate
andproposesactionsinnaturallanguageinorder t t+1
changecausedbyactions.
to complete certain objectives. Each text envi-
ronment can be formally represented as a goal- 2. Environment-driven transition simulator
conditionedpartiallyobservableMarkovdecision F : C Ã— S â†’ S predicts s given c
env t+1
process (POMDP) (Kaelbling et al., 1998) with and sact , where s is the state that results
t+1 t+1
the 7-tuple (S,A,T,O,R,C,D), where S de- afteranyenvironment-driventransitions.
notes the state space, A denotes the action space,
3. GameprogresssimulatorF : CÃ—SÃ—A â†’
T : S Ã—A â†’ S denotesthetransitionfunction,O R
RÃ—{0,1} predicts the reward r and the
denotestheobservationfunction,R : S Ã—A â†’ R t+1
game completion status d given c, s ,
denotes the reward function, C denotes a natural t+1 t+1
anda .
languageâ€œcontextmessageâ€thatdescribesthegoal t
and action semantics, and D : S Ã— A â†’ {0,1} In our experiments, we measure the ability for
denotesthebinarycompletionindicatorfunction. LLMstomodelF , F , andF separately, as
act env R
wellasthecompleteF (i.e. inwhichalltransitions
are captured in a single step). We consider two
1Code and data are available at https://github.
com/cognitiveailab/GPT-simulator. variantsoftheLLM-Simtask:FullStatePrediction: TheLLMoutputsthecom- State F F F
act env
plete state. For example, when functioning as F, Rules Change Full Diff Full Diff Full Diff
given c, s and a , the model generates the full dynamic 59.0 59.5 76.1 75.2 44.1 49.7
t t LLM
static 62.8 72.2 73.0 89.5 61.9 93.8
gamestates alongsider andd .
t+1 t+1 t+1
dynamic 59.9 51.6 77.1 68.4 38.6 22.2
State Difference Prediction: The LLM outputs Human
static 63.5 73.9 77.5 90.2 73.8 92.3
only the difference between the input and output
dynamic 54.1 52.2 70.8 67.7 24.4 22.3
states. Forexample,whenfunctioningasF,given Norule
static 56.6 70.4 65.3 84.6 73.0 91.7
c,s anda ,themodelgeneratesonlythedifference
t t
Table2: AverageaccuracypergameofGPT-4predictingthe
between the current and subsequent game states,
wholestatetransitions(F)aswellasaction-driventransitions
âˆ†((s t,r t,d t),(s t+1,r t+1,d t+1)), as a way to re- (F act)andenvironment-driventransitions(F env). Wereport
ducetheneedtogenerateredundantorunchanging settingsthatuseLLMgeneratedrules,humanwrittenrules,or
norules.Dynamicandstaticdenotewhetherthegameobject
information. Wedonotapplystatedifferencepre-
propertiesandgameprogressshouldbechanged;Fullanddiff
diction to the game progress simulator F as its denotewhetherthepredictionoutcomeisthefullgamestate
R
output(r andd )isnotcomplex. orstatedifferences.Numbersareshowninpercentage.
t+1 t+1
2.2 Data Rules GameProgress
LLM 92.1
To facilitate evaluation on the LLM-Sim
Human 81.8
task, we introduce a novel dataset of text Norule 61.5
game state transitions. Our dataset, BYTE-
Table3: GPT-4gameprogresspredictionresults
SIZED32-State-Prediction (BYTESIZED32-SP),
consists of 76,369 transitions represented as versionsofthecontext,onewheretherulesarewrit-
(c,s ,r ,d ,a ,sact ,s ,r ,d ) tuples tenbyahumanexpert(oneofthegameauthors),
t t t t t+1 t+1 t+1 t+1
collectedfrom31distincttextgames. Additional andonewheretheyareproducedbyanLLMwith
corpusstatisticsaresummarizedinTable1. accesstothegamecode,andonewherenorulesare
provided. SeeAppendixCforadditionaldetails.
DataCollection: Ourdatasetisderivedfromthe
open BYTESIZED32 corpus (Wang et al., 2023), 2.3 Evaluation
which consistsof 32human-authored text games
Performance on LLM-Sim is determined by the
thateachsimulateadifferentscientificorcommon-
modelâ€™spredictionaccuracyw.r.t. thegroundtruth
sense reasoning concept. We first modify each
labelsoveradatasetoftestsamples. Dependingon
BYTESIZED32 game to dump the game state
theexperimentalcondition,theLLMmustmodel
(s ,r ,d )aswellasitsintermediatestatesact at
t t t t+1 object properties (when simulating F , F , or
each time step t as a JSON object. We hold out act env
F)and/orgameprogress(whensimulatingF or
one game as an example and seed our dataset of R
F),definedas:
transitions by first following the gold-label goal-
followingtrajectoryprovidedwitheachgame. We ObjectProperties: alistofallobjectsinthegame,
thendeterministicallycollecteveryvalidtransition alongwitheachobjectâ€™sproperties(e.g.,tempera-
thatisatmostonestepawayfromthegold-label ture,size)andrelationshipstootherobjects(e.g.,
trajectorybyqueryingthegameforthesetofvalid beingwithinorontopofanotherobject).
actionsateachstep. GameProgress: thestatusoftheagentw.r.t. the
overallgoal,consistingofthecurrentaccumulated
Additional Context: Each game also includes a
reward, whether the game has terminated, and
contextmessage,c,thatprovidesadditionalinfor-
whethertheoverallgoalhasbeenachieved.
mationtothemodel. Thecontextconsistsoffour
WenotethatineachcasetheLLMisprovided
parts: actionrulesdescribingtheeffectofeachac-
with the ground truth previous state (when func-
tiononthegamestate,objectrulesdescribingthe
tionsasF thepreviousstateissact )aswellas
meaningofeachobjectpropertyandwhetherthey env t+1
the overall task context. That is to say, the LLM
are affected by the gameâ€™s underlying dynamics,
alwaysperformsasingle-stepprediction.
scoringrulesdescribinghowanagentearnsreward
and the conditions under which the game is won
3 Experiments
or lost, and one or two example transitions (see
Appendix B for details) from the held-out game Figure 1 demonstrates how we evaluate the per-
mentionedabove. Foreachgamewegeneratethree formanceofamodelontheLLM-SimtaskusingGame Avg.Annotator GPT-4 somemajorobservationsbelow:
bath-tub-water-temperature 0.99 0.60 Predicting action-driven transitions is easier
clean-energy 0.50 0.35
thanpredictingenvironment-driventransitions:
take-photo 0.83 0.00
metal-detector 0.86 0.50 At best, GPT-4 is able to simulate 77.1% of dy-
mix-paint 0.85 0.50
namic action-driven transitions correctly. In con-
Average 0.80 0.49 trast,GPT-4simulatesatmost49.7%ofdynamic
environment-driven transitions correctly. This in-
Table4: Comparisonbetweenaccuracyofhumanannotators
andGPT-4onasubsetoftheBYTESIZED32-SPdataset.Tran- dicatesthatthemostchallengingpartoftheLLM-
sitionsweresampledtonormalizeGPT-4performanceat50% Simtaskislikelysimulatingtheunderlyingenvi-
(ifpossible)andannotatorsweretaskedwithmodelingthe
ronmentaldynamics.
completetransitionfunctionF andoutputtingthefullstate.
Predicting static transitions is easier than dy-
in-context learning. We evaluate the accuracy of
GPT-4inboththeFullStateandStateDifference namic transitions: Unsurprisingly, modeling a
static transition is substantially easier than a dy-
prediction regimes. The model receives the pre-
namic transition across most conditions. While
viousstate(encodedasa JSON object),previous
theLLMneedstodeterminewhetheragiveninitial
action,andcontextmessage,itproducesthesubse-
stateandactionwillresultinastatechangeineither
quent state (eitheras a complete JSON object or
case, dynamic transitions also require simulating
asadiff). SeeAppendixAfordetails.
thedynamicsinexactlythesamewayastheunder-
We note that the transition dynamics between
lyinggameenginebyleveragingtheinformation
statesdependprimarilyontheverbusedintheac-
tion (e.g., take, put, cook, ...). In addition, some inthecontextmessage.
state-actionpairsdonotresultinanychangestoob-
Predictingfullgamestatesiseasierfordynamic
jectpropertiesorgameprogress. Toensurebalance
states,whereaspredictingstatedifferenceiseas-
acrosstheseconditions(andincreasethetractabil-
ierforstaticstates: Predictingthestatedifference
ity of our experiments), we sub-sample a dataset
for dynamic state significantly improves the per-
D fromthefullBYTESIZED32-SP set. Formally,
formance(>10%)ofsimulatingstatictransitions,
lets betheinputstateofasimulatorfunctionand
in whiledecreasestheperformancewhensimulating
s be the output state of the simulator function
out dynamic transitions. This may be because state
(e.g. s = s and s = sact for F ). We call
in t out t+1 act differencepredictionisaimedatreducingpotential
anytransitioninwhichs = s (accordingtothe
out in format errors. However, GPT-4 is able to get the
ground-truth)staticandcalleachothertransition
responseformatcorrectinmostcases,whileintro-
dynamic. Notethattheenvironment-driventransi-
ducingthestatedifferenceincreasesthecomplexity
tion following a dynamic action-driven transition
oftheoutputformatofthetask.
isnotnecessarilydynamic. Forexample,astatein
Gamerulesmatter,andLLMsareabletogen-
which the agent takes an apple while the remain-
erategoodenoughgamerules: Performanceof
ing objects in the environment remain the same
GPT-4onallthreesimulationtasksdropsinmost
is a dynamic action-driven transition and a static
conditionswhengamerulesarenotprovidedinthe
environment-driventransition. WeconstructD by
contextmessage. However,wefailtofindobvious
randomlysampling10dynamictransitionsand10
performancedifferencesbetweengamerulesgen-
statictransitionsfrom BYTESIZED32-SP foreach
eratedbyhumanexpertsandbyLLMsthemselves.
possibleactionverb(takingasmanyaspossibleif
fewerthan10exist)w.r.taction-driventransitions. GPT-4canpredictgameprogressinmostcases:
Theresultingexperimentaldatasetconsistsof2954 Table 3 presents the results of GPT-4 predicting
transitiontuples. game progress. With game rules information in
thecontext,GPT-4canpredictthegameprogress
4 Results
correctlyin92.1%testcases. Thepresenceofthese
Table 2 presents the accuracy of GPT-4 simulat- rulesincontextiscrucial: withoutthem,GPT-4â€™s
ing the whole state transitions as well as its ac- predictionaccuracydropsto61.5%.
curacyofsimulatingaction-driventransitionsand
Humans outperform GPT-4 on the LLM-Sim
environment-driven transitions alone.2 We report
task: Weprovideapreliminaryhumanstudyonthe
2SeeAppendixEfortheresultsofGPT-3.5. LLM-Simtask. Inparticular,wetakethe5gamescorrect value incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
Figure 2: Simulation performance of whole state transition (top), action-driven transitions (middle) and
environment-driven transitions (bottom) as a function of the property being modified, in the GPT-4, full state
prediction,withhumanwrittenrulescondition. Thex-axisrepresentsspecificobjectproperties,andy-axisrepre-
sentsperformance(0-100%). Errorsarebrokendownintoincorrectvalueandunalteredvalue. RefertoTable7for
themeaningofeachproperty.
fromthe BYTESIZED32-SPdatasetinwhichGPT- the property is not changed in its corresponding
4 produced the worst accuracy at modeling F . condition). We observe that GPT-4 is able to
act
Foreachgame,werandomlysample20gameswith handlemostsimplebooleanvaluepropertieswell.
theaimofhaving10transitionswhereGPT-4suc- Theerrorsareconcentratedonnon-trivialproper-
ceededand10transitionswhereGPT-4failed(note tiesthatrequiresarithmetic(e.g.,temperature,
that this is not always possible because on some timeAboveMaxTemp), common-sense (e.g.,
games GPT-4 fails/succeeds on most transitions). current_aperture, current_focus), or
Inaddition,webalanceeachsetof10transitions scientific knowledge (e.g., on). We also ob-
to have 5 dynamic transitions and 5 static transi- serve that when predicting the action-driven and
tions. Weinstructfourhumanannotators(4authors environment-driven transitions in a single step,
of this paper) to model as F using the human- GPT-4 tends to focus more on action-driven tran-
act
generatedrulesascontextinafullgamestatepre- sitions, resulting in more unaltered value errors
dictionsetting. ResultsarereportedinTable4. The onstatesthatitcanpredictcorrectlywhensolely
overall human accuracy is 80%, compared to the simulatingenvironment-driventransitions.
sampledLLMaccuracyof50%,andthevariation
amongannotatorsissmall. Thissuggeststhatwhile 5 Conclusion
ourtaskisgenerallystraightforwardandrelatively
We propose BYTESIZED32-State-Prediction, a
easy for humans, there is still a significant room
benchmarkof76,369virtualtextenvironmentstate
forimprovementforLLMs.
transitionsfortestingLLMsassimulators. Weeval-
GPT-4 is more likely to make an error when uate GPT-4 on this world modeling task. Across
arithmetic,common-sense,orscientificknowl- models and conditions, the best recorded perfor-
edgeisneeded: Becausemosterrorsoccurinmod- manceis59.9%onaccuratelysimulatingstatetran-
elingdynamictransitions,weconductanadditional sitions that involve non-trivial changes. Because
analysis to better understand failure modes. We simulationerrorsaccumulateacrosssteps,asimu-
use the setting with the best performance on dy- latorwithmodestsingle-stepaccuracyhaslimited
namictransitions(GPT-4,Human-writtencontext, utilityinpracticeâ€“forexample,after10steps,av-
full state prediction) and further break down the eragesimulationaccuracywouldreduceto0.59910,
resultsaccordingtothespecificobjectproperties orlessthan1%. OurresultsindicatethatLLMsare
that are changed during the transition. Figure 2 notyetabletoreliablyactastextworldsimula-
shows,forthewholestatetransitions,action-driven tors. FurthererroranalysisshowsthatwhileLLMs
transitions,andenvironment-driventransitions,the arebetteratsimulatingtheresultsofuseractions,it
proportion of predictions that are either correct, isdifficultforLLMstohandleenvironment-driven
set the property to an incorrect value, or fail to transitionsandtransitionsthatrequirearithmetic,
changethepropertyvalue(emptycolumnsmeans commonsense,orscientificknowledge.6 LimitationsandEthicalConcerns OurworkhighlightstheissuewithusingLLMsas
text-basedworldsimulators. Indownstreamtasks,
6.1 Limitations
suchasgamesimulation,LLMsmaygeneratemis-
Thisworkconsiderstwostrongin-contextlearning leadingornon-factualinformation. Forexample,
LLMs,GPT-3.5andGPT-4,intheirabilitytoactas if the simulator suggests burning a house to boil
explicitformalsimulators.Weadoptthesemodels water, our work does not prevent this, nor do we
becausetheyaregenerallythemostperformantoff- evaluatetheethicalimplicationsofsuchpotentially
the-shelf models across a variety of benchmarks. dangerous suggestions. As a result, we believe
While we observe that even GPT-3.5 and GPT-4 such applications are neither suitable nor safe to
achieveamodestscoreattheproposedtask,weac- bedeployedtoasettingwheretheydirectlyinter-
knowledgethatwedidnotexhaustivelyevaluatea act with humans, especially children, e.g., in an
largeselectionoflargelanguagemodels,andother educationalsetting. Weurgeresearchersandprac-
modelsmayperformbetter. Weprovidethiswork titionerstouseourproposedtaskanddatasetina
asabenchmarktoevaluatetheperformanceofex- mindfulmanner.
istingandfuturemodelsonthetaskofaccurately
Acknowledgements
simulatingstatespacetransitions.
In this work, we propose two representational
Wewishtothankthethreeanonymousreviewers
formalismsforrepresentingstatespaces,onethat
for their helpful comments on an earlier draft of
includesfullstatespace,whiletheotherfocuseson
thispaper.
statedifference,bothrepresentedusingJSONob-
jects. Wehavechosentheserepresentationsbased
on their popularity and compatibility with the in- References
put and output formats of most LLM pretraining
JoshAchiam,StevenAdler,SandhiniAgarwal,Lama
data(e.g.Fakhouryetal.,2023),aswellasbeing Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
abletodirectlycompareagainstgoldstandardsim- DiogoAlmeida,JankoAltenschmidt,SamAltman,
ShyamalAnadkat,etal.2023. Gpt-4technicalreport.
ulator output for evaluation, though it is possible
arXivpreprintarXiv:2303.08774.
that other representational formats may be more
performantatthesimulationtask. AshutoshAdhikari,XingdiYuan,Marc-AlexandreCÃ´tÃ©,
MikulÃ¡Å¡Zelinka, Marc-AntoineRondeau, Romain
Finally, the state spaces produced in this work
Laroche,PascalPoupart,JianTang,AdamTrischler,
arefocusedaroundthedomainofcommon-sense
andWillHamilton.2020. Learningdynamicbelief
andearly(elementary)scientificreasoning. These graphstogeneralizeontext-basedgames. Advances
tasks,suchasopeningcontainersoractivatingde- inNeuralInformationProcessingSystems,33:3045â€“
3057.
vices, were chosen because the results of these
actions are common knowledge, and models are Prithviraj Ammanabrolu and Matthew Hausknecht.
likely to be most performant in simulating these 2020. Graph constrained reinforcement learning
for natural language action spaces. arXiv preprint
actions. While this work does address a selec-
arXiv:2001.08837.
tionoflessfrequentactionsandproperties,itdoes
not address using LLMs as simulators for highly Marc-AlexandreCÃ´tÃ©,ÃkosKÃ¡dÃ¡r,XingdiYuan,Ben
Kybartas,TavianBarnes,EmeryFine,JamesMoore,
domain-specificareas,suchasphysicalormedical
Ruo Yu Tao, Matthew Hausknecht, Layla El Asri,
simulation. A long term goal of this work is to
MahmoudAdada,WendyTay,andAdamTrischler.
facilitateusinglanguagemodelsassimulatorsfor 2018. Textworld: Alearningenvironmentfortext-
high-impactdomains,andweviewthisworkasa basedgames. CoRR,abs/1806.11532.
stepping-stone to developing progressively more
SarahFakhoury,SaikatChakraborty,MadanMusuvathi,
capablelanguagemodelsimulators. andShuvenduKLahiri.2023. Towardsgenerating
functionallycorrectcodeeditsfromnaturallanguage
6.2 EthicalConcerns issuedescriptions. arXivpreprintarXiv:2304.03816.
We do not foresee an immediate ethical or soci- AngelaFan,JackUrbanek,PratikRingshia,EmilyDi-
etalimpactresultingfromourwork. However,we nan, Emma Qian, Siddharth Karamcheti, Shrimai
acknowledgethatasanLLMapplication,thepro- Prabhumoye,DouweKiela,TimRocktaschel,Arthur
Szlam, and Jason Weston. 2020. Generating inter-
posed LLM-Sim task could be affected in some
active worlds with text. Proceedings of the AAAI
way by misinformation and hallucinations intro-
ConferenceonArtificialIntelligence,34(02):1693â€“
duced by the specific LLM selected by the user. 1700.Shibo Hao, Yi Gu, Haodi Ma, Joshua Hong, Zhen of the 2022 Conference on Empirical Methods in
Wang, Daisy Wang, and Zhiting Hu. 2023. Rea- NaturalLanguageProcessing,pages11279â€“11298.
soningwithlanguagemodelisplanningwithworld
model. In Proceedings of the 2023 Conference on RuoyaoWang,GrahamTodd,XingdiYuan,ZiangXiao,
EmpiricalMethodsinNaturalLanguageProcessing, Marc-AlexandreCÃ´tÃ©,andPeterJansen.2023. Byte-
pages8154â€“8173. Sized32: Acorpusandchallengetaskforgenerating
task-specificworldmodelsexpressedastextgames.
MatthewHausknecht,PrithvirajAmmanabrolu,Marc- In Proceedings of the 2023 Conference on Empiri-
AlexandreCÃ´tÃ©,andXingdiYuan.2020. Interactive calMethodsinNaturalLanguageProcessing,pages
fictiongames: Acolossaladventure. InProceedings 13455â€“13471,Singapore.AssociationforComputa-
of the AAAI Conference on Artificial Intelligence, tionalLinguistics.
volume34,pages7903â€“7910.
LionelWong,GabrielGrand,AlexanderKLew,NoahD
PeterJansen.2022. Asystematicsurveyoftextworlds Goodman, Vikash K Mansinghka, Jacob Andreas,
asembodiednaturallanguageenvironments. InPro- andJoshuaBTenenbaum.2023. Fromwordmod-
ceedingsofthe3rdWordplay:WhenLanguageMeets els to world models: Translating from natural lan-
GamesWorkshop(Wordplay2022),pages1â€“15. guagetotheprobabilisticlanguageofthought. arXiv
preprintarXiv:2306.12672.
Leslie Pack Kaelbling, Michael L Littman, and An-
thony R Cassandra. 1998. Planning and acting in
partially observable stochastic domains. Artificial
intelligence,101(1-2):99â€“134.
Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu,
Shiqi Zhang, Joydeep Biswas, and Peter Stone.
2023. Llm+ p: Empowering large language mod-
elswithoptimalplanningproficiency. arXivpreprint
arXiv:2304.11477.
Kolby Nottingham, Prithviraj Ammanabrolu, Alane
Suhr, Yejin Choi, Hannaneh Hajishirzi, Sameer
Singh, and Roy Fox. 2023. Do embodied agents
dreamofpixelatedsheep: Embodieddecisionmak-
ingusinglanguageguidedworldmodelling. InIn-
ternationalConferenceonMachineLearning,pages
26311â€“26325.PMLR.
Mohit Shridhar, Xingdi Yuan, Marc-Alexandre CÃ´tÃ©,
Yonatan Bisk, Adam Trischler, and Matthew
Hausknecht.2020. Alfworld: Aligningtextandem-
bodiedenvironmentsforinteractivelearning. arXiv
preprintarXiv:2010.03768.
HaoTang,DarrenKey,andKevinEllis.2024. World-
coder,amodel-basedllmagent:Buildingworldmod-
elsbywritingcodeandinteractingwiththeenviron-
ment. arXivpreprintarXiv:2402.12275.
Jack Urbanek, Angela Fan, Siddharth Karamcheti,
Saachi Jain, Samuel Humeau, Emily Dinan, Tim
RocktÃ¤schel, Douwe Kiela, Arthur Szlam, and Ja-
son Weston. 2019. Learning to speak and act in a
fantasytextadventuregame.
KarthikValmeekam,MatthewMarquez,SarathSreed-
haran, and Subbarao Kambhampati. 2023. On the
planning abilities of large language models-a criti-
cal investigation. Advances in Neural Information
ProcessingSystems,36:75993â€“76005.
NickWalton.2020. HowwescaledAIDungeon2to
supportover1,000,000users.
RuoyaoWang,PeterJansen,Marc-AlexandreCÃ´tÃ©,and
Prithviraj Ammanabrolu. 2022. Scienceworld: Is
youragentsmarterthana5thgrader? InProceedingsA Modeldetails Object Rule Generation Prompt
YouwillbegivenaPythonclasswhichdefinesanobjectinatext
game.Listtheclassesinheritedbythisclassandexplainthe
For the GPT-3.5 model, we use the propertiesoftheobjectbasedonyourunderstandingofthecode.
Thepropertiesyouneedtoexplainarecommentedascritical
gpt-3.5-turbo-0125model. FortheGPT-4 propertiesintheinitfunction.Iftheclasscontainsatickmethod
function,youshouldalsodecribehowtheobjectpropertieswillbe
model, we use the gpt-4-0125-preview changedateachgametick.Otherwise,donotexplainany
model. For both models, the temperature is set property.Yourresponseshouldfollowtheformatoftheexample
below:
to 0 to get deterministic results. We also turn on Hereisthecodefortheexample:
{OBJECT_CLASS_CODE}
the JSON mode of both models, which ensures Theexpectedoutputis:
Object:Stove
that the model gives a valid JSON response.
Inherits:Container,Device
Our experiments cost approximately $5,000 for Properties:
maxTemperature:themaximumtemperatureofthestovein
OpenAIAPIusage. degreesCelsius
tempIncreasePerTick:thetemperatureincreasespertickfor
objectsonthestoveifthestoveison.
Nowhereisanotherobjectclassthatneedsyoutoexplain:
{OBJECT_CLASS_CODE}
B Gametransitionexamples
For action rules generation, we prompt GPT-4
(gpt-4-0125-preview) with the code of the
Wemanuallypickthewash-clothesgameinBYTE-
whole game, but unlike object rules, we do not
SIZED32 astheexamplegameasitcontainsboth
offeranyin-contextexample. WeaskGPT-4tode-
statetransitionsdrivenbyactionsandgameâ€™sunder-
scribeeachoftheactionsinthegame. Belowisan
lyingdynamics. Intaskswherethemodelpredicts
exampleofourpromptforactionrulegeneration:
action transition, environment-driven transitions,
or the game progress alone, we provide one cor-
Action Rule Generation Prompt
responding in-context example. In the task that
YouwillbegivenaPythonprogramwhichdefinesanatextgame.
requiresthemodeltopredicteverything,weoffer Describetheallactionsbasedonyourunderstandingofthecode.
Youcanfindallactionslistedinthecommentsatthebeginningof
two in-context examples in the prompt. The two
theprogram.Youshoulddescribeallconstraintsofeachaction
examplesaremanuallypickedsuchthatinoneex- andhowgamestateswillbechangedbytakingeachaction.
Hereisthecodeofthegame:
ample the game state is changed directly by the {GAME_CODE}
actiontakenwhileintheotherexamplethegame
Similartoactionrules,wegeneratescorerules
stateischangedbythegameâ€™sunderlyingdynam-
bypromptingGPT-4(gpt-4-0125-preview)
ics.
with the code of the game and ask GPT-4 to de-
scribehowthegamecanbewonorloseandhow
rewardscanbeearned. Belowisanexampleofour
C Gamerulesgeneration
promptforscorerulegeneration:
Score Rule Generation Prompt
C.1 LLMgeneratedrules
YouwillbegivenaPythonprogramwhichdefinesanatextgame.
Describehowthegamecanbewonorlose,andhowgamescores
canbeearnedbasedonyourunderstandingofthe
ForLLMgeneratedrules,wemanuallycheckall calculateScorefunctionintheTextGameclass.
Hereisthecodeofthegame.Donotdescribethemainfunction.
ofthemtoavoidmisinformationandoffensivecon-
{GAME_CODE}
tent.
C.2 Human-WrittenActionRules
WepromptGPT-4(gpt-4-0125-preview)
with the code of each object class to acquire the The action rules describe how each action can
rulesofeachobject. Wealsoprovideonein-context changethegamestates. Theexpertannotatorreads
example. WeaskGPT-4todescribethemeaning the game description and source code for each
of each critical property (i.e. properties that do game. Theywentthroughthelistofavailableac-
notinheritfromparent)oftheobjectandthetick tionsinthegameandtheircorrespondingfunctions
functionoftheobject(i.e. afunctionthatdefines inthegame. Eachactionrulehasthreemainparts:
how object properties may change at each time Action,Description,andRules. TheActionspec-
step regardless of the action taken). Below is an ifies the name of the action (e.g., action). The
exampleofourpromptofobjectrulegeneration: Descriptionexplainsthegeneralpurposeoftheac-tion(e.g.,connecttwoobjectswithinputterminals). D.1 PromptExample: F
act
TheRulesisanunorderedlistofruledescriptions
D.1.1 FullStatePrediction
thatdescribetheconstraintsoftheactionwhenin-
teractingwithdifferentobjects(e.g.,Atleastone
Full State Prediction Prompt (F )
act
oftheobjectsshouldbeawireoramultimeter)or
Youareasimulatorofatextgame.Readthetaskdescriptionofa
how the rule might function under different con- textgame.GiventhecurrentgamestateinJSON,youneedto
ditions (e.g., Disconnect terminal if the terminal decidethenewgamestateaftertakinganaction.
YourresponseshouldbeinthesameJSONformatasthegiven
is already connected to other objects). To ensure gamestate.
Hereisanexample:
accuracy,theannotatorplaysthroughthegameand Examplegametaskdescription:
Yourtaskistowashthedirtydishes.
checks if the written object rules were correctly
Herearethedescriptionsofallgameobjectspropertiesinthe
reflectedinthegameplay. examplegame:
{OBJECT_RULES}
Herearethedescriptionsofallgameactionsintheexamplegame:
C.3 Human-WrittenObjectRules
{ACTION_RULES}
Hereisthegamestate:
Theobjectrulesdescribethemeaningofeachob- {GAME_STATE}
Theactiontotakeisputplate(ID:5)indirtycup(ID:4)
jectproperty(e.g.,temperature,size,weight,etc.) Theexpectedresponseis:
{GAME_STATE}
and how they will be changed at each time step.
Hereisthegamethatyouneedtosimulate:
The expert annotators read the game description TaskDescription:
Yourtaskistofigureouttheweightofthecube.Usetheanswer
andsourcecodeforeachgame. Theywentthrough actiontogiveyouranswer.
Herearethedescriptionsofallgameobjectsproperties:
theobjectclassesinthecodescriptandwrotethe
{OBJECT_RULES}
objectrules. Eachobjectrulehasthreemainparts: Herearethedescriptionsofallgameactions:
{ACTION_RULES}
Object, Description, and Properties. The Object Hereisthegamestate:
{GAME_STATE}
specifiesthenameoftheobject. TheDescription Theactiontotakeis:
look
explains the general purpose of the object (e.g.,
GarbageCanisacontainerthatcanholdgarbage).
D.1.2 StateDifferencePrediction
In the Description, the inheritance of the object
class has been noted. The Properties is an un-
State Difference Prediction Prompt (F )
act
orderedlistofpropertydescriptionsthatdescribe
Youareasimulatorofatextgame.Readthetaskdescriptionofa
eachpropertyofthatobject(e.g., AMoldhasits
textgame.GiventhecurrentgamestateinJSON,youneedto
shape.) andtheirdefaultvalue(e.g.,Bydefault,a decidethenewgamestateaftertakinganaction.
YourresponseshouldbeintheJSONformat.Itshouldhavetwo
GameObjectisnotcombustible.) iftheobjectisan keys:â€™modifiedâ€™andâ€™removedâ€™.Theâ€™modifiedâ€™keystoresalistof
alltheobjectstatesthatareaddedorchangedaftertakingthe
abstractclass. Forobjectswithtickfunction,there
action.Keepitanemptylistifnoobjectisaddedormodified.Theâ€™
isanotherpropertydescribinghowanobjectmay removedâ€™keystoresalistofuuidsoftheobjectsthatareremoved.
Keepitanemptylistifnoobjectisremoved.
change under each tick. To ensure accuracy, the Hereisanexample:
Examplegametaskdescription:
annotatorplaysthroughthegameandchecksifthe Yourtaskistowashthedirtydishes.
writtenobjectruleswerecorrectlyreflectedinthe Herearethedescriptionsofallgameobjectspropertiesinthe
examplegame:
gameplay. {OBJECT_RULES}
Herearethedescriptionsofallgameactionsintheexamplegame:
{ACTION_RULES}
C.4 Human-WrittenScoreRules
Hereisthegamestate:
{GAME_STATE}
Scorerulesdescribetheconditionstowinorlose Theactiontotakeisputplate(ID:5)indirtycup(ID:4)
Theexpectedresponseis:
thegameandhowrewardscanbeearned. Anex- {GAME_STATE_DIFFERENCE}
pert annotator (one of the BYTESIZED32 game Hereisthegamethatyouneedtosimulate:
TaskDescription:
authors)createstherulesbyreadingthegamede- Yourtaskistofigureouttheweightofthecube.Usetheanswer
actiontogiveyouranswer.
scriptionandthecodeofthescorefunction. Herearethedescriptionsofallgameobjectsproperties:
{OBJECT_RULES}
Herearethedescriptionsofallgameactions:
D Prompts {ACTION_RULES}
Hereisthegamestate:
{GAME_STATE}
Theactiontotakeis:
The prompts introduced in this section includes
look
gamerulesthatcaneitherbehumanwrittenrules
orLLMgeneratedrules. Forexperimentswithout
gamerules,wesimplyremovetherulesfromthe
correspondingprompts.D.2 PromptExample: F D.3 PromptExample: F (GameProgress)
env R
D.2.1 FullStatePrediction
Game Progress Prediction Prompt (F )
R
Full State Prediction Prompt (F )
env Youareasimulatorofatextgame.Readthetaskdescriptionofa
textgame.GiventhecurrentgamestateinJSON,youneedto
Youareasimulatorofatextgame.Readthetaskdescription. predictthecurrentgamescore,whetherthegameisover,and
GiventhecurrentgamestateinJSON,youneedtodecidehow whethertheagentwinsthegame.
thegamestatechangesinthenexttimestep(withoutconsidering YourresponseshouldbeaJSONwiththreekeys:â€™scoreâ€™,â€™
theagentactions).Rulesforsuchchangesaredescribedasthe gameOverâ€™,andâ€™gameWonâ€™.â€™scoreâ€™storesthecurrentgamescore,
tickfunctionofeachobject. â€™gameOverâ€™storesaboolvalueonwhetherthegameisover,andâ€™
YourresponseshouldbeinthesameJSONformatasthegiven gameWonâ€™storesaboolvalueonwhetherthegameiswon.
gamestate. Hereisanexample:
Hereisanexample: Examplegametaskdescription:
Examplegametaskdescription: Yourtaskistowashthedirtydishes.
Yourtaskistowashthedirtydishes. Herearethedescriptionsofallgameobjectspropertiesinthe
Herearethedescriptionsofallgameobjectspropertiesinthe examplegame:
examplegame: {OBJECT_RULES}
{OBJECT_RULES} Hereisadescriptionofthegamescorefunction:
Hereisthegamestate: {SCORE_RULES}
{GAME_STATE} Hereisthepreviousgamestate:
Theexpectedresponseis: {GAME_STATE}
{GAME_STATE} Thegamescoreofthepreivousstateis:
Hereisthegamethatyouneedtosimulate: {â€™scoreâ€™:âˆ’1,â€™gameOverâ€™:False,â€™gameWonâ€™:False}
TaskDescription: Theactiontotakeisusedishsoap(ID:12)onglass(ID:8)
Yourtaskistofigureouttheweightofthecube.Usetheanswer {GAME_STATE}
actiontogiveyouranswer. Theexpectedresponseis:
Herearethedescriptionsofallgameobjectsproperties: {â€™scoreâ€™:3,â€™gameOverâ€™:True,â€™gameWonâ€™:True}
{OBJECT_RULES} Hereisthegamethatyouneedtosimulate:
Hereisthegamestate: TaskDescription:
{GAME_STATE} Yourtaskistofigureouttheweightofthecube.Usetheanswer
actiontogiveyouranswer.
Herearethedescriptionsofallgameobjectsproperties:
D.2.2 StateDifferencePrediction
{OBJECT_RULES}
Hereisadescriptionofthegamescorefunction:
{SCORE_RULES}
State Difference Prediction Prompt (F env) Hereisthepreviousgamestate:
{GAME_STATE}
Youareasimulatorofatextgame.Readthetaskdescription. Thegamescoreofthepreivousstateis:
GiventhecurrentgamestateinJSON,youneedtodecidehow {â€™scoreâ€™:0,â€™gameOverâ€™:False,â€™gameWonâ€™:False}
thegamestatechangesinthenexttimestep(withoutconsidering Theactiontotakeis:
theagentactions).Rulesforsuchchangesaredescribedasthe look
tickfunctionofeachobject. Hereisthecurrentgamestateaftertakingtheaction:
YourresponseshouldbeintheJSONformat.Itshouldhavetwo {GAME_STATE}
keys:â€™modifiedâ€™andâ€™removedâ€™.Theâ€™modifiedâ€™keystoresalistof
alltheobjectstatesthatareaddedorchangedaftertakingthe
action.Keepitanemptylistifnoobjectisaddedormodified.Theâ€™
removedâ€™keystoresalistofuuidsoftheobjectsthatareremoved.
Keepitanemptylistifnoobjectisremoved.
Hereisanexample:
Examplegametaskdescription:
Yourtaskistowashthedirtydishes.
Herearethedescriptionsofallgameobjectspropertiesinthe
examplegame:
{OBJECT_RULES}
Hereisthegamestate:
{GAME_STATE}
Theexpectedresponseis:
{GAME_STATE_DIFFERENCE}
Hereisthegamethatyouneedtosimulate:
TaskDescription:
Yourtaskistofigureouttheweightofthecube.Usetheanswer
actiontogiveyouranswer.
Herearethedescriptionsofallgameobjectsproperties:
{OBJECT_RULES}
Hereisthegamestate:
{GAME_STATE}D.4 PromptExample: F D.4.2 StateDifferencePrediction
D.4.1 FullStatePrediction
State Difference Prediction Prompt (F)
Full State Prediction Prompt (F) Youareasimulatorofatextgame.Readthetaskdescriptionand
thecurrentenvironmentobservationdescription.Giventhecurrent
Youareasimulatorofatextgame.Readthetaskdescriptionofa gamestatein\textsc{JSON},youneedtodecidethenewgame
textgame.GiventhecurrentgamestateinJSON,youneedto stateaftertakinganaction.
decidethenewgamestateaftertakinganactionincludingthe Yourresponseshouldbeinthe\textsc{JSON}format.Itshould
gamescore. havethreekeys:â€™modifiedâ€™,â€™removedâ€™,andâ€™scoreâ€™.Theâ€™modifiedâ€™
Youmayneedtocreatenewobjectswhenyoupredictthenew keystoresalistofalltheobjectstatesthatareaddedorchanged
gamestate.Youshouldassigntheuuidofnewobjectsstarting aftertakingtheaction.Keepitanemptylistifnoobjectisaddedor
fromtheUUIDbasegivenintheinstructions.Yourresponseshould modified.Theâ€™removedâ€™keystoresalistofuuidsoftheobjects
beinthesameJSONformatasthegivengamestate. thatareremoved.Keepitanemptylistifnoobjectisremoved.
Notethatwhilegamestatescanbechangedbyactions,some Theâ€™scoreâ€™keystoresadictionarywiththreekeys:â€™scoreâ€™isthe
gamestatesmaychangeoverthetime,whichisdescribedinthe currentgamescore,â€™gameOverâ€™isabooleanofwhetherthegame
tickfunctionofeachobjectclass. isover,andâ€™gameWonâ€™isabooleanofwhethertheagentwonthe
Herearetwoexamplesofbothcases.Bothexamplesarefromthe game.Ifaplayerearnsascoreorwins/losesthegame,you
sameexamplegame. shouldreflectthatchangeinthedictionarysavedundertheâ€™scoreâ€™
Examplegametaskdescription: key.Otherwise,youshouldsetvalueoftheâ€™scoreâ€™keytoan
Yourtaskistowashthedirtydishes. emptydictionary.Notethatwhilegamestatescanbechangedby
Herearethedescriptionsofallgameobjectspropertiesinthe actions,somegamestatesmaychangeoverthetime,whichis
examplegame: describedinthetickfunctionofeachobjectclass.
{OBJECT_RULES} Notethatwhilegamestatescanbechangedbyactions,some
Herearethedescriptionsofallgameactionsintheexamplegame: gamestatesmaychangeoverthetime,whichisdescribedinthe
tickfunctionofeachobjectclass.
{ACTION_RULES} Herearetwoexamplesofbothcases.Bothexamplesarefromthe
Hereisadescriptionofthescorefunctionoftheexamplegame: sameexamplegame.
{SCORE_RULES} Examplegametaskdescription:
Inthefirstexample,thegamestateischangedbyanaction: Yourtaskistowashthedirtydishes.
Hereisthegamestate: Herearethedescriptionsofallgameobjectspropertiesinthe
{GAME_STATE} examplegame:
ThecurrentgameUUIDbaseis12 {OBJECT_RULES}
Theactiontotakeis:putplate(ID:5)indirtycup(ID:4) Herearedescriptionsofallgameactionsintheexamplegame:
Theexpectedresponseis: {ACTION_RULES}
{GAME_STATE} Hereisadescriptionofthescorefunctionoftheexamplegame:
Inthesecondexamplefromthesameexamplegame,thegame {SCORE_RULES}
stateischangedoverthetime.Notethatwhileinthisexamplethe Inthefirstexample,thegamestateischangedbyanaction:
gamestateischangedbytimeonly,itispossiblethatagame Currentobservation:
stateischangedbybothanactionandtime. {GAME_OBSERVATION}
Hereisthegamestate: Hereisthegamestate:
{GAME_STATE} {GAME_STATE}
ThecurrentgameUUIDbaseis13 Theactiontotakeisputdirtyplate(ID:5)inmug(ID:6)
Theactiontotakeis:eatdishwasher(ID:2)withdirtyplate(ID:5) Theexpectedresponseis:
Theexpectedresponseis: {GAME_STATE_DIFFERENCE}
{GAME_STATE} Inthesecondexamplefromthesameexamplegame,thegame
Hereisthegamethatyouneedtosimulate: stateischangedoverthetime.Notethatwhileinthisexamplethe
{OBJECT_RULES} gamestateischangedbytimeonly,itispossiblethatagame
Herearethedescriptionsofallgameactions: stateischangedbybothanactionandtime.
{ACTION_RULES} Currentobservation:
Hereisadescriptionofthegamescorefunction: {Example_2observation}
{SCORE_RULES} Hereisthegamestate:
Hereisthegamestate: {GAME_STATE}
{GAME_STATE} Theactiontotakeiseatdishwasher(ID:2)withdirtyplate(ID:5)
ThecurrentgameUUIDbaseis12 Theexpectedresponseis:
Theactiontotakeis: {GAME_STATE_DIFFERENCE}
look Hereisthegamethatyouneedtosimulate:
TaskDescription:
Yourtaskistoboilwater.
Herearethedescriptionsofallgameobjectsproperties:
{OBJECT_RULES}
Herearethedescriptionsofallgameactions:
{ACTION_RULES}
Hereisadescriptionofthescorefunctionofthegame:
{SCORE_RULES}
Currentobservation:
{GAME_OBSERVATION}
Hereisthegamestate:
{GAME_STATE}
ThecurrentgameUUIDbaseis12
Theactiontotakeis:
lookD.5 OtherExamples State F F F
act env
Rules Change Full Diff Full Diff Full Diff
Belowisanexampleoftheruleofanaction:
dynamic 34.5 21.4 36.0 31.7 7.8 2.9
LLM
static 37.5 54.0 44.6 65.9 41.8 63.1
Action Rule Example
dynamic 26.8 21.2 43.3 36.1 12.5 0.4
Human
put: static 35.6 58.9 42.3 64.7 22.0 74.2
Description:putanobjectintoatargetcontainer
Rules: dynamic 15.4 23.5 43.8 35.7 1.7 0.8
Norule
1.Thetargetmustbeacontainer(Container) static 26.9 50.0 35.2 63.0 17.2 54.8
2.Thetargetcontainermustbeopen
3.Theobjectmustbeintheinventory
4.Theobjectmustbemoveable(isMoveable) Table5: AverageaccuracypergameofGPT-3.5predicting
thewholestatetransitions(F)aswellasaction-driventran-
sitions(F )andenvironment-driventransitions(F ). We
Belowisanexampleoftheruleofanobject: act env
reportsettingsthatuseLLMgeneratedrules,humanwritten
rules, or no rules. Dynamic and static denote whether the
Object Rule Example gameobjectpropertiesandgameprogressshouldbechanged;
Fullanddiffdenotewhetherthepredictionoutcomeisthefull
Object:Container gamestateorstatedifferences.Numbersshowninpercentage.
Description:Abstractclassforthingsthatcanbeconsideredâ€™
containersâ€™(e.g.adrawer,abox,atable,ashelf,etc.)
Properties:
âˆ’AContainerisacontainer. Rules GameProgress
âˆ’AContainercouldbeopened(e.g.,e.g.adrawer,adoor,abox,
etc.),orisitalwaysâ€™openâ€™(e.g.atable,ashelf,etc.). LLM 73.9
âˆ’AContainerhasapropertyindicatingifitisopened.
âˆ’AContainerhasapropertyindicatingtheprefixtousewhen Human 63.3
referringtothecontainer(e.g."inthedrawer","onthetable",etc.).
Norule 64.2
Bydefault,theprefixisâ€™inâ€™
Table6: GPT-3.5gameprogresspredictionresults
Belowisanexampleofthescorerule:
Score Rule Example
Belowisanexampleofa JSON thatdescribes
Theplayerwinsthegamebygettingalldishesclean. thedifferenceoftwogamestates:
Theplayergetsonepointforeachdishthatiscleaned.
Theplayerlosesonepointforeachdishthatismadedirty.
Game State Difference Example
Belowisanexampleofagamestate: {â€™modifiedâ€™:[{â€™nameâ€™:â€™agent(ID:0)â€™,â€™uuidâ€™:0,â€™typeâ€™:â€™Agentâ€™,â€™
propertiesâ€™:{â€™isContainerâ€™:True,â€™isMoveableâ€™:True,â€™isOpenableâ€™:
False,â€™isOpenâ€™:True,â€™containerPrefixâ€™:â€™inâ€™},â€™containsâ€™:[â€™mug(ID:
Game State Example 6)â€™,â€™knife(ID:7)â€™]},{â€™nameâ€™:â€™mug(ID:6)â€™,â€™uuidâ€™:6,â€™typeâ€™:â€™Dishâ€™,â€™
propertiesâ€™:{â€™isContainerâ€™:True,â€™isMoveableâ€™:True,â€™isOpenableâ€™:
{â€™game_stateâ€™:[{â€™nameâ€™:â€™agent(ID:0)â€™,â€™uuidâ€™:0,â€™typeâ€™:â€™Agentâ€™,â€™ False,â€™isOpenâ€™:True,â€™containerPrefixâ€™:â€™inâ€™,â€™dishTypeâ€™:â€™mugâ€™,â€™
propertiesâ€™:{â€™isContainerâ€™:True,â€™isMoveableâ€™:True,â€™isOpenableâ€™: isDirtyâ€™:True,â€™foodMessNameâ€™:â€™sandwhichâ€™},â€™containsâ€™:[â€™plate(ID:
False,â€™isOpenâ€™:True,â€™containerPrefixâ€™:â€™inâ€™},â€™containsâ€™:[â€™plate(ID: 5)â€™]}],â€™removedâ€™:[],â€™scoreâ€™:{}}
5)â€™,â€™mug(ID:6)â€™,â€™knife(ID:7)â€™]},{â€™nameâ€™:â€™plate(ID:5)â€™,â€™uuidâ€™:5,â€™
typeâ€™:â€™Dishâ€™,â€™propertiesâ€™:{â€™isContainerâ€™:True,â€™isMoveableâ€™:True,â€™
isOpenableâ€™:False,â€™isOpenâ€™:True,â€™containerPrefixâ€™:â€™onâ€™,â€™dishType E GPT-3.5results
â€™:â€™plateâ€™,â€™isDirtyâ€™:True,â€™foodMessNameâ€™:â€™orangeâ€™},â€™containsâ€™:[]},{â€™
nameâ€™:â€™mug(ID:6)â€™,â€™uuidâ€™:6,â€™typeâ€™:â€™Dishâ€™,â€™propertiesâ€™:{â€™
isContainerâ€™:True,â€™isMoveableâ€™:True,â€™isOpenableâ€™:False,â€™isOpen Table 5 and Table 6 shows the performance of a
â€™:True,â€™containerPrefixâ€™:â€™inâ€™,â€™dishTypeâ€™:â€™mugâ€™,â€™isDirtyâ€™:True,â€™
foodMessNameâ€™:â€™sandwhichâ€™},â€™containsâ€™:[]},{â€™nameâ€™:â€™knife(ID:7) GPT-3.5 simulator predicting objects properties
â€™,â€™uuidâ€™:7,â€™typeâ€™:â€™Dishâ€™,â€™propertiesâ€™:{â€™isContainerâ€™:True,â€™
and game progress respectively. There is a huge
isMoveableâ€™:True,â€™isOpenableâ€™:False,â€™isOpenâ€™:True,â€™
containerPrefixâ€™:â€™inâ€™,â€™dishTypeâ€™:â€™knifeâ€™,â€™isDirtyâ€™:True,â€™ gapbetweentheGPT-4performanceandGPT-3.5
foodMessNameâ€™:â€™apple(ID:11)â€™},â€™containsâ€™:[]},{â€™nameâ€™:â€™
dishwasher(ID:2)â€™,â€™uuidâ€™:2,â€™typeâ€™:â€™DishWasherâ€™,â€™propertiesâ€™:{â€™ performance, providing yet another example of
isContainerâ€™:True,â€™isMoveableâ€™:False,â€™isOpenableâ€™:True,â€™isOpen
â€™:True,â€™containerPrefixâ€™:â€™inâ€™,â€™isDeviceâ€™:True,â€™isActivatableâ€™:True,â€™ how fast LLM develops in the two years. It is
isOnâ€™:False,â€™cycleStageâ€™:0,â€™finishedCycleâ€™:False},â€™containsâ€™:[â€™ alsoworthnoticesthattheperformancedifference
cup(ID:4)â€™]},{â€™nameâ€™:â€™cup(ID:4)â€™,â€™uuidâ€™:4,â€™typeâ€™:â€™Dishâ€™,â€™
propertiesâ€™:{â€™isContainerâ€™:True,â€™isMoveableâ€™:True,â€™isOpenableâ€™: islargerwhennorulesisprovided,indicatingthat
False,â€™isOpenâ€™:True,â€™containerPrefixâ€™:â€™inâ€™,â€™dishTypeâ€™:â€™cupâ€™,â€™
isDirtyâ€™:True,â€™foodMessNameâ€™:â€™peanutbutterâ€™},â€™containsâ€™:[]},{â€™ GPT-3.5 is especially weak at applying common
nameâ€™:â€™bottleofdishsoap(ID:3)â€™,â€™uuidâ€™:3,â€™typeâ€™:â€™DishSoapBottle
senseknowledgetothisfew-shotworldsimulation
â€™,â€™propertiesâ€™:{â€™isContainerâ€™:False,â€™isMoveableâ€™:True,â€™isDeviceâ€™:
True,â€™isActivatableâ€™:True,â€™isOnâ€™:False},â€™containsâ€™:[]},{â€™nameâ€™:â€™ task.
glass(ID:8)â€™,â€™uuidâ€™:8,â€™typeâ€™:â€™Dishâ€™,â€™propertiesâ€™:{â€™isContainerâ€™:
True,â€™isMoveableâ€™:True,â€™isOpenableâ€™:False,â€™isOpenâ€™:True,â€™
containerPrefixâ€™:â€™inâ€™,â€™dishTypeâ€™:â€™glassâ€™,â€™isDirtyâ€™:False},â€™containsâ€™: F Histograms
[]},{â€™nameâ€™:â€™bowl(ID:9)â€™,â€™uuidâ€™:9,â€™typeâ€™:â€™Dishâ€™,â€™propertiesâ€™:{â€™
isContainerâ€™:True,â€™isMoveableâ€™:True,â€™isOpenableâ€™:False,â€™isOpen
â€™:True,â€™containerPrefixâ€™:â€™inâ€™,â€™dishTypeâ€™:â€™bowlâ€™,â€™isDirtyâ€™:False},â€™ 1. In Figure 3, we show detailed experimental
containsâ€™:[]},{â€™nameâ€™:â€™banana(ID:10)â€™,â€™uuidâ€™:10,â€™typeâ€™:â€™Foodâ€™,â€™
propertiesâ€™:{â€™isContainerâ€™:False,â€™isMoveableâ€™:True,â€™isFoodâ€™:True}, resultsonthefullstatepredictiontaskper-
â€™containsâ€™:[]},{â€™scoreâ€™:âˆ’1,â€™gameOverâ€™:False,â€™gameWonâ€™:False}]}
formedbyGPT-4.PropertyName Description
buried Objectsburiedintheroom
combustionTimeRemaining Numberoftimestepsremainingtocombustofacombustingobject
connects Electricalobjectsconnectingtothecurrentobject
contains Objectsinthecurrentobject
cook Howaningredientiscooked
current_aperture Currentapertureofacamera
current_focus Theobjectthatthecameraiscurrentlyfocusingon
current_iso CurrentISOofacamera
current_shutter_speed Currentshutterspeedofacamera
cut Howaningredientiscut
cycleStage Thecurrentstageofthewashingmachineâ€™scycle(running/washing/finished).
durability Numberoftimesleftforashoveltodigsomething
finishedCycle Abooleanindicatorofwhetherthewashingmachinehasfinished
food Thefoodlevelofayoungbird.Reduce1iftheyoungbirdisnotfedateachtimestep.
grow Numberoftimestepsthatayoungbirdhasgrown
hatch Numberoftimestepsthataneggishatched
isAboveMaxTemp Whetherthetemperatureofthecurrentfoodisaboveitsmaximumpreservationtemperature
isActivated Whetheradeviceisactivated
isChoppable Whetheranobjectischoppable
isCombusting Whetheranobjectiscombusting
isDirty Whetheradishisdirty
isMoveable Whetherthecurrentobjectismoveable
isOn Whetheradeviceisturnedon
isOpen Whetheracontainerisopen
isWet Whetheraclothesiswet
is_open Whetheradoorisopen
liquid Whetherthereisliquidinacontainer
mode Modeofamultimeter
objects Recordofthenumberoftimestepsthateachobjectisontheinclinedplane
on Whetheralightbulbison
photo Theobjectthatthecamerahastakenapictureof
prefix Prefixabstracttodescribetheobject.E.g.,atreeandsomefirewood
stage Lifestageofabird
stateOfMatter Stateofmatterofasubstance
sunburn Whethertheplayerâ€™sskinisburntbythesun
temperature Objecttemperature
tick Numberofticksthatanobjectisplacedonaninclinedplane
timeAboveMaxTemp Numberoftimestepsthatafoodisaboveitsmaximumpreservationtemperature
use_sunscreen Whethertheplayerhasusedthesunscreen
volume Volumeofanobject
warm Thewarmthreceivedbyaneggduringitshatchingstage
wearSpaceSuit Whethertheagentwearsthespacesuit
Table7: DescriptionofobjectpropertiesmentionedinFigure2
2. In Figure 4, we show detailed experimental
resultsonthestatedifferencepredictiontask
performedbyGPT-4.
3. In Figure 5, we show detailed experimental
resultsonthefullstatepredictiontaskper-
formedbyGPT-3.5.
4. In Figure 6, we show detailed experimental
resultsonthestatedifferencepredictiontask
performedbyGPT-3.5.(a)Human-generatedrules.
correct value incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
(b)LLM-generatedrules.
correct value incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
(c)Norules.
correct value incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
Figure3: GPT-4-FullStatepredictionfroma)Human-generatedrules,b)LLM-generatedrules,andc)Norules.(a)Human-generatedrules.
correct value incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
(b)LLM-generatedrules.
correct value incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
(c)Norules.
correct value incorrect incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
Figure4: GPT-4-Differencepredictionfroma)Human-generatedrules,b)LLM-generatedrules,andc)Norules.(a)Human-generatedrules.
correct value incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
(b)LLM-generatedrules.
correct value incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
(c)Norules.
correct value incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
Figure5: GPT-3.5-FullStatepredictionfroma)Human-generatedrules,b)LLM-generatedrules,andc)Norules.(a)Human-generatedrules.
correct value incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
(b)LLM-generatedrules.
correct value incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
(c)Norules.
correct value incorrect incorrect value unaltered value
100
50
0
100
50
0
100
50
0
buriedco mbc uo sn tin oec nco Ttn is mta ec in Ro s eo mkc au inrr ine gncu t_r are pnc eu t r_ tr f ur oe rcn ec uu t_ sr ir se oncu t_t shc uy ttc ele r_Sd stu par ega eebfi diln itis yhf eo do Cd yg clr eowhatchisAboi vs eA Mct aii v xs a TC eth e mo di p ps pC ao bmi ls ebD ui srt ti y is nM govi esO abn leisOpei ns Wetis_opeliq nuidmodeobjeco tsnphotoprefixstagestateOsu f Mnb au tt te r enm rpt ei rc ak tut ri emeAu bs oe v_ esv u Mo n al su xcm Trw eee ma er
n
pmwearSpaceSuit
Figure6: GPT-3.5-Differencepredictionfroma)Human-generatedrules,b)LLM-generatedrules,andc)Norules.