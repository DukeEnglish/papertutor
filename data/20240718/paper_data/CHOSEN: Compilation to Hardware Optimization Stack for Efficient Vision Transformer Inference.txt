CHOSEN: Compilation to Hardware Optimization Stack for
Efficient Vision Transformer Inference
MohammadErfanSadeghi ArashFayyazi
UniversityofSouthernCalifornia UniversityofSouthernCalifornia
LosAngeles,California,USA LosAngeles,California,USA
sadeghim@usc.edu fayyazi@usc.edu
SuhasSomashekar MassoudPedram
UniversityofSouthernCalifornia UniversityofSouthernCalifornia
LosAngeles,California,USA LosAngeles,California,USA
ssomashe@usc.edu pedram@usc.edu
ABSTRACT ViTsrelyonaseriesofidenticalencoderblockstoprogressively
VisionTransformers(ViTs)representagroundbreakingshiftinma- extractcomplexfeaturesfromanimage.Theseencoderblockscon-
chinelearningapproachestocomputervision.Unliketraditional sistoftwoprincipalcomponents:Multi-headedAttention(MHA)
approaches,ViTsemploytheself-attentionmechanism,whichhas andFeed-ForwardNetwork(FFN),eachprefacedwithalayernor-
beenwidelyusedinnaturallanguageprocessing,toanalyzeimage malizationblock.EmbeddedwithinMHAandFFNarelinearlayers,
patches.Despitetheiradvantagesinmodelingvisualtasks,deploy- GELU,andsoftmax,integratedviatworesidualconnectionsthat
ingViTsonhardwareplatforms,notablyField-ProgrammableGate bookendthenormalizationstages.Theoutputofthefinalencoder
Arrays(FPGAs),introducesconsiderablechallenges.Thesechal- blockgoesthroughaclassifiertoobtaintheclasspredictions.
lengesstemprimarilyfromthenon-linearcalculationsandhigh ImplementingVisionTransformers(ViTs)andothertransformer-
computationalandmemorydemandsofViTs.Thispaperintroduces basedmodelsonField-ProgrammableGateArrays(FPGAs)presents
CHOSEN,asoftware-hardwareco-designframeworktoaddress uniquechallengesthatstemfromthearchitecturesâ€™complexityand
thesechallengesandofferanautomatedframeworkforViTde- resourcedemands.Theprimaryhurdlesincludethehighdemand
ploymentontheFPGAsinordertomaximizeperformance.Our formemoryduetotheextensivenumberofparametersandthe
frameworkisbuiltuponthreefundamentalcontributions:multi- intensivecomputationrequiredforprocessingtheself-attention
kerneldesigntomaximizethebandwidth,mainlytargetingbenefits acrossimagepatches.FPGAs,althoughflexibleandcapableofpar-
ofmultiDDRmemorybanks,approximatenon-linearfunctions allelprocessing,oftenstrugglewithlimitedon-chipmemoryand
thatexhibitminimalaccuracydegradation,andefficientuseofavail- bandwidth,whichcanbottlenecktheperformanceofViTs.Addi-
ablelogicblocksontheFPGA,andefficientcompilertomaximize tionally,thestaticnatureofFPGAarchitecturescomplicatesthe
theperformanceandmemory-efficiencyofthecomputingkernels implementationofthedynamicallyvaryingcomputationalpatterns
bypresentinganovelalgorithmfordesignspaceexplorationto ofViTs.
findoptimalhardwareconfigurationthatachievesoptimalthrough- Awiderangeofmethodshasbeenexploredtoimprovetheeffi-
putandlatency.Comparedtothestate-of-the-artViTaccelerators, ciencyofViTs,includingapproacheslikequantization[6],model
CHOSENachievesa1.5xand1.42ximprovementinthethroughput pruning[7],tokenpruning[8],andlow-rankapproximation[9].
ontheDeiT-SandDeiT-Bmodels. However,deployingViTsinpracticalapplicationsrequiresinnova-
tiveapproachesinhardwareoptimization,suchasstrategicmemory
managementandmulti-kerneldesignforincreasedthroughput.The
CHOSENframeworkintegratesthesestrategieseffectivelyinad-
1 INTRODUCTION
ditiontoitscompilertoofferacompletestackforautomatingthe
Thelandscapeofcomputervisionhasbeenfundamentallytrans- FPGAdeploymentofViTs.Themaincontributionsofthispaper
formed with the advent of deep learning, among which Vision aresummarizedbelow.
Transformers(ViTs)[1â€“4]haveemergedasaparticularlypromis-
ingapproach.Unliketraditionalconvolutionalneuralnetworks
(CNNs)thatrelyonlocalreceptivefields,ViTsleveragethepower â€¢ Wepresentanend-to-endframeworkcalledCHOSEN,which
ofself-attentionmechanismstocaptureglobaldependencieswithin generateshigh-performanceViTacceleratorssuitedtoatarget
animage,enablingamorecomprehensiveunderstandingofvisual FPGAdevicefromahigh-leveldescriptionoftheViTmodelin
data.ThiscapabilityhasplacedViTsattheforefrontofresearch, anymachinelearningframework,suchasPyTorchwhilemaking
demonstratingstate-of-the-artperformanceacrossawiderangeof effectiveuseoftheavailableFPGAresourcesandmemoryband-
tasksincomputervision.Overall,deeplearninghasrevolutionized width.NotethatCHOSENcanhandleanytransformer-based
variousdomainsbyprovidingrobustalgorithmscapableoflearning model,whilethispaperfocusesonViTs.
complexpatternsfromlargedatasets,thusenablingunprecedented â€¢ WedevelopoptimizedsynthesizableC++templates,achieving
advancementsintheapplicationofartificialintelligence[5]across high-throughputacceleratordesignsonFPGAsbyfocusingon
numerous fields, from healthcare to entertainment to scientific multi-kerneldesigntomaximizebandwidthutilizationandkeep
research. all the used resources busy. The CHOSEN ViT follows static
4202
luJ
71
]VC.sc[
1v63721.7042:viXraschedulingandhasadifferentmemorylayoutforeachoperation generatessynthesizableC-levelcodedescriptionsthatcanbeused
toachievefullburstreaddatafromoff-chipmemorybanks. togenerateanFPGAbitstream.
â€¢ Weintroduceapowerfulcompiler(CHOSENCompiler)formap-
pingagiventransformer-basedmodelrunningonanydataset 4 ACCELERATORDESIGNOPTIMIZATIONS
ontoouroptimizedacceleratordesignbyconvertingthenet- Thissectionfocusesonimprovingtheefficiencyandperformance
workmodeltoacomputationalgraph,schedulingthegraphâ€™s ofaViTacceleratorusingFPGAdevice-awareoptimizations.Solu-
execution,andoptimizingitsnodesbyleveragingcombining tionsincludedataplacementoptimizationstoreducethenumber
matricesifwehaveenoughresources. ofaccessestoDRAM,theuseoftheon-chipmemorytobalance
â€¢ Comparedtothestate-of-the-artwork,usingouroptimizations computationvs.memorybandwidth,andapproximationsfornon-
focusedonmulti-kerneldesignandmaximizingbandwidthuti- linearitiesfunctions.
lization,weachievesignificantimprovementinthethroughput.
4.1 KernelArchitecture
2 RELATEDWORK Ouracceleratorisamulti-kerneldesignwhereeachkernelper-
ThissectionincludespriorworksonViTarchitectures,compiler formsthesameoperation.Eachkernelcomprises(i)a1Darrayof
optimizations,andapproximationsofnon-linearfunctions. processingelements(PEs),whichareresponsibleforexecutingthe
MACoperationsassociatedwiththematrixmultiplications,(ii)a
2.1 Compiler memoryhierarchyfeedingdatatothesaid1Darraycompromising
ofregisterfiles,theon-chipmemory(BlockRAMsandUltraRAMs
Previouseffortshaveexploredsoftware-hardwareco-designframe-
onFPGAdevices),andexternaloff-chipmemory(DRAM),and(iii)
worksforefficientlydeployingViTs.TheVAQFframework[10]
aprocessingunit(PU)thatperformsapproximatednon-linearity
dynamicallyadjustsweightsprecision,activationsprecision,and
andotherrequiredoperationsliketheadditionofskipandmain
hardwaresettingsbasedonFPGAresourcesandtargetFPS.ViTCoD
pathsasshowninFig.1
[11]proposesmethodsforpruningandreconfiguringtheattention
FPGA FPGA FPGA FPGA
mapsinViTstocreateeitherdenserorsparserpatterns,whichhelps DDR DDR DDR DDR
Memory Memory Memory Memory
inmanagingcomputationalworkloadsmoreeffectively.However, Bank Bank Bank Bank
bothVAQF[10]andViTCoD[11]donotleverageoff-chip(DDR)
memoryparallelismanddonotintroduceasetofapproximations
forefficientlycalculatingnon-linearfunctionsonFPGAs. Controller & Computing Computing Kernel
Scheduler Kernel
Computing 1D PE array
2.2 Hardwarearchitecture Co Km ep rnu eti lng Co Km ep rnu eti lng
Kernel
Ap np or no -x lii nm ea at re d
ssrreeffffuuBB
SeveralarchitectureshavebeenproposedtoaccelerateVisionTrans- SLR0 SLR1 SLR2 functions
former(ViT)andTransformerinferenceonFPGAs,typicallyem- VU9P
ployingquantizationtechniquesthatreducethemodelsizeand Figure1:OverviewofMulti-kernelCHOSEN-ViTarchitecture
computationalrequirementsbyconvertingweightsandactivations ontheVU9PFPGA.
Forour1DarrayofPEs,weadoptthearchitectureproposedin
to8-bitrepresentationssuchasAuto-ViT-Accpresentedin[12].ME-
[14].Theirarchitectureisusedtoperformefficientmultiplication
ViT[13]isastate-of-the-artViTacceleratorthatmitigatesthehigh- ofAandBmatriceswhereAâˆˆRğ‘›Ã—ğ‘˜ andBâˆˆRğ‘˜Ã—ğ‘š
.Theoutput
bandwidthdemandsofVisionTransformers(ViTs)duringinference matrixisCâˆˆRğ‘›Ã—ğ‘š
.Thecomputationalresourcesareorganized
byemployingasingle-loadpolicyandutilizesmulti-purposebuffers intoğ‘ƒ ğ‘›of1Dprocessingelements,whichencapsulateavectoroper-
withinamemory-efficientprocessingelement(ME-PE)tominimize ationofğ‘ƒ ğ‘šcomputeelements(i.e.,DSPsontheFPGA).Tosupport
memorytrafficforViTacceleratorsonFPGAs.Theyachievethisby
ahierarchicalhardwaredesign,eachmatrixisfurtherdecomposed
avoidingstoringandreloadinginmatrixmultiplicationsandbuffer-
intoseverallevelsoftiling.WetilematrixAandBcolumnand
ingtheintermediateresults.However,ME-ViTdoesnotexplore row-wisewithfactorofğ‘‡ ğ‘›andğ‘‡ ğ‘š,respectively.
multipleDDRbankstoachievehigherbandwidth.
4.2 Non-linearapproximations
3 CHOSENFRAMEWORK
Implementingthenon-linearfunctionsoftheVisionTransformer
CHOSENisacompilationframeworkthatenablestheoptimization (ViT)presentssignificantchallengesduetotheirinherentcomputa-
anddeploymentofViTsonFPGAs.Ittakesahigh-leveldescrip- tionalcomplexity.ToenableanefficientFPGA-basedimplementa-
tionoftheViTmodelspecifiedinPyTorchandgeneratesahigh- tionofViT,weemployedasetofapproximationsfornon-linearities
performanceViTacceleratordesigntailoredtotheFPGAdevice. aspresentedinPEANO-ViT[15].Specifically,theyapproximated
TheCHOSENcompileroptimizestheinferencegraphassociated theinversesquarerootfunctioninlayernormalizationusingbit
withtheViTmodel,aligningitwiththeacceleratordesign.Next, manipulationoperationsandpre-storedfractionalpowersoftwo.
itproduceshardwareparametersfortheacceleratorandastatic Forthesoftmaxfunction,theyutilizedaPadÃ©-basedapproximation
scheduleforexecutingitsvariousoperations.Adetailedexplana- oftheexponentialfunction,complementedbybitmanipulation
tionofthestatespaceexplorationprocessusedtofindtheopti- techniquestoeliminatedivisionoperations.Additionally,theGELU
malhardwareparametersisprovidedinSection5.Finally,using activationfunctionwasreplacedwithapiece-wiselinearapproxi-
optimizedacceleratorcomponenttemplates,CHOSENcompiler mationthatcloselymimicstheoriginalfunction.Thesestrategic
2DDR Banks
approximations not only facilitate the efficient implementation Original Matrix #1 #2 #3 #4
ofViTsonFPGAsbutalsoexhibitnegligibledegradationinthe
modelâ€™saccuracy.WeusedalloftheseapproximationsintheCHO-
Fill in DDR banks
SENViTimplementationtoachievehighthroughputandbalance
usageofDSPandLUTsinourdesign.
4.3 MemoryLayoutandDataPlacement
Toutilizetheoff-chipmemorybandwidth,wegroupactivation
(a)StoringamatrixinfourDDRbanks.
data(A)aswellasweights(B)beforesendingthemtotheon-chip
memory.Forbothmatrices(e.g.,AandB),wegroup(cid:106)ğ´ğ‘‹ğ¼ 2_ Ã—ğ‘Š ğ·ğ¼ ğ‘Šğ·ğ‘‡ğ»(cid:107)
Compute Kernel #1
Softmax
oftheminthecolumndimension.Bythispacking,weperformfull
burst read/write of data from/to the memory banks and utilize
Compute Kernel #2
themaximumpossibleburstsize(512-bitwidth)allowableonthe
AdvancedeXtensibleInterface(AXI)busofthetargetFPGAboard.
Compute Kernel #3
WeuseallavailableDDRbankstoloadandstorethedatatomax-
imizethebandwidth.Wedividetheoriginalmatrixcolumn-wise
intoğµğ‘,whichdenotesthetotalnumberofavailableDDRbanks Compute Kernel #4
andis4inourcase(seeSection6formoredetailsregardingthe
1 2 3 4 5 6 7 8 9 10 11 12
targetFPGAboard),smallermatricesandstoreeachsmallermatrix Cycle
inoneDDRbankasshowninFig.2a.Intheprovidedexample (b)SchedulingforSoftmaxoperations.
showninFig.2,wehave4DDRbanksand4hardwarekernels.For Gelu
operationsoutsideofthehead,likekey,query,valuematrices,and
Compute Kernel #1
Gelucomputations,webringthedatafromthesamerowbutwith
differentDDRbanksandpassthemtodifferenthardwarekernels
Compute Kernel #2
forcomputation(seeFig.2c).Forthehead-wiseoperations,includ-
ingsoftmax,webringthedatafromthesamebankandthesame
row(cid:108) ğµğ‘ ğ‘â„(cid:109)
timestofinishtherequiredcomputationsforonerow
Compute Kernel #3
whereğ‘ â„representsthenumberofheads.Forinstance,inthecase Compute Kernel #4
ofViT-B,ittakesthreeroundstofinisharow,asshowninFig.2b.
WithrespecttolayerNorm,whereeachhardwarekernelrequires 1 2 3 4
Cycle
thewholerowtocompleteitscomputation,suchascalculatingthe
meanandvariance,CHOSENoffersefficientrotatingscheduling (c)SchedulingforLayerNormoperations.
LayerNorm
(seeFig.2d).Hardwarekernel#1operatesonthefirstpartofrow
#1fromDDRbank#1,whilehardwarekernel#2performsonthe Compute Kernel #1
secondpartofrow#2fromDDRbank#2.Similarly,otherkernels
accesscorrespondingdata.Inthenextround,Hardwarekernel#1
Compute Kernel #2
operatesonthesecondpartofrow#1fromDDRbank#2,while
hardwarekernel#2performsonthethirdpartofrow#3fromDDR
Compute Kernel #3
bank#3.Inthisapproach,wemaximizetheutilizationofpotential
bandwidthandkeepallhardwarekernelsbusy. Compute Kernel #4
5 CHOSENCOMPILER 1 2 3 4
Cycle
Thissectionelaboratesonourcompilerframework,designedto (d)SchedulingforGeluoperations.
enhancetheexecutionefficiencyoftransformermodelsonFPGAs. Figure2:Schedulingofdifferentoperationswhileusingmultiple
ThecompileradeptlyutilizestheunderlyingFPGAarchitecture, DDRbanks.DifferentpatternsrepresentdifferentDDRmemory
focusingonoptimalscheduling,preciseoperationmappingtohard- banks,whiledifferentcolorsrepresentdifferentrows.
wareresources,andminimizingthedatamovement,therebyfacili-
(1) ModelConversion:Initially,thetransformermodel,developed
tatinghigh-performanceVitaccelerationhardwareonFPGAs.
usingframeworkssuchasPyTorchorTensorFlowistransformed
intoaDirectedAcyclicGraph(DAG).Thisgraphoutlinesthe
5.1 CompilerDesignandExecutionFramework
modelâ€™scomputationaldependenciesanddataflow,providinga
Ourcompilerframeworkstartswithahigh-leveldescriptionofa basisforfurtheranalysisandoptimization.
ViTmodelandconvertsitintoahardware-acceleratedimplementa- (2) GraphAnalysisandOptimization:Thecompilerconductsan
tiontailoredtothetargetFPGAâ€™sarchitecture.Thetransformation in-depthanalysisoftheDAGtoclassifyoperationsanddeduce
ofaViTmodelintoanFPGA-compatibleformatunfoldsthrough essentialcharacteristicssuchasoperationtypes,datasizes,and
severalsteps,asexplainedbelow. dependencychains.Thisinformationiscrucialforoptimizingthe
3executionscheduleandeffectivelymappingtheoperationsonto Algorithm1ExhaustiveSearchforFindingOptimalTileParame-
theFPGA.ItisworthmentioningthattheCHOSENCompilercan ters
optimizeitsnodesbyleveragingcombiningmatricesifwehave 1: Input:ModelGraphğº,DataWidthğ·ğ‘Š,MemoryConstraints
enoughresources.Forinstance,wecancalculateğ‘˜matrixinone ğ‘€
shotandthenseparateitcolumn-wiseforeachheadorcalculate 2: Output:Optimaltilesizesğ‘‡ ğ‘›,ğ‘‡ ğ‘š,ParallelismFactorsğ‘ƒ ğ‘›,ğ‘ƒ ğ‘š
khead-wiseandnamethemğ‘˜_â„matrices.Ifwehaveenough 3: Initializeminimumcost:min_costâ†âˆ
wre es io gu hr tc mes ato rn iceth se oft ğ‘˜ar ,g ğ‘e ,t anF dPG ğ‘£A to, iw ne crec aa sn ee tv he en sec co on nc dat de in ma et ne st ioh ne 4: Calculateğ‘ƒ ğ‘š:ğ‘ƒ ğ‘š â† (cid:106)ğ´ğ‘‹ğ¼ 2_ Ã—ğ‘Š ğ·ğ¼ ğ‘Šğ·ğ‘‡ğ»(cid:107) //Fixedvaluebasedon
datawidth
wof eth cae nse ic no cn red am seat tr hi ex bto ata cc hhi se iv zeep toot ae cn ht ii ea vll ey ph oig teh ne tr iğ‘‡ ağ‘š lly.I hn igp har ea rl ğ‘‡le ğ‘›l,
.
5 6:
:
S foet ro ğ‘‡p ğ‘šti âˆˆm {a fl_ eap sm ibâ† leğ‘‡ğ‘ƒ ğ‘šğ‘š
sizes}do
(3)
A Dl el so igf nth Se pse acc eas Ee xs pre losu ralt tii on nla :r Tg he er cd oe msi pg in les rp aa sc se e.
ssesvarioushard-
7: forğ‘ƒ ğ‘› âˆˆ{feasibleğ‘ƒ ğ‘›sizes}whereğ‘ƒ ğ‘› < ğ‘‡ ğ‘ƒğ‘š
ğ‘š
do
8: forğ‘‡ ğ‘› âˆˆ{feasibleğ‘‡ ğ‘›sizes}do
wareconfigurationsandoperationalparametersusingacustom
9:
Cost:costâ†compute_cost(ğ‘ƒ ğ‘›,ğ‘ƒ ğ‘š,ğ‘‡ ğ‘›,ğ‘‡ ğ‘š,ğº,ğ‘€)
heuristic-based algorithm for design space exploration. This
10:
ifcost<min_costthen
phaseascertainstheoptimaltilingandparallelizationstrategies,
11: Updateminimumcostandoptimalsizes:
ensuringtheyalignwithboththehardwareâ€™scapabilitiesand
12: min_costâ†cost
thecomputationaldemandsofthemodel.
13:
optimal_pnâ†ğ‘ƒ
ğ‘›
(4) CodeGenerationandDeployment:Thefinalphaseisthegen-
14:
optimal_tnâ†ğ‘‡
ğ‘›
erationofsynthesizableC++templatesandhardwaredescription
15:
optimal_tmâ†ğ‘‡
ğ‘š
code,culminatingintheproductionoftheFPGAbitstream.This
16: endif
transformationconvertsthehigh-levelsoftwaremodelintoa
17: endfor
practicalhardwareimplementation.
18: endfor
19: endfor
5.2 CompilerOptimizationforMatrix
20:
returnoptimal_pn,optimal_pm,optimal_tn,optimal_tm
Multiplications
Optimizingmatrixmultiplicationforhardwareimplementations
necessitatesafine-grainedanalysisofcomputationalresourcesand feasiblesizeisevaluatedtofindtheoptimalconfigurationof
datamanagement.Thissectiondescribesourapproachtodeter- computeandmemoryresources.
miningoptimaltileparameters,whichiscrucialforenhancingthe (2) ParallelismFactorğ‘ƒ ğ‘›:Reflectsthenumberofprocessingele-
performanceofmatrixmultiplicationcomputations,especiallyin mentsandisconstrainedbyğ‘ƒ ğ‘› < ğ‘‡ ğ‘ƒğ‘š ğ‘š,ensuringthatdataforthe
transformermodels.Wepresentanewalgorithmthatbalancesthe nextroundofcomputationisalreadydistributedtoallPEs.
computationalloadacrossprocessingelementswhileminimizing (3) TilingFactorğ‘‡ ğ‘›:Correspondstothenumberofelementsfrom
memoryaccesslatenciesandmaximizingthroughput. onecolumnofmatrixğ´loadedpercycle,which,whencombined
Thealgorithmforcomputingoptimaltileparameters,aspre- withğ‘‡ ğ‘š,shouldnotexceedthetotalmemorycapacityğ‘†asğ‘‡ ğ‘›Ã—
sentedinAlgorithm1,outlinesasystematicapproachtoidentifying ğ‘‡ ğ‘š â‰¤ğ‘†.
themosteffectivetilingandparallelizationstrategies.Thealgorithm
5.2.3 CostFunctionforOptimizingMultipleMatrixMultiplications.
exploresadesignspacedefinedbytheconstraintsoftheavailable
Inoptimizingtransformermodels,particularlyformatrixmulti-
hardwareresources,thepropertiesofthematrixoperation,and
plicationswithinattentionmechanisms,thisfunctionisdesigned
thecompilerâ€™shigh-levelunderstandingofthetransformermodel
tominimizelatencybybalancingthecomputationalloadacross
representedasaDirectedAcyclicGraph(DAG).
processingelements(PEs)andcomputationunitswithinPEs.The
5.2.1 InitializationandFixedParameters. Theparallelismfactorğ‘ƒ ğ‘š costfunction,Latency,iscalculatedasfollows:
iscomputedasğ‘ƒ ğ‘š = (cid:106)ğ´ğ‘‹ğ¼ 2_ Ã—ğ‘Š ğ·ğ¼ ğ‘Šğ·ğ‘‡ğ»(cid:107) ,establishingafixednumber ğ¿ğ‘ğ‘¡ğ‘’ğ‘›ğ‘ğ‘¦=ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ğ¶ğ‘¦ğ‘ğ‘™ğ‘’ğ‘ 
ofcomputationunitsbasedonthedataandAXIwidth.ForDDR4 ğ¹ğ‘Ÿğ‘’ğ‘ğ‘¢ğ‘’ğ‘›ğ‘ğ‘¦
memory,aminimumof512bitsasAXIwidthmustbetransferred ğ‘‡ ğ‘›Ã—ğ‘‡ ğ‘šÃ—ğ‘˜Ã—ğ‘›ğ‘¢ğ‘šğ‘‡ğ‘–ğ‘™ğ‘’ğ‘ ğ‘…ğ‘œğ‘¤Ã—ğ‘›ğ‘¢ğ‘šğ‘‡ğ‘–ğ‘™ğ‘’ğ‘ ğ¶ğ‘œğ‘™Ã—ğ‘˜ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘™ğ¹ğ‘ğ‘ğ‘¡ğ‘œğ‘Ÿ
=
tomakeupfortheI/Oclockmultiplier,andmuchlongerburstsare ğ‘ƒ ğ‘›Ã—ğ‘ƒ ğ‘šÃ—ğ¹ğ‘Ÿğ‘’ğ‘ğ‘¢ğ‘’ğ‘›ğ‘ğ‘¦
requiredtosaturateDDRbandwidthinpractice. (1)
Whereğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ğ¶ğ‘¦ğ‘ğ‘™ğ‘’ğ‘ isthetotalnumberofcyclesrequiredtoperform
5.2.2 ExplorationofTilingParameters. Theexplorationoftilesizes allmultiplicationoperations.ğ¹ğ‘Ÿğ‘’ğ‘ğ‘¢ğ‘’ğ‘›ğ‘ğ‘¦istheoperatingfrequency
ğ‘‡ ğ‘› andğ‘‡ ğ‘š andtheparallelismfactorğ‘ƒ ğ‘› isconductedwithinfea- ofthehardwareaccelerator.
siblerangesdeterminedbythehardwarespecificationsandthe Thecalculationofğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ğ¶ğ‘¦ğ‘ğ‘™ğ‘’ğ‘ includesotherparametersthat
natureofthematrixoperations.Thenestedloopsinthealgorithm areoutlinedinthefollowing.i)ComputationofTotalOperations:
reflectanexhaustivesearchwithintheseranges,ensuringthateach Thetotaloperationsrequiredforamatrixmultiplicationbetween
combinationofğ‘‡ ğ‘›,ğ‘‡ ğ‘š,andğ‘ƒ ğ‘›isevaluatedforitsperformance: matricesğ´andğµaredeterminedbythetilesizesğ‘‡ ğ‘›andğ‘‡ ğ‘š,andthe
(1) TilingFactorğ‘‡ ğ‘š:Representsthenumberofelementsfromone dimensionsofthematricesinvolved.Wemodeledthiscalculationas:
rowofmatrixğµ thatareloadedintothecomputeunits.Each ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™ğ‘‚ğ‘ğ‘  =ğ‘œğ‘ğ‘ ğ‘ƒğ‘’ğ‘Ÿğ‘‡ğ‘–ğ‘™ğ‘’Ã—ğ‘›ğ‘¢ğ‘šğ‘‡ğ‘–ğ‘™ğ‘’ğ‘ ğ‘…ğ‘œğ‘¤Ã—ğ‘›ğ‘¢ğ‘šğ‘‡ğ‘–ğ‘™ğ‘’ğ‘ ğ¶ğ‘œğ‘™,whereeach
4tileâ€™soperations,ğ‘œğ‘ğ‘ ğ‘ƒğ‘’ğ‘Ÿğ‘‡ğ‘–ğ‘™ğ‘’ =ğ‘‡ ğ‘›Ã—ğ‘‡ ğ‘šÃ—ğ‘˜,whereğ‘ â„ğ‘ğ‘Ÿğ‘’ğ‘‘ğ·ğ‘–ğ‘šğ‘’ğ‘›ğ‘ ğ‘–ğ‘œğ‘› Algorithm2CHOSENâ€™sAlgorithmforFindingOptimalTilePa-
denotedasğ‘˜istheinnerdimensionsharedbetweenmatricesğ´and rameters
ğµ.ğ‘›ğ‘¢ğ‘šğ‘‡ğ‘–ğ‘™ğ‘’ğ‘ ğ‘…ğ‘œğ‘¤(ğ‘›ğ‘¢ğ‘šğ‘‡ğ‘–ğ‘™ğ‘’ğ‘ ğ¶ğ‘œğ‘™)definehowmanytilesmatrixA(B)
1:
Input:ViTModelGraphğº,DataWidthğ·ğ‘Š,FPGAMemory
aredividedintoalongitsrows(columns).Thisequationreflects Constraintsğ‘€
themultiplicationoperationsneededtocomputetheproductof 2: Output:Optimaltilesizesğ‘‡ ğ‘›,ğ‘‡ ğ‘š,ParallelismFactorsğ‘ƒ ğ‘›,ğ‘ƒ ğ‘š
submatricesdefinedbythetiles. 3: Initializesetsize:set_size
ii)DistributionofOperationsAcrossHardwareResources:The 4: Numberofiterations:iterations
divisionofğ‘¡ğ‘œğ‘¡ğ‘ğ‘™ğ‘‚ğ‘ğ‘ byğ‘ƒ ğ‘›andğ‘ƒ ğ‘š reflectsthedistributionofoper- 5: Preservationsize:preservation_size
ationsacrossmultipleprocessingelements(PEs)andcomputation 6: Calculateğ‘ƒ ğ‘š:ğ‘ƒ ğ‘š â† (cid:106)ğ´ğ‘‹ğ¼ 2_ Ã—ğ‘Š ğ·ğ¼ ğ‘Šğ·ğ‘‡ğ»(cid:107) //Fixedvalue
units(CU),respectively:
7:
Extractspecificlayerinformationfromğº
ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™ğ‘‚ğ‘ğ‘ 
ğ‘ğ‘‘ğ‘—ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘‘_ğ‘ğ‘¦ğ‘ğ‘™ğ‘’ğ‘  = Ã—ğ‘˜ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘™ğ¹ğ‘ğ‘ğ‘¡ğ‘œğ‘Ÿ 8: InitializesetwithrandomconfigurationstailoredtoFPGAspecs
ğ‘ƒ ğ‘›Ã—ğ‘ƒ ğ‘š 9: foriteration=1toiterationsdo
Whereğ‘ƒ ğ‘›(ğ‘ƒ ğ‘š)isthenumberofprocessingelements(computation 10: Evaluateperformanceofeachconfigurationintermsof
unitsperprocessingelement). latency
Thisdivisioniscriticalbecauseitensuresthatthecomputational 11: Preservehigh-performanceconfigurationsbasedonlatency
loadisbalancedacrossallavailablehardwareresources,thereby improvements
optimizingtheutilizationoftheFPGAâ€™sresourcesandminimizing 12: Generatenewsetbyadaptivestrategy
thecomputationtime. 13: Replaceoldsetwiththenewone
iii)AdjustmentforMulti-Kernel:Theğ‘˜ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘™ğ¹ğ‘ğ‘ğ‘¡ğ‘œğ‘Ÿ incorporates 14: endfor
themulti-kernelnatureofdesignedarchitecture,particularlyperti- 15: Bestconfigurationâ†configurationfromthefinalsetwiththe
nentfordevicesliketheXilinxUltraScale+FPGA.Fortransformer lowestlatency
models,wherematrixmultiplicationisperformedwithinmultiple 16: returnoptimal_pn,optimal_pm,optimal_tn,optimal_tm
attentionheads,thisparameteriscalculatedasfollows:
(cid:40) âŒˆ num_heads âŒ‰ ifhead_flagistrue
ğ‘˜ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘™ğ¹ğ‘ğ‘ğ‘¡ğ‘œğ‘Ÿ = num_kernels
1 otherwise
num_kernels
ii)PerformanceEvaluation:Eachconfigurationâ€™seffectiveness
Thisadjustmentisnecessarytoalignthecomputationalloadwith
ismeasuredspecificallybyitsimpactonlatencyreductioninViT
thephysicaldistributionofcomputationalresourcesacrossdifferent
applications.iii)EvaluationCache:Storeslatencyresultsofpre-
kernelsintheFPGA,ensuringefficientdatadistributionandparallel
viously tested configurations to avoid redundant computations,
processing.
optimizingtherefinementprocess.iv)RefinementandPreserva-
Theexhaustivesearchapproachtodeterminingoptimaltilepa-
tion:Ensuresconfigurationsyieldingthebestlatencyresultsare
rameters,asdescribedintheAlgorithm1,exploresallpotential
combinations ofğ‘‡ ğ‘›,ğ‘‡ ğ‘š, ğ‘ƒ ğ‘›, and ğ‘ƒ ğ‘š that satisfy hardware con- carriedforward.v)AdaptiveRefinementStrategy:Prioritizesad-
straints.Thenumberofvalidconfigurationscanbeexceedingly justmentsinparameterssuchasğ‘ƒ ğ‘›andğ‘‡ ğ‘š ,whichareempirically
linkedtobetterperformanceinthecurrentapplication,guidingthe
highinpracticalscenarios.Forinstance,evenforsmallmodelslike
settowardspotentiallyoptimalregionsofthedesignspace.
ViTTinyonXilinxUltraScale+VU9PFPGA,wehaveapproximately
Ourapproachsignificantlyreducesthenumberofevaluations
116,144validcombinationsoftilingparameters,anditcangoup
required.Forinstance,inthecaseofViTTiny,theproposedalgo-
to586,554validcombinationsforViTSmallonthesameFPGA.
rithmconvergedtotheoptimalconfigurationwithapproximately
Evaluatingthecostforeachofthesecombinationsdemandsexten-
2,000evaluations,whileforViTSmall,around3,700evaluations
sivecomputationalresourcesandtime,resultinginasignificant
werenecessary.Thisrepresentsadrasticreductioncomparedtothe
overheadonthecompiler.
potentialmillionsofevaluationsrequiredbyanexhaustivesearch,
5.3 CHOSENAlgorithmforEfficientDesign demonstratingouralgorithmâ€™sefficiencyinfindingnear-optimal
solutionswithinamuchsmallercomputationalbudget.
SpaceExploration
To address the inefficiencies of the exhaustive search, a novel
6 RESULTSANDDISCUSSIONS
heuristic-basedsearchalgorithmisproposedtoreducethenumber
ofevaluationpointsrequiredtoconvergetoanoptimalsolution. Inthisstudy,CHOSEN-ViTâ€™shardwaremodelwasimplemented
Algorithm2isspecificallytailoredtooptimizetilingparametersfor on a Xilinx UltraScale+ VU9P board running at 200 MHz. This
deployingVisionTransformers(ViTs)onFPGAplatforms,address- FPGAdeviceincludes64GiBDDR4ECC-protectedmemorywith
ingconstraintssuchaslimitedmemoryandparallelprocessing.The adedicatedPCIex16connection.TherearefourDDRbanks.To
algorithmstartswithasetofrandomlygeneratedtilingparameters evaluatetheperformanceofCHOSEN-ViT,weemployedthepub-
thatfitwithintheFPGAâ€™sspecifications.Ittheniterativelyrefines liclyavailableImageNet-1Kdataset[16]andtwodifferentmodel
theseparameterstominimizelatencyforViTinference. architectures,namelyDeiT[2]andViT[4],acrossvarioussizes
Thekeycomponentsofourimplementationare:i)InitialParam (small,base,andlarge).Itisimportanttopointoutthatourexperi-
Set Creation: Parameters are generated within feasible ranges mentalsetupdoesnotrequireextensiveretrainingfortheproposed
specific to FPGA constraints, ensuring a diverse starting point. approximations.
5Figure 3: Efficiency comparison between exhaustive and
CHOSENsearchmethodsacrossdifferentViTmodels.
Figure5:ParetofrontiercomparisonforViTSmallmodel.
Table1:HardwaremetricsforDeiT-BImplementation.
HWDesign HWModule BRAM36 URAM DSP LUT FF
Auto-Vit-Acc[12] - - - 2066 128K -
ME-PE 288 - 1024 192K 137K
ME-ViT[13]
MultiME-PE 1440 - 5120 960K 685K
1DPEarray 180 192 848 101K 73K
Controller&Scheduler 120 0 9 11K 8K
CHOSEN-ViT
Non-linearfunctions 0 0 116 17K 15K
Total 1440 192 6225 833K 607K
ensuresthatthecompilerâ€™sresourcesarenotwastedonevaluating
Figure4:ParetofrontiercomparisonforfViTTinymodel.
sub-optimalconfigurations.
6.1 ComparisonofCHOSENâ€™sAlgorithmtothe
6.3 HardwareCost
ExhaustiveSearch
Table1detailsthehardwaremetricsachievedbyimplementing
Theproposedalgorithmforfindingthehardwareparametersgreatly
CHOSEN-ViT.Byutilizingtherapidandhardware-compatibleap-
improvedthesearchperformancecomparedtoexhaustivesearch
proximationsintroducedbyPEANO-ViT[15],theresourceusage
methods.TheleftgraphinFigure3depictsadecreaseinthenumber
associatedwithhardware-intensiveandcostlyiterativemethods
ofevaluationcasesrequiredbytheproposedmethodcompared
forexactnon-linearimplementationhasbeengreatlydiminished.
totheexhaustivesearch.Thisreductionisconsistentacrossall
Furthermore,Table1providestheresourceutilizationbreakdown
modelsizes,highlightingourproposedapproachâ€™sabilitytotarget
foreachmoduleineachcomputingkernelofCHOSEN-ViT.Please
optimalconfigurationsmoredirectlyandwithfewercomputations.
notethatthehardwaremetricsforDeiT-Baseimplementationare
Similarly,therightgraphinFigure3showsasubstantialdecrease
reported.Weusedeightcomputingkernelsinparallel.Inprocess-
inexecutiontimesfortheproposedmethod.
ingnon-linearfunctionssuchasnormalization,softmax,andGELU,
6.2 EffectivenessofCHOSENCompiler wesimultaneouslyhandle16elements,resultinginaLevelofParal-
lelism(LoP)of16.ThisLoPcanbeadjustedtoalignwithresource
Inthissection,weassessedtheeffectivenessoftheCHOSENâ€™salgo-
availabilityandlatencyobjectives,makingCHOSENaversatile
rithminfindingtheoptimalparametersforthebestperformance
frameworkforenhancingthespeedofmachinelearningtasks.In-
ofourinferenceengine.Theproposedalgorithmdemonstratessub-
creasingtheLoPorthenumberofcomputingkernelsenhances
stantialeffectivenessinoptimizingtransformermodels,particularly
processingspeedbutmayleadtohigherresourceconsumption.As
initsabilitytoidentifyParetooptimalevaluationpointswithfewer
canbeseen,ourimplementationcanusehigherDSPnumbersfor
evaluatedpointscomparedtoexhaustivemethods.Thiscapability
thematrix-matrixmultiplicationwhilehavingfewerLUTsandFFs
isillustratedintheplotsforViTTinyandViTSmallmodels,as
duetotheproposedapproximations.
depictedinFigs.4and5.
Paretofrontier,representedbythemagentalineintheplots,
6.4 PerformanceComparisonwiththe
connectspointsthatofferthebesttrade-offbetweenlatencyand
State-of-the-ArtViTAccelerators
parallelism.Theproposedapproachcapturesnearlyalltheexhaus-
tivesearchâ€™sPareto-optimalpoints,demonstratingitsefficiency. WecomparetheperformanceobtainedbyCHOSENondifferent
Theproposedalgorithmsignificantlyreducesthenumberofevalua- ViTmodelswiththoseofthepriorwork.Tohavemeaningfuland
tions,focusingonlyonconfigurationspotentiallyleadingtooptimal faircomparisons,wecompareourresultsonlywithworksthathave
outcomes.Thistargetedexplorationisevidentinthedensityof usedthesameorasimilarFPGAboardasours,withcomparable
pointsalongtheParetofrontiercomparedtothebroaderscatter resources.Table2showstheperformancecomparisonbetween
oftheexhaustivepoints.Byfocusingthesearcharoundthemost CHOSEN-ViT and prior work references on ViT models on the
promisingareasofthesolutionspace,theCHOSENâ€™salgorithm ImageNetdataset.CHOSEN-ViToutperformsthestate-of-the-art
6Table2:PerformanceComparison&CHOSEN-ViTConfigu-
[13] KyleMarinoetal.ME-vit:Asingle-loadmemory-efficientFPGAacceleratorfor
ration. visiontransformers.In30thIEEEHiPC2023,pages213â€“223.IEEE,2023.
[14] JohannesdeFineLichtetal.Flexiblecommunicationavoidingmatrixmultipli-
ViTModel HardwareDesign ğ‘ƒğ‘› ğ‘ƒğ‘š ğ‘‡ğ‘› ğ‘‡ğ‘š FPS cationonFPGAwithhigh-levelsynthesis.InFPGAâ€™20,pages244â€“254.ACM,
2020.
ME-ViT[13] - - - - 298â€  [15] MohammadErfanSadeghietal.Peano-vit:Power-efficientapproximationsof
DeiT-T non-linearitiesinvisiontransformers,2024.
CHOSEN-ViT 35 16 210 576 171
[16] JiaDengetal.Imagenet:Alarge-scalehierarchicalimagedatabase.In2009IEEE
ME-ViT[13] - - - - 88 ComputerSocietyConferenceonComputerVisionandPatternRecognition,2009.
DeiT-S
CHOSEN-ViT 99 16 198 1600 132
ME-ViT[13] - - - - 21
DeiT-B Auto-ViT-Acc[12] - - - - 26
CHOSEN-ViT 102 16 212 3072 37
â€ Theyhaveon-chipmemorystorageforweightsandhaveclaimed300Mhzfrequency.
ViT accelerators by delivering 1.5x and 1.42x higher frame-per-
secondonDeiT-SandDeiT-B.CHOSEN-ViTexecutesatafrequency
of200MHz.Atthesametime,ME-ViT[13]reportedafrequencyof
300MHz.ME-ViT[13]delivershigherFPSinthecaseofDeiT-Tas
theycanbringalltheweightsrequiredforthismodelon-chipand
theydonotneedtotilethememoryforthismodelasitmanually
optimized.Instead,CHOSENpresentedanautomatedframework
thatcanbeusedforanytransformer-basedmodelthatisnotlimited
toViTs.
7 CONCLUSION
ThispaperintroducesCHOSEN-ViT,acompiler-to-hardwareopti-
mizationstackfordeployingVisionTransformers(ViTs)onFPGAs.
CHOSENframeworkfeaturesamulti-kernelacceleratorarchitec-
turethatmaximizesbandwidthbyleveragingmultipleDDRmem-
orybanks.TheCHOSENcompilerenhancescomputingkernelper-
formanceandmemoryefficiencywhilemanagingdatamovements
statically.ComparedtoleadingViTaccelerators,CHOSEN-ViTde-
liversthroughputimprovementsof1.5xforDeiT-Sand1.42xfor
DeiT-Bmodels.
REFERENCES
[1] AlexeyDosovitskiyetal. Animageisworth16x16words:Transformersfor
imagerecognitionatscale.In9thICLR,2021.
[2] HugoTouvronetal.Trainingdata-efficientimagetransformers&distillation
throughattention.InProceedingsofthe38thInt.Conf.onMachineLearning,2021.
[3] ArashFayyazietal. Neuroblend:Towardslow-poweryetaccurateneural
network-basedinferenceengineblendingbinaryandfixed-pointconvolutions.
InProceedingsoftheGLSVLSI2024,pages730â€“735.ACM,2024.
[4] ZeLiuetal. Swintransformer:Hierarchicalvisiontransformerusingshifted
windows.In2021IEEE/CVFInternationalConferenceonComputerVision,2021.
[5] BardiaBaraeinejad,MasoodFallahShayan,AmirRezaVazifeh,DibaRashidi,
MohammadSaberiHamedani,HamedTavolinejad,PouyaGorji,ParsaRazmara,
KiarashVaziri,DaryooshVashaee,andMohammadFakharzadeh.Designand
implementationofanultralow-powerECGpatchandsmartcloud-basedplatform.
IEEETrans.Instrum.Meas.,71:1â€“11,2022.
[6] ZhenhuaLiuetal.Post-trainingquantizationforvisiontransformer.InAnnual
ConferenceonNeuralInformationProcessingSystems2021,2021.
[7] FangYuetal.Width&depthpruningforvisiontransformers.InThirty-Sixth
AAAIConferenceonArtificialIntelligence,2022.
[8] JungHwanHeoetal. Training-freeaccelerationofvitswithdelayedspatial
merging,2024.
[9] SeyedarminAzizi,MahdiNazemi,andMassoudPedram.Memory-efficientvision
transformers:Anactivation-awaremixed-rankcompressionstrategy,2024.
[10] MengshuSunetal.VAQF:fullyautomaticsoftware-hardwareco-designframe-
workforlow-bitvisiontransformer.2022.
[11] HaoranYouetal.Vitcod:Visiontransformeraccelerationviadedicatedalgorithm
andacceleratorco-design.InIEEEHPCA2023,pages273â€“286.IEEE,2023.
[12] ZhengangLietal.Auto-vit-acc:Anfpga-awareautomaticaccelerationframework
forvisiontransformerwithmixed-schemequantization.In32ndFPL2022,pages
109â€“116.IEEE,2022.
7