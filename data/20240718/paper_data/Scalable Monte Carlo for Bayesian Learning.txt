Scalable Monte Carlo for Bayesian
Learning
PaulFearnhead,ChristopherNemeth,ChrisJ.OatesandChrisSherlock
4202
luJ
71
]LM.tats[
1v15721.7042:viXraContents
Preface 1
1 Background 4
1.1 MonteCarloMethods 5
1.1.1 WhatisMonteCarloIntegration? 5
1.1.2 ImportanceSampling 7
1.1.3 MonteCarloorQuadrature? 7
1.1.4 ControlVariates 9
1.1.5 MonteCarloIntegrationandBayesianStatistics 11
1.2 ExampleApplications 14
1.2.1 LogisticRegression 15
1.2.2 BayesianMatrixFactorisation 15
1.2.3 BayesianNeuralNetworksforClassification 16
1.3 MarkovChains 17
1.3.1 ReversibleMarkovchains 18
1.3.2 Convergence,Averages,andVariances 19
1.4 StochasticDifferentialEquations 22
1.4.1 TheOrnsteinâ€“UhlenbeckProcess 23
1.4.2 TheInfinitesimalGenerator 24
1.4.3 LangevinDiffusions 26
1.5 TheKernelTrick 28
1.5.1 Finite-DimensionalInnerProductSpaces 28
1.5.2 KernelsinaFinite-DimensionalInnerProductSpace 31
1.5.3 ANewInnerProductandtheKernelTrickinFiniteDimensions 34
1.5.4 GeneralKernels 35
1.5.5 ThePoweroftheKernelTrick 38
1.6 ChapterNotes 40
2 ReversibleMCMCanditsScaling 42
2.1 TheMetropolisâ€“HastingsAlgorithm 43
2.1.1 Component-wiseupdatesandGibbsmoves 48
2.1.2 TheMetropolisâ€“HastingsIndependenceSampler 49
2.1.3 TheRandomWalkMetropolisAlgorithm 50
iiiiv Contents
2.1.4 TheMetropolis-AdjustedLangevinAlgorithm 53
2.2 HamiltonianMonteCarlo 57
2.3 ChapterNotes 63
3 StochasticGradientMCMCAlgorithms 65
3.1 TheUnadjustedLangevinAlgorithm 65
3.2 Approximatevs.ExactMCMC 67
3.3 StochasticGradientLangevinDynamics 69
3.3.1 ControllingStochasticityintheGradientEstimator 72
3.3.2 Example:TheValueofControlVariates 78
3.3.3 ConvergenceResultsforStochasticGradientLangevinDynamics 80
3.4 AGeneralFrameworkforstochasticgradientMCMC 85
3.5 GuidanceforEfficientScalableBayesianLearning 90
3.5.1 ExperimentsonaLogisticRegressionModel 92
3.5.2 ExperimentsonaBayesianNeuralNetworkModel 97
3.6 GeneralisationsandExtensions 100
3.6.1 ScalableInferenceforModelsinConstrainedSpaces 100
3.6.2 ScalableInferencewithTimeSeriesData 102
3.7 ChapterNotes 105
4 Non-ReversibleMCMC 106
4.1 TheBenefitsofNon-Reversibility 106
4.2 HamiltonianMonteCarloRevisited 109
4.3 LiftingSchemesforMCMC 112
4.3.1 Non-ReversibleHMC 112
4.3.2 Gustafsonâ€™sAlgorithmandMultidimensionalGeneralisations 113
4.4 ImprovingNon-reversibility:DelayedRejection 119
4.4.1 TheDiscreteBouncyParticleSampler 121
4.5 ChapterNotes 124
5 Continuous-TimeMCMC 126
5.1 Continuous-TimeMCMCastheLimitofNon-ReversibleMCMC 126
5.2 PiecewiseDeterministicMarkovProcesses 129
5.2.1 WhatisaPDMP? 129
5.2.2 SimulatingPDMPs 130
5.2.3 TheGeneratorandInvariantDistributionofaPDMP 134
5.2.4 TheLimitingProcessofSection5.1asaPDMP 136
5.3 Continuous-timeMCMCviaPDMPs 139
5.3.1 DifferentSamplers 140
5.3.2 UseofPDMPOutput 154
5.3.3 ComparisonofSamplers 155
5.4 EfficientSimulationofPDMPSamplers 159
5.4.1 SimulatingPDMPs 159
5.4.2 ExploitingModelSparsity 165Contents v
5.4.3 DataSubsamplingIdeas 168
5.5 Extensions 175
5.5.1 DiscontinuousTargetDistribution 176
5.5.2 ReversibleJumpPDMPSamplers 179
5.5.3 MoreGeneralVelocityModels 184
5.6 ChapterNotes 191
6 AssessingandImprovingMCMC 192
6.1 DiagnosticsforMCMC 192
6.1.1 ConvergenceDiagnostics 193
6.1.2 BiasDiagnostics 194
6.1.3 ImprovedBiasDiagnosticsviatheKernelTrick 197
6.2 ConvergenceBoundsforMCMC 200
6.2.1 BoundsonIntegralProbabilityMetrics 200
6.2.2 ChoiceofAuxiliaryMarkovProcess 203
6.2.3 KernelSteinDiscrepancy 205
6.2.4 ConvergenceControl 210
6.2.5 StochasticGradientSteinDiscrepancy 216
6.3 OptimalWeightsforMCMC 218
6.4 OptimalThinningforMCMC 223
6.5 ChapterNotes 224
References 229Preface
Atthetimeofwriting,science,industry,andsocietyarebeingtransformed
by the emergence of a new generation of powerful machine learning and
artificialintelligence(AI)methodologies.Thesafeuseofsuchalgorithms
demands a probabilistic viewpoint, enabling reasoning in settings where
data are noisy or limited, and endowing predictions with an appropriate
degree of confidence for downstream decision-making and mitigation of
risk.Yet,itremainstruethatfundamentalprobabilisticoperations,suchas
conditioning on an observed dataset, are not easily performed at the scale
required.
The aim of this book is to provide a graduate-level introduction to ad-
vancedtopicsinMarkovchainMonteCarlo(MCMC),asappliedbroadlyin
theBayesiancomputationalcontext.Most,ifnotallofthesetopics(stochas-
ticgradientMCMC,non-reversibleMCMC,continuoustimeMCMC,and
new techniques for convergence assessment) have emerged as recently as
thelastdecade,andhavedrivensubstantialrecentpracticalandtheoretical
advances in the field. A particular focus is on methods that are scalable
withrespecttoeithertheamountofdata,orthedatadimension,motivated
by the emerging high-priority application areas in machine learning and
AI.Throughoutthisbook,theclearpresentationofideasisprioritisedover
arigoroustechnicaltreatmentofallmathematicaldetails;appropriateref-
erences for further reading are provided in the end-notes of each chapter.
In particular, we will limit the use of measure theory; the reader should
assumethatallsetsandfunctionsaremeasurablewithrespecttoanappro-
priatesigma-algebra,andallcontinuousdistributionsshouldbeassumedto
beabsolutelycontinuouswithrespecttoLebesguemeasureandalldensities
shouldbeassumedtobedensitieswithrespecttoLebesguemeasure.
Thisbookhasbeenindirectlyshapedbytheresearchersandcolleagues
â€“ too numerous to name individually â€“ who have contributed to recent
progress in the field. Special gratitude must go to Rebekah Fearnhead,
Heishiro Kanagawa, TamaÂ´s Papp and Lorenzo Rimella, for proof-reading
12 Preface
themanuscript,toRichardHoweyfortypesettingthefigures,andtoNatalie
TomlinsonandAnnaScrivenfortheirencouragementandtypesettingsup-
port.TheauthorsaregratefulforfinancialsupportfromtheEngineeringand
PhysicalSciencesCouncil(throughgrantsEP/W019590/1,EP/R018561/1,
EP/R034710/1,EP/V022636/1andEP/Y028783/1),theAlanTuringInsti-
tute,andtheLeverhulmeTrust.
PaulFearnhead ChrisJ.Oates
ChristopherNemeth NewcastleUniversity,UK
ChrisSherlock
LancasterUniversity,UKPreface 3
CommonNotation
ğ‘› total number of iterations of an algorithm or Monte Carlo
samplesize.
ğ‘‘ dimension(ofparameterspace).
ğ‘ numberofelementsinthedataset.
D thedataset{y 1,...,yğ‘},.
ğœ½ theparameter.
ğ¿(ğœ½;D) thelikelihoodfunction.
â„“(ğœ½;D) thelog-likelihoodfunction.
ğœ‹ (ğœ½) thepriordensity.
0
ğœ‹(ğœ½|D) theposteriordensity,oftenabbreviatedtoğœ‹(ğœ½).
I theindicatorfunction.
Iğ‘‘ theğ‘‘Ã—ğ‘‘identitymatrix.
ğ‘¥
ğ‘–
theğ‘–thcomponentofthevectorx.
xğ‘˜ theğ‘˜thvectorinasequence(xğ‘˜)ğ‘˜=1,2,....
ğ‘¥ ğ‘˜(ğ‘–) theğ‘–thcomponentofthevectorxğ‘˜.
i.i.d. independentandidenticallydistributed.
=D
equalindistribution.
D
â†’ convergesindistribution.
ğ›¿ theDiracdistribution,whichplacesallmassatx.
x
N(Â·;ğ,V) the density of a normal random variable with mean ğ and
covarianceV.
Uğ‘‘(Â·) the density for a uniform random variable on the ğ‘‘-
dimensionalsphere,Sğ‘‘âˆ’1 âŠ‚Rğ‘‘.
Lğ‘(ğœ‹) thesetofmeasurablefunctions ğ‘“ withâˆ« |ğ‘“(x)|ğ‘ dğœ‹(x) <âˆ.
ğ¶ğ‘ (Rğ‘‘,Rğ‘) the set of functions ğ‘“ : Rğ‘‘ â†’ Rğ‘ for which continuous
derivativesexistofordersuptoğ‘  âˆˆ {0,1,...}âˆª{âˆ}.
ğ‘¥ ğ‘› =ğ‘‚(ğ‘ ğ‘›) thereexistğ‘› 0andğ‘€ suchthatforallğ‘› â‰¥ğ‘› 0,|ğ‘¥ ğ‘›| â‰¤ ğ‘€ğ‘ ğ‘›.
ğ‘‹ ğ‘› =ğ‘‚ ğ‘(ğ‘ ğ‘›) foranyğœ– > 0thereexistğ‘› 0 and ğ‘€ suchthatforallğ‘› â‰¥ ğ‘› 0,
P(|ğ‘‹ ğ‘›| > ğ‘€ğ‘ ğ‘›) <ğœ–.1
Background
This book describes some recent developments in scalable Monte Carlo
algorithms and their applications within Bayesian learning: what exactly
doesthismean?
MonteCarlomethodsareaclassofcomputationalmethodsthatinvolve
repeated sampling to numerically approximate quantities of interest. We
specificallyfocusonMonteCarlointegrationmethods,whicharesampling-
basedmethodsforevaluatingorapproximatingthevalueofintegrals.Such
methods are widely used across science and engineering, but our motiva-
tioncomesparticularlyfromBayesianstatistics.Oneofthekeyquantities
in Bayesian statistics is the posterior distribution, which encapsulates our
belief regarding unknown parameters of a model given our prior belief
and an observed dataset. We can then obtain estimates of the parameters,
orquantifyouruncertaintyabouttheparameters,intermsofexpectations
withrespecttotheposteriordistribution.Forexample,acommonestimate
ofaparameteristheposteriorexpectationofthatparameter;thepredictive
probability of future observations is the expectation of the density/mass
functionofthefutureobservationtakenwithrespecttotheposteriordistri-
bution.Calculatingtheseexpectationsinvolvesevaluatinganintegral,and
the idea of Monte Carlo is to use samples from the posterior to estimate
suchintegrals.
ThemainchallengewithusingMonteCarloinBayesianstatisticsisoften
inderivinganefficientalgorithmtosamplefromtheposteriordistribution.
Markov chain Monte Carlo is a general and widely-used class of methods
for sampling from a distribution, based on simulating a Markov process
thathastheposteriordistributionasitsstationarydistribution.
Inrecentyears,therehasbeeninterestinapplyingMarkovchainMonte
Carlotoever-increasinglycomplexandchallengingproblems.Forexample,
the dimension, ğ‘‘ say, of the parameter space of the models we wish to fit
to data, or the number of data points, ğ‘ say, in our data set can be large.
As either ğ‘‘ or ğ‘ increases, the efficiency of Markov chain Monte Carlo
41.1 MonteCarloMethods 5
methods may reduce. For example, as ğ‘‘ increases we may need to have
moreiterationsofourMarkovchainMonteCarloalgorithmtoachievethe
required level of accuracy, while as ğ‘ increases, the computational cost
periterationofastandardalgorithmwillincrease.ScalableMarkovchain
MonteCarlomethodsarespecificallythosemethodswhichcanscalewell
aseitherorbothofğ‘‘ and ğ‘ increase.
The remainder of this introductory chapter will cover background rele-
vanttoscalableMarkovchainMonteCarlo.Thenextsectionwillintroduce
MonteCarlomethods,explainwhyMonteCarlointegrationiswidely-used,
and explain how it is relevant to Bayesian statistics. This will be followed
by an introduction to some of the statistical models and applications that
willbeusedtodemonstratethemethodsinthisbook,aswellasaninformal
and brief introduction to some of the concepts from stochastic processes
that will be used in later chapters. Finally, the chapter ends with a short
introduction to kernel methods in preparation for a deeper exposition in
Chapter6.
1.1 MonteCarloMethods
1.1.1 WhatisMonteCarloIntegration?
Assume we have a distribution of interest. For simplicity of presentation,
hereandfortheremainderofthischapter,weassumethatthedistribution
iscontinuousonRğ‘‘.LetXdenotearandomvariablewiththisdistribution
and let ğœ‹(x) denote the corresponding probability density function for X;
wewillalsouse ğœ‹ torefertothedistributionitselfwhenthatisnecessary.
Thentheexpectationofsomefunctionâ„ofXisanintegral
âˆ«
ğ¼ =E[â„(X)] = â„(x)ğœ‹(x) dx.
This expectation is well-defined, that is, â„ is integrable with respect to ğœ‹,
ifâˆ« |â„(x)|ğœ‹(x) dx < âˆ.Weabbreviatethisto â„ âˆˆ L1(ğœ‹) andthroughout
this section we assume that this holds true. If we can sample from ğœ‹(Â·)
thenwecanestimatethisexpectation/integralby(i)drawingğ‘›independent
realisations, x 1,...,xğ‘›, from ğœ‹(Â·) and (ii) calculating the sample average
ofthevaluesâ„(x 1),...,â„(xğ‘›).Thisgivesanestimateof ğ¼,namely
ğ‘›
1 âˆ‘ï¸
ğ¼Ë†=
ğ‘›
â„(xğ‘˜).
ğ‘˜=1
ThisiscalledaMonteCarloestimateofğ¼,asitisobtainedfromindependent,
randomsamplesfromğœ‹(Â·).6 Background
TheMonteCarloestimatorcanbeinterpretedasbeingbasedonğ‘›inde-
pendentrandomvariablesX 1,...,Xğ‘›,ofwhichx 1,...,xğ‘›arerealisations.
Isitagoodestimator?Thisisimpossibletoansweringenerality,butwecan
at least describe some good properties that the estimator can admit. First,
sincetheXğ‘– arei.i.d,E(cid:2)ğ¼Ë†(cid:3) = E[â„(X 1)] = ğ¼,sotheestimatorisunbiased.
Secondly, and more importantly, the strong law of large numbers tells us
that we can make our estimate arbitrarily accurate, with high probability,
if we choose ğ‘› large enough. Formally, provided ğ¼ is well defined, that is
â„ âˆˆ L1(ğœ‹),andoursamplesfromğœ‹(Â·) areindependent,thenasğ‘› â†’âˆ,
ğ‘›
1 âˆ‘ï¸
ğ‘›
â„(Xğ‘˜) â†’ ğ¼ almostsurely. (1.1)
ğ‘˜=1
Almostsureconvergencemeansthatthecollectionofoutcomeswherethe
convergencedoesnotoccurhasacombinedprobabilityof0.
Thus,withhighprobability,ourMonteCarloestimatorwillbeaccurate
if we choose ğ‘› large enough, but the result does not tell us how large ğ‘›
needs to be, nor how accurate the estimator will be for a given value of
ğ‘›. However, provided that âˆ« â„(x)2ğœ‹(x) dx < âˆ, which we abbreviate to
â„ âˆˆ L2(ğœ‹),wecanusethecentrallimittheoremtoanswerthesequestions.
Againassumethatoursamplesfromğœ‹(Â·) areindependent,anddefine
âˆ«
ğ‘‰ = {â„(x)âˆ’ğ¼}2ğœ‹(x) dx.
Then,thecentrallimittheoremstatesthat
âˆš ğ‘›(cid:32) ğ‘›1 (cid:205)ğ‘› ğ‘˜=1âˆšâ„(Xğ‘˜)âˆ’ğ¼(cid:33)
â†’D N(0,1),
ğ‘‰
asğ‘› â†’âˆ.Heretheconvergenceisindistribution,andwehaveconvergence
toastandardnormaldistributioninthelimit.
One way of interpreting this result is that, for large enough ğ‘›, then
approximately
1
âˆ‘ï¸ğ‘› (cid:18) ğ‘‰(cid:19)
ğ‘›
â„(Xğ‘˜) âˆ¼N ğ¼,
ğ‘›
.
ğ‘˜=1
That is our estimator will be approximately normally distributed, with
meanequaltotheintegral,ğ¼,andavariancethatisğ‘‰/ğ‘›.Thisshowsthatthe
quantityğ‘‰ governshoweasyitistoestimateğ¼ viaMonteCarlointegration,
and the accuracy depends on both ğ‘‰ and ğ‘›. The order of the error of a
Monte Carlo estimator is
âˆšï¸ğ‘‰/ğ‘›
and, thus, the Monte Carlo error decays
withsamplesizeatarateofğ‘›âˆ’1/2.1.1 MonteCarloMethods 7
1.1.2 ImportanceSampling
What if we are interested in calculating or approximating a more general
integral, ğ¼ = âˆ« ğ‘”(x)dx, of some function ğ‘” over a region Î©? We can use
Î©
MonteCarlosamplingtoestimatethisintegralbyre-writingtheintegralas
anexpectationwithrespecttosomedensityfunction ğ‘(Â·) definedonÎ©as
follows,
âˆ« ğ‘”(x)
ğ¼ = ğ‘(x) dx=E[â„(X)],
ğ‘(x)
Î©
where â„(x) = ğ‘”(x)/ğ‘(x).If ğ¼ iswell-defined,thatisâˆ« |ğ‘”(x)|dx < âˆ,then
â„ âˆˆ L1(ğ‘),andğ¼ canbeestimatedusingMonteCarlointegrationasabove,
basedonindependentrealisedsamplesx 1,...,xğ‘› fromğ‘(Â·) bycalculating
thearithmeticmeanofâ„(x 1),...,â„(xğ‘›).ThisprocessiscalledImportance
Sampling,andğ‘(Â·) isknownastheproposaldistribution.
For this Monte Carlo estimator to be feasible, we have two constraints
on ğ‘. First, we need ğ‘(x) > 0 whenever ğ‘”(x) > 0, in order for â„(x) to be
well-defined. Second, we need to be able to easily sample from ğ‘(Â·). The
choiceofğ‘(Â·)willaffecttheaccuracyoftheestimator,withthevarianceof
ourestimatorforaMonteCarlosampleofsizeğ‘›beingğ‘‰/ğ‘›where
âˆ« (cid:18)ğ‘”(x) (cid:19)2
ğ‘‰ = âˆ’ğ¼ ğ‘(x) dx.
ğ‘(x)
This variance will be small if ğ‘”(x)/ğ‘(x) is roughly constant, and one can
show that the optimal choice of ğ‘(Â·) in terms of minimisingğ‘‰ is ğ‘(x) âˆ
|ğ‘”(x)|. If ğ‘”(x) is non-negative everywhere (or non-positive everywhere)
then such a choice of ğ‘ will give an estimator that has zero-variance, that
is an exact estimator. More generally the varianceğ‘‰ will be large if there
arevaluesofxforwhichğ‘”(x)/ğ‘(x) islarge.Thisleadstoarule-of-thumb
that,ifÎ©isunbounded,onewantsğ‘(x) tohaveheaviertailsthan |ğ‘”(x)| to
avoidthisratioblowingupas âˆ¥xâˆ¥ â†’âˆ.
1.1.3 MonteCarloorQuadrature?
It is natural to ask why one should use Monte Carlo integration when
therearealternativenumericalintegrationmethods,suchasquadrature.To
seethepotentialbenefitsofMonteCarlomethods,considerestimatingan
integral on the unit hyper-cube [0,1]ğ‘‘. We can then compare quadrature
withMonteCarlointegrationbasedonsamplesfromauniformdistribution
on [0,1]ğ‘‘.
First,consider ğ‘‘ = 1.Inthiscase,quadraturemethodstendtobemuch8 Background
   
   
   
   
   
   
                       
x
Figure1.1 Exampleoftrapezoidrule.Wecanestimatethe
integral,by(i)settingğ‘¥ 1,...,ğ‘¥ ğ‘› tobeevenlyspacedpointson
[0,1];(ii)creatingğ‘›âˆ’1trapezoidsbasedonjoiningupthepoints
(ğ‘¥ ğ‘˜,â„(ğ‘¥ ğ‘˜))(shadedinregions);and(iii)estimatingtheintegral
bythesumoftheareasofthetrapezoids.
more accurate than Monte Carlo methods. We have seen that the Monte
Carlovariance,ifwehaveğ‘›MonteCarlosamples,isğ‘‚(1/ğ‘›),whichmeans
thattheerrorofourMonteCarloestimatorwillbeğ‘‚ ğ‘(ğ‘›âˆ’1/2).
Bycomparison,asimplenumericalmethodisthetrapezoidalrule.This
involves evaluating the integrand, â„(ğ‘¥) at a set of equally spaced points,
ğ‘¥ 1,...,ğ‘¥ ğ‘›,on [0,1],andapproximatingtheintegralusingthetotalareaof
thetrapezoidsformedbyjoiningupthepoints(ğ‘¥ ğ‘˜,â„(ğ‘¥ ğ‘˜))forğ‘˜ =1,...,ğ‘›,
see Figure 1.1. Assuming our integrand has a bounded second derivative
|â„â€²â€²(ğ‘¥)| < ğ¿ for some ğ¿, then we can bound the error in the estimate of
theintegralasğ¿ğ›¿2/12,whereğ›¿ =1/(ğ‘›âˆ’1) isthewidthofeachtrapezoid.
Thisgivesanerrorthatdecayslikeğ‘‚(1/ğ‘›2),whichismuchbetterthanthe
MonteCarlomethod.Furthermore,higher-orderquadraturemethods,such
as Simpsonâ€™s rule, can obtain even faster decay of the approximate error
withğ‘›,iftheintegrandissufficientlysmooth.
So,quadraturemethodscanbemoreaccuratefor1-dimensionalintegrals,
at least for functions whose second derivatives are bounded. However,
)x(h1.1 MonteCarloMethods 9
now consider higher-dimensional integrals involving functions â„(x), the
only information about which we have is that the second-order (partial)
derivativesarebounded.Thenwecanapplyacubaturerulebasedonagrid
of ğ‘š +1 equally spaced points in each dimension. The spacing of these
points will be ğ›¿ = 1/ğ‘š and there will be ğ‘› = (ğ‘š + 1)ğ‘‘ points in total.
If we have a cubature whose error decays like ğ›¿ğ‘Ÿ, for some power ğ‘Ÿ, for
example, ğ‘Ÿ = 2 for the trapezoidal rule, then the error decays at a rate of
ğ‘šâˆ’ğ‘Ÿ â‰ˆ ğ‘›âˆ’ğ‘Ÿ/ğ‘‘. For large ğ‘‘, this convergence will be slower than the ğ‘›âˆ’1/2
rate of Monte Carlo integration, explaining why Monte Carlo is often the
defaultmethodfornumericallyapproximatinghigh-dimensionalintegrals.
Toovercomethiscurseofdimensionincubature,itisusuallynecessaryto
identifyasenseinwhichtheintegrandâ„(x)iseffectivelylow-dimensional,
whichcanbedifficultorimpossibledependingontheappliedcontext.
1.1.4 ControlVariates
Letusreturntotheproblemofestimatingtheexpectationofsomefunction
ofarandomvariable,
âˆ«
ğ¼ =E[â„(X)] = â„(x)ğœ‹(x) dx,
whereğœ‹(x)isthedensityofX.Wehaveseenhowwecanestimatethisusing
asamplefrom ğœ‹(Â·),andthattheaccuracyofthisestimatorisproportional
to
âˆ« âˆ«
ğ‘‰ = {â„(x)âˆ’ğ¼}2ğœ‹(x) dx= â„(x)2ğœ‹(x) dxâˆ’ğ¼2.
The latter expression is just the standard expression for the variance of
â„(X).Thisshowsthatitiseasiertoestimateexpectationsoffunctionsthat
varylesswhenevaluatedatX.
Assume that we know the expectation of a set of random variables
ğ‘” 1(X),...,ğ‘” ğ½(X),eachatransformationofX.Withoutlossofgenerality,
wecanassumethattheserandomvariableshavemeanzero,i.e.,
E(cid:2)ğ‘” ğ‘—(X)(cid:3) =0, for ğ‘— =1,...,ğ½,
as, if this is not the case, we can define new random variables equal to
theoldrandomvariablesminustheirexpectations.Then,foranyconstants
ğ›¾ 1,...,ğ›¾ ğ‘›,
ğ½ (cid:34) ğ½ (cid:35)
ğ¼ =E[â„(X)]âˆ’âˆ‘ï¸ ğ›¾ ğ‘—E(cid:2)ğ‘” ğ‘—(X)(cid:3) =E â„(X)âˆ’âˆ‘ï¸ ğ›¾ ğ‘—ğ‘” ğ½(X) . (1.2)
ğ‘—=1 ğ‘—=110 Background
     
     
                 
x x x
Figure1.2 ExampleofcontrolvariatesforestimatingE[sin(ğ‘‹)],
where ğ‘‹ hasastandardnormaldistributionN(0,1).Eachplot
showsthefunctionwhoseexpectationisbeingestimatedand50
valuesusedintheMonteCarloestimate(dots).Fromlefttoright
thefunctionsarerespectively:â„(ğ‘¥) =sin(ğ‘¥),â„(ğ‘¥) =sin(ğ‘¥)âˆ’ğ‘¥,
andâ„(ğ‘¥) =sin(ğ‘¥)âˆ’ğœ‹ğ‘¥/2+(ğ‘¥2âˆ’1)/2.Theexpectationofeach
functionisconstructedtobethesame.Theeffectofintroducing
controlvariatesinthemiddleandright-handplotistoflattenout
thefunctionweareintegratingâ€“inthemiddleplot,thishappens
forğ‘¥ â‰ˆ0andfortheright-handplotforğ‘¥ â‰ˆğœ‹/2.Thevariability
ofthefunctionvalues,i.e.thedots,issmallestforthemiddleplot
andlargestfortheright-handplot.
Bysuitablechoiceoftheconstantsğ›¾ 1,...,ğ›¾ ğ½,thevariabilityoftherandom
variable â„(X)âˆ’(cid:205)ğ½ ğ‘—=1ğ›¾ ğ‘—ğ‘” ğ‘—(X) canbemadesmallerthanthatof â„(X),and
thus a Monte Carlo estimate of ğ¼ based on (1.2) will have smaller Monte
CarlovariancethanthebasicMonteCarloestimator.Wecall(cid:205)ğ½ ğ‘—=1ğ›¾ ğ‘—ğ‘” ğ‘—(X)
a control variate for â„(X). Heuristically, we want to choose ğ›¾ 1,...,ğ›¾ ğ½ so
thatâ„(X) â‰ˆ ğ›¾ 0+(cid:205)ğ½ ğ‘—=1ğ›¾ ğ‘—ğ‘” ğ‘—(X),whichmeansthatâ„(X)âˆ’(cid:205)ğ½ ğ‘—=1ğ›¾ ğ‘—ğ‘” ğ‘—(X) is
approximatelyconstant.
Asasimpleexample,considerestimatingtheexpectationofsin(ğ‘‹)where
ğ‘‹hasastandardnormaldistributionN(0,1).Weknowthatthisexpectation
is0asthedistributionof ğ‘‹ issymmetricabout0andsin(âˆ’ğ‘¥) = âˆ’sin(ğ‘¥).
We will compare the simple Monte Carlo estimator of the expectation
with estimates using control variates with the functions ğ‘” (ğ‘¥) = ğ‘¥ and
1
ğ‘” (ğ‘¥) = ğ‘¥2 âˆ’1. By using a Taylor expansion of sin(ğ‘¥) at ğ‘¥ = 0 we have
2
sin(ğ‘¥) â‰ˆğ‘¥ forsmallğ‘¥,andthusasimplechoiceofcontrolvariateisğ‘” (ğ‘¥).
1
We show pictorially the benefit of using this control variate in Figure
1.2,whereweseethatsin(ğ‘¥) âˆ’ğ‘¥ â‰ˆ 0formostğ‘¥ valuessampledfromthe
standardnormaldistribution.ThisreducestheMonteCarlovarianceofthe
estimateofE[â„(ğ‘‹)] byclosetoafactorof2.
Care must be taken with control variates, however. For example, if we1.1 MonteCarloMethods 11
performaTaylorexpansionofsin(ğ‘¥) atğ‘¥ = ğœ‹/2wegetsin(ğ‘¥) â‰ˆ 1âˆ’ (ğ‘¥âˆ’
ğœ‹/2)2/2, which suggests using âˆ’ğ‘” (ğ‘¥)/2+ğœ‹ğ‘” (ğ‘¥)/2 as a control variate.
2 1
However, this choice leads to an increase in the Monte Carlo variance by
overafactorof3.Figure1.2showsthatthefunctionsin(ğ‘¥)âˆ’ğœ‹ğ‘¥/2+(ğ‘¥2âˆ’1)/2
is roughly constant for ğ‘¥ â‰ˆ ğœ‹/2, but overall it is more variable across the
rangeğ‘¥ âˆˆ [âˆ’2,2],wheremostoftheprobabilitymassofN(0,1) lies.
This example shows that the choice of ğ›¾ 1,...,ğ›¾ ğ½ is important when
using control variates. In some situations, there may be a natural way of
choosingtheseâ€“forexample,basedonaTaylorexpansionofthefunction
of interest around the mode of the distribution of X. However, it is also
possible to choose these values based on simulation. Ideally, we would
chooseğ›¾ 1,...,ğ›¾ ğ½ tominimisetheMonteCarlovariance
âˆ« (cid:40) ğ½ (cid:41)2
âˆ‘ï¸
â„(x)âˆ’ ğ›¾ ğ‘—ğ‘” ğ‘—(x) ğœ‹(x) dxâˆ’ğ¼2,
ğ‘—=1
andwecanobtainaMonteCarloestimateofthis.Ifx 1,...,xğ‘› arerealised
samplesfromğœ‹(Â·),thenwecanchooseğ›¾ 1,...,ğ›¾ ğ½ tominimise
ğ‘› (cid:32) ğ½ (cid:33)2
âˆ‘ï¸ âˆ‘ï¸
â„(xğ‘˜)âˆ’ ğ›¾ ğ‘—ğ‘” ğ‘—(xğ‘˜) ,
ğ‘˜=1 ğ‘—=1
which just involves minimising a sum of squares criterion. If we let h be
the ğ‘›Ã—1 vector whoseğ‘–th entry is â„(xğ‘–), ğœ¸ be the ğ½ Ã—1 vector whoseğ‘–th
entryis ğ›¾ ğ‘–,andZbethe ğ‘›Ã—ğ½ matrixwhose (ğ‘–, ğ‘—)thentryis ğ‘” ğ‘—(xğ‘–),then,
assumingZisoffullrank,theleast-squaresestimateofğœ¸is
ğœ¸Ë† = (ZâŠ¤Z)âˆ’1ZâŠ¤h.
These estimates ğœ¸Ë† depend on the Monte Carlo samples, and thus for the
MonteCarloestimateofğ¼tobeunbiasedweneedtouseanewsetofMonte
CarlosamplesfromXforestimating ğ¼ usingtheğœ¸Ë†.
While we have presented the idea of control variates for estimating ex-
pectationsoffunctions,similarideascanbeusedwithimportancesampling
forestimatinggeneralintegrals.
1.1.5 MonteCarloIntegrationandBayesianStatistics
One of the most important applications of Monte Carlo methods occurs
withinBayesianstatistics.Toexplainwhy,considertheproblemofmaking
inferences, from data, about the parameter of a statistical model. We will12 Background
use the notation D to denote data in general. In some situations, we will
need to distinguish individual data points, and in those settings, we will
assumeD = {y 1,...,yğ‘},withyğ‘– beingtheğ‘–thdatapointandğ‘ beingthe
sizeofourdataset.
We further assume that we have a model for the data. Let the model
depend on a parameter ğœ½, and denote the likelihood of the data under
our model by ğ¿(ğœ½;D). The likelihood is the probability, or probability
density, of observing data D under our model if the parameter is ğœ½. In
Bayesianstatistics,werepresentbeliefs,oruncertainty,abouttheparameter,
ğœ½,throughprobabilitydistributions.Ourbeliefsabout ğœ½ beforeseeingthe
dataaregivenbyaprior,ğœ‹ (ğœ½),and,onceweobservedata,Bayesâ€™Theorem
0
providestheupdatetotheposteriordistribution:
ğœ‹(ğœ½ | D) âˆ ğœ‹ (ğœ½)ğ¿(ğœ½;D). (1.3)
0
Where it will not cause confusion, we may drop the explicit conditioning
onthedataintheposterior,andwriteğœ‹(ğœ½) ratherthanğœ‹(ğœ½ | D).
Assuming the correctness of our model, the posterior distribution con-
tainsallinformationabouttheparameter, ğœ½,thatcanbelogicallydeduced
from our prior belief and the dataset. From it, we can then obtain a point
estimateforğœ½,suchasitsposteriormean,andquantifyuncertaintyinterms
oftheposteriorprobabilityofğœ½ lyinginagivensetofvalues.However,in
most applications, the posterior distribution is intractable, meaning that it
cannot be explicitly calculated. The central challenge is that the posterior
density ğœ‹(ğœ½ | D) isknown,viaBayesâ€™Theorem,onlyuptoanormalising
constant.
The intractability of the posterior distribution is a key motivator for
Monte Carlo methods. If we can draw samples from ğœ‹(ğœ½ | D), then we
can obtain simple, and often accurate, Monte Carlo estimates of posterior
quantitiesofinterest.Givenrealisationsğœ½ 1,...,ğœ½ğ‘›sampledfromğœ‹(ğœ½ | D),
andafunctionâ„(ğœ½) whoseexpectation
âˆ«
ğ¼ :=E ğœ‹ [â„(ğœ½)] = â„(ğœ½)ğœ‹(ğœ½ | D) dğœ½
isofinterest,define
ğ‘›
ğœ‡ (cid:98)â„(ğ‘›) := ğ‘›1 âˆ‘ï¸ â„(ğœ½ğ‘˜). (1.4)
ğ‘˜=1
As mentioned earlier, for any function â„ âˆˆ L1(ğœ‹), the strong law of large
numbers (1.1) tells us that we can estimate E ğœ‹ [â„(ğœ½)] as accurately as1.1 MonteCarloMethods 13
we desire using Monte Carlo integration, and provided enough samples
are taken: ğœ‡ (cid:98)â„(ğ‘›) â†’ E ğœ‹ [â„(ğœ½)] almost surely as ğ‘› â†’ âˆ. Moreover, if â„ âˆˆ
L2(ğœ‹) then the central limit theorem states that the Monte Carlo error,
ğœ‡ (cid:98)â„(ğ‘›) âˆ’E
ğœ‹
[â„(ğœ½)] isğ‘‚ ğ‘(ğ‘›âˆ’1/2).
Forexample,thevectorofposteriormeanscanbeestimatedby
ğ‘›
1 âˆ‘ï¸
ğœ½Ë† =
ğ‘›
ğœ½ğ‘˜,
ğ‘˜=1
andtheposteriorprobabilityofğœ½ âˆˆ B forsomesetB canbeestimatedby
theproportionofMonteCarlosamplesinB
ğ‘›
1 âˆ‘ï¸
PË† (ğœ½ âˆˆ B) =
ğ‘›
I{ğœ½ğ‘˜ âˆˆ B},
ğ‘˜=1
whereI{ğœ½ğ‘˜ âˆˆ B}istheindicatorfunctionoftheeventğœ½ğ‘˜ âˆˆ B.
ThechallengewiththisMonteCarloapproachtoBayesianstatisticsisthe
difficultyinsamplingfrom ğœ‹(ğœ½),particularlyif ğœ½ ishigh-dimensional.Of
theMonteCarlointegrationmethodswehavementionedsofar,importance
samplingoffersanalternativewhenweareunabletosamplefromğœ‹directly.
Consider estimating the posterior expectation for some function â„(ğœ½), so
â„(ğœ½) = ğœ½ would give us the posterior mean of ğœ½ and â„(ğœ½) = I{ğœ½ âˆˆ B}
would give us the posterior probability of ğœ½ âˆˆ B. Let ğ‘(ğœ½) be a proposal
distributionwiththesamesupportastheposterior.Thenwehave
âˆ« âˆ« â„(ğœ½)ğœ‹(ğœ½)
E[â„(ğœ½) | D] = â„(ğœ½)ğœ‹(ğœ½) dğœ½ = ğ‘(ğœ½) dğœ½.
ğ‘(ğœ½)
Itiscommontodefineweightsğ‘¤(ğœ½) := ğœ‹(ğœ½)/ğ‘(ğœ½).Thengivenanindepen-
dentsampleğœ½ 1,...,ğœ½ğ‘›fromğ‘(ğœ½),wecanestimatetheposteriorexpectation
bytheimportancesamplingestimator
ğ‘›
1 âˆ‘ï¸
ğ‘›
ğ‘¤(ğœ½ğ‘˜)â„(ğœ½ğ‘˜).
ğ‘˜=1
Therearetwoissueswiththisestimator.Thefirstisthatasweonlyknow
theposterioruptoaconstantofproportionality,weonlyknowtheweights
up to a constant of proportionality. However, the constant of proportion-
ality can be estimated by setting â„(ğœ½) = 1, whence E[â„(ğœ½)] = 1 as the
expectationofaconstantistheconstant.Thuswecanusetheunnormalised
posteriordensityinthedefinitionoftheweights,andestimatethenormal-
ising constant as (1/ğ‘›)(cid:205)ğ‘› ğ‘˜=1ğ‘¤(ğœ½ğ‘˜). The posterior expectation of â„(ğœ½) is14 Background
thenestimatedas
âˆ‘ï¸ ğ‘˜ğ‘›
=1
(cid:205)ğ‘›
ğ‘—ğ‘¤ =1( ğ‘¤ğœ½ğ‘˜ ()
ğœ½ğ‘—)â„(ğœ½ğ‘˜),
whichrequiresknowingtheposteriordensityonlyuptoaconstantofpropor-
tionality.Oftenwedefinenormalisedweightsğ‘¤âˆ—(ğœ½ğ‘˜) = ğ‘¤(ğœ½ğ‘˜)/(cid:205)ğ‘› ğ‘—=1ğ‘¤(ğœ½ğ‘—),
andwecanthenviewtheweightedsamples(ğœ½ğ‘˜,ğ‘¤âˆ—(ğœ½ğ‘˜)),forğ‘˜ =1,...,ğ‘›,
asadiscreteapproximationtotheposterior.
The second issue is that the Monte Carlo variances of our estimators
of posterior expectations depend on the variability of the weights. Often
this will be large if ğœ½ is high-dimensional. To see this, consider a toy
example where the posterior has independent components. Assume each
component is normal with mean 0 and variance ğœ2, and the importance-
sampling proposal distribution is also independent over components, but
withastandardnormaldistribution,i.e.,withmeanzeroandunitvariance,
for each component. The importance sampling weight for a realisation
ğœ½ = (ğœƒ 1,...,ğœƒ ğ‘‘) is
(cid:40) ğœ2âˆ’1âˆ‘ï¸ğ‘‘ (cid:41)
ğ‘¤(ğœ½) = ğœâˆ’ğ‘‘ exp ğœƒ2 .
2ğœ2 ğ‘–
ğ‘–=1
Now(cid:205)ğ‘‘ ğœƒ2hasağœ’2distributionundertheproposal,andusingthemoment
ğ‘–=1 ğ‘– ğ‘‘
generatingfunctionofağœ’2distribution,weobtaintheMonteCarlovariance
ğ‘‘
oftheweight:
var{ğ‘¤(ğœ½)} = ğœâˆ’ğ‘‘ (cid:0) 2âˆ’ğœ2(cid:1)âˆ’ğ‘‘/2âˆ’1.
âˆš
Writing ğœ2 = 1+ğœ–, for some ğœ– > 0, this variance is (1/ 1âˆ’ğœ–2)ğ‘‘ âˆ’1,
which increases exponentially with ğ‘‘. The focus of Markov chain Monte
Carlo(MCMC)methodsthatweintroduceinthenextchapteristoproduce
samplingalgorithmsthatavoidthisexponentialcurseofdimensionality.
1.2 ExampleApplications
Inlaterchapters,wewilldemonstratetheMonteCarlomethodsonsomeex-
amplemodelswhichwenowintroduce.Whilstthesemodelsaresomewhat
simple to describe, their posteriors exhibit many of the features of more
challenging posterior distributions, in particular, with respect to scalable
sampling.1.2 ExampleApplications 15
1.2.1 LogisticRegression
Logisticregressionmodelstherelationshipbetweenabinaryresponseand
asetofcovariates.Denotetheresponsesby ğ‘¦ 1,...,ğ‘¦ ğ‘ andthecovariates
by ğ‘‘-dimensionalvectorsx 1,...,xğ‘.Then,logisticregressionmodelsthe
data (the responses) as conditionally independent, given a ğ‘‘-dimensional
parameterğœ½ andthecovariates,andthat
exp{xâŠ¤ğœ½}
P(cid:0)ğ‘Œ = ğ‘¦ ğ‘—|xğ‘—,ğœ½(cid:1) = 1+exp{ğ‘— xâŠ¤ğœ½}.
ğ‘—
Anintercepttermcanbeincludedinthemodelbysettingthefirstcoordinate
ofeachofx 1,...,xğ‘ tobe1.
Ourinterestwillbeinsamplingfromtheposteriordistributionofğœ½.To
definetheposterior,weneedtospecifyaprior ğœ‹ (ğœ½),andwewillassume
0
that our prior is Gaussian with mean 0 and variance ğšº . This leads to a
ğœ½
posterior distribution, ğœ‹(ğœ½|D), which can be written succinctly up to a
multiplicativeconstantas
ğœ‹(ğœ½|D)
âˆexp(cid:26) âˆ’1 ğœ½âŠ¤ğšºâˆ’1ğœ½(cid:27) (cid:214)ğ‘ exp{ğ‘¦ ğ‘—xâŠ¤ ğ‘—ğœ½}
.
2 ğœ½ 1+exp{xâŠ¤ğœ½}
ğ‘—=1 ğ‘—
This is a canonical, albeit relatively simple, test problem for sampling
methodologies. When we consider sampling methods for this model, we
will drop the explicit conditioning on data D and use ğœ‹(ğœ½) to denote the
targetdistributionofthesampler.Thesamplersweconsiderwilloftenuse
gradientinformationabouttheirtargetdistribution,andwehave
ğœ•lo ğœ•g ğœƒğœ‹ ğ‘–(ğœ½) =âˆ’(cid:2) ğœ½âŠ¤ğšº ğœ½âˆ’1(cid:3) ğ‘– +âˆ‘ï¸ ğ‘—ğ‘
=1
ğ‘¥( ğ‘—ğ‘–) (cid:40) ğ‘¦ ğ‘— âˆ’ 1+ex ep x{ px {âŠ¤ ğ‘— xğœ½ âŠ¤ ğ‘—} ğœ½}(cid:41) , (1.5)
whereğ‘¥( ğ‘—ğ‘–) indicatestheğ‘–thcomponentofxğ‘—.
1.2.2 BayesianMatrixFactorisation
Bayesian matrix factorisation attempts to find a representation of a high-
dimensionalmatrixastheproductoftwolower-dimensionalmatrices.Con-
sider an ğ‘› Ã— ğ‘š matrix Y, and let ğœ½ = {U,V} where U and V are ğ‘› Ã— ğ‘‘
and ğ‘‘ Ã—ğ‘š matrices respectively. Then the approximation is Y â‰ˆ UV. If
ğ‘‘ â‰ª min{ğ‘š,ğ‘›} then this can lead to a substantial reduction in dimen-
sion, and the model can be viewed as attempting to find low-dimensional
structureinY.16 Background
TheinterpretationofthismodelisthateachrowofVisafactor,andwe
aimtoapproximateeachrowofYasalinearcombinationofthesefactors.
TheentriesinUarecalledfactorloadings,andgivetherelativeweightof
eachfactorforeachrowofY.
One common approach to fitting these models is to use a Gaussian
workingmodel,thusuptoadditiveconstants,thelog-likelihoodis
ï£± ğ‘› ğ‘š (cid:32) ğ‘‘ (cid:33)2ï£¼
ğ¿(ğœ½;D) =âˆ’ğ‘›ğ‘šlogğœâˆ’ 2ğœ1
2
ï£´ ï£´ï£²âˆ‘ï¸âˆ‘ï¸ ğ‘Œ
ğ‘–,ğ‘—
âˆ’âˆ‘ï¸ ğ‘ˆ ğ‘–,ğ‘˜ğ‘‰
ğ‘˜,ğ‘—
ï£´ ï£´ï£½,
ï£´ ï£´ğ‘–=1 ğ‘—=1 ğ‘˜=1 ï£´ ï£´
ï£³ ï£¾
whereğœ2isthevarianceofthedifferencebetweenentriesofYandUV.In
Bayesianmatrixfactorisation,wethenintroduceapriorontheparameters
U and V. Often, the prior for each entry is Gaussian, or is a mixture of a
Gaussianandapoint-massatzero,asthisencouragessparsityinthefactors
which potentially aids the interpretation of U and V. It is also possible to
introduceaprioroverthenumberoffactors,ğ‘‘,withthepriorsfortheentries
ofUandVpotentiallydependingonğ‘‘.
1.2.3 BayesianNeuralNetworksforClassification
Artificial neural networks are a flexible and popular class of models used
in machine learning for solving supervised learning problems, such as
regressionandclassificationtasks.Inthecaseofclassification,assumethat
ğ‘¦ 1,ğ‘¦ 2,...,ğ‘¦
ğ‘
areobserveddata,whereeachğ‘¦ ğ‘—representsoneofğºclasses,
i.e. ğ‘¦ ğ‘— âˆˆ {1,2,...,ğº}. Assuming ğ‘‘âˆ’dimensional vectors x 1,x 2,...,xğ‘
forthecovariates,thenunderasimpletwo-layerneuralnetworkmodel,the
probabilityofaparticularclass ğ‘¦ ğ‘— is
P(ğ‘Œ = ğ‘¦ ğ‘—|xğ‘—,ğœ½) âˆexp(AâŠ¤ ğ‘¦ ğ‘—ğœ(BâŠ¤xğ‘— +b)+ğ‘ ğ‘¦ ğ‘—), (1.6)
where b is a ğ‘‘ â„-dimensional vector, B is a ğ‘‘ Ã— ğ‘‘ â„ matrix, with ğ‘‘ â„ the
dimension of the variables in the hidden layer. The function ğœ : Rğ‘‘ â„ â†’
(0,1)ğ‘‘ â„ isavectorsoftmaxfunctionwithğœ(z) ğ‘– = exp(ğ‘§ ğ‘–)/{(cid:205)ğ‘‘ ğ‘—=â„ 1exp(ğ‘§ ğ‘—)}
forğ‘– = 1,...,ğ‘‘ â„. The notation Ağ‘– refers to theğ‘–-th column of the ğ‘‘ â„ Ã—ğº
matrixA.Theparametersofthemodelğœ½ =vec(a,A,b,B) arerepresented
byvectorsa,b,commonlyreferredtoasbiases,andmatricesA,B,which
arecommonlyreferredtoasweights.
TakingaBayesianapproachtoparameterestimation,wecanplaceinde-
pendentGaussianpriorsoneachoftheelementsofthebiasesandweights
inğœ½.MonteCarloalgorithmscanbeusedtosamplefromtheposterior,1.3 MarkovChains 17
ğ‘
(cid:214)
ğœ‹(ğœ½|D) âˆ ğœ‹ 0(ğœ½) P(ğ‘¦ ğ‘—|xğ‘—,ğœ½). (1.7)
ğ‘—=1
For Bayesian neural network models, the dataset sizes tend to be very
large and approximating the posterior distribution requires Monte Carlo
methods which are scalable to large datasets. In Chapter 3, we will use
stochastic gradient Markov chain Monte Carlo algorithms to approximate
theBayesianneuralnetworkposteriordistribution.
1.3 MarkovChains
This section describes discrete-time Markov chains, focusing on the con-
cepts that will be required to understand the Markov chain Monte Carlo
method and its efficiency: the stationary distribution, reversibility, con-
vergence to the stationary distribution, ergodic averages, integrated auto-
correlationtimeandeffectivesamplesize.
Definition 1.1 A discrete-time Markov chain on a state space X is a
collectionofrandomvariables{ğ‘‹ ğ‘˜}âˆ ğ‘˜=0witheachğ‘‹
ğ‘˜
âˆˆ X,suchthatforany
A âŠ† X,
P(ğ‘‹ ğ‘˜+1 âˆˆ A | ğ‘‹ ğ‘˜ =ğ‘¥ ğ‘˜,...,ğ‘‹ 0 =ğ‘¥ 0) =P(ğ‘‹ ğ‘˜+1 âˆˆ A | ğ‘‹ ğ‘˜ =ğ‘¥ ğ‘˜); (1.8)
conditional on the current state, the distribution of the next state is inde-
pendentofallpreviousstates.
Inthischapter,wewillonlyconsiderhomogeneousMarkovchains,where
thedistributionofthenextstategiventhecurrentstatedoesnotdependon
thevalueof ğ‘˜.Suchachainhasastationarydistribution,ğœˆ,if ğ‘‹ ğ‘˜ âˆ¼ ğœˆ =â‡’
ğ‘‹
ğ‘˜+1
âˆ¼ ğœˆ.Ifthechainalsohasauniquelimitingdistribution,thenthismust
be ğœˆ since, by repeated induction, if ğ‘‹ ğ‘— âˆ¼ ğœˆ then ğ‘‹ ğ‘˜ âˆ¼ ğœˆ for all ğ‘˜ > ğ‘—,
includingas ğ‘˜ â†’âˆ.
ThefollowingtwoexamplesofMarkovchainsontheverticesofan ğ‘š-
sided polygon illustrate different ways that a chain can be stationary. We
labeltheverticesofthepolygonfrom0toğ‘šâˆ’1,increasinginaclockwise
direction;thus,X = {0,1,...,ğ‘šâˆ’1}.
Example1.2 (SeeFigure1.3,left.)Let{ğ‘‹ ğ‘˜}âˆ ğ‘˜=0beaMarkovchainonthe
verticesofanğ‘š-sidedpolygonwherethestateattimeğ‘˜+1isobtainedfrom
thestateattime ğ‘˜ bymovingtothenextvertexinaclockwisedirection.If
attimeğ‘˜ thechainisequallylikelytobeateachofthevertices,thenthisis18 Background
ğ´ ğ´
1/3 1/3
ğ¼ ğµ ğ¼ ğµ
1/3
ğ» ğ¶ ğ» ğ¶
ğº ğ· ğº ğ·
ğ¹ ğ¸ ğ¹ ğ¸
Figure1.3 9-sidedpolygonwheretheMarkovchainonlymoves
clockwise(leftfigure),asinExample1.2ormoveseithera
clockwiseoranti-clockwisedirectionwithprobability1/3(right
figure),asinExample1.3.
stillthecaseattimeğ‘˜+1.ThestationarydistributionhasP(ğ‘‹
ğ‘˜
=ğ‘¥) =1/ğ‘š
forğ‘¥ âˆˆ X.
Example 1.3 (See Figure 1.3, right.) Let {ğ‘‹ ğ‘˜}âˆ
ğ‘˜=0
be a Markov chain on
theverticesofanğ‘›-sidedpolygonwherethestateattime ğ‘˜ +1isobtained
fromthestateattim.eğ‘˜ byperformingoneofthefollowingmoves,eachof
whichhasaprobabilityof1/3:movetothenextvertexinananti-clockwise
direction; do not move; move to the next vertex in a clockwise direction.
AswithExample1.2thestationarydistributionhasP(ğ‘‹ ğ‘˜ =ğ‘¥) = 1/ğ‘š for
ğ‘¥ âˆˆ X.
1.3.1 ReversibleMarkovchains
Example1.2hasaclearflowinaclockwisedirectionand,becauseofthis,
isanexampleofanon-reversibleMarkovchain;thesewillbediscussedin
detailinChapter4.Bycontrast,inExample1.3,consideranytwoadjacent
vertices: at stationarity, the probability of being at the first and moving to
thesecondisthesameastheprobabilityofbeingatthesecondandmoving
tothefirst.Indeed,thisistrueofanypairofvertices,withtheprobability
being0iftheyarenotadjacent.ThisisanexampleofareversibleMarkov
chain.
Definition 1.4 A Markov chain {ğ‘‹ ğ‘˜}âˆ
ğ‘˜=1
with a state space of X is re-
versiblewithrespecttoadistribution ğœˆ when,foranytwosets B,C âŠ† X,
if ğ‘‹ ğ‘˜ âˆ¼ ğœˆthenP(ğ‘‹ ğ‘˜ âˆˆ B,ğ‘‹ ğ‘˜+1 âˆˆ C) =P(ğ‘‹ ğ‘˜ âˆˆ C,ğ‘‹ ğ‘˜+1 âˆˆ B).1.3 MarkovChains 19
Considerthedecomposition
P(ğ‘‹ âˆˆ B,ğ‘‹ âˆˆ C) =P(ğ‘‹ âˆˆ B)P(ğ‘‹ âˆˆ C|ğ‘‹ âˆˆ B).
ğ‘˜ ğ‘˜+1 ğ‘˜ ğ‘˜+1 ğ‘˜
Thefirsttermontheright-handsideistheamountofprobabilitymassinB
attimeğ‘˜ andthesecondtermisthefractionofthatmasswhichmovestoC
attimeğ‘˜+1,sotheproductistheamountofprobabilitymassmovingfrom
B to C.Ifthechainisreversiblewithrespectto ğœˆ and ğ‘‹ ğ‘˜ âˆ¼ ğœˆ,thenthisis
alsotheamountofmassmovingfromC toB.Giventhisbalance,referred
to as detailed balance, we would expect the total amount of probability
massinanysettoremainconstant.Indeed,settingC =XinDefinition1.4,
weseethatreversibilityimpliesthatifğ‘‹
ğ‘˜
âˆ¼ ğœˆ,P(ğ‘‹
ğ‘˜
âˆˆ B) =P(X
ğ‘˜+1
âˆˆ B).
SincethisisalsotrueforallB, ğ‘‹
ğ‘˜+1
âˆ¼ ğœˆ.
1.3.2 Convergence,Averages,andVariances
In Example 1.3, whatever the value or distribution of ğ‘‹ , as ğ‘˜ â†’ âˆ the
0
distribution of ğ‘‹ ğ‘˜ converges to the stationary distribution. For simplicity
of presentation, we show this when ğ‘š = 2ğ‘šâ€² +1 is odd. For all ğ‘¥ ,ğ‘¥ âˆˆ
0
X, P(ğ‘‹ ğ‘šâ€² =ğ‘¥|ğ‘‹ 0 =ğ‘¥ 0) â‰¥ 1/3ğ‘šâ€² since it takes at most ğ‘šâ€² moves in a
single direction to reach ğ‘¥, and if the chain arrives earlier, we include the
probabilityofitstayingatğ‘¥ untiltimeğ‘šâ€².Thus,thetransitionprobability
afterğ‘šâ€² stepscanbewrittenasamixture:
P(ğ‘‹ ğ‘šâ€² =ğ‘¥|ğ‘‹ 0 =ğ‘¥ 0) = ğ›¿ğœˆ(ğ‘¥)+(1âˆ’ğ›¿)ğ‘(ğ‘¥|ğ‘¥ 0), (1.9)
forsomeconditionalprobabilitymassfunctionğ‘andwithğ›¿ =ğ‘š/3ğ‘šâ€².The
distribution at the start of a given iteration can always be thought of as a
mixtureofğœˆandsomeotherdistribution,wherethemixtureprobabilityfor
ğœˆcouldbe0.Wecanimaginethatthereisahiddencoin,andifitisshowing
â€headsâ€ then the distribution of the chain is ğœˆ. Since ğœˆ is the stationary
distribution,ifthecoiniscurrentlyshowingâ€headsâ€itwillstillbeshowing
headsafterafurtherğ‘šâ€²moves.Ifthecoinisshowingâ€tailsâ€then(1.9)tells
usthatthereisaprobabilityofatleastğ›¿thatitwillbeshowingheadsafter
thenextğ‘šâ€² moves.Equivalently,themixtureprobabilityofthecomponent
thatisnotğœˆhasbeenmultipliedby1âˆ’ğ›¿orless.Afterğ‘˜ğ‘šâ€² iterations,itis,
thereforeatmost (1âˆ’ğ›¿)ğ‘˜ â†’0as ğ‘˜ â†’âˆ.
However,convergencetoastationarydistributiondoesnotoccurforall
Markovchains.ThechaininExample1.2isdeterministic:if ğ‘‹ = 0,then
0
ğ‘‹ ğ‘˜ğ‘š = 0 for all integers, ğ‘˜. The following examples illustrate two further
cases.20 Background
ğ´
1/2 1/2
ğ¼ ğµ
ğ» ğ¶
ğº ğ·
ğ¹ ğ¸
Figure1.4 9-sidedpolygonwithMarkovtransitionsdescribedin
Example1.5.
Example1.5 (SeeFigure1.4.)AlterExample1.3sothatthechaincannot
remainatitscurrentvertexbutmustmoveeitherclockwiseoranticlockwise
by a single vertex, each with a probability of 1/2. As with the Examples
1.2and1.3,thestationarydistributionhasP(ğ‘‹
ğ‘˜
=ğ‘¥) =1/ğ‘š forğ‘¥ âˆˆ X.
Ifğ‘›isanevennumber,andğ‘‹ iseventhenthechaininExample1.5only
0
visits even-numbered states at even-numbered times, and odd-numbered
statesatodd-numberedtimes.Suchchainsaretermedperiodicandclearly
donotconvergetotheirstationarydistribution.
Example 1.6 Consider a Markov chain of the form in Example 1.3, but
on two separate ğ‘š-sided polygons with no movement between the two. A
chain with separate regions between which there can be no movement is
termedreduciblebecauseitcanbereducedtosimplercomponentparts.
Areduciblechaindoesnotevenhaveasinglestationarydistribution.In
Example1.6forany ğ›½ âˆˆ [0,1] thedistributionwithprobabilities ğ›½/ğ‘š for
eachvertexonthefirstpolygonand(1âˆ’ğ›½)/ğ‘šforeachvertexonthesecond
polygonisstationary.
Achainwhichisnotreducibleistermedirreducible,andachainwhich
isnotperiodicistermedaperiodic.
ErgodicAverages
TheergodictheoremforaMarkovchainonageneralstate-space,X,states
thatprovidedthechainsatisfiesnaturalgeneralisationsofirreducibilityand
aperiodicity, and has a proper stationary distribution, ğœˆ, then as ğ‘˜ â†’ âˆ,
thedistributionofğ‘‹ ğ‘˜convergestothatstationarydistribution.Furthermore,
subjecttothesameconditions,foranyâ„ âˆˆ L1(ğœˆ),samplesfromtheMarkov1.3 MarkovChains 21
chainsatisfyastronglawoflargenumbers:
ğ‘›
1 âˆ‘ï¸
(cid:98)ğ¼ ğ‘›(â„) := ğ‘› â„(ğ‘‹ ğ‘˜) â†’E ğœˆ [â„(ğ‘‹)] (1.10)
ğ‘˜=1
almostsurelyasğ‘› â†’âˆ.
IntegratedAuto-CorrelationTimeandEffectiveSampleSize
Let us assume that ğ‘‹ is, in fact, drawn from the stationary distribution.
0
Define ğœ â„2 := Varğœˆ [â„(ğ‘‹)] andassume ğœ â„2 < âˆ.For ğ‘˜ âˆˆ {0,1,2,...},the
lag-ğ‘˜auto-correlationisğœŒ
ğ‘˜
:=Cor[â„(ğ‘‹ 0),â„(ğ‘‹ ğ‘˜)] =Cor(cid:2)â„(ğ‘‹ ğ‘—),â„(ğ‘‹ ğ‘—+ğ‘˜)(cid:3)
since the Markov chain is time-homogeneous. If the ğ‘‹ ğ‘— were independent
(cid:104) (cid:105)
samples from ğœˆ then ğ‘›Var (cid:98)ğ¼ ğ‘›(â„) = ğœ â„2. For a stationary Markov chain
with
âˆ
âˆ‘ï¸
|ğœŒ ğ‘˜| < âˆ, (1.11)
ğ‘˜=1
itholdsthat
(cid:104) (cid:105)
lim ğ‘›Var (cid:98)ğ¼ ğ‘›(â„) = ğœ â„2 IACTâ„, (1.12)
ğ‘›â†’âˆ
where
âˆ
âˆ‘ï¸
IACTâ„ :=1+2 ğœŒ ğ‘˜, (1.13)
ğ‘˜=1
is the integrated auto-correlation time. To see why this is the case, firstly,
without loss of generality, take â„ to have E ğœˆ [â„(ğ‘‹)] = 0; if this is not
true initially, we subtract off the expectation: the variance properties are
unchanged.Then
(cid:104) (cid:105) 1 (cid:34) âˆ‘ï¸ğ‘› âˆ‘ï¸ğ‘› (cid:35) ğœ2 âˆ‘ï¸ğ‘› âˆ‘ï¸ğ‘›
ğ‘›Var (cid:98)ğ¼ ğ‘›(â„) = ğ‘›E â„(ğ‘‹ ğ‘—)â„(ğ‘‹ ğ‘˜) = ğ‘›â„ ğœŒ |ğ‘˜âˆ’ğ‘—|. (1.14)
ğ‘˜=1 ğ‘—=1 ğ‘˜=1 ğ‘—=1
But(cid:205)ğ‘› ğ‘˜=1(cid:205)ğ‘› ğ‘—=1ğœŒ |ğ‘˜âˆ’ğ‘—| =ğ‘›ğœŒ 0+2(cid:205)ğ‘› ğ‘˜=1(ğ‘›âˆ’ğ‘˜)ğœŒ ğ‘˜,so
ğ‘› (cid:104) (cid:105) âˆ‘ï¸ğ‘› (cid:18) ğ‘˜(cid:19) âˆ‘ï¸âˆ (cid:18) ğ‘˜(cid:19)
ğœ2Var (cid:98)ğ¼ ğ‘›(â„) =1+2 1âˆ’ ğ‘› ğœŒ ğ‘˜ =1+2 max 0,1âˆ’ ğ‘› ğœŒ ğ‘˜.
â„ ğ‘˜=1 ğ‘˜=0
Given(1.11),thedominatedconvergetheorempermitsustoexchangethe
ordering of the limit as ğ‘› â†’ âˆ and the sum over ğ‘˜, which provides the
limit(1.12).22 Background
Thepracticalconsequenceof (1.12)isthat,forfiniteğ‘›,
(cid:104) (cid:105) ğœ2
Var (cid:98)ğ¼ â„ â‰ˆ ğ‘›/IACâ„ Tâ„, (1.15)
thesameasthevarianceifğ‘›/IACTâ„i.i.d.samplesfromğœˆhadbeenused.The
quantity ğ‘›/IACTâ„ is, therefore, known as the effective sample size. Since
they relate directly to the inverse variance of (cid:98)ğ¼ ğ‘›(â„), effective sample size
andtheinverseoftheintegratedauto-correlationtimeareusefulmeasures
oftheefficiencyofaMarkovchainforestimatingE
ğœˆ
[â„(ğ‘‹)].
1.4 StochasticDifferentialEquations
TheLangevinstochasticdifferentialequationisthebasisfortheMetropolis
Adjusted Langevin Algorithm (Section 2.1.4) and for stochastic gradient
Langevin methods (Chapter 3). It is also key to understanding the effi-
ciencyofvariousMetropolisâ€“Hastingsalgorithmswhenthedimension,ğ‘‘,
ishigh(seeChapter2).Westartwithaheuristicintroductiontostochastic
differential equations before considering a special case of the Langevin
diffusionknownastheOrnsteinâ€“Uhlenbeckprocessandthenmovingonto
thegeneralLangevindiffusion.
Consideradifferentialequationoftheform
dğ‘¥
ğ‘¡ = ğ‘(ğ‘¥ ,ğ‘¡),
dğ‘¡ ğ‘¡
withaknowninitialvalueforğ‘¥ .DiscretisingtimeleadstothesimpleEuler
0
approximation
ğ›¿ğ‘¥ â‰ˆ ğ‘(ğ‘¥ ,ğ‘¡)ğ›¿ğ‘¡,
ğ‘¡ ğ‘¡
whereğ›¿ğ‘¥ ğ‘¡ = ğ‘¥ ğ‘¡+ğ›¿ğ‘¡ âˆ’ğ‘¥ ğ‘¡.Settingğ›¿ğ‘¡ =ğ‘‡/ğ‘š,startingwithğ‘¥ 0,andrecursively
applying the Euler update ğ‘š times leads to an approximation (cid:98)ğ‘¥ ğ‘‡, which
approachesthetruevalueğ‘¥
ğ‘‡
asğ‘š â†’âˆ.
Insteadofdeterministicupdates,wemightwishtoallowfortheaddition
of random noise with scale proportional to ğ‘(ğ‘¥ ğ‘¡,ğ‘¡). The initial value, ğ‘‹ 0,
may now be random and setting ğ›¿ğ‘‹ ğ‘¡ := ğ‘‹ ğ‘¡+ğ›¿ğ‘¡ âˆ’ ğ‘‹ ğ‘¡ leads to one possible
update
ğ›¿ğ‘‹
ğ‘¡
â‰ˆ ğ‘(ğ‘‹ ğ‘¡,ğ‘¡)ğ›¿ğ‘¡+ğ‘(ğ‘‹ ğ‘¡,ğ‘¡)ğœ– ğ‘¡, ğœ–
ğ‘¡
âˆ¼N(0,ğ›¿ğ‘¡),
where the Gaussian noise terms ğœ– ğ‘¡ are independent of all previous ran-
domness, and ğ‘‹ ğ‘¡ has become a random variable. A noise distribution of
theformN(0,ğ›¿ğ‘¡) ischosenbecauseitisself-consistent.Forexample,with1.4 StochasticDifferentialEquations 23
ğ‘(ğ‘‹ ğ‘¡,ğ‘¡) = ğ‘andğ‘(ğ‘¥ ğ‘¡,ğ‘¡) = ğ‘,aftertwotimestepsinitialisedat ğ‘‹
0
=ğ‘¥ 0,we
have
ğ‘‹
2ğ›¿ğ‘¡
â‰ˆğ‘¥ 0+ğ‘ğ›¿ğ‘¡+ğ‘ğœ–
ğ›¿ğ‘¡
+ğ‘ğ›¿ğ‘¡+ğ‘ğœ–
2ğ›¿ğ‘¡
=ğ‘¥ 0+2ğ‘ğ›¿ğ‘¡+ğ‘ğœ–Ëœ
2ğ›¿ğ‘¡
whereğœ–Ëœ 2ğ›¿ğ‘¡ âˆ¼N(0,2ğ›¿ğ‘¡),sincethetwonoisetermsğœ– ğ›¿ğ‘¡,ğœ– 2ğ›¿ğ‘¡ areindependent.
However,theright-handsideofthisexpressionisexactlyofthesameform
wewouldgetfromasingletimestepofsize2ğ›¿ğ‘¡ toobtain ğ‘‹ 2ğ›¿ğ‘¡ from ğ‘‹ 0.
Theprocesswithğ‘ =0,ğ‘ =1andğ‘‹ =0consistsofasequenceofmean-
0
zeroGaussianincrements,eachwithavarianceofğ›¿ğ‘¡.Thisisadiscretisation
ofaprocessknownasBrownianmotion,whichisoftendenotedbyğ‘Š ğ‘¡.In
particular,wehavethat
ğ›¿ğ‘Š
ğ‘¡
=ğ‘Š
ğ‘¡+ğ›¿ğ‘¡
âˆ’ğ‘Š
ğ‘¡
âˆ¼N(0,ğ›¿ğ‘¡),
and ğ‘Š ğ‘¡ âˆ¼ N(0,ğ‘¡). From the definition of ğ‘Š ğ‘¡, we may rewrite the noisy
updateas
ğ›¿ğ‘‹ ğ‘¡ â‰ˆ ğ‘(ğ‘‹ ğ‘¡,ğ‘¡)ğ›¿ğ‘¡+ğ‘(ğ‘‹ ğ‘¡,ğ‘¡)ğ›¿ğ‘Š ğ‘¡. (1.16)
Considerthisprocessonsomeinterval [0,ğ‘‡],withğ›¿ğ‘¡ =ğ‘‡/ğ‘š and ğ‘‹ =ğ‘¥ ,
0 0
forsomeinitialvalueğ‘¥ .Subjecttosomeregularityconditions,thelimitas
0
ğ‘š â†’âˆexistsandiswritten:
dğ‘‹
ğ‘¡
= ğ‘(ğ‘‹ ğ‘¡,ğ‘¡)dğ‘¡+ğ‘(ğ‘‹ ğ‘¡,ğ‘¡)dğ‘Š ğ‘¡.
Thisisknownasastochasticdifferentialequation(SDE),and(1.16)isthe
Eulerâ€“Maruyama approximation to it. Subject to the initial condition, the
solutiontothisSDEisthestochasticprocess{ğ‘‹ ğ‘¡} ğ‘¡âˆˆ[0,ğ‘‡] obtainedfromthe
limitğ›¿ğ‘¡ â†’0ofthediscrete-timeprocessdefinedthrough(1.16).
The above heuristic describes a one-dimensional SDE and its Eulerâ€“
Maruyama discretisation; however, it is straightforward to extend these to
higherdimensionswithXğ‘¡ âˆˆ Rğ‘‘,a : Rğ‘‘ Ã—[0,âˆ) â†’ Rğ‘‘,Wğ‘¡ âˆˆ Rğ‘˜ andthe
ğ‘‘Ã—ğ‘˜ matrixb:Rğ‘‘ Ã—[0,âˆ) â†’Rğ‘‘ğ‘˜.
A stochastic process that satisfies an SDE is called a diffusion. For the
mostpart,wewilldealwithtime-homogeneousdiffusions,whereğ‘ and ğ‘
havenoexplicittimedependence;however,time-inhomogeneousdiffusions
willbeusedinChapter3.
1.4.1 TheOrnsteinâ€“UhlenbeckProcess
ConsidertheSDE
1
dğ‘‹
ğ‘¡
=âˆ’ 2ğœ2ğ‘2ğ‘‹ ğ‘¡dğ‘¡+ğ‘dğ‘Š ğ‘¡.24 Background
TheEulerâ€“Maruyamadiscretisationgives
(cid:18) ğ‘2 (cid:19)
ğ‘‹
ğ‘¡+ğ›¿ğ‘¡
â‰ˆ ğ‘‹
ğ‘¡
+ğ›¿ğ‘‹
ğ‘¡
= 1âˆ’ 2ğœ2ğ›¿ğ‘¡ ğ‘‹
ğ‘¡
+ğ‘ğ›¿ğ‘Š ğ‘¡.
Sinceğ›¿ğ‘Š ğ‘¡isGaussiandistributedandindependentofğ‘‹ ğ‘¡,ifğ‘‹ ğ‘¡isGaussianso
is ğ‘‹ ğ‘¡+ğ›¿ğ‘¡.Moreover,ifE[ğ‘‹ ğ‘¡] = 0,thenE[ğ‘‹ ğ‘¡+ğ›¿ğ‘¡] = 0.Finally,ifVar[ğ‘‹ ğ‘¡] =
ğœ2 then
(cid:18) ğ‘2 (cid:19)2 1
Var[ğ‘‹ ğ‘¡+ğ›¿ğ‘¡] = 1âˆ’ 2ğœ2ğ›¿ğ‘¡ ğœ2+ğ‘2ğ›¿ğ‘¡ = ğœ2+ 4ğœ4ğ‘4ğ›¿ğ‘¡2.
In the limit ğ‘š â†’ âˆ, as the number of increments is increased, with
ğ›¿ğ‘¡ = ğ‘‡/ğ‘š â†“ 0, the term in ğ›¿ğ‘¡2 becomes irrelevant: the variance does not
change.Thus,if ğ‘‹ 0 âˆ¼ N(0,ğœ2) then ğ‘‹ ğ‘¡ âˆ¼ N(0,ğœ2) forallğ‘¡ > 0;theSDE
is stationary. Shifting the coordinate system by ğ‘š we see that the slightly
moregeneralSDE
1
dğ‘‹ ğ‘¡ =âˆ’ 2ğœ2ğ‘2(ğ‘‹ ğ‘¡ âˆ’ğ‘š)dğ‘¡+ğ‘dğ‘Š ğ‘¡ (1.17)
hasastationarydistributionofN(ğ‘š,ğœ2).TheprocessarisingfromtheSDE
(1.17) is known as the Ornsteinâ€“Uhlenbeck (OU) process. Substituting
ğ‘  = ğ‘2ğ‘¡, the SDE becomes dğ‘‹ ğ‘  = âˆ’(ğ‘‹ ğ‘  âˆ’ ğ‘š)/(2ğœ2)dğ‘  + dğ‘Š ğ‘ , which
explains why ğ‘2 is termed the speed of the diffusion. Figure 1.5 presents
threerealisationsofOUprocesseswithstationarydistributionN(ğ‘š,1)and
started from the corresponding ğ‘š/2. Each diffusion has a different speed,
andtheeffectofthisontheconvergenceto,andmixingwithin,thestationary
distributionisclearlyvisible.
1.4.2 TheInfinitesimalGenerator
The infinitesimal generator (or, simply, generator) of a continuous-time
stochasticprocessactsonafunctionâ„oftheprocess:
(Lâ„)(x) := ğœ•ğœ• ğ‘¡E[â„(Xğ‘¡)|X 0 =x](cid:12) (cid:12) (cid:12)
(cid:12)
ğ‘¡=0
= l ğ›¿i ğ‘¡m â†“0E[â„(Xğ›¿ ğ›¿ğ‘¡) ğ‘¡]âˆ’â„(x) . (1.18)
Thesetoffunctionsforwhichthelimitexistsforallxiscalledthedomain
oftheinfinitesimalgenerator.Subjecttoregularityconditions,thisincludes
the set of compactly supported functions with a second derivative that is
continuous,denotedğ¶2.
0
For processes defined by an SDE, we can gain some insight into their1.4 StochasticDifferentialEquations 25
 
 
 
 
 
            
t
Figure1.5 ThreerealisationsoftheOrnsteinâ€“Uhlenbeck
processes,allwithğœ =1,andonthetimeinterval [0,10].Other
parametersettingsareğ‘¥ =2,ğ‘š =4andğ‘ =3;ğ‘¥ =ğ‘š =0and
0 0
ğ‘ =1;ğ‘¥ =âˆ’2,ğ‘š =âˆ’4andğ‘ =1/3.
0
generatorbyconsideringaTaylorexpansion.Forsimplicityofpresentation,
weconsiderğ‘¥ âˆˆ R:
(cid:20) (cid:21)
1 1 1
E[â„(ğ‘‹ )âˆ’â„(ğ‘¥)] = E (ğ‘‹ âˆ’ğ‘¥)â„â€²(ğ‘¥)+ (ğ‘‹ âˆ’ğ‘¥)2â„â€²â€²(ğ‘¥)+... .
ğ›¿ğ‘¡ ğ›¿ğ‘¡ ğ›¿ğ‘¡ ğ›¿ğ‘¡ 2 ğ›¿ğ‘¡
The Eulerâ€“Maruyama approximation of the SDE is ğ‘‹ ğ›¿ğ‘¡ âˆ’ ğ‘¥ â‰ˆ ğ‘(ğ‘¥)ğ›¿ğ‘¡ +
ğ‘(ğ‘¥)ğ›¿ğ‘Š ğ‘¡. Thus E[ğ‘‹ ğ›¿ğ‘¡ âˆ’ğ‘¥] â‰ˆ ğ‘(ğ‘¥)ğ›¿ğ‘¡ and E(cid:2) (ğ‘‹ ğ›¿ğ‘¡ âˆ’ğ‘¥)2(cid:3) â‰ˆ ğ‘(ğ‘¥)2ğ›¿ğ‘¡ +
ğ‘(ğ‘¥)2[ğ›¿ğ‘¡]2, with all higher order expectations at most ğ‘œ(ğ›¿ğ‘¡). Thus, we
mightexpectthat
dâ„ 1 d2â„
(Lâ„)(ğ‘¥) = ğ‘(ğ‘¥) + ğ‘(ğ‘¥)2 ,
dğ‘¥ 2 dğ‘¥2
andthisisindeedthecase.Foramultivariatediffusion,thegeneratoris
(Lâ„)(x) =âˆ‘ï¸ ğ‘–=ğ‘‘
1
ğ‘ ğ‘–ğœ•ğœ• ğ‘¥â„ ğ‘–(cid:12) (cid:12) (cid:12)
(cid:12)
x+ 1 2âˆ‘ï¸ ğ‘–=ğ‘‘
1
âˆ‘ï¸ ğ‘—ğ‘‘
=1
(ğ‘ğ‘âŠ¤) ğ‘–,ğ‘—ğœ•ğ‘¥ğœ• ğ‘–2 ğœ•â„
ğ‘¥
ğ‘—(cid:12) (cid:12) (cid:12)
(cid:12)
x. (1.19)
Generatorsofdiffusionprocessesareusedinthenextsubsectiontoderive
x26 Background
thestationarydensityoftwoclassesofdiffusionthatappearrepeatedlyin
Chapters 2 and 3. Generators of diffusions are also used in Chapter 6 for
theassessmentandimprovementofalgorithms.Finally,Chapter5employs
the generators of another class of continuous-time stochastic processes to
determinetheprocessesâ€™stationarydistributions.
1.4.3 LangevinDiffusions
Wenowdescribetwoclassesofdiffusion,theoverdampedandunderdamped
Langevindiffusions,wherethestationarydensityformsanexplicitpartof
theSDEformulation.
TheOverdampedLangevinDiffusion
Consider a positive, differentiable density function ğ‘“(x) for x âˆˆ Rğ‘‘, and
thefollowingSDE:
1
dXğ‘¡ = âˆ‡log ğ‘“(Xğ‘¡)ğ‘2dğ‘¡+ğ‘dWğ‘¡. (1.20)
2
AsolutiontothisSDEisknownasanoverdampedLangevindiffusion.The
OUprocess(1.17)with ğ‘“(ğ‘¥) = N(ğ‘¥;ğ‘š,1/ğ‘) isaspecialcaseofthisclass
ofdiffusions,andinthiscase,asseeninSection1.4.1, ğ‘“ isthedensityofthe
stationaryprocess.Infact,thisistrueingeneral:thestationarydensityofthe
overdamped Langevin diffusion (1.20) is ğ‘“. To see this in one dimension,
considertheinfinitesimalgeneratorofthediffusion:
1 ğ‘“â€²(ğ‘¥) 1
(Lâ„)(ğ‘¥) = ğ‘2 â„â€²(ğ‘¥)+ ğ‘2â„â€²â€²(ğ‘¥).
2 ğ‘“(ğ‘¥) 2
Thisistherateofchangeoftheexpectationofâ„(ğ‘‹ ğ‘¡) atğ‘¡ =0,whenstarted
from ğ‘‹ = ğ‘¥. Suppose instead that ğ‘‹ has a density of ğ‘“. Then, the rate
0 0
of change of the expectation of ğ‘‹ ğ‘¡ at ğ‘¡ = 0 can be calculated by taking
expectationswithrespectto ğ‘‹ .Thisis
0
1 âˆ« (cid:26) ğ‘“â€²(ğ‘¥) (cid:27) 1 âˆ«
ğ‘2 â„â€²(ğ‘¥)+â„â€²â€²(ğ‘¥) ğ‘“(ğ‘¥) dğ‘¥ = ğ‘2 {ğ‘“(ğ‘¥)â„â€²(ğ‘¥)}â€² dğ‘¥ =0
2 ğ‘“(ğ‘¥) 2
for all sufficiently smooth â„ with compact support. Thus, if ğ‘‹ âˆ¼ ğ‘“,
0
dd ğ‘¡E[â„(ğ‘‹ ğ‘¡)](cid:12) (cid:12)
ğ‘¡=0
= 0. This is true for all â„ âˆˆ ğ¶ 02, and so the distribution
ofğ‘‹
ğ‘¡
doesnotchangeasğ‘¡increasesfrom0.Thedistributionattime0must,
therefore, be the stationary distribution of the Langevin diffusion (1.20),
and ğ‘“ isthecorrespondingstationarydensity.
WhenLangevindiffusionsareemployedinaBayesiansetting, ğ‘“(x)isof-
tenaposteriordensitywhosenormalisingconstantis,typically,intractable.1.4 StochasticDifferentialEquations 27
Thefactthatthecalculationofâˆ‡log ğ‘“(Xğ‘¡)doesnotrequirethisnormalising
constantiscrucialtothepracticaluseofthesediffusions.
TheUnderdampedLangevinDiffusion
The underdamped Langevin diffusion extends the state space to include a
velocitycomponent,Pğ‘¡:
dXğ‘¡ =Pğ‘¡dğ‘¡, (1.21)
âˆšï¸
dPğ‘¡ =âˆ’ğ›¾Pğ‘¡dğ‘¡+ğ‘âˆ‡log ğ‘“(Xğ‘¡)dğ‘¡+ 2ğ›¾ğ‘dWğ‘¡ (1.22)
Intuitively, dividing (1.22) through by ğ›¾ and taking the limit as ğ›¾ â†’ âˆ
and ğ‘ â†’ âˆ with ğ‘/ğ›¾ = ğ‘2/2 fixed, we obtain the overdamped Langevin
diffusion,sothelatterisalimitingcaseoftheunderdampeddiffusion.
TheunderdampedLangevindiffusiontargets ğ‘“(x)ğ‘”(p),where
(cid:18) (cid:19)
1 1
ğ‘”(p) = âˆš exp âˆ’ âˆ¥pâˆ¥2 .
2ğœ‹ğ‘ 2ğ‘
To see this we, again, restrict ourselves to the one-dimensional case to
simplifythepresentationand,again,westartfromthegenerator:
ğ‘“â€²(ğ‘¥)
(Lâ„)(ğ‘¥,ğ‘) = ğ‘â„ (ğ‘¥,ğ‘)âˆ’ğ›¾ğ‘â„ (ğ‘¥,ğ‘)+ğ‘ â„ (ğ‘¥,ğ‘)+ğ›¾ğ‘â„ (ğ‘¥,ğ‘),
ğ‘¥ ğ‘ ğ‘“(ğ‘¥) ğ‘ ğ‘,ğ‘
where we have used subscripts to denote differentiation of â„ with respect
toğ‘¥ or ğ‘.Thequantity (Lâ„)(ğ‘¥,ğ‘) istherateofchangeoftheexpectation
of â„(ğ‘‹ ğ‘¡,ğ‘ƒ ğ‘¡) at ğ‘¡ = 0, when started at ğ‘‹
0
= ğ‘¥ and ğ‘ƒ
0
= ğ‘. Thus if ğ‘‹
0
and
ğ‘ƒ have respective densities of ğ‘“(ğ‘¥) and ğ‘”(ğ‘), then the rate of change of
0
E[â„(ğ‘‹ ğ‘¡,ğ‘ƒ ğ‘¡)] atğ‘¡ =0is
âˆ¬ (cid:26) ğ‘“â€²(ğ‘¥) (cid:27)
ğ‘â„
ğ‘¥
âˆ’ğ›¾ğ‘â„
ğ‘
+ğ‘
ğ‘“(ğ‘¥)
â„
ğ‘
+ğ›¾ğ‘â„
ğ‘,ğ‘
ğ‘“(ğ‘¥)ğ‘”(ğ‘)dğ‘dğ‘¥.
In the manipulations that follow, we will twice use the fact that ğ‘”â€²(ğ‘) =
âˆ’ğ‘ğ‘”(ğ‘)/ğ‘.Firstly,integrationbypartsgives
âˆ« âˆ«
ğ›¾ğ‘â„ ğ‘,ğ‘ğ‘”(ğ‘) dğ‘ = ğ‘ğ›¾â„ ğ‘ğ‘”(ğ‘) dğ‘,
sothesecondandfourthtermscancel.Secondly,twointegrationsbyparts,
firstwithrespectto ğ‘ andthenwithrespecttoğ‘¥,give
âˆ¬ âˆ¬
ğ‘ğ‘“â€²(ğ‘¥)â„ ğ‘ğ‘”(ğ‘) dğ‘dğ‘¥ = ğ‘“â€²(ğ‘¥)â„ğ‘ğ‘”(ğ‘) dğ‘dğ‘¥
âˆ¬
=âˆ’ ğ‘“(ğ‘¥)â„ ğ‘¥ğ‘ğ‘”(ğ‘) dğ‘dğ‘¥,28 Background
sothefirstandthirdtermscancel.Theargumentiscompletedanalogously
tothatfortheoverdampedLangevindiffusion.
In Chapter 3, we explore further the overdamped and underdamped
Langevin diffusions as practical algorithms for scalable Monte Carlo in-
ference in the large-data setting and show that the discretisation of these
diffusion processes leads to important special cases of the general frame-
workforstochasticgradientMCMCalgorithms.
1.5 TheKernelTrick
Chapter 6 introduces the kernel Stein discrepancy and uses it to measure
the discrepancy between a sample of points and a distribution of interest.
Practical use of the methodology is made feasible by the ability to reduce
whatappearstobeaninfiniteamountofcomputationâ€“maximisingaquan-
tityoveranuncountablyinfinitesetofpossiblefunctionsâ€“toonlyafinite
numberofarithmeticoperations.Thekeymechanismforthissimplification
is often called the kernel trick, and the setting for its use is a reproducing
kernelHilbertspace.
This section first explains the kernel trick in the more familiar setting
of a finite-dimensional inner-product space, before extending to the more
general setting required for Chapter 6. Whilst many of the concepts in-
troduced are much more general, our presentation focuses on the specific
setting of relevance: the vectors of our inner-product space are functions,
theassociatedfieldisRandtheinnerproductisanintegralwithrespectto
aprobabilitydistribution.
Throughout, ğ‘“(Â·), ğ‘”(Â·) etc. are functions from X â†’ R, where X is Rğ‘‘
or some closed or open subset of Rğ‘‘; ğ‘“(x), ğ‘”(x) etc denote the function
evaluated at x âˆˆ X. The probability distribution ğœˆ is assumed to have a
densityğœˆ(x) onX.
1.5.1 Finite-DimensionalInnerProductSpaces
Let 0(Â·) be the function such that 0(x) = 0 for all x âˆˆ X. A set, V, of
functionsfromX â†’RisavectorspaceoverRifthefollowingaxiomsare
satisfied:
1. 0(Â·) âˆˆ V.
2. ğ‘“(Â·) âˆˆ V =â‡’ âˆ’ğ‘“(Â·) âˆˆ V.
3. ğ‘“(Â·),ğ‘”(Â·) âˆˆ V =â‡’ ğ‘“(Â·)+ğ‘”(Â·) âˆˆ V.
4. ğ‘“(Â·) âˆˆ Vandğ‘ âˆˆ R =â‡’ ğ‘ğ‘“(Â·) âˆˆ V.1.5 TheKernelTrick 29
Aside: The associativity, commutativity and distributativity axioms of
a general vector space are satisfied automatically when the elements are
functionsandfromX toRandthefieldisR.
Everyfinite-dimensionalvectorspacehasadimension,ğ‘›,suchthatthere
isasetofğ‘›vectors{ğ‘ 1(Â·),...,ğ‘ ğ‘›(Â·)}whichsatisfytwoproperties:
1. Linearindependence:Ifthereareğ‘ 1,...,ğ‘ ğ‘› âˆˆ Rsuchthat(cid:205) ğ‘–ğ‘› =1ğ‘ ğ‘–ğ‘ ğ‘–(Â·) =
0thenğ‘
ğ‘–
=0forallğ‘– âˆˆ {1,...,ğ‘›}.
2. Spanning V: for each ğ‘“(Â·) âˆˆ V there are ğ‘ 1,...,ğ‘ ğ‘› âˆˆ R such that
ğ‘“(Â·) =(cid:205) ğ‘–ğ‘› =1ğ‘ ğ‘–ğ‘ ğ‘–(Â·).
Theset{ğ‘ 1(Â·),...,ğ‘ ğ‘›(Â·)}iscalledabasis.
Example1.7 Itisstraightforwardtocheckthattheset
V= {ğ‘“(Â·) : ğ‘“(ğ‘¥) = ğ‘sin(ğ‘¥+ğœƒ) : ğ‘ âˆˆ R,ğœƒ âˆˆ [0,2ğœ‹)}
= {ğ‘“(Â·) : ğ‘“(ğ‘¥) = ğ‘sinğ‘¥+ğ‘cosğ‘¥;ğ‘,ğ‘ âˆˆ R}
satisfies Axioms 1â€“4, whatever the domain, X âŠ† R. We may take ğ‘ (Â·) =
1
sin(Â·)andğ‘ (Â·) =cos(Â·).However,wemayalsotakeğ‘ (Â·) =sin(Â·)+3cos(Â·)
2 1
andğ‘ (Â·) =cos(Â·),forexample.
2
For any vector space V of functions from X â†’ R and any distribution
ğœˆ with a probability density function on X of ğœˆ(ğ‘¥), we define the inner
product
âˆ«
âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© = ğ‘“(x)ğ‘”(x)ğœˆ(x) dx, (1.23)
ğœˆ
wherehereandthroughoutthissection,iftheintegralrangeisnotspecified
thenitisX.Werefertothisinnerproductas âŸ¨Â·,Â·âŸ© .
ğœˆ
The inner product defined by (1.23) clearly satisfies two of the three
defining properties of an inner product: âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© = âŸ¨ğ‘”(Â·), ğ‘“(Â·)âŸ© and
âŸ¨ğ‘“(Â·)+ğ‘”(Â·),â„(Â·)âŸ© = âŸ¨ğ‘“(Â·),â„(Â·)âŸ© + âŸ¨ğ‘”(Â·),â„(Â·)âŸ©. However, we have only
that âŸ¨ğ‘“(Â·), ğ‘“(Â·)âŸ© = 0 â‡” ğ‘“(x) = 0(x) ğœˆ-almost everywhere, rather than
âŸ¨ğ‘“(Â·), ğ‘“(Â·)âŸ© = 0 â‡” ğ‘“(Â·) = 0(Â·). Each ğ‘“ belongs to an equivalence class
of functions that are equal ğœˆ-almost everywhere. This set of equivalence
classes forms a vector space and (1.23) defines an inner product on this
space,notonthespaceoffunctions,V.Tokeepthepresentationinthissec-
tionasstraightforwardaspossibleourwordingignoresthisdistinction,but
themorerigorousreadermaywishtoreplaceanyvectorspaceoffunctions
and inner product between these functions with the corresponding vector
spaceofequivalenceclassesoffunctionsandinnerproductsbetweenthese
equivalenceclasses.30 Background
Theinnerproductprovidesanorm,calledtheinducednorm,thesquare
ofwhichis
âˆ«
âˆ¥ğ‘“(Â·)âˆ¥2 = âŸ¨ğ‘“(Â·), ğ‘“(Â·)âŸ© = ğ‘“(x)2ğœˆ(x) dx.
ğœˆ ğœˆ
Example 1.8 (Example 1.7 continued) Let X = [0,2ğœ‹] and let ğœˆ be the
uniformdistributionon [0,2ğœ‹].Forany ğ‘“(Â·),ğ‘”(Â·) âˆˆ V,
1
âˆ« 2ğœ‹
1
âˆ« 2ğœ‹
âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© = ğ‘“(ğ‘¥)ğ‘”(ğ‘¥) dğ‘¥ and âˆ¥ğ‘“(Â·)âˆ¥2 = ğ‘“(ğ‘¥)2 dğ‘¥.
ğœˆ 2ğœ‹ ğœˆ 2ğœ‹
0 0
Example1.9 ForageneralvectorspaceVoffunctionsoftheformX â†’R,
letV
ğœˆ
betheelementsofVwhichhaveafinitenorminducedbyğœˆ:
(cid:26) âˆ« (cid:27)
V ğœˆ = ğ‘“(Â·) âˆˆ V: ğ‘“(x)2ğœˆ(x) dx < âˆ .
ThenV ğœˆisalsoavectorspace,sinceAxioms1,2and4aresatisfiedtrivially,
andAxiom3issatisfiedsinceforany ğ‘“(Â·),ğ‘”(Â·) âˆˆ V ğœˆ,
âˆ¥ğ‘“(Â·)+ğ‘”(Â·)âˆ¥2 = âŸ¨ğ‘“(Â·)+ğ‘”(Â·), ğ‘“(Â·)+ğ‘”(Â·)âŸ©
ğœˆ ğœˆ
= âˆ¥ğ‘“(Â·)âˆ¥2 +2âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© +âˆ¥ğ‘”(Â·)âˆ¥2
ğœˆ ğœˆ ğœˆ
â‰¤ âˆ¥ğ‘“(Â·)âˆ¥2
ğœˆ
+2âˆ¥ğ‘“(Â·)âˆ¥ ğœˆâˆ¥ğ‘”(Â·)âˆ¥
ğœˆ
+âˆ¥ğ‘”(Â·)âˆ¥2
ğœˆ
< âˆ,
wherethethirdlineusestheCauchyâ€“Schwarzinequality,which,inthiscase,
isthefamiliarinequalityE[ğ‘“(X)ğ‘”(X)]2 â‰¤ E[ğ‘“(X)2]E(cid:2)ğ‘”(X)2(cid:3) ,whereX
hasadensityğœˆonX.
Henceforth, for narrative simplicity, we will assume that V is a finite-
dimensionalvectorspacewithdimensionğ‘›.Section1.5.4extendsthenar-
rativetopotentiallyinfinite-dimensionalspaces.
When considering the inner product âŸ¨Â·,Â·âŸ© , two vectors ğ‘“(Â·),ğ‘”(Â·) âˆˆ
ğœˆ
V are said to be orthogonal if âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© = 0 and the basis vectors,
ğœˆ
ğ‘’ 1(Â·),...,ğ‘’ ğ‘›(Â·) aresaidtobeorthonormaliftheyareorthogonalandeach
hasanormof1:foreach ğ‘—,ğ‘˜ âˆˆ {1,...,ğ‘›},
âˆ¥ğ‘’ ğ‘—(Â·)âˆ¥ ğœˆ =1 and âŸ¨ğ‘’ ğ‘—(Â·),ğ‘’ ğ‘˜(Â·)âŸ© ğœˆ =0
whenever ğ‘— â‰  ğ‘˜. We will reserve the symbols {ğ‘’ ğ‘˜(Â·)}ğ‘›
ğ‘˜=1
for any set of ğ‘›
orthonormalbasisfunctions.
Therepresentationof ğ‘“(Â·) intermsofanorthonormalbasis
ğ‘›
âˆ‘ï¸
ğ‘“(Â·) = ğ‘“ ğ‘’ (Â·)
ğ‘— ğ‘—
ğ‘—=11.5 TheKernelTrick 31
is termed an orthonormal decomposition of ğ‘“(Â·). Since the ğ‘’ ğ‘–(Â·) are or-
thonormal,theprojectionof ğ‘“(Â·) ontoğ‘’ ğ‘˜(Â·) is ğ‘“ ğ‘˜:
(cid:42) ğ‘› (cid:43) ğ‘›
âˆ‘ï¸ âˆ‘ï¸
âŸ¨ğ‘“(Â·),ğ‘’ (Â·)âŸ© = ğ‘“ ğ‘’ (Â·),ğ‘’ (Â·) = ğ‘“ âŸ¨ğ‘’ (Â·),ğ‘’ (Â·)âŸ©
ğ‘˜ ğœˆ ğ‘— ğ‘— ğ‘˜ ğ‘— ğ‘— ğ‘˜ ğœˆ
ğ‘—=1 ğœˆ ğ‘—=1
= ğ‘“ ğ‘˜. (1.24)
Furthermore, the squared norm of ğ‘“(Â·) is the sum of the squares of the
orthonormalprojections:
(cid:42) ğ‘› ğ‘› (cid:43) ğ‘› ğ‘›
âˆ‘ï¸ âˆ‘ï¸ âˆ‘ï¸âˆ‘ï¸
âˆ¥ğ‘“(Â·)âˆ¥2 = ğ‘“ ğ‘’ (Â·), ğ‘“ ğ‘’ (Â·) = ğ‘“ ğ‘“ âŸ¨ğ‘’ (Â·),ğ‘’ (Â·)âŸ©
ğ‘— ğ‘— ğ‘˜ ğ‘˜ ğ‘— ğ‘˜ ğ‘— ğ‘˜
ğ‘—=1 ğ‘˜=1 ğ‘—=1 ğ‘˜=1
ğ‘›
âˆ‘ï¸
= ğ‘“2. (1.25)
ğ‘—
ğ‘—=1
Example1.10 InExample1.7,sinceâˆ« 2ğœ‹ sin2ğ‘¥ dğ‘¥ = âˆ« 2ğœ‹ cos2ğ‘¥ dğ‘¥ = ğœ‹
0 0
andâˆ« 2ğœ‹ sinğ‘¥cosğ‘¥ dğ‘¥ =0,
0
âˆš âˆš
ğ‘’ (Â·) = 2sin(Â·) and ğ‘’ (Â·) = 2cos(Â·)
1 2
form an orthonormal basis for V when ğœˆ is the uniform distribution on
[0,2ğœ‹].Anyfunction ğ‘“(Â·) âˆˆ Vcanbewrittenas ğ‘“(Â·) = ğ‘“ ğ‘’ (Â·)+ ğ‘“ ğ‘’ (Â·).
1 1 2 2
Forexampleset
âˆš
3 1
ğ‘“(ğ‘¥) =sin(ğ‘¥+ğœ‹/6) = sinğ‘¥+ cosğ‘¥. (1.26)
2 2
âˆš âˆš âˆš
So ğ‘“ = 3/(2 2) and ğ‘“ =1/(2 2).Also
1 2
3 1 1 1
âˆ« 2ğœ‹
âˆ¥ğ‘“(Â·)âˆ¥2 = ğ‘“2+ ğ‘“2 = + = = sin2(ğ‘¥+ğœ‹/6) dğ‘¥.
ğœˆ 1 2 8 8 2 2ğœ‹
0
1.5.2 KernelsinaFinite-DimensionalInnerProductSpace
As in the previous subsection, let V be an ğ‘›-dimensional vector space of
functions from X to R and let ğœˆ be a probability distribution on X with a
probabilitydensityof ğœˆ(x),x âˆˆ X.Finally,let {ğ‘’ ğ‘˜(Â·)}ğ‘›
ğ‘˜=1
beasetofbasis
functionswhichisorthonormalwithrespecttotheinnerproduct(1.23).
Letğœ† 1,...,ğœ† ğ‘›beasetofnon-negativescalarsandconsiderthefollowing
real-valuedfunctiononXÃ—X:
ğ‘›
âˆ‘ï¸
k(x,y) = ğœ† ğ‘—ğ‘’ ğ‘—(x)ğ‘’ ğ‘—(y). (1.27)
ğ‘—=132 Background
Clearly,k(Â·,Â·)issymmetric:k(y,x) =k(x,y).Moreover,k(Â·,Â·)ispositive
semidefinite:foranyfiniteğ½ < âˆ,ğ‘ 1,...,ğ‘
ğ½
âˆˆ Randx 1,...xğ½ âˆˆ Rğ‘‘,
ğ½ ğ½ ğ½ ğ½ ğ‘›
âˆ‘ï¸âˆ‘ï¸ âˆ‘ï¸âˆ‘ï¸ âˆ‘ï¸
ğ‘ ğ‘—ğ‘ ğ‘˜k(xğ‘—,xğ‘˜) = ğ‘ ğ‘—ğ‘
ğ‘˜
ğœ† ğ‘™ğ‘’ ğ‘™(xğ‘—)ğ‘’ ğ‘™(xğ‘˜)
ğ‘—=1 ğ‘˜=1 ğ‘—=1 ğ‘˜=1 ğ‘™=1
ğ‘› ğ½ ğ½
âˆ‘ï¸ âˆ‘ï¸âˆ‘ï¸
= ğœ†
ğ‘™
ğ‘ ğ‘—ğ‘ ğ‘˜ğ‘’ ğ‘™(xğ‘—)ğ‘’ ğ‘™(xğ‘˜)
ğ‘™=1 ğ‘—=1 ğ‘˜=1
ğ‘› (cid:40) ğ½ (cid:41)2
âˆ‘ï¸ âˆ‘ï¸
= ğœ†
ğ‘™
ğ‘ ğ‘—ğ‘’ ğ‘™(xğ‘—) â‰¥ 0.
ğ‘™=1 ğ‘—=1
Anyfunctionk(Â·,Â·) :XÃ—X â†’Rwhichisbothsymmetricandpositive
semidefiniteiscalledakernel.
Example1.11 ContinuingExample1.7,letk : [0,2ğœ‹]Ã—[0,2ğœ‹] â†’Rbe
1 3
k(ğ‘¥,ğ‘¦) = ğ‘’ (ğ‘¥)ğ‘’ (ğ‘¦)+ ğ‘’ (ğ‘¥)ğ‘’ (ğ‘¦) =sinğ‘¥sinğ‘¦+3cosğ‘¥cosğ‘¦
2 1 1 2 2 2
=2cos(ğ‘¦âˆ’ğ‘¥)+cos(ğ‘¦+ğ‘¥).
Thisissymmetricandpositivedefinitebyconstruction.
Giventhedefinitionofk(Â·,Â·) in(1.27),define
ğ‘›
âˆ‘ï¸
k(x,Â·) = ğœ† ğ‘—ğ‘’ ğ‘—(x)ğ‘’ ğ‘—(Â·), (1.28)
ğ‘—=1
andk(Â·,x) =k(x,Â·).Sinceğ‘’ ğ‘—(x) âˆˆ R,k(x,Â·) âˆˆ V.Furthermore,for ğ‘“(Â·) âˆˆ
Vdefinetheoperatorğ‘‡ via
k
âˆ«
ğ‘‡ ğ‘“(Â·) = k(Â·,y)ğ‘“(y)ğœˆ(y) dy. (1.29)
k
Thenğ‘‡ isalinearoperator,sinceforanyğ‘,ğ‘ âˆˆ Rand ğ‘“(Â·),ğ‘”(Â·) âˆˆ V,
k
ğ‘‡ {ğ‘ğ‘“(Â·)+ğ‘ğ‘”(Â·)} = ğ‘ğ‘‡ ğ‘“(Â·)+ğ‘ğ‘‡ ğ‘”(Â·).
k k k1.5 TheKernelTrick 33
Now,writing ğ‘“(Â·) =(cid:205)ğ‘›
ğ‘˜=1
ğ‘“ ğ‘˜ğ‘’ ğ‘˜(Â·),
âˆ«
(ğ‘‡ ğ‘“(Â·))(x) = k(x,y)ğ‘“(y)ğœˆ(y)dy
k
(cid:42) ğ‘› ğ‘› (cid:43)
âˆ‘ï¸ âˆ‘ï¸
= âŸ¨k(x,Â·), ğ‘“(Â·)âŸ©
ğœˆ
= ğœ† ğ‘—ğ‘’ ğ‘—(x)ğ‘’ ğ‘—(Â·), ğ‘“ ğ‘˜ğ‘’ ğ‘˜(Â·)
ğ‘—=1 ğ‘˜=1 ğœˆ
ğ‘› ğ‘› ğ‘›
âˆ‘ï¸âˆ‘ï¸ âˆ‘ï¸
= ğœ† ğ‘—ğ‘’ ğ‘—(x)ğ‘“
ğ‘˜
âŸ¨ğ‘’ ğ‘—(Â·),ğ‘’ ğ‘˜(Â·)âŸ©
ğœˆ
= ğœ† ğ‘˜ğ‘“ ğ‘˜ğ‘’ ğ‘˜(x).
ğ‘—=1 ğ‘˜=1 ğ‘˜=1
Soğ‘‡ kğ‘“(Â·) = (cid:205)ğ‘› ğ‘˜=1ğœ† ğ‘˜ğ‘“ ğ‘˜ğ‘’ ğ‘˜(Â·) and, hence,ğ‘‡ kğ‘“(Â·) âˆˆ V, too. Moreover, con-
sidering ğ‘“(Â·) = ğ‘’ ğ‘—(Â·), we see that ğ‘‡ kğ‘’ ğ‘—(Â·) = ğœ† ğ‘—ğ‘’ ğ‘—(Â·); each ğ‘’ ğ‘—(Â·) is an
eigenfunctionofğ‘‡
k
withacorrespondingeigenvalueofğœ† ğ‘—.
Example 1.12 Continuing Example 1.7, with the kernel from Example
1.11,
k(ğ‘¥,Â·) =sinğ‘¥sin(Â·)+3cosğ‘¥cos(Â·) =2cos(Â·âˆ’ğ‘¥)+cos(Â·+ğ‘¥).
Let ğ‘“(Â·) beasdefinedin(1.26).Then,usingthedefiniteintegralsatthe
startofExample1.10,
(cid:40)âˆš (cid:41)
1
âˆ« 2ğœ‹
3 1
ğ‘‡ ğ‘“(Â·) = {sin(Â·)sinğ‘¦+3cos(Â·)cosğ‘¦} sinğ‘¦+ cosğ‘¦ dğ‘¦
k 2ğœ‹ 2 2
0
1
âˆ« 2ğœ‹âˆš
= 3sin(Â·)sin2ğ‘¦+3cos(Â·)cos2ğ‘¦ dğ‘¦
4ğœ‹
0
1 (cid:110)âˆš (cid:111)
= 3sin(Â·)+3cos(Â·) .
4
Since
âˆš
âˆš âˆš 3 1
ğ‘’ (Â·) = 2sin(Â·), ğ‘’ (Â·) = 2cos(Â·), ğ‘“ = âˆš , ğ‘“ = âˆš ,
1 2 1 2
2 2 2 2
ğœ† =1/2andğœ† =3/2,ğ‘‡ ğ‘“(Â·) is,therefore,
1 2 k
ğœ† ğ‘“ ğ‘’ (Â·)+ğœ† ğ‘“ ğ‘’ (Â·),
1 1 1 2 2 2
aswewouldhope.34 Background
1.5.3 ANewInnerProductandtheKernelTrickinFinite
Dimensions
Let {ğ‘’ ğ‘—(Â·)}ğ‘›
ğ‘—=1
beanorthonormalbasisforVandletk bedefinedthrough
(1.27)withrespecttothisbasis.For ğ‘“(Â·),ğ‘”(Â·) âˆˆ Vwith
ğ‘› ğ‘›
âˆ‘ï¸ âˆ‘ï¸
ğ‘“(Â·) = ğ‘“ ğ‘—ğ‘’ ğ‘—(Â·) and ğ‘”(Â·) = ğ‘” ğ‘—ğ‘’ ğ‘—(Â·), (1.30)
ğ‘—=1 ğ‘—=1
theinnerproductwithrespecttoğœˆisthesumoftheproductsoftheorthog-
onalprojections:
(cid:42) ğ‘› ğ‘› (cid:43) ğ‘› ğ‘›
âˆ‘ï¸ âˆ‘ï¸ âˆ‘ï¸âˆ‘ï¸
âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© = ğ‘“ ğ‘’ (Â·), ğ‘” ğ‘’ (Â·) = ğ‘“ ğ‘” âŸ¨ğ‘’ (Â·),ğ‘’ (Â·)âŸ©
ğœˆ ğ‘— ğ‘— ğ‘˜ ğ‘˜ ğ‘— ğ‘˜ ğ‘— ğ‘˜ ğœˆ
ğ‘—=1 ğ‘˜=1 ğœˆ ğ‘—=1 ğ‘˜=1
ğ‘›
âˆ‘ï¸
= ğ‘“ ğ‘” .
ğ‘— ğ‘—
ğ‘—=1
Wenowdefineanewinnerproduct
ğ‘› ğ‘“ ğ‘”
âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© =âˆ‘ï¸ ğ‘— ğ‘—, (1.31)
k ğœ†
ğ‘—
ğ‘—=1
where the {ğœ† ğ‘—}ğ‘› ğ‘—=1, are exactly those from the definition of k and are the
eigenvaluesoftheoperatorğ‘‡ .
k
This inner product may be rephrased in terms of a set of eigenfunc-
tionswhichareorthonormalwithrespectto âŸ¨Â·,Â·âŸ© : {ğ‘’â€²(Â·)}ğ‘› withğ‘’â€²(Â·) =
k ğ‘— ğ‘—=1 ğ‘—
âˆšï¸ğœ† ğ‘—ğ‘’ ğ‘—(Â·).Withrespecttothisbasis,thevector
ğ‘›
âˆ‘ï¸
ğ‘“(Â·) = ğ‘“â€²ğ‘’â€²(Â·)
ğ‘— ğ‘—
ğ‘—=1
with ğ‘“ ğ‘—â€² = ğ‘“ ğ‘—/âˆšï¸ğœ† ğ‘—.Usingananalogousdecompositionforğ‘”(Â·),
ğ‘›
âˆ‘ï¸
âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© = ğ‘“â€²ğ‘”â€²,
k ğ‘— ğ‘—
ğ‘—=1
asexpected.Finally,
ğ‘›
âˆ‘ï¸
k(x,y) = ğ‘’â€²(x)ğ‘’â€²(y).
ğ‘— ğ‘—
ğ‘—=11.5 TheKernelTrick 35
âˆš
Example 1.13 In Example 1.11, ğ‘’â€²(Â·) = sin(Â·) and ğ‘’â€²(Â·) = 3cos(Â·).
1 2
Clearly,
k(ğ‘¥,ğ‘¦) =sinğ‘¥sinğ‘¦+3cosğ‘¥cosğ‘¦ = ğ‘’â€²(ğ‘¥)ğ‘’â€²(ğ‘¦)+ğ‘’â€²(ğ‘¥)ğ‘’â€²(ğ‘¦).
1 1 2 2
For ğ‘“(Â·) asinExample1.26,
âˆš âˆš âˆš
3 1 3 3âˆš
ğ‘“(Â·) = sin(Â·)+ cos(Â·) = sin(Â·)+ 3cos(Â·),
2 2 2 6
âˆš âˆš
so ğ‘“â€² = 3/2and ğ‘“â€² = 3/6.Thus
1 2
3 3 5
âˆ¥ğ‘“(Â·)âˆ¥2 = + = .
k 4 36 6
TheKernelTrick
Fromthedefinition(1.28)andwith ğ‘“(Â·) decomposedasin(1.30),
âŸ¨k(x,Â·), ğ‘“(Â·)âŸ©
k
=
(cid:42) âˆ‘ï¸ğ‘›
ğœ† ğ‘—ğ‘’ ğ‘—(x)ğ‘’
ğ‘—(Â·),âˆ‘ï¸ğ‘›
ğ‘“ ğ‘˜ğ‘’
ğ‘˜(Â·)(cid:43) =âˆ‘ï¸ğ‘› ğœ† ğ‘—ğ‘’ ğœ†ğ‘—(x)ğ‘“
ğ‘—
ğ‘—
ğ‘—=1 ğ‘˜=1 ğ‘—=1
k
= ğ‘“(x). (1.32)
Moreover,choosing ğ‘“(Â·)tobek(y,Â·), ğ‘“ ğ‘— =ğœ† ğ‘—ğ‘’ ğ‘—(y)from(1.28),and,hence,
ğ‘›
âˆ‘ï¸
âŸ¨k(x,Â·),k(y,Â·)âŸ©
k
= ğœ† ğ‘—ğ‘’ ğ‘—(x)ğ‘’ ğ‘—(y) =k(x,y). (1.33)
ğ‘—=1
Together,(1.32)and(1.33)enabletheevaluationofinnerproductsinâŸ¨Â·,Â·âŸ©
k
without needing to know the original basis functions ğ‘’ 1(Â·),...,ğ‘’ ğ‘›(Â·) nor
the associated valuesğœ† 1,...,ğœ† ğ‘›. Indeed, we do not even need to know ğœˆ.
Thisisknownasthekerneltrick,andwewillexemplifyitsuseinSection
1.5.5.First,wegeneralisetoamuchbroaderclassofkernels.
1.5.4 GeneralKernels
InSection1.5.2wecreatedakernelvia(1.27)usingaknownorthonormal
basis for the inner-product space V, with the inner product specifed by
(1.23)accordingtothedensityğœˆ.However,akernelisanypositive-definite
symmetricfunctionandweareinterestedinkernelsk :XÃ—X â†’R.
Example1.14 TheGaussiankernelis
k(x,y) =exp(cid:0) âˆ’âˆ¥yâˆ’xâˆ¥2(cid:1),36 Background
whereâˆ¥Â·âˆ¥representsthestandardEuclideannorm.Thisisclearlysymmet-
ric.ToseethatkisalsopositivesemidefiniteonX =Rğ‘‘,notethat
(cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19)
1 1 1
Zâˆ¼Nğ‘‘ x, Iğ‘‘ and Y|Zâˆ¼Nğ‘‘ Z, Iğ‘‘ =â‡’ Yâˆ¼Nğ‘‘ x, Iğ‘‘ ,
4 4 2
fromwhich
âˆ«
exp(cid:0) âˆ’âˆ¥yâˆ’xâˆ¥2(cid:1) = ğ›¾ exp(cid:0) âˆ’2âˆ¥yâˆ’zâˆ¥2(cid:1) exp(cid:0) âˆ’2âˆ¥xâˆ’zâˆ¥2(cid:1) dz,
whereğ›¾ =2ğ‘‘/ğœ‹ğ‘‘/2.Hence(cid:205)ğ½ ğ‘—=1(cid:205) ğ‘˜ğ½ =1ğ‘ ğ‘—ğ‘ ğ‘˜k(xğ‘—,xğ‘˜) is
ğ½ ğ½ âˆ«
ğ›¾âˆ‘ï¸âˆ‘ï¸ ğ‘ ğ‘—ğ‘ ğ‘˜ exp(cid:0) âˆ’2âˆ¥xğ‘— âˆ’zâˆ¥2(cid:1) exp(cid:0) âˆ’2âˆ¥xğ‘˜ âˆ’zâˆ¥2(cid:1) dz
ğ‘—=1 ğ‘˜=1
âˆ« ğ½ ğ½
= ğ›¾ âˆ‘ï¸âˆ‘ï¸ ğ‘ ğ‘—ğ‘ ğ‘˜exp(cid:0) âˆ’2âˆ¥xğ‘— âˆ’zâˆ¥2(cid:1) exp(cid:0) âˆ’2âˆ¥xğ‘˜ âˆ’zâˆ¥2(cid:1) dz
ğ‘—=1 ğ‘˜=1
âˆ« (cid:40) ğ½ (cid:41)2
= ğ›¾ âˆ‘ï¸ ğ‘ ğ‘—exp(cid:0) âˆ’2âˆ¥xğ‘— âˆ’zâˆ¥2(cid:1) dz
ğ‘—=1
â‰¥ 0.
When specifying k in Example 1.14, we have not specified a vector
space,noradensityğœˆ,noranassociatedinnerproduct.However,sincekis
akernel,wemighthopethatifwedospecifyğœˆandtheinnerproductâŸ¨Â·,Â·âŸ©
ğœˆ
in(1.23),thentheremightbeavectorspacewithabasisthatisorthonormal
withrespecttoâŸ¨Â·,Â·âŸ© suchthatkhasthedecomposition(1.27).Ifthiswere
ğœˆ
thecasethenwewouldknowthattherewasanewinnerproductâŸ¨Â·,Â·âŸ© such
k
that (1.32) and (1.33) held. Hence we could evaluate inner products with
respecttokwithoutknowingthebasisitselfnortheeigenvaluesofğ‘‡ ,nor,
k
even,thedetailsaboutğœˆ.
The decomposition in (1.23) does not hold in general, but Mercerâ€™s
Theoremandgeneralisationsofittellusthatananalogousdecomposition
butwithğ‘›potentiallyinfiniteholdswidely.
Specifically, let X be Rğ‘‘ or a closed or open subset of Rğ‘‘, k(Â·,Â·) :
X Ã—X â†’ R be a kernel and ğœˆ(x), x âˆˆ X, be a probability density on X.
Then,providedk(x,y) isacontinuousfunctionofxandy,and
âˆ«
k(x,y)2ğœˆ(y) dy < âˆ forallx âˆˆ X, (1.34)
thelinearoperatorğ‘‡ definedin(1.29)hasatmostcountablymanypositive
k
(andnonegative)eigenvaluesğœ† ,ğœ† ,... withcorrespondingeigenfunctions
1 21.5 TheKernelTrick 37
ğ‘’ (Â·),ğ‘’ (Â·),... which are orthonormal with respect to the inner product
1 2
âŸ¨Â·,Â·âŸ© definedin(1.23).Furthermore,kcanbedecomposedas
ğœˆ
âˆ
âˆ‘ï¸
k(x,y) = ğœ† ğ‘˜ğ‘’ ğ‘—(x)ğ‘’ ğ‘—(y)
ğ‘—=1
and the set {âˆšï¸ğœ† ğ‘—ğ‘’ ğ‘—(Â·)}âˆ
ğ‘—=1
forms an orthonormal basis with respect to the
innerproduct
âˆ ğ‘“ ğ‘”
âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© =âˆ‘ï¸ ğ‘— ğ‘—,
k ğœ†
ğ‘—
ğ‘—=1
where
âˆ âˆ
âˆ‘ï¸ âˆ‘ï¸
ğ‘“(Â·) = ğ‘“ ğ‘—ğ‘’ ğ‘—(Â·) and ğ‘”(Â·) = ğ‘” ğ‘—ğ‘’ ğ‘—(Â·). (1.35)
ğ‘—=1 ğ‘—=1
The space in which ğ‘’ (Â·),ğ‘’ (Â·),... lie is a generalisation of the vector
1 2
spaceofExample1.9totheHilbertspace,H ğœˆ,offunctions ğ‘“(Â·) :X â†’R
withtheinnerproductâŸ¨Â·,Â·âŸ© andsuchthatâˆ¥ğ‘“(Â·)âˆ¥2 =âˆ« ğ‘“(x)2ğœˆ(x) dx < âˆ.
ğœˆ ğœˆ
Likewisetheorthonormalbasis{âˆšï¸ğœ† ğ‘—ğ‘’ ğ‘—(Â·)}âˆ ğ‘—=1liesinthereproducingkernel
Hilbert space, H , of functions with the inner product âŸ¨Â·,Â·âŸ© and such
k k
that âˆ¥ğ‘“(Â·)âˆ¥ < âˆ. A Hilbert space H is an inner product space with
k
a potentially infinite set of basis vectors that is complete; informally, it
containsnoâ€holesâ€,sothatforanysequence ğ‘“ , ğ‘“ ,... with(cid:205)âˆ ğ‘“2 < âˆ
1 2 ğ‘—=1 ğ‘—
then(consideringH k,forexample) ğ‘“(Â·) =limğ‘›â†’âˆ(cid:205)ğ‘›
ğ‘—=1
ğ‘“ ğ‘—ğ‘’â€² ğ‘—(Â·)exists,with
distance measured through the norm induced by the inner product, and is
inH .
k
Thus,thesimplificationsoftheinnerproductsin(1.32)and(1.33)con-
tinuetohold;ingeneral,theintermediatestepsmustreplaceğ‘›withâˆ.
Example1.15 FortheGaussiankernelofExample1.14,k(x,Â·) =exp(âˆ’âˆ¥xâˆ’
Â·âˆ¥2) and
(cid:10) exp(âˆ’âˆ¥xâˆ’Â·âˆ¥2),exp(âˆ’âˆ¥yâˆ’Â·âˆ¥2)(cid:11) =exp(âˆ’âˆ¥yâˆ’xâˆ¥2).
k
Also,forany ğ‘“(Â·) âˆˆ H ,
k
(cid:10) exp(âˆ’âˆ¥xâˆ’Â·âˆ¥2), ğ‘“(Â·)(cid:11) = ğ‘“(x).
k
Trace-ClassKernels
Akernelwhereâˆ« k(x,x)ğœˆ(x) dx= ğ‘ < âˆisreferredtoastraceclass.This
propertyhasimportantconsequencesforthesetofeigenvalues,ğœ† ,ğœ† ,...,
1 238 Background
ofğ‘‡ ,since
k
âˆ« âˆ« âˆ
âˆ‘ï¸
k(x,x)ğœˆ(x) dx= ğœ† ğ‘˜ğ‘’ ğ‘˜(x)ğ‘’ ğ‘˜(x)ğœˆ(x) dx
ğ‘˜=1
âˆ âˆ« âˆ
âˆ‘ï¸ âˆ‘ï¸
= ğœ†
ğ‘˜
ğ‘’ ğ‘˜(x)2ğœˆ(x) dx= ğœ† ğ‘˜.
ğ‘˜=1 ğ‘˜=1
Thus(cid:205)âˆ ğ‘˜=1ğœ†
ğ‘˜
= ğ‘.Sinceeachğœ†
ğ‘˜
â‰¥ 0,wehavelimğ‘˜â†’âˆğœ†
ğ‘˜
=0.
The Gaussian kernel of Example 1.14 is trace class with ğ‘ = 1 since
k(x,x) = 1forallx âˆˆ Rğ‘‘.ThekernelwewillmeetininChapter6isalso
oftraceclass,followingasimilarreasoning.
Withoutlossofgenerality,welabeltheeigenvaluesğœ† ,ğœ† ... inorderof
1 2
decreasingsize(choosinganyoneofthepossibilitiesifsomeoftheğœ† ğ‘— are
notunique).Withthedecompositionof ğ‘“(Â·) in(1.35),
âˆ ğ‘“2 âˆ
âˆ¥ğ‘“(Â·)âˆ¥2 =âˆ‘ï¸ ğ‘— â‰¥ 1 âˆ‘ï¸ ğ‘“2 = 1 âˆ¥ğ‘“(Â·)âˆ¥2.
k ğœ† ğœ† ğ‘— ğœ† ğœˆ
ğ‘—=1 ğ‘— 1 ğ‘—=1 1
Thusâˆ¥ğ‘“(Â·)âˆ¥
k
< âˆ =â‡’ âˆ¥ğ‘“(Â·)âˆ¥
ğœˆ
< âˆandhenceH
k
âŠ† H ğœˆ.Ingeneral,H
k
isstrictlysmallerthanH ğœˆ andthemorequicklytheeigenvaluesofğ‘‡ kdecay
thesmallerthespaceH .
k
1.5.5 ThePoweroftheKernelTrick
Supposewehavevaluesx 1,...,xğ‘š âˆˆ X andweareinterestedin
(cid:40) ğ‘š (cid:41)
âˆ‘ï¸
Vâˆ— = ğ‘”(Â·) :ğ‘”(Â·) = ğ‘” ğ‘—k(xğ‘—,Â·), ğ‘” 1,...,ğ‘”
ğ‘š
âˆˆ R .
ğ‘—=1
Firstly,foranyğ‘”(Â·) =(cid:205)ğ‘š ğ‘—=1ğ‘” ğ‘—k(xğ‘—,Â·),
(cid:42) ğ‘š ğ‘š (cid:43) ğ‘š ğ‘š
âˆ‘ï¸ âˆ‘ï¸ âˆ‘ï¸âˆ‘ï¸
âˆ¥ğ‘”(Â·)âˆ¥2 = ğ‘” ğ‘—k(xğ‘—,Â·), ğ‘” ğ‘˜k(xğ‘˜,Â·) = ğ‘”
ğ‘—
âŸ¨k(xğ‘—,Â·),k(xğ‘˜,Â·âŸ©ğ‘”
ğ‘˜
k
ğ‘—=1 ğ‘˜=1 ğ‘—=1 ğ‘˜=1
k
ğ‘š ğ‘š
âˆ‘ï¸âˆ‘ï¸
= ğ‘” ğ‘—k(xğ‘—,xğ‘˜)ğ‘” ğ‘˜ < âˆ. (1.36)
ğ‘—=1 ğ‘˜=1
So,Vâˆ— âŠ† H .Secondly,forany ğ‘“(Â·) âˆˆ H ,
k k
ğ‘š ğ‘š
âˆ‘ï¸ âˆ‘ï¸
âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© k = ğ‘” ğ‘— âŸ¨ğ‘“(Â·),k(xğ‘—,Â·)âŸ© k = ğ‘” ğ‘—ğ‘“(xğ‘—). (1.37)
ğ‘—=1 ğ‘—=1
Suppose there is a particular function of interest, ğ‘“(Â·) âˆˆ H , and we
k1.5 TheKernelTrick 39
wouldliketoconstructthefunctionğ‘”(Â·) âˆˆ Vâˆ— thatmostcloselyresembles
ğ‘“(Â·) in shape. We could find the unit vector in Vâˆ— which has the largest
componentinthe ğ‘“(Â·) direction:
ğ‘”(Â·) = argmax âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© .
(cid:98) k
ğ‘”(Â·)âˆˆVâˆ—:âˆ¥ğ‘”(Â·)âˆ¥=1
Thesizeoftheinnerproduct,âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© ,isameasureoftheabilityofVâˆ—
(cid:98) k
torepresent ğ‘“(Â·).
Definef = [ğ‘“(x 1),..., ğ‘“(xğ‘š)]âŠ¤ andg = [ğ‘” 1,...ğ‘” ğ‘š]âŠ¤ andletKbethe
matrixwithelementsğ¾
ğ‘–,ğ‘—
=k(xğ‘–,xğ‘—).Then(1.36)and(1.37)become
âŸ¨ğ‘“(Â·),ğ‘”(Â·)âŸ© =gâŠ¤f and âˆ¥ğ‘”(Â·)âˆ¥2 =gâŠ¤Kg.
k k
Tofindğ‘”(Â·)wemustfindthevectorgthatmaximisesgâŠ¤fsubjecttogâŠ¤Kg=
(cid:98) (cid:98)
1.
Let A be a square matrix such that AAâŠ¤ = K and set h = AâŠ¤g. Then,
equivalently,wewishtomaximisehâŠ¤Aâˆ’1fsuchthatâˆ¥hâˆ¥ =1.Wemustfind
theunit ğ‘š-vectorwiththelargestcomponentintheAâˆ’1f direction,which
is
Aâˆ’1f Aâˆ’âŠ¤Aâˆ’1f Kâˆ’1f
(cid:98)h=
âˆšï¸ (Aâˆ’1f)âŠ¤Aâˆ’1f
=â‡’ (cid:98)g= âˆš
fâŠ¤Aâˆ’âŠ¤Aâˆ’1f
= âˆš fâŠ¤Kâˆ’1f,
since (cid:98)g=Aâˆ’âŠ¤ (cid:98)h.Theinnerproduct (cid:98)gâŠ¤f is
fâŠ¤Kâˆ’1f âˆš
âˆš = fâŠ¤Kâˆ’1f.
fâŠ¤Kâˆ’1f
Thiscalculationonlyrequiresustobeabletoevaluate ğ‘“(xğ‘—) andk(xğ‘—,xğ‘˜)
for ğ‘—,ğ‘˜ = 1,...,ğ‘š.Wedonotneedtoknowtheeigenfunctions ğ‘’ (Â·),...
1
noreigenvaluesğœ† ,... ofğ‘‡ .Indeed,wedonotevenneedtoknowğœˆ;only
1 k
that(1.34)issatisfied.
Example 1.16 Let X = R and let k be the one-dimensional case of
the Gaussian kernel in Example 1.14. We find the approximations to the
function
1
ğ‘“(ğ‘¥) = ,
1+ğ‘¥2
usinggraduallymoreandmorekernelfunctionsk(ğ‘¥ ğ‘—,ğ‘¥).Forpoints,ğ‘¥ 1,...,ğ‘¥ ğ½,
K is the matrix with elements ğ¾ ğ‘–,ğ‘— = exp[âˆ’(ğ‘¥ ğ‘– âˆ’ğ‘¥ ğ‘—)2], and f is the vec-
tor with ğ‘“ ğ‘— = ğ‘“(ğ‘¥ ğ‘—). We set (ğ‘¥ 1,ğ‘¥ 2,ğ‘¥ 3,ğ‘¥ 4,ğ‘¥ 5,ğ‘¥ 6,ğ‘¥ 7) = (âˆ’3,...,3) and
approximate ğ‘“(ğ‘¥) using just ğ‘¥ then ğ‘¥ ,...,ğ‘¥ , then ğ‘¥ ,...,ğ‘¥ and finally
1 1 3 1 5
ğ‘¥ ,...,ğ‘¥ . Figure 1.6 compares the four approximations with the truth.
1 7
Eachtimenewpointsareaddedtotheset,theapproximationimproves,but40 Background
   
 7
 $
     %
 &
 '
   
   
   
   
         
x
Figure1.6 Thefunction ğ‘“(ğ‘¥) =1/(1+ğ‘¥2)(T)andkernel-based
approximationsto ğ‘“(ğ‘¥)fromExample1.16.CurvesuseA:
ğ‘¥ =âˆ’3,B:ğ‘¥ =âˆ’3,âˆ’2,âˆ’1,C:ğ‘¥ =âˆ’3,...,1andD:ğ‘¥ =âˆ’3,...,3.
itmatterswherethepointsareadded;somebasisvectorsaremorehelpful
thanothers.
1.6 ChapterNotes
Therearemanytextswhichcovertheintroductorymaterialfromthischapter
inmoredepthandrigourthanwehaveallowed;wesuggestafewoneach
topic.
BasicMonteCarloandimportancesamplingiscoveredinRipley(2009)
andRubinsteinandKroese(2008).ForanintroductiontoBayesianstatistics
and the use of Monte Carlo methods for Bayesian analysis, see Bernardo
andSmith(2009),Robert(2007)andRobertandCasella(1999).
Norris(1998)providesagentleintroductiontoMarkovchainsondiscrete
statespaces,whileMeynandTweedie(2012)givesathoroughtreatmenton
generalstatespaces;alessthoroughbutmorereadilyaccessibletreatment
for general state spaces is given in Roberts and Rosenthal (2004). Geyer
(1992) describes methods for estimating the integrated auto-correlation
 Q R L W F Q X I1.6 ChapterNotes 41
time from a sample of the chain when the Markov chain is reversible; for
thenon-reversiblechainsofChapter4theintegratedauto-correlationcanbe
estimatedbyfittinganauto-regressiveprocesstothetimeseries{â„(ğ‘‹ ğ‘˜)}ğ‘›
ğ‘˜=1
orbyestimatingthespectraldensityoftheseriesatafrequencyof0(e.g.
HeidelbergerandWelch,1981).
Stochastic differential equations and diffusions are the subject of Ok-
sendal (2013), Rogers and Williams (2000a) and Rogers and Williams
(2000b). An alternative to simple Monte Carlo, which attempts to obtain
betterconvergencerateswiththeMonteCarlosamplesizeğ‘›,isquasi-Monte
Carlo. See, for example, Caflisch (1998) for an introduction and Lâ€™Ecuyer
andLemieux(2002)forworkonrandomisedquasi-MonteCarlo.
Chapter 1 of Conway (2010) introduces Hilbert spaces in general, and
kernelsandreproducingkernelHilbertspacesarecoveredinChapter6of
RasmussenandWilliams(2005).Mercerâ€™sTheoremisusuallystatedfora
compactX;wehaveusedthegeneralisationtonon-compactspacesinSun
(2005).2
Reversible MCMC and its Scaling
BuildingontheintroductionstoBayesianstatistics,MonteCarlomethods
and Markov chains in Chapter 1, this section introduces Markov chain
MonteCarloalgorithmsasagenericcomputationalsolutiontothechallenge
ofusingMonteCarlomethodstosamplefromtheposteriordistributionand,
hence,estimateposteriorexpectationsofquantitiesofinterest.
As described in Chapter 1, if it is possible to sample directly from the
posterior, ğœ‹(ğœ½) := ğœ‹(ğœ½|D) (see equation (1.3)) then for any function â„
with E ğœ‹ (cid:2)â„2(ğœ½)(cid:3) < âˆ, it is possible to estimate E ğœ‹ [â„(ğœ½)] via the Monte
Carlo average (1.4), the typical error of which is of size ğ‘›âˆ’1/2, where ğ‘› is
thenumberofsamples.Unfortunately,itisusuallynotpossible,oriscom-
putationallyinfeasible,togenerateindependentandidenticallydistributed
samplesfrom ğœ‹.Importancesamplingprovides,perhaps,themostnatural
alternativetodirectsampling;however,asexemplifiedinSection1.1.5the
variance of importance sampling estimators typically degrades exponen-
tiallyquicklywithdimension.
Markov chain Monte Carlo (MCMC) is a generalisation of the Monte
Carlo method that, as we will see, has several favourable properties when
itcomestofacilitatingcomputationinBayesianstatisticsproblems.Inthis
context,theaimofMCMCistoconstructaMarkovchain, {ğœ½ğ‘˜}âˆ
ğ‘˜=1
whose
limitingdistributionistheposteriordistributionofinterest,sothatsamples
from a sufficiently long chain, except, perhaps, those near the beginning,
arise approximately from the posterior and can be used to create Monte
Carlo approximations to expectations as in (1.4), via the ergodic average
definedin(1.10).
The workhorse of MCMC is the Metropolisâ€“Hastings algorithm. We
describe the general Metropolisâ€“Hastings algorithm and show that the
resulting chain satisfies detailed balance with respect to ğœ‹. We then in-
vestigate particular special cases: the independence sampler, the random
walk Metropolis algorithm, the Metropolis-adjusted Langevin algorithm,
andHamiltonianMonteCarlo.Foreachofthesecases,weoverviewthebe-
422.1 TheMetropolisâ€“HastingsAlgorithm 43
haviourasthedimension ğ‘‘ â†’ âˆ,motivatingtheneedforfurtherscalable
methods.
Throughout this chapter, we denote the support of ğœ‹ by Î˜; for example
Î˜mightbeRğ‘‘ forsomeğ‘‘ âˆˆ N.
2.1 TheMetropolisâ€“HastingsAlgorithm
TheideaoftheMetropolisâ€“Hastingsalgorithmistodefinethedynamicsof
aMarkovchainbyspecifyinganarbitraryproposaldistributionforthenext
stateoftheMarkovchain,andthenhavingamechanismwherethisproposal
iseitheracceptedorrejected.Ifitisrejected,thestateoftheMarkovchainis
unchanged.Aswewillsee,itisgenerallypossibletochoosetheacceptance
probabilitytodependonthetargetdistribution,sothattheresultingMarkov
chainwillhavethetargetdistributionasitsstationarydistribution.
TheMetropolisâ€“HastingsalgorithmisgiveninAlgorithm1.Theposte-
rior density, ğœ‹, appears in both the numerator and denominator of the ac-
ceptanceprobability,ğ›¼(ğœ½ğ‘˜,ğœ½â€²),sotermsinvolvingthetypicallyintractable
density ğœ‹(ğœ½) can be replaced with the tractable product of the prior and
the likelihood, ğœ‹ (ğœ½)ğ¿(ğœ½;D); we do not need to know the normalising
0
constant, ğ‘(D) =âˆ« ğœ‹ (ğœ½)ğ¿(ğœ½;D)dğœ½,asitwillcancelintheratio.
Î˜ 0
As well as ğœ‹(ğœ½), and an initial value for the parameter vector, the
Metropolisâ€“Hastingsalgorithmrequiresaproposaldensity,ğ‘(ğœ½â€²|ğœ½).Com-
monchoicesofthedensityğ‘ includethefollowing:
Metropolisâ€“Hastingsindependencesampler(MHIS) ğ‘(ğœ½â€² | ğœ½) := ğ‘â€²(ğœ½â€²)
forsomedensity ğ‘â€².Theproposaldoesnotdependonthecurrent
state; for example, ğ‘â€² could be the same as a sensible importance
samplingproposaldistribution(seeSection1.1.5).
RandomwalkMetropolis(RWM) ğ‘(ğœ½â€² | ğœ½) = ğ‘â€²(ğœ½â€² âˆ’ ğœ½), where ğ‘â€² is
a density such that for any vector v âˆˆ Î˜, ğ‘â€²(v) = ğ‘â€²(âˆ’v). For
example ğœ½â€²|ğœ½ âˆ¼ N(ğœ½,ğœ†2Iğ‘‘),whereIğ‘‘ isthe ğ‘‘ Ã—ğ‘‘ identitymatrix
andğœ† > 0.
Metropolis-adjustedLangevinalgorithm(MALA) addsaspecificform
ofoffsettoaGaussianRWMproposal.Forexample,ğœ½â€²|ğœ½ âˆ¼N(ğœ½+
1ğœ†2âˆ‡logğœ‹(ğœ½),ğœ†2Iğ‘‘).
2
HamiltonianMonteCarlo(HMC) starting from ğœ½ and with a random
momentum,suchaspâˆ¼N(0,ğ‘€Iğ‘‘),Hamiltoniandynamicsareap-
proximatelyintegratedforwardsonapotentialsurfaceofâˆ’logğœ‹(ğœ½).
Theproposal,ğœ½â€²,isthepositionaftersomefixedtimeğ‘‡.44 ReversibleMCMCanditsScaling
Laterinthischapterwedescribeandinvestigatetheseclassesofproposals
inmoredetailandexaminetheirrelativeefficiencies.
Algorithm1:Metropolisâ€“Hastingsalgorithm
Input:Densityğœ‹(ğœ½),initialvalueğœ½ andproposaldensityğ‘(ğœ½â€²|ğœ½).
0
for ğ‘˜ âˆˆ 0,...,ğ‘›âˆ’1do
Proposeğœ½â€² fromğ‘(ğœ½â€²|ğœ½ğ‘˜)
Calculatetheacceptanceprobability:
ğ›¼(ğœ½ğ‘˜,ğœ½â€²) :=min(cid:18) 1, ğœ‹ğœ‹ (( ğœ½ğœ½ ğ‘˜â€²) )ğ‘ ğ‘( (ğœ½ ğœ½ğ‘˜ â€²|| ğœ½ğœ½ ğ‘˜â€²) )(cid:19) . (2.1)
Withaprobabilityofğ›¼(ğœ½ğ‘˜,ğœ½â€²) accepttheproposal,ğœ½ğ‘˜+1 â† ğœ½â€²;
otherwiserejectit,ğœ½ğ‘˜+1 â† ğœ½ğ‘˜.
end
That the Metropolisâ€“Hastings algorithm has a stationary density of ğœ‹,
follows directly from the fact that it is reversible with respect to ğœ‹ (see
Section1.3).Wenowshowthatthisisthecase.First,noticethat
ğœ‹(ğœ½)ğ‘(ğœ½â€²|ğœ½)ğ›¼(ğœ½,ğœ½â€²) = ğœ‹(ğœ½â€²)ğ‘(ğœ½|ğœ½â€²)ğ›¼(ğœ½â€²,ğœ½),
sincebotharemin(ğœ‹(ğœ½)ğ‘(ğœ½â€²|ğœ½),ğœ‹(ğœ½â€²)ğ‘(ğœ½|ğœ½â€²)).Nowsupposethatğœ½ğ‘˜ âˆ¼ ğœ‹,
letB,C âŠ† Î˜andletAbetheeventthattheproposalisaccepted.Then
âˆ« âˆ«
P(A,ğœ½ğ‘˜ âˆˆ B,ğœ½ğ‘˜+1 âˆˆ C) = ğœ‹(ğœ½ğ‘˜)ğ‘(ğœ½â€² | ğœ½ğ‘˜)ğ›¼(ğœ½ğ‘˜,ğœ½â€²) dğœ½â€²dğœ½ğ‘˜
ğœ½ğ‘˜âˆˆB ğœ½â€²âˆˆC
âˆ« âˆ«
= ğœ‹(ğœ½â€²)ğ‘(ğœ½ğ‘˜ | ğœ½â€²)ğ›¼(ğœ½â€²,ğœ½ğ‘˜) dğœ½ğ‘˜dğœ½â€²
ğœ½ğ‘˜âˆˆB ğœ½â€²âˆˆC
âˆ« âˆ«
= ğœ‹(ğœ½ğ‘˜)ğ‘(ğœ½â€² | ğœ½ğ‘˜)ğ›¼(ğœ½ğ‘˜,ğœ½â€²) dğœ½ğ‘˜dğœ½â€²
ğœ½â€²âˆˆB ğœ½ğ‘˜âˆˆC
=P(A,ğœ½ğ‘˜ âˆˆ C,ğœ½ğ‘˜+1 âˆˆ B)
where,onthepenultimatelinewehaveswitchedthelabels.Sinceğœ½ğ‘˜ = ğœ½ğ‘˜+1
onarejection,wealsohavethat
(cid:16) (cid:17) (cid:16) (cid:17)
P Aâˆ,ğœ½ğ‘˜ âˆˆ B,ğœ½ğ‘˜+1 âˆˆ C =P Aâˆ,ğœ½ğ‘˜ âˆˆ C,ğœ½ğ‘˜+1 âˆˆ B .
SummingthetwoequalitiesaboveforAandAâˆ gives
P(ğœ½ğ‘˜ âˆˆ B,ğœ½ğ‘˜+1 âˆˆ C) =P(ğœ½ğ‘˜ âˆˆ C,ğœ½ğ‘˜+1 âˆˆ B),
asrequired.2.1 TheMetropolisâ€“HastingsAlgorithm 45
Burn-In,Mixing,EstimatorsandtheirVariance
Typically, the initial value for the Markov chain is not sampled from ğœ‹,
sinceifitwerepossibletodothisthentherewouldbenoneedforMCMC.
Hence,themarginaldistributionsofearlypointsintheMarkovchainmight
notbesufficientlyclosetoğœ‹.Inpractice,wediscardsuchearlypointsfrom
the sample; the terms warm-up or burn-in are applied to both this initial
period and the samples that arise from it. Here, we imagine that there are
ğ‘burn-insamples,ğœ½ âˆ’ğ‘+1,...ğœ½
0
andthattheremainingsamples,whichare
deemedtobefromachainthathasapproximatelyconverged,areğœ½ 1,...,ğœ½ğ‘›.
The expectation of any function â„(ğœ½) with respect to the posterior is then
estimatedvia:
ğ‘›
1 âˆ‘ï¸
(cid:98)ğ¼ ğ‘›(â„) :=
ğ‘›
â„(ğœ½ğ‘˜). (2.2)
ğ‘˜=1
FollowingtheexpositioninSection1.3.2,subjecttoconditions,including
thatE
ğœ‹
(cid:2)â„(ğœ½)2(cid:3) < âˆ,thevarianceofthisestimatormaybeapproximated
as in (1.15); this is an approximation both because the Markov chain has
notfullyconvergedaftertheğ‘burn-initerations,andbecauseğ‘›isfinite.As
withstandardMonteCarloestimates,thestandarderrordecreasesasğ‘›âˆ’1/2;
however,theconstantofproportionalityis(typically)higher,reflectingthe
factthatthesamplesare(typically)positivelycorrelated.
In most MCMC algorithms, the positive correlation arises from two
separatesources:firstly,aproposalmayberejected,inwhichcasethenew
position of the chain is the same as the old position; secondly most types
ofMetropolis-Hastingsalgorithmarelocal:theproposalis,insomesense,
closetothecurrentvaluewhencomparedtothesizeofthemainposterior
mass. Consequently, the chain can take many iterations to move from one
part of the posterior to another. The act of moving around the posterior
is termed mixing and in this book we informally refer to the number of
iterations taken to move substantially within the context of the posterior
distributionasthemixingtime.
RunningExample
The following running example of an isotropic Gaussian target distribu-
tion serves to demonstrate some properties of the Metropolisâ€“Hastings
algorithm in practice. In the next section, it will be used to illustrate the
different measures of efficiency of a Metropolisâ€“Hastings Markov chain
algorithm.46 ReversibleMCMCanditsScaling
Example2.1 Givenğ‘‘ âˆˆ N,andğœ½ = (ğœƒ 1,...,ğœƒ ğ‘‘)âŠ¤,let
(cid:32) ğ‘‘ (cid:33) (cid:18) (cid:19)
1 1âˆ‘ï¸ 1 1
ğœ‹ ğ‘‘(ğœ½) =N(ğœ½;0,Iğ‘‘) â‰¡
(2ğœ‹)ğ‘‘/2
exp âˆ’
2
ğœƒ ğ‘–2 â‰¡
(2ğœ‹)ğ‘‘/2
exp âˆ’ 2âˆ¥ğœ½âˆ¥2 ,
ğ‘–=1
where âˆ¥Â·âˆ¥ denotestheEuclideannorm,andIğ‘‘ theğ‘‘Ã—ğ‘‘ identitymatrix.
Fornow,weexploretheabovetargetusingtheRWMalgorithmdescribed
above:
(cid:18) (cid:19)
1 1
ğ‘(ğœ½â€²|ğœ½) =N(cid:0) ğœ½â€²;ğœ½,ğœ†2Iğ‘‘(cid:1) â‰¡
(2ğœ‹)ğ‘‘/2ğœ†ğ‘‘
exp âˆ’ 2ğœ†2âˆ¥ğœ½â€²âˆ’ğœ½âˆ¥2 .
Figure2.1showsplotsfromğ‘› =1000iterationsofthealgorithminExample
2.1 with ğ‘‘ = 1. The top plot starts from ğœ½ = 20 while the other two start
0
from ğœ½ = 1.Morethan99.7%oftheposteriormassliesbetween ğœ½ = âˆ’3
0
andğœ½ =3,andsothechainthatwasstartedoutsideofthisregionfirstheads
towardsthemainmass.Onceithasarrived,itthenexplorestheregionfor
the remainder of the time, ğ‘›. The exploration is slow because the scale of
theproposedjumps,ğœ† =0.2,issmallcomparedwiththesizeoftheregion.
With larger proposed jumps, ğœ† = 2, the exploration is much more rapid.
However, with jumps of sizeğœ† = 20, most of the proposals are outside of
thehigh-densityregion,sotheacceptanceratioissmallandtheproposals
arerejected.Thus,eventhoughtheproposedjumpsarelarge,thealgorithm
doesnotexploretherangeofposteriorvaluesquickly.
Î»=0.2 Î»=2 Î»=20
    
 
      
 
 
                                
k k k
Figure2.1 TraceplotsfromthreeRWMrunsonğœ‹ ğ‘‘ from
Example2.1withğ‘‘ =1,usinginitialvaluesof20,1and1,and
scalingsof0.2,2and20respectively.
Theory tells us that the distribution of ğœ½ğ‘˜ converges to ğœ‹ as ğ‘˜ â†’ âˆ.
For a finite ğ‘˜, ğœ½ğ‘˜ will not be an exact draw from ğœ‹ but it might be close.
In Figure 2.1 (left) we might deem the distribution sufficiently close after2.1 TheMetropolisâ€“HastingsAlgorithm 47
approximately300iterationsandsowemightdiscardğœ½ ,...,ğœ½ asburn-
0 299
inandtake{ğœ½ ,...,ğœ½ }tobeanapproximate,correlated,samplefrom
300 1000
ğœ‹foruseinaMonteCarloaverage,ğœ‡ (cid:98)â„,oftheform(1.4).Therunsillustrated
inFigure2.1(middleandright)startedfromasensiblevalueintheposterior
andso{ğœ½ ,...,ğœ½ }mightreasonablybeused.
1 1000
Let us now ignore the need for burn-in when ğœ½ = 20 and ğœ† = 0.2, or
0
considerathoughtexperimentwherethisalgorithmwasalsostartedfrom
ğœ½ = 1. From Figure 2.2, the sample obtained when ğœ† = 2 appears to
0
represent ğœ‹,whichissymmetricaboutasinglemodeat0andhassupport
beyond Â±2, much better than either of the other two samples. Thus, we
mightexpectestimates, ğœ‡ (cid:98)â„,obtainedfromthealgorithmwhenğœ† =2tobe,
insomesense,moreaccurate.
   
       
   
   
   
   
           
                   
Î¸ Î¸ Î¸
Figure2.2 Histogramsofthesamplesobtainedfromthe
algorithmsinFigure2.1.Theleftplot(correspondingtoğœ† =0.2,
ğœ½ =20)wascreatedafterdiscarding{ğœ½ ,...,ğœ½ }asburn-in;
0 0 299
fortheothertworuns(centre:ğœ† =2;right:ğœ† =20)onlyğœ½ was
0
discarded.
The empirical acceptance rate for a Metropolisâ€“Hastings algorithm is
the fraction of the ğ‘› proposals that were accepted. For the three RWM
algorithms, these were respectively 0.881, 0.485 and 0.059; the smaller
the proposed jumps, the closer ğœ‹(ğœ½â€²) typically is to ğœ‹(ğœ½ğ‘˜) and so the
higher the acceptance rate. For a stationary Metropolisâ€“Hastings Markov
chain,theempiricalacceptancerateapproximatesthetrueacceptancerate
atstationarity:
ğ›¼ =E
ğœ½âˆ¼ğœ‹,ğœ½â€²âˆ¼ğ‘(Â·|ğœ½)
[ğ›¼(ğœ½,ğœ½â€²)]
AspectsoftheproposalfortheRWM,MALAandHMCareoftentunedby
targetinganempiricalacceptanceratethatisneithertoohighnortoolow.In
latersections,theacceptanceratewillprovideuswithanintuitiveentrance
intothebehaviourofthecanonicalMetropolisâ€“Hastingsalgorithmsasthe
 \ W L V Q H '  \ W L V Q H '  \ W L V Q H '48 ReversibleMCMCanditsScaling
dimension of the parameter vector increases. Here it will be helpful to
define the acceptance ratio: ğœŒ(ğœ½,ğœ½â€²) := ğœ‹(ğœ½â€²)ğ‘(ğœ½|ğœ½â€²)/{ğœ‹(ğœ½)ğ‘(ğœ½â€²|ğœ½)}, so
thatğ›¼(ğœ½,ğœ½â€²) =min[1,ğœŒ(ğœ½,ğœ½â€²)].
2.1.1 Component-wiseupdatesandGibbsmoves
Algorithm1,theMetropolisâ€“Hastingsalgorithm,andallofthespecialcases
that we will examine in this chapter, are written so that a single iteration
consistsofaproposaltochangetheentireğœ½vectorandadecisiononwhether
ornottoacceptthisproposal.However,itisalsopossible,andsometimes
helpful,tosequentiallyupdatesubsetsofthecomponentsofğœ½.Indeed,each
iterationoftheveryfirstMetropolisâ€“Hastingsalgorithm(Metropolisetal.,
1953) cycled through pairs of components (ğ‘¥ and ğ‘¦ coordinates of each
particleinalatticeofalargenumberofparticles),applyingarandomwalk
Metropolisupdateonepairatatime.
Denote the set of components to be updated by
ğœ½(ğ‘–)
and the remaining
componentsbyğœ½(âˆ’ğ‘–).Bywritingthetargetasğœ‹(ğœ½) = ğœ‹(ğœ½(âˆ’ğ‘–))ğœ‹(ğœ½(ğ‘–)|ğœ½(âˆ’ğ‘–)),
and the proposal as ğ‘ ğ‘–(ğœ½â€²(ğ‘–)|ğœ½(ğ‘–),ğœ½(âˆ’ğ‘–)), essentially the same argument as
foraproposalthatchangesallcomponentsshowsthatthecomponent-wise
propose/accept-rejectstepwithanacceptanceprobabilityof
min(cid:18)
1,
ğœ‹(ğœ½â€²(ğ‘–)|ğœ½(âˆ’ğ‘–))ğ‘ ğ‘–(ğœ½(ğ‘–)|ğœ½â€²(ğ‘–),ğœ½(âˆ’ğ‘–))(cid:19)
ğœ‹(ğœ½(ğ‘–)|ğœ½(âˆ’ğ‘–))ğ‘ ğ‘–(ğœ½â€²(ğ‘–)|ğœ½(ğ‘–),ğœ½(âˆ’ğ‘–))
satisfiesdetailedbalancewithrespecttothefullposterior, ğœ‹.Ofcourse,if
only that move were used, some components would never be updated, the
algorithm would be reducible, and ergodic averages would, therefore, not
convergetothecorrespondingtrueexpectations.Thecompositionofmany
such moves over different components, typically, does not satisfy this de-
tailedbalancecondition,but,sinceeachmovepreservesğœ‹,thecomposition
does,too.
Inthespecialcasewheretheproposalfortheğ‘–thblockofcomponentsis
ğ‘ ğ‘–(ğœ½â€²(ğ‘–)|ğœ½ğ‘˜) := ğœ‹(ğœ½â€²(ğ‘–)|ğœ½ ğ‘˜(âˆ’ğ‘–)),
theacceptanceprobabilityis1andthemoveiscalledaGibbsmove.Sucha
moveisonlyfeasiblewhenitispossibletosamplefromğœ‹(ğœ½(ğ‘–)|ğœ½(âˆ’ğ‘–))which
ğ‘˜
most usually occurs when, conditional on
ğœ½(âˆ’ğ‘–),
the prior for
ğœ½(ğ‘–)
is con-
ğ‘˜
jugate with its likelihood. For example, when ğ‘¦ 1,...,ğ‘¦ ğ‘ are independent
realisations from a N(ğœ‡,1/ğœ) distribution and ğœ‡ and ğœ have independent
priors with ğœ‡ following a Student-t distribution and ğœ âˆ¼ Gam(ğ‘,ğ‘), then
a posteriori ğœ|ğœ‡ âˆ¼ Gam(ğ‘ + ğ‘›/2,ğ‘ + 1 2(cid:205)ğ‘› ğ‘—=1(ğ‘¦ ğ‘– âˆ’ ğœ‡)2); this property is2.1 TheMetropolisâ€“HastingsAlgorithm 49
sometimes called conditional conjugacy. Gibbs moves offer a further ad-
vantagewhencomparedwithmanyotherMetropolis-Hastingsmoves,over
andabovethefactthattheacceptanceprobabilityis1:theupdatedparam-
etercomponentissampledfromthefullrangeofitsconditionalposterior.
Whencomponentsareclosetoindependent,thiscontrastswithalgorithms
suchastherandomwalkMetropolisandMALA,where,inmoderatetohigh
dimensions,themovesarelocalâ€“theproposedvalueisclosetothecurrent
value.However,when,asistypicallythecase,componentsarecorrelated,
the conditional posterior for a component can have a much smaller range
thanitsmarginalposterior,andsotheGibbsmoves,too,are,ineffect,local.
WhilsttheyareausefultoolintheMCMCarmoury,Gibbsmovesarenot
the focus of this book and for further information, we refer the interested
readertothegeneraltextscitedinSection2.3.
2.1.2 TheMetropolisâ€“HastingsIndependenceSampler
Consider the Metropolisâ€“Hastings independence sampler (MHIS) in the
case where ğ‘(ğœ½) = ğœ‹(ğœ½). In this case ğ›¼(ğœ½ğ‘˜,ğœ½â€²) = 1 and every proposal is
accepted.Sinceproposalsarefrom ğœ‹,theMHISprovidesuswithani.i.d.
samplefrom ğœ‹.Ofcourse,inpractice,wearetypicallynotabletosample
from ğœ‹, but this suggests a heuristic for the MHIS: choose a proposal so
thattheacceptancerateisascloseaspossibleto1.
Forunimodalposteriorsinlowdimensionsareasonableapproximation
canoftenbeobtainedbyfirstusinganumericalmethodtofindtheposterior
modeandthenchoosingaproposalthatmatchesthemodeandthecurvature
ofthelog-posterioratthispoint.Thisstrategydoesnotscalefavourablyto
highdimensions,however,asthefollowingsimpleexampleshows.
ConsidertheisotropicunitGaussianposteriorfromExample2.1anduse
thefollowingMHISproposal:
(cid:18) (cid:19)
1 1
ğ‘(ğœ½â€²|ğœ½) =N(0,ğœ2Iğ‘‘) â‰¡
(2ğœ‹)ğ‘‘/2ğœğ‘‘
exp âˆ’ 2ğœ2âˆ¥ğœ½â€²âˆ¥2 .
Theacceptanceratio, ğœŒ(ğœ½,ğœ½â€²),is
exp(âˆ’1âˆ¥ğœ½â€²âˆ¥2)exp(âˆ’ 1 âˆ¥ğœ½âˆ¥2) (cid:26) 1 (cid:18) 1 (cid:19) (cid:27)
2 2ğœ2 =exp 1âˆ’ (cid:0) âˆ¥ğœ½âˆ¥2âˆ’âˆ¥ğœ½â€²âˆ¥2(cid:1) ,
exp(âˆ’1âˆ¥ğœ½âˆ¥2)exp(âˆ’ 1 âˆ¥ğœ½â€²âˆ¥2) 2 ğœ2
2 2ğœ2
so
(cid:18) (cid:19) (cid:18) (cid:19)
1 1 1 1 1
logğœŒ(ğœ½,ğœ½â€²) = 1âˆ’ âˆ¥ğœ½âˆ¥2âˆ’ âˆ¥ğœ½â€²âˆ¥2 .
ğ‘‘ 2 ğœ2 ğ‘‘ ğ‘‘50 ReversibleMCMCanditsScaling
Ifthechainisstationary,thenâˆ¥ğœ½âˆ¥2 =(cid:205) ğ‘–ğ‘‘ =1ğœƒ ğ‘–2 âˆ¼ ğœ’ ğ‘‘2sinceğœƒ
ğ‘–
ğ‘– âˆ¼ğ‘–ğ‘‘ N(0,1).Thus
E(cid:2) âˆ¥ğœ½âˆ¥2/ğ‘‘(cid:3) = 1 and Var(cid:2) âˆ¥ğœ½âˆ¥2/ğ‘‘(cid:3) = 2/ğ‘‘, and the same properties hold
for âˆ¥ğœ½â€²/ğœâˆ¥2/ğ‘‘. Thus, in high dimensions, to a first-order approximation,
âˆ¥ğœ½âˆ¥2/ğ‘‘ â‰ˆ1and âˆ¥ğœ½â€²âˆ¥2/ğ‘‘ â‰ˆ ğœ2 and
(cid:18) (cid:19)
1 1 1
logğœŒ(ğœ½,ğœ½â€²) â‰ˆ 1âˆ’ (cid:0) 1âˆ’ğœ2(cid:1).
ğ‘‘ 2 ğœ2
Thisgivesafirst-orderapproximationtotheacceptancerateof
(cid:18) (cid:26) ğ‘‘ (cid:27)(cid:19)
min 1,exp âˆ’ (cid:0)ğœ2âˆ’1(cid:1)2 ,
2ğœ2
which grows exponentially small with dimension unless ğœ = 1. Alterna-
âˆš
tively,stabilisingtheacceptancerateabovezerorequiresğœ2 =1+ğ‘‚(1/ ğ‘‘);
theapproximationmustbecomemoreandmoreaccurateasğ‘‘ â†’âˆ.
The exponential decrease in acceptance rate with dimension is closely
linked with the exponential increase in the variance of the weights with
dimensionintheimportancesamplingexampleattheendofSection1.1.5.
Inhighdimensions,asufficientlyaccurateandtractableapproximation,ğ‘,
israrelyavailable;consequentlyimportancesamplingandMHISarerarely
used,exceptinrelativelysimple,low-dimensionalscenarios.
2.1.3 TheRandomWalkMetropolisAlgorithm
TherandomwalkMetropolis(RWM)algorithmwasthefirstMCMCalgo-
rithmtoeverbeused.Unliketheindependencesampler,itdoesnotrequire
anaccurateglobalapproximationtotheposteriorandcanbetunedsothat
itworkseveninveryhighdimensions.Furthermore,unlikethealgorithms
that we shall explore subsequently, it does not require the gradient of the
logposterior.
ThemostfrequentlyusedRWMproposal,theso-calledpreconditioned
RWM, has the form ğœ½â€²|ğœ½ = ğœ½ + N(0,ğœ†2V), where V is an estimate of
the posterior variance matrix and ğœ† is a tunable scaling parameter. This
enhancement can increase the efficiency of the algorithm by many orders
ofmagnitudewhenthecomponentsofğœ½ arehighlycorrelatedand/orvary
onverydifferentlengthscales.However,whatevertheproposal,theRWM
constraint, that ğ‘(ğœ½â€²|ğœ½) = ğ‘(ğœ½|ğœ½â€²), means that the acceptance probability
simplifiestomin{1,ğœ‹(ğœ½â€²)/ğœ‹(ğœ½)}.2.1 TheMetropolisâ€“HastingsAlgorithm 51
ScalingofRWMwithDimension
We again consider the isotropic Gaussian posterior of Example 2.1 and
showhowtheRWMalgorithmusingaN(ğœ½,ğœ†2Iğ‘‘)proposalcanbemadeto
worknomatterwhatthedimension.
Writetheproposalasğœ½â€² = ğœ½ +ğœ†Z,whereZ âˆ¼ N(0,Iğ‘‘).Thelogaccep-
tanceratioisthen
1 1 1
logğœŒ(ğœ½,ğœ½â€²) =âˆ’ âˆ¥ğœ½ +ğœ†Zâˆ¥2+ âˆ¥ğœ½âˆ¥2 =âˆ’ğœ†âˆ¥ğœ½âˆ¥(cid:98)ğœ½ Â·Zâˆ’ ğœ†2âˆ¥Zâˆ¥2
2 2 2
1
=D âˆ’ğœ†âˆ¥ğœ½âˆ¥ ğ‘â€²âˆ’ ğœ†2âˆ¥Zâˆ¥2, (2.3)
2
where ğ‘â€² âˆ¼ N(0,1) and (cid:98)ğœ½ = ğœ½/âˆ¥ğœ½âˆ¥. Now âˆ¥Zâˆ¥2 âˆ¼ ğœ’ ğ‘‘2 and âˆ¥ğœ½âˆ¥2 âˆ¼ ğœ’ ğ‘‘2,
and by the same argument as used for the MHIS, we might make a first
âˆš
approximation of âˆ¥Zâˆ¥2 â‰ˆ ğ‘‘ and âˆ¥ğœ½âˆ¥ â‰ˆ ğ‘‘, from which it appears that
the acceptance ratio must decay exponentially quickly with dimension.
However,thisneednotbethecase,sincewecancontrolthescaling,ğœ†.The
âˆš
factthat âˆ¥ğ‘âˆ¥2/ğ‘‘ â‰ˆ1and âˆ¥ğœ½âˆ¥/ ğ‘‘ â‰ˆ1suggestssetting
â„“
ğœ† = âˆš (2.4)
ğ‘‘
forsomefixedâ„“ > 0.Inthiscase
(cid:20) (cid:26) âˆ¥ğœ½âˆ¥ 1 1 (cid:27)(cid:21)
ğ›¼(ğœ½,ğœ½â€²) =D min 1,exp âˆ’â„“ğ‘â€² âˆš âˆ’ â„“2 âˆ¥Zâˆ¥2
ğ‘‘ 2 ğ‘‘
(cid:20) (cid:26) (cid:27)(cid:21)
1
â‰ˆmin 1,exp âˆ’â„“ğ‘â€²âˆ’ â„“2 .
2
Thisquantityisstableawayfromzeroanddoesnotdependondimension.
Takingexpectations,elementarycalculusgives
(cid:18) (cid:19)
1
E
ğœ½âˆ¼ğœ‹,ğœ½â€²âˆ¼ğ‘(Â·|ğœ½)
[ğ›¼(ğœ½,ğœ½â€²)] â‰ˆ2Î¦ âˆ’ 2â„“ ,
whereÎ¦isthecumulativedistributionfunctionofastandardnormalrandom
variable. This equation describes how, for a high-dimensional Gaussian
target,theacceptanceratedecreasesasthe(dimensionally-adjusted)scaling,
â„“,increases.
Indeed, much more is true. Figure 2.3 shows trace plots for ğœƒ , the first
1
component of ğœ½, when ğ‘‘ = 50 and when ğ‘‘ = 500 and using a scaling of
âˆš
ğœ† = â„“/ ğ‘‘ with â„“ = 2. The behaviours of the trace plots appear similar,
except that when ğ‘‘ = 500 the time scale over which the process explores
theposterioristentimesthatwhenğ‘‘ =50.52 ReversibleMCMCanditsScaling
d=50
 
 
 
 
 
 
 
                              
k
d=500
 
 
 
 
 
 
 
                                    
k
Figure2.3 Traceplotsforthefirstcomponent,ğœƒ ,ofğœ½ fora
1
RWMHonğœ‹(ğœ½) âˆexp(âˆ’1âˆ¥ğœ½âˆ¥2)inğ‘‘ =50(top)andğ‘‘ =500
2
(bottom).Bothalgorithmswereinitialisedusingasamplefromğœ‹
âˆš
andeachusedascalingofğœ† =â„“/ ğ‘‘ withâ„“ =2.
âˆš
As dimension goes to infinity, with a scaling of â„“/ ğ‘‘ and with time
sped up by a factor of ğ‘‘ (essentially running for ğ‘›ğ‘‘ iterations rather than
ğ‘›),thepathofthefirstcomponentapproaches(indistribution)thepathof
thestochasticdifferentialequation(2.5),below.Forsimplicityofnotation,
wedenotethefirstcomponentbyğœƒ anddenoteitsmarginaldistributionby
ğ‘“(ğœƒ) âˆexp(âˆ’ğœƒ2/2).
dğœƒ ğ‘¡ = 1 [log ğ‘“(ğœƒ ğ‘¡)]â€² â„(â„“)dğ‘¡+âˆšï¸ â„(â„“)dğ‘Š ğ‘¡, (2.5)
2
where â„(â„“) = â„“2 Ã—2Î¦(âˆ’â„“/2). This is the OU process defined in (1.17),
Î¸
Î¸2.1 TheMetropolisâ€“HastingsAlgorithm 53
with ğ‘ = âˆšï¸â„(â„“);ithasaN(0,1) stationarydistribution.Here, â„(â„“) canbe
thoughtofasthespeed ofthediffusion,withalargervaluecorresponding
to a diffusion that will converge to stationarity more quickly, and can be
maximised with respect to â„“, giving â„“ â‰ˆ 2.38. This corresponds to an
opt
acceptancerateof2Î¦(âˆ’â„“ /2) â‰ˆ0.234,andleadstothewell-knownadvice
opt
to choose the RWM scaling so that the acceptance rate is approximately
1/4.
Ofmoreimportanceforusisthatthelimitingprocessisapproachedby
âˆš
lettingğœ† =â„“/ ğ‘‘andspeedinguptimebyafactorofğ‘‘.Reversingthislogic,
in dimension ğ‘‘, the first component moves ğ‘‘ times more slowly than the
diffusion.Inotherwordsthetimeor,equivalently,thenumberofiterations
takenbytheRWMtoexploretheposteriorindimension ğ‘‘ isproportional
toğ‘‘.
Figure2.4emphasisesthislineardependenceondimensionbycontinu-
ingtheexampleinFigure2.3.Indimensionğ‘‘ =50,thealgorithmisrunfor
ğ‘› =10000iterations,andforeachcomponent,theauto-correlationsarecal-
culateduptoalagof300.Thedottedbluelineshowsthecomponent-wise
averageofeachauto-correlation.For ğ‘‘ = 500,ğ‘› = 100000iterationswere
usedandauto-correlationsuptoalagof3000werecalculated.Thedashed
red line shows the component-wise averages plotted against lag/10. The
curves are almost indistinguishable and the resulting estimated integrated
auto-correlation times are, respectively, 70 and 718. The corresponding
effectivesamplesizesare,therefore,almostidentical,eventhoughtheex-
perimentwithğ‘‘ =500usedtentimesthenumberofiterations.
The above arguments have been made rigorous and applied to more
complextargetssuchasğœ‹(ğœ½) =(cid:206) ğ‘–ğ‘‘ =1ğ¶ ğ‘–ğ‘“(ğ¶ ğ‘–ğœƒ ğ‘–),foralargeclassofdensity
functions ğ‘“ (see Roberts and Rosenthal, 2001, for example). The limiting
process for the first coordinate becomes a Langevin diffusion (1.20) with
a stationary density of ğ¶ ğ‘“(ğ¶ ğœƒ ), and in all cases the time taken by the
1 1 1
RWMtoexplorethetargetisproportionaltoğ‘‘.
2.1.4 TheMetropolis-AdjustedLangevinAlgorithm
The Metropolis-adjusted Langevin algorithm (MALA) differs from the
RWM proposal of ğœ½â€²|ğœ½ âˆ¼ N(ğœ½,ğœ†2Iğ‘‘) through an additional determinis-
ticoffsetof 1ğœ†2âˆ‡logğœ‹(ğœ½).Wemotivatethisproposalandthengeneraliseit
2
toallowpreconditioningviaapositivedefinitevariancematrix,V;aswith
theRWM,thiscanbringdramaticefficiencyimprovementsinpractice.
The deterministic offset can be seen as an additional movement in the
â€œuphillâ€ direction, that is biasing the proposal to move to areas of higher54 ReversibleMCMCanditsScaling
    d=50
d=500
   
   
   
   
   
             
 O D J (d=50)  R U  O D J    (d=500)
Figure2.4 Component-wiseaverageauto-correlationplotsfora
RWMonğœ‹(ğœ½) âˆexp(âˆ’1âˆ¥ğœ½âˆ¥2)inğ‘‘ =50andğ‘‘ =500.Both
2
algorithmswereinitialisedusingasamplefromğœ‹andeachuseda
âˆš
scalingofğœ† =â„“/ ğ‘‘ withâ„“ =2.
posteriordensity;however,thereisadeepermotivation.Theproposalcan
bewrittenas
1
ğœ½â€²|ğœ½ = ğœ½ + ğœ†2âˆ‡logğœ‹(ğœ½)+ğ (2.6)
2
whereğ âˆ¼N(0,ğœ†2Iğ‘‘).
Substituting ğœ†2 = ğ›¿ğ‘¡, we see that the proposal is exactly the Eulerâ€“
Maruyama discretisation of the Langevin diffusion that has a stationary
distributionofğœ‹,(1.20)(withğ‘ =1).Inparticular,inthehypotheticallimit
as ğœ† â†“ 0 the algorithm should require no accept-reject step to target ğœ‹. In
thissense,itisanaturalformfortheproposal.
WenowderivethepreconditionedMALAproposal.Forageneralpositive-
definite V, let A be a square matrix such that AAâŠ¤ = V, and consider
ğ =Ağœ½.Multiplying(2.6)byAgives
1
ğâ€²|ğ =ğ+ ğœ†2Aâˆ‡ logğœ‹(ğœ½)+Ağ,
2 ğœ½
where we have made explicit that the gradient is with respect to ğœ½. The
Ï2.1 TheMetropolisâ€“HastingsAlgorithm 55
densityforğ is (cid:101)ğœ‹(ğ) âˆ ğœ‹(Aâˆ’1ğ) = ğœ‹(ğœ½).Further,âˆ‡ ğœƒ =AâŠ¤âˆ‡ ğœ“,so
1
ğâ€²|ğ =ğ+ ğœ†2Vâˆ‡ logğœ‹(ğ)+Ağ.
2 ğ (cid:101)
Since Ağ âˆ¼ N(0,ğœ†2V), this corresponds to the preconditioned MALA
proposal:
(cid:18) (cid:19)
1
ğœ½â€²|ğœ½ âˆ¼N ğœ½ + ğœ†2Vâˆ‡logğœ‹(ğœ½),ğœ†2V .
2
Whentheposteriorisunimodal,preconditionedMALAisoftenmosteffi-
cientwhenVisanapproximationtotheposteriorvariance.
WenowexplorethescalingofMALAwithdimensionandthesensitivity
tolargegradients.Inbothoftheseanalysesthefollowingsimplificationof
partofthelogacceptanceratiowillbehelpful.FortheMALAproposalin
(2.6),andwritingg(ğœ½) forthegradientatğœ½,
ğ‘(ğœ½|ğœ½â€²) 1 ğœ†2 1 ğœ†2
log = âˆ¥ğœ½â€²âˆ’ğœ½ âˆ’ g(ğœ½)âˆ¥2âˆ’ âˆ¥ğœ½ âˆ’ğœ½â€²âˆ’ g(ğœ½â€²)âˆ¥2
ğ‘(ğœ½â€²|ğœ½) 2ğœ†2 2 2ğœ†2 2
= 1 [g(ğœ½)+g(ğœ½â€²)]âŠ¤ (cid:2)ğœ†2g(ğœ½)âˆ’ğœ†2g(ğœ½â€²)+4(ğœ½ âˆ’ğœ½â€²)(cid:3)
8
=âˆ’1 [g(ğœ½)+g(ğœ½â€²)]âŠ¤ (cid:2)ğœ†2g(ğœ½)+ğœ†2g(ğœ½â€²)+4ğ(cid:3). (2.7)
8
ScalingofMALAwithDimension
IntheisotropicGaussianrunningexample,Example2.1,thelogacceptance
ratioforMALAis,using(2.7),
1 1 ğœ†2 1
logğœŒ(ğœ½,ğœ½â€²) = âˆ¥ğœ½âˆ¥2âˆ’ âˆ¥ğœ½â€²âˆ¥2âˆ’ âˆ¥ğœ½ +ğœ½â€²âˆ¥2+ (ğœ½ +ğœ½â€²)âŠ¤Z.
2 2 8 2
Substitutingğœ½â€² = (1âˆ’1ğœ†2)ğœ½+ğœ†Zfrom(2.6)andcollectingterms,weobtain
2
logğœŒ(ğœ½,ğœ½â€²) =âˆ’ğœ†3 (cid:20) ğœ†(cid:8) âˆ¥Zâˆ¥2âˆ’âˆ¥ğœ½âˆ¥2(cid:9) + 1 ğœ†3âˆ¥ğœ½âˆ¥2+(2âˆ’ğœ†2)ğœ½âŠ¤Z(cid:21) , (2.8)
8 4
whereZ âˆ¼ N(0,Iğ‘‘).Since âˆ¥Zâˆ¥2 and âˆ¥ğœ½âˆ¥2 areboth ğœ’ ğ‘‘2,eachhasanexpec-
tationofğ‘‘ andtheirdifferenceisğ‘‚ ğ‘(ğ‘‘1/2);further,ğœ½âŠ¤Zâˆ¼N(0,âˆ¥ğœ½âˆ¥2).
Tounderstandtherelativesizesofthetermsweinformallywrite:
(cid:104) (cid:16) (cid:17) (cid:16) (cid:17)(cid:105)
logğœŒ(ğœ½,ğœ½â€²) =ğœ†3 ğœ†ğ‘‚
ğ‘
ğ‘‘1/2 +ğœ†3ğ‘‚ ğ‘(ğ‘‘)+(2âˆ’ğœ†2)ğ‘‚
ğ‘
ğ‘‘1/2 .
Thus,withğœ† = â„“/ğ‘‘1/6,thefirsttermvanishesandthesecondandthirdare
ğ‘‚ ğ‘(1),leadingtoanacceptanceratiothatisğ‘‚ ğ‘(1).56 ReversibleMCMCanditsScaling
AsfortheRWM,itispossibletoobtainalimitingdiffusionoftheform
(2.5) for the first component of ğœ½ as the dimension goes to infinity. For
MALA, however, the required scaling is ğœ† = â„“/ğ‘‘1/6, time is sped up by a
factor of ğ‘‘1/3 (essentially running for ğ‘›ğ‘‘1/3 iterations rather than ğ‘›) and,
fortheGaussiantarget,thespeedofthediffusionis â„(â„“) = 2â„“2Î¦(âˆ’â„“3/4).
Optimising the speed with respect to the scaling leads to a recommended
acceptance rate of approximately, 57.4%. As with the RWM, the more
important point for us is that the limiting OU process mixes in a time of
ğ‘‚(1), so the original process, before it has been sped up, mixes in a time
ofğ‘‚(ğ‘‘1/3).Thisisconsiderablyfasterthantheğ‘‚(ğ‘‘) mixingoftheRWM.
AsfortheRWM,theaboveresult,whichisspecifictoaN(0,Iğ‘‘) target,
has been generalised to targets of the form ğœ‹(ğœ½) = (cid:206) ğ‘–ğ‘‘ =1ğ¶ ğ‘–ğ‘“(ğ¶ ğ‘–ğœƒ ğ‘–), again
leading to a Langevin diffusion for the first component in the limit as
ğ‘‘ â†’âˆ,anoptimalacceptancerateof57.4%,andrequiringtimetobesped
upbyafactorofğ‘‘1/3;seeRobertsandRosenthal(2001).
The above product results for MALA rely on the existence and good
behaviour of all derivatives of ğ‘“ up to the 7th order, and that the process
was started from stationarity. Christensen et al. (2005) investigates the
behaviourofMALAonahigh-dimensionalisotropicGaussiantargetwhen
the algorithm is started close to the mode. When a scaling of ğœ† = â„“/ğ‘‘1/6
is used, in the limit as ğ‘‘ â†’ âˆ the process, sped up by a factor of ğ‘‘1/3,
does not move. Substituting ğœ½ = 0, for example, into (2.8), we see that
logğœŒ = âˆ’ğœ†4âˆ¥Zâˆ¥2/8. Since âˆ¥Zâˆ¥2 = ğ‘‚ ğ‘(ğ‘‘), the acceptance probability is
approximately exp[âˆ’â„“4ğ‘‘1/3]. If, instead, a scaling of ğœ† = â„“/ğ‘‘1/4 is used
then then acceptance rate remains ğ‘‚ ğ‘(1) as ğ‘‘ â†’ âˆ. Christensen et al.
(2005) shows that this new process, sped up by a factor of ğ‘‘1/2, moves
deterministicallytowardstheregionofthemainposteriormass.Reductions
inefficiencycanalsooccurifonlylowerderivativesofthetargetarewell-
behaved.
Sensitivitytogradients
WhilstthescalingpropertiesofMALAarefavourablecomparedwiththose
oftheRWMandMHIS,theperformanceofMALAisnotoriouslysensitive
tolargegradients.Weillustratethiswithasimpleexampleinonedimension.
Example2.2 Let ğœƒ âˆˆ Randforsome ğ‘ > 0let ğœ‹(ğœƒ) âˆ exp(cid:0) âˆ’1|ğœƒ|ğ‘(cid:1) ,so
ğ‘
âˆ‡logğœ‹(ğœƒ) =âˆ’ğœƒ|ğœƒ|ğ‘âˆ’2 and |âˆ‡logğœ‹(ğœƒ)| = |ğœƒ|ğ‘âˆ’1.
Whenğ‘ > 2,whateverthe(fixed)valueofğœ†,forlargeenoughğœƒ,E[ğœƒâ€²|ğœƒ]
is dominated by the term 1ğœ†2âˆ‡logğœ‹(ğœƒ), so that (with a very high proba-
22.2 HamiltonianMonteCarlo 57
bility) the proposal has the opposite sign to the current value and a much
largermagnitude,ğœ†2|ğœƒ|ğ‘âˆ’1/2.
Writingğœ– =ğœ†ğ‘,whereğ‘ âˆ¼N(0,1),thelogacceptanceratioforMALA
is ğœŒ(ğœƒ,ğœƒâ€²) =logğœ‹(ğœƒâ€²)âˆ’logğœ‹(ğœƒ)+ğµ(ğœƒ,ğœƒâ€²),where,from(2.7),
1
ğµ(ğœƒ,ğœƒâ€²) = {ğœƒ|ğœƒ|ğ‘âˆ’2+ğœƒâ€²|ğœƒâ€²|ğ‘âˆ’2}{4ğœ†ğ‘ âˆ’ğœ†2ğœƒ|ğœƒ|ğ‘âˆ’2âˆ’ğœ†2ğœƒâ€²|ğœƒâ€²|ğ‘âˆ’2}. (2.9)
8
The highest order term in (2.9) arises from the product of ğœƒâ€² terms, so
it is negative and of order |ğœƒ|2(ğ‘âˆ’1)2. The difference in log posteriors is
dominated by logğœ‹(ğœƒâ€²) âˆ¼ âˆ’|ğœƒ|ğ‘(ğ‘âˆ’1), which is, again, large and negative.
Hence, the acceptance probability is almost certainly very close to 0. Un-
surprisingly, since the proposal is even further from the main mass than
the current value is, the proposal is almost certainly rejected. As ğœƒ moves
furtherandfurtherintothetailofthetarget,theaverage(overtheproposal
distribution) acceptance probability for MALA becomes arbitrarily small
andthealgorithmconvergesincreasinglyslowly.
In Example 2.2, similar poor behaviour occurs even with ğ‘ = 2 (a
Gaussianposterior),providedğœ†2 > 2.Moregenerally,MALAcanbecome
â€stuckâ€ anywhere that âˆ¥âˆ‡logğœ‹âˆ¥ is large. In particular, the basic MALA
algorithmshouldbeusedwithcautioniftheusersuspectsthattheposterior
hastailswhicharelighterthanGaussian.Mitigationsagainstthisbehaviour
arebrieflydiscussedintheChapterNotes.
2.2 HamiltonianMonteCarlo
We have seen that when the dimension ğ‘‘ is high, MALA can maintain a
highacceptanceratewithascalingofâ„“/ğ‘‘1/6,whereastheRWMrequiresa
scalingofâ„“/ğ‘‘1/2.Inotherwords,MALAcanproposemuchlargersensible
jumps than the RWM. As we shall see, Hamiltonian Monte Carlo allows
evenlargerjumpsthanMALA,whilstmaintainingahighacceptancerate.
Hamiltonian Monte Carlo (HMC) can be viewed as using a Metropolisâ€“
Hastings algorithm, but with a more intricate proposal mechanism than
thoseseensofar.
One may consider âˆ’logğœ‹(ğœ½) as a potential energy surface. Intuitively
onemaythinkofthisasaphysicalsurfaceonwhichaâ€œparticleâ€withmassğ‘€
currentlysitsataâ€œheightâ€(strictly,potentialenergy)ofâˆ’logğœ‹(ğœ½) abovea
currentparametervalue,ğœ½ âˆˆ Rğ‘‘.Toobtaintheproposal,theparticleisgiven
a random momentum, p âˆˆ Rğ‘‘ drawn from a symmetric distribution. The
truefrictionlessmotionthattheparticlewouldundergoalongthepotential58 ReversibleMCMCanditsScaling
surface according to Hamiltonian dynamics is approximated numerically.
Theproposalisthepositionğœ½â€² âˆˆ Rğ‘‘ afteratimeğ‘‡,atuningparameter.
Asweshallsee,thelog-acceptanceratioforthealgorithmcanbewritten
as
(cid:26) (cid:27)
1 1
logğœŒ(ğœ½,ğœ½â€²) =âˆ’logğœ‹(ğœ½)+ pâŠ¤pâˆ’ âˆ’logğœ‹(ğœ½â€²)+ pâ€²âŠ¤pâ€² ,
2ğ‘€ 2ğ‘€
where pâ€² is the momentum at timeğ‘‡. The term, pâŠ¤p/(2ğ‘€) is the kinetic
energy of the particle, and âˆ’logğœ‹(ğœ½) is the potential energy, so the ac-
ceptancerateismin[1,exp(âˆ’ğ›¿ğ¸)],whereğ›¿ğ¸ isthechangeintotalenergy
over time ğ‘‡. Frictionless motion conserves the total energy so that under
the exact dynamics the acceptance probability is 1. Numerical integration
approximates the dynamics, using an integration step size, ğœ–. A smaller ğœ–
gives a more accurate numerical scheme and a higher average acceptance
rate, but for a givenğ‘‡ it also requires more numerical steps and, hence, a
largercomputationalcost.
Wenowprovideamorerigorousdescriptionofastandardversionofthe
algorithm,includinganexplanationoftheacceptanceprobabilitythatleads
toastationarydistributionofğœ‹.
Thefirstcomponentofthealgorithmisapositive-definitemassmatrix,
M,theinverseofwhichplaysasimilarroletothepreconditioningmatrix
V used in the RWM and MALA. The mass of an object, as used in the
intuitive explanation above, is the ratio between the magnitude of a force
that is applied and the magnitude of the acceleration that results and is a
scalar. For additional generality, in HMC, we imagine that this ratio can
bedifferentalongeachofasetof ğ‘‘ orthogonalprincipalaxesleadingtoa
massmatrixratherthanascalar.
ThecorecomponentoftheHMCalgorithmisthenumericalintegration
scheme,whichrepeatedlyusestheleapfrogsteptodeterministicallyevolve
the position and momentum from a time ğ‘¡ to a time ğ‘¡ +ğœ–: (ğœ½ğ‘¡+ğœ–,pğ‘¡+ğœ–) =
Leap(ğœ½ğ‘¡,pğ‘¡;ğœ–,M),where
1 1
p
âˆ—
=pğ‘¡+ âˆ‡logğœ‹(ğœ½ğ‘¡), ğœ½ğ‘¡+ğœ– = ğœ½ğ‘¡+ğœ–Mâˆ’1p âˆ—, pğ‘¡+ğœ– =p âˆ—+ âˆ‡logğœ‹(ğœ½ğ‘¡+ğœ–).
2 2
HMCusestheleapfrogschemeratherthan,forexample,theEulerorRungeâ€“
Kutta schemes because the leapfrog scheme possesses two key properties
thatwillbediscussedshortly.
HMC repeats the leapfrog step ğ¿ times, where ğ¿ğœ– = ğ‘‡, to obtain the
proposal, ğœ½â€² = ğœ½ğ‘‡ as depicted in Figure 2.5. The proposed momentum is,
in fact, pâ€² = âˆ’pğ‘‡ and we denote the transformation: (ğœ½,p) â†’ (ğœ½â€²,pâ€²) by
ğ¿
Leap .
âˆ’2.2 HamiltonianMonteCarlo 59
 
 F X U U H Q W
 S U R S R V H G
 
 
 
 
 
 
             
Figure2.5 Initialpointğœ½ =ğœ½ 0 =+andfinalpointğœ½â€² =ğœ½ 2.5 =Ã—
afterğ¿ =25leapfrogstepsusingatimeintervalofğœ– =0.1anda
massmatrixofM=I .Themomentumatthecurrentand
2
proposedpoint(beforethemomentflip)isproportionaltothesize
ofthecorrespondingarrowandintermediatepointsappearas
smallsolidcircles.
Standard HMC proposes p from a N(0,M) distribution, and can be
viewed as targeting a joint density of (ğœ½,p) that is the product of the
densityforpandtheposterior:
ğœ‹(ğœ½,p) = ğœ‹(ğœ½)(2ğœ‹)âˆ’ğ‘‘/2det(M)âˆ’1/2exp(cid:2) âˆ’ 1 pâŠ¤Mâˆ’1p(cid:3)
(cid:101)
2
At the end of each iteration, we discard p, and the marginal for ğœ½ is ğœ‹,
as required. Algorithm 2 details the standard version of the Hamiltonian
MonteCarloalgorithm.
HMC combines a momentum refresh with a Metropolisâ€“Hastings step
whichusesadeterministicproposal(ğœ½,p) â† (ğœ½â€²,pâ€²) â‰¡Leapğ¿(ğœ½,p;ğœ–;M);
âˆ’
finallythenewmomentumisdiscarded.Themomentumrefreshmentpre-
servesğœ‹asitsamplesdirectlyfromthecorrectconditional.Wenowexplain
(cid:101)
whytheaccept-rejectstepwithadeterministicproposalalsopreservesğœ‹.
(cid:101)
Theleapfrogsteppossessestwokeyproperties:60 ReversibleMCMCanditsScaling
Algorithm2:HamiltonianMonteCarlo
Input:Densityğœ‹(ğœ½),initialvalueğœ½ ,massmatrixM,timeinterval
0
ğ‘‡,numberofleapfrogsteps ğ¿.
ğœ– â†ğ‘‡/ğ¿.
for ğ‘˜ âˆˆ 0,...,ğ‘›âˆ’1do
Samplepâˆ¼N(0,M).
(ğœ½â€²,pâ€²) â†Leap âˆ’ğ¿(ğœ½ğ‘˜,p).
Calculatetheacceptanceprobability:
(cid:18) ğœ‹(ğœ½â€²,pâ€²)(cid:19)
ğ›¼(ğœ½ğ‘˜,p;ğœ½â€²,pâ€²) :=min 1, (cid:101)
(cid:101)ğœ‹(ğœ½ğ‘˜,p)
.
Withaprobabilityofğ›¼(ğœ½ğ‘˜,p;ğœ½â€²,pâ€²) accepttheproposal,
ğœ½ğ‘˜+1 â† ğœ½â€²;otherwiserejectit,ğœ½ğ‘˜+1 â† ğœ½ğ‘˜.
end
Property1 LeaphasaJacobianof1.
Property2 IfLeap(ğœ½,p) = (ğœ½â€²,pâ€²) thenLeap(ğœ½â€²,âˆ’pâ€²) = (ğœ½,âˆ’p).
Property1 arisesbecause theLeapfrogis acomposition ofthreetransfor-
mations each of which has a Jacobian of 1. Property 2 is straightforward
to verify, and emulates frictionless dynamics in that if after moving for
sometimethemomentumofanobjectissuddenlyreversed,afterthesame
amountoftimeagaintheobjectwillendupbackwhereitstarted,moving
with the same speed as when it started but in the opposite direction. The
composition of ğ¿ leapfrog steps possesses the same property: in Figure
2.5, starting at the Ã— but with a momentum given by the reverse of the
corresponding arrow, and proceeding for 25 leapfrog steps leads to the +
position, but with a momentum of exactly the reverse of the true initial
momentumthatthecorrespondingarrowrepresents.
Naturally,Leapğ¿ ,thecompositionof ğ¿ leapfrogsteps,combinedwitha
âˆ’
ğ¿
momentumflip,alsohasaJacobianof1.Moreover,Leap isself-inverse:
âˆ’
Leapğ¿(Leapğ¿(ğœ½,p)) = (ğœ½,p); equivalently, from (ğœ½â€²,pâ€²) we would pro-
âˆ’ âˆ’
pose (ğœ½,p).
AsinSection2.1,thedetailedbalanceconditionistrivialunderrejection
sowefocusonacceptances.LetAbetheeventofanacceptanceandwrite
(ğœ½ğ‘˜,pğ‘˜) and (ğœ½ğ‘˜+1,pğ‘˜+1) for the position and momentum before and after
the acceptance step (and before the momentum is discarded). Then, for
B âˆˆ R2ğ‘‘ and C âˆˆ R2ğ‘‘, and writing Leapğ¿(A) for the image of a set A
âˆ’2.2 HamiltonianMonteCarlo 61
ğ¿
underLeap ,
âˆ’
P(A,(ğœ½ğ‘˜,pğ‘˜) âˆˆ B,(ğœ½ğ‘˜+1,pğ‘˜+1) âˆˆ C)
âˆ¬
= ğœ‹(ğœ½,p)ğ›¼(ğœ½,p;ğœ½â€²,pâ€²) d(ğœ½,p)
(cid:101)
Bâˆ©Leapâˆ’ğ¿(C)
âˆ¬
= ğœ‹(ğœ½â€²,pâ€²)ğ›¼(ğœ½â€²,pâ€²;ğœ½,p)) d(ğœ½â€²,pâ€²)
(cid:101)
Leapâˆ’ğ¿(B)âˆ©C
=P(A,(ğœ½ğ‘˜,pğ‘˜) âˆˆ C,(ğœ½ğ‘˜+1,pğ‘˜+1) âˆˆ B),
ğ¿
where on both intermediate lines we have used that Leap is self inverse
âˆ’
andthepenultimatelineusesthattheJacobianof (ğœ½,p) â†’ (ğœ½â€²,pâ€²) is1.
ScalingofHMCwithDimension
Givenaparticularintegrationtime,ğ‘‡,thesmallerthestepsize,ğœ–,themore
accurate the leapfrog scheme, and the closer the acceptance rate is to 1.
Atthesametime,thecomputationalcostisproportionaltothenumberof
leapfrog steps, ğ¿ = âŒˆğ‘‡/ğœ–âŒ‰. Alarge ğœ– leads tomany rejections anda small
ğœ– leads to a high computational cost, suggesting that there is an optimal
choiceofğœ– betweenthesetwoextremes.
Inthisanalysis,weconsiderageneralproducttarget,ğœ‹(ğœ½) =(cid:206) ğ‘–ğ‘‘
=1
ğ‘“(ğœƒ ğ‘–),
andassumeanidentitymassmatrix,M = Iğ‘‘.Inthiscase,theevolutionof
each (ğœƒ ğ‘–,ğ‘ ğ‘–) by Leap âˆ’ğ¿ does not depend on any of the other components.
TheacceptanceratioforHMCis
ğœŒ(ğœ½,p;ğœ½â€²,pâ€²) =
(cid:101)ğœ‹(ğœ½â€²,pâ€²) =(cid:214)ğ‘‘
ğœŒ(ğ‘–)
ğœ‹(ğœ½,p) 1
(cid:101) ğ‘–=1
where (ğœ½â€²,pâ€²) =Leapğ¿(ğœ½,p),adeterministicfunction,and
âˆ’
ğ‘“(ğœƒâ€²)N(ğ‘â€²;0,1)
ğœŒ(ğ‘–) = ğ‘– ğ‘– .
1 ğ‘“(ğœƒ ğ‘–)N(ğ‘ ğ‘–;0,1)
ğ¿
At stationarity, after cancellations, and using the unit Jacobian of Leap ,
âˆ’
wehave
(cid:104) (cid:105) âˆ«
E
ğœƒ ğ‘–âˆ¼ğ‘“,ğ‘ ğ‘–âˆ¼N(0,1)
ğœŒ 1(ğ‘–) = ğ‘“(ğœƒ ğ‘–â€²)N(ğ‘ ğ‘–â€²;0,1) dğœƒ ğ‘–dğ‘
ğ‘–
âˆ«
= ğ‘“(ğœƒâ€²)N(ğ‘â€²;0,1) dğœƒâ€²dğ‘â€² =1. (2.10)
ğ‘– ğ‘– ğ‘– ğ‘–
Moreover,theğœŒ(ğ‘–)
arei.i.d.,so,bythecentrallimittheorem,approximately,
1
ğ‘‘
âˆ‘ï¸
logğœŒ = logğœŒ
ğ‘–
âˆ¼N(ğ‘‘E[logğœŒ 1],ğ‘‘Var[logğœŒ 1]),
ğ‘–=162 ReversibleMCMCanditsScaling
fromwhichweseethatğœŒhasapproximatelyalognormaldistribution.From
(2.10), and the component-wise independence, E[ğœŒ] = 1, so E[logğœŒ] =
âˆ’1Var[logğœŒ]and,hence,E[logğœŒ ] â‰ˆâˆ’1Var[logğœŒ ].Thisgivesthesame
2 1 2 1
distributionforthelog-acceptanceratioaswefoundfortheRWMin(2.3)
withthesamescalingoftheexpectationandvariancewithdimensionifğœ†
(fortheRWM)orğœ– (forHMC)iskeptfixed.FortheRWM,thisnecessitated
takingğœ†2 âˆ 1/ğ‘‘;however,forHamiltoniandynamicsapproximatedbythe
leapfrog integrator with step size ğœ– over a time periodğ‘‡, the error in the
totalenergyisğ‘‚(ğœ–2);i.e.,E[|logğœŒ |] =ğ‘‚(ğœ–2).Thus
1
1
Var[logğœŒ ]+ Var[logğœŒ ]2
1 4 1
=Var[logğœŒ ]+E[logğœŒ ]2 =E(cid:2) (logğœŒ )2(cid:3) =ğ‘‚(ğœ–4).
1 1 1
Setting ğœ– = ğ‘‚(ğ‘‘âˆ’1/4) gives Var[logğœŒ ] = ğ‘‚(1/ğ‘‘), so both E[logğœŒ] and
1
Var[logğœŒ]areğ‘‚(1),asrequiredfortheacceptanceratiotobewell-behaved.
Taking ğœ– âˆ ğ‘‘âˆ’1/4, and ğ‘‡ fixed as dimension increases, implies that for a
given amount of movement in each component, the number of leapfrog
steps, and hence the computational cost, increases in proportion to ğ‘‘1/4.
Contrasting this with a cost of ğ‘‘1/3 for MALA and ğ‘‘ for the RWM shows
whyHMCisoftenthealgorithmofchoiceforhigh-dimensionaltargets.
TuningHMC
Afteramorerigorousscalinganalysisthanourheuristicexplanation,Beskos
etal.(2013)concludesthatgivenğ‘‡,inthehigh-dimensionallimit,ğœ– should
bechosensothattheacceptancerateisaround65%;thislimitisapproached
slowly,however,andinpractice,itisoftenfoundthatahigheracceptance
rateisoptimal.
ThemaindifficultywithtuningHMCisinchoosingtheintegrationtime,
ğ‘‡.Forexample,foraN(0,ğœ2)target,ğœ‹,usingamomentumofğ‘ âˆ¼N(0,1),
itisstraightforwardtoshowthatifğœƒ âˆ¼ ğœ‹thenunderthetrueHamiltonian
0
dynamics,Cor[ğœƒ 0,ğœƒ ğ‘‡] =cos(ğ‘‡/ğœ).IfthetargetisaproductofGaussians,
each with a different length scale, then the auto-correlations between the
currentvaluesandtheproposalsforeachcoordinatehavedifferentperiods.
The periodicity means that increasingğ‘‡ does not monotonically decrease
theauto-correlationandthedifferentperiodsmeanthattheminimumcorre-
lationoverallcomponents,whichupperboundstheminimumofthelag-1
auto-correlations,isanerraticfunctionofğ‘‡.Hence,theoverallefficiency
can,andoftendoes,behaveerraticallyasğ‘‡ isvaried.Thisisillustratedin
Figure2.6wheretheoptimalchoiceofğ‘‡isaround8â€“9,butslightdeviations
fromthisrangeleadtosubstantialdecreasesinefficiency.2.3 ChapterNotes 63
Î¸ N(0,i2),i=1, ,5
iâˆ¼
    
    
    
    
    
    
    
    
    
                  
T
Figure2.6 Cor(ğœƒ 0,ğœƒ ğ‘‡)againstğ‘‡ forall5componentsofğœ½ when
ğœ‹(ğœ½) âˆexp[âˆ’1(cid:205)5 ğœƒ2/ğ‘–2],ğœ½ âˆ¼ğœ‹andpâˆ¼N(0,I )(non-solid
2 ğ‘–=1 ğ‘– 0 5
lines).Thethicksolidlineisthepointwisemaximumover
components.
2.3 ChapterNotes
This chapter has only touched the surface on many established aspects
of MCMC and variations on the Metropolisâ€“Hastings algorithm of Hast-
ings(1970).ThefirstMCMCalgorithmwastherandom-walkMetropolis-
within-GibbsalgorithmofMetropolisetal.(1953),whilsttheMALAwas
suggestedandstudiedinBesag(1994)andRobertsandTweedie(1996)and
HMC was proposed in Duane et al. (1987). There are many texts and re-
viewarticlesdevotedtoMarkovchainMonteCarlo,includingGeyer(1992),
RobertandCasella(1999),GamermanandLopes(2006)andBrooksetal.
(2011).
The first high-dimensional RWM scaling result showing a limiting dif-
fusion appears in Roberts et al. (1997) and applies to a product target,
ğœ‹(ğœ½) âˆ (cid:206) ğ‘–ğ‘‘
=1
ğ‘“(ğœƒ ğ‘–); this is extended to MALA in Roberts and Rosen-
thal (1998) and, for both the RWM and MALA, to targets of the form
(cid:206) ğ‘–ğ‘‘ =1ğ¶ ğ‘–ğ‘“(ğ¶ ğ‘–ğœƒ ğ‘–) in Roberts and Rosenthal (2001). Sherlock and Roberts
(2009) tackles the RWM on spherical and elliptical targets, showing that
insomesituationstheoptimalacceptanceratecanbelessthan0.234,and
)
Î¸,
Î¸(roC
T
064 ReversibleMCMCanditsScaling
Sherlocketal.(2015)extendstheanalysisforproducttargetstothepseudo-
marginalRWM.Ofthemanyotherscalingresultsforthesetwoalgorithms,
wehighlightthefollowing:Christensenetal.(2005)examinesthetransient
phasesofthealgorithms,Beskosetal.(2009)considersachangeofmea-
surefromaproductlawand,finally,Kamatani(2020)considerstheRWM
onsphericallysymmetricscale-mixturesofGaussiansandshowsthatwhen
the tails are heavier than exponential, although the optimal scaling is still
â„“/ğ‘‘, the norm of the process, âˆ¥ğœ½âˆ¥, mixes in a time of ğ‘‚(ğ‘‘2) rather than
ğ‘‚(ğ‘‘),suggestingthattheRWMmaybetoocostlyonsome,morerealistic
heavy-tailedtargets.
Example 2.2 illustrated the poor behaviour of MALA in the tails of
targets with tails that are lighter than Gaussian. A simple solution is to
truncate the gradient term (Roberts and Tweedie, 1996). Livingstone and
Zanella(2022)providesanalternativeuseofgradientswithintheproposal
that leads to the same limiting behaviour as MALA, but is automatically
robusttoissueswithlight-tails.
A single iteration of HMC approximates Hamiltonian dynamics over a
finite time ğ‘‡, whatever the dimension. Thus, if, as in the earlier scaling
analysis, ğ‘‡ is kept fixed, there can be no limiting diffusion for a product
target. A similar scaling analysis to ours appears in Neal (2011), which
itselfisbasedonCreutz(1988);amorerigorousanalysisisgiveninBeskos
etal.(2013).
RecentworkshavemitigatedagainsttheerraticdependenceoftheHMC
efficiency on the integration time,ğ‘‡. Techniques include introducing ran-
domnessintothelengthofthepath(Neal,2011;Bou-RabeeandSanz-Serna,
2017;Hoffmanetal.,2021),randomisingthechoiceofproposalpointfrom
those along the path (Hoffman and Gelman, 2014; Sherlock et al., 2023,
the former also automatically choosing ğ‘‡ at each iteration and the latter
adjustingğ‘‡ accordingtoanaturallengthscaleofthetarget)orbyjittering
themomentumaftereachleapfrogstep(Riou-DurandandVogrinc,2023).
FurthervariationsontheHMCalgorithmincludethetrulynon-reversible
Horowitz(1991),whichisdiscussedinmoredetailinSection4.3,andSohl-
Dickstein et al. (2014), which tries to mitigate one of the key issues with
Horowitz(1991).
AseparatestrandofmethodologicaldevelopmentsforreversibleMCMC
starts with position-dependent preconditioning of MALA and extends to
Riemann manifold Hamiltonian Monte Carlo (Girolami and Calderhead,
2011)andRiemannmanifoldMALA(Xifaraetal.,2014)whichitselffeeds
intotheStochasticGradientRiemannianLangevinDynamicsdescribedin
Section3.4.3
Stochastic Gradient MCMC Algorithms
Chapter2introducedMarkovchainMonteCarloalgorithmsasasimulation-
basedapproachtoapproximatedistributionsofinterest.Adrawbackofthe
algorithmsintroducedinChapter2isthattheircomputationaltimescales
poorlywithlargedatasets.Inthischapter,wewillexploreaclassofalgo-
rithmsthatcanbeviewedasapproximationsofthealgorithmsintroducedin
Chapter2.WeintroducethestochasticgradientLangevinalgorithm,andex-
tensionsofthisalgorithm,whicharepopularBayesianinferencemethodsin
thefieldofmachinelearning.ComparedtotraditionalMCMCalgorithms,
wewillnowreplacethegradientofthelogdensityofthetargetdistribution
withastochasticapproximation.Thisstochasticapproximationisgenerated
using a subsample of the full dataset to produce an approximate MCMC
algorithm. This class of stochastic gradient MCMC algorithms is com-
putationally faster than standard MCMC algorithms but at the expense of
introducingasmallasymptoticbiasthatcanbecorrectedpost-hoc.Through
this chapter, we will discuss the motivation behind these algorithms, and
theirextensions,andprovideempiricalcomparisonstotraditionalMCMC
algorithms.
3.1 TheUnadjustedLangevinAlgorithm
Recallthatweaimtosamplefromaposteriordistributionwithdensityğœ‹(ğœ½),
where for this chapter, ğœ½ is a ğ‘‘âˆ’dimensional vector in Rğ‘‘. It is assumed
forthemethodswediscussinthischapterthatlogğœ‹(ğœ½) iscontinuousand
differentiable almost everywhere. Simulating a stochastic process that has
ğœ‹ as its stationary distribution is a well-established method for generating
samples approximately from ğœ‹(ğœ½). By sampling from such a process for
anextendedperiod,anddiscardingtheinitialburn-insamples,weobtaina
set of samples that approximate ğœ‹(ğœ½). The accuracy of the approximation
depends on how quickly the stochastic process converges to its stationary
distributionfromtheinitialpoint,relativetothelengthoftheburn-inperiod,
6566 StochasticGradientMCMCAlgorithms
aswellasonthetimeforthechaintomixwithinthestationarydistribution.
The Markov Chain Monte Carlo (MCMC; see Chapter 2) method is the
mostwidelyusedtechniqueforsamplinginthismanner
Withğ‘ =1,theoverdampedLangevindiffusionfirstintroducedin(1.20)
ofSection1.4.3is
1
dğœ½ğ‘¡ = âˆ‡logğœ‹(ğœ½ğ‘¡)dğ‘¡+dğ‘Š ğ‘¡, (3.1)
2
where 1âˆ‡logğœ‹(ğœ½ğ‘¡) isthedrifttermandğ‘Š ğ‘¡ denotes ğ‘‘-dimensionalBrow-
2
nian motion. In this chapter we sometimes refer to the solution to this
stochastic differential equation (SDE) simply as the Langevin diffusion.
Under mild regularity conditions, the Langevin diffusion has ğœ‹ as its sta-
tionarydistribution.AsdetailedinSection1.4and,inparticular(1.16),this
equationcanbeinterpretedasdefiningthedynamicsofaMarkovprocess
over infinitesimally small time intervals. That is, for a small time-interval
ğ›¿ > 0, the Langevin diffusion has a discrete-time analogue given by the
Eulerâ€“Maruyamaapproximation,
ğ›¿ âˆš
ğœ½ğ‘¡+ğ›¿ = ğœ½ğ‘¡ + âˆ‡logğœ‹(ğœ½ğ‘¡)+ ğ›¿Z, ğ‘¡ â‰¥ 0 (3.2)
2
whereZisavectorofğ‘‘ independentstandardGaussianrandomvariables.
This discrete-time update equation is commonly known as the unadjusted
Langevin algorithm (ULA) or the Langevin Monte Carlo algorithm. The
discrete-timesequence{ğœ½ğ‘¡} ğ‘¡â‰¥0generatedby(3.2)differsfromthesequence
producedbytheprocessin(3.1).Theupdateequationgivenin(3.2)provides
astraightforwardandpracticallyimplementablemethodforgeneratingap-
proximate samples from the overdamped Langevin diffusion. To generate
samplesoveradurationğ‘‡ = ğ‘›ğ›¿,whereğ‘›isaninteger,webeginbysetting
theinitialstateoftheprocesstoğœ½ ,andthenrepeatedlysimulatetheprocess
0
using(3.2)toobtainvaluesattimesğ›¿,2ğ›¿,...,ğ‘›ğ›¿.Wewillusethenotation
ğœ½ğ‘˜ torefertothestateoftheprocessattime ğ‘˜ğ›¿.AswiththeMCMCalgo-
rithms discussed in Chapter 2, an estimate of any expectation is obtained
viaaMonteCarloaverage:E
ğœ‹
[â„(ğœ½)] â‰ˆ ğ‘›1 (cid:205)ğ‘› ğ‘˜=1â„(ğœ½ğ‘˜).
To improve the accuracy of the Eulerâ€“Maruyama discretisation (3.2)
when sampling from the Langevin diffusion at a fixed time ğ‘‡, we can
decrease ğ›¿. As ğ›¿ becomes smaller, the discretisation error decreases and
the approximation becomes more accurate. In theory, we can achieve any
desired degree of accuracy in approximating the SDE (3.1) by selecting
ğ›¿ small enough. However, for a fixedğ‘‡, the computational cost increases
in proportion to 1/ğ›¿. Alternatively, given a fixed computational budget,
ğ‘‡ decreases in proportion to ğ›¿. The longer ğ‘‡ is, the more information3.2 Approximatevs.ExactMCMC 67
about the diffusionâ€™s stationary distribution we collect, and hence, for a
fixed computation budget, the variance of any estimate from the samples
increasesasthebiasdecreases.Inpractice,therefore,thechoiceofğ›¿requires
acompromisebetweenthebiasandthevarianceofourestimators.
3.2 Approximatevs.ExactMCMC
The overdamped Langevin diffusion has ğœ‹ as its stationary distribution
and therefore it is natural to consider this stochastic process as the basis
for an MCMC algorithm. In fact, if it were possible to simulate exactly
the dynamics of the Langevin diffusion, then we could use the resulting
realisationsatasetofdiscretetimepointsasourMCMCoutput.However,
for general ğœ‹(ğœ½), the Langevin dynamics are intractable, and therefore it
is necessary to resort to using samples generated by the Eulerâ€“Maruyama
approximation(3.2).
This is most commonly seen with the Metropolis-adjusted Langevin
Algorithm (MALA) (see Section 2.1.4). This algorithm uses the Eulerâ€“
Maruyamaapproximation(3.2)overanappropriatelychosentime-interval,
ğ›¿, to define the proposal distribution of a standard Metropolisâ€“Hastings
sampler (see Algorithm 1). Simulated values are then either accepted or
rejected based on the Metropolisâ€“Hastings acceptance probability (2.1).
Such an algorithm has good theoretical properties, and in particular, can
scale better to high-dimensional problems than the simpler random walk
MCMCalgorithm.SeeSection2.1.4foramoredetaileddescriptionofthe
MALAalgorithmanditsdimensionalscaling.
AsimpleralgorithmisthejustdescribedunadjustedLangevinalgorithm
(3.2), which simulates from the Eulerâ€“Maruyama approximation of the
Langevin diffusion but does not use a Metropolisâ€“Hastings accept-reject
step, and so the stationary distribution of the resulting Markov chain is
not ğœ‹. Hence, even once the Markov chain has essentially converged, the
Monte Carlo samples are from an approximation to ğœ‹ rather than from ğœ‹
itself.Becauseofthis,estimatorsofexpectationsaretypicallybiased,even
as the number of samples, ğ‘›, grows to infinity. Computationally, such an
algorithmisquickerperiteration,butoftenthissavingissmallasthecostof
calculatingâˆ‡logğœ‹(ğœ½),whichisrequiredforonestepoftheULAalgorithm,
typicallyscalesatleastlinearlywiththedatasetsize.IftheMALAalgorithm
isoptimallytuned,thenapproximately40%ofthesampleswillberejected,
which leads to wasted computation compared to ULA where all samples,
albeitbiased,areaccepted.However,thisiscounteractedbythelargerstep
sizesthatarepossiblewithMALA.68 StochasticGradientMCMCAlgorithms
Example:SamplingfromaGaussianPosteriorDistribution
To illustrate the computational and statistical accuracy trade-offs between
the ULA and MALA schemes, we consider a simple bivariate Gaussian
posteriordistribution,whichweshalluseasarunningexamplethroughout
this chapter. We assume that data arise as realisations from a Gaussian
location model with mean parameter ğœ½ assumed to be unknown and the
varianceVisknown.WeselectaconjugateGaussianpriorfortheunknown
ğœ½ whichleadstothegenerativemodel
yğ‘—|ğœ½ âˆ¼N(ğœ½,V), ğœ½ âˆ¼N(0,I 2), for ğ‘— =1,...,ğ‘, (3.3)
(cid:18) (cid:19)
1 0
where we set V = and I is a 2-dimensional identity matrix. For
0 10 2
thissimplemodel,itispossibletoderiveatractableposteriordistribution
ğœ½|yâˆ¼N(ğ ğ‘,ğšº ğ‘),whereğšº
ğ‘
= (ğ‘Vâˆ’1+I 2)âˆ’1andğ
ğ‘
= ğšº ğ‘(Vâˆ’1(cid:205)ğ‘ ğ‘—=1yğ‘—).
We can use both ULA and MALA schemes to sample from the posterior
distribution and compare the Monte Carlo accuracy of both algorithms
against the known ground-truth posterior distribution. We measure the
distributional accuracy between the true posterior ğœ‹ and a Monte Carlo
approximationğœ‹Ëœ usingtheWasserstein-2distance,
âˆ«
d2 (ğœ‹,ğœ‹Ëœ) = inf âˆ¥ğœ½ âˆ’ğœ½â€²âˆ¥2dğœ(ğœ½,ğœ½â€²), (3.4)
ğ‘Š
2 ğœâˆˆÎ“(ğœ‹,ğœ‹Ëœ) Rğ‘‘Ã—Rğ‘‘
wheretheinf istakenwithrespecttoalljointdistributionsğœ whichhaveğœ‹
andğœ‹Ë† astheirmarginaldistributions.Inthesettingwherebothğœ‹andğœ‹Ë† are
Gaussian,thereisatractableclosed-formexpressionfortheWasserstein-2
distance,
d2
ğ‘Š
2(N(ğ ğ‘,ğšº ğ‘),N(ğ ğ‘,ğšº ğ‘)) = âˆ¥ğ ğ‘âˆ’ğ ğ‘âˆ¥2 2+trace(ğšº ğ‘+ğšº ğ‘âˆ’2(ğšº1 ğ‘/2ğšº ğ‘ğšº1 ğ‘/2)1/2).
In Figure 3.1, we calculated the approximate Wasserstein-2 distance
betweenthetrueposteriorandamoment-matchedGaussianapproximation
to the Monte Carlo samples generated by the ULA/MALA algorithms.
We simulated ğ‘ = 1000 (left panel) and ğ‘ = 10000 (right panel) data
pointsfromthemodel(3.3)andranULA/MALAfor ğ‘› = 1000iterations.
For each ğ‘, MALA and ULA used the same step size, ğ›¿ = 1/ğ‘. Since
the true posterior is Gaussian, we expect the moment-matched Gaussian
approximation for the MALA sampler to get more and more accurate as
the number of iterations increases. Since the ULA algorithm update is a
conditionalGaussian,thestationarydistributionforULAisalsoGaussian,
sothemoment-matchedGaussianapproximationtothiswillalsogetmore
andmoreaccurateasthenumberofiterationsincreases.3.3 StochasticGradientLangevinDynamics 69
ComparingthecomputationaltimeforULAandMALA,theperiteration
costofULAiscomparabletoMALAinitially,ifnotslightlybetter.However,
withalargercomputationalbudget,i.e.moreMonteCarloiterations,ULA
is less accurate due to the asymptotic bias from discretising the Langevin
diffusion.WhentakingintoaccountthereducedcomputationalcostofULA,
thismeansthatULAisbetterforsmallcomputationalbudgets,whereasfor
moderate to large computational budgets, MALA is better. Note that the
computational budget required for MALA to display improved statistical
efficiencyoverULAisdependentonthedatasetsize.Thisishighlightedin
Figure 3.1, where ğ‘ = 1000 in the left panel and ğ‘ = 10000 in the right
panel.
The reason that ULA is competitive with MALA only for very small
computational budgets is that the computational gain per iteration is only
roughlytwo-fold(i.e.notcalculatingtheaccept-rejectratioroughlyhalves
thecostasthegradientstillneedstobecalculated),andthisisonlyasmall
gainrelativetothebiasthatisintroduced.If,ontheotherhand,therewas
a way of implementing ULA, or something like ULA, which was ğ‘‚(ğ‘)
faster,thenthecomputationalbenefitcomparedtoMALAwouldbemore
significant. To achieve such a speed-up, this would require an algorithm
where the cost of calculating or approximating the gradient is only ğ‘‚(1)
â€“ this is the key idea behind the stochastic gradient Langevin dynamics
algorithmwhichwillbeexploredindetailintheremainderofthischapter.
3.3 StochasticGradientLangevinDynamics
WehaveseenhowtheULAalgorithmiscomputationallyfasterthanMALA,
attheexpenseofintroducingabiaswhichproducessamplesnotfromthe
desiredinvariantdistributionğœ‹,butadistributionclosetoğœ‹.Evenwithout
the Metropolis-Hastings acceptance probability, the ULA algorithm still
incurs a cost in calculating the gradient of the log-posterior density and
under common assumptions, this computational cost scales linearly with
thedatasetsize.
Recent interest in Bayesian analysis has considered the challenge of
scalableinferenceinthepresenceoflargedatasets,wherethelog-posterior
density is defined as a sum over data points. For instance, if we consider
data y 1,...,yğ‘ that are conditionally independent given ğœ½, then ğœ‹(ğœ½) âˆ
ğœ‹ 0(ğœ½)(cid:206)ğ‘
ğ‘—=1
ğ‘“(yğ‘—|ğœ½). Here, ğœ‹ 0(ğœ½) is the prior density, and ğ‘“(yğ‘—|ğœ½) is the
likelihoodforthe ğ‘—thobservation.Inthiscontext,wedefinethelog-posterior
densityas70 StochasticGradientMCMCAlgorithms
ULA ULA
0.8
MALA MALA
0.8
0.7
0.7
0.6
0.6 0.5
0.4
0.5
0.3
0 2 4 6 0 2 4 6 8
Computational time Computational time
Figure3.1 Wassersteindistancebetweenthetrueğœ‹and
approximateposteriordistributionagainstcomputationaltime(in
seconds),wheretheapproximateposteriorğœ‹Ëœ isgeneratedusing
theULAandMALAschemes.Leftpanelğ‘ =1000andright
panelğ‘ =10000.
ğ‘
âˆ‘ï¸ 1
logğœ‹(ğœ½) = logğœ‹ ğ‘—(ğœ½), where logğœ‹ ğ‘—(ğœ½) =log ğ‘“(yğ‘—|ğœ½)+
ğ‘
logğœ‹ 0(ğœ½).
ğ‘—=1
(3.5)
ThecomputationalbottleneckforULAisincalculatingâˆ‡logğœ‹(ğœ½),which
canbeexpensiveifwehavealargedataset.Foradatasetwithğ‘independent
observations,wherethelog-posteriordensityisasumover ğ‘ independent
terms(3.5),thecomputationalcostofevaluatingthelog-posteriordensity,
oritsgradient,isğ‘‚(ğ‘) foreachiterationofULA.
AsolutiontothisproblemistousestochasticgradientLangevindynamics
(SGLD,WellingandTeh,2011),whichavoidscalculatingâˆ‡logğœ‹(ğœ½),and
instead uses an unbiased estimator of the gradient at each iteration. It is
trivial to obtain an unbiased estimate using a random subsample of the
terms in the sum. The simplest implementation is to choose ğ‘š â‰ª ğ‘ and
estimateâˆ‡logğœ‹(ğœ½) with
ğ‘ âˆ‘ï¸
âˆ‡(ğ‘š)logğœ‹(ğœ½) =
ğ‘š
âˆ‡logğœ‹ ğ‘—(ğœ½), (3.6)
ğ‘—âˆˆSğ‘š
where S ğ‘š is a random sample of size ğ‘š taken without replacement from
{1,...,ğ‘}. We call this the simple estimator of the gradient and use the
ecnatsid
nietsressaW
ecnatsid
nietsressaW3.3 StochasticGradientLangevinDynamics 71
superscript (ğ‘š) todenotethesubsamplesizeusedinconstructingouresti-
mator.TheresultingSGLDalgorithmisgiveninAlgorithm3.Essentially,
theSGLDalgorithmisthesameasULA(3.2)andissimulatinganEulerâ€“
MaruyamadiscretisationoftheLangevindiffusion.Theonlydifferenceis
thatthetruegradientisreplacedwiththeestimatedgradient(3.6).
Usinganestimatorforthegradientaddsadditionalnoise,withavariance
ofğ‘‚(ğ›¿2),andthereforethestochasticdynamicsnolongerfollowtheULA
update equation (3.2); instead the SGLD algorithm targets a distribution
that is close to a tempered version of ğœ‹. However, for sufficiently small
ğ›¿,thisadditionalvariancebecomesnegligiblecomparedwiththeinjected
Gaussiannoiseof(3.2),whichhasavarianceofğ›¿.Itispossibletogeneralise
Algorithm 3 to the setting of adaptive step sizes ğ›¿ ğ‘˜ which are dependent
on the iteration number ğ‘˜. This is not commonly used in practice and for
simplicity,weworkwiththeconstantstepsizeversiongiveninAlgorithm
3. A justification for using the SGLD algorithm with a decaying step size
canbegivenbyaninformalargumentalongthelinesthatifthestepsizeis
ğ›¿ ğ‘˜ â†“ 0 for ğ‘˜ â†’ âˆ, then the process will converge to the true overdamped
Langevindiffusion,andhencetheMonteCarlosampleswillbeexactinthe
limit(seeSection3.3.3).
Algorithm3:StochasticGradientLangevinDynamics(SGLD)
Input:ğœ½ ,ğ›¿.
0
for ğ‘˜ âˆˆ 1,...,ğ‘›do
DrawasubsetS
ğ‘š
âŠ‚ {1,...,ğ‘}
Estimateâˆ‡(ğ‘š)logğœ‹(ğœ½) using(3.6)
DrawZğ‘˜ âˆ¼N(0,ğ›¿I)
Updateğœ½ğ‘˜+1 â† ğœ½ğ‘˜ + 2ğ›¿âˆ‡(ğ‘š)logğœ‹(ğœ½)+Zğ‘˜
end
TheadvantageofSGLDisthat,ifthesubsamplesizeğ‘šismuchsmaller
than the full dataset size ğ‘, the per-iteration cost of the algorithm can be
muchsmallerthanthatofeitherMALAorULA.Forlargedataapplications,
SGLDhasbeenempiricallyshowntoperformbetterthanstandardMCMC
when there is a fixed computational budget (Ahn et al., 2015; Li et al.,
2016).Inchallengingexamples,performancehasbeenbasedonmeasures
of predictive accuracy on a held-out test dataset, rather than based on
how accurately the samples approximate the true posterior distribution.
Furthermore,theconclusionsfromsuchstudieswillclearlydependonthe
computationalbudget,withlargerbudgetsfavouringexactmethodssuchas72 StochasticGradientMCMCAlgorithms
MALA;seethetheoreticalresultsinSection3.3.3andempiricalresultsin
Section3.2.
The SGLD algorithm is closely related to stochastic gradient descent
(SGD) (Robbins and Monro, 1951), an efficient algorithm for finding the
local maxima of a function. The only difference is the inclusion of the
additive Gaussian noise at each iteration of SGLD. Without the noise,
but with a suitably decreasing step size, SGD would converge to a local
maximum of the density ğœ‹(ğœ½). Again, SGLD has been shown empirically
to out-perform stochastic gradient descent (Chen et al., 2014), at least in
termsofpredictiveaccuracyâ€“intuitivelythisisbecauseSGLDwillproduce
samplesfromtheregionaroundtheestimateobtainedbySGD,andthuscan
average over the uncertainty in the parameters. This strong link between
SGLD and SGD may also explain why the former performs well when
comparedtoexactMCMCmethods,atleastintermsofpredictiveaccuracy.
3.3.1 ControllingStochasticityintheGradientEstimator
ThekeyingredientofSGLDisfoundinreplacingthetruegradientwithan
unbiasedestimator.Themoreaccuratethisestimatoris,thelowerthebias
will be for the same computational cost, and thus it is natural to consider
alternativestothesimpleestimator(3.6).Onewayofreducingthevariance
ofaMonteCarloestimatoristousecontrolvariates(seeSection1.1.4fora
detailedexplanation),whichinoursettinginvolveschoosingasetofsimple
functionsğ‘” ğ‘—, ğ‘— =1,...,ğ‘,whichwerefertoascontrolvariates,andwhose
sum(cid:205)ğ‘ ğ‘—=1ğ‘” ğ‘—(ğœ½) canbeevaluatedforanyğœ½.
Wecanrewritethefull-datagradientofthelog-posteriordensityas
ğ‘ ğ‘ ğ‘
âˆ‘ï¸ âˆ‡logğœ‹ ğ‘—(ğœ½) =âˆ‘ï¸ ğ‘” ğ‘—(ğœ½)+âˆ‘ï¸(cid:0) âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ’ğ‘” ğ‘—(ğœ½)(cid:1),
ğ‘—=1 ğ‘—=1 ğ‘—=1
andfromthis,wecanobtainanunbiasedestimator
âˆ‘ï¸ğ‘ ğ‘ âˆ‘ï¸
ğ‘” ğ‘—(ğœ½)+
ğ‘š
(âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ’ğ‘” ğ‘—(ğœ½)), (3.7)
ğ‘—=1 ğ‘—âˆˆSğ‘š
where again S ğ‘š is a random sample of size ğ‘š drawn from {1,...,ğ‘}.
Theintuitionbehindthisideaisthatifeachğ‘” ğ‘—(ğœ½) â‰ˆ âˆ‡logğœ‹ ğ‘—(ğœ½),thenthis
estimator can have a much smaller variance than the simple subsampled
gradientestimator(3.6).
Oneapproachtochoosingthecontrolvariatefunctionğ‘” ğ‘—(ğœ½)thatisoften
usedinpractice,isto(i)useSGDtofindanapproximation,(cid:98)ğœ½,tothemode3.3 StochasticGradientLangevinDynamics 73
of the distribution ğœ‹; and (ii) set ğ‘” ğ‘—(ğœ½) = âˆ‡logğœ‹ ğ‘—((cid:98)ğœ½). This leads to the
followingcontrolvariateestimator,
âˆ‘ï¸ğ‘ ğ‘ âˆ‘ï¸ (cid:16) (cid:17)
âˆ‡(ğ‘š)logğœ‹ cv(ğœ½) = âˆ‡logğœ‹ ğ‘—((cid:98)ğœ½)+
ğ‘š
âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ’âˆ‡logğœ‹ ğ‘—((cid:98)ğœ½) .
ğ‘—=1 ğ‘—âˆˆSğ‘š
(3.8)
Implementingsuchanestimatorinvolvesaninitialup-frontcostforfinding
a suitable (cid:98)ğœ½ and then calculating, storing, and summing âˆ‡logğœ‹ ğ‘—((cid:98)ğœ½) for
ğ‘— = 1,...,ğ‘.Forthesetypesofcontrolvariateapproaches,themaincost
isfromfindingasuitable(cid:98)ğœ½.Although,oncefound,wecanthenuse(cid:98)ğœ½ asa
startingvaluefortheSGLDalgorithm,replacingğœ½ 0with(cid:98)ğœ½ inAlgorithm3,
whichcansignificantlyreducetheburn-inphase.
The advantage of using the control variate-based estimator can be seen
ifwecomparethevarianceboundsofthisestimatoragainstthesimpleesti-
mator.Ifweassumethateachlogğœ‹ ğ‘—(ğœ½)istwicecontinuouslydifferentiable
on Rğ‘‘ and has Lipschitz-continuous gradients, then there exist positive
constants ğ¿ ğ‘— > 0forall ğ‘— =1,...,ğ‘,suchthat
âˆ¥âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ’âˆ‡logğœ‹ ğ‘—(ğœ½â€²)âˆ¥ â‰¤ ğ¿ ğ‘—âˆ¥ğœ½ âˆ’ğœ½â€²âˆ¥. (3.9)
Lemma 3.1 and several subsequent results provide bounds on the trace
ofthevariancematrixofeachestimatorofâˆ‡logğœ‹(ğœ½).Sincevariancesare
non-negative,thisboundsthevariancesofeachindividualcomponent.Also,
since all eigenvalues of a variance matrix are non-negative, it bounds the
largest of these; i.e. the variance of the worst-behaved linear combination
ofcomponents.Finally,foranyğ‘‘-vectorrandomvariableğƒ withE[ğƒ] =0,
(cid:34) ğ‘‘ (cid:35)
tr(Var[ğƒ]) =E âˆ‘ï¸ ğœ‰2 =E(cid:2) âˆ¥ğƒâˆ¥2(cid:3) â‰¥ Var[âˆ¥ğƒâˆ¥],
ğ‘–
ğ‘–=1
so the bounds also apply to the variance of the Euclidean norm of the
gradient.ForanyrandomvectorğƒwithE[ğƒ] =0,werefertotheimportant
quantityofE(cid:2) âˆ¥ğƒâˆ¥2(cid:3)
=tr(Var[ğƒ]) asitspseudo-variance.
Lemma3.1 Assumecondition(3.9),thenthereareconstantsğ¶ ,ğ¶ > 0
1 2
where the pseudo variances of the simple gradient estimator (3.6) and
controlvariate-basedgradientestimator(3.8)havethefollowingbounds:
(cid:16) (cid:17) ğ‘2
tr Var(cid:2) âˆ‡(ğ‘š)logğœ‹(ğœ½)(cid:3) â‰¤ ğ¶ , (3.10)
1 ğ‘š
(cid:16) (cid:17) ğ‘2
tr Var(cid:2) âˆ‡(ğ‘š)logğœ‹ cv(ğœ½)(cid:3) â‰¤ ğ¶ 2âˆ¥ğœ½ âˆ’(cid:98)ğœ½âˆ¥2
ğ‘š
, (3.11)74 StochasticGradientMCMCAlgorithms
Proof Weprovethisresultforthecontrolvariate-basedgradientestimators
(3.8);theresultforthesimpleSGLDestimator(3.6)followsanalogously.
Wefirstdefineğƒ := âˆ‡(ğ‘š)logğœ‹ (ğœ½)âˆ’âˆ‡logğœ‹(ğœ½),sothatğƒ measuresthe
cv
noiseinthegradientestimateandhasmeanzero.Thetraceofthevariance
inthenoiseisthengivenby
E(cid:2) âˆ¥ğƒâˆ¥2(cid:3) =E(cid:104)(cid:13) (cid:13)âˆ‡(ğ‘š)logğœ‹ cv(ğœ½)âˆ’âˆ‡logğœ‹(ğœ½)(cid:13) (cid:13)2(cid:105)
=Eï£® ï£¯ ï£¯ ï£¯(cid:13) (cid:13) (cid:13) (cid:13)ğ‘šğ‘ âˆ‘ï¸ (cid:16) âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ’âˆ‡logğœ‹ ğ‘—((cid:98)ğœ½)(cid:17) âˆ’ (cid:16) âˆ‡logğœ‹(ğœ½)âˆ’âˆ‡logğœ‹((cid:98)ğœ½)(cid:17)(cid:13) (cid:13) (cid:13) (cid:13)2ï£¹ ï£º ï£º
ï£º
ï£¯(cid:13) ğ‘—âˆˆSğ‘š (cid:13) ï£º
ï£° ï£»
=Eï£® ï£¯ ï£¯ ï£¯(cid:13) (cid:13) (cid:13) (cid:13)ğ‘šğ‘ âˆ‘ï¸ (cid:26) (cid:16) âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ’âˆ‡logğœ‹ ğ‘—((cid:98)ğœ½)(cid:17) âˆ’ ğ‘1 (cid:16) âˆ‡logğœ‹(ğœ½)âˆ’âˆ‡logğœ‹((cid:98)ğœ½)(cid:17)(cid:27)(cid:13) (cid:13) (cid:13) (cid:13)2ï£¹ ï£º ï£º
ï£º
ï£¯(cid:13) ğ‘—âˆˆSğ‘š (cid:13) ï£º
ï£° ï£»
â‰¤ ğ‘šğ‘ 22 E(cid:34) âˆ‘ï¸ (cid:13) (cid:13) (cid:13) (cid:13)(cid:16) âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ’âˆ‡logğœ‹ ğ‘—((cid:98)ğœ½)(cid:17) âˆ’ ğ‘1 (cid:16) âˆ‡logğœ‹(ğœ½)âˆ’âˆ‡logğœ‹((cid:98)ğœ½)(cid:17)(cid:13) (cid:13) (cid:13) (cid:13)2(cid:35) .
ğ‘—âˆˆSğ‘š
where the final line follows from the triangle inequality and due to inde-
pendencebetweentheâˆ‡logğœ‹ ğ‘—(ğœ½)termsinthesettingofsubsamplingwith
replacement. For subsampling without replacement, the sampled indices
willbenegativelycorrelatedandthuswillleadtolowervariance.Forany
random variable X, we have
E(cid:2) âˆ¥Xâˆ’E[X]âˆ¥2(cid:3)
â‰¤
E(cid:2) âˆ¥Xâˆ¥2(cid:3)
. Using this
result,andtheLipschitzassumption(3.9),leadsto
E(cid:2) âˆ¥ğƒâˆ¥2(cid:3) â‰¤ ğ‘šğ‘ 22 âˆ‘ï¸ E(cid:20)(cid:13) (cid:13) (cid:13)âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ’âˆ‡logğœ‹ ğ‘—((cid:98)ğœ½)(cid:13) (cid:13) (cid:13)2(cid:21)
ğ‘—âˆˆSğ‘š
ğ‘2 (cid:20)(cid:13) (cid:13)2(cid:21)
â‰¤
ğ‘š
E (cid:13) (cid:13)âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ’âˆ‡logğœ‹ ğ‘—((cid:98)ğœ½)(cid:13)
(cid:13)
ğ‘2 1 âˆ‘ï¸ğ‘ (cid:16) (cid:13) (cid:13)(cid:17)2 ğ‘2 (cid:13) (cid:13)2 1 (cid:32) âˆ‘ï¸ğ‘ (cid:33)
â‰¤
ğ‘š ğ‘
ğ¿ ğ‘—(cid:13) (cid:13)ğœ½ âˆ’(cid:98)ğœ½(cid:13)
(cid:13)
=
ğ‘š
(cid:13) (cid:13)ğœ½ âˆ’(cid:98)ğœ½(cid:13)
(cid:13) ğ‘
ğ¿2
ğ‘—
,
ğ‘—=1 ğ‘—=1
where the second line follows from the exchangeability of the indices ğ‘—
and on that line, ğ‘—, is a single index sampled uniformly at random from
1,...,ğ‘.Thisprovesthestatedresultandgivesğ¶ = 1 (cid:205)ğ‘ ğ¿2. â–¡
2 ğ‘ ğ‘—=1 ğ‘—
Ifwemakethefurtherassumptionthatforall ğ‘— = 1,...,ğ‘ thereexists
apositiveconstant ğ¿ > 0suchthat
âˆ¥âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ’âˆ‡logğœ‹ ğ‘—(ğœ½â€²)âˆ¥ â‰¤ ğ¿âˆ¥ğœ½ âˆ’ğœ½â€²âˆ¥ (3.12)
holds.Then,itisstraightforwardtoshowthatwehavethefollowingLips-3.3 StochasticGradientLangevinDynamics 75
chitzboundonthegradientofthelog-posterior,
âˆ¥âˆ‡logğœ‹(ğœ½)âˆ’âˆ‡logğœ‹(ğœ½â€²)âˆ¥ â‰¤ ğ¿ğ‘âˆ¥ğœ½ âˆ’ğœ½â€²âˆ¥, (3.13)
whichnowleadstoanupdatedconstantğ¶ = ğ¿2 in(3.11)ofLemma3.1.
2
By comparing the upper bounds on the variance of the gradients in
(3.10)and(3.11),wecanseethatwhenğœ½ iscloseto(cid:98)ğœ½ wewouldexpectthe
variance in the control variate estimator to be smaller than for the simple
estimator. Furthermore, in many big data settings where ğ‘ is large, we
would expect by the Bernsteinâ€“von Mises theorem (e.g. LeCam, 1986)
that a value of ğœ½ drawn from the posterior distribution to be of distance
ğ‘‚(ğ‘âˆ’1/2)fromthemodeofthedistribution(cid:98)ğœ½,i.e.weexpectâˆ¥ğœ½âˆ’(cid:98)ğœ½âˆ¥2tobe
ğ‘‚(ğ‘âˆ’1). Therefore, compared to the ğ‘‚(ğ‘2/ğ‘š) variance from the simple
estimator(3.10),wewouldexpecttoseeareducedğ‘‚(ğ‘/ğ‘š)variance(3.11)
for the control variate gradient estimator. This simple argument suggests
that,forthesamelevelofaccuracy,wecanreducethecomputationalcost
ofSGLDbyğ‘‚(ğ‘)ifweusecontrolvariate-basedgradientestimators.This
issupportedbyanumberoftheoreticalresultswhichshowthatifweignore
the pre-processing cost of finding(cid:98)ğœ½, the computational cost per effective
sample of SGLD with control variates isğ‘‚(1), rather than theğ‘‚(ğ‘) cost
forSGLDwiththesimplegradientestimator(3.6).
Afurtherconsequenceoftheseboundsonthevarianceisthattheysug-
gest that if ğœ½ is far from(cid:98)ğœ½, then the variance when using control variates
canbelarger,potentiallysubstantiallylargerthanthatofthesimpleestima-
tor. This point is illustrated in the top-left panel of Figure 3.2, where the
variance in the simple gradient estimator (3.6) is approximately constant
for all ğœ½. However, the variance in the control variate gradient estimator
increases as ğœ½ moves away from (cid:98)ğœ½. Two natural ways of addressing this
issue have been proposed in the literature. One option is to only use the
control variate estimator when ğœ½ is close enough to (cid:98)ğœ½ (Fearnhead et al.,
2018),thoughitisuptotheusertodefinewhatisâ€œcloseenoughâ€inprac-
tice. The second approach, a Langevin interpretation of the optimisation
algorithmSAGA,whichwasproposedinDubeyetal.(2016),istoupdate
(cid:98)ğœ½whilstrunningtheSGLDalgorithm.Thiscanbedoneefficientlybyusing
ğ‘” ğ‘—(ğœ½) = âˆ‡logğœ‹ ğ‘—(ğœ½ğ‘˜ ),whereğœ½ğ‘˜ isthevalueofğœ½ atthemostrecentitera-
ğ‘— ğ‘—
tionoftheSGLDalgorithmwhereâˆ‡logğœ‹ ğ‘—(ğœ½)wasevaluated.Thisinvolves
updatingthestorageofğ‘” ğ‘—(ğœ½) anditssumateachiteration;importantlythe
lattercanbedonewithanğ‘‚(ğ‘š) cost.
An alternative approach to reducing the variance, for both the simple
andcontrolvariate-basedgradientestimators,istousenon-uniformlygen-
eratedsubsampleswithinthegradientestimator.Thisapproach,introduced76 StochasticGradientMCMCAlgorithms
in Putcha et al. (2023) and known as preferential subsampling, generates
subsamplesS ğ‘š âŠ‚ {1,...,ğ‘}ofsizeğ‘š withreplacement,wheretheprob-
abilityofdrawingthe ğ‘—thdatapointisğ‘ ğ‘— andtheexpectednumberoftimes
thatthe ğ‘—thdatapointappearsinthesubsampleisğ‘šğ‘ ğ‘—.Thisthenleadsto
anewsimple,asopposedtoCV-based,unbiasedgradientestimator
âˆ‡(ğ‘š)logğœ‹ (ğœ½) =
1 âˆ‘ï¸ âˆ‡logğœ‹ ğ‘—(ğœ½)
, (3.14)
ps ğ‘š ğ‘
ğ‘—
ğ‘—âˆˆSğ‘š
where ğ‘ ğ‘— > 0 for all ğ‘— = 1,...,ğ‘ and (cid:205)ğ‘ ğ‘—=1 ğ‘ ğ‘— = 1. The simple gradient
estimator(3.6)isgivenasaspecialcasewhen ğ‘ ğ‘— =1/ğ‘ forall ğ‘—.
Ifwedefinetheerrorinthestochasticgradientasğƒ = âˆ‡(ğ‘š)logğœ‹ (ğœ½)âˆ’
ps
âˆ‡logğœ‹(ğœ½), then taking expectations over the random subsample, whose
distributiondependsontheweightsp= (ğ‘ 1,...,ğ‘ ğ‘),leadstothepseudo-
varianceofâˆ‡(ğ‘š)logğœ‹ (ğœ½),
ps
(cid:16) (cid:17)
E(cid:2) âˆ¥ğƒâˆ¥2(cid:3) =tr Var[âˆ‡(ğ‘š)logğœ‹ (ğœ½)] .
ps
Lemma3.2 Theoptimalweightspâˆ— whichminimisethepseudo-variance
(cid:16) (cid:17)
min tr Var[âˆ‡(ğ‘š)logğœ‹ (ğœ½)]
p:ğ‘ ğ‘—âˆˆ[0,1],(cid:205) ğ‘—ğ‘ ğ‘—=1 ps
areequivalentlyfoundbyminimising
ğ‘
minâˆ‘ï¸ ğ‘1 (cid:13) (cid:13)âˆ‡logğœ‹ ğ‘—(ğœ½)(cid:13) (cid:13)2,
p ğ‘—
ğ‘—=1
resultinginoptimalweightsoftheform
ğ‘âˆ— =
âˆ¥âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ¥
for ğ‘— =1,...,ğ‘. (3.15)
ğ‘— (cid:205) ğ‘–ğ‘ =1âˆ¥âˆ‡logğœ‹ ğ‘–(ğœ½)âˆ¥
Proof A full proof of this result is given in Putcha et al. (2023). In
brief, this result follows from two steps. Firstly, a straightforward expan-
sionoftr(cid:0) Var[âˆ‡(ğ‘š)logğœ‹ (ğœ½)](cid:1) withthegradientestimatorgivenin(3.14)
ps
leads to ğ‘š1 (cid:205)ğ‘
ğ‘—=1
ğ‘1 ğ‘—(cid:13) (cid:13)âˆ‡logğœ‹ ğ‘—(ğœ½)(cid:13) (cid:13)2 + ğ¶, where ğ¶ > 0 is a constant that
is independent of p. Minimising this term with respect to the constraint
{p: ğ‘
ğ‘—
âˆˆ [0,1],(cid:205)
ğ‘—
ğ‘
ğ‘—
=1}followsbyusingLagrangemultipliers.
â–¡
Inpractice,theoptimalweights ğ‘âˆ—,whichwouldminimisethegradient
ğ‘—
variance, are dependent on the current iterate ğœ½ğ‘˜ of the SGLD algorithm.
This means that for each iteration ğ‘˜ in Algorithm 3, every ğ‘ ğ‘— for all ğ‘— =3.3 StochasticGradientLangevinDynamics 77
1,...,ğ‘ would need to be updated, which is an ğ‘‚(ğ‘) calculation and
woulddefeatthepurposeofusingsubsamplesofsizeğ‘š â‰ª ğ‘ intheSGLD
algorithm. We could instead replace the optimal weights ğ‘âˆ— (3.15) with
ğ‘—
approximateweights ğ‘ (cid:98)ğ‘—,wherein(3.15)wereplace ğœ½ withanestimateof
the posterior mode(cid:98)ğœ½. As discussed in the case of control variate gradient
estimators,finding(cid:98)ğœ½ requiresaone-offpre-processingcost.
Weighted sampling can be combined with the control variate estimator
(3.7) with a natural choice of weights that are increasing with the size of
the derivative of âˆ‡logğœ‹ ğ‘—(ğœ½) at(cid:98)ğœ½. We can also use stratified sampling to
try to ensure each subsample is representative of the full data. However,
regardlessofthechoiceofgradientestimator,animportantquestionis:how
large should the subsample size ğ‘š be? Taking one iteration of SGLD, the
varianceofthenoisefromthegradienttermisdominatedbythevariance
of the injected noise. As the former is proportional to ğ›¿2, and the latter to
ğ›¿,ğ‘š willbeğ‘‚(1) as ğ‘ increasesifwechooseğ›¿ = ğ‘‚(1/ğ‘) (thesquareof
thetargetsize).ThechoiceofstepsizeisdiscussedfurtherinSection3.5.
Subsample size could also be dynamically adjusted whilst running the
SGLDalgorithm.Theidea,whichisparticularlyrelevantwhenusingcon-
trol variates, is that the accuracy of the estimator of the gradient can vary
considerably with ğœ½. To counteract this, it may be more efficient to have
a larger subsample size when the variance would be larger. One simple
approachistospecifyanupperbound,sayğ‘‰,onthevariancethatwewould
liketoachieve,andconsiderhowtovarysubsamplesizetoachievethis.
An extension of the result in Lemma 3.1 can be derived for weighted
gradientsifthecontrolvariategradientestimator(3.7)inLemma3.1isre-
placedwiththepreferentialsamplinggradientestimator(3.14).Thisresults
inanewupperboundforthevarianceofthegradientestimator,
tr(cid:16) Var(cid:2) âˆ‡(ğ‘š)logğœ‹ cv(ğœ½)(cid:3)(cid:17) â‰¤ ğ‘š1 âˆ¥ğœ½ âˆ’(cid:98)ğœ½âˆ¥2âˆ‘ï¸ğ‘ ğ¿ ğ‘2 ğ‘—, (3.16)
ğ‘—
ğ‘–=1
where ğ‘ ğ‘— are subsample weights (3.15) and ğ¿ ğ‘— are Lipschitz constants on
thegradientcomponents(3.9).Asimilarresultcanbederivedforthesimple
gradientestimator(3.6).AswiththecontrolvariateboundinLemma3.1,
theboundin(3.16)isalsoğ‘‚(ğ‘).Theğ‘‚(1/ğ‘) term âˆ¥ğœ½âˆ’(cid:98)ğœ½âˆ¥2 cancelswith
thesummationover ğ‘ terms.However,eachofthe ğ‘ termsisğ‘‚(ğ‘) since
eachğ‘ ğ‘— isğ‘‚(1/ğ‘).Choosingappropriateweightsğ‘ ğ‘— foreach ğ‘— =1,...,ğ‘
reducesthemultiplierof ğ‘.
Givenourspecifiedupperboundğ‘‰ > 0,wecanplugthisinto(3.16).By
rearrangingtheinequalityandusingtheoptimalweights ğ‘âˆ— (3.15),wecan
ğ‘—78 StochasticGradientMCMCAlgorithms
showthatthesubsamplesizeshouldbeatleast
(cid:18) ğ‘ ğ¿2(cid:19)
ğ‘š > 1 âˆ¥ğœ½ âˆ’(cid:98)ğœ½âˆ¥2 âˆ‘ï¸ ğ‘— .
ğ‘‰ ğ‘âˆ—
ğ‘–=1 ğ‘—
Forafixedboundğ‘‰,fixed ğ‘ andfixedweights ğ‘âˆ—,theoptimalsubsample
ğ‘—
sizeisğ‘š âˆ âˆ¥ğœ½âˆ’(cid:98)ğœ½âˆ¥2,whichsuggeststhatforSGLDwithcontrolvariates,the
subsamplesizeshouldincreaseataratewhichisquadraticinthedistance
between the current iterate of the SGLD chain ğœ½ğ‘˜ and the mode of the
posteriordistribution(cid:98)ğœ½.Whilsttheconstantofproportionalitymaybehard
to calculate, a user can choose a constant based on a reasonable average
subsamplesizetheywanttoachieveâ€“andthiswouldstillenforcethatwe
have similar accuracy for the estimate of the gradient for all iterations of
SGLD.
3.3.2 Example:TheValueofControlVariates
Recall the tractable Gaussian posterior example ğœ‹(ğœ½) = N(ğ ğ‘,ğšº ğ‘) in
(3.3), where ğšº ğ‘ = (ğ‘Vâˆ’1 + I 2)âˆ’1 and ğ ğ‘ = ğšº ğ‘(Vâˆ’1(cid:205)ğ‘ ğ‘—=1yğ‘—). From
this posterior distribution, we can calculate the full-data gradient, as well
as the simple stochastic (3.6) and control variate-based gradients (3.8).
The gradient for the ğ‘—th component is âˆ‡logğœ‹ ğ‘—(ğœ½) = âˆ‡log ğ‘“(yğ‘—|ğœ½) +
(1/ğ‘)âˆ‡logğœ‹ (ğœ½) and for this example we can easily derive the poste-
0
rior mode (cid:98)ğœ½ = ğšº ğ‘(Vâˆ’1(cid:205)ğ‘ ğ‘—=1yğ‘—) and use this within the control variate
gradientestimator.Forthefull-data,simplestochastic,andcontrolvariate
gradientestimatorswehavethefollowing,
ğ‘ ğ‘
âˆ‘ï¸ âˆ‘ï¸
âˆ‡logğœ‹(ğœ½) = âˆ‡logğœ‹ ğ‘—(ğœ½) =âˆ’ Vâˆ’1yğ‘— âˆ’(ğ‘Vâˆ’1+I 2)ğœ½,
ğ‘—=1 ğ‘—=1
âˆ‡(ğ‘š)logğœ‹(ğœ½) = ğ‘šğ‘ âˆ‘ï¸ âˆ‡logğœ‹ ğ‘—(ğœ½) =âˆ’ ğ‘šğ‘ âˆ‘ï¸ Vâˆ’1yğ‘— âˆ’ (cid:0)ğ‘Vâˆ’1+I 2(cid:1) ğœ½,
ğ‘—âˆˆSğ‘š ğ‘—âˆˆSğ‘š3.3 StochasticGradientLangevinDynamics 79
âˆ‘ï¸ğ‘ ğ‘ âˆ‘ï¸ (cid:16) (cid:17)
âˆ‡(ğ‘š)logğœ‹ cv(ğœ½) = âˆ‡logğœ‹ ğ‘—((cid:98)ğœ½)+
ğ‘š
âˆ‡logğœ‹ ğ‘—(ğœ½)âˆ’âˆ‡logğœ‹ ğ‘—((cid:98)ğœ½)
ğ‘—=1 ğ‘—âˆˆSğ‘š
ğ‘
=âˆ’âˆ‘ï¸ Vâˆ’1yğ‘— âˆ’(ğ‘Vâˆ’1+I 2)(cid:98)ğœ½ + (cid:0)ğ‘Vâˆ’1+I 2(cid:1) (cid:16) (cid:98)ğœ½ âˆ’ğœ½(cid:17)
ğ‘—=1
ğ‘
âˆ‘ï¸
=âˆ’ Vâˆ’1yğ‘— âˆ’(ğ‘Vâˆ’1+I 2)ğœ½.
ğ‘—=1
ForthisGaussianexample,withthecontrolvariateestimatorsettothepos-
teriormode,thecontrolvariate-basedgradientresultsinthesamegradient
estimatorasthefull-datagradient.Thesimplegradientestimator(3.6)gives
anunbiasedestimateofthefull-datagradient,however,forsmallsubsam-
plesizes,thisestimatorcanleadtopoorposteriorapproximations.Forthis
particularmodel,itispossibletoseparatethedatayğ‘— fromtheparameters
ğœ½ in such a way that the gradient estimator can be updated at each Monte
Carloiterationwithoutre-evaluatingthedata,i.e.thedatacomponentofthe
gradient could be pre-computed and stored. Therefore, for this particular
model,thesimpleSGLDgradientestimatorwouldnotberecommendedas
themodelstructureeasilyleadstomoreefficientgradientestimators.How-
ever,derivingbettergradientestimators,suchasforthisGaussianposterior
model,isusuallyonlypossibleforsimplemodelsandthereforethesimple
unbiasedgradientestimator(3.6)isstillapopularchoicewithintheSGLD
scheme(Algorithm3)forgeneralmodels.
Figure 3.2 shows the posterior approximation for the Gaussian model
using the three gradient estimators, where stochastic gradients are calcu-
latedusing1%ofthefulldataset.TheULAsampler(top-right)withouta
Metropolisâ€“Hastingscorrectionproducesanaccurate,albeitslightlybiased,
approximationsimilartotheSGLDwithcontrolvariates(SGLD-CV)algo-
rithm(bottom-right),whichhasthesamegradientestimatorforthismodel.
TheSGLDalgorithm(bottom-left)hasthecorrectposteriormeanbutpro-
ducesanover-dispersedapproximationtotheposteriorvariance.Reducing
the stochasticity in the gradient estimator, for example, by increasing the
subsample size, will lead to improved empirical performance. This is a
well-known feature of the SGLD algorithm and its theoretical properties
arediscussedinthenextsection.80 StochasticGradientMCMCAlgorithms
 9 D U L D Q F H  R I  V W R F K D V W L F  J U D G L H Q W V  8 / $  V D P S O H U
   
  
   
      
 6 * / '
   
 6 * / '  & 9   
   
  
   
 
                                            
Î¸ Î¸
 6 * / '  V D P S O H U     G D W D  6 * / '  & 9  V D P S O H U     G D W D
  
  
  
  
  
  
     
   
                                       
Î¸ Î¸
Figure3.2 Topleft:Varianceoftheestimatedgradientstaken
overarangeofğœƒ(1) forthefirstcomponentofğœ½.Thevariancefor
theSGLDestimatorisstableacrossğœƒ(1),whereasthevariancein
theSGLD-CVgradientestimatorincreasesas|ğœƒ(1) âˆ’(cid:98)ğœƒ(1)|
increases.Theremainingplotsgivetheposteriorapproximationto
thefirstmarginalcomponentğœƒ(1) forULA,SGLDand
SGLD-CV,withthesolidblacklinerepresentingthetruedensity.
3.3.3 ConvergenceResultsforStochasticGradientLangevin
Dynamics
TheSGLDalgorithmprovidesasimpleandefficientapproachforsampling
fromaposteriordistribution ğœ‹.However,akeyquestioniswhethererrors
can accumulate over many SGLD iterations, leading to poor approximate
samples.Fortunately,undersuitableregularityconditionsonğœ‹,theoretical
resultsindicatethatSGLDcanavoidpersistenterroraccumulation.Akey
    J R O   H F Q D L U D 93.3 StochasticGradientLangevinDynamics 81
assumptionisthatthedriftintheunderlyingLangevindiffusionpushesthe
state ğœ½ toward regions of high probability under ğœ‹. This ensures that the
diffusion is geometrically ergodic - i.e. it forgets its initial position at an
exponentialrate.Asaresult,theSGLD-generatedsamplestendtoremain
intheregionsofhighprobabilityunderğœ‹.
Therearetwomaintheoreticalapproachesforanalyzingtheaccuracyof
SGLD.(i)Wecanconsidertheaccuracyofestimatingexpectationsofthe
formE
ğœ‹
[â„(ğœ½)],forsometestfunctionâ„(ğœ½)undertheposteriordistribution
ğœ‹.Thisinvolvestakingtheaverageofâ„(ğœ½ğ‘˜)overğ‘›SGLDiterates{ğœ½ğ‘˜}ğ‘› ğ‘˜=1.
Themeansquarederror(MSE)betweenthisMonteCarloaverageandthe
trueexpectationE
ğœ‹
[â„(ğœ½)]providesonemeasureofSGLDaccuracy.Tehet
al.(2016)studiedthiserrormetricinthesettingwheretheSGLDstepsize
ğ›¿ ğ‘˜ decaysoveriterations.(ii)Alternatively,wecanboundtheerrorbetween
thedistributionoftheSGLDiteratesandtheposteriorğœ‹afterğ‘›steps.This
involvesanalysingthetotalvariation,orWassersteindistance,betweenthe
marginaldistributionoftheSGLDchainatiterationğ‘›(i.e.ğœ‹Ëœğ‘›)andğœ‹.Since
SGLDisbasedontheLangevindiffusion,itsergodicitypropertiescanbe
leveragedtoprovethemarginaldistributionsconvergetoğœ‹.
Consider approach (i). The MSE of the SGLD estimator can be upper
boundedbyğ¶ ğ‘(ğ›¿2+1/ğ‘›ğ›¿),whereğ¶ ğ‘ isaconstantdependentonthedataset
sizeğ‘.Theğ›¿2termreflectsthesquaredbiasand1/ğ‘›ğ›¿isthevarianceterm.
For a fixed computational budget ğ‘›, the bias increases if the step size ğ›¿
increases,whilethevariancedecreaseswithincreasingğ›¿.Tehetal.(2016)
showedthatinthesettingofadecreasingstepsizeğ›¿ ğ‘˜,inordertominimise
the asymptotic MSE, the optimal ğ›¿ decays at rate of ğ‘›âˆ’1/3. This yields an
MSE rate of ğ‘›âˆ’2/3, which is slower than the ğ‘›âˆ’1 rate for standard Monte
Carlo methods. The slower convergence arises from controlling both bias
andvariance,whichissimilartootherasymptoticallybiasedMonteCarlo
methods. On the other hand, for larger computational budgets (i.e. larger
ğ‘›),exactMCMCwilloutperformSGLD,becauseunlikeforexactMCMC
methods,thebiasfromSGLDisnon-vanishing.
Forapproach(ii),onequantifiestheaccuracyofSGLDviatheaccuracy
of the marginal distribution of the SGLD samples, ğœ½ğ‘˜, at iteration ğ‘˜. We
denote this marginal distribution by ğœ‹Ëœğ‘˜. Accuracy is commonly measured
bytheWassersteindistance(3.4)betweenğœ‹Ëœğ‘˜ andtheposteriordistribution
ğœ‹,asthismakestheanalysismoretractable.However,careisneededwhen
interpretingtheWassersteindistanceasitisnotscale-invariant,i.e.chang-
ingtheunitsscalesthedistance.Additionally,forafixedlevelofaccuracy
ineachmarginal,thedistancegrowsasğ‘‘1/2 withdimensionğ‘‘.
MuchofthetheoryforULAandSGLDassumesthelogposteriordensity,82 StochasticGradientMCMCAlgorithms
logğœ‹(ğœ½),issmoothandstronglyconcave.Thekeyassumptionsforanalysis
of these algorithms are that logğœ‹(ğœ½) is ğ‘™-convex (3.18) and logğœ‹(ğœ½) is
continuously differentiable with ğ¿-Lipschitz gradients (3.17). This means
thereexistconstants0 < ğ‘™ â‰¤ ğ¿ suchthatforallğœ½ andğœ½â€²:
âˆ¥âˆ‡logğœ‹(ğœ½â€²)âˆ’âˆ‡logğœ‹(ğœ½)âˆ¥ â‰¤ ğ¿âˆ¥ğœ½ âˆ’ğœ½â€²âˆ¥, and (3.17)
ğ‘™
âˆ’âŸ¨âˆ‡logğœ‹(ğœ½)âˆ’âˆ‡logğœ‹(ğœ½â€²),ğœ½ âˆ’ğœ½â€²âŸ© â‰¥ âˆ¥ğœ½ âˆ’ğœ½â€²âˆ¥2, (3.18)
2
where we define ğœ… = ğ¿/ğ‘™ as the condition number. The first condition
(3.17) bounds how fast the Langevin drift can change, and thus controls
the step size (which should be ğ›¿ < 1/ğ¿). The second assumption (3.18)
ensuresthatthedrifttermpushes ğœ½ towardshigh-densityregions,making
theLangevindiffusiongeometricallyergodic.Together,theseassumptions
implyanupperandlowerboundonthedirectionalderivativesofthelogpos-
teriordensity.Theboundsenablestablediscretisationandpreventpersistent
erroraccumulationintheSGLDalgorithm.Theyalsoimplylogğœ‹(ğœ½)isuni-
modal. By leveraging strong concavity, the resulting theory provides step
size conditions and rates of convergence for ULA/SGLD. When logğœ‹(ğœ½)
is non-strongly concave, alternative assumptions are required (Raginsky
etal.,2017;Majkaetal.,2020),forinstancethatlogğœ‹(ğœ½)isdissipative,i.e.
âŸ¨ğœ½,âˆ‡logğœ‹(ğœ½)âŸ© â‰¥ ğ‘âˆ¥ğœ½âˆ¥2âˆ’ğ‘,forsomeğ‘ > 0andğ‘ â‰¥ 0.
Under the above assumptions (3.17)-(3.18), Dalalyan and Karagulyan
(2019)showedthatrunningtheSGLDalgorithmwithastepsizeparameter
ğ›¿ â‰¤ 2/(ğ‘™ + ğ¿), the Wasserstein-2 distance dğ‘Š (ğœ‹Ëœğ‘›,ğœ‹) between the SGLD
2
marginalğœ‹Ëœğ‘› atiterationğ‘›andtheposteriorğœ‹canbeboundedas:
dğ‘Š 2(ğœ‹Ëœğ‘›,ğœ‹) â‰¤ (1âˆ’ğ‘™ğ›¿)ğ‘› dğ‘Š 2(ğœ‹Ëœ 0,ğœ‹)+ğ¶ 1(ğ›¿ğ‘‘)1/2+ğ¶ 2ğœ(ğ›¿ğ‘‘)1/2, (3.19)
whereğ‘™,ğ¶ ,ğ¶ areconstants,ğ‘‘isthedimension,andğœ2isanupperbound
1 2
on the variance of any individual component of the stochastic gradient
(3.10). In the case of ULA, ğœ2 = 0. The first term in the upper bound
decays exponentially, controlling bias from the initial distribution of the
algorithm ğœ‹Ëœ wheretheMarkovchainisinitialisedfrom.Thesecondterm
0
represents the error that results from the Eulerâ€“Maruyama discretisation
of the Langevin diffusion. The final term relates to the variance in the
stochastic gradient. In the case of the simple gradient estimator (3.6) the
variance is ğ‘‚(ğ‘2/ğ‘š) and the final term in the bound is ğ‘‚(ğ‘âˆšï¸ (ğ›¿ğ‘‘/ğ‘š)),
whichisthenthedominatingtermintheupperbound.
GiventhatthemainmotivationofSGLDistoperformBayesianinference
overlarge-scaledata,anaturalquestionistoaskhowdoesSGLDscaleas
datasizeğ‘ increases?Onewayofaddressingthisistoask,asğ‘ increases,3.3 StochasticGradientLangevinDynamics 83
what is the computational cost of running SGLD so that we have a fixed
level of approximation? We need to define our measure of approximation
appropriately to account for the fact that ğœ‹ will change as ğ‘ increases:
undercertainassumptions,suchastheBernsteinâ€“vonMises(LeCam,1986)
assumption, the variance will decay as 1/ğ‘. This has been investigated
by Nagapetyan et al. (2017) and Baker et al. (2019) who consider using
control variates as a pre-processing step, which has a computational cost
thatislinearin ğ‘.Ignoringthecostofthispre-processingstepforSGLD,
usingcontrolvariatesasymptoticallyhasacomputationalcostpereffective
samplethatisconstant.Bycomparison,thecomputationalcostpereffective
sampleofSGLDwiththesimpleestimatorofthegradient(3.6)islinearin
ğ‘.
Example:TheoreticalPropertiesonaGaussianTargetDistribution
WecangaininsightintothepropertiesoftheSGLDalgorithmbyreturning
toourrunningGaussianexample(3.3).Recallthattheposteriorunderthis
model is a bivariate Gaussian distribution ğœ½|y âˆ¼ N(ğ ğ‘,ğšº ğ‘). In (3.3), we
assumed that the covariance matrix ğšº ğ‘ was diagonal, however, we will
now instead consider a general symmetric positive semi-definite matrix.
We can express the variance matrix in terms of some rotation matrix P
andadiagonalmatrixD,whoseentriessatisfytheconditionğœ2 â‰¥ ğœ2,i.e.
1 2
ğšº ğ‘ = PâŠ¤DP. Under this Gaussian posterior model, the drift term of the
Langevindiffusionis
âˆ‡logğœ‹(ğœ½) =âˆ’ğšºâˆ’1(ğœ½ âˆ’ ğ ) =âˆ’PâŠ¤Dâˆ’1P(ğœ½ âˆ’ ğ ).
ğ‘ ğ‘ ğ‘
The ğ‘˜ +1thiterationoftheSGLDalgorithmis
ğ›¿ âˆš
ğœ½ğ‘˜+1 = ğœ½ğ‘˜ âˆ’ 2PâŠ¤Dâˆ’1P(ğœ½ğ‘˜ âˆ’ ğ ğ‘)+ğ›¿ğ‚ğ‘˜ + ğ›¿Zğ‘˜, (3.20)
whereZğ‘˜isavectoroftwoindependentstandardGaussianrandomvariables
and ğ‚ğ‘˜ istheerrorinducedbyourstochasticestimateof âˆ‡logğœ‹(ğœ½ğ‘˜).The
entriesofDâˆ’1correspondtotheconstantsthatappearinassumptions(3.17)-
(3.18),withğ‘™ =1/ğœ2andğ¿ =1/ğœ2,whicharediscussedfurtherinSection
1 2
3.5intermsoftheirimpactonthestepsizeparameterğ›¿.
We can simplify the SGLD algorithm by considering updates on the
transformedstateğœ½Ëœ =P(ğœ½ âˆ’ ğ ),whichgivesSGLDupdates,
ğ‘
ğ›¿ âˆš
ğœ½Ëœ
ğ‘˜+1
=ğœ½Ëœ
ğ‘˜
âˆ’ 2Dâˆ’1ğœ½Ëœ
ğ‘˜
+ğ›¿Pğ‚+ ğ›¿PZ
(cid:18) 1âˆ’ğ›¿/(2ğœ2) 0 (cid:19) âˆš
=
0
1
1âˆ’ğ›¿/(2ğœ2)
ğœ½Ëœ
ğ‘˜
+ğ›¿Pğ‚ğ‘˜ + ğ›¿PZğ‘˜,
284 StochasticGradientMCMCAlgorithms
wherethevarianceofPZğ‘˜ isstilltheidentityasPisarotationmatrix.
TheSGLDupdateisavectorauto-regressiveprocess.Thisprocesswill
have a stationary distribution if ğ›¿ < 4ğœ2 = 4/ğ¿, otherwise the process
2
will produce trajectories which will tend to infinity in at least one of the
two components. A similar assumption on the step size is required to es-
tablish the upper bound on dğ‘Š (ğœ‹Ëœğ‘›,ğœ‹) in (3.19) for log-concave posterior
2
distributions.
For simplicity in the manner of convergence, we choose ğ›¿ < 2ğœ2 and
2
then define ğœ† ğ‘— = ğ›¿/(2ğœ2 ğ‘—) < 1. This then leads to the following SGLD
dynamicsforeachcomponent, ğ‘— =1,2
ğœƒËœ ğ‘˜( +ğ‘—)
1
= (1âˆ’ğœ† ğ‘—)ğ‘˜ğœƒËœ 0(ğ‘—)
+âˆ‘ï¸ğ‘˜
(1âˆ’ğœ† ğ‘—)ğ‘˜âˆ’ğ‘–
(cid:16)
ğ›¿Pğ‚ğ‘–
+âˆš ğ›¿PZğ‘–(cid:17)(ğ‘—)
, (3.21)
ğ‘–=1
where ğœƒËœ ğ‘˜(ğ‘—) is the ğ‘—th component of ğœ½Ëœ ğ‘˜. From this, we immediately see
from the first term on the right-hand side of (3.21) that the SGLD algo-
rithm forgets its initial condition exponentially quickly. However, the rate
ofexponentialdecayisslowerforthecomponentwiththelargermarginal
variance, i.e. ğœ2. Furthermore, as the step size ğ›¿ is constrained by the
1
smaller marginal variance ğœ2, this rate will have to be slow if ğœ2 â‰ª ğœ2;
2 2 1
thissuggeststhattherearebenefitsfromre-scalingtheposteriorsothatthe
marginalvariancesofdifferentcomponentsareapproximatelyequal.
Taking the expectation of (3.21), with respect to ğ‚ and Z, and letting
ğ‘˜ â†’ âˆ, results in SGLD dynamics that have the correct limiting mean,
but with an inflated variance. This is most easily seen if we assume that
the variance of Pğ‚ is independent of position. In this case, the stationary
distributionofSGLDwillhaveavarianceof
Varğœ‹Ëœ (cid:2) ğœ½Ëœ(cid:3) = (cid:18) (1âˆ’(1âˆ’ 0ğœ† 1)2)âˆ’1 (1âˆ’(1âˆ’0 ğœ† )2)âˆ’1 (cid:19) (ğ›¿2ğšº ğ‘ +ğ›¿I 2),
2
where I is a 2-dimensional identity matrix. The marginal variance for
2
component ğ‘— isthus
ğœ2
ğ‘—
1âˆ’1+ ğ›¿/ğ›¿ (Î£
4ğœğ‘—ğ‘—
2)
= ğœ2
ğ‘—
(cid:0) 1+ğ›¿Î£ ğ‘—ğ‘—(cid:1) +
4ğ›¿
+ğ‘‚(ğ›¿2).
ğ‘—
The inflation in variance comes both from the noise in the estimate of
âˆ‡logğœ‹(ğœ½), which is the ğ›¿Î£ ğ‘—ğ‘— factor, and the Euler approximation, which
suppliestheadditiveconstant,ğ›¿/4.Formoregeneralposteriordistributions,
the mean of the stationary distribution of the SGLD algorithm will not
necessarilybecorrect,butwewouldexpectthemeantobemoreaccurate3.4 AGeneralFrameworkforstochasticgradientMCMC 85
thanthevariance,withthevarianceofSGLDbeinggreaterthanthatofthe
trueposterior.Thisanalysisfurthersuggeststhat,forposteriordistributions
whichareclosetoGaussian,itmaybepossibletoperformabettercorrection
to compensate for the inflation of the variance. For example, we could
replaceZğ‘˜ withGaussianrandomvariableswher âˆšethecovariancematrixis
chosensuchthatthecovariancematrixofğ›¿ğ‚ğ‘˜ + ğ›¿Zbecomestheidentity
matrix.
3.4 AGeneralFrameworkforstochasticgradientMCMC
Stochastic gradient MCMC is not limited to approximating the Langevin
diffusion.Wecanconstructotherdiffusionprocessesthatalsohaveğœ‹astheir
stationarydistribution.Byapproximatingthedynamicsofthesealternative
diffusions, we can develop stochastic gradient versions of many popular
MCMCalgorithmsbeyondtheLangevinmethod.
Ma et al. (2015) proposed a general framework for stochastic gradient
MCMC that extends the approach beyond the Langevin diffusion. This
frameworkallowsustodevelopstochasticgradientanaloguesofalgorithms
likeHamiltonianMonteCarlo(HMC)(asintroducedinSection2.2),which
leveragesHamiltoniandynamics.stochasticgradientHMC(SGHMC)has
beenshowntodisplayimprovedmixingpropertiescomparedtostochastic
gradientLangevindynamics.
BeyondbothSGLDandSGHMC,stochasticgradientMCMCapproaches
provideageneralandflexibleframeworktoadaptmanyMCMCalgorithms
tolargedatasetswherefull-dataMCMCisinfeasible.Byapproximatingthe
dynamics of various diffusions with the correct stationary distribution, it
ispossibletodevelopfast,scalableMCMCalgorithmstailoredtodifferent
posteriorgeometriesanddatasets.
Weintroduceageneralclassofdiffusionmodels,thatmayalsoinclude
auxiliary variables, and we denote the full state by ğ‘ âˆˆ Rğ‘‘ ğ‘. This state
contains our variable of interest ğœ½, as well as an auxiliary variable p.
For example, in the case of the overdamped Langevin diffusion, ğ‘ = ğœ½,
and extending the state space to include a velocity variable p allows for
the underdamped Langevin diffusion of Section 1.4.3, which relates to
HamiltonianMCMC,givingğ‘ = (ğœ½,p).
Wedefinethegeneralstochasticdifferentialequationforğ‘as
1 âˆšï¸
dğ‘ = b(ğ‘)dğ‘¡+ D(ğ‘)dğ‘Š ğ‘¡, (3.22)
2
whereb(ğ‘)isthedriftterm,D(ğ‘)isapositivesemidefinitediffusionmatrix86 StochasticGradientMCMCAlgorithms
withmatrixsquarerootâˆšï¸ D(ğ‘) andğ‘Š ğ‘¡ denotes ğ‘‘ ğ‘-dimensionalBrownian
motion. Ma et al. (2015) provide a general framework for how to choose
b(ğ‘)andD(ğ‘)toachieveadesiredstationarydistribution.Givenageneral
functionğ»(ğ‘),whereexp{âˆ’ğ»(ğ‘)}isintegrable,simulatingfromanSDE
withdriftterm,
b(ğ‘) =âˆ’[D(ğ‘)+Q(ğ‘)]âˆ‡ğ»(ğ‘)+Î“(ğ‘), where (3.23)
âˆ‘ï¸ğ‘‘ ğœ•
Î“ ğ‘–(ğ‘) = ğœ•ğ‘ğ‘—(Dğ‘–ğ‘—(ğ‘)+Qğ‘–ğ‘—(ğ‘)),
ğ‘—=1
ensuresthatthestationarydistributionof(3.22)isproportionaltoexp{âˆ’ğ»(ğ‘)}.
The matrix Q(ğ‘) is a skew-symmetric curl matrix which controls the de-
terministic traversing effects of the SDE sampler, whereas D(ğ‘) controls
the diffuse dynamics of the process. The general SDE (3.22) can be de-
composed into (i) Riemannian-Langevin dynamics which are reversible
andcontrolledbyD(ğ‘)and(ii)deterministicHamiltoniandynamicswhich
areirreversibleandcontrolledbyQ(ğ‘).FortheLangevin-typealgorithms,
where Q(ğ‘) = 0, it can be shown that they are able to quickly converge
towardsamodeofthedistributionanddiffusivelyexploretheregionaround
themode.ForthedeterministicHamiltonianMonteCarloalgorithm,where
D(ğ‘) = 0, the algorithm excels at deterministically traversing along level
setsoftheHamiltonian.
ToapproximatelysamplefromtheSDEwediscretisethedynamicsusing
the same Eulerâ€“Maruyama scheme used for the Langevin diffusion (3.1),
i.e.,
ğ›¿ âˆš
ğ‘ğ‘˜+ğ›¿ = ğ‘ğ‘˜ âˆ’ [(D(ğ‘ğ‘˜)+Q(ğ‘ğ‘˜))âˆ‡ğ»(ğ‘ğ‘˜)+Î“(ğ‘ğ‘˜)]+ ğ›¿Z, ğ‘˜ â‰¥ 0,
2
(3.24)
where Z âˆ¼ N(0,D(ğ‘ğ‘˜)). If ğ‘ = ğœ½, the posterior distribution ğœ‹ is the
stationarydistributionforthechoice ğ»(ğ‘) = âˆ’logğœ‹(ğœ½).Ifweincludean
auxiliary variable, i.e. ğ‘ = (ğœ½,p), and we choose ğ»(ğ‘) = âˆ’logğœ‹(ğœ½) +
ğ¾(p) for some user-chosen function ğ¾(Â·), then ğœ‹ is the ğœ½-marginal of the
stationarydistribution.
FromthegeneralSDEframework(3.22),wecanobtainstochasticgradi-
entMCMC(SGMCMC)algorithmsbyreplacingâˆ‡ğ»(ğ‘ğ‘˜)in(3.24)withan
unbiasedestimate(cid:98)âˆ‡ğ»(ğ‘ğ‘˜) thatisevaluatedonasubsampleofthedataset.
As shown in Section 3.3.3, and Figure 3.2, the statistical efficiency of
stochastic gradient algorithms is strongly tied to the variance of the gra-
dient estimate. We can view that the variability of the gradient estimate
inflatesthenoiseinputinto(3.24)â€“whichwillleadtoastationarydistribu-3.4 AGeneralFrameworkforstochasticgradientMCMC 87
tion whose variance is also inflated. Therefore, where feasible, we should
(cid:104) (cid:105)
correctforthis.IfwedefineV(ğ‘ğ‘˜) =Var (cid:98)âˆ‡ğ»(ğ‘ğ‘˜) asthevarianceofthe
stochasticgradient,thentheconditionalvarianceofğ‘ğ‘˜+ğ›¿ givenğ‘ğ‘˜ willbe
inflatedbyğ›¿2B(ğ‘ğ‘˜),where
1
B(ğ‘ğ‘˜) = (D(ğ‘ğ‘˜)+Q(ğ‘ğ‘˜))V(ğ‘ğ‘˜)(D(ğ‘ğ‘˜)+Q(ğ‘ğ‘˜))âŠ¤. (3.25)
4
Correcting for this inflation in the SGMCMC setting leads to a modified
discrete-timealgorithmin(3.24),whereâˆ‡ğ»(ğ‘ğ‘˜)isreplacedbythestochas-
ticapproximation(cid:98)âˆ‡ğ»(ğ‘ğ‘˜)butwealsoreducethevarianceofthenoiseterm,
soZ âˆ¼ N(0,D(ğ‘ğ‘˜) âˆ’ğ›¿B(ğ‘ğ‘˜)).Thechallengewiththisideainpracticeis
howdoweestimateB(ğ‘ğ‘˜)?
Through different choices of ğ»(ğ‘), D(ğ‘) and Q(ğ‘), we can derive
several SGMCMC algorithms as special cases of the general discretised
SDE(3.24).Someofthesespecialcaseswillbeintroducedinthefollowing
sections.
StochasticGradientLangevinDynamics
TheSGLDalgorithm(introducedinSection3.3)followsfromthedynamics
ofthegeneralSDE(3.24)bysetting
ğ‘ = ğœ½, ğ»(ğ‘) =âˆ’logğœ‹(ğœ½), D(ğ‘) =I, Q(ğ‘) =0
togivedynamics
ğ›¿ âˆš
ğœ½ğ‘˜+ğ›¿ = ğœ½ğ‘˜ + [âˆ‡logğœ‹(ğœ½ğ‘˜)]+ ğ›¿Z, ğ‘˜ â‰¥ 0,
2
which is the same Eulerâ€“Maruyama approximation of the Langevin dif-
fusion introduced in (3.2), but where in practice âˆ‡logğœ‹(ğœ½ğ‘˜) would be
replaced with a stochastic gradient estimator, using, for example, (3.6),
(3.8)or(3.14).
StochasticGradientHamiltonianMonteCarlo
ThepopularHMCalgorithmintroducedinSection2.2canalsobederived
as a special case of the general SDE dynamics (3.24). As discussed in
Section 2.2, the HMC algorithm introduces a velocity component p to
improve the mixing of the Markov chain and a mass matrix M, where
the Hamiltonian dynamics are used to update the position ğœ½ and velocity
componentsp.Inpractice,theHMCalgorithmusestheleapfrognumerical
integrationschemetominimisenumericalerrors,however,forthepurpose
of illustration, we shall consider the simpler Euler integration scheme for
creatingastochasticgradientHMCalgorithm.88 StochasticGradientMCMCAlgorithms
TheEuler-discretisedHamiltoniandynamicsforthestateğ‘ = (ğœ½,p) are
(cid:18) ğœ½ğ‘˜+ğ›¿(cid:19)
=
(cid:18) ğœ½ğ‘˜(cid:19)
+
ğ›¿ (cid:20) Mâˆ’1pğ‘˜ (cid:21)
, ğ‘˜ â‰¥ 0, (3.26)
pğ‘˜+ğ›¿ pğ‘˜ 2 âˆ‡logğœ‹(ğœ½ğ‘˜)
whichfitsintothegeneralSDEframeworkof (3.22)and(3.23)bysetting
(cid:18) (cid:19)
1 0 âˆ’I
ğ»(ğ‘) =âˆ’logğœ‹(ğœ½)+ pâŠ¤Mâˆ’1p, D(ğ‘) =0 and Q(ğ‘) = .
2 I 0
If the gradient âˆ‡logğœ‹(ğœ½) in (3.26) is replaced by a stochastic gradient
âˆ‡Ë† logğœ‹(ğœ½) = âˆ‡logğœ‹(ğœ½) +N(0,V(ğœ½)), where V(ğœ½) is the variance of the
stochasticgradient,thenunderthisstochasticsettingthedynamicsin(3.26)
willbecome
ğ›¿
pğ‘˜+ğ›¿ =pğ‘˜ + âˆ‡logğœ‹(ğœ½)+N(0,ğ›¿V(ğœ½ğ‘˜)),
2
whichisknownasthenaivestochasticgradientHMC(SGHMC)algorithm
(Chenetal.,2014;Maetal.,2015).ItwasprovedinChenetal.(2014)that
thenaiveSGHMCalgorithmdoesnotworkwellastheerrorfromestimating
the gradient will accumulate over iterations and cannot be controlled. To
overcome this, the authors suggest adding a friction term for the velocity,
thisisequivalenttousingastochasticgradientversionoftheunderdamped
Langevindynamics,ofSection1.4.3.Theintuitionisthattheintroductionof
frictionmeansthaterrorsfrompreviousiterationswilldecaygeometrically
sothattheoverallerrorfromusingastochasticgradientcanbecontrolled.
Wecanfurtherimproveaccuracybyusingtheideaofcorrectingthevariance
oftheinjectednoisethatisintroducedateachiteration.
ReturningtothegeneralSDEframework(3.22),thecorrectedstochastic
gradientHMCalgorithmfollowsbysetting
1
ğ‘ = (ğœ½,p), ğ»(ğ‘) =âˆ’logğœ‹(ğœ½)+ pâŠ¤Mâˆ’1p,
2
(cid:18) (cid:19) (cid:18) (cid:19)
0 0 0 âˆ’I
D(ğ‘) = , Q(ğ‘) = ,
0 C I 0
whereCisasagenericmatrix,sometimesknownasthefrictionterm,andis
chosensuchthatC âª° ğ›¿V(ğœ½)isapositivesemi-definitematrix.Discretising
this general form SDE with this particular D(ğ‘) and Q(ğ‘) leads to the
dynamics,
(cid:18) ğœ½ğ‘˜+ğ›¿(cid:19)
=
(cid:18) ğœ½ğ‘˜(cid:19)
+
ğ›¿ (cid:20) Mâˆ’1pğ‘˜ (cid:21)
+
(cid:20) âˆš0 (cid:21)
, ğ‘˜ â‰¥ 0. (3.27)
pğ‘˜+ğ›¿ pğ‘˜ 2 âˆ‡Ë† logğœ‹(ğœ½ğ‘˜)âˆ’CMâˆ’1pğ‘˜ ğ›¿Z3.4 AGeneralFrameworkforstochasticgradientMCMC 89
Thegradientâˆ‡logğœ‹(ğœ½ğ‘˜)isreplacedbyastochasticestimatorâˆ‡Ë† logğœ‹(ğœ½ğ‘˜)
andZâˆ¼N(0,Câˆ’ğ›¿BË†),whereBË† isanestimateofV(ğœ½ğ‘˜).
TheefficiencywithwhichanMCMCalgorithmcanexploreaposterior
distribution is heavily tied to the geometry of the posterior. If the ğœ½ com-
ponents of the posterior distribution are strongly correlated, then the step
size will need to be optimised for the component with the smallest vari-
abilityinordertoensurethatthealgorithmdoesnotdiverge(asillustrated
in Section 3.3.3 for the case of a Gaussian target distribution). This will
significantly reduce the mixing time of the other components unless the
posterior distribution is reparameterised so that the components of ğœ½ are
uncorrelatedandhavesimilarmarginaldistributions.Withinthecontextof
SGMCMCdynamics,itispossibletodevelopalgorithmsthatincorporate
reparameterisationbypreconditioningthegradientswithapositive-definite
matrix G(ğœ½). If G(ğœ½) is the expected Fisher information of the posterior
distribution, then the SGMCMC dynamics will be locally adapted to the
posteriorcurvaturebyexploitingtheRiemanniangeometryoftheposterior
distribution.
StochasticGradientRiemannianLangevinDynamics
Riemannian versions of SGLD (stochastic gradient Riemannian Langevin
dynamics;SGRLD)andSGHMC(stochasticgradientRiemannianHamil-
tonianMonteCarlo;SGRHMC)alsofollowasspecialcasesofthegeneral-
formSDE(3.23).WecanderiveSGRLDbysetting
ğ‘ = ğœ½, ğ»(ğ‘) =âˆ’logğœ‹(ğœ½), D(ğ‘) =G(ğœ½)âˆ’1, Q(ğ‘) =0
whichleadstothediscrete-timedynamics
ğ›¿ âˆš
ğœ½ğ‘˜+ğ›¿ = ğœ½ğ‘˜ + (cid:2) G(ğœ½ğ‘˜)âˆ’1âˆ‡Ë† logğœ‹(ğœ½ğ‘˜)+Î“(ğœ½ğ‘˜)(cid:3) + â„Z, ğ‘˜ â‰¥ 0,
2
with Z âˆ¼ N(0,G(ğœ½ğ‘˜)âˆ’1) and âˆ‡Ë† logğœ‹(ğœ½ğ‘˜) is a stochastic estimator for
âˆ‡logğœ‹(ğœ½ğ‘˜). The term G(ğœ½ğ‘˜)âˆ’1âˆ‡logğœ‹(ğœ½ğ‘˜) is the natural gradient of the
posteriordistributionwhichgivesthedirectionofsteepestascentbytaking
into account the geometry implied by G(ğœ½ğ‘˜). If G(ğœ½) = I, then the direc-
tion of steepest ascent would be given in the Euclidean space. The term
Î“ ğ‘–(ğœ½) = (cid:205)
ğ‘—
ğœ•(G ğœ•(ğœ½ ğœ½) ğ‘—âˆ’1)ğ‘–ğ‘— accounts for the curvature of the manifold defined
byG(ğœ½).AstochasticgradientHMCimplementationthatutilisestheRie-
manniangeometryoftheposteriordistributioncanalsobederivedwithin
the general SDE framework. Taking the curl matrix Q(ğœ½) from SGHMC90 StochasticGradientMCMCAlgorithms
andreplacingtheidentitymatriceswithG(ğœ½)âˆ’1/2 leadstoanSGHMCal-
gorithmthatisadaptivetothelocalposteriorgeometry.
TheoreticalcomparisonofSGMCMCalgorithms
WhencomparingthevarietyofSGMCMCalgorithmsitisnaturaltocon-
siderwhichalgorithmisthemostaccurateandcomputationallyefficient.It
ispossibletocomparethetheoreticalconvergenceratesforsomeofthese
algorithms.InthecaseofSGHMCandSGLD,andinthecontextofsmooth
andstronglylog-concaveposteriors,itispossibletoderiveboundsonthe
Wasserstein-2 distance between the posterior and the SGMCMC sample
distribution.Theseresultsarenon-asymptoticandboundtheWasserstein-2
error for some ğ‘˜ iterations of the SGMCMC algorithm using optimally
tuned step sizes. These results show that if the stochastic gradients have
lowvariance,thenSGLDrequiresğ‘‚(ğ‘‘2/ğœ–2)iterationsforagivenaccuracy
ğœ–, while SGHMC needs onlyğ‘‚(ğ‘‘/ğœ–). So SGHMC is generally preferred,
withincreasingbenefitsinhigherdimensions(seeFigure3.4foranumer-
ical illustration). However, there is a phase transition in SGHMC as the
gradient noise variance grows, above a threshold SGHMC behaves like
SGLD,requiringğ‘‚(ğ‘‘2/ğœ–2) iterations.
3.5 GuidanceforEfficientScalableBayesianLearning
Each of the SGMCMC algorithms introduced has tuning parameters that
needtobechosenbytheuserwhenrunningthesealgorithms.SomeSGM-
CMC algorithms, such as SGLD with control variates, require additional
tuningparameters,e.g.choosingacontrolvariate,butcommontoallSGM-
CMC algorithms is the step size parameter ğ›¿, the subsample size ğ‘š, and
thenumberofMonteCarloiterationsğ‘›.
For MCMC algorithms with Metropolisâ€“Hastings corrections, such as
MALA (Section 2.1.4) and HMC (Section 2.2), and which do not utilise
data subsampling, the main tuning parameter is the step size ğ›¿. Existing
theoretical results have established that the optimal ğ›¿ should be chosen
suchthattheMetropolisâ€“Hastingsacceptancerateis57.4%(inthecaseof
MALA)oratleast65%(inthecaseofHMC).Undercertainassumptions
on the posterior distribution, this choice minimises the integrated auto-
correlation time of the Markov chain produced by these algorithms (see
Section1.3.2forfurtherdetails).
InthecaseofSGMCMCalgorithms,whichdonotincludeaMetropolisâ€“
Hastings acceptance step, minimising the auto-correlation of the Markov3.5 GuidanceforEfficientScalableBayesianLearning 91
chain is not an appropriate objective for optimising ğ›¿. Intuitively, this is
becausetheauto-correlationcanbereducedbysimplylettingğ›¿ â†’âˆ,butin
thecaseoftheULAandSGMCMCalgorithms,thiswillincreasethebiasin
thediscretiseddiffusionprocessandleadtopoorposteriorapproximations.
This is not an issue for MALA and HMC as the Metropolisâ€“Hastings
acceptanceratewilltendtozeroasğ›¿ â†’âˆ,andsointhissetting,minimising
the auto-correlation time will balance between making large jumps in the
posterior space (i.e large ğ›¿) against having a reasonable acceptance rate.
Alternative metrics are required to minimise the variance in the Markov
chainandaccountfortheasymptoticbiaspresentinSGMCMCalgorithms.
ApopularchoiceisthekernelSteindiscrepancy(KSD)metric,akernelised
versionoftheSteindiscrepancydiscussedindetailinChapter6.TheKSD
provides a measure of discrepancy between the true posterior distribution
and the Monte Carlo approximation generated by an SGMCMC or other
MCMCalgorithm.UsingtheKSDmetric,itispossibletooptimiseğ›¿(and
otherSGMCMCtuningparameters)byassessingvarioustuningparameters
over a grid of possible values and selecting the tuning parameters which
minimise the KSD (Coullon et al., 2023). Related ideas, based on Steinâ€™s
methodandexploredinChapter6,canbeusedtooptimallythintheMarkov
chaintomaximisetheinformationabouttheposteriorcontainedbyasmaller
setofMonteCarlosamples.
Thestepsizeparameterğ›¿inSGLDcanbechosenusingtheconvergence
results in Section 3.3.3. The upper bound on the Wasserstein-2 distance
from Dalalyan and Karagulyan (2019), under assumptions 3.17 and 3.18,
requires ğ›¿ â‰¤ 2/(ğ‘™ + ğ¿) in order to establish convergence for the SGLD
algorithm. Setting ğ›¿ to be too small leads to slow convergence of the
Markovchain,butastepsizethatistoolargecancausetheSGLDalgorithm
to diverge. If ğ‘™ and ğ¿ are known, then this information can be used to set
ğ›¿. For example, returning to the running Gaussian example (3.3) where
theposteriordistributionis ğœ½|y âˆ¼ N(ğ ğ‘,ğšº ğ‘),weknowthatâˆ‡logğœ‹(ğœ½) =
âˆ’ğšºâˆ’1(ğœ½âˆ’ğ )andthattheLipschitzconstantğ¿measuresthelargestchange
ğ‘ ğ‘
inthegradient.TakingtheHessiani.e.,âˆ‡âˆ‡logğœ‹(ğœ½) =âˆ’ğšºâˆ’1,theLipschitz
ğ‘
constant is equal to the spectral norm of the inverse covariance matrix
ğ¿ = âˆ¥âˆ‡logğœ‹(ğœ½)âˆ¥ â‰¤ âˆ¥âˆ‡âˆ‡logğœ‹(ğœ½)âˆ¥ â‰¤ âˆ¥ğšºâˆ’ ğ‘1âˆ¥ = 1/ğœ† min(ğšº ğ‘), which is
equaltothereciprocalofthesmallesteigenvalueofthecovariancematrix.
As for the smoothness parameter ğ‘™, this is the largest eigenvalue of the
Hessianğ‘™ = âˆ¥âˆ‡âˆ‡logğœ‹(ğœ½)âˆ¥ â‰¥ ğœ† max(ğšº ğ‘).Therefore,ifğ›¿ â‰¤ 2/(ğ‘™ +ğ¿),then
ğ›¿ â‰ˆğœ† min(ğšº ğ‘)/ğœ† max(ğšº ğ‘),whichisequaltotheconditionnumberğœ… = ğ¿/ğ‘™.
We can assess the relationship between the step size parameter and the
propertiesoftheGaussianmodelbyconsideringtwocovariancefunctionsÎ£92 StochasticGradientMCMCAlgorithms
(cid:18) (cid:19) (cid:18) (cid:19)
1 0 1 3
fromtheGaussianmodel(3.3),whereğšº(ğ‘–) = andğšº(ğ‘–ğ‘–) = .
0 10 3 10
Under covariance ğšº(ğ‘–), the variables ğœ½ are uncorrelated whereas for ğšº(ğ‘–ğ‘–)
thereisimposedcorrelationbetweenthecomponentsofğœ½.Thisleadstocon-
ditionnumbersğœ…(ğ‘–) â‰ˆ10âˆ’3andğœ…(ğ‘–ğ‘–) â‰ˆ10âˆ’4forğšº(ğ‘–) andğšº(ğ‘–ğ‘–),respectively.
InFigure3.3,weplottheWasserstein-2distancebetweenthetrueGaussian
posterior distribution with ğ‘ = 1000 data points with the approximation
generated from ğ‘› = 10000 iterations of the SGLD algorithm, where the
stepsizeparameterğ›¿ isvariedoveragridofvaluesğ›¿ âˆˆ {10âˆ’5,...,10âˆ’1}.
TheleftpanelofFigure3.3isforthemodelwithuncorrelatedcovariance
matrixğšº(ğ‘–) andtherightpanelusesğšº(ğ‘–ğ‘–).Forbothexperiments,thereisa
valuefor ğ›¿ whichminimisestheWasserstein-2distanceandinthecaseof
uncorrelatedvariables,i.e.ğšº(ğ‘–),theoptimalğ›¿islargerthaninthecorrelated
caseğšº(ğ‘–ğ‘–).
Thedotindicatesthestepsizerecommendedbythetheoretical
results, i.e. ğ›¿ = ğ¿/ğ‘™, which closely aligns with the optimal grid search
opt
result.
In general settings, however, it is not possible to calculate the optimal
stepsizeparameterasthisdependsonpropertiesoftheunknownposterior
distribution. Under certain conditions on the posterior distribution, and
assuming that ğ‘ is sufficiently large, then by the Bernsteinâ€“von Mises
theorem,thevarianceoftheposteriordistributionwillbeoforderğ‘‚(ğ‘‘/ğ‘).
Therefore,settingthestepsizeparametertobeproportionalto1/ğ‘,i.e.ğ›¿ âˆ
1/ğ‘,givesasimpleheuristicstepsizewhichisoftenusedbypractitioners.
Note that, for the Gaussian posterior example given above, this heuristic
wouldleadtoastepsizeğ›¿ = 1/ğ‘ = 10âˆ’3,whichmatchestheoptimalstep
sizeparameterforthesettingwithuncorrelatedğœ½components,i.e.ğšº(ğ‘–)
(see
theleftpanelinFigure3.3).However,thisstepsizewouldbetoolargefor
thecorrelatedsettingwithcovarianceÎ£(ğ‘–ğ‘–) (seerightpanelinFigure3.3).
AnalternativeperspectivediscussedinSection3.3.1isthatfortheSGLD-
type algorithms, the variance of the gradient component of the Langevin
dynamics is ğ‘‚(ğ›¿2) and therefore dominated by the ğ‘‚(ğ›¿) variance from
the injected noise of the process. For the SGLD algorithm with a simple
unbiasedgradientestimator,thevarianceofthegradientisğ‘‚(ğ‘2),andso
a natural choice for ğ›¿ to control the variance of the stochastic gradient is
ğ›¿ =1/ğ‘.
3.5.1 ExperimentsonaLogisticRegressionModel
The logistic regression model, first introduced in Section 1.2.1, is used to
predict the probability of binary outcomes ğ‘¦ ğ‘— âˆˆ {0,1} given covariates3.5 GuidanceforEfficientScalableBayesianLearning 93
       
   
   
   
   
   
       
 6 W H S  V L ] H   O R J     6 W H S  V L ] H   O R J   
Figure3.3 TheWasserstein-2distancebetweenthetrueand
approximateposteriordistributionswhenvaryingthestepsize
parameterğ›¿.LeftpanelisforthemodelwithcovarianceÎ£(ğ‘–).
RightpanelisforthemodelwithcovarianceÎ£(ğ‘–ğ‘–).
xğ‘— âˆˆ Rğ‘‘ ğ‘¥. Assuming a Gaussian prior for the regression coefficients ğœ½ âˆ¼
N(0,Î£ ğœ½),theposteriordistribution,conditionalonthedataD = {ğ‘¦ ğ‘—,xğ‘—}ğ‘ ğ‘—=1,
isgivenbytheunnormaliseddensity
ğœ‹(ğœ½) := ğœ‹(ğœ½|D)
âˆexp(cid:26) âˆ’1 ğœ½ğ‘‡Î£âˆ’1ğœ½(cid:27) (cid:214)ğ‘ exp{ğ‘¦ ğ‘—xâŠ¤ ğ‘—ğœ½}
.
2 ğœ½ 1+exp{xğ‘‡ğœ½}
ğ‘—=1 ğ‘—
Metropolisâ€“Hastings-basedMCMCalgorithms,suchasMALA(Section
2.1.4) and HMC (Section 2.2), can be used to sample from the posterior
distributionofthelogisticregressionmodel.However,inthelargedataset-
ting,thesealgorithmswillconvergeslowlyduetothehighercomputational
costofevaluatingtheposteriordensity,anditsgradient,onthefulldataset.
Whereas SGMCMC algorithms are faster, per Monte Carlo iteration, but
introduceanasymptoticbiasintotheposteriorapproximation.
To assess the statistical accuracy of SGMCMC against exact MCMC
approaches, consider a logistic regression model with ğ‘ = 10000 obser-
vations, which is small enough to allow MALA and HMC approaches to
be computationally feasible. The dataset is split into a training and test
datasetwitha80/20split.Dataaresimulatedfromthelogisticregression
model where the dimension of the parameter vector ğœ½ âˆˆ Rğ‘‘ is varied,
ğ‘‘ âˆˆ {100,200,300,400,500}.Thestatisticalaccuracyoftheposteriorap-
proximationoftheSGLDalgorithm(Alg.3)andSGHMCalgorithm(3.27),
 H F Q D W V L '    Q L H W V U H V V D :  H F Q D W V L '    Q L H W V U H V V D :94 StochasticGradientMCMCAlgorithms
withandwithoutcontrolvariates(3.7),iscomparedagainstalongMonte
CarlorunoftheNUTSalgorithm(HoffmanandGelman,2014)usingthe
PythonpackageBlackJax(Cabezasetal.,2024),whichprovidesaground-
truthMonteCarloapproximationtotheposteriordistribution.Asnotedin
Section 3.5, standard MCMC diagnostics are not applicable for assessing
the convergence of SGMCMC algorithms, and so as a proxy for posterior
accuracy, the mean squared error (MSE) in the estimate of the posterior
meanandvariancegivenbytheSGMCMCalgorithmsiscomparedagainst
theposteriormeanandvariancetakenfromtheNUTSsamples.TheNUTS
and SGMCMC algorithms are each run for ğ‘› = 10000 iterations and for
theSGMCMCalgorithms,asubsamplesizeof10%isused.Notethatthe
stepsizeparameterisfixedusingtheheuristicğ›¿ =1/ğ‘ forallexperiments.
Notethatimprovednumericalresultscouldbeachievedbyoptimisingthe
stepsizeparameterforeachdimensionğ‘‘.
Figure3.4showstheMSEintheestimateofE
ğœ‹
[ğœ½]andVarğœ‹ [ğœ½],where
the true expectation and variance are given by the NUTS sampler. The
plotted results are presented as the MSE averaged over the parameter di-
mension.TheresultsshowthattheSGHMCalgorithmsaremorerobustto
higherdimensionsthantheSGLD-typealgorithms.Thiscoincideswiththe
established theory that compared to SGHMC, SGLD requires more itera-
tionstoachieveasimilarlevelofaccuracy.Notethatforhigher-dimensional
problems,itmaybenecessarytoruntheSGDoptimiserforlongertofind
themodeofthedistributionthatisusedincontrolvariate-basedSGMCMC
algorithms.
The posterior accuracy results in Figure 3.4 suggest that without in-
creasingthe numberof MonteCarloiterations, theSGMCMCalgorithms
willproducepoorerposteriorapproximationswithincreasingparameterdi-
mension.TheresultsshowthatSGMCMCalgorithmscanproducehighly
accurate approximations for the first and second moment of the posterior
distribution,andinthecaseofSGHMC,thefirstmomentisverysimilarto
the first moment given by the NUTS sampler. As illustrated previously in
Figure 3.2, SGLD can produce good approximations to the first posterior
moment, but for small data subsamples it tends to produce overestimates
of the second posterior moment. The reason for the poorer posterior ap-
proximationoftheSGLD-basedsamplerscomparedtotheSGHMC-based
samplerscanbeseenintheMonteCarlotraceplotsinFigure3.5.Forthe
higher-dimensionalsetting(ğ‘‘ =500),wecanseethatforposteriorcompo-
nents ğœƒ and ğœƒ , the mixing is worse for SGLD and SGLD-CV compared
1 2
toSGHMCandSGHMC-CV.ThisisthenreflectedintheMonteCarloap-
proximationfortheposteriormeanandvariance(Figure3.4),whereSGLD3.5 GuidanceforEfficientScalableBayesianLearning 95
  H  
 6 * / '       6 * / '
      
 6 * / '  & 9  6 * / '  & 9
    
 6 * + 0 &  6 * + 0 &
      
 6 * + 0 &  & 9       6 * + 0 &  & 9
      
    
      
    
           
               
 ' L P H Q V L R Q  ' L P H Q V L R Q
Figure3.4 Themeansquarederror(MSE)ofE ğœ‹ [ğœ½] (leftpanel)
andVarğœ‹ [ğœ½] (rightpanel)comparedtothesamemoments
calculatedfromtheNUTSposteriorsamples,whicharetreatedas
theground-truth.TheresultsplottedarefortheaverageMSE
takenoveralldimensionsofthemeanandmarginalvarianceof
ğœ‹(ğœ½).
and SGLD-CV are not as accurate as SGHMC and SGHMC-CV when
ğ‘‘ = 500, but display similar levels of accuracy for ğ‘‘ = 100 and ğ‘‘ = 200.
ThemixingoftheSGLD-basedsamplerscouldbeimprovedbyhand-tuning
the step-size parameter ğ›¿, or preconditioning the gradients to account for
thecorrelationstructureoftheposteriordistribution.
Beyond posterior accuracy, we can also assess the predictive accuracy
of SGMCMC algorithms against exact full-data MCMC algorithms, in
this case using the NUTS sampler. Figure 3.6 illustrates that SGMCMC
algorithms are competitive against slower Metropolisâ€“Hastings-based al-
gorithms when assessed against predictive accuracy. Figure 3.6 plots the
percentageimprovementinlog-posteriorpredictiveaccuracyforeachSGM-
CMC algorithm over the log-posterior predictive accuracy of the NUTS
sampler, which is treated as the gold standard approach. The results are
given for the logistic regression model on a test dataset using posterior
samplesoverarangeofparameterdimensionsğ‘‘.Theresultshighlightthat
SGMCMC algorithms are competitive and potentially superior to slower,
full-data, MCMC algorithms in terms of predictive accuracy, displaying
only a small decrease in efficiency but with a significant computational
advantage.
 ( 6 0  ( 6 096 StochasticGradientMCMCAlgorithms
SGLD SGLD
0.0 1.2
0.1
1.0
0.2
0.8
0.3
0.4
0.6
0.5
0 5000 10000 0 5000 10000
Iterations Iterations
SGLD-CV SGLD-CV
0.2 1.2
0.0
1.0
0.2 0.8
0.4
0.6
0.6
0 5000 10000 0 5000 10000
Iterations Iterations
SGHMC SGHMC
0.0
1.2
0.2 1.0
0.4 0.8
0.6
0.6
0 5000 10000 0 5000 10000
Iterations Iterations
SGHMC-CV SGHMC-CV
0.2 1.4
0.0 1.2
0.2 1.0
0.4 0.8
0.6
0.6
0 5000 10000 0 5000 10000
Iterations Iterations
NUTS NUTS
1.4
0.0
1.2
0.2
1.0
0.4 0.8
0.6 0.6
0 2000 4000 0 2000 4000
Iterations Iterations
Figure3.5 Traceplotsforthefirsttwocomponentsofğœ½ with
ğ‘‘ =500.
Î¸
Î¸
Î¸
Î¸
Î¸
1
1
1
1
1
Î¸
Î¸
Î¸
Î¸
Î¸
2
2
2
2
23.5 GuidanceforEfficientScalableBayesianLearning 97
SGLD
3
SGLD-CV
SGHMC
2
SGHMC-CV
1
0
1
2
3
4
100 200 300 400 500
Dimension
Figure3.6 Percentageimprovementinthelog-predictivedensity
ofeachSGMCMCalgorithmrelativetothelogpredictivedensity
oftheNUTSsampleronthelogisticregressionmodelcalculated
onatestdataset.Thedimensionoftheparameterofinterestis
ğ‘‘ âˆˆ {100,200,300,400,500}.
3.5.2 ExperimentsonaBayesianNeuralNetworkModel
A Bayesian neural network model for multi-class classification was intro-
duced in Section 1.2.3, where the dataset D = {ğ‘¦ ğ‘—,xğ‘—}ğ‘ ğ‘—=1is comprised of
a collection of ğº classes ğ‘¦ ğ‘— âˆˆ {1,...,ğº} and covariates xğ‘— âˆˆ Rğ‘‘ ğ‘¥. The
unnormalisedposteriordensityis
ğ‘
(cid:214)
ğœ‹(ğœ½) := ğœ‹(ğœ½|D) âˆ ğœ‹ 0(ğœ½) exp(AâŠ¤ ğ‘¦ ğ‘—+1ğœ(BâŠ¤xğ‘— +b)+ğ‘ ğ‘¦ ğ‘—+1), (3.28)
ğ‘—=1
where ğœ(Â·) isasoftmaxactivationfunction(seeSectionSection1.2.3for
details).Themodelparametersğœ½ =vec(A,B,a,b)aretheweightsA,Band
biases a,b of the network model. We shall assume independent standard
Gaussianpriorsforeachparameter,i.e.ğœ½ âˆ¼N(0,I).
Neural networks are commonly used for image classification tasks.
One of the most fundamental and widely used datasets in image clas-
sification is the MNIST handwritten digit dataset. The MNIST dataset
consists of images of handwritten digits, ranging from zero to nine, i.e.
tnemevorpmi
egatnecrep
evitciderp-goL98 StochasticGradientMCMCAlgorithms
Figure3.7 AselectionofdigitsfromtheMNISTdataset.Image
source-Wikipedia.
ğ‘¦ ğ‘— âˆˆ {0,1,2,3,4,5,6,7,8,9} (see Figure 3.7 for a subsample of the
dataset). Each image is represented by a small square of 28 pixels by
28pixelswhicharetreatedascovariates.Eachxğ‘— âˆˆ R784 isavectorisation
ofamatrixmadeupof28rowsand28columns,witheachpixelcontaining
grayscale information representing the darkness of that specific point in
theimage.Abrighterpixelwouldhaveahighervalue,whileadarkerone
wouldhavealowervalue.
TheBayesianneuralnetworkforthisexample(3.28)hastwolayers:an
inputlayerthatreceivestheinformationfromthe28Ã—28image,andahidden
layer containing 100 hidden variables that act as intermediate processing
units.Theparametersoftheneuralnetworkğœ½ areoftheformA âˆˆ R10Ã—100,
B âˆˆ R784Ã—100,a âˆˆ R1Ã—10,andb âˆˆ R1Ã—100.
The MNIST dataset contains a large collection of 60000 images in the
trainingset.Eachimagehasacorrespondinglabel,indicatingwhichdigit
(0 âˆ’ 9) it represents. Using SGMCMC algorithms, we can approximate
the posterior distribution of the Bayesian neural network using subsam-
ples of the labelled images and pixel values to train the Bayesian neural
networktorecognisepatternsandrelationshipsbetweenthepixelsandthe
correspondingdigits.
We use the SGLD and SGHMC algorithms from the Python package
SGMCMCJax(CoullonandNemeth,2022),andtheircontrol-variatecoun-
terparts,todrawsamplesfromtheBayesianneuralnetworkposterior(3.28).
Weruneachalgorithmfor2000iterationsandretainevery10thiterationof
theMarkovchain.Asubsamplesizeof1%ofthefulldatasetisusedforall3.5 GuidanceforEfficientScalableBayesianLearning 99
0.9
0.8
0.7
0.6
SGLD
0.5 SGLD-CV
SGHMC
SGHMC-CV
0.4
0 50 100 150 200
Number of Iterations
Figure3.8 Averageposteriorpredictiveaccuracyoverallclasses
foreachoftheSGMCMCsamplers.
SGMCMC samplers. For the control-variate-based algorithms, a stochas-
tic gradient descent algorithm is used to find the posterior mode and the
Markovchainisinitialisedattheposteriormode.
There is a separate set of 10000 unseen images, also with correspond-
ing labels but hidden from the training process. This test set allows us to
evaluate how well our neural network performs on new data. By feeding
these new images into the network, we can see if the posterior network is
able to accurately classify the images into one of the ten-digit categories
(0-9). Figure 3.8 shows the posterior predictive accuracy for each SGM-
CMC sampler over the number of Monte Carlo iterations (storing every
10thposteriorsample).Theresultsshowthatallofthesamplersconverge
toapproximately93%accuracyinclassifyingtheMNISTtestsetdigits.The
SGLD and SGHMC samplers converge at a similar rate (in terms of pre-
dictiveaccuracy).Thecontrolvariate-basedSGLDandSGHMCsamplers
also converge at a similar rate to each other but achieve higher predictive
accuracywithfewerMonteCarloiterationsasthesesamplersareinitialised
attheposteriormodeandthusremovetheburn-inphaseoftheMonteCarlo
sampler.
ycarucca
evitciderP100 StochasticGradientMCMCAlgorithms
3.6 GeneralisationsandExtensions
TheSGMCMCframeworkoutlinedinSection3.4canbeextendedbeyond
the SGLD algorithm to improve Markov chain mixing. However, two key
assumptionslimittheapplicabilityofcurrentSGMCMCalgorithms:(i)the
parametersğœ½ âˆˆ Rğ‘‘existinanunconstrainedspace,and(ii)thelog-posterior
densitylogğœ‹(ğœ½) isasumoverconditionallyindependentterms.
Assumption(i)precludesestimating ğœ½ onaconstrainedspace(e.g. ğœ½ âˆˆ
[0,1]ğ‘‘). Assumption (ii) requires data y 1,...,yğ‘ to be independent or
have limited dependence, restricting the applicability of SGMCMC for
timeseriesorspatialmodels.
OngoingresearchaimstorelaxtheseassumptionsandexpandSGMCMC
tobroadermodelclasses.Somepromisingdirectionsinclude:
â€¢ Transformationtechniquestoenablesamplingonconstrainedparameter
spaces(Brosseetal.,2017;Bubecketal.,2018;Hsiehetal.,2018).
â€¢ Exploitingshort-rangedependenciesandothermodelstructurestoallow
subsamplingfortimeseriesandnetworkdata(Lietal.,2016;Maetal.,
2017;Aicheretal.,2023).
â€¢ Leveragingalternativestochasticprocesseswithdesiredinvariantdistri-
butionsassamplersformodelswithcomplexdataandparameterstruc-
tures(Bakeretal.,2018).
Bydevelopingspecialisedsubsamplingschemesandtransformations,it
ispossibletomakeSGMCMCalgorithmsmoreapplicabletoawiderrange
ofBayesianmodelswhileretainingcomputationalefficiency.
3.6.1 ScalableInferenceforModelsinConstrainedSpaces
Manystatisticalmodelscontainparameterswithinherentconstraints,such
as the variance parameter ğœ2 in a Gaussian distribution (ğœ âˆˆ R+) or the
success probability ğ‘ in a Bernoulli model (ğ‘ âˆˆ [0,1]). Simulating these
constrainedparametersusingstandardLangevindynamics(3.2)willoften
producesamplesviolatingtheconstraints.Forinstance,ifatiteration ğ‘˜ of
theSGLDalgorithmğœ½ğ‘˜ = ğœ ğ‘˜2isclosetozero,thenwithhighprobability,the
nextiterateğœ½ğ‘˜+1 islikelytobenegative,breakingthepositivityconstraint.
One solution is to shrink the step size ğ›¿ â†’ 0 as ğœ2 â†’ 0, but this leads to
poormixingneartheboundary.
A natural approach is to transform the Langevin dynamics so sampling
occursinanunconstrainedspace,butthechoiceoftransformationgreatly3.6 GeneralisationsandExtensions 101
impacts mixing near the boundary. Alternatively, we can project the dy-
namicsintotheconstrainedspace,however,thisyieldspoorerconvergence
compared to the unconstrained setting. The mirrored Langevin algorithm
(Hsiehetal.,2018)wasproposedtoaddressthisissue.Itbuildsonthemir-
rored descent algorithm (Beck and Teboulle, 2003) from the optimisation
literaturetotransformconstrainedsamplingintoanunconstrainedproblem
usingamirrormap.Comparedtoagenericmappingfunction,mirrormaps
haveadditionalproperties,suchasstrictconvexity,differentiabilityanddi-
verginggradientsattheboundaryofthedomain,whichmakesmirrormap
algorithmswell-suitedtoconstrainedsamplingandoptimisationproblems.
Ifweassumethatğœ‹(ğœ½)isthedensityofaconstraineddistribution,namely
thatlogğœ‹(ğœ½)hasaboundedconvexdomain,thenassumingthatthereexists
a mirror map ğœ“(Â·) which is closed and proper, we can map the variable
ğœ½ âˆ¼ ğœ‹ from the constrained space (primal space) to the unconstrained
space (dual space), where ğ‘ := âˆ‡ğœ“(ğœ½) and ğ‘ âˆ¼ ğœˆ. Under the assumption
that ğœ“ is a convex function that is closed, proper, and twice continuously
differentiable, with Fenchel dual noted as ğœ“âˆ—, then Theorem 1 of Hsieh
etal.(2018)showsthatâˆ‡ğœ“âˆ—(ğ‘) âˆ¼ ğœ‹.Thisresultimpliesthatitispossible
to transform the problem of sampling from a constrained distribution ğœ‹
to the simpler problem of sampling from an unconstrained distribution ğœˆ.
Usingthealgorithmshighlightedinthischapter,wecansimulateaMarkov
chain ğ‘ âˆ¼ ğœˆ and apply the mapping âˆ‡ğœ“âˆ—(ğ‘) to produce samples from the
desiredposteriordistributionğœ‹.InthecaseoftheLangevinsampler,thisis
achievedbymodifyingtheoriginalLangevindiffusion(3.1)toamirrored
Langevindiffusion,
1
dğ‘ = (âˆ‡logğœˆâ—¦âˆ‡ğœ“)(ğœ½)dğ‘¡+dğ‘Š ğ‘¡ (3.29)
2
ğœ½ = âˆ‡ğœ“âˆ—(ğ‘). (3.30)
Inpractice,asnotedearlierinthischapter,itisnotpossibletosimulateex-
actlyfromthemirrorLangevindiffusion.UsingthesameEulerâ€“Maruyama
discretisationschemeitispossibletocreateapracticaldiscrete-timealgo-
rithm.StochasticgradientimplementationsofthemirrorLangevindynam-
icsareeasilyderivedinthedualspaceandfollowdirectlyfromtheSGLD
algorithm.
One popular model that requires sampling from a constrained domain
is the latent Dirichlet allocation (LDA) model (Blei et al., 2003) which is
used for topic modelling. Here, the model parameters are constrained to
the probability simplex, i.e. ğœƒ ğ‘– â‰¥ 0,ğ‘– = 1,...,ğ‘‘ and (cid:205) ğ‘–ğ‘‘ =1ğœƒ ğ‘– = 1. Mir-
roredLangevindynamics(3.29)canbeusedtosimulatefromthesimplex102 StochasticGradientMCMCAlgorithms
distribution by mapping the parameters to Rğ‘‘ and running the Langevin
dynamicsalgorithmontheunconstrainedspace.Theentropicmirrormap
(Beck and Teboulle, 2003) satisfies the required assumptions for a valid
mapfunctionunderthemirroredLangevindynamics,
ğ‘‘ (cid:32) ğ‘‘ (cid:33) (cid:32) ğ‘‘ (cid:33)
âˆ‘ï¸ âˆ‘ï¸ âˆ‘ï¸
ğœ“(ğœ½) = ğœƒ ğ‘–logğœƒ ğ‘– + 1âˆ’ ğœƒ ğ‘– log 1âˆ’ ğœƒ ğ‘– , (3.31)
ğ‘–=1 ğ‘–=1 ğ‘–=1
where0log0:=0.Thetransformedlog-posteriordensityisthengivenby
ğ‘‘
âˆ‘ï¸
logğœˆ(ğ‘) =logğœ‹(ğœ½)â—¦âˆ‡ğœ“âˆ—(ğ‘)âˆ’ ğœ— ğ‘– +(ğ‘‘+1)ğœ“âˆ—(ğ‘), (3.32)
ğ‘–=1
where ğœ“âˆ—(ğ‘) = log(1+(cid:205) ğ‘–ğ‘‘ =1exp(ğœ— ğ‘–)) is the Fenchal dual of ğœ“(Â·) and is
strictly convex with Lipschitz gradients. Aside from transforming a con-
strainedsamplingproblemintoanunconstrainedsamplingproblem,mirror
mapscanalsoleadtosimplerposteriordistributionsinthedualspace.For
example, the Dirichlet posterior distribution introduced above, leads to a
posteriordistributiononthedualspace(3.32)whichisstrictlylog-concave.
Insteadofusingmirrormapstosamplefromtheposteriordistributionof
the LDA model, we could instead use the stochastic gradient Riemannian
Langevin dynamics algorithm (see Section 3.4). Under the SGRLD algo-
rithm, the constrained parameters ğœ½ can be transformed to Rğ‘‘ via several
alternative reparameterisations (see Patterson and Teh (2013) for a list).
However, this can induce asymptotic biases dominating the boundary re-
gions. An alternative approach is to recognise that the LDA posterior can
beexpressedasatransformationofindependentgammarandomvariables.
Therefore, rather than simulating from the simplex distribution via the
Langevindiffusion,onecouldinsteadutilisetheCoxâ€“Ingersollâ€“Ross(CIR)
process (Cox et al., 1985), which is invariant with respect to the gamma
distribution. This CIR-based approach (Baker et al., 2018) avoids bound-
ary biases. More broadly, leveraging alternative stochastic processes with
desired invariant distributions can enable specialised samplers for models
withcomplexstructures.
3.6.2 ScalableInferencewithTimeSeriesData
A key requirement for developing stochastic gradient algorithms is the
abilitytogenerateunbiasedestimatesofâˆ‡logğœ‹(ğœ½)usingdatasubsampling,
as in (3.6). This is straightforward when the log-posterior density, and
its gradient, are expressed as a sum of logğœ‹ ğ‘–(ğœ½) and âˆ‡logğœ‹ ğ‘–(ğœ½) terms,3.6 GeneralisationsandExtensions 103
respectively, i.e. logğœ‹(ğœ½) = (cid:205) ğ‘–ğ‘ =1logğœ‹ ğ‘–(ğœ½). Randomly subsampling these
termsprovidesanunbiasedlog-densityandgradientestimate.
However, for models where data are not conditionally independent, for
example,networkdata,timeseries,orspatialdata,thelog-posteriordensity
cannotbeexpressedasasimplesum.Naivelysubsamplingwillyieldbiased
estimatesoflogğœ‹(ğœ½)andâˆ‡logğœ‹(ğœ½).Capturingbothshort-andlong-range
dependencies in spatial data with subsampling remains an open challenge
forSGMCMC.Fornetworkdata,Lietal.(2016)developedanSGMCMC
algorithm for the mixed-membership stochastic block model using block
structureandstratifiedsubsamplingtoobtainunbiasedgradientestimates.
RecentworkinSGMCMCfortemporallycorrelateddatahasfocusedon
hiddenMarkovmodels(Maetal.,2017)withfinitestates,lineardynamical
systems(Aicheretal.,2019)andgeneralnonlinearhiddenMarkovmodels
(Aicheretal.,2023).Underthismodellingframework,thehiddenMarkov
modelconsistsoftwostochasticprocesses:i)alatentstateprocess{Xğ‘¡}ğ‘‡ ğ‘¡=0,
whichisaMarkovchainthatevolvesovertimeğ‘¡ =1,...,ğ‘‡,withXğ‘¡depend-
ingonlyonXğ‘¡âˆ’1 andğœ½,withtransitiondensitygivenby ğ‘(xğ‘¡|xğ‘¡âˆ’1,ğœ½);and
ii)anobservedprocess{Yğ‘¡}ğ‘‡
ğ‘¡=0
thatisconditionallyindependentgiventhe
latentstatesandğœ½,whichareobservedwithprobabilitydensityğ‘(yğ‘¡|xğ‘¡,ğœ½).
Assumingmodelparametersğœ½,thefullgenerativemodel(Figure3.9)is
Xğ‘¡|(Xğ‘¡âˆ’1 =xğ‘¡âˆ’1,ğœ½) âˆ¼ ğ‘(xğ‘¡|xğ‘¡âˆ’1,ğœ½) (3.33)
Yğ‘¡|(Xğ‘¡ =xğ‘¡,ğœ½) âˆ¼ ğ‘(yğ‘¡|xğ‘¡,ğœ½). (3.34)
The latent Markov chain Xğ‘¡ captures the dynamics and temporal depen-
dence, while the observations Yğ‘¡ depend only on the current state of the
latent process. Hidden Markov models are useful for modelling complex
time series data byaugmenting the observables with latent states. Itis of-
tencommontodistinguishbetweenhiddenMarkovmodelsandstate-space
models,whereinthecaseoftheformerthelatentprocessXğ‘¡ isdiscreteand
iscontinuousinthecaseofthelatter.However,forthesakeofconvenience,
weshallusethetermhiddenMarkovmodeltocoverbothmodeltypes.
UsingSGMCMCmethods,itispossibletoestimatethemodelparameters
ğœ½ for general hidden Markov models which exhibit temporal dependency
in the observations. As before, the goal is to sample from the posterior
distribution ğœ‹(ğœ½) := ğ‘(ğœ½|y) where y = {y 1,...,yğ‘‡} is the observed data
sequence, which is proportional to the product of the likelihood ğ‘(y|ğœ½)
and the prior ğœ‹ (ğœ½). The likelihood ğ‘(y|ğœ½) typically cannot be evaluated
0
exactly,asitrequiressumming(discretesetting)orintegrating(continuous
setting)overthelatentstatesX.Focusingonthecontinuousvariablesetting,104 StochasticGradientMCMCAlgorithms
X
0
Xğ‘¡âˆ’2 Xğ‘¡âˆ’1 Xğ‘¡ Xğ‘¡+1 Xğ‘¡+2 Xğ‘‡
y
0
yğ‘¡âˆ’2 yğ‘¡âˆ’1 yğ‘¡ yğ‘¡+1 yğ‘¡+2 yğ‘‡
S Sâˆ—
Figure3.9 GraphicalrepresentationofthehiddenMarkovmodel
withlatentvariablesXğ‘– andobservationsyğ‘–.Thesubsequenceis
capturedinthesolidboxSandthebufferregionishighlightedby
thedottedboxSâˆ—.
the latent states can be integrated out numerically using particle filtering
techniques(Doucetetal.,2009).UsingaparticleapproximationofFisherâ€™s
identity(Nemethetal.,2016),
âˆ‡ ğœ½logğœ‹(ğœ½) = âˆ‡ ğœ½logğ‘(y 1:ğ‘‡|ğœ½) =E X|Y,ğœ½ [âˆ‡ ğœ½logğ‘(X 1:ğ‘‡,y 1:ğ‘‡|ğœ½)] (3.35)
ğ‘‡
âˆ‘ï¸
= E
X|Y,ğœ½
[âˆ‡ ğœ½logğ‘(Xğ‘¡,yğ‘¡|xğ‘¡âˆ’1,ğœ½)]
ğ‘¡=1
it is possible to unbiasedly approximate âˆ‡ logğœ‹(ğœ½) by replacing the pos-
ğœ½
terior distribution of the latent states ğ‘(x 1:ğ‘‡|y 1:ğ‘‡,ğœ½) with a numerical ap-
proximationrepresentedbyasetofğ‘ƒparticles{X(ğ‘)}ğ‘ƒ
.
1:ğ‘‡ ğ‘=1
CalculatingFisherâ€™sidentitycanbecomputationallyexpensiveforlarge
ğ‘‡ andsoanSGMCMCapproximationtoFisherâ€™sidentitycanbeusedtore-
placethefulldatagradient(3.35)withastochasticapproximationestimated
from a random subset of the data. This allows each gradient evaluation to
be cheaper, enabling more MCMC iterations and better convergence for
large ğ‘‡. However, naively subsampling the data randomly (3.6) induces
bias since it breaks temporal dependencies. To address this issue, Aicher
etal.(2019,2023)proposetosubsamplecontiguoussubsequences.Figure
3.9providesagraphicalrepresentationofthehiddenMarkovmodelwhich
alsohighlightsthesubsampleddataasacontiguoussubsequenceS ofsize
ğ‘š.ThestochasticgradientfollowingFisherâ€™sidentity(3.35)isthen
âˆ‡ ğœ½(ğ‘š)logğ‘(y 1:ğ‘‡|ğœ½) =âˆ‘ï¸ Pr(ğ‘¡ âˆˆ S)âˆ’1Â·E
X|ySâˆ—,ğœ½
[âˆ‡ ğœ½logğ‘(Xğ‘¡,yğ‘¡|xğ‘¡âˆ’1,ğœ½)].
ğ‘¡âˆˆS
(3.36)
However, the stochastic gradient estimator (3.36) is biased because the
expectation is taken over the latent state which is dependent only on y
S3.7 ChapterNotes 105
and not y 1:ğ‘‡. This bias can be reduced by extending the subsequence S
to include a buffered region Sâˆ—. The expectation in (3.35) is then taken
overthewiderbufferedrange ğ‘(xğ‘¡|y Sâˆ—,ğœ½) ratherthan ğ‘(xğ‘¡|y S,ğœ½).Results
from Aicher et al. (2019) show that under Lipschitz assumptions on the
model(3.33),anditsgradients,theerrorinthestochasticgradientsdecays
geometricallywiththebuffersize |Sâˆ—|.
3.7 ChapterNotes
MarkovchainMonteCarloalgorithmshavebeenthecornerstoneofBayesian
inferencesincethe1990s.However,asthesizeofdatasetshasgrown,the
requirement that each MCMC update uses all of the data to approximate
theposteriordistributionhascreatedacomputationalchallenge.Therehas
beensignificantrecentinterestintheStatisticsandMachineLearningcom-
munitiestocreatenewMonteCarlo-basedalgorithmsforscalableBayesian
inferenceinthepresenceoflargedatasets(Bardenetetal.,2014).Broadly
speaking,scalableMCMCalgorithmstendtofallintotwocategorieswhich
either (i) subsample the data (Welling and Teh, 2011; Chen et al., 2014;
NemethandFearnhead,2021),ascoveredinthischapter,or(ii)useparallel
computingtodistributethecomputationalcostacrossmultipleCPUs(Scott
etal.,2016;NemethandSherlock,2018;Vyneretal.,2023).
In the context of data subsampling, the per iteration cost of the Monte
Carloalgorithmisreduced.However,thisreductionincomputationalcostis
onlybeneficialifthesubsamplingschemeleadstoposteriorapproximations
with high statistical accuracy. Chatterji et al. (2018) gives results on the
numberofiterations,andresultingcomputationalcost,requiredfordifferent
stochasticgradientalgorithmstoproducesamplesfromadistributionwhich
iswithinaspecifiedâ€œdistanceâ€of ğœ‹.Otherworks(Bierkensetal.,2019b;
HugginsandZou,2017;Pollocketal.,2020)havestudiedthecomputational
andstatisticaltrade-offsthatresultfromapproximateandscalableMCMC
schemes,whichareoftenreferredtoasexact-approximatealgorithms.Itis
oftenthecasewithscalableMCMCalgorithmsthatthereisnofreelunch
and simple naive subsampling alone does not lead to statistically efficient
algorithms,seeforexampleJohndrowetal.(2020).Inthecaseofcontrol-
variatesforsubsampling,anumberoftheoreticalresults(e.g.Nagapetyan
etal.,2017;Bakeretal.,2019;Brosseetal.,2018)showthatifweignore
the pre-processing cost of finding (cid:98)ğœ½, the computational cost per-effective
sample of SGLD with control variates isğ‘‚(1), rather than theğ‘‚(ğ‘) cost
forSGLDwiththesimplegradientestimator(3.6).4
Non-Reversible MCMC
AreversibleMarkovchainisanyMarkovchainthatsatisfiesdetailedbal-
ance;seeSection1.3.Remember,thisconditionstatesthat,atstationarity,
theprobabilityofthechainstartinginasetB andmovingtosetC isequal
totheprobabilityofitstartinginthesetCandmovingtoB.Thismeansthat
thedynamicsoftheprocessarethesamebackwardsintimeasforwardsin
time.OneconsequenceofreversibilityisthattheMarkovchaincanexhibit
random-walkbehaviour,whereitcanreturntostatesorregionsofthestate
spacewhereithasrecentlybeen.
Anon-reversibleMarkovchainisanyMarkovchainthatdoesnotsatisfy
detailed balance. As we will see, the potential benefit of non-reversibility
isthattheMarkovchaincanmorequicklyexplorethestatespaceasitcan
suppress the random walk behaviour. However, designing non-reversible
Markovchainswiththerequiredstationarydistribution,orevendetermining
thestationarydistributionofanon-reversibleMarkovchain,ismuchmore
challenging than for a reversible chain. This chapter will describe one
approachtodesigningnon-reversibleMCMCsamplersbasedontheideaof
liftingâ€“whichinvolvestakingareversibleMCMCschemeandthenlifting
it to a higher-dimensional state-space to enable the use of non-reversible
moves. These ideas naturally motivate the non-reversible continuous-time
MCMCsamplersofChapter5.
4.1 TheBenefitsofNon-Reversibility
To see the benefits of non-reversible Markov chains, we will consider the
followingsimpleexample.
Example4.1 Let ğ‘‹ =0and
0
ğ‘‹
ğ‘˜
= (ğ‘‹ ğ‘˜âˆ’1+ğ½ ğ‘˜)(modğ‘†),
sothatğ‘‹ ğ‘˜followsarandomwalkon{0,...,ğ‘†âˆ’1}.Hereğ½ ğ‘˜isthejumpsize,
1064.1 TheBenefitsofNon-Reversibility 107
whichcanhaveanydistributionon{âˆ’â„,...,â„}thatissymmetricabout0,
and (modğ‘†) meanswetaketheremainderafterdividingbyğ‘†.Weinclude
(modğ‘†),soarandomwalkthatmovestonegativevalues,orvaluesequal
to or above ğ‘†, gets mapped back to {0,...,ğ‘† âˆ’1}, with ğ‘† mapping to 0
andâˆ’1toğ‘†âˆ’1andsoon.Forsimplicity,weconsiderğ½ ğ‘˜ tohaveauniform
distribution on {âˆ’â„,âˆ’â„+1,...,â„}. It is straightforward to show that the
resulting Markov chain is reversible and has the uniform distribution on
{0,...,ğ‘†âˆ’1}asitsstationarydistribution.
First,considerâ„ =1andlookatthebehaviourofthechainasweincrease
ğ‘†.InthetoprowofFigure4.1,weshowtraceplotsofthechainforğ‘† =100,
ğ‘† = 200 and ğ‘† = 400. In each case, we show the path of the chain over
40ğ‘† iterations. What we observe is that as ğ‘† increases the chain becomes
muchsloweratexploringthestate-space.Wecanseethismoreclearlyifwe
look at the empirical marginal distribution of the chain after ğ‘› time steps.
Let ğ‘ be a chosen burn-in period, then for ğ‘› > ğ‘ the empirical marginal
distribution,whichisournaturalestimatorofthestationarydistributionof
thechain,is
ğ‘›
1 âˆ‘ï¸
(cid:98)ğœ‹ ğ‘›(ğ‘–) = ğ‘›âˆ’ğ‘ I{ğ‘‹ ğ‘˜ =ğ‘–}. (4.1)
ğ‘˜=ğ‘+1
Thisisjusttheproportionoftime,afterburn-in,thatthechainwasinstate
ğ‘–.Wecanthencomparethisestimatewiththetruestationarydistribution,
by calculating the total variation distance between the two. This is just
(cid:205) ğ‘–ğ‘† =âˆ’ 01| (cid:98)ğœ‹ ğ‘›(ğ‘–) âˆ’1/ğ‘†|, and is shown in the top-row of Figure 4.2, where we
showthetotalvariationdistanceagainstğ‘›/ğ‘†andagainstğ‘›/ğ‘†2 forğ‘† =100,
ğ‘† = 200andğ‘† = 400.Weseeevidencethat,asweincrease ğ‘†,thetimewe
needtorunourMarkovchainmustincreaseproportionallywithğ‘†2tohave
thesamedegreeofaccuracy.
It is interesting to compare this with the performance of the following
non-reversible Markov chain, which we construct by making the random
walk biased; i.e., choosing a jump distribution ğ½ ğ‘˜ whose expectation is
non-zero.
Example4.2 InExample4.1,keepğ½ ğ‘˜ takingvaluesin{âˆ’1,0,1},butset
thejumpprobabilitiestobe {2/9,1/3,4/9} respectivelysothatapositive
jumpistwiceaslikelyasanegativeone.
WeshowtheresultingtraceplotsoftheMarkovchaininthebottomrow
ofFigure4.1.Qualitativelythetraceplotslookverydifferenttothoseinthe
toprow,asthepathstendtomoveupwardsateachiteration.Thisislinked108 Non-ReversibleMCMC
Figure4.1 TraceplotsoftwoMCMCalgorithmsforsampling
fromauniformdistributionon{0,...,ğ‘†âˆ’1}fordifferentvalues
ofğ‘†.Arandomwalkofstepsizeuniformon{âˆ’1,0,1}(Example
4.1,top),andanon-reversible(biased)randomwalkwhichis
twiceaslikelytohaveastepof1thanastepof-1(Example4.2,
bottom).Columnsareforğ‘† =100(left),ğ‘† =200(middle)and
ğ‘† =400(right).WeshowthestateoftheMCMCalgorithmfor
40ğ‘†iterations(toprow)or4ğ‘†iterations(bottomrow).Forthis
scalingofiterations,weseethereversibleMCMCalgorithm
mixesmoreslowlyasğ‘†increases,whereasqualitativelythe
mixingofthenon-reversiblealgorithmremainssimilar.
to the non-reversibility of the chain, as a realisation of the chain forward
intimewillnowlookverydifferentfromarealisationbackwardsintime.
Furthermore,therealisationsfordifferent ğ‘† looksimilar.Thatis,oncewe
scale the number of iterations by ğ‘†, chains with different ğ‘† mix similarly.
This is shown quantitatively in the bottom left plot of Figure 4.2, where
we plot the total variation distance of the empirical marginal distribution
ofourchain(4.1)fromtheuniformdistribution,againstğ‘›/ğ‘†:thisisalmost
identicalforthethreevaluesofğ‘†.
Why does the non-reversible chain have better mixing properties? In-
tuitively, the poor performance of the reversible chain is because it has
random-walk behaviour: it will often move up on one iteration and then
movedownonthenext.Thenon-reversiblechainsuppressesthisrandom-4.2 HamiltonianMonteCarloRevisited 109
walk behaviour as its bias means it will tend to move in the same direc-
tion.Thequalitativedifferencebetweenthesereversibleandnon-reversible
chains that we have demonstrated empirically, can be shown theoretically
(Diaconisetal.,2000).
For a simple heuristic of this behaviour, consider ğ‘‹ = âŒŠğ‘†/2âŒ‹ and ğ‘› â‰¤
0
âŒŠğ‘†/2âŒ‹.Forthesymmetricrandomwalk,E[ğ‘‹ ğ‘›âˆ’ğ‘‹ 0] =0and,sincethetotal
movementbyiterationğ‘›isasumofğ‘›independentmoves,Var[ğ‘‹ ğ‘›âˆ’ğ‘‹ 0] âˆ
ğ‘›,sothetypicalamountofmovementinthefirstğ‘›iterationsisproportional
âˆš
to ğ‘›. However, for the biased random walk, E[ğ‘‹ ğ‘›âˆ’ğ‘‹ 0] âˆ ğ‘› and so the
amountofmovementisroughlyproportionaltoğ‘›.
Importantly, when we measured the performance of the non-reversible
Markov chain we looked at the accuracy of (4.1), which is the proportion
oftimeitspendsineachstateaveragedovertime.If,instead,welookatthe
convergence of P(ğ‘‹ ğ‘› =ğ‘–) to 1/ğ‘†, we would obtain a very different result
tothatshowninFigure4.2,asthebiasoftherandomwalkinExample4.2
meansthatthecentreofthedistributionofğ‘‹ ğ‘›changeswithğ‘›:thebenefitof
thenon-reversiblechainisonlyrealisedaswetaketheergodicaverageover
different time-points. This is most easily seen for the extreme case where
ğ½ ğ‘˜ = 1 with probability 1. In that case, we find that the distribution of ğ‘‹ ğ‘›
isapointmassatasinglevalueforeachğ‘›,butbyaveragingovertimewe
stillhavethat(4.1)convergestotheuniformdistributionatarateof1/ğ‘›.
Finally,asanaside,weobservethatthepoorperformanceofthereversible
chain is also linked to the fact that the size of the moves at each iteration
is small â€“ this can be quantified in terms of the variance of ğ‘‹ ğ‘˜ âˆ’ ğ‘‹ ğ‘˜âˆ’1
relativetothevarianceofthestationarydistribution.Anditisthefactthat
this ratio increased as we increased ğ‘† that meant that the reversible chain
performedrelativelypoorlyforlarger ğ‘†.Toseethiswecanimplementthe
reversiblerandomwalk,butsetthemaximumstepsize â„ = ğ‘†/100soitis
proportionaltoğ‘†.Thetotalvariationdistancebetween(4.1)andtheuniform
distributionforsuchachainisshowninthebottomrightplotofFigure4.2,
anddemonstratesbetterscalingwithğ‘†:infact,likethenon-reversiblechain,
asğ‘†increaseswenowobtainthesameaccuracyprovidingwescaleğ‘›tobe
proportionaltoğ‘†.
4.2 HamiltonianMonteCarloRevisited
TheHamiltonianMonteCarlo,orHMC,algorithmofSection2.2isoften
viewed as a non-reversible MCMC algorithm. However, strictly it is a
reversiblealgorithm.
Remember that the HMC algorithm for sampling from a density ğœ‹(ğœ½),110 Non-ReversibleMCMC
       
S=400 S=400
S=200 S=200
    S=100     S=100
       
       
       
                             
Iterations/S Iterations/S2
       
S=400 S=400
S=200 S=200
    S=100     S=100
       
       
       
                           
Iterations/S Iterations/S
Figure4.2 Empiricaltotalvariationdistance(TVD)between
(4.1)andtheuniformdistributionagainstthenumberofiterations
anddifferentvaluesofğ‘†:ğ‘† =100(blue),ğ‘† =200(red)and
ğ‘† =400(black).TVDfortherandomwalkofExample4.1with
stepsize1(toprow)withğ‘¥-axisscaledbyğ‘†(topleft)orğ‘†2(top
right).TVDforthenon-reversibleExample4.2(bottomleft),and
fortheExample4.1withstepsizescaledbyğ‘†(bottomright);in
bothcasetheğ‘¥-axisisscaledbyğ‘†.Allresultsareaveragedover
10realisationsofthechains.
involvesaugmentingthestateofourMCMCalgorithmwithamomentum
variableofthesamedimensionasğœ½.Denotethemomentumvariablebyp,
andthestateofourMarkovchainby(ğœ½,p).Inthefollowing,forsimplicity,
we will assume that the mass matrix is the identity. We introduce a target
 ' 9 7
 ' 9 7
 ' 9 7
 ' 9 74.2 HamiltonianMonteCarloRevisited 111
densityfor (ğœ½,p),
(cid:26) (cid:27)
1
ğœ‹Ëœ(ğœ½,p) âˆ ğœ‹(ğœ½)exp âˆ’ pâŠ¤p ,
2
whichhasindependentcomponents,withğœ½ fromğœ‹andphavingastandard
Gaussiandistribution.AnHMCalgorithmwhichhasğœ‹Ëœ(ğœ½,p)asitsstation-
ary density interleaves the following three moves at each iteration. Given
currentstate (ğœ½ğ‘˜,pğ‘˜)
(1) SimulateanewmomentumpfromastandardGaussiandistribution.
(2)(i) Obtaintheproposedstate (ğœ½â€²,pâ€²) byrunningtheleapfrogdynamics,
for some number, ğ¿, of steps with some step length, ğœ–, starting from
(ğœ½ğ‘˜,p),andflipthefinalmomentum.
(ii) Accepttheproposedstate, (ğœ½ğ‘˜+1,pâ€²â€²) = (ğœ½â€²,pâ€²) withprobability
(cid:18) ğœ‹(ğœ½â€²,pâ€²)(cid:19)
min 1, ,
ğœ‹(ğœ½ğ‘˜,p)
otherwise (ğœ½ğ‘˜+1,pâ€²â€²) = (ğœ½ğ‘˜,p).
(3) Flipthemomentum, (ğœ½ğ‘˜+1,pğ‘˜+1) = (ğœ½ğ‘˜,âˆ’pâ€²â€²).
In the notation of Section 2.2, the proposal in step (2i) is denoted by
Leap
âˆ’ğ¿(ğœ½ğ‘˜,p).
Move (2) involves simulating non-reversible Hamiltonian
dynamicstoproduceapotentiallylargeproposedmove,butthemoveitself
is reversible. As, trivially, are moves (1) and (3). The move (3) has no
net effect on the algorithm since the momentum is discarded at the next
iteration, and it is not included in the description in Section 2.2. It does,
however,ensurethat,iftheproposalisaccepted,thefinalmomentumisthe
sameasthatwhichwasobtainedthroughtheleapfrogapproximationtothe
Hamiltoniandynamicsratherthanitsopposite.Thiswillbehelpfulinthe
nextsection.
Interleaving three different reversible moves does not necessarily result
in a reversible Markov chain (see the next section, for example). But in
this case, it is straightforward to show that the marginal process for ğœ½
is a reversible Markov chain. The benefit of HMC is in the use of the
non-reversibledeterministicleap-frogdynamicstoproducelargeproposed
movesthathaveahighchanceofbeingaccepted.Aswesawintheprevious
section,theissueswithreversibleMCMCalgorithmsoccurwhenthestep
size is small â€“ and HMC gets around this by being able to propose large
moves rather than being non-reversible. This fact is seen in the scaling
resultsforHMCasthedimensionofthestate-spaceincreases(seeSection
2.2andtheliteratureinSection2.3).112 Non-ReversibleMCMC
4.3 LiftingSchemesforMCMC
Whilst HMC is a reversible algorithm when viewed as a Markov chain
on ğœ½,someoftheideasbehindtheHamiltoniandynamicsarecommonto
non-reversibleMCMCalgorithms.Furthermore,itispossibletoadaptthe
HMCalgorithmsothatitisnon-reversible.
Mostnon-reversibleMCMCalgorithmsinvolvetheideaofâ€œliftingâ€,that
is,definingtheMarkovchainonahigher-dimensionalstatespacethanyou
wish to sample from. Moreover, they tend to do this in a way similar to
HMC, in that if you wish to sample from some target distribution, ğœ‹(ğœ½),
you work with a Markov chain with state (ğœ½,p), where p is of the same
dimension, ğ‘‘, as ğœ½ and can be interpreted as the momentum or velocity
that is describing the direction and speed with which the Markov chain is
currentlymovingthroughğœ½ space.Thenon-reversibilityofthealgorithmis
basedontryingtoencourageMarkovchainmovesthatcontinueinroughly
thesamedirectionoversuccessiveiterations.
4.3.1 Non-ReversibleHMC
Oneofthefirsttrulynon-reversiblealgorithmsisanextensionofHMCdue
toHorowitz(1991).Theideaistoadapthowthemomentumisrefreshedat
eachiterationsothatthemomentumatthecurrentiterationwillbesimilar
tothatatthepreviousiteration.Thiscanbeachievedbyreplacingstep(1)
oftheHMCalgorithmwiththeupdate
pâ€² = ğ›¾p+(1âˆ’ğ›¾2)1/2ğœ»,
where ğœ» is a realisation of a ğ‘‘-dimensional standard Gaussian random
variable, and 0 < ğ›¾ < 1. If p has a standard Gaussian distribution, then
so does pâ€²: it is Gaussian as it is a linear combination of two independent
Gaussianrandomvariables,theexpectationoftheright-handsideis0,and
thevarianceisğ›¾2Iğ‘‘+(1âˆ’ğ›¾2)Iğ‘‘ =Iğ‘‘.Ifğ›¾iscloseto1thenpâ€²willbeclose
top.TheoverallalgorithmisgiveninAlgorithm4.
This algorithm has the required stationary distribution, as each step
satisfiesdetailedbalancewithrespecttotheextendedposterior,ğœ‹.However,
(cid:101)
whilst each step of the algorithm is a reversible Markov chain move, by
interleavingthemovesweobtainanon-reversiblealgorithm.
WhilstthisalgorithmgeneralisesHMC,inpracticeitisrarelynoticeably
moreefficient(seeforexampleNeal,2011).Thereasonisthemomentum
flipthatoccursifwerejectourproposal,as,ifğ›¾islargethissendsthechain
backinthedirectionfromwhenceitcame.Thusweneedtoeitherchoosethe4.3 LiftingSchemesforMCMC 113
Algorithm4:Non-reversibleHMCofHorowitz(1991)
Input:Densityğœ‹(ğœ½),initialvalueğœ½ andmomentump sampled
0 0
fromN(0,Iğ‘‘),andrefreshrateğ›¾ âˆˆ [0,1).
for ğ‘˜ âˆˆ 0,...,ğ‘›âˆ’1do
Simulateğœ» âˆ¼N(0,Iğ‘‘) andsetpâ€² = ğ›¾pğ‘˜ +(1âˆ’ğ›¾2)1/2ğœ».
(ğœ½â€²,pâ€²â€²) â†Leap âˆ’ğ¿(ğœ½ğ‘˜,pâ€²).
Calculatetheacceptanceprobability:
(cid:18) ğœ‹(ğœ½â€²,pâ€²â€²)(cid:19)
ğ›¼(ğœ½ğ‘˜,pâ€²;ğœ½â€²,pâ€²â€²) :=min 1, (cid:101)
(cid:101)ğœ‹(ğœ½ğ‘˜,pâ€²)
.
Withaprobabilityofğ›¼(ğœ½ğ‘˜,pâ€²;ğœ½â€²,pâ€²â€²) accepttheproposal,
(ğœ½ğ‘˜+1,pâ€²â€²â€²) â† (ğœ½â€²,pâ€²â€²);otherwiserejectit,
(ğœ½ğ‘˜+1,pâ€²â€²â€²) â† (ğœ½ğ‘˜,pğ‘˜).
Flipthevelocity: (ğœ½ğ‘˜+1,pğ‘˜+1) â† (ğœ½ğ‘˜+1,âˆ’pâ€²â€²â€²).
end
leapfrogstepsize,ğœ–,tobesmallenoughthattheprobabilityofacceptance
after ğ¿ stepsisusuallyverycloseto1,orweneedtochooseğ›¾ tobesmall
so that the new momentum is relatively unrelated to the old momentum.
The first comes at a high computational cost while the second leads to
an algorithm that is very similar to standard HMC (which corresponds to
ğ›¾ = 0). Later, in Section 4.4, we will present some alternative ideas that
canalleviatetheproblemsofmomentumflipsinalgorithmssuchasthis.
4.3.2 Gustafsonâ€™sAlgorithmandMultidimensionalGeneralisations
It is possible to use similar ideas to obtain non-reversible versions of a
random walk Metropolisâ€“Hastings algorithm, known as guided random
walks. This was first proposed by Gustafson (1998) for component-wise
updates, though it has a natural extension to multivariate updates which
we will also describe. First, consider the univariate case and a Gaussian
random walk proposal with a variance of ğ›¿2 and ğœ âˆ¼ N(0,ğ›¿2). Given a
currentvalue,ğœƒ,wecanwritethisproposalas
ğœƒâ€² = ğœƒ+ ğ‘|ğœ|,
where ğ‘ is uniformly sampled from {âˆ’1,1}. We can think of ğ‘ as the
directionofthemoveand|ğœ|asthesizeofthemove.TheideaofGustafson
(1998) is to augment the state of the chain with ğ‘ and to simulate a chain114 Non-ReversibleMCMC
suchthatthedirectionofthemoveislikelytobethesameoversuccessive
timesteps.Thiscanbeachievedbyiteratingthefollowingtwosteps
(1) Simulateğœ,arealisationofaGaussianrandomvariable,andset(ğœƒâ€²,ğ‘â€²) =
(ğœƒ ğ‘˜ + ğ‘ ğ‘˜|ğœ|,âˆ’ğ‘ ğ‘˜) withprobability
(cid:26) ğœ‹(ğœƒâ€²)(cid:27)
min 1,
ğœ‹(ğœƒ )
ğ‘˜
otherwiseset (ğœƒâ€²,ğ‘â€²) = (ğœƒ ğ‘˜,ğ‘ ğ‘˜).
(2) Flipthedirection,so (ğœƒ ğ‘˜+1,ğ‘ ğ‘˜+1) = (ğœƒâ€²,âˆ’ğ‘â€²).
Thestationarydistributionofthisalgorithmhasindependentdistributions
for ğœƒ and ğ‘, with ğœƒ from the distribution whose density is proportional to
ğœ‹(ğœƒ),and ğ‘ havingauniformdistributionon{âˆ’1,1}.Thisfollowsasboth
steps(1)and(2)arereversiblemovesthatkeepsuchadistributioninvariant.
To see the behaviour of this algorithm, and compare it to a standard
random walk Metropolisâ€“Hastings algorithm, we show results of both
algorithms when sampling from a Gaussian target distribution in Figures
4.3 and 4.4. For Figure 4.3, we implement both algorithms using a small
proposal variance, ğ›¿2. Here we see the poor mixing of the random walk
Metropolis due to its reversibility and the random walk behaviour of its
output.Thismeansthatittakesnearly1000stepstoreachthemodeofthe
target distribution. By comparison, Gustafsonâ€™s algorithm suppresses this
random walk behaviour, with large periods of time spent moving in the
samedirection.Aswearesamplingfromauni-modaltarget,thequalitative
dynamics of the algorithm are as follows: when it is moving towards the
mode the acceptance probability is 1 and the algorithm keeps moving in
thatdirection.Itisonlywhenitismovingawayfromthemodethatithas
anychanceofrejectingaproposalandswitchingthedirectionofitsmove.
The behaviourof thetwo algorithmswhenwe usea largerstep size,as
shown in Figure 4.4, is very different. In this case, both trace plots look
qualitativelysimilar,andbothsamplershavesimilarlygoodperformanceas
shownbytheauto-correlationplots.Thereasonisthatforalargestepsize,
the chances of rejecting the proposal and switching the direction are now
muchhigher,closerto0.5onaverage.Thisalsotiesinwiththeobservation
from Section 4.1 that reversibility is only an issue when the step sizes are
small.
If we wish to sample from a multivariate target ğœ‹(ğœ½), we can do so
byapplying thisupdate component-wise.Thatis, weaugment thestateto
(ğœ½,p) where p is ğ‘‘-dimensional and each entry of p is either 1 or âˆ’1 and
specifiesthedirectionofthenextupdateofthecorrespondingcomponent4.3 LiftingSchemesforMCMC 115
 5 : 0 +  * X V W D I V R Q
   
   
   
   
   
   
   
                     
 N k
       
       
       
       
       
       
       
               
 / D J  / D J
Figure4.3 ComparisonofrandomwalkMetropolisâ€“Hastings
(leftcolumn)andtheguidedrandomwalk(rightcolumn)when
samplingfroma1-dGaussian.TheproposalisGaussianwitha
standarddeviationof0.1inbothcases.Toprowshowstraceplots,
andbottomrowshowstheestimatedauto-correlationofthe
chains.
of ğœ½. Then we have ğ‘‘ parts to each iteration of the algorithm where each
partusestheabovealgorithmtoupdateadifferentcomponentofğœ½.
One can see the similarity with the algorithm of Horowitz (1991). We
haveaugmentedthestatetoincludeacomponent,ofthesamedimensionas
ğœ½,thatgovernsthedirectionoftheupdateoftheMarkovchain.OurMarkov
chain update is based on interleaving two reversible moves, but with the
resultingMarkovchainbeingnon-reversible.Finally,eachreversiblemove
involvesaflipofdirection;providingtheacceptanceprobabilityinstep(1)
 ) & $
Î¸ k
 ) & $
Î¸ k116 Non-ReversibleMCMC
 5 : 0 +  * X V W D I V R Q
   
   
   
   
   
   
                 
k k
       
       
       
       
       
       
       
                     
 / D J  / D J
Figure4.4 ComparisonofrandomwalkMetropolisâ€“Hastings
(leftcolumn)andtheguidedrandomwalkalgorithm(right
column)whensamplingfroma1-dGaussian.Theproposalis
Gaussianwithastandarddeviationof2.38inbothcases.Toprow
showstraceplots,andbottomrowshowstheestimated
auto-correlationofthechains.
is high, then these cancel out and the chain is likely to move in the same
directionovermultipletime-steps.
Finally, one can implement the idea of Gustafson (1998) in a way that
jointly updates the ğ‘‘-dimensional state. This can be achieved by letting p
be a ğ‘‘-dimensional unit vector. Define a target distribution on (ğœ½,p) that
istheproductof ğœ‹(ğœ½) andtheuniformdensityforponthe ğ‘‘-dimensional
sphere; we denote the density by Uğ‘‘(p) and the surface of the sphere as
S ğ‘‘.Thistargetwillbekeptinvariantbythefollowingalgorithm,whereto
 ) & $
Î¸
k
 ) & $
Î¸
k4.3 LiftingSchemesforMCMC 117
aidthepresentationofthealgorithminSection4.4wereplacetherandom
|ğœ| withafixed,user-prescribed ğ›¿ > 0.Hereandfortheremainderofthis
chaptertheproposalisadeterministic,1-1map,ratherthanadensity,and
weusethesymbolqratherthanğ‘.
Algorithm 5: Multi-dimensional guided random walk, with fixed
direction.
Input:Densityğœ‹(ğœ½),initialvalueğœ½ andspeedğ›¿ > 0,unitvector
0
p
0
sampledfromUğ‘‘.
for ğ‘˜ âˆˆ 0,...,ğ‘›âˆ’1do
Propose (ğœ½â€²,pâ€²) =q 1(ğœ½ğ‘˜,pğ‘˜) = (ğœ½ğ‘˜ +ğ›¿pğ‘˜,âˆ’pğ‘˜).
Withprobability
(cid:26) ğœ‹(ğœ½â€²)(cid:27)
ğ›¼ 1(ğœ½ğ‘˜,pğ‘˜;ğœ½â€²,pâ€²) :=min 1,
ğœ‹(ğœ½ğ‘˜)
accepttheproposal, (ğœ½ğ‘˜+1,pâ€²â€²) â† (ğœ½â€²,pâ€²);otherwiserejectit,
(ğœ½ğ‘˜+1,pâ€²â€²) â† (ğœ½ğ‘˜,pğ‘˜).
Flipthevelocity: (ğœ½ğ‘˜+1,pğ‘˜+1) = (ğœ½ğ‘˜+1,âˆ’pâ€²â€²).
end
The velocity flip does not update ğœ½, and p âˆˆ S ğ‘‘ â‡” âˆ’p âˆˆ S ğ‘‘, so the
flip is reversible with respect to ğœ‹(ğœ½)Uğ‘‘(p), which must, therefore, be
the stationary density. It is helpful to explore exactly why the first step
is also reversible with respect to this density. Suppose that (ğœ½,p) has a
density of ğœ‹(ğœ½)Uğ‘‘(p) and let B and C be disjoint sets in Rğ‘‘ Ã—S ğ‘‘. Then
P((ğœ½,p) âˆˆ B,(ğœ½â€²,pâ€²) âˆˆ C) is
âˆ« (cid:18) ğœ‹(ğœ½â€²)(cid:19)
ğœ‹(ğœ½)Uğ‘‘(p)min 1,
ğœ‹(ğœ½)
1 B(ğœ½,p)1 C(ğœ½â€²,pâ€²) dğœ½dp
âˆ« (cid:18) ğœ‹(ğœ½) (cid:19)
= ğœ‹(ğœ½â€²)Uğ‘‘(pâ€²)min 1,
ğœ‹(ğœ½â€²)
1 B(ğœ½,p)1 C(ğœ½â€²,pâ€²) dğœ½dp
âˆ« (cid:18) ğœ‹(ğœ½) (cid:19)
= ğœ‹(ğœ½â€²)Uğ‘‘(pâ€²)min 1,
ğœ‹(ğœ½â€²)
1 B(ğœ½,p)1 C(ğœ½â€²,pâ€²) dğœ½â€²dpâ€²,
as required. Here, the second line follows by rearrangement and because
the algorithm forces p âˆˆ S ğ‘‘ â‡” pâ€² âˆˆ S ğ‘‘. The third line follows from the
unitJacobianofthetransformationq .
1
While this algorithm keeps the target on (ğœ½,p) invariant, the algorithm
is reducible; p can only take two values: p and âˆ’p , whilst ğœ½ is confined
0 0
to a discrete grid on the vector ğœ½ +ğ›¿p . It is straightforward to make the
0 0118 Non-ReversibleMCMC
   
   
   
   
   
                   
Figure4.5 Traceplotfor50000iterationsofthealgorithmof
Gustafson(1998)samplingfroma2-ğ‘‘ densityconcentratedon
theunitcircle.Theheatmapshowsthetargetdensity(redisthe
regionofhighdensity),andtheblacklineshowsthetraceofthe
algorithm.
algorithmirreducibleindimension2andabovebyaddingoccasionalmoves
thatupdatep,forexample,thatsampleanewvalueofpfromUğ‘‘.
ComparisononaRing-shapedTarget
To see the benefits of these non-reversible algorithms, we compared the
guidedrandomwalkalgorithmwiththatofastandardrandomwalkMetropo-
lisalgorithmforsamplingfromadensitythatconcentratesontheperimeter
of a circle in 2-ğ‘‘. This mimics a common challenge of sampling from
a density that concentrates near a lower-dimensional manifold within a
higher-dimensionalspace.WeimplementedAlgorithm5witharefreshof
thedirectionevery10iterations.
Trace plots for the non-reversible and reversible algorithms are shown
inFigures4.5and4.6,respectively.Eachalgorithmusesthesameaverage
step size. For good mixing in the manifold scenario, the step size needs
to be of the order of the width of the density orthogonal to the circle â€“
and thus is small relative to the size of the circle itself. As we have seen4.4 ImprovingNon-reversibility:DelayedRejection 119
   
   
   
   
   
                   
Figure4.6 Traceplotfor50000iterationsoftherandom-walk
Metropolisalgorithmsamplingfroma2-ğ‘‘ densityconcentrated
ontheunitcircle.Theheatmapshowsthetargetdensity(redis
theregionofhighdensity),andtheblacklineisthetraceofthe
algorithm.
previously, using such a small step size leads to random-walk behaviour
for the reversible algorithm. By comparison, the non-reversible algorithm
is able to suppress this. The overall effect is much better mixing for the
non-reversible algorithm, which takes 50000 iterations to explore the full
extentofthering.Bycomparison,overthesamenumberofiterations,the
reversiblealgorithmhasonlyexploredthebottomhalfofthering;infact,
ittakessixtimesthisnumberofiterationstoexploretheentirering.
4.4 ImprovingNon-reversibility:DelayedRejection
The major source of inefficiency in Algorithm 5 is the net reversal of
momentum whenever the proposed new position and momentum (ğœ½â€²,pâ€²)
arerejected.Thesubsequentmomentumflipisdesignedtokeeptheprocess
movinginthesamedirectionasitwasatthestartoftheiteration;however,
it has the opposite effect when there is a rejection, causing the chain to
retrace its steps. The delayed-rejection method of Green and Mira (2001)120 Non-ReversibleMCMC
canbeappliedtoanyreversiblestepandprovidesanaturalmechanismfor
reducingtheprobabilityofrejectionasfollows:whenevertheoriginalstep
wouldhaverejectedtheproposal,anewvalueisproposed;theacceptance
probabilityforthisnewproposalisdesignedexactlysothatthecombination
of the rejected existing step and the potential new step satisfies detailed
balancewithrespecttotheintendedposterior.
The validity of the propose-accept/reject step of Algorithm 5 relies
on the Jacobian of q
1
being 1 and the fact that q 1(ğœ½â€²,pâ€²) â‰¡ q 1(ğœ½ğ‘˜ +
ğ›¿pğ‘˜,âˆ’pğ‘˜) = (ğœ½ğ‘˜,pğ‘˜). Following analogous constraints, we incorporate a
delayed-rejectionmoveasfollows:If(ğœ½â€²,pâ€²)isrejected,wecanmakeanew
proposalbasednotonlyonthecurrentstate,(ğœ½ğ‘˜,pğ‘˜)butalsoontheinitial,
rejectedproposal,(ğœ½â€²,pâ€²).Inthiscase,wenowconsiderthecurrentstateto
betheoriginalcurrentstateandtheinitial,rejectedproposal:(ğœ½ğ‘˜,pğ‘˜,ğœ½â€²,pâ€²);
we call this the full state. We then make a proposal for this full state;
i.e., we propose a new original state and a new initial, rejected proposal:
(ğœ½â€²â€²,pâ€²â€²,ğœ½â€²â€²â€²,pâ€²â€²â€²) =q 2(ğœ½ğ‘˜,pğ‘˜,ğœ½â€²,pâ€²),where(ğœ½â€²â€²â€²,pâ€²â€²â€²) = (ğœ½â€²â€²+ğ›¿pâ€²â€²,âˆ’pâ€²â€²).
Tosimplifythenotationinthefollowing,wedefine
zğ‘˜ = (ğœ½ğ‘˜,pğ‘˜), zâ€² = (ğœ½â€²,pâ€²), zâ€²â€² = (ğœ½â€²â€²,pâ€²â€²) and zâ€²â€²â€² = (ğœ½â€²â€²â€²,pâ€²â€²â€²).
Wewilleitheracceptorrejecttheproposal(zâ€²â€²,zâ€²â€²â€²) =q 2(zğ‘˜,zâ€²)forthefull
stateandwechoosetheprobabilityofacceptanceexactlysothatthemove
satisfies detailed balance with respect to the density of the current state
(whichimpliestheinitialproposal),includingthefactthatitwasrejected:
ğœ‹ËœËœ(zğ‘˜,zâ€²) := ğœ‹(ğœ½ğ‘˜)Uğ‘‘(pğ‘˜)I[zâ€² =q 1(zğ‘˜)]{1âˆ’ğ›¼ 1(zğ‘˜;zâ€²)}.
By analogy with the Metropolisâ€“Hastings algorithm we might expect this
acceptanceprobabilitytobe
(cid:20) {1âˆ’ğ›¼ (zâ€²â€²;zâ€²â€²â€²)}ğœ‹(ğœ½â€²â€²)(cid:21)
ğ›¼ 2(zğ‘˜,zâ€²;zâ€²â€²,zâ€²â€²â€²) :=min 1, {1âˆ’ğ›¼1
1(zğ‘˜;zâ€²)}ğœ‹(ğœ½ğ‘˜)
,
where for simplicity of presentation we have not included the indicator
functions I[zâ€²â€²â€² =q 1(zâ€²â€²)] and I[zâ€² =q 1(zğ‘˜)] in the numerator and de-
nominator of the fraction, respectively, since by design these are both 1.
Indeed, subject to conditions on q , ğ›¼ is correct. For the proposal and
2 2
accept/rejectsteptobevalid,q musthaveaJacobianof1,andmustsatisfy
2
q 2(zâ€²â€²,zâ€²â€²â€²) = (zğ‘˜,zâ€²). The probability of being at zğ‘˜ with a deterministic
proposalofzâ€² thathasbeenrejected,andthenmovingtothisnewfullstate
is,therefore,
ğœ‹ËœËœ(zğ‘˜,zâ€²)ğ›¼ 2(zğ‘˜zâ€²;zâ€²â€²,zâ€²â€²â€²),4.4 ImprovingNon-reversibility:DelayedRejection 121
which,bydesign,isequalto
ğœ‹ËœËœ(zâ€²â€²,zâ€²â€²â€²)ğ›¼ 2(zâ€²â€²,zâ€²â€²â€²;zğ‘˜,zâ€²).
Usingthetwoconstraintsonq andananalogousargumenttothatusedfor
2
Algorithm5,detailedbalanceis,therefore,satisfied.
4.4.1 TheDiscreteBouncyParticleSampler
Thecurrentstateiszğ‘˜,giventhis,zâ€² isfixedviaq 1.The1-1mapq
1
simi-
larly fixes the relationship between zâ€²â€² and zâ€²â€²â€² so the additional flexibility
this delayed-rejection formulation allows is the freedom to choose zâ€²â€² or,
equivalently,zâ€²â€²â€².
To make ğ›¼ close to 1, a sensible aim is to choose (zâ€²â€²,zâ€²â€²â€²) such that
2
ğœ‹(ğœ½â€²â€²) â‰ˆ ğœ‹(ğœ½ğ‘˜) and ğ›¼ 1(zâ€²â€²;zâ€²â€²â€²) â‰ˆ ğ›¼ 1(zğ‘˜;zâ€²). If we set ğœ½â€²â€²â€² = ğœ½â€², both of
theseconditionswillbesatisfiedifğœ‹(ğœ½â€²)/ğœ‹(ğœ½) â‰ˆ ğœ‹(ğœ½â€²)/ğœ‹(ğœ½â€²â€²);i.e.
logğœ‹(ğœ½â€²)âˆ’logğœ‹(ğœ½â€²â€²) â‰ˆlogğœ‹(ğœ½â€²)âˆ’logğœ‹(ğœ½ğ‘˜).
Taylorexpandingaboutğœ½â€²,werequireğ›¿gÂ·pâ‰ˆ ğ›¿gÂ·pâ€²â€²,whereg= âˆ‡logğœ‹(ğœ½â€²);
i.e. both pâ€²â€² and p should have approximately the same component in the
gradientdirection.Perhapsthemostnaturalwaytoachievethisisbysetting
pâ€²â€² = Î¨ g(p) :=âˆ’pğ‘˜ +2(pğ‘˜ Â· (cid:98)g) (cid:98)g,
whereg=g/âˆ¥gâˆ¥,isthedirectionofthegradientoflogğœ‹atğœ½â€².Inthiscase,
(cid:98)
Î¨ g(pâ€²â€²) =pğ‘˜ âˆ’2(pğ‘˜ Â· (cid:98)g) (cid:98)g+2[(cid:8) âˆ’pğ‘˜ +2(pğ‘˜ Â· (cid:98)g) (cid:98)g(cid:9) Â· (cid:98)g] (cid:98)g=pğ‘˜.
Further,sinceÎ¨ (Â·) isself-inverse,theabsolutevalueofitsJacobianmust
g
be1.Thefullproposalis,therefore,
(zâ€²â€²,zâ€²â€²â€²) =q 2(zğ‘˜,zâ€²) = (cid:0) ğœ½â€²âˆ’Î¨ g(pğ‘˜),Î¨ g(pğ‘˜),ğœ½â€²,âˆ’Î¨ g(pğ‘˜)(cid:1).
However, since zâ€²â€²â€² plays no part in any subsequent movement and since
momenta do not figure in the acceptance probabilities, it can simplify
notationtothinkoftheproposalas
(ğœ½â€²â€²,pâ€²â€²) =qâˆ— 2(ğœ½ğ‘˜,pğ‘˜,ğœ½â€²) := (cid:0) ğœ½â€²âˆ’Î¨ g(pğ‘˜),Î¨ g(pğ‘˜)(cid:1),
theinitialacceptanceprobabilityas
(cid:26) ğœ‹(ğœ½â€²)(cid:27)
ğ›¼ 1âˆ—(ğœ½ğ‘˜,ğœ½â€²) :=min 1,
ğœ‹(ğœ½ğ‘˜)
,122 Non-ReversibleMCMC
andthesecondacceptanceprobabilityas
(cid:20) {1âˆ’ğ›¼âˆ—(ğœ½â€²â€²,ğœ½â€²)}ğœ‹(ğœ½â€²â€²)(cid:21)
ğ›¼âˆ—(ğœ½,ğœ½â€²,ğœ½â€²â€²) =min 1, 1 .
2 {1âˆ’ğ›¼âˆ—(ğœ½ğ‘˜,ğœ½â€²)}ğœ‹(ğœ½ğ‘˜)
1
ThefullalgorithmisgiveninAlgorithm6andillustratedinFigure4.7.
Algorithm6:DiscreteBouncyParticleSampler
Input:Densityğœ‹(ğœ½),initialvalueğœ½ andspeedğ›¿,unitvectorp
0 0
sampledfromUğ‘‘.
forğ‘¡ âˆˆ 0,...,ğ‘‡ âˆ’1do
Propose (ğœ½â€²,pâ€²) =q 1(ğœ½ğ‘˜,pğ‘˜).
Withaprobabilityofğ›¼âˆ—(ğœ½ğ‘˜,ğœ½â€²) accepttheproposal:
1
(ğœ½ğ‘˜+1,pğ‘˜+1) â† (ğœ½â€²,pâ€²).
Iftheproposalisnotacceptedthenpropose
(ğœ½â€²â€²,pâ€²â€²) =qâˆ—(ğœ½ğ‘˜,pğ‘˜,ğœ½â€²).
2
Withaprobabilityofğ›¼âˆ—(ğœ½ğ‘˜,ğœ½â€²,ğœ½â€²â€²) acceptthisproposal:
2
(ğœ½ğ‘˜+1,pğ‘˜+1) â† (ğœ½â€²â€²,pâ€²â€²),otherwise (ğœ½ğ‘˜+1,pğ‘˜+1) = (ğœ½ğ‘˜,pğ‘˜).
Flipthevelocity: (ğœ½ğ‘˜+1,pğ‘˜+1) = (ğœ½ğ‘˜+1,âˆ’pğ‘˜+1).
end
As with Algorithm 5, we can ensure that Algorithm 6 is irreducible by
refreshing the unit vector p. This could involve sampling pğ‘˜ âˆ¼ Uğ‘‘ every
ğ‘š iterations for some integer ğ‘š, or with probability ğ‘ on any iteration;
however,thisstillallowsforrejectionscausingthesamplertoexactlyretrace
the recent past. More usually, therefore, after every velocity flip step, the
followingupdateismade:
pğ‘˜+1 = âˆ¥ğ›¾ğ›¾p pğ‘˜ ğ‘˜++ 11 ++ âˆšï¸âˆšï¸ 1 1âˆ’ âˆ’ğ›¾ ğ›¾2 2ğƒ ğƒâˆ¥,
whereğƒ âˆ¼N(0, ğ‘‘1Iğ‘‘) and0 â‰¤ ğ›¾ < 1.
Considering the combined effect of the initial proposal, the delayed-
rejection step and the momentum flip on a hypothetical particle at ğœ½ğ‘˜
with a velocity of pğ‘˜ moving along a level, frictionless surface provides
a useful insight into the behaviour of Algorithm 6. In the following we
defineR (p) := âˆ’Î¨ (p) = pâˆ’2(pÂ·g) g,whichisareflectionofpinthe
g g (cid:98) (cid:98)
hyperplaneperpendiculartog.
â€¢ If the initial proposal is accepted then the net effect is (ğœ½ğ‘˜+1,pğ‘˜+1) =
(ğœ½ğ‘˜ +ğ›¿pğ‘˜,pğ‘˜);theparticlemovesexactlyasitshouldoveratimeğ›¿.4.4 ImprovingNon-reversibility:DelayedRejection 123
Î¸
k 1
âˆ’
p
k 1
âˆ’
Î¸ k Î¸00
p
k
p00
âˆ’
Î¸0
Figure4.7 Heuristicofconsecutivestepsfromthediscrete
bouncyparticlesampler.From(ğœ½ğ‘˜âˆ’1,pğ‘˜âˆ’1)theinitialproposalis
acceptedandthemomentumisflipped,leadingto(ğœ½ğ‘˜,pğ‘˜).The
initialproposalfromthispoint(ğœ½â€²isshownbutpâ€² =âˆ’pğ‘˜ isnot)is
rejected.Thethicksolidlineshowsacontourofğœ‹atğœ½â€² withthe
tangentlineatğœ½â€² showndashed.Thefullproposalincludes
(ğœ½â€²â€²,pâ€²â€²);thefigureshowsâˆ’pâ€²â€² toemphasisehow,iftheproposal
isaccepted,withthesubsequentmomentumflippedthe
movementisanalogoustoabounceoffthetangenthyperplane.
â€¢ Iftheinitialproposalisrejected,butthedelayed-rejectionproposalisac-
cepted,thentheneteffectis(ğœ½ğ‘˜+1,pğ‘˜+1) = (cid:0) ğœ½ğ‘˜ +ğ›¿pğ‘˜ +ğ›¿R g(pğ‘˜),R g(pğ‘˜)(cid:1) ;
theparticlemovesforwardforatimeğ›¿ toğœ½â€² thenreflectsoffthehyper-
planeperpendiculartogandmovesforwardforanothertimeğ›¿.
â€¢ If both the initial step and the delayed-rejection step are rejected then
(ğœ½ğ‘˜+1,pğ‘˜+1) = (ğœ½ğ‘˜,âˆ’pğ‘˜);theparticlereversesdirection.
If it were not for the occasional full rejection, the path of the points
outputted from the algorithm would resemble a time discretisation of the
smoothpathofaparticlemovingalongafrictionlesssurfaceandoccasion-
allybouncingoffahardbarrierinthehyperplaneperpendiculartothelocal
gradient. For this reason, the algorithm is known as the Discrete Bouncy
ParticleSampler.Inthelimit,asğ›¿â†“0andthenumberofstepsisincreased
in proportion to 1/ğ›¿, this becomes a continuous-time algorithm known as
theBouncyParticleSampler,whichweshallmeetinSection5.3.1.124 Non-ReversibleMCMC
       
       
       
       
       
           
Figure4.8 Trajectoriesafter5000iterations(left)and50000
iterations(right)ofthediscretebouncyparticlesampleronthe
two-dimensionalringtargetofFigures4.5and4.6,andusingthe
samestepsize.
PerformanceontheRing-shapedTarget
We exemplify the improved trajectories of the discrete bouncy particle
samplerbyimplementingitonthesametwo-dimensionalring-shapedtarget
for which the guided random walk with a directional update every 10
iterations took 50000 iterations to explore (Figure 4.5) and the random
walkMetropoliswiththesamestepsizetook300000iterationstoexplore
(Figure4.6showsthefirst50000iterations).
Ourdiscretebouncyparticlesamplerusesthesamestepsizeastheearlier
algorithmsandsetsğ›¾sothatthedirectionoftravelisonlypartiallyforgotten
fromjustafteronebouncetojustbeforethenext(seeSherlockandThiery,
2022). Figure 4.8 shows the path of the discrete bouncy particle sampler
after5000(left)and50000(right)iterations,onthetwo-dimensionalring
target. Exploration of the full circle takes only a tenth of the number of
iterationsthattheguidedrandomwalkrequiresandasixtiethofthenumber
of iterations required by the RWM. The coverage after the full 50000
iterationsisalsomorecompletethanwhenusingtheguidedrandomwalk.
4.5 ChapterNotes
Perhaps the earliest theoretical results showing that non-reversible chains
havebettermixingpropertiesweregiveninDiaconisetal.(2000).There-4.5 ChapterNotes 125
sultsfromapre-printofthisworkwereextendedinChenetal.(1999).See
alsoNeal(2004)andSunetal.(2010)whichshowthatnon-reversiblesam-
plersreduceasymptoticvariance.MorerecentresultsaregiveninBierkens
(2016).
Thediscretebouncyparticlesampler,describedinSection4.4,isgiven
in Sherlock and Thiery (2022). Similar algorithms appear in Neal (2003)
andVanettietal.(2017).Thekeydifferenceistheuseofâ€externalbouncesâ€
ratherthanâ€internalbouncesâ€:reflectionhappensinthecurrentpointrather
than the proposed point, so that: (ğœ½â€²â€²,pâ€²â€²,ğœ½â€²â€²â€²,pâ€²â€²â€²) = (ğœ½ğ‘˜,Î¨ g(pğ‘˜),ğœ½ğ‘˜ +
Î¨ g(pğ‘˜),âˆ’Î¨ g(pğ‘˜)), where g = âˆ‡logğœ‹(ğœ½ğ‘˜). Use of the bounce move that
is key to the success of the discrete bouncy particle sampler will be seen
within the continuous-time bouncy particle sampler described in the next
chapter. It has also been used in other discrete-time MCMC algorithms.
For example, the Hug move in Ludkin and Sherlock (2022) uses repeated
bouncesinthesamewaythatHMCusesrepeatedleapfrogsteps,withthe
resultthatthepathtotheproposalstaysclosetothecontourofğœ‹onwhichit
started,andjustaswithHMC,foragivenintegrationtime,theacceptance
probabilitycanbemadeascloseto1asdesiredbyreducingthestepsize.
Analternativetotheliftingschemesdescribedinthischapteraremethods
thatadaptareversibleMarkovchaintoanon-reversibleonewithoutadding
additional states. The general approach is to find a loop of states, and
then adapt the probability flow around this loop such that the net flow of
probabilityateachstateispreserved.Forexample,ifwehavestatesğ‘–, ğ‘— and
ğ‘˜ thenwecanreduceeachofthethreeprobabilitiesofmovingfromğ‘–toğ‘–, ğ‘—
to ğ‘— and ğ‘˜ to ğ‘˜ bytheminimumofthethreeandincreaseeachofthethree
probabilitytransitionsfromğ‘–to ğ‘—, ğ‘— toğ‘˜ andğ‘˜ toğ‘–bythesameamount,so
thattheinvariantdistributionofthechainisunchanged.Suchchangeshave
been described as adding vortices. These ideas are described in Sun et al.
(2010) and Turitsyn et al. (2011). See Suwa and Todo (2010) for related
ideas. These constructions are hard to adapt to general Markov chains,
particularly chainswithout discretestates, though seeBierkens (2016)for
an approach to adapt the Metropolisâ€“Hastings acceptance probability to
introducenon-reversibility.5
Continuous-Time MCMC
The previous chapter introduced the idea of non-reversible MCMC, and
demonstrated that non-reversibility may help improve the Markov chainâ€™s
mixing by suppressing random-walk behaviour. In this chapter, we now
presentaclassofnon-reversibleMCMCalgorithmsthatcantargetageneral
distribution, ğœ‹(ğœ½). These algorithms are different from standard MCMC
algorithmsinthattheyarebasedonsimulatingacontinuous-timeMarkov
chain. Furthermore, specific examples of these continuous-time MCMC
algorithms can be derived as continuous-time limits of the non-reversible
algorithmsweintroducedinthepreviouschapter.
As a way of motivating these algorithms, we will first look at this
continuous-time limit. The resulting continuous-time process is from a
class of processes called piecewise deterministic Markov processes. We
willintroducesomebackgroundonthisclassofprocesses,includingsome
detailsaroundhowwecansimulatetheircontinuous-timetrajectories,be-
foreintroducingexampleMCMCalgorithmsandvariousextensions.These
algorithms use gradient information, and unless stated otherwise, we will
assume that the target distribution ğœ‹(ğœ½) is differentiable everywhere (in
practice being continuous and differentiable almost everywhere is suffi-
cient).
Withinthischapter,wewillneedtorefertobothcomponentsofavector
andpossiblythestateofthevectoratdifferenttimes.Todistinguishbetween
these, we will use the convention that when both time and component are
needed, we subscript by time and superscript by the component. So, for
example,ğœƒ(ğ‘–),willbetheğ‘–thcomponentofthestate,ğœ½,attimeğ‘¡.
ğ‘¡
5.1 Continuous-TimeMCMCastheLimitofNon-Reversible
MCMC
To help build intuition for continuous-time MCMC, and to see how it
linkstodiscrete-timeMCMCalgorithms,wewillshowwecanderivethe
1265.1 Continuous-TimeMCMCastheLimitofNon-ReversibleMCMC127
continuous-time algorithm as the limit of a discrete-time algorithm as we
let the step size in the discrete-time algorithm to tend to 0. Here, we will
consider this limiting argument at an informal level, before presenting a
moreformaljustificationforcontinuous-timeMCMCmethods.
Wewillconsidersamplingfroma1-dimensionaltargetdistributionusing
a simplified version of the non-reversible guided random walk algorithm
thatwasintroducedinSection4.3.Oursimplificationistoassumethatthe
stepsizeateachiterationisfixed.Ourstatewillstillbe(ğœƒ,ğ‘),withğ‘either
1orâˆ’1andspecifyingthedirectionofthenextproposedmove,andwewill
let the size of the move be equal to some fixed value ğ›¿. Such an MCMC
algorithm would not be irreducible, as it could only explore values of the
state that are integer multiples of ğ›¿ away from its initial value. However,
the algorithm will still have the correct invariant distribution; i.e. if we
simulate the initial state from the target distribution for ğœƒ and a uniform
distributionfor ğ‘,thenthiswillalsobethedistributionofthestateatany
future iteration. The issue of lack of irreducibility vanishes in the limit as
ğ›¿ â†’0.
Asareminder,ifthetargetdistributionofinterestisğœ‹(ğœƒ)thentheMCMC
algorithmwilliteratethefollowingmoves
(1a) Proposeamovefrom(ğœƒ,ğ‘)to(ğœƒ+ğ›¿ğ‘,âˆ’ğ‘).Acceptthiswiththestandard
Metropolisâ€“Hastingsacceptanceprobability,whichsimplifiesto
(cid:26) ğœ‹(ğœƒ+ğ›¿ğ‘)(cid:27)
min 1,
ğœ‹(ğœƒ)
(1b) Movefrom (ğœƒâ€²,ğ‘) to (ğœƒâ€²,âˆ’ğ‘).
In step (1a), we propose a move of size ğ›¿ in direction ğ‘. If we accept this
move,thenwewillflipthedirection ğ‘ inbothsteps(1a)and(1b)â€“sothe
directionwillbethesameatthenextiteration.Ifwerejectthemove,then
we will only flip ğ‘ in step (1b) and thus the direction of the move will be
flippedforthenextiteration.
Underthisframework,wecanthenconsiderlettingğ›¿ â†’0whileincreas-
ingthenumberofiterationsğ‘›.Thatiswefixavalueğ‘ andforanynumber
ofiterations,ğ‘› willset ğ›¿ = ğ‘ /ğ‘›.Wewillscaletimesothattheğ‘–thMCMC
transition will occur at time ğ‘–ğ›¿, and define (ğœƒ ğ‘¡,ğ‘ ğ‘¡) to be the value of the
stateaftertheğ‘–thMCMCtransitionforğ‘–ğ›¿ â‰¤ ğ‘¡ < (ğ‘–+1)ğ›¿.128 Continuous-TimeMCMC
Now,foreachmoveinstep(1a)therejectionprobabilityforsmallğ›¿is
max{0,1âˆ’exp[logğœ‹(ğœƒ+ğ›¿ğ‘)âˆ’logğœ‹(ğœƒ)]}
(cid:26) (cid:20) dlogğœ‹(ğœƒ) (cid:21)(cid:27)
=max 0,1âˆ’exp ğ›¿+ğ‘œ(ğ›¿)
dğœƒ
(cid:26) dlogğœ‹(ğœƒ)(cid:27)
=max 0,âˆ’ğ‘ ğ›¿+ğ‘œ(ğ›¿),
dğœƒ
assumingthat,forexample,thederivativeofğœ‹(ğœƒ) iscontinuous.
Thusinourlimitasğ›¿ â†’0,rejectionsinstep(1a)willoccuraseventsin
aPoissonprocessofrate
ğœ†(ğœƒ ğ‘¡,ğ‘ ğ‘¡)
=max(cid:26)
0,âˆ’ğ‘
ğ‘¡dlog dğœ‹ ğœƒ(ğœƒ ğ‘¡)(cid:27)
.
The dynamics between these events will be deterministic, with ğ‘ ğ‘¡ being
constant and ğœƒ ğ‘¡ changing as per a constant velocity model with velocity
ğ‘ ğ‘¡. At each event, the velocity will just flip. While the process is moving
to areas of higher probability density, as defined by ğœ‹(ğœƒ), the rate of the
Poisson process will be 0. Thus events will only occur if the process is
movingtoareasoflowerprobabilitymass.
Howdoesthislimiting,continuous-timealgorithmcomparetothealgo-
rithmofGustafson(1998)?Wewillcomparewiththestandard,irreducible
versionofGustafson(1998)wherethestepsizeateachiterationisrandom.
We show trace plots for both algorithms for sampling from a mixture of
two Gaussians in Figure 5.1. The target distribution is an equal mix of a
Gaussianwithmean2andvariance1andwithmean0andvariance0.12.
Thiswaschosensothatwehavetwomodeswheredifferentstepsizeswould
beoptimal,whilststillallowingforsufficientoverlapofthemodesthatthe
chainswouldmixbetweenthem.
Wecanseethatqualitativelythetwotrace-plotsaresimilar.Bothmethods
produce zig-zag-like traces, as they will continue to move in the same
directionwhenmovingtoareasofhigherprobabilitydensity.However,the
continuous-timeprocesshasanumberofpotentialadvantages:
â€¢ If we could simulate the continuous-time trajectory directly, then it has
thebenefitofhavingfewereventswherethevelocitychanges(andwhere
the state needs to be updated) than iterations of Gustafsonâ€™s algorithm
â€“ in our example, there are around 200 events in the continuous-time
algorithmascomparedto1000iterationsofGustafsonâ€™salgorithm.
â€¢ Italsohasthebenefitoflesstuning,asnostepsizeneedstobespecified.5.2 PiecewiseDeterministicMarkovProcesses 129
 
 
 
 
   
 
 
   
                   
 , W H U D W L R Q  k   7 L P H  t 
Figure5.1 TraceplotsofGustafsonâ€™salgorithm(left)andthe
continuous-timelimit(right)forsamplingfromamixtureof
Gaussians.
â€¢ Finallyithastheadvantagethatthefullcontinuous-timesamplepathcan
beusedtocalculateMonteCarloaverages.
However,directlysimulatingthecontinuous-timetrajectoryisnotnormally
possible â€“ and it is both the difficulty with simulating the continuous-
time process and the additional computational overhead of doing so that
arethemaindisadvantages.Furthermore,accountingfortheverydifferent
computationalcosts,periterationversusperunitofcontinuoustime,makes
thealgorithmshardtocomparetheoretically.Wewillreturntoissuesaround
simulatingcontinuous-timeMarkovprocesseslikethisbelow.
5.2 PiecewiseDeterministicMarkovProcesses
Thecontinuous-timelimitingprocesswederivedintheprevioussectionis
anexampleofapiecewisedeterministicMarkovprocess,orPDMP.These
areMarkovprocessesthatevolvedeterministicallybetweenasetofrandom
events.Wewillnowintroducetheseprocessesbeforeconsideringhowthey
canbedesignedandusedtosamplefromatargetdistributionofinterest.
5.2.1 WhatisaPDMP?
WewilldenotethestateofaPDMPattimeğ‘¡ byzğ‘¡.APDMPisdefinedby
thefollowingproperties:
x k x t130 Continuous-TimeMCMC
(i) The deterministic dynamics. The PDMP evolves deterministically be-
tweenasetofeventtimes.WeconsiderPDMPswherethedeterministic
dynamicsarespecifiedthroughanordinarydifferentialequation
d dz ğ‘¡ğ‘¡ = ğ“(zğ‘¡), (5.1)
for some gradient field ğ“(Â·). We will also define ğš½ to be the transition
function, or flow map, for these dynamics, so for ğ‘  > 0 the solution to
thedifferentialequationsatisfieszğ‘ +ğ‘¡ =ğš½(zğ‘¡,ğ‘ ).
(ii) Theeventrate.Randomeventsoccuratarateğœ†(zğ‘¡) thatdependsonthe
currentstate.
(iii) Thetransitionkernelatevents.Ateachevent,attimeğœ,thestatechanges
accordingtosomeMarkovtransitionkernelQ(Zğœ âˆˆ Â·|zğœâˆ’),where
zğœâˆ’ =limzğœâˆ’ğœ–
ğœ–â†“0
isthevalueofthestateimmediatelybeforetheevent.ThatisQ(Zğœ âˆˆ Â·|zğœâˆ’)
definestheconditionalprobabilityofmovingtosetÂ·,giventhestateim-
mediatelybeforetheevent.
Tosimplifyexposition,andbecausethisisconsistentwiththePDMPswe
willuseforMCMC,wewillprimarilyfocusondiscretetransitionkernelsat
events,andletğ‘(Â·|z) denotetheprobabilitymassfunctionassociatedwith
thetransitionkernel.Thoughtheideasbelowextendnaturallytocontinuous
transitionkernels.
AsthedeterministicdynamicsareMarkov,andtheeventrateandtransi-
tiondensitydependjustonthecurrentstate,thentheresultingprocesswill
beMarkov.
5.2.2 SimulatingPDMPs
To be able to use a PDMP as the basis of a sampling algorithm, we will
needtobeabletosimulateandstorerealisationsofthePDMP.First,wecan
store a realisation of the continuous-time path of a PDMP by storing just
theinitialstateofthePDMP,andthetimeandeventimmediatelyaftereach
event.Wewillcallthesepointstheskeletonoftherealisation.Ifwesimulate
aPDMPuptotimeğ‘‡ thenitsskeletonwillbeoftheform{ğ‘¡ ğ‘˜,zğ‘¡ ğ‘˜}ğ‘› ğ‘˜=0,where
ğ‘¡ 0 = 0, and ğ‘¡ 1,...,ğ‘¡ ğ‘› are the event times of the PDMP prior to ğ‘‡. Given
this skeleton, we can fill in the continuous-time path using the transition
functionforthedeterministicdynamics:
zğ‘¡ =ğš½(zğ‘¡ ,ğ‘¡âˆ’ğ‘¡ ğ‘˜),whereğ‘¡ ğ‘˜ isthelargestskeletontimelessthanğ‘¡.
ğ‘˜5.2 PiecewiseDeterministicMarkovProcesses 131
ThussimulatingaPDMPwilljustrequiretheabilitytosimulatetheskeleton
points.Ifweassumethatsimulatingfromthetransitiondensityateventsis
straightforward,thentheonlychallengewillbesimulatingtheeventtimes
themselves.Wecandothisbyusingthefollowingargumentthatshowsthat
thetimeuntilthenexteventcanberecastasthetimeuntilthefirsteventin
atimeinhomogeneousPoissonprocess.
To simplify notation we will consider simulating the time of the first
event, and denote the initial state as Z = z. By the Markov property, the
0
same approach can then be applied to simulating subsequent events: as if
the current state is Zğ‘¡ = z then the subsequent time until the next event
is the same as the time until the first event if we start the process at state
Z =z.
0
If there has not been an event by time ğ‘¡, then due to the deterministic
dynamics between events we know that the state at time ğ‘¡ will be zğ‘¡ =
ğš½(z,ğ‘¡). The instantaneous rate of an event at time ğ‘¡, if there has been no
event before ğ‘¡, is thus ğœ†(zğ‘¡) = ğœ†(ğš½(z,ğ‘¡)). Thus, the rate of the first event
of the PDMP is equal to the rate of the first event in an inhomogeneous
Poissonprocesswithrate
ğœ†Ëœ (ğ‘¡) =ğœ†(ğš½(z,ğ‘¡)).
z
Here,weusethetildesymboltodistinguishthisratefromtheratefunction,
ğœ†, that depends on the state. We also subscript the rate by z, the initial
state.Asdescribedabove,bytheMarkovproperty,ifwehavesimulatedthe
PDMPuntiltimeğ‘ andthecurrentstateiszğ‘ ,thentherateofthenextevent
asafunctionofthefurthertime,ğ‘¡,untilthenexteventwillbeğœ†Ëœ (ğ‘¡).
zğ‘ 
Asaresult,wehavetransformedtheproblemofsimulatingaPDMPto
thatofsimulatingthefirsteventofatimeinhomogeneousPoissonprocess.
There are several methods for simulating such an event time (see e.g.
LewisandShedler,1979;Bouchard-CoË†teÂ´ etal.,2018)andwewilloutline
threegeneralstrategiesfordoingso.Whetherthesecanbeimplementedin
practice depends on the form of ğœ†Ëœ , and we will return to this with some
z
exampleslater.
DirectSimulationbyInversion
In theory, one can simulate directly the time to the next event. Let ğœ be
therandomvariablethatisthetimeuntilthefirst(ornext)event.Standard
propertiesofaPoissonprocessgivethattheprobabilityofnoeventbytime
ğ‘¡ is
(cid:26) âˆ« ğ‘¡ (cid:27)
P(ğœ > ğ‘¡) =exp âˆ’ ğœ†Ëœ (ğ‘ )dğ‘  .
z
0132 Continuous-TimeMCMC
Foracontinuousrandomvariable, ğ‘‹,withdistributionfunction ğ¹ ğ‘‹(Â·),we
have that the transformed random variable ğ¹ ğ‘‹(ğ‘‹) has a standard uniform
distribution. From this, we can simulate ğ‘‹ by simulating ğ‘¢, a realisation
ofastandarduniformdistributionandsettingğ‘¥ = ğ¹âˆ’1(ğ‘¢).Thedistribution
ğ‘‹
functionforğœis1âˆ’P(ğœ > ğ‘¡),thuswecansimulateğœfromğ‘¢bysolving
(cid:26) âˆ« ğœ (cid:27)
ğ‘¢ =1âˆ’exp âˆ’ ğœ†Ëœ (ğ‘ )dğ‘  .
z
0
Thiscanberearrangedto
âˆ« ğœ
âˆ’ ğœ†Ëœ (ğ‘ )dğ‘  =log(1âˆ’ğ‘¢).
z
0
In practice, it is common to further simplify this expression using that if
ğ‘ˆ isastandarduniformrandomvariablethenâˆ’log(1âˆ’ğ‘ˆ) hasastandard
exponentialdistribution.Thusifğ‘¤isarealisationofastandardexponential
randomvariablethenğœcanbesimulatedasthesolutionof
âˆ« ğœ
ğœ†Ëœ (ğ‘ )dğ‘  = ğ‘¤. (5.2)
z
0
AsummaryofthisapproachisgiveninAlgorithm7.
Algorithm7:Directsimulationofeventtime
Input:Ratefunctionğœ†Ëœ .
z
Simulateğ‘¤,fromastandardexponentialdistribution.
Findğœ â‰¥ 0the(smallest)solutionto
âˆ« ğœ
ğœ†Ëœ (ğ‘ )dğ‘  = ğ‘¤.
z
0
Output:ğœ.
Whether we can implement direct simulation depends on whether we
can solve (5.2). This is possible if ğœ†Ëœ (ğ‘ ) is constant, linear, or piecewise
z
linear in ğ‘ . It is also possible if it is some other simple function, such as
proportionaltotheexponentialofalinearfunctionofğ‘ .
PoissonThinning
Whatifwecannotsimulatetheeventdirectlybyinversion?Inthiscase,the
most common approach to simulation is based on Poisson thinning. This
approach is based on the following property of Poisson processes: If we
have a Poisson process with rate ğœ†+(ğ‘ ), and we simulate points from this5.2 PiecewiseDeterministicMarkovProcesses 133
Poissonprocessandthenaccepteachpointwithprobabilityğ›¼(ğ‘ ),thenthe
acceptedpointshavethesamedistributionaspointsfromaPoissonprocess
with rate ğœ†+(ğ‘ )ğ›¼(ğ‘ ). As we are only keeping, i.e. accepting, some of the
simulatedpoints,thisiscalledathinnedpointprocess.
Poisson thinning inverts this property. For any rate function ğœ†+(ğ‘ ) that
upperboundsğœ†Ëœ (ğ‘ ),i.e.whereğœ†+(ğ‘ ) â‰¥ ğœ†Ëœ (ğ‘ )forallğ‘  â‰¥ 0,wecansimulate
z z
thetimeuntilthenexteventasthefirsteventofathinnedPoissonprocess.
ThisleadstoAlgorithm8
Algorithm8:SimulationofeventtimeviaPoissonthinning
Input:Ratefunctionsğœ†+ andğœ†Ëœ ,withğœ†+(ğ‘ ) â‰¥ ğœ†Ëœ (ğ‘ ) forallğ‘  â‰¥ 0.
z z
Setğ‘  =0andğœ =0
whileğœ =0do
Simulateğ‘¡,thetimeofthefirsteventafterğ‘ inaPoissonprocess
withrateğœ†+.
Setğ‘  =ğ‘¡.
Withprobabilityğœ†Ëœ (ğ‘¡)/ğœ†+(ğ‘¡),setğœ =ğ‘¡.
z
end
Output:ğœ,thefirsteventinaPoissonprocesswithrateğœ†Ëœ .
z
For this to work we need to be able to upper boundğœ†Ëœ by a simple rate
z
function,forwhichwecandirectlysimulateevents.Inpractice,thiswould
oftenbealinearorpiecewiselinearratefunction.TheefficiencyofPoisson
thinning depends on how close the upper bound rate is to ğœ†Ëœ . In practice,
z
we can improve on the simple Poisson thinning algorithm with adaptive
thinning.Thatis,ifwesimulateaneventandthenrejectit,wecanusethe
information from evaluating ğœ†Ëœ to improve our upper bound. We will see
z
someexamplesofsuchadaptivethinningbelow.
Superposition
ThefinalpropertyofPoissonprocessesthatcanhelpwithsimulatingtheir
events is that of superposition. This says that if we have two Poisson pro-
cesses, one with rate ğœ†(1)(ğ‘ ) and one with rate ğœ†(2)(ğ‘ ), and we indepen-
dentlysimulateeventsfromeachprocessandtaketheunionofevents,then
these have the same distribution as events in a Poisson process with rate
ğœ†(1)(ğ‘ )+ğœ†(2)(ğ‘ ).
In terms of simulating the first event in a Poisson process, this can be
re-expressed as if ğœ(1) is the first event time for a Poisson process with
rateğœ†(1)(ğ‘ ),and ğœ(2) isthefirsteventtimeforaPoissonprocesswithrate134 Continuous-TimeMCMC
ğœ†(2)(ğ‘ ),thenmin{ğœ(1),ğœ(2)}isdistributedasthefirsteventtimeinaPoisson
processwithrateğœ†(1)(ğ‘ )+ğœ†(2)(ğ‘ ).
By induction, superposition trivially applies if we consider more than
two independent Poisson processes. That is, the time of the first event in
anyoftheprocessesisdistributedasthetimeofthefirsteventofaPoisson
process whose rate is the sum of the rates. Superposition can be useful
as it allows us to split a complex rate function into a sum of simpler rate
functions.Ifwecansimulateeventsfromprocesseswitheachofthesimpler
rates,thenitallowsustosimulateeventsfromtheprocesswiththecomplex
ratefunction.
5.2.3 TheGeneratorandInvariantDistributionofaPDMP
InordertouseaPDMPtosamplefromatargetdistribution,wefirstneed
to be able to determine what the stationary distribution of a given PDMP
is. Here, we give an informal derivation of how to calculate the invariant
distribution of a PDMP. (Assuming the PDMP satisfies some regularity
conditions, and in particular is irreducible, then this invariant distribution
will be its stationary distribution.) In the next section, we will invert this
characterisationoftheinvariantdistributiontoconstructsimplerecipesfor
thedynamicsofaPDMPtohaveagiventargetdistributionasitsstationary
distribution.IntermsofunderstandingthedevelopmentofPDMPsamplers
in the rest of this chapter, the key result is (5.4) below â€“ and those not
interested in the intuition behind this result could skip the intervening
materialinthissubsection.
First,weneedtoconsiderthegeneratorofourPDMP.Thisisrigorously
derived in Davis (1984). Remember from Section 1.4.2 that the generator
of a continuous-time Markov process is an operator that gives the time
derivativeoftheexpectedvalueofafunctionofthestate,asafunctionof
itscurrentvalue.If L isthegenerator,and â„ asuitabletestfunctionfrom
thedomainofthegenerator,then
(Lâ„)(z)
=limE[â„(Zğ‘¡)|Z
0
=z]âˆ’â„(z)
.
ğ‘¡â†“0 ğ‘¡
Informally we can calculate the generator by considering the two types
ofdynamicsofthePDMP.First,ifweconsidersolelythedeterministicdy-
namics(5.1),thenthechangeinâ„(zğ‘¡) isdeterministicandthecontribution
to the generator is just the time-derivative of â„(zğ‘¡) at ğ‘¡ = 0, which by the5.2 PiecewiseDeterministicMarkovProcesses 135
productruleis
dâ„(zğ‘¡)(cid:12)
(cid:12) (cid:12) = ğ“(z)Â·âˆ‡â„(z).
dğ‘¡ (cid:12)
ğ‘¡=0
Second,wehavethecontributionfromtherandomevents.Theprobability
of an event in [0,ğ‘¡] isğœ†(z)ğ‘¡ +ğ‘œ(ğ‘¡). If an event occurs, the change in â„(z)
is E Q(Â·|z) [â„(Zâ€²)] âˆ’ â„(z) + ğ‘œ(ğ‘¡), where the expectation is with respect to
Zâ€² âˆ¼ Q(Â·|z), the transition kernel at an event. This gives a contribution to
thegeneratorthatis
ğœ†(z) (cid:2)E
Q(Â·|z)
[â„(Zâ€²)]âˆ’â„(z)(cid:3).
Thusthegeneratoris
(Lâ„)(z) = ğ“(z)Â·âˆ‡â„(z)+ğœ†(z) (cid:2)E
Q(Â·|z)
[â„(Zâ€²)]âˆ’â„(z)(cid:3).
The domain of the generator is given in Davis (1984). One extension of
PDMPs that will be relevant later is that we can introduce boundaries,
with additional specified, possibly random, behaviour if the PDMP hits
a boundary. In such a case, the behaviour at the boundaries affects the
generator solely through its domain. Essentially, the domain is reduced
to include only those functions whose expectation is unaffected by the
dynamicsontheboundary.
If we start the PDMP with an initial distribution ğœ‹(z) for Z , then the
0
derivative of E[â„(Zğ‘¡)] at ğ‘¡ = 0 is equal to the average of the generator
appliedtoâ„(z) withrespecttoğœ‹(z).Thisisequalto
âˆ«
(Lâ„)(z)ğœ‹(z)dz.
Foranyâ„inthedomainofthegenerator,ifğœ‹(z)issufficientlywell-behaved,
thenthisintegralwillbeequalto
âˆ«
â„(z)(Lâˆ—ğœ‹)(z)dz, (5.3)
whereLâˆ— isadifferentoperator,calledtheadjointofthegenerator.
We can attempt to define the invariant distribution of the PDMP by
the property that, if we draw Z from this invariant distribution, then the
0
expectation of any function of the state will be constant over time â€“ as
if started from the invariant distribution, the marginal distribution of the
PDMPwillnotchange.Thus(5.3)mustbeequalto0if ğœ‹ istheinvariant
distribution.Asthismusthappenforanyfunction â„ofthestate,forwhich
theexpectationexists,thissuggeststhatğœ‹mustsatisfy (Lâˆ—ğœ‹)(z) =0.
It is possible to derive the adjoint Lâˆ— using integration by parts. From136 Continuous-TimeMCMC
this,wehavethat(Lâˆ—ğœ‹)(z) =0impliesthattheinvariantdistributionmust
satisfy
âˆ’âˆ‘ï¸ğ‘‘ ğœ•ğœ™ ğ‘–(z)ğœ‹(z) +âˆ‘ï¸
ğœ‹(zâ€²)ğœ†(zâ€²)ğ‘(z|zâ€²)âˆ’ğœ‹(z)ğœ†(z) =0, (5.4)
ğœ•ğ‘§
ğ‘–
ğ‘–=1 zâ€²
whereğ‘(z|zâ€²)istheprobabilitymassfunctionassociatedwiththetransition
kernel Q(Â·|zâ€²). This equation has a natural interpretation. The first term
on the left-hand side quantifies the change in probability mass due to the
deterministicdynamics,thesecondtermisthechangeduetoeventsmoving
intostatezandthelastisthechangeduetoeventsthatmovethestateoutof
z.If ğœ‹ isaninvariantdistribution,thenthenetchangeinprobabilitymass
iszero.
In the following, we will use (5.4) to define the invariant distribution
of our PDMP. Though this requires inverting the informal argument we
have made â€“ see Chevallier et al. (2021) for results that give relatively
weakconditionsunderwhichyoucaninvertthisargumentandwhere(5.4)
impliesthatğœ‹(z) istheinvariantdistributionofourPDMP.
5.2.4 TheLimitingProcessofSection5.1asaPDMP
We can now recognise the limiting process derived in Section 5.1 as a
PDMP. Remember that we want to sample from a distribution ğœ‹(ğœƒ) for
some scalar ğœƒ. To do this we introduced a velocity or momentum, ğ‘, and
defined a state z = (ğœƒ,ğ‘) â€“ strictly this is z = (ğœƒ,ğ‘)âŠ¤, but we will use the
shorthand (ğœƒ,ğ‘) in the following. Henceforth, we will use the notation z,
or zğ‘¡, and (ğœƒ,ğ‘), or (ğœƒ ğ‘¡,ğ‘ ğ‘¡) interchangeably â€“ as viewed most helpful for
thegivencontext.Forreasonsthatwillbecomeapparent,wewillcallğœƒ the
positioncomponentofthestate,and ğ‘ thevelocitycomponent.
The limiting process of Section 5.1 was a PDMP with state z = (ğœƒ,ğ‘),
withğœƒ âˆˆ Rand ğ‘ âˆˆ {âˆ’1,1},definedbythefollowingproperties:
(U1) Deterministicdynamics.Thedeterministicdyanamicsareaconstantve-
locitymodel:
d dğœƒ ğ‘¡ğ‘¡ = ğ‘ ğ‘¡, d dğ‘ ğ‘¡ğ‘¡ =0.
(U2) Eventrate.Therateofeventsis
(cid:26) dlogğœ‹(ğœƒ)(cid:27)
ğœ†(ğœƒ,ğ‘) =max 0,âˆ’ğ‘ .
dğœƒ5.2 PiecewiseDeterministicMarkovProcesses 137
(U3) Transition kernel at events. At an event the velocity component of the
stateflips,i.e. ğ‘ ğœ =âˆ’ğ‘ ğœâˆ’.
WewillcallthisPDMPtheunivariatePDMP.
It is possible to show, using (5.4), that the invariant distribution of this
PDMP is ğœ‹Ëœ(z) = ğœ‹(ğœƒ)ğœ‹ ğ‘(ğ‘), where ğœ‹ ğ‘ is the probability mass function
for a uniform distribution on {âˆ’1,1}. That is the ğœƒ-marginal is ğœ‹(ğœƒ), the
distribution we wish to sample from. Furthermore, under the invariant
distribution, ğ‘ is independent of ğœƒ and has a uniform distribution. For
this simple example, the invariant distribution will also be the stationary
distribution,unlesswehavereducibilitycausedbyaregionwhereğœ‹(ğœƒ) =0
thatseparatestworegionswithpositiveprobabilityunderğœ‹.
As we will be considering more general PDMP samplers, it is helpful
to consider a slightly different question. For PDMPs with the given deter-
ministicdynamicsandtransitionsatevents,howwouldwecalculateevent
ratesthatwouldgiveaninvariantdistributionwhoseğœƒmarginalisğœ‹(ğœƒ)?In
answeringthisquestion,wewillcoverthestepsforshowingthattheevent
rategivenaboveleadstothestatedinvariantdistribution.
Todothiswewilluse(5.4).Ifwesubstituteinadistributionğœ‹Ëœ(ğœƒ,ğ‘),and
the deterministic dynamics and transition kernel at events, this illustrates
thatforğœ‹Ëœ(ğœƒ,ğ‘) tobeaninvariantdistribution,itmustsatisfy
dğœ‹Ëœ(ğœƒ,ğ‘)
âˆ’ğ‘ +ğœ†(ğœƒ,âˆ’ğ‘)ğœ‹Ëœ(ğœƒ,âˆ’ğ‘)âˆ’ğœ†(ğœƒ,ğ‘)ğœ‹Ëœ(ğœƒ,ğ‘) =0. (5.5)
dğœƒ
Here,thefirsttermcomesfromtheconstantvelocitydeterministicdynam-
ics,andthesecondcomesfromthereonlybeingonepossibletransitionto
state (ğœƒ,ğ‘) atanevent,andthisisfromastate (ğœƒ,âˆ’ğ‘).
So what event rate would lead to an invariant distribution with the cor-
rectionğœƒ-marginal?Inansweringthisquestion,wefirstseethattheremay
bearangeofdifferenteventratesthatwouldleadtoavalidinvariantdistri-
bution.Notleastbecausemanypossibleinvariantdistributionswouldhave
ağœƒ-marginalasğœ‹(ğœƒ).So,ourfirststepistoattempttofindaratesuchthat
theinvariantdistributionhasğœƒindependentofğ‘.Denotesuchadistribution
by ğœ‹Ëœ(z) = ğœ‹(ğœƒ)ğœ‹ ğ‘(ğ‘),where ğœ‹ ğ‘ canbeanydistributionon {âˆ’1,1}.Then
substitutingthisinto(5.5),andusing
dğœ‹(ğœƒ) dlogğœ‹(ğœƒ)
= ğœ‹(ğœƒ)
dğœƒ dğœƒ
gives
dlogğœ‹(ğœƒ)
âˆ’ğ‘
dğœƒ
ğœ‹(ğœƒ)ğœ‹ ğ‘(ğ‘)+ğœ†(ğœƒ,âˆ’ğ‘)ğœ‹(ğœƒ)ğœ‹ ğ‘(âˆ’ğ‘)âˆ’ğœ†(ğœƒ,ğ‘)ğœ‹(ğœƒ)ğœ‹ ğ‘(ğ‘) =0.138 Continuous-TimeMCMC
Ifweconsiderğœƒ forwhichğœ‹(ğœƒ) > 0thenthisstates
dlogğœ‹(ğœƒ)
ğœ†(ğœƒ,âˆ’ğ‘)ğœ‹ ğ‘(âˆ’ğ‘)âˆ’ğœ†(ğœƒ,ğ‘)ğœ‹ ğ‘(ğ‘) = ğ‘
dğœƒ
ğœ‹ ğ‘(ğ‘). (5.6)
Ifweconsiderthesameargument,butforthestate (ğœƒ,âˆ’ğ‘),weget
dlogğœ‹(ğœƒ)
ğœ†(ğœƒ,ğ‘)ğœ‹ ğ‘(ğ‘)âˆ’ğœ†(ğœƒ,âˆ’ğ‘)ğœ‹ ğ‘(âˆ’ğ‘) =âˆ’ğ‘
dğœƒ
ğœ‹ ğ‘(âˆ’ğ‘). (5.7)
Adding(5.6)to(5.7)gives
dlogğœ‹(ğœƒ)
0=
dğœƒ
(cid:0)ğ‘ğœ‹ ğ‘(ğ‘)âˆ’ ğ‘ğœ‹ ğ‘(âˆ’ğ‘)(cid:1).
From this, we can conclude that the distribution ğœ‹ ğ‘ must satisfy ğœ‹ ğ‘(ğ‘) =
ğœ‹ ğ‘(âˆ’ğ‘), i.e. be the uniform distribution on {âˆ’1,1}. This makes sense
intuitively. The transition at the events only changes the velocity. Thus
invariancefortheğœƒ-componentcomesfromaveragingoutthedynamicsfor
different ğ‘,andthisrequiresthattheinvariantdistributionfor ğ‘hasamean
of zero.As ğ‘ can onlytake two values,this means itmust be theuniform
distribution. For the PDMPs that we consider later, that only change the
velocityateventsandhaveconstantvelocitydynamics,asimilarargument
holds that the invariant distribution for the velocity component must have
zeroasthemean.
If we now return to our question of what rates will lead to an invariant
distribution with ğœƒ-marginal equal to ğœ‹(ğœƒ), and substitute in (5.7) that
ğœ‹ ğ‘(ğ‘) = ğœ‹ ğ‘(âˆ’ğ‘) = 1/2 for ğ‘ âˆˆ {âˆ’1,1} then, by removing this common
factor,weget
dlogğœ‹(ğœƒ)
ğœ†(ğœƒ,ğ‘)âˆ’ğœ†(ğœƒ,âˆ’ğ‘) =âˆ’ğ‘ .
dğœƒ
Asolutiontothisequationistheratewespecifiedabove,
(cid:26) dlogğœ‹(ğœƒ)(cid:27)
ğœ†(ğœƒ,ğ‘) =max 0,âˆ’ğ‘ . (5.8)
dğœƒ
However, this is not the only solution. In fact, for any positive function
ğ›¾(ğœƒ) â‰¥ 0,therate
(cid:26) dlogğœ‹(ğœƒ)(cid:27)
max 0,âˆ’ğ‘ +ğ›¾(ğœƒ),
dğœƒ
willalsoleadtothesameinvariantdistribution.
Theratein(5.8)isthesmallestratethatwillleadtotherequiredinvariant
distribution. This is often called the canonical rate. Intuitively, there are
twoadvantagesofusingthecanonicalrate,asopposedtoalargerrate.The5.3 Continuous-timeMCMCviaPDMPs 139
firstisthatalargerratewillleadtomoreevents,andthusislikelytohavea
largercomputationalcostforsimulatingtheresultingPDMP.Thesecondis
thatalargerratewillleadtomorechangesinvelocityandwillre-introduce
therandomwalkbehaviourthatweweretryingtoavoidwithnon-reversible
MCMC. Thus, we would expect that using the canonical rate will lead to
bettermixing.
Afinalcommentontherateswearerequiredtouse,suchasthecanonical
rate, is that they depend on the target distribution ğœ‹(ğœƒ) only through the
derivativeofâˆ‡logğœ‹(ğœƒ).Thisisimportantasitmeansthatğœ‹(ğœƒ)onlyneeds
tobeknownuptoaconstantofproportionality,asiscommonlythecasefor
samplingfromtheposteriordistributioninBayesianstatistics,seeSection
1.1.5.
5.3 Continuous-timeMCMCviaPDMPs
In practice, we will want to use MCMC to sample a target density in Rğ‘‘.
VariousPDMPsgeneralisetheprocessintroducedintheprevioussectionto
ğ‘‘ > 1.WewilldescribethreesuchfamiliesofPDMPs,allofwhichreduce
totheunivariatePDMPofSection5.2.4ifğ‘‘ =1butdifferforğ‘‘ > 1.They
eachsharesomecommonfeatures,whichwewilldescribefirst.
Assumewewishtosamplefromğœ‹(ğœ½)whereğœ½isğ‘‘-dimensional.Thestate
ofourPDMPwillbezğ‘¡ = (ğœ½âŠ¤
ğ‘¡
,pâŠ¤
ğ‘¡
)âŠ¤,wherepğ‘¡ isalsoğ‘‘-dimensional.Aswe
usetheconventionthatvectorsarecolumnvectors,whendefiningzğ‘¡wehave
had to transpose these vectors to concatenate ğœ½ğ‘¡ and pğ‘¡. In the following,
to simplify notation, we will abuse this and just write zğ‘¡ = (ğœ½ğ‘¡,pğ‘¡). As
before,wecanthinkof ğœ½ asthepositioncomponentof thestate,andpas
thevelocity.
ThedeterministicdynamicsofthethreefamiliesofPDMPswillbethe
same:
(CV) Deterministic dynamics. The process evolves according to a Constant
Velocity(CV)model.
d dğœ½ ğ‘¡ğ‘¡ =pğ‘¡, d dp ğ‘¡ğ‘¡ =0, (5.9)
orinthenotationweusedtodefinePDMPs,ğ“ = (p,0).Thesolutionof
thedeterministicdynamicsare
ğš½(z,ğ‘¡) =ğš½((ğœ½,p),ğ‘¡) = (ğœ½ +ğ‘¡p,p). (5.10)
Furthermore, they also only allow the velocity component to change at
events.140 Continuous-TimeMCMC
ThethreefamiliesofPDMPswilldifferintermsofthepossiblevalues
for the velocity component, the event rate, and the transition kernel for
the velocity at events. In each case, these are chosen so that the invariant
distributionofthePDMPwillhaveağœ½-marginalthatisğœ‹(ğœ½),andforwhich
the velocity component, p, is independent of the position ğœ½. Throughout,
wewilldenotetheinvariantdistributionasğœ‹Ëœ(ğœ½,p) = ğœ‹(ğœ½)ğœ‹ (p),thoughas
p
mentioned,theformofğœ‹ willdifferbetweendifferentfamiliesofPDMPs.
p
Beforewedescribethethreefamiliesindetail,itishelpfultointroduce
some notation. We will use âˆ‡ to denote the gradient vector with respect
ğœ½
to ğœ½ only. This is the ğ‘‘-dimensional column vector whose entries are the
partial derivatives with respect to the components of ğœ½. The first term in
the equation for the invariant distribution of the PDMP (5.4) will be the
same for all three families as they share the same deterministic dynamics
andformoftheinvariantdistribution.Ignoringtheminussign,thistermis
âˆ‘ï¸2ğ‘‘ ğœ•ğœ™ ğ‘–( ğœ•z ğ‘§)ğœ‹Ëœ(z) =âˆ‘ï¸ğ‘‘ ğœ•ğ‘ ğ‘–ğœ‹ ğœ•Ëœ( ğœƒğœ½,p)
= ğœ‹
p(p)âˆ‘ï¸ğ‘‘
ğ‘
ğ‘–ğœ• ğœ•ğœ‹ ğœƒ(ğœ½)
ğ‘– ğ‘– ğ‘–
ğ‘–=1 ğ‘–=1 ğ‘–=1
âˆ‘ï¸ğ‘‘ ğœ•logğœ‹(ğœ½)
= ğœ‹ p(p) ğœ‹(ğœ½)ğ‘
ğ‘– ğœ•ğœƒ
ğ‘–
ğ‘–=1
= ğœ‹Ëœ(ğœ½,p) (pÂ·âˆ‡ logğœ‹(ğœ½)). (5.11)
ğœ½
Here,wehavefirstusedthatonlytheğœƒ ğ‘– componentsarechanging,andthen
usedğœ‹Ëœ(ğœ½,p) = ğœ‹(ğœ½)ğœ‹ (p).Thethirdstepcomesfromthedefinitionofthe
p
derivativeoflogğœ‹(ğœ½) intermsofthederivativeofğœ‹(ğœ½),andthefinalstep
fromusingğœ‹(ğœ½)ğœ‹ (p) = ğœ‹Ëœ(ğœ½,p).
p
5.3.1 DifferentSamplers
TheCoordinateSampler
PossiblythesimplestextensionofourunivariatePDMPtoonethatsamples
from a multi-dimensional distribution is the Coordinate Sampler of Wu
andRobert(2020).Forthissampler,thesetofpossiblevelocitiesisV =
cs
{Â±eğ‘–} ğ‘–ğ‘‘ =1whereeğ‘–istheğ‘–thunitvector.Thatis,eğ‘–istheunitvectorwhoseğ‘–th
componentis1,andallothercomponentsare0.Thus,thepossiblevelocities
correspond to moving in either a positive or negative direction along one
of the coordinate axes in Rğ‘‘. It can be viewed as a sampler which applies
the univariate PDMP dynamics along each coordinate in turn â€“ though
the order in which different coordinate directions are chosen is random.
Introducingaconstantrefreshrateğœ† r â‰¥ 0,thedynamicsofthecoordinate5.3 Continuous-timeMCMCviaPDMPs 141
samplerinvolvetheconstantvelocity(CV)deterministicdynamicstogether
with
(CS1) Eventrate.Eventsoccurwiththerate
ğœ† cs(ğœ½,p) =max{0,âˆ’pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)}+ğœ† r.
(CS2) Transitionkernelatevents.Atanevent,theprobabilityofswitchingtoa
newvelocitypâ€² âˆˆ V is
cs
1
ğ‘ cs((ğœ½,pâ€²)|(ğœ½,p)) =
ğ¶(ğœ½)
(max{0,pâ€²Â·âˆ‡ ğœ½logğœ‹(ğœ½)}+ğœ† r),
wherethenormalisingconstantis
ğ¶(ğœ½) = âˆ‘ï¸ (max{0,pâ€²Â·âˆ‡ ğœ½logğœ‹(ğœ½)}+ğœ† r) =2ğ‘‘ğœ† r+âˆ‘ï¸ğ‘‘ (cid:12) (cid:12) (cid:12) (cid:12)ğœ•lo ğœ•g ğœƒğœ‹ ğ‘–(ğœ½)(cid:12) (cid:12) (cid:12) (cid:12).
pâ€²âˆˆV
cs
ğ‘–=1
The refresh rate ğœ† r introduces additional random velocity switches. As
discussedabove,intuitivelyalargerrefreshratewillleadtomorerandom
walk behaviour and thus worse mixing. However, choosingğœ† r > 0 allows
forstrongertheoreticalresultsaboutthesampler,includingthatthesampler
will be irreducible unless e.g. ğœ‹(ğœ½) has disconnected regions where there
ispositiveprobability.
The invariant distribution of the Coordinate Sampler is given by the
followingresult.
Theorem 5.1 For any ğœ† r â‰¥ 0, the Coordinate Sampler, whose dynam-
ics are defined by (CV), (CS1) and (CS2), has an invariant distribution
ğœ‹Ëœ(ğœ½,p) = ğœ‹(ğœ½)ğœ‹ (p) whereğœ‹ istheuniformdistributionoverV .
p p cs
Proof We show this result by showing that (5.4) holds. To simplify ex-
pressions slightly, we will use the notation that for any scalar ğ‘ we have
{ğ‘} =max{0,ğ‘}.
+
Substitutingintheeventrateandtransitionkernelanddistributionğœ‹Ëœ,for
p âˆˆ V ,theleft-handsideof(5.4)is
cs
ğœ‹Ëœ(ğœ½,p)(âˆ’pÂ·âˆ‡ ğœ½logğœ‹(ğœ½))âˆ’ğœ‹Ëœ(ğœ½,p)({âˆ’pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r)
âˆ‘ï¸
+ ({âˆ’pâ€²Â·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r)ğœ‹Ëœ(ğœ½,pâ€²)ğ‘ cs((ğœ½,p)|(ğœ½,pâ€²)),
pâ€²âˆˆV
cs
wherewehaveused(5.9)tosimplifythefirstterm.Bythedefinitionof ğœ‹Ëœ,142 Continuous-TimeMCMC
wehaveğœ‹Ëœ(ğœ½,p) = ğœ‹Ëœ(ğœ½,pâ€²) forallp,pâ€² âˆˆ V .Thusthissimplifiesto
cs
âˆ’pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)âˆ’({âˆ’pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r)
âˆ‘ï¸
+ ({âˆ’pâ€²Â·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r)ğ‘ cs((ğœ½,p)|(ğœ½,pâ€²)).
pâ€²âˆˆV
cs
Nowusingthedefinitionofğ‘ ,wegetthatthefinalterminthisexpression
cs
is
âˆ‘ï¸
({âˆ’pâ€²Â·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r)ğ‘ cs((ğœ½,p)|(ğœ½,pâ€²))
pâ€²âˆˆV
cs
= âˆ‘ï¸ ({âˆ’pâ€²Â·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r) ğ¶(1
ğœ½)
(cid:0) {pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r(cid:1)
pâ€²âˆˆV
cs
= (cid:0) {pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r(cid:1) ğ¶(1
ğœ½)
âˆ‘ï¸ ({âˆ’pâ€²Â·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r)
pâ€²âˆˆV
cs
= (cid:0) {pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r(cid:1),
whereforthelastlineweuse
âˆ‘ï¸
ğ¶(ğœ½) = ({âˆ’pâ€²Â·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r).
pâ€²âˆˆV
cs
Substitutingintoourexpressionfortheleft-handsideof(5.4)gives
âˆ’pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)âˆ’({âˆ’pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r)+ (cid:0) {pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)} ++ğœ† r(cid:1)
=âˆ’pÂ·âˆ‡ logğœ‹(ğœ½)âˆ’({âˆ’pÂ·âˆ‡ logğœ‹(ğœ½)} )+ (cid:0) {pÂ·âˆ‡ logğœ‹(ğœ½)} (cid:1).
ğœ½ ğœ½ + ğœ½ +
By considering separately the cases where p Â· âˆ‡ logğœ‹(ğœ½) â‰¥ 0 and p Â·
ğœ½
âˆ‡ logğœ‹(ğœ½) < 0, it is simple to see that this expression for the left-hand
ğœ½
sideof(5.4)is0,asrequired. â–¡
TheZigâ€“ZagSampler
We now present the Zigâ€“Zag algorithm of Bierkens et al. (2019b). This
algorithmhasvelocitiesinV = {Â±1}ğ‘‘,andthestatemovessimultaneously
zz
alongeachcoordinateaxis,andthevelocitydetermineswhichdirectionit
moves for each axis. There are 2ğ‘‘ possible velocities, and if for example
ğ‘‘ = 2,thesewillbe (1,1), (1,âˆ’1), (âˆ’1,1) and (âˆ’1,âˆ’1).Atanevent,one
component of the velocity will change signs. The sampler gets its name
fromtheresultingdynamicsconsistingofzig-zagginglines.
TodefinethedynamicsoftheZigâ€“ZagSampleritishelpfultointroduce5.3 Continuous-timeMCMCviaPDMPs 143
coordinate-specificrates
(cid:26) ğœ•logğœ‹(ğœ½)(cid:27)
ğœ† ğ‘–(ğœ½,p) =max 0,âˆ’ğ‘
ğ‘– ğœ•ğœƒ
,
ğ‘–
whichisofthesameformasthecanonicalrateoftheunivariatePDMPif
we just vary thatğ‘–th component of ğœ½. We also introduce the functions ğ¹ ğ‘–,
forğ‘– =1,...,ğ‘‘,whichflipsthesignoftheğ‘–thcomponentofavector.Soif
pâ€² = ğ¹ ğ‘–(p) then ğ‘ ğ‘–â€² =âˆ’ğ‘ ğ‘– and,for ğ‘— â‰ ğ‘–, ğ‘â€² ğ‘— = ğ‘ ğ‘—.
ThePDMPprocessisdefinedbyCVdynamicstogetherwith
(ZZ1) Eventrate.Eventsoccurwiththerate
ğ‘‘
âˆ‘ï¸
ğœ† zz(ğœ½,p) = ğœ† ğ‘–(ğœ½,p).
ğ‘–=1
(ZZ2) Transitionkernelatevents.Ataneventtheprobabilitymassfunctionof
thetransitionis
ğ‘ zz(ğœ½,pâ€²|ğœ½,p) =
ğœ†ğœ† ğ‘–( (ğœ½ ğœ½, ,p p)
), forpâ€² = ğ¹ ğ‘–(p).
zz
Thusthepositionisunchanged,andweflipcomponentğ‘– ofthevelocity
withprobabilityproportionaltoğœ† ğ‘–(ğœ½,p).
Here we have presented the dynamics in terms of the rate of an event
and a transition probability for that event. However, by the superposition
property of Poisson processes that was discussed above, one can equiva-
lentlyrepresentthedynamicsintermsofğ‘‘possibleeventtypes.Eventtype
ğ‘– corresponds to flipping theğ‘–th component of the velocity, and this event
occurs,independentlyofotherevents,withrateğœ† ğ‘–.Thisviewofthedynam-
icsoftheZigâ€“Zagalgorithmisoftenusedinalgorithmicimplementations
tosamplerealisationsoftheprocess.
We can relate the Zigâ€“Zag Sampler to a limiting version of the guided
randomwalkalgorithmofGustafson(1998)inasimilarwaytotheargument
presented in Section 5.1. The Zigâ€“Zag Sampler is the limit of an MCMC
algorithmthatrepeatedlyappliesoneiterationoftheguidedrandomwalk
algorithmtoeachcomponentofğœ½ inturn.
ThefollowingresultgivestheinvariantdistributionofthePDMPprocess.
Theorem 5.2 The Zigâ€“Zag Sampler, defined by (CV), (ZZ1) and (ZZ2)
has invariant distribution ğœ‹Ëœ(ğœ½,p) = ğœ‹(ğœ½)ğœ‹ (p) where ğœ‹ is the uniform
p p
distributionoverV .
zz144 Continuous-TimeMCMC
Proof Again,weshowthisresultbyshowingthat(5.4)holds.Bythesame
argument as in the first step of the proof of Theorem 5.1, if we substitute
the form of ğœ‹Ëœ and the definition of the dynamics of the Zigâ€“Zag Sampler
intotheleft-handsideof(5.4)wegetthatthisisproportionalto
ğ‘‘ ğ‘‘
âˆ‘ï¸ âˆ‘ï¸
âˆ’pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)âˆ’ ğœ† ğ‘–(ğœ½,p)+ ğœ† ğ‘–(ğœ½,ğ¹ ğ‘–(p)). (5.12)
ğ‘–=1 ğ‘–=1
The first term relates to the change in probability mass due to the deter-
ministicdynamicsandisthesametermasappearedinthecalculationsfor
the Coordinate Sampler. The second term is the rate of leaving the state
(ğœ½,p),andthethirdistherateofmovingtothestate(ğœ½,p)whichhastobe
fromastateoftheform (ğœ½,ğ¹ ğ‘–(p)).AsintheargumentfortheCoordinate
Sampler,wehaveremovedtheğœ‹Ëœ termsasthesearethesamefor (ğœ½,p) and
(ğœ½,ğ¹ ğ‘–(p)) forallğ‘–.
Tosimplifythisexpressionweuse
ğœ•logğœ‹(ğœ½)
âˆ’ğœ† ğ‘–(ğœ½,p)+ğœ†(ğœ½,ğ¹ ğ‘–(p)) = ğ‘
ğ‘– ğœ•ğœƒ
,
ğ‘–
and
âˆ‘ï¸ğ‘‘ ğœ•logğœ‹(ğœ½)
pÂ·âˆ‡ ğœ½logğœ‹(ğœ½) = ğ‘
ğ‘– ğœ•ğœƒ
.
ğ‘–
ğ‘–=1
Thus(5.12)becomes
âˆ‘ï¸ğ‘‘ (cid:18) ğœ•logğœ‹(ğœ½) ğœ•logğœ‹(ğœ½)(cid:19)
âˆ’ğ‘
ğ‘– ğœ•ğœƒ
+ ğ‘
ğ‘– ğœ•ğœƒ
=0,
ğ‘– ğ‘–
ğ‘–=1
asrequired. â–¡
BouncyParticleSampler
ThethirdsamplerthatweintroduceistheBouncyParticleSampler,which
was first introduced as a way of simulating particle systems in statistical
mechanics(PetersanddeWith,2012),butwasthenproposedasageneral
sampling algorithm by Bouchard-CoË†teÂ´ et al. (2018). It can be derived as
a continuous-time limit of the Discrete Bouncy Particle Sampler that was
introducedinSection4.4.Likethatalgorithm,thetransitionsateventsare
reflectionsofthevelocityinthecontoursoflogğœ‹(ğœ½).
Forağ‘‘-dimensionalvectorg,letg=g/(gÂ·g)1/2betheunitvectorinthe
(cid:98)
directionofg.AsinSection4.4,definethefunctionR (p) =pâˆ’2(pÂ·g)g,
g (cid:98) (cid:98)
tobethereflectionofpinthehyperplaneperpendiculartog.Animportant5.3 Continuous-timeMCMCviaPDMPs 145
propertyofareflection,thatwewillusebelow,isthatitpreservesthesize
ofthevector.Thatis
(cid:0) (cid:1) (cid:0) (cid:1)
R (p)Â·R (p) = pâˆ’2(pÂ·g) g Â· pâˆ’2(pÂ·g) g
g g (cid:98) (cid:98) (cid:98) (cid:98)
=pÂ·pâˆ’4(pÂ·g) pÂ·g+4(pÂ·g)2gÂ·g
(cid:98) (cid:98) (cid:98) (cid:98) (cid:98)
=pÂ·pâˆ’4(pÂ·g)2+4(pÂ·g)2 =pÂ·p,
(cid:98) (cid:98)
whereforthepenultimateequalitywehaveusedthatgisaunitvector.Also,
(cid:98)
reflectionisaninvolution,thatisR (R (p)) =p.Toseethis
g g
(cid:0) (cid:1)
R (R (p)) = R pâˆ’2(pÂ·g) g
g g g (cid:98) (cid:98)
=pâˆ’2(pÂ·g) gâˆ’2{(pâˆ’2(pÂ·g) g)Â·g}g
(cid:98) (cid:98) (cid:98) (cid:98) (cid:98) (cid:98)
=pâˆ’2(pÂ·g) gâˆ’2{pÂ·gâˆ’2(pÂ·g)}g
(cid:98) (cid:98) (cid:98) (cid:98) (cid:98)
=pâˆ’2(pÂ·g) g+2(pÂ·g) g=p.
(cid:98) (cid:98) (cid:98) (cid:98)
TherearetwoversionsoftheBouncyParticleSampler,thatdifferonlyin
thesetofpossiblevelocities.Wewillmainlyworkwiththeversionwhere
the velocities take values in Rğ‘‘, and have an invariant distribution that is
standardnormal.Foranyrefreshrateğœ† r â‰¥ 0,theBouncyParticleSampler
inthiscaseisaPDMPwithconstantvelocitydynamics(CV)and
(BPS1) Eventrate.Eventsoccuratarate
ğœ† BPS(ğœ½,p) =max{0,âˆ’pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)}+ğœ† r.
(BPS2) Transition at events. At an event with probability 1 âˆ’ ğœ† r/ğœ† BPS(ğœ½,p),
reflect the velocity in the hyperplane perpendicular to âˆ‡ logğœ‹(ğœ½), that
ğœ½
isthenewvelocityis
pâ€² = R (p), withg= âˆ‡ logğœ‹(ğœ½);
g ğœ½
otherwisesampleanewvelocity,pâ€²fromastandardnormaldistribution.
Thepositionisunchangedatanevent.
AswiththeZigâ€“ZagSampler,wecaninterpretthedynamicsintermsof
events of different types. In this case, we have reflection events that occur
withratemax{0,âˆ’pÂ·âˆ‡ ğœ½logğœ‹(ğœ½)},andrefresheventsthatoccurwithrateğœ† r.
Ifğœ† r > 0thenBouchard-CoË†teÂ´ etal.(2018)provethattheresultingprocess
isirreducible,assumingweakconditionson ğœ‹(ğœ½).Furthermore,theygive
anexamplewhereifğœ† r = 0,thesamplerwillbereducible,andthisoccurs
ifweweretousetheBouncyParticleSamplertosamplefromaGaussian
distribution.AsmanytargetdistributionscanbeclosetoGaussian,wemay
haveareduciblesampler,oronewhichmixesslowlyifğœ† r =0.Inpractice,
tuningğœ† r isimportant,asnotonlycanthesamplermixpoorlyforğœ† r â‰ˆ 0,146 Continuous-TimeMCMC
butifwechooseğœ† rtoolargeitwillintroducerandomwalkbehaviourwhich
willalsoleadtopoormixing.Wewillreturntothisissuelaterinthissection
andinSection5.3.3
Thealternativeversionofthealgorithmhasvelocitiesthatlieontheunit
ğ‘‘-dimensional hypersphere. The only difference in terms of the dynamics
is that at a refresh event, we sample a new velocity from the uniform
distributiononthesphereratherthanfromastandardnormaldistribution.
Furthermore,thereareextensionsoftheBouncyParticleSamplerthatonly
partially refresh the velocity. That is at a refresh event we sample a new
velocity from a Markov kernel which has a standard normal distribution
(or for the alternative version a uniform distribution on the sphere) as its
stationarydistribution.
ThefollowingresultgivestheinvariantdistributionoftheBouncyParti-
cleSampler.
Theorem5.3 Foranyğœ† r â‰¥ 0,theBouncyParticleSampler,whosedynam-
icsaredefinedby(CV),(BPS1)and(BPS2),hasaninvariantdistribution
ğœ‹Ëœ(ğœ½,p) = ğœ‹(ğœ½)ğœ‹ (p) where ğœ‹ isthedensityofa ğ‘‘-dimensionalstandard
p p
normaldistribution.
Proof AsourpresentationofPDMPshasfocussedondiscretetransitions
atevents,wewillprovetheresultforğœ† r = 0only.Theextensiontoğœ† r > 0
isstraightforward,astheadditionalrefreshratestriviallykeepğœ‹Ëœ invariant.
Asshownabove,areflectiondoesnotchangethelengthofavector.As
fortheproposedinvariantdistribution,ğœ‹ (p)dependsonponlythroughits
p
length,wehaveğœ‹ (p) = ğœ‹ (R (p)),foranydirectionofreflectiong.Thus
p p g
areflectioneventdoesnotchangethevalueofğœ‹Ëœ.Thismeanswecanusethe
same argument as at the start of the proofs of Theorem 5.1 and Theorem
5.2togetthattheleft-handsideof(5.4)isproportionalto
âˆ’pÂ·âˆ‡ logğœ‹(ğœ½)+ğœ† (ğœ½,R (p))âˆ’ğœ† (ğœ½,p), (5.13)
ğœ½ BPS g BPS
wheretosimplifynotationwehaveusedg= âˆ‡ logğœ‹(ğœ½).Themiddleterm
ğœ½
is the rate of transitioning to state (ğœ½,p) and uses, as shown above, that
reflectionsareinvolutions,soitisthestate(ğœ½,R (p))thatwilltransitionto
g
(ğœ½,p) atareflectionevent.Substitutingintheformofğœ† ,andusingthe
BPS
definitionofg,wehave
ğœ† (ğœ½,R (p))âˆ’ğœ† (ğœ½,p) =max{0,R (p)Â·g}âˆ’max{0,pÂ·g}.
BPS g BPS g
Now
R (p)Â·g= (pâˆ’2(pÂ·g)g)Â·g=pÂ·gâˆ’2(pÂ·g)(gÂ·g) =pÂ·gâˆ’2(pÂ·g)(gÂ·g),
g (cid:98) (cid:98) (cid:98) (cid:98) (cid:98) (cid:98)5.3 Continuous-timeMCMCviaPDMPs 147
wherethelastequalityfollowsasgisproportionaltog.Asgisaunitvector,
(cid:98) (cid:98)
wehaveR (p)Â·g=âˆ’pÂ·g.Substitutinggives
g
ğœ† (ğœ½,R (p))âˆ’ğœ† (ğœ½,p) =max{0,âˆ’pÂ·g}âˆ’max{0,pÂ·g} =âˆ’pÂ·g.
BPS g BPS
By definition of g this is just pÂ·âˆ‡ logğœ‹(ğœ½). Substituting this into (5.13)
ğœ½
weseethattheleft-handsideof(5.4)is0asrequired.
â–¡
Example:SamplingfromaGaussianTarget
To gain an initial understanding of these algorithms in practice, how they
differ from each other and how they compare to HMC, we will consider
their implementation for sampling from a Gaussian distribution. This is
an example where all methods can be implemented exactly and enables a
simplecomparisonofthedynamicsofthedifferentsamplers.
TosimplifynotationwewillassumeourtargetGaussiandistributionhas
ameanzero.Thiscanbeassumedwithoutlossofgeneralityintermsofthe
behaviour of the samplers, as we can re-centre any Gaussian distribution
withnon-zeromeanandthiswouldnotchangethesamplersâ€™dynamics.A
mean-zeroGaussiandistributioniscommonlyparameterisedbyitscovari-
ance matrix, ğšº say, but in terms of its density function, it is easier to use
theprecisionmatrix,whichistheinverseofthecovariancematrix.Wewill
denotetheprecisionmatrixbyQ = ğšºâˆ’1.Weassumethatğšº,andhenceQ,
ispositive-definite.Thenuptoanadditiveconstant,wehave
1
logğœ‹(ğœ½) =âˆ’ ğœ½âŠ¤Qğœ½.
2
TheratesofthePDMPsamplersdependonğœ‹throughâˆ’âˆ‡ logğœ‹(ğœ½),which
ğœ½
fortheGaussiantargetisQğœ½.
Before showing the output from the different PDMP samplers for this
model, we will describe an approach to simulating the PDMPs. Each of
the three PDMPs introduced in the previous section can be viewed as
having multiple types of event, with each event having a deterministic
transition.FortheZigâ€“ZagSampler,wehaveoneeventassociatedwitheach
componentofğœ½,andthatflipstheassociatedcomponentofthevelocity.For
the Bouncy Particle Sampler, and the Coordinate Sampler, there are two
events,oneofwhichisarefreshofthevelocity.Ourapproachtosimulating
these PDMPs is to use the idea of superposition, that is we will simulate
the time for each of the possible events, find which occurs first, and then
thistypeofeventwithitsassociatedtimeisthenexteventforourPDMP.
As described in Section 5.2.2, to simulate times of events we need,148 Continuous-TimeMCMC
foreachtypeofevent,tocalculatetherateofthetimeuntilthenextevent,
giventhecurrentstate.Wewilldescribehowtocalculatethisforthebounce
event of the Bouncy Particle Sampler, and for a flip event in the Zigâ€“Zag
Sampler.Simulatingtherefresheventsistrivial,andsimulatingtheevents
oftheCoordinateSamplerfollowsbysimilararguments.
LetthecurrentstateofourPDMPbez= (ğœ½,p),andletğœ†Ëœ (ğ‘¡)betherate
z
atwhichaneventoccursintermsofthefuturetimeğ‘¡.Wewillfirstconsider
thebounceeventoftheBouncyParticleSampler.Letthecurrenttimebeğ‘ ,
sozğ‘  =z,then
ğœ†Ëœ z(ğ‘¡) =max{0,pğ‘ +ğ‘¡ Â·(âˆ’âˆ‡ ğœ½logğœ‹(ğœ½ğ‘¡+ğ‘ )} =max{0,pâŠ¤ ğ‘ +ğ‘¡Qğœ½ğ‘ +ğ‘¡}
=max{0,pâŠ¤Q(ğœ½ +ğ‘¡p)} =max{0,pâŠ¤Qğœ½ +ğ‘¡pâŠ¤Qp}.
Herewehaveusedthedefinitionofğœ†Ëœ z(ğ‘¡),substitutedinlogğœ‹(ğœ½ğ‘¡+ğ‘ )forour
targetandthenusedthefactthatupuntilthenextevent,pğ‘ +ğ‘¡ =pğ‘  =pand
ğœ½ğ‘ +ğ‘¡ = ğœ½ğ‘  +ğ‘¡pğ‘  = ğœ½ +ğ‘¡p.
Weareviewingğœ†Ëœ (ğ‘¡) asafunctionofthefurthertimeuntiltheevent,ğ‘¡.
z
We can see that ğœ†Ëœ is the maximum of zero and a linear function of ğ‘¡, and
defining ğ‘ = pâŠ¤Qğœ½ and ğ‘ = pâŠ¤Qp, the linear function is equal to ğ‘ +ğ‘ğ‘¡.
Furthermore,asQispositive-definitewehaveğ‘ > 0.Forthisrate,wecan
simulate event times directly using Algorithm 7. To do this, we need to
solveâˆ« ğ‘¡ ğœ†Ëœ (ğ‘¢)dğ‘¢ = ğ‘¤.Therearetwocasesfortheintegral.First,ifğ‘ > 0,
0 z
thenğœ†Ëœ (ğ‘¢) = ğ‘+ğ‘ğ‘¢forallğ‘¢ > 0,so
z
âˆ« ğ‘¡ âˆ« ğ‘¡ ğ‘ğ‘¡2
ğœ†Ëœ (ğ‘¢)dğ‘¢ = (ğ‘+ğ‘ğ‘¢)dğ‘¢ = ğ‘ğ‘¡+ ,
z 2
0 0
âˆš
andthisisequaltoğ‘¤ > 0ifğ‘¡ =âˆ’ğ‘/ğ‘+ ğ‘2+2ğ‘¤ğ‘/ğ‘.Ifğ‘ < 0thenğ‘+ğ‘ğ‘¡
isonlypositiveforğ‘¡ > |ğ‘|/ğ‘,thusforsuchğ‘¡
âˆ« ğ‘¡ âˆ« ğ‘¡ âˆ« ğ‘¡âˆ’|ğ‘|/ğ‘ ğ‘(ğ‘¡âˆ’|ğ‘|/ğ‘)2
ğœ†Ëœ (ğ‘¢)dğ‘¢ = (ğ‘+ğ‘ğ‘¢)dğ‘¢ = ğ‘ğ‘¢â€²2dğ‘¢â€² = .
z 2
0 |ğ‘|/ğ‘ 0
Thisisequaltoğ‘¤ > 0whenğ‘¡ = |ğ‘|/ğ‘+âˆšï¸ 2ğ‘¤/ğ‘.
TheresultingalgorithmforoneiterationoftheBouncyParticleSampler
isgiveninAlgorithm9.Thealgorithmsimulatesthetimeofarefreshevent
and a bounce event. It sets the time of the next event to be the smaller of
thesetwotimes,andupdatesthepositionofthestate.Then,dependingon
which type of event occurred first, it updates the velocity. For a refresh
event,thisinvolvessimulatingfromthesamplerâ€™sinvariantdistributionfor
thevelocity,whichdependingonthetypeofBouncyParticleSamplercan
be either a standard Gaussian distribution or the uniform distribution on5.3 Continuous-timeMCMCviaPDMPs 149
the unit hyper-sphere. For a bounce event, the velocity is reflected in the
hyperplaneperpendiculartoâˆ’âˆ‡logğœ‹(ğœ½) atthecurrentposition ğœ½â€²,which
forourmodelisQğœ½â€².
Algorithm9:BouncyParticleSampler:GaussianTarget
Input:PrecisionMatrix,Q,currentstate (ğœ½,p),refreshrateğœ† r > 0
Calculateğ‘ =pâŠ¤Qğœ½ andğ‘ =pâŠ¤Qp.
Simulateğ‘¤ andğ‘¤ ,independentrealisationsofastandard
1 2
exponentialrandomvariable.
Calculatetimeuntilarefresheventğœ
1
= ğ‘¤ 1/ğœ† r.
Calculatetimeuntilabounceevent:ifğ‘ < 0ğœ =âˆšï¸ 2ğ‘¤ /ğ‘+|ğ‘|/ğ‘,
2 2
âˆšï¸
otherwiseğœ =âˆ’ğ‘/ğ‘+ ğ‘2+2ğ‘¤ ğ‘/ğ‘.
2 2
Calculateeventtimeğ‘¡ =min{ğœ ,ğœ }.
1 2
Updatepositionğœ½â€² = ğœ½ =ğ‘¡p.
Decidedoneventtypeandupdatevelocity:
if ğœ < ğœ then
1 2
Refreshevent.Simulatepâ€² fromitsinvariantdistribution.
else
Bounceevent.Set
Qğœ½â€²
pâ€² =pâˆ’2(pâŠ¤Qğœ½â€²) .
âˆšï¸
ğœ½â€²âŠ¤QâŠ¤Qğœ½â€²
end
Output:Timetonexteventğ‘¡,andnewstate (ğœ½â€²,pâ€²)
A similar derivation is possible for the Zigâ€“Zag Sampler. The only
differenceisthatthefliprateoftheğ‘–thcomponentof ğ‘ ğ‘– is
max{0,âˆ’ğ‘ ğ‘–(âˆ‡ ğœ½logğœ‹(ğœ½)) ğ‘–} =max{0,ğ‘ ğ‘–(Qğœ½) ğ‘–},
where we write, for example, (Qğœ½) ğ‘– to denote the ğ‘–th component of Qğœ½.
Thus,theassociatedrateasafunctionoftimeuntilthisevent,ifthecurrent
stateofz= (ğœ½,p),is
ğœ†Ëœ z(ğ‘–)(ğ‘¡) =max{0,ğ‘ ğ‘–[Q(ğœ½ +ğ‘¡p)] ğ‘–} =max{0,ğ‘ ğ‘–(Qğœ½)
ğ‘–
+ğ‘¡ğ‘ ğ‘–(Qp) ğ‘–}.
This again is the maximum of 0 and a linear function of ğ‘¡ and can be
simulatedasdescribedabove.Asabove,wecansetğœ†Ëœ(ğ‘–)(ğ‘¡) =max{0,ğ‘+ğ‘ğ‘¡}
z
butnowwithğ‘ = ğ‘ ğ‘–(Qğœ½) ğ‘– and ğ‘ = ğ‘ ğ‘–(Qp) ğ‘–.Theonlydifferenceisthatin
thiscase, ğ‘ canbenegative.If ğ‘ < 0and ğ‘ < 0,thenthiseventcannever150 Continuous-TimeMCMC
happen.Ifğ‘ > 0,thenaneventcanhappenforğ‘¡ < ğ‘/|ğ‘|.Inthiscase
âˆ« ğ‘¡ ğ‘ğ‘¡2
ğ‘¤ = (ğ‘+ğ‘ğ‘¢)dğ‘¢ â‡’ ğ‘¤ = ğ‘ğ‘¡+ .
2
0
This has a solution for ğ‘¡ > 0 only if ğ‘¤ â‰¤ ğ‘2/(2|ğ‘|), in which case ğ‘¡ =
âˆš
âˆ’ğ‘/ğ‘ + ğ‘2+2ğ‘¤ğ‘/ğ‘. If ğ‘¤ > ğ‘2/(2|ğ‘|) then this event does not happen.
If an event cannot or does not happen, then algorithmically we set the
associatedeventtimetoinfinity.
AnalgorithmforoneiterationoftheZigâ€“ZagSamplerisgiveninAlgo-
rithm10.IthasasimilarformastheBouncyParticleSampler.Wecalculate
theeventtimeforeachtypeofeventâ€“thoughduetothefourpossiblecases
we have not given the formulae for calculating the event times within the
algorithm. We then set the event time to the smallest of these times and
update the position. Finally, the event type is calculated and we apply the
appropriate transition to the velocity, remembering that ğ¹ ğ‘–(p) flips theğ‘–th
componentofthevectorp.
Algorithm10:Zigâ€“ZagSampler:GaussianTarget
Input:PrecisionMatrix,Q,currentstate (ğœ½,p),refreshrateğœ† r > 0
forğ‘– =1,...,ğ‘‘ do
Calculateğ‘ ğ‘– = ğ‘ ğ‘–(Qğœ½) ğ‘– andğ‘ ğ‘– = ğ‘ ğ‘–(Qp) ğ‘–.
Simulateğ‘¤ ğ‘–,arealisationofastandardexponentialrandom
variable.
Calculateğœ ğ‘–,theeventtimeforaflipoftheğ‘–thcomponentofp.
end
Calculateeventtimeğ‘¡ =minğ‘–=1,...,ğ‘‘{ğœ ğ‘–}.
Updatepositionğœ½â€² = ğœ½ =ğ‘¡p.
Decideoneventtype,ğ‘–âˆ— =argmin{ğœ ğ‘–}.
Updatevelocitypâ€² = ğ¹ ğ‘–âˆ—(p).
Output:Timetonexteventğ‘¡,andnewstate (ğœ½â€²,pâ€²)
To gain some intuition of the properties of these PDMP algorithms,
wewillfirstlookqualitativelyattheoutputofrunningthealgorithmsfora
bivariateGaussianâ€“aswecanplottherealisationsfromthepathsgenerated
bythepositioncomponentofthePDMPs.First,welookattheimportance
of the refresh rate with the Bouncy Particle Sampler. To most clearly see
thepotentialissuesforthissampler,itishelpfultoobserveitsamplingfrom
a target with uncorrelated, equal variance components. See Figure 5.2 for
outputfromtheBouncyParticleSamplerfordifferentrefreshrates.5.3 Continuous-timeMCMCviaPDMPs 151
   
   
   
   
   
   
   
           
Î¸(1) Î¸(1)
   
   
   
   
   
   
   
           
Î¸(1) Î¸(1)
Figure5.2 Plotsofrealisationsofthetrajectoryorpathofthe
BouncyParticleSamplerwhensamplingfromastandard(i.e.
uncorrelated,equalvariance)bivariateGaussiandistribution.
Trajectoriesshownfornorefreshevents(topleft),ğœ†
r
=0.1(top
right),ğœ† r =1(bottomleft)andğœ† r =10(topright).Theheatmap
showsthelogposteriordensityofthetargetineachcase.
Thetop-leftplotshowsthetrajectoryifwedonotuseanyrefreshevents.
Wecanclearlyseeevidenceofthesamplerbeingreducibleâ€“asthesampler
doesnotenteralargeregionaroundthemode.Bouchard-CoË†teÂ´etal.(2018)
provethattheBouncyParticleSamplerisinfactreducibleforthisexample.
Furthermore,theyshowthatthisisavoidedifweuseanynon-zerorefresh
rate, and if we do so the sampler will converge to the target distribution.
However,wegetverydifferentbehaviourfordifferentvaluesoftherefresh
rate,asshownintheremainingplotsofFigure5.2.Asmallrateproducesa
)2(Î¸
)2(Î¸
)2(Î¸
)2(Î¸152 Continuous-TimeMCMC
sampler, that whilst irreducible, has poor mixing properties (see top-right
plot).Thesamplerhaslongperiodsbetweenrefreshevents,andforeachof
these periods, there are regions of the state space that the sampler cannot
reach.Toolargearefreshratemeansthatthesamplershowsrandom-walk
behaviour, which can also adversely affect its mixing (see bottom-right
plot). Tuning of the refresh rate to a good intermediate value can result
in a sampler that mixes well and avoids this random-walk behaviour (see
bottom-leftplot).Wewillreturntohowtotunetherefreshratelater.Finally,
whilsttheCoordinateSampleralsohasrefreshevents,itdoesnotsufferfrom
thesameproblemsastheBouncyParticleSampler,andwillbeirreducible
evenifğœ† r =0.
We now compare the outputs of the three different PDMP samplers,
withtheBouncyParticleSamplerusinganappropriatelytunedrefreshrate,
ğœ† r =1.TheseareshowninFigure5.3togetherwiththeoutputfromHMC.
At this stage, there are two main points we wish to make. First, one can
seethequalitativesimilaritiesanddifferencesbetweenthedifferentPDMP
samplers.Eachsamplerexploresğœ½spacewithstraight-linetrajectories,and
they all have the property that they continue in the same direction whilst
moving to areas of higher probability density â€“ though for the Zigâ€“Zag
Sampler, this has to be interpreted separately for each axis component.
However,thetrajectoriesthemselvesareverydifferentduetothedifferent
possible velocities and transitions. The Coordinate Sampler explores the
posterior by exploring a single component of ğœ½ at a time. This has some
similarities with a Gibbs sampler (see Section 2.1.1), and intuition from
resultsonmixingofGibbssamplerssuggestthatthissamplerwillperform
best when there is no strong correlation between the components of ğœ½.
TheZigâ€“ZagSamplerhastrajectoriesconsistingofdiagonallines,andthe
transitions that flip a single component of the velocity lead to trajectories
that look like zig-zags, which gives the sampler its name. Finally, the
BouncyParticleSamplercanhavetrajectoriesthatexplorethespaceinany
direction.
Second, it is interesting to compare PDMP samplers with HMC (see
bottom-rightplot).Forthismodel,wecansolvetheHamiltoniandynamics
foreachproposaloftheHMCalgorithmexactly,andthuswealwayswillac-
ceptaproposal.ThetrajectoriesoftheHamiltoniandynamicsareelliptical,
ascomparedtothestraight-linesegmentsofourPDMPsamplers.However,
the main difference is that the output of a PDMP sampler is a continuous
path, whilst for HMC, we obtain a set of points. For non-Gaussian target
distributions,theHMCsamplerwillnotalwaysaccepttheproposalwhich
canleadtoworsemixing.Insuchcases,whilstwecannotdirectlysample5.3 Continuous-timeMCMCviaPDMPs 153
   
   
   
   
   
   
   
           
Î¸(1) Î¸(1)
   
   
   
   
   
   
   
           
Î¸(1) Î¸(1)
Figure5.3 ComparisonofthreePDMPalgorithmsandHMCfor
samplingfromabivariateGaussianwithunitmarginalvariances
andcorrelationof0.5.Realisationsofthetrajectories(bluelines)
oftheCoordinateSampler(topleft),theZigâ€“ZagSampler(top
right)andtheBouncyParticleSamplerwithğœ† r =1(bottomleft).
TrajectoriesofHamiltoniandynamics(line)andthesampled
points(dots)fromHMC(bottomright).Theheatmapshowsthe
logposteriordensityofthetargetineachcase.
thetrajectoriesofthePDMPsamplers,thisonlyimpactsthecomputational
cost of simulation, rather than the output or the mixing properties of the
sampler.
)2(Î¸
)2(Î¸
)2(Î¸
)2(Î¸154 Continuous-TimeMCMC
5.3.2 UseofPDMPOutput
SimulatingaPDMP,asdescribedinSection5.2.2,producesaskeletonof
thesamplepathoftheprocess.Assumethatwehavesimulatedtheprocess
uptosometimeğ‘‡.Wewilldenotethisskeletonbytheset{ğœ ğ‘–,(ğœ½ğœ ğ‘–,pğœ ğ‘–)}ğ‘› ğ‘˜=+1
0
that gives the initial state of the process, with ğœ = 0, the time and state
0
aftereachevent,for ğ‘˜ = 1,...,ğ‘›,andthefinalstateoftheprocessattime
ğœ
ğ‘›+1
=ğ‘‡.Howdoweusethisoutputtoapproximatethetargetdistribution?
For any Monte Carlo method, an approximation to the target distribu-
tion, ğœ‹(ğœ½) comes from the ability to estimate the expectation for arbitrary
functions of ğœ½ with respect to ğœ‹. Thus consider estimating E ğœ‹ [â„(ğœ½)] for
some function â„ for which this expectation exists. First, we describe how
wedonotestimatethisexpectation!Wecannotjustusethesampleaverage
of â„(Â·) at the skeleton points for ğœ½, even after allowing some burn-in. In
general, the skeleton points will not be sampled from ğœ‹ at stationarity, as
theywillbebiasedtowardsvalueswherethereisalargeaveragerateofan
eventoccurring.
Instead,weneedtoestimatetheexpectationwithrespecttothecontinuous-
timesamplepath,afterallowingforasuitableburn-in.Therearetwoways
ofdoingthis.Assumewechoosetheburn-intobesometimeğ‘†.Thenone
approach is to calculate the average value of the integral of â„(ğœ½ğ‘¡) for our
sample path for ğ‘† < ğ‘¡ â‰¤ ğ‘‡. This can be calculated from the skeleton as
follows. First, we work out the value of ğœ½ğ‘† for our sample path. This is
possiblebyfindingğ‘™ suchthatğœ ğ‘™ â‰¤ ğ‘† < ğœ ğ‘™+1,andusinglinearinterpolation
ğœ âˆ’ğ‘† ğ‘†âˆ’ğœ
ğœ½ğ‘† = ğœğ‘™+1
âˆ’ğœ
ğœ½ğ‘™ +
ğœ
âˆ’ğ‘™
ğœ
ğœ½ğ‘™.
ğ‘™+1 ğ‘™ ğ‘™+1 ğ‘™
Thenourestimatorcanbecalculatedas
EË† ğœ‹ [â„(ğœ½)] = ğ‘‡ âˆ’1 ğ‘† (cid:18)âˆ« ğœ ğ‘™+1 â„(cid:18) ğœ½ğ‘† +(ğ‘¡âˆ’ğ‘†)ğœ½ ğœğœ ğ‘™+1 âˆ’ âˆ’ğœ½ ğ‘†ğ‘†(cid:19) dğ‘¡
ğ‘† ğ‘™+1
+ âˆ‘ï¸ğ¾ âˆ« ğœ ğ‘˜+1 â„(cid:18) ğœ½ğœ
ğ‘˜
+(ğ‘¡âˆ’ğœ ğ‘˜)ğœ½ ğœğœ ğ‘˜+1 âˆ’ âˆ’ğœ½ ğœğœ ğ‘˜(cid:19) dğ‘¡(cid:33)
ğ‘˜=ğ‘™+1 ğœ ğ‘˜ ğ‘˜+1 ğ‘˜
Thisestimatorisonlypracticalifwecananalyticallycalculatetheintegrals
alongthelinearsegmentsofthepath.Amoregeneral,andarguablysimpler
approachistoevaluate ğœ½ğ‘¡ at ğ‘ evenlyspacedpointsbetween ğ‘† andğ‘‡ and
then use standard Monte Carlo averages with respect to this set of values.
Thatis,letğ›¿ = (ğ‘‡ âˆ’ğ‘†)/ğ‘ andusinglinearinterpolationasaboveevaluate5.3 Continuous-timeMCMCviaPDMPs 155
ğœ½ğ‘†+ğ‘—ğ›¿ for ğ‘— =1,...,ğ‘.ThenourestimatorofE ğœ‹ [â„(ğœ½)] wouldnowbe
ğ‘
1 âˆ‘ï¸
EË†
ğœ‹
[â„(ğœ½)] =
ğ‘
â„(ğœ½ğ‘†+ğ‘—ğ›¿).
ğ‘—=1
One advantage of this approach is the final output is similar to that for
standardMCMC,whicheasescomparisonandenablesustousemethodsfor
assessingtheaccuracyofstandardMCMCestimatorssuchastheintegrated
auto-correlationtimeandeffectivesamplesize(seeSection1.3.2).
5.3.3 ComparisonofSamplers
Bierkensetal.(2022)examinesthemixingpropertiesoftheBouncyParticle
Sampler and the Zigâ€“Zag Sampler in the limit as the dimension of the
space, ğ‘‘ â†’ âˆ, for the special case where the posterior of interest is a ğ‘‘-
dimensional standard normal distribution. In related work, Bierkens et al.
(2023a)investigatesfinite-dimensionalnormaltargetswheresomeprincipal
components have a much smaller length scale than others. We summarise
thefindingsofthesetwopapersandprovidesomeintuitionforthem.
Tocomparethesamplers,weneedtoconsiderboththeircomputational
cost for simulating a trajectory of fixed duration, and how the mixing of
the process depends on time. First, consider the computational cost, and
the intensity of bounce events on a ğ‘‘-dimensional standard normal target,
so that at stationarity âˆ‡logğœ‹(ğœ½) = âˆ’ğœ½. The momentum for the Zigâ€“Zag
Samplerisp âˆˆ {âˆ’1,+1}ğ‘‘.FortheBouncyParticleSampler,wedescribe
zz
thecasewherepissampledfromUğ‘‘,theuniformdistributionontheunit
hypersphere.If,instead,p
BPS
âˆ¼N(0, ğ‘‘1Iğ‘‘),forlargeğ‘‘,âˆ¥p BPSâˆ¥2 â‰ˆ1andthe
analysisisthe âˆšsameasforthesettingwherep
BPS
âˆ¼ Uğ‘‘.Speedinguptime
byafactorof ğ‘‘leadstotheversionoftheBPSthatsamplespâˆ¼N(0,Iğ‘‘),
butmakesnodifferencetotheoverallefficiencyintermsofmixingperunit
ofcomputationaleffort.
Foreithersampler,let ğ‘ ğ‘– betheğ‘–thcomponentofitsmomentum.Forthe
BouncyParticleSampler,theintensityisğœ† BPS(ğœ½,p) =max{0,(cid:205) ğ‘–ğ‘‘
=1
ğ‘ ğ‘–ğœƒ ğ‘–} =
ğ‘‚(1),sinceeachterminthesumhasthesameexpectationof0andavari-
ance ofğ‘‚(1/ğ‘‘). Thus,there areğ‘‚(1) events perunit oftime. Incontrast,
for the Zigâ€“Zag Sampler, the intensity isğœ† zz(ğœ½,p) = (cid:205) ğ‘–ğ‘‘ =1max{0,ğ‘ ğ‘–ğœƒ ğ‘–} =
ğ‘‚(ğ‘‘),sinceeachterminthesumhasthesamepositiveexpectation.Hence,
thereareğ‘‚(ğ‘‘) eventsperunittime.Ingeneral,foreachsampler,thecom-
putational cost of performing a bounce is ğ‘‚(ğ‘‘): for the Bouncy Particle
Sampler,thisistheorderofthecostofcalculatingthegradientrequiredfor156 Continuous-TimeMCMC
boththeeventrateandforcalculatingthenewvelocityatabounceevent;
forZig-Zag,afterabounceeventwewillneedtoupdatetheratesforeach
oftheğ‘‘ possibleevents(thoughseeSection5.4.2forsituationswherethis
can be reduced). Thus the total cost per unit time isğ‘‚(ğ‘‘) for the Bouncy
ParticleSamplerandğ‘‚ (cid:0)ğ‘‘2(cid:1) fortheZigâ€“ZagSampler.
The above costing generalises to any reasonably well-behaved target.
However, because it only updates a component at a time, in cases where
components have a sparse conditional dependence graph the cost of per-
formingaZigâ€“Zagbouncecanbereducedtoğ‘‚(1) (seeSection5.4.2).
Nowweturntothemixingproperties.Inthisspecialcaseofanisotropic
target, the state of the Markov process can be encapsulated by the radial
component, âˆ¥ğœ½âˆ¥, and the angle between the radius and the momentum,
whichisproportionaltoğœ½ Â·p.
For Bouncy Particle Samplers, the radial component mixes in ğ‘‚(ğ‘‘)
time,whereastheangularcomponentmixesinğ‘‚(1) time.Toseewhy,for
simplicity,weignoreanyrefreshevents.Considerasinglestraight-linepath
betweenbounces,whichwewillcallasegment:becausethecontoursona
N(0,Iğ‘‘) targetarespherical,logğœ‹ increasesmonotonicallytoamaximum
alongthesegmentandthendecreasesmonotonicallyuntilthenextbounce.
Let ğ¸ be the size of the drop in logğœ‹ from its maximum until the next
bounce.Startaclockatatimewhenlogğœ‹isatamaximumandletğ‘¡ bethe
timesincetheclockstarted.Sincetherearenorefreshevents,iftherehas
beennobouncesincetheclockstarted,thesizeofthetotaldropinlogğœ‹by
timeğ‘¡ is
âˆ« ğ‘¡
ğ·(ğ‘¡) =âˆ’ pÂ·âˆ‡logğœ‹(ğœ½ğ‘ )dğ‘ .
0
Now,forğ‘¡ > 0,ğœ‹(ğœ½ğ‘¡) decreasesuntilabounceoccurs,so
ğ¸ > ğ·(ğ‘¡) â‡”â€Nobouncebytimeğ‘¡.â€
However,whilelogğœ‹isdecreasing,bounceeventsfollowaninhomogeneous
Poisson process with a rate at time ğ‘  of ğœ†(ğ‘ ) = âˆ’p Â· âˆ‡logğœ‹(ğœ½ğ‘ ), so the
probabilitythattherehasbeennoeventbytimeğ‘¡ is
(cid:20) âˆ« ğ‘¡ (cid:21)
exp âˆ’ ğœ†(ğ‘ )dğ‘  =exp[âˆ’ğ·(ğ‘¡)].
0
Thus P(ğ¸ > ğ·(ğ‘¡)) = exp[âˆ’ğ·(ğ‘¡)], so ğ¸ has an exponential distribution
withrateparameter1.
Overtheğ‘‚(1)timebetweenbounces,theangleğœ½Â·pmovesmonotonically
fromitsmostnegativeextent(justafterabounce)toitsmostpositiveextent5.3 Continuous-timeMCMCviaPDMPs 157
(justbeforethenextbounce).Thus,ğœ½ Â·pmixesinğ‘‚(1) time.However,
1 1
logğœ‹(ğœ½) =constantâˆ’ âˆ¥ğœ½âˆ¥2 =constantâˆ’ ğœ’2
ğ‘‘
2 2
âˆš
atstationarity,anda ğœ’2 randomvariablehasastandarddeviationof 2ğ‘‘.
ğ‘‘
So,tomix,thelogğœ‹ processneedstomovebyğ‘‚(ğ‘‘1/2),yetitonlymoves
byğ‘‚(1) inğ‘‚(1) time.Inananalogousmannertothelimitfortherandom
walk Metropolis in Section 2.1.3, speeding up time by a factor of ğ‘‘ leads
toalimitingdiffusionfor âˆ¥ğœ½âˆ¥;thus âˆ¥ğœ½âˆ¥ mixesinğ‘‚(ğ‘‘) time.
By maximising the speed of the limiting diffusion for âˆ¥ğœ½âˆ¥, the same
analysisadvisesontuningtherefreshratefortheBouncyParticleSampler,
ğœ† r.Thissuggestschoosingğœ† r sothattheratioofrefreshtobounceevents
isâ‰ˆ0.78.
Inthecaseofanisotropicnormaltarget,theZigâ€“ZagSamplersimplifies
toğ‘‘independentone-dimensionalinstancesofGustafsonâ€™salgorithm(Sec-
tion 4.3). Thus, each individual component mixes in ğ‘‚(1) time, so both
âˆ¥ğœ½âˆ¥ andğœ½ Â·pmixinğ‘‚(1) time.
Multiplyingthemixingtimesbythecomputationalcosts,wecandefine
mixingcosts.ForBouncyParticleSamplers,theseareğ‘‚(ğ‘‘)fortheangular
component and ğ‘‚(ğ‘‘2) for the radial component, whereas the costs for
the Zigâ€“Zag Sampler are ğ‘‚(ğ‘‘2) for both components. If one follows the
adage that a sampler is only as good as its worst-mixing component, this
suggests that, at least for well-behaved targets, both algorithms have a
similarefficiency.
WhataboutthemixingoftheBouncyParticleSamplerforotherfunctions
ofthestate?Bierkensetal.(2022)showthatithasthesameğ‘‚(ğ‘‘2) ratefor
marginal components of the state â€“ i.e. if we are interested in ğœƒ ğ‘– for some
ğ‘–.ThiscomparestoresultsinDeligiannidisetal.(2021)whichsuggestthat
mixingcostsformarginalcomponentsareğ‘‚(ğ‘‘).Thedifferenceinresults
comesfromdifferentchoicesofhowtherefreshratedependsonğ‘‘.Bierkens
etal.(2022)haveaconstantrate,whereasDeligiannidisetal.(2021)assume
that the rate decays like ğ‘‚(ğ‘‘âˆ’1/2). The latter choice improves mixing for
marginalcomponentsbutworsensthemixingoftheradialcomponent,so
thatasğ‘‘ â†’âˆ,thelimitingprocessfortheradialcomponentisdegenerate.
To see this in practice, we compared the performance of Zigâ€“Zag and
theBouncyParticleSampleratsamplingfromaGaussianwithğ‘‘ =20and
ğ‘‘ = 1000. Results are shown in Figure 5.4, where we scale the number
of events simulated to be proportional to the dimension, ğ‘‘. The theory
statesthatforthisscalingwewouldexpectsimilarmixingfortheZigâ€“Zag
sampleroverthelengthofthesimulation.Weobservethisqualitativelyfor158 Continuous-TimeMCMC
6 6 6
5 5 5
4 4 4
3 3 3
0 1 0 1 0 1
Proportion of run Proportion of run Proportion of run
2 2 2
0 0 0
2 2 2
0 1 0 1 0 1
Proportion of run Proportion of run Proportion of run
33 33 33
32 32 32
31 31 31
30 30 30
0 1 0 1 0 1
Proportion of run Proportion of run Proportion of run
2 2 2
0 0 0
2 2 2
0 1 0 1 0 1
Proportion of run Proportion of run Proportion of run
Figure5.4 TraceplotsforZigâ€“Zag(left-handcolumn),Bouncy
ParticleSamplerwithğœ†
r
=1.5âˆšï¸ğ‘‘/20(middlecolumn)and
BouncyParticleSamplerwithğœ†
r
=1.5(right-handcolumn)fora
Gaussiantargetwithğ‘‘ =20(toptworows)andğ‘‘ =1000(bottom
tworows).Ineachcaseweshowtraceplotsfortheradial
componentofthestate,âˆ¥ğœ½âˆ¥,andthefirstcomponentofthestate,
ğœƒ .Weranallsamplersfor20ğ‘‘bounceevents,andscaledthetime
1
axisbytheproportionoftheresultingsimulationtime.
Î¸
Î¸
Î¸
Î¸
1
k
k
1
k
k
Î¸
Î¸
Î¸
Î¸
1
k
k
1
k
k
Î¸
Î¸
Î¸
Î¸
1
k
k
1
k
k5.4 EfficientSimulationofPDMPSamplers 159
both âˆ¥ğœ½âˆ¥ and ğœƒ . The theory also suggests similar qualitative behaviour
1 âˆš
for the Bouncy Particle Sampler with a refresh rate that scales with ğ‘‘,
so that the proportion of refresh events is roughly similar for different ğ‘‘;
we observe this in the middle column of the plot. By comparison, if we
use a fixed refresh rate, as in Deligiannidis et al. (2021), then we observe
better mixing for ğœƒ but worse mixing for âˆ¥ğœ½âˆ¥ as we increase ğ‘‘ â€“ see the
1
right-handcolumnofFigure5.4.
One important consequence of the theoretical results, and that is seen
in the results in Figure 5.4, is that care is needed when we assess mixing
and convergence of, in particular, the Bouncy Particle Sampler â€“ as we
cangetsubstantiallydifferentmeasuresofmixing,suchasauto-correlation
time, depending on which function of the state we consider. Observing
a fast mixing chain for one component may mask that other functions of
thestatearemixingveryslowly(seeSection6.2.4formorediscussionon
summarising convergence in multivariate settings and measures that can
givedifferingimportancetodifferentcoordinates).
Bierkens et al. (2023a) investigate fixed, finite-dimensional normal tar-
getswherebetween1and ğ‘‘ âˆ’1principalcomponentshavealengthscale
of ğœ–, while the remainder have a length scale of 1. Both algorithms have
ğ‘‚(ğœ–âˆ’1)eventsperunittimebecausethemomentumisğ‘‚(1)butsomelength
scales are ğ‘‚(ğœ–). The Bouncy Particle Sampler mixes in ğ‘‚(1) time; how-
ever,thealignmentoftheZigâ€“ZagSampleriscrucialtoitsmixingtime:if
theprincipalaxesofthetargetarealignedwiththeğ‘‘ Zigâ€“Zagmomentum
componentsthenitalsomixesinğ‘‚(1) time,butinalmostallotherscenar-
ios its mixing time is ğ‘‚(ğœ–âˆ’1). Preconditioning is usually advised for any
MCMCalgorithm;thisanalysishighlightsthattheneedforpreconditioning
the Zigâ€“Zag Sampler is even more marked than it is for Bouncy Particle
Samplers.
5.4 EfficientSimulationofPDMPSamplers
We now consider various approaches for simulating the PDMP samplers.
As a running example that we will use to help explain some of the ideas,
wewillconsiderthelogisticregressionmodelwithaGaussianprior,which
wasintroducedinSection1.2.1.
5.4.1 SimulatingPDMPs
WhensamplingfromtheGaussiantarget,theratesthatdeterminethetime
untilthenexteventwerelinearandthuswecouldsimulatetheeventtimes160 Continuous-TimeMCMC
of the PDMP exactly. What happens for more complicated targets where
thisisnotpossible?Herewedescribethreepossiblemethodsforsimulating
theseevents.
ThemostcommonapproachesforsimulatingeventsofaPDMParebased
ontheideaofPoissonthinning(seeSection5.2.2).Rememberthisinvolves
upper-bounding the event rate, simulating events with this bounding rate,
andthenacceptingthesimulatedeventswiththeratioofthetrueratetothe
boundingrate. Thechallengewith Poissonthinningis findinggoodupper
bounds that are simple enough that we can simulate events analytically,
and,ideally,closetothetruerate,asthecomputationalefficiencyofPoisson
thinningdependsonhowclosetheboundingrateistothetruerate.Thefirst
twomethodswedescribearebasedonthisideabutdifferintheassumptions
theymakeonthetargetandhowtheboundingratesareconstructed.
ThefirstapproachcomesfromBierkensetal.(2019b)andassumesthat
the Hessian of the minus log-target is bounded. To simplify the notation,
definethevectorU(ğœ½) =âˆ’âˆ‡logğœ‹(ğœ½),soU= (ğ‘ˆ 1(ğœ½),...,ğ‘ˆ ğ‘‘(ğœ½)) with
ğœ•logğœ‹(ğœ½)
ğ‘ˆ ğ‘—(ğœ½) =âˆ’
ğœ•ğœƒ
.
ğ‘—
NowtheHessianofâˆ’logğœ‹(ğœ½) isağ‘‘Ã—ğ‘‘ matrixH(ğœ½) definedas
H(ğœ½) = (cid:0) âˆ‡ğ‘ˆ 1(ğœ½) Â·Â·Â· âˆ‡ğ‘ˆ ğ‘‘(ğœ½) (cid:1).
ThenweassumethatthereissomematrixJsuchthatforanyvector,w,and
anyğœ½,
wâŠ¤H(ğœ½)w â‰¤ wâŠ¤Jw.
ThisholdsforGaussiantargetdistributions,asH(ğœ½) =Hisaconstant.More
importantly, it holds for targets which are heavier-tailed than Gaussian,
includingtheposteriordistributionforlogisticregressionormanyversions
of robust regression if we have e.g. Gaussian priors on the parameters of
themodel.
Now,asintroducedbefore,considerarateforthenextevent,orthenext
specifictypeofevent,inaPDMP,ğœ†Ëœ (ğ‘¡),intermsofthefurthertimeuntil
z
theeventğ‘¡.Assumethat
ğœ†Ëœ (ğ‘¡) =max{0,wÂ·U(ğœ½ +pğ‘¡)},
z
whereU = âˆ’âˆ‡logğœ‹ asdefined above,the currentstate is (ğœ½,p),and wis
somevectorthatdependsonthesampler.FortheBouncyParticleSampler
or the Coordinate Sampler, if we are considering time until the next non-
refresh event, then w = p, whereas for the Zigâ€“Zag Sampler if we are5.4 EfficientSimulationofPDMPSamplers 161
considering the next flip of component ğ‘— then w will be either the unit
vectorwith1orâˆ’1inthe ğ‘—thecomponentandzeroelsewhere.
NowconsiderthetermwÂ·U(ğœ½ +pğ‘¡).Thiscanberewrittenas
wÂ·U(ğœ½ +pğ‘¡)
=wÂ·U(ğœ½)+âˆ‘ï¸ğ‘‘
ğ‘¤
ğ‘–âˆ« ğ‘¡ dğ‘ˆ ğ‘–(ğœ½ dğ‘ +pğ‘ )
dğ‘ 
ğ‘–=1 0
ğ‘‘ âˆ« ğ‘¡
âˆ‘ï¸
=wÂ·U(ğœ½)+ ğ‘¤
ğ‘–
pÂ·âˆ‡ğ‘ˆ ğ‘–(ğœ½ +pğ‘ )dğ‘ 
ğ‘–=1 0
âˆ« ğ‘¡
=wÂ·U(ğœ½)+ wâŠ¤H(ğœ½ +pğ‘ )pdğ‘ .
0
Thefirstequalitycomesfromwritingthevalueofafunctionattimeğ‘¡asits
valueattime0plustheintegralofitsderivativefromtime0totimeğ‘¡.We
thenusethechainruletogetthederivativeofğ‘ˆ ğ‘–(ğœ½+pğ‘ ) withrespecttoğ‘ ,
andfinallythedefinitionoftheHessianmatrix.
Now,byCauchyâ€“Schwarzforvectors,wâŠ¤Hp â‰¤ âˆ¥wâˆ¥âˆ¥Hpâˆ¥,whereâˆ¥wâˆ¥ =
((cid:205) ğ‘–ğ‘‘ =1ğ‘¤ ğ‘–)1/2istheğ¿ 2normofthevectorw.This,togetherwithourassump-
tionontheboundoftheHessian,gives
wâŠ¤H(ğœ½ +pğ‘ )p â‰¤ âˆ¥wâˆ¥âˆ¥H(ğœ½ +pğ‘ )pâˆ¥ â‰¤ âˆ¥wâˆ¥âˆ¥Jpâˆ¥
whichisaconstant.Thuswegetthelinearbound
wÂ·U(ğœ½ +pğ‘¡) â‰¤ wÂ·U(ğœ½)+âˆ¥wâˆ¥âˆ¥Jpâˆ¥ğ‘¡,
orequivalentlythepiecewiselinearboundontherate
ğœ†Ëœ (ğ‘¡) â‰¤ max{0,wÂ·U(ğœ½)+âˆ¥wâˆ¥âˆ¥Jpâˆ¥ğ‘¡}.
z
We can simulate events from this upper-bounding rate analytically, in an
equivalentwaytowhichwesimulatetheeventsfortheGaussiantarget.If
wâ‰ p,wecanuseinsteadwâŠ¤Hp â‰¤ âˆ¥pâˆ¥âˆ¥Hwâˆ¥ togetthealternativebound
ğœ†Ëœ (ğ‘¡) â‰¤ max{0,wÂ·U(ğœ½)+âˆ¥pâˆ¥âˆ¥Jwâˆ¥ğ‘¡}.
z
Oursecondapproach(SuttonandFearnhead,2023)isbasedonadifferent
assumptionforthetarget,namelythatwecandecomposeâˆ’âˆ‡logğœ‹(ğœ½+pğ‘¡),
as a function of ğ‘¡ for any ğœ½ and p into the sum of convex and concave
functions,andassumetheconcavefunctionisdifferentiableeverywhere.A
function ğ‘“ (ğ‘¡) forğ‘¡ â‰¥ 0 is a convex function if for any 0 â‰¤ ğ‘Ÿ < ğ‘  < ğ‘¡, we
âˆª
have
ğ‘¡âˆ’ğ‘  ğ‘ âˆ’ğ‘Ÿ
ğ‘“ (ğ‘ ) â‰¤ ğ‘“ (ğ‘Ÿ)+ ğ‘“ (ğ‘¡),
âˆª ğ‘¡âˆ’ğ‘Ÿ âˆª ğ‘¡âˆ’ğ‘Ÿ âˆª
whileafunction ğ‘“ (ğ‘¡) forğ‘¡ â‰¥ 0isaconcavefunctionifâˆ’ğ‘“ (ğ‘¡) isconvex.
âˆ© âˆ©162 Continuous-TimeMCMC
Thatisifwepickanytwopointsonthefunctionandjointhembyastraight
line,thenthefunctionliesbelowthelineifitisconvex,andabovetheline
ifitisconcave.SeeFigure5.5foranexample.
Wewillassumethatwecandecomposetherateuntilthenexteventas
ğœ†Ëœ (ğ‘¡) =max{0, ğ‘“ (ğ‘¡)+ ğ‘“ (ğ‘¡)},
z âˆª âˆ©
i.e. in terms of a single convex and single concave function â€“ though the
ideasbelowapplytriviallyifourdecompositioninvolvesmultipleconcave
andconvexfunctions.(Infact,thesumofconvexfunctionsisconvex,and
the sum of concave functions is concave, so we can immediately simplify
thedecompositiontothecaseweareconsidering.)Ourstartingpointisthe
bound
ğœ†Ëœ (ğ‘¡) =max{0, ğ‘“ (ğ‘¡)+ ğ‘“ (ğ‘¡)} â‰¤ max{0, ğ‘“ (ğ‘¡)}+max{0, ğ‘“ (ğ‘¡)}. (5.14)
z âˆª âˆ© âˆª âˆ©
Sutton and Fearnhead (2023) then use the fact that we can bound ğ‘“ (ğ‘¡)
âˆª
and ğ‘“ (ğ‘¡) by piecewise linear functions just by evaluating the functions
âˆ©
at a set of grid points. Once we have these piecewise linear bounds, they
immediatelygiveusapiecewiselinearboundonğœ†Ëœ (ğ‘¡)bysubstitutingthem
z
into(5.14).
Howdowegetpiecewiselinearboundson ğ‘“ (ğ‘¡)and ğ‘“ (ğ‘¡)?Itissimplest
âˆª âˆ©
to see this through a picture â€“ see Figure 5.5. For the convex function,
the bound comes immediately from the definition: if we evaluate ğ‘“ (ğ‘¡) at
âˆª
ğ‘¡ =0andğ‘¡ =ğ‘¡ ,thenthestraightlinethatjoinsthesepointsgivesanupper
1
boundon [0,ğ‘¡ ].Foraconcavefunction,weneedtoevaluate ğ‘“ (ğ‘¡) andits
1 âˆ©
derivative at ğ‘¡ = 0 and ğ‘¡ = ğ‘¡ . We then construct the tangents to ğ‘“ (ğ‘¡) at
1 âˆ©
ğ‘¡ =0andğ‘¡ =ğ‘¡ ,andthefunctionliesbelowbothtangents.
1
The above approach gives upper bounds on some interval [0,ğ‘¡ ], and
1
wecanproceedbyusingtheseupperboundstosimulateevents,ifany,on
[0,ğ‘¡ ]. If there are no events, we then choose some ğ‘¡ > ğ‘¡ and calculate
1 2 1
an upper bound on [ğ‘¡ ,ğ‘¡ ] and repeat the process. In practice, Sutton and
1 2
Fearnhead (2023) suggest choosing ğ‘¡ ,ğ‘¡ ,... to be equally spaced, and
1 2
suggestwaysofchoosingthespacinginanadaptivewaythatbalancesthe
number of times we do not simulate an event from the bounding process
on an interval, against the number of times we simulate events from the
boundingprocessthatarenotaccepted.Theideaisthatiftheintervalsare
toolow,wewastetimebyhavingtoosmallanintervalandthushavingto
calculatetheupperbound,whereasiftheintervalistoolargethentheupper
bound can become loose and we waste time by simulating lots of events
that are rejected. It is also possible to recycle calculations used to decide
whethertoacceptaneventtoimprovethebounds.5.4 EfficientSimulationofPDMPSamplers 163
       
       
   
   
   
   
   
   
   
                       
t t
Figure5.5 Exampleofaconvexfunction(left)andaconcave
function(right).Foraconvexfunction,thestraightline(shownin
grey)thatjoinsanytwopointswillupper-boundthefunction
betweenthosetwopoints.Foraconcavefunction,thestraightline
(showningreydashed)thatjoinsanytwopointswilllower-bound
thefunctionbetweenthosetwopoints.Foraconcavefunction,we
canupper-boundthefunctionbyanytangenttothefunction
(showningrey).Exampleboundsfor [0,0.5] and [0.5.1] are
shownbythegreyline(left-handplot)andminimumofthegrey
lines(right-handplot).
The final set of methods we will overview is based on simulating the
eventsusingnumericalmethods.Therehavebeentwodistinctapproaches
that have been suggested. The first is based on the equation for directly
simulatingtheeventtimes.Rememberthatwecansimulatethenextevent
timeforaprocesswithrateğœ†Ëœ (ğ‘¡)bysimulatingğ‘¢,arealisationofastandard
z
uniformrandomvariable,andthenfindingğœthesolutionto
âˆ« ğœ
âˆ’ ğœ†Ëœ (ğ‘ )dğ‘  =log(1âˆ’ğ‘¢).
z
0
The smallest solution, ğœ, of this equation, is the time until the next event.
Paganietal.(2020)suggestsolvingthisequationnumericallyusingBrentâ€™s
method(Pressetal.,2007).Theotherapproachistousenumericalmethods
tofindanupperbound.Corbellaetal.(2022)suggestsuchamethod,where
theyuseBrentâ€™salgorithmtofindthemaximumofğœ†Ëœ (ğ‘¡) onsomeinterval
z
[0,ğ‘¡ ], then propose points from a constant rate set to this maximum and
1
usePoissonthinning.Ifnoeventissimulatedovertheinterval [0,ğ‘¡ ] they
1
repeattheprocessonthenextinterval.
f
u
f
u164 Continuous-TimeMCMC
The advantage of using such numerical methods is that they are fully
general, that is they can be applied to any model in an automatic manner.
The disadvantages are two-fold. First, computationally they can be slow,
depending on the numerical methods used. The second is that numerical
errors may lead to errors in the simulation of the dynamics of the PDMP,
so that the resulting PDMP may no longer target the correct distribution.
The hope is that any numerical error is small so that the PDMP will have
a stationary distribution that is still close to the target distribution. Pagani
etal.(2020)giveresultsonhownumericalerrorwillimpactthedistribution
thatthePDMPissamplingfrom.
Example:BoundedHessianforLogisticRegression
Logisticregression isone examplewherewe havea boundedHessian.To
seethis,letğœ‹(ğœ½)betheposteriorforthelogisticregressionmodelofSection
1.2.1withaGaussianprior.Thendifferentiating(1.5)gives
âˆ’ğœ•2logğœ‹(ğœ½) = (cid:2) ğšºâˆ’1(cid:3) +âˆ‘ï¸ğ‘ ğ‘¥(ğ‘–)ğ‘¥(ğ‘™) (cid:40) exp{xâŠ¤ ğ‘—ğœ½} (cid:41)(cid:40) 1 (cid:41) ,
ğœ•ğœƒ ğ‘–ğœ•ğœƒ
ğ‘™
ğœ½ ğ‘–,ğ‘™
ğ‘—=1
ğ‘— ğ‘— 1+exp{xâŠ¤ ğ‘—ğœ½} 1+exp{xâŠ¤ ğ‘—ğœ½}
where the subscripts ğ‘–,ğ‘™ denote the (ğ‘–,ğ‘™)th element of the corresponding
matrix.Now,foranyprobabilityğ‘ wehaveğ‘(1âˆ’ğ‘) â‰¤ 1/4,so
ğœ•2logğœ‹(ğœ½)
â‰¤
(cid:2) ğšºâˆ’1(cid:3)
+
1âˆ‘ï¸ğ‘
ğ‘¥(ğ‘–)ğ‘¥(ğ‘™).
ğœ•ğœƒ ğ‘–ğœ•ğœƒ ğ‘™ ğœ½ ğ‘–,ğ‘™ 4 ğ‘— ğ‘—
ğ‘—=1
Ifweintroduceağ‘Ã—ğ‘‘matrixXwhose(ğ‘—,ğ‘™)thentryisğ‘¥(ğ‘™),thenthisgives
ğ‘—
aboundontheHessianofâˆ’logğœ‹(ğœ½) thatisJ= ğšºâˆ’1+(1/4)XâŠ¤X.
FortheBouncyParticleSampler,therateofthenextbounceevent,ifthe
currentstateis (ğœ½,p),is
max{0,pÂ·âˆ‡(âˆ’logğœ‹(ğœ½ +ğ‘¡p)} â‰¤ max{0,âˆ’pÂ·âˆ‡(logğœ‹(ğœ½)+âˆ¥pâˆ¥âˆ¥Jpâˆ¥ğ‘¡},
by the above argument. For the Zigâ€“Zag Sampler, the rate of the next flip
ofcomponentğ‘– ofthevelocityisboundedaboveby,forexample,
(cid:26) ğœ•logğœ‹(ğœ½) âˆš (cid:27)
max 0,âˆ’ğ‘ ğ‘– ğœ•ğœƒ + ğ‘‘âˆ¥Jeğ‘–âˆ¥ğ‘¡ .
ğ‘–
Example:Concaveâ€“convexSamplingforBayesianMatrixFactorisation
ConsidertheBayesianmatrixfactorisationmodelofSection1.2.2.Tosim-
plifynotationwewillassumeanimproperuniformpriorfortheparameters5.4 EfficientSimulationofPDMPSamplers 165
ğœ½ = {U,V}andsetğœ2 =1.Theresultinglog-posterioris
ï£± ğ‘› ğ‘š (cid:32) ğ‘‘ (cid:33)2ï£¼
logğœ‹(U,V|Y) =âˆ’1 ï£´ ï£´ï£²âˆ‘ï¸âˆ‘ï¸ ğ‘Œ
ğ‘–ğ‘—
âˆ’âˆ‘ï¸ ğ‘ˆ ğ‘–ğ‘˜ğ‘‰
ğ‘˜ğ‘—
ï£´ ï£´ï£½.
2
ï£´ ï£´ğ‘–=1 ğ‘—=1 ğ‘˜=1 ï£´ ï£´
ï£³ ï£¾
Aswewillsee,theeventratesforthismodelfortheZigâ€“ZagSamplerorthe
BouncyParticleSamplerarepolynomialsofthetimetoanevent,andsuch
events can be simulated by concaveâ€“convex sampling. We will show this
fortheZigâ€“ZagSampler,buttheextensiontotheBouncyParticleSampler
issimple.
Considertherateforupdateğ‘ˆ ğ‘–,ğ‘™.Thisdependsonthederivativeofminus
logğœ‹,whichis
ğœ•logğœ‹(U,V|Y) âˆ‘ï¸ğ‘š (cid:32) âˆ‘ï¸ğ‘‘ (cid:33)
âˆ’ = ğ‘Œ âˆ’ ğ‘ˆ ğ‘‰ ğ‘‰ .
ğœ•ğ‘ˆ ğ‘–,ğ‘— ğ‘–,ğ‘˜ ğ‘˜,ğ‘— ğ‘™,ğ‘—
ğ‘–,ğ‘™
ğ‘—=1 ğ‘˜=1
Ifthecurrentstateisgivenbyaposition (U,V) andavelocity (U(cid:164),V(cid:164)) then
therateofaneventasafunctionofthetimetothenexteventğ‘¡ is
ğœ•logğœ‹(U+ğ‘¡U(cid:164),V+ğ‘¡V(cid:164)|Y)
âˆ’ğ‘ˆ(cid:164)
ğ‘–,ğ‘™ ğœ•ğ‘ˆ
ğ‘–,ğ‘™
ğ‘š (cid:32) ğ‘‘ (cid:33)
âˆ‘ï¸ âˆ‘ï¸
=ğ‘ˆ(cid:164) ğ‘Œ âˆ’ (ğ‘ˆ +ğ‘¡ğ‘ˆ(cid:164) )(ğ‘‰ +ğ‘¡ğ‘‰(cid:164) ) (ğ‘‰ +ğ‘¡ğ‘‰(cid:164) ).
ğ‘–,ğ‘™ ğ‘–,ğ‘— ğ‘–,ğ‘˜ ğ‘–,ğ‘˜ ğ‘˜,ğ‘— ğ‘˜,ğ‘— ğ‘™,ğ‘— ğ‘™,ğ‘—
ğ‘—=1 ğ‘˜=1
Thisiscubicinğ‘¡,anditiseasytoobtainaconcaveâ€“convexdecomposition
of this rate. The convex function will be the sum of terms in the cubic
expressionthathavepositivecoefficients,andtheconcavefunctionwillbe
thesumoftermswithnegativecoefficients.
5.4.2 ExploitingModelSparsity
One advantage of PDMP samplers is that they can take advantage of a
certaintypeofsparsityinthetargetdistributiontospeedupcomputation.
ThisismosteasilydescribedfortheZigâ€“ZagSampler,thoughsimilarideas
canbeusedforanadaptedversionoftheBouncyParticleSampler(seethe
section on the Local Bouncy Particle Sampler in Bouchard-CoË†teÂ´ et al.,
2018).
WehavedescribedhowwecansimulatetheZigâ€“ZagSamplerbysimu-
latingğ‘‘eventtimes,oneforeachpossibletransitionofthevelocity.Wethen
implementtheeventthatoccursfirst,andthenresimulatethefurthertimes
foreachofthe ğ‘‘ possibleevents.Werepeatthisprocessmultipletimesin166 Continuous-TimeMCMC
ordertosimulatetheskeletonofarealisationoftheprocess.However,we
canimproveonthisimplementationiftheeventthatoccursdoesnotaffect
theratesofmanyoftheothertypesofevents.Thiscanhappenifthemodel
hasaformofsparsityintermsof
ğœ•logğœ‹(ğœ½)
(5.15)
ğœ•ğœƒ
ğ‘–
onlydependingonasmallnumberofthecomponentsofğœ½.
To describe the idea formally, it is helpful to introduce some notation.
Forğ‘– =1,...,ğ‘‘letS ğ‘– âŠ‚ {1,...,ğ‘‘}denotethecomponentsofğœ½ that(5.15)
depends on. So if ğ‘— is not in S ğ‘–, then (5.15) will not change as we vary
ğœƒ ğ‘— ifwekeepallothercomponentsof ğœ½ fixed.Thismeansthatifwehave
an event that changes the ğ‘–th component of ğœ½, then this will only affect
the future rate of events that change the ğ‘—th component of ğœ½ for ğ‘— âˆˆ S ğ‘–.
By the Markov property of the PDMP, if the rates are unchanged, we can
re-use the simulated event times for ğ‘— âˆ‰ S ğ‘– if ğ‘— â‰  ğ‘–. We obviously need
tore-simulatetheeventthatflipstheğ‘–thcomponentofthevelocityevenif
ğ‘– âˆ‰S ğ‘–.TheresultingalgorithmisshowninAlgorithm11,withthekeypart
beingthataftereacheventweonlyre-simulatesomeoftheeventtimes,for
othereventswejustupdateandre-usethepreviouslysimulatedtimes.
As one example of the potential advantage of this algorithm, consider
simulating a Gaussian target where the precision matrix is tri-diagonal.
That is, the (ğ‘–, ğ‘—) entry of the precision matrix is zero if |ğ‘–âˆ’ ğ‘—| > 1. Such
a model occurs if there is some form of Markov or AR(1) structure to the
components of ğœ½. In this case, S ğ‘– = {ğ‘– âˆ’1,ğ‘–,ğ‘– +1} for ğ‘– = 2,...,ğ‘‘ âˆ’1,
withS
1
= {1,2}andS
ğ‘‘
= {ğ‘‘âˆ’1,ğ‘‘}.TounderstandtheideaofAlgorithm
11,imagine ğ‘‘ = 5say,andthatwehavesimulatedthatthefurthertimeto
the five possible events is 0.3, 0.7, 1.3, âˆ and 0.5. The event that occurs
firstcorrespondstoflippingthefirstcomponentofthevelocity.Thischange
only affects the rate at which future events that affect the first and second
components of the velocity occur. So we need to re-simulate the further
timetothenexteventofthesetypes.Fortheotherthreetypesofevents,we
justupdatethefurthertimetotakeaccountofthefactthatatimeoflength
0.3 has passed. Thus the events at which the third to fifth components of
thevelocitychangewillnowoccurafterafurthertimeperiodof1.0,âˆand
0.2,respectively.
Intermsofthecomputationaladvantageofthisscheme,inthisexample,
if ğ‘‘ is large then the computational cost per iteration involves resampling
atmost3eventtimesratherthanğ‘‘eventtimes.Itisalsopossibletofurther
improveonAlgorithm11byusingthefactthattheorderofoccurrenceof5.4 EfficientSimulationofPDMPSamplers 167
Algorithm11:Zigâ€“ZagSampler:ExploitingSparsity
Input:Eventratesforeachtypeofeventğœ† ğ‘–,initialstate (ğœ½,p),
simulationtimeğ‘‡.
Setğ‘  =0and ğ‘˜ =0.
forğ‘– =1,...,ğ‘‘ do
Simulateğ‘¡
ğ‘–
thetimeuntilthenexteventthatflipstheğ‘–th
componentofthevelocity.
end
whilesÂ¡T do
Calculatefurthertimetonexteventğ‘¡ =minğ‘–=1,...,ğ‘‘{ğ‘¡ ğ‘–}.
Updatepositionğœ½ğ‘ +ğ‘¡ = ğœ½ğ‘  +ğ‘¡p.
Decideoneventtype,ğ‘–âˆ— =argmin{ğ‘¡ ğ‘–}.
Updatevelocitypğ‘ +ğ‘¡ = ğ¹ ğ‘–âˆ—(p).
Updatetimeğ‘  = ğ‘ +ğ‘¡.
Storeskeletonpoints:set ğ‘˜ = ğ‘˜ +1,ğœ ğ‘˜ = ğ‘ andğœ½ğœ = ğœ½ğ‘ .
ğ‘˜
Updatefurthertimetoevents:
forğ‘– =1,...,ğ‘‘ do
ifğ‘– âˆˆ S
ğ‘–âˆ—
âˆª{ğ‘–âˆ—}then
Simulateğ‘¡
ğ‘–
thetimeuntilthenexteventthatflipstheğ‘–th
componentofthevelocity.
end
else
Setğ‘¡
ğ‘–
=ğ‘¡
ğ‘–
âˆ’ğ‘¡.
end
end
end
Output:Skeletonofevents{(ğœ ğ‘˜,ğœ½ğœ ğ‘˜)}ğ‘›
ğ‘˜=0
eventsthatwedonotre-simulatewillnotchange(seeBouchard-CoË†teÂ´etal.,
2018)â€“andthiscanreducethecostperiterationtobeoftheorderofthe
numberofeventtimesthatweneedtore-simulate.
Example:LogisticRegression
When would this idea be useful for sampling from the posterior of our
logisticregressionmodel?Therateofaneventthatflipscomponentğ‘–ofthe
velocitydependsontheğœƒ
ğ‘–
derivativeoflogğœ‹(ğœ½),whichfrom(1.5),is
âˆ’(cid:2) ğœ½âŠ¤ğšº ğœ½âˆ’1(cid:3)
ğ‘–
+âˆ‘ï¸ğ‘
ğ‘¥( ğ‘—ğ‘–)
(cid:40)
ğ‘¦
ğ‘—
âˆ’
1+ex ep x{ px {âŠ¤
ğ‘—
xğœ½ âŠ¤} ğœ½}(cid:41)
.
ğ‘—=1 ğ‘—168 Continuous-TimeMCMC
Weneedthistodependononlyasmallsetofcomponentsofğœ½.Thiswould
requiretwothings.Firstthatğšºâˆ’1issparsesoonlyasmallnumberofentries
ğœ½
of the ğ‘–th row or column of ğšºâˆ’1 are non-zero. Second, we would require
ğœ½
that the observations for which
ğœƒ(ğ‘–)
â‰  0 would, combined, only have a
ğ‘—
smallnumberofcomponentsofthecovariatesthatarenon-zero.Formally,
we can define the set of rates that we would need to update after a flip of
componentğ‘– ofğœ½ as
(cid:110) (cid:111)
S ğ‘– = ğ‘˜ : (ğšºâˆ’1) ğ‘–,ğ‘˜ â‰ 0, orâˆƒ ğ‘— suchthatx( ğ‘—ğ‘–)x( ğ‘—ğ‘˜) â‰ 0 .
This can happen for models with random effects which are included
within ğœ½. If we set the random effects to be ğœƒ 1,...,ğœƒ ğ‘, then for ğ‘— âˆˆ
{1,...,ğ‘}, x(ğ‘—) = 1 and x(ğ‘–) = 0 for ğ‘– â‰  ğ‘—. If further, we have that the
ğ‘— ğ‘—
randomeffectsareindependentofeachotherandtheotherparameters,S
ğ‘–
willonlyincludetheparametersofthefixedeffects.
5.4.3 DataSubsamplingIdeas
OnepotentialadvantageofPDMPsamplersinBayesianstatisticsisthatthey
can use subsampling ideas to reduce the computational cost per iteration.
ThiswasfirstsuggestedfortheZigâ€“ZagSamplerbyBierkensetal.(2019b),
thoughtheideasapplymorewidely.
Thestartingpointisamoregeneralobservationthatwecanpotentially
simulate from a target distribution if we have an unbiased estimator of
âˆ‡logğœ‹. This is most easily seen for the Zigâ€“Zag Sampler, and we will
focus just on this case for simplicity. See Fearnhead et al. (2018) and
relatedideasforthelocalBouncyParticleSamplerinBouchard-CoË†teÂ´ etal.
(2018)forhowthisisgeneralisedtootherPDMPs.
The Zigâ€“Zag Sampler has ğ‘‘ possible types of event. Consider the ğ‘–th
suchevent.Ifthecurrentpositionisğœ½andtheğ‘–thcomponentofthevelocity
is ğ‘ ğ‘–,thenthiscomponentflipswitharate
(cid:26) ğœ•logğœ‹(ğœ½)(cid:27)
max 0,âˆ’ğ‘ ğ‘– ğœ•ğœƒ .
ğ‘–
The key property of this rate that means that the sampler targets ğœ‹(ğœ½) is
thatthedifferenceinratebetweenaflipfrom ğ‘ ğ‘– toâˆ’ğ‘ ğ‘– andtherateofthe
reverseeventis
(cid:26) ğœ•logğœ‹(ğœ½)(cid:27) (cid:26) ğœ•logğœ‹(ğœ½)(cid:27) ğœ•logğœ‹(ğœ½)
max 0,âˆ’ğ‘ ğ‘– ğœ•ğœƒ âˆ’max 0,ğ‘ ğ‘– ğœ•ğœƒ =âˆ’ğ‘ ğ‘– ğœ•ğœƒ .
ğ‘– ğ‘– ğ‘–
In practice, for Zigâ€“Zag, one of the two rates is equal to 0, and this is the5.4 EfficientSimulationofPDMPSamplers 169
most efficient choice and corresponds to the Zigâ€“Zag Sampler using the
canonicalrates(seeSection5.3.1).
Nowimaginewehaveafamilyofvector-valuedrandomvariablesG(ğœ½),
such that E[G(ğœ½)] = âˆ’âˆ‡logğœ‹(ğœ½) for all ğœ½. Then if we implement the
same dynamics as the Zigâ€“Zag Sampler, but with the rate of flipping the
ğ‘–thcomponentofthevelocityequalto
E[max{0,ğ‘ ğ‘–ğº ğ‘–(ğœ½)}],
then this will also produce a PDMP sampler that targets ğœ‹. To see this, as
above,considerthedifferenceintherateofflipping ğ‘ ğ‘– toâˆ’ğ‘ ğ‘– andtherate
ofthereverseevent.Thisis
E[max{0,ğ‘ ğ‘–ğº ğ‘–(ğœ½)}]âˆ’E[max{0,âˆ’ğ‘ ğ‘–ğº ğ‘–(ğœ½)}]
=E[max{0,ğ‘ ğ‘–ğº ğ‘–(ğœ½)}âˆ’max{0,âˆ’ğ‘ ğ‘–ğº ğ‘–(ğœ½)}]
ğœ•logğœ‹(ğœ½)
=E[ğ‘ ğ‘–ğº ğ‘–(ğœ½)] = ğ‘ ğ‘–E[ğº ğ‘–(ğœ½)] =âˆ’ğ‘
ğ‘– ğœ•ğœƒ
,
ğ‘–
where we have used the standard result max{0,ğ‘¥} âˆ’ max{0,âˆ’ğ‘¥} = ğ‘¥,
linearityofexpectation,andthedefinitionoftheexpectationofG.Thisis
preciselytheconditionweneedontheratesforaPDMPSamplerwiththe
Zigâ€“Zag dynamics to target ğœ‹, the only difference is the rates being used
arenolongerthecanonicalrates.
InordertousetheZigâ€“ZagSamplerwiththeseratesweneedawayof
simulatingtheevents.ThisismorechallengingthanforstandardZigâ€“Zag
asweneedtodealwiththeratesbeingdefinedimplicitlybyanexpectation.
Todothis,thestandardapproachistofindabounding ğ‘ ğ‘–(ğœ½) suchthatfor
any realisation of G(ğœ½) we have ğ‘ ğ‘–ğº ğ‘–(ğœ½) â‰¤ ğ‘ ğ‘–(ğœ½). If we can find such a
boundthenwecanstillusePoissonthinningtosimulatetheevents.Letthe
timeuntilthenexteventwhichflips ğ‘ ğ‘– be
ğœ†Ëœ z(ğ‘–)(ğ‘¡) =E[max{0,ğ‘ ğ‘–ğº ğ‘–(ğœ½ +ğ‘¡p)}],
and the corresponding bounding rate, which is used to simulate potential
events, be ğ‘ ğ‘–(ğœ½ +ğ‘¡p). Then Poisson thinning for events of rate ğœ†Ëœ z(ğ‘–)(ğ‘¡) is
possiblebyusingthefollowingsteps:
(T0) Setcurrenttimetoğ‘  =0
(T1) Simulate the time ğœ > ğ‘  of the next event a process with rate ğœ†Â¯(ğ‘¡) =
ğ‘ ğ‘–(ğœ½ +ğ‘¡p).
(T2) Simulateğ‘” ğ‘–,arealisationofğº ğ‘–(ğœ½ +ğœp).
(T3) Accepttheeventtimewithprobabilitymax{0,ğ‘ ğ‘–ğ‘” ğ‘–}/ğ‘ ğ‘–(ğœ½ +ğ‘¡p).Other-
wisesetğ‘  = ğœandreturnto(T1).170 Continuous-TimeMCMC
ToseethatthisisavalidPoissonthinningalgorithmtosimulateeventswith
rateğœ†Ëœ(ğ‘–)(ğ‘¡),wejustneedtocalculatetheprobabilityofacceptinganevent
z
in step (T3). By averaging over the possible realisation of ğ‘” ğ‘– in step (T2)
andusingthefactthatbydefinitionforanyğ‘” ğ‘–,theprobabilityinstep(T3)
islessthanorequalto1,thisis
E[max{0,ğ‘ ğ‘–ğº ğ‘–}/ğ‘ ğ‘–(ğœ½ +ğ‘¡p)] =
E[m ğ‘a ğ‘–(x ğœ½{0 +, ğ‘¡ğ‘ pğ‘–ğº
)
ğ‘–}]
=
ğ‘
ğ‘–ğœ† (Ëœ ğœ½z(ğ‘–) +(ğ‘¡ ğ‘¡)
p),
asrequired.
Howdoesthisidearelatetotheuseofsubsampling?Considerğœ‹beinga
posteriordistribution,andsupposethatlogğœ‹canbewrittenasasum
ğ‘
âˆ‘ï¸
logğœ‹(ğœ½) = logğœ‹ ğ‘—(ğœ½),
ğ‘—=1
where logğœ‹ ğ‘— for ğ‘— = 1,...,ğ‘ is 1/ğ‘ times the log-prior plus the log-
likelihood contributions from the ğ‘—th data point. Then this gives a simple
wayofconstructinganunbiasedestimatorofâˆ’âˆ‡logğœ‹(ğœ½),bysimulating ğ¼
uniformlyon{1,...,ğ‘}andsettingG(ğœ½) toâˆ’ğ‘âˆ‡logğœ‹ ğ¼(ğœ½).
The advantageof using suchan unbiased estimatorwithin theZigâ€“Zag
SampleristhatateachiterationofthePoissonthinningalgorithmusedto
simulate an event, i.e. step (T2) and (T3) above, we need to process only
one data point. This gives a per-iteration saving of a factor of ğ‘ over the
standardZigâ€“ZagSamplerwhichrequirescalculatingderivativesoflogğœ‹.
However, there are additional costs to using this subsampling idea. First,
often the bounds that we use for Poisson thinning will be larger if we use
subsampling â€“ as they have to bound the rate for all possible realisations
of ğ‘” ğ‘–. This will lead to more iterations of the Poisson thinning algorithm
to simulate the PDMP for the same amount of (stochastic process) time.
Second, as we are no longer using the canonical rates we will introduce
more events, and this will lead to more random-walk-like behaviour and
slower mixing. Empirical results in Bierkens et al. (2019b) suggest that
the overall effect of these is to counteract the factor of ğ‘ improvement in
per-iterationcost.
SocansubsamplingideaswithinPDMPsbebeneficial?Itturnsoutthey
can,butwemustuseabetter,i.e.lowervariance,estimatorforG.Thiscan
bedoneusingcontrolvariateideasthatarecommoninSGLD(seeSection
3.3.1). We first run an optimisation algorithm, such as SGD, to find the
mode or a value close to the mode of logğœ‹. Denote this value by(cid:98)ğœ½. Then5.4 EfficientSimulationofPDMPSamplers 171
wecanwrite
ğ‘
âˆ‘ï¸
logğœ‹(ğœ½) =logğœ‹((cid:98)ğœ½)+ {logğœ‹ ğ‘—(ğœ½)âˆ’logğœ‹ ğ‘—((cid:98)ğœ½)}.
ğ‘—=1
Soanunbiasedestimatorcanbeobtainedbyfirstsampling ğ¼ uniformlyon
{1,...,ğ‘}andthensettingG(ğœ½) to
âˆ’logğœ‹((cid:98)ğœ½)âˆ’ğ‘{âˆ‡logğœ‹ ğ¼(ğœ½)âˆ’âˆ‡logğœ‹ ğ¼((cid:98)ğœ½)}.
Importantlythetermâˆ’logğœ‹((cid:98)ğœ½) isaconstant,sorequiresasingleup-front
ğ‘‚(ğ‘) cost to calculate it. Then evaluating a realisation of this estimator
has ğ‘‚(1) cost. If the Hessian of âˆ’logğœ‹ is bounded, then Bierkens et al.
(2019b)showthatwecanobtaintheboundsneededtosimulatetheZigâ€“Zag
Samplerusingthisunbiasedestimatorusingthelinearboundsdescribedfor
boundedHessiantargetsinSection5.4.1.Inthiscase,forafixedaccuracy
ofthefinalMonteCarlosample,wecanobtainaspeed-upbyafactorofğ‘,
afterfinding(cid:98)ğœ½ andcalculatingâˆ’logğœ‹((cid:98)ğœ½),relativetothestandardZigâ€“Zag
Sampler.
Example:SubsamplingforLogisticRegression
To further explain how to implement the Zigâ€“Zag Sampler with subsam-
pling,wewillconsiderthelogisticregressionmodel.Tosimplifyexposition
wewillassumethatwehaveanimproperflatprior,sointhenotationabove
ğœ‹ (ğœ½) âˆ1.Thuswecandropthecontributionofthepriortoğœ‹andwehave
0
ğœ‹(ğœ½) âˆ(cid:206)ğ‘ ğ‘—=1ğœ‹ ğ‘—(ğœ½) with
ğœ‹ ğ‘—(ğœ½) = (cid:32) 1ex +p e{ xğ‘¦ pğ‘— {x xâŠ¤ ğ‘— âŠ¤ğœ½ ğœ½} }(cid:33) ,
ğ‘—
where ğ‘¦ ğ‘— is the binary response and xğ‘— is the vector of covariates for the
ğ‘—thobservation.
Takingthefirstderivativesofâˆ’logğœ‹(ğœ½) gives
(cid:40) (cid:41)
âˆ’ğœ•logğœ‹ ğ‘—(ğœ½)
=ğ‘¥(ğ‘–)
exp{xâŠ¤ ğ‘—ğœ½}
âˆ’ğ‘¦ .
ğœ•ğœƒ
ğ‘–
ğ‘— 1+exp{xâŠ¤ ğ‘—ğœ½} ğ‘—
Using 0 â‰¤ exp(ğ‘)/(1 + exp(ğ‘)) â‰¤ 1, we have that the modulus of this
derivativeisboundedbyğ‘¥(ğ‘–).Thusifweusetheunbiasedestimator
ğ‘—
ğº ğ‘–(ğœ½)
=âˆ’ğ‘ğœ•log ğœ•ğœƒğœ‹ ğ¼(ğœ½)
, ğ¼ uniformlydistributedon{1,...,ğ‘},
ğ‘–172 Continuous-TimeMCMC
thenwecanboundtherateofaneventby
ğ‘ ğ‘–(ğœ½) = ğ‘ max |ğ‘¥( ğ‘—ğ‘–)|.
ğ‘—=1,...,ğ‘
Inthefollowing,wewillcalltheresultingsamplerZigâ€“Zagwithsubsam-
pling.
Howaboutifweusecontrolvariates?Fix(cid:98)ğœ½,andconsidertheestimator
ofthegradient
(cid:32) (cid:33)
ğº(ğ¶ğ‘‰)(ğœ½)
=âˆ’ğœ•logğœ‹((cid:98)ğœ½)
âˆ’ğ‘
ğœ•logğœ‹ ğ¼(ğœ½)
âˆ’
ğœ•logğœ‹ ğ¼((cid:98)ğœ½)
,
ğ‘– ğœ•ğœƒ ğœ•ğœƒ ğœ•ğœƒ
ğ‘– ğ‘– ğ‘–
withagain,ğ¼ isuniformlydistributedon{1,...,ğ‘}.Toobtainappropriate
boundsforp(ğ‘—)G(ğ‘—)(ğœ½),considerthesecondderivatives
ğ¶ğ‘‰
(cid:40) (cid:41)
âˆ’ğœ•2logğœ‹ ğ‘—(ğœ½)
=ğ‘¥(ğ‘–)x(ğ‘™)
exp{xâŠ¤ ğ‘—ğœ½}
.
ğœ•ğœƒ ğ‘–ğœ•ğœƒ
ğ‘™
ğ‘— ğ‘— (1+exp{xâŠ¤ ğ‘—ğœ½)})2
As before using that 0 â‰¤ exp(ğ‘)/(1 + exp(ğ‘))2 â‰¤ 1/4, we can bound
the modulus of this second derivative by
(1/4)|x(ğ‘–)x(ğ‘™)|.
This gives the
ğ‘— ğ‘—
followingbound
(cid:12) (cid:12)
(cid:12)ğœ•logğœ‹ ğ‘—(ğœ½ +ğ‘¡p) ğœ•logğœ‹ ğ‘—((cid:98)ğœ½)(cid:12)
(cid:12) âˆ’ (cid:12)
(cid:12) ğœ•ğœƒ ğœ•ğœƒ (cid:12)
(cid:12) ğ‘– ğ‘– (cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)ğœ•logğœ‹ ğ‘—(ğœ½ +ğ‘¡p) ğœ•logğœ‹ ğ‘—(ğœ½)(cid:12)
(cid:12)
(cid:12)ğœ•logğœ‹ ğ‘—(ğœ½) ğœ•logğœ‹ ğ‘—((cid:98)ğœ½)(cid:12)
â‰¤ (cid:12) âˆ’ (cid:12)+(cid:12) âˆ’ (cid:12)
(cid:12) ğœ•ğœƒ ğ‘– ğœ•ğœƒ ğ‘– (cid:12) (cid:12) (cid:12) ğœ•ğœƒ ğ‘– ğœ•ğœƒ ğ‘– (cid:12) (cid:12)
1 (cid:16) (cid:17)
â‰¤ 4|ğ‘¥( ğ‘—ğ‘–)|âˆ¥xğ‘–âˆ¥ âˆ¥ğœ½ âˆ’(cid:98)ğœ½âˆ¥+ğ‘¡âˆ¥pâˆ¥ , (5.16)
whereâˆ¥Â·âˆ¥denotestheEuclideannorm.Thelatterinequalitycomesfrom(i)
boundingthechangeinafunctionbythesizeofthechangeintheargument
timesaboundonthegradientinthedirectionofthechange;and(ii)asthe
gradient ğœ•logğœ‹ ğ‘—/ğœ•ğœƒ ğ‘– isboundedby (1/4)|x( ğ‘—ğ‘–)x( ğ‘—ğ‘™)| intheğ‘™thdirection,we
canboundthedot-productofthegradientwithavectorvby
ğ‘‘ ğ‘‘
âˆ‘ï¸1 4|ğ‘¥( ğ‘—ğ‘–)ğ‘¥( ğ‘—ğ‘™)ğ‘£ ğ‘™| = 1 4|ğ‘¥( ğ‘—ğ‘–)|âˆ‘ï¸ |ğ‘¥( ğ‘—ğ‘™)ğ‘£ ğ‘™| â‰¤ 1 4|ğ‘¥( ğ‘—ğ‘–)|âˆ¥xğ‘–âˆ¥âˆ¥vâˆ¥,
ğ‘™=1 ğ‘™=1
withthelaststepusingCauchyâ€“Schwarz.
Using (5.16), we get the following linear bound on the rate of events5.4 EfficientSimulationofPDMPSamplers 173
whenweusecontrolvariates.
max{0,ğ‘ ğ‘–ğº ğ‘–(ğ¶ğ‘‰)(ğœ½ +ğ‘¡p)}
(cid:40) (cid:41)
ğœ•logğœ‹((cid:98)ğœ½) 1 (cid:16) (cid:17)
â‰¤ max 0,âˆ’ğ‘ ğ‘– ğœ•ğœƒ
ğ‘–
+ 4ğ‘ğ‘€ ğ‘– âˆ¥ğœ½ âˆ’(cid:98)ğœ½âˆ¥+ğ‘¡âˆ¥pâˆ¥ ,
where ğ‘€ ğ‘– = maxğ‘—=1,...,ğ‘(|ğ‘¥( ğ‘—ğ‘–)|âˆ¥xğ‘—âˆ¥). In the following, we will call the
resultingsamplerZigâ€“Zagwithcontrolvariates.
To demonstrate how subsampling works in practice and the scaling of
the methods with sample size we will compare three PDMP samplers for
logisticregressionwithsamplesizesofğ‘ =100andğ‘ =900.Thesearethe
standard Zigâ€“Zag Sampler, Zigâ€“Zag with subsampling and Zigâ€“Zag with
controlvariates.Inparticular,wewanttogiveintuitionaboutthedifferent
impacts of the computational cost for estimating gradients, the efficiency
ofthePoissonthinningboundsonsimulatingevents,andthemixingofthe
PDMPonthethreealgorithms.
Results are shown in Figure 5.6. There are a number of points to draw
out. First, we see the potential advantage of subsampling in reducing the
cost per iteration of the samplers. If this is dominated by accessing and
calculatinggradientsforeachdatapoint,thenthesubsamplingversionsof
Zigâ€“Zagareabletoproposemanymoreeventtimes(asseenbythelarger
numberofbluedotsforthemiddleandbottomrows).However,thisinitself
doesnotleadtoamoreaccurateMCMCmethodforthesamecomputational
costâ€“asthedrawbackofsubsamplingisthattheboundsusedforPoisson
thinning are worse. About two proposed events are needed for one actual
event with standard Zigâ€“Zag, but this reduces to over 10 proposed events
forthetwosamplerswhichusesubsampling.
One impact of this is, if we consider ğ‘ = 100 then the standard Zigâ€“
Zag process is simulated for stochastic process time of 80 time units, and
this is only increased to 130 time units for Zigâ€“Zag with subsampling
and 160 time units for Zigâ€“Zag with control variates. Moreover, the Zigâ€“
Zagprocesseswhichusesubsamplinghaveahigheroverallrateofevents,
particularlywhencontrolvariatesarenotused.Thisleadstomorerandom-
walk behaviour for Zigâ€“Zag with subsampling (see middle row) which
worsens the mixing of the sampling. This is less of an issue when we use
controlvariates.
Next,considerthescalingofthealgorithmsbycomparingğ‘ =100with
ğ‘ = 900. First, the posterior for ğ‘ = 900 is more concentrated, but if we
re-scaleaxes(ashasbeendoneintheplots)thentheposteriorcontoursand
thedynamicsofstandardZigâ€“Zagaresimilarforthetwocases.However,if174 Continuous-TimeMCMC
Figure5.6 ExampleoutputofZigâ€“ZagSamplersforlogistic
regression:standardZigâ€“Zag(toprow),Zigâ€“Zagwith
subsampling(middlerow)andZigâ€“Zagwithcontrolvariates
(bottomrow).Foreachplot,theheatmapshowsthecontoursof
logğœ‹,theblacklineshowsthetrajectoryofZigâ€“Zagandtheblue
dotsshowthepointswhereweproposeapossibleevent.Inall
cases,weranZigâ€“Zagforthesamenumberofdata-pointgradient
calculations.Asthetoprowdoesnotinvolvesubsampling,this
meansweproposeğ‘-timesasmanyeventsforthemiddleand
bottomrowsasforthetoprow.Resultsforğ‘ =100(left-hand
column)andğ‘ =900(right-handcolumn).5.5 Extensions 175
wehavefixedthecomputationalresource,thentheimpactonstandardZigâ€“
Zag is that we can only simulate the process for a shorter period â€“ in this
casesimulating9timesfeweractualevents.ForZigâ€“Zagwithsubsampling,
we are able to propose the same number of events, but the higher rate of
events and the looser bound for Poisson thinning means that we are only
abletosimulateatrajectorythatisonly4timesaslongasforthestandard
Zigâ€“Zag, despite proposing 900 times as many events. Moreover, we see
thatthetrajectoryisincreasinglydiffusiveandthustheoverallexploration
of the state-space of this sampler qualitatively looks no better than for
standard Zigâ€“Zag. This property is shown more rigorously by Bierkens
et al. (2019b), who show that the scaling with ğ‘ of the standard Zigâ€“Zag
andZigâ€“Zagwithsubsamplingissimilar.Moreover,theirempiricalresults
suggest that for the same computational cost, standard Zigâ€“Zag is more
accurate.
Bycomparison,weseebettermixingbehaviourforZigâ€“Zagwithcontrol
variates.Thesamplerisabletosimulateatrajectorythatisapproximately
ten times as long as the standard Zigâ€“Zag. Moreover, the mixing looks
qualitatively similar to that of the algorithm for ğ‘ = 100 and to that of
thestandardZigâ€“Zagfor ğ‘ =900.Thisisagainshownmorerigorouslyin
Bierkensetal.(2019b),whereresultssuggestthattheaccuracyasmeasured,
say,byeffectivesamplesizeperCPUcostscalesbyafactorofğ‘ betterfor
Zigâ€“Zag with control variates than for the other two samplers. However,
Zigâ€“Zagwithcontrolvariatesdoesneedanadditionalpre-processingstep
tofindthemode,oravaluenearthemode,oftheposteriorandtocalculate
thegradientofthelogposterioratthisestimateofthemode.Thisimproved
scaling has been termed super-efficiency, and the fact that we can only
achieve super-efficiency after a pre-processing step is shown theoretically
byJohndrowetal.(2020).
5.5 Extensions
ThePDMPsamplerswehaveconsideredsofarareappropriateforsampling
fromcontinuousdensitiesthataredifferentiablealmosteverywhereandare
basedonspecificconstantvelocitydynamics.Wenowdescriberecentwork
atgeneralisingthesamplers:toallowsamplingfromdiscontinuoustargets;
introduce reversible-jump moves to allow sampling from targets defined
acrossspacesofdifferentdimension;andgeneralisethevelocityspaceand
theconstantvelocitydynamics.176 Continuous-TimeMCMC
5.5.1 DiscontinuousTargetDistribution
The PDMP samplers we have described can sample from target densities
thataredifferentiableeverywhere.Itisalsoeasytoseethattheyaresuitable
for densities that are non-differentiable, providing the set of points where
the density is not differentiable is a null set. However, as described, they
cannotbeusedfordensitiesthatarenotcontinuouseverywhere.
It is possible to extend PDMP samplers so they are suitable for many
discontinuoustargetdensities.TheideaistousestandardPDMPdynamics
inregionswherethetargetiscontinuous,andthenaddadditionaldynamics
wheneverthePDMPsamplerreachesapointofdiscontinuity.Thisapproach
has been suggested by Bierkens et al. (2018) for continuous densities,
but defined only on a compact region, and by Chevallier et al. (2021) in
moregenerality.Wewilloutlinethebasicideaandgivesomeexamplesof
appropriatedynamicsatpointsofdiscontinuityfordifferentsamplers.
Assume our target density ğœ‹(ğœ½) can be defined in terms of a set of
continuous densities, ğœ‹(ğ‘–), each constrained to a set of open regions ğ¸ ğ‘– of
Rğ‘‘,forğ‘– =1,...,ğ¾ forsomeğ¾.LetÎ“bethesetofğœ½ pointsthatlieonthe
boundaryofoneormoreregions,andassumethisisanull-setwithrespect
toLebesguemeasureofRğ‘‘.Weassumethatğ¸
ğ‘–
andÎ“partitionRğ‘‘,sothat
anyğœ½ âˆˆ Rğ‘‘ liesinpreciselyoneofğ¸ 1,...,ğ¸ ğ¾,Î“.Forğœ½ âˆ‰ Î“,ourtargetis
ğœ‹(ğœ½) = ğœ‹(ğ‘–)(ğœ½) forğœ½ âˆˆ ğ¸ ğ‘–.
The simplest example of such a density will be for ğœ½ constrained to some
compactregion,ğ¸ .InthiscasewehaveÎ“astheboundaryofğ¸ andğ¸ is
1 1 2
thecomplementofğ¸ âˆªÎ“,withğœ‹(2)(ğœ½) =0forğœ½ âˆˆ ğ¸ .
1 2
The idea is that we can define a PDMP sampler that is appropriate for
each ğœ‹(ğ‘–),butneedtonowdefinewhathappenswhenthe ğœ½ componentof
thestatetriestoleaveğ¸ ğ‘–.Toexplainthis,whilstkeepingthenotationsimple,
wewillconsiderthecaseofğ¾ =2regions,anddescribeconditionsforthe
PDMP sampler on the boundary between ğ¸ and ğ¸ that are sufficient for
1 2
it to target ğœ‹(ğœ½) as defined above. Extending this to ğ¾ > 2 is trivial as
we just applythe same conditions toeach boundary between tworegions.
(We do not need to consider behaviour at points that lie on the boundary
betweenthreeormoreregionsasthesamplerwillnothitsuchpointswith
probability1.)
For ğœ½ âˆˆ Î“, let n(ğœ½) be the normal to the boundary and assume that
thenormalisdefinedtopointoutofregion ğ¸ .AssumewehaveaPDMP
1
samplerwithvelocitysetVandwithstationarydistributionforthevelocity
componentthatisindependentofğœ½ andisdenotedby ğœ‹ .Oncewehitthe
p5.5 Extensions 177
boundary,thevelocitywilldeterminewhetherthestateismovingoutofğ¸
1
andinto ğ¸ orvice-versa.Todistinguishthesetwopossibilities,definefor
2
eachğœ½ âˆˆ Î“
V+ = (cid:8) p âˆˆ V :n(ğœ½)âŠ¤p > 0(cid:9), and Vâˆ’ = (cid:8) p âˆˆ V :n(ğœ½)âŠ¤p < 0(cid:9).
ğœ½ ğœ½
So,forexample,ifthestateis(ğœ½,p)forğœ½ âˆˆ Î“andp âˆˆ V+thenthesampler
ğœ½
wasinregionğ¸ andismovingintoğ¸ .
1 2
Nowdefineafamilyofprobabilitydensity,orprobabilitymass,functions
forp âˆˆ V,as
(cid:26) |n(ğœ½)âŠ¤p|ğœ‹ (p)ğœ‹(2)(ğœ½) ifp âˆˆ V+
â„“ (p) = p ğœ½
ğœ½ |n(ğœ½)âŠ¤p|ğœ‹ (p)ğœ‹(1)(ğœ½) otherwise
p
This is just proportional to the density ğœ‹ (p) weighted by the size of the
p
velocityinthedirectionofthenormaln(ğœ½) andweightedbythedensityat
ğœ½ intheregionthatthesamplerismovingto.
Finally,defineafamilyoftransitionkernelsforthevelocitycomponent,
Qğ‘(pâ€² âˆˆ Â·|p)foreachğœ½ âˆˆ Î“.Thefollowingtheorem,takenfromChevallier
ğœ½
et al. (2021), gives appropriate dynamics for our PDMP sampler on the
boundary.
Theorem 5.4 Assume ğœ‹ is symmetric, so ğœ‹ (p) = ğœ‹ (âˆ’p), and that for
p p p
each ğœ½ âˆˆ Î“ the transition kernel Qğ‘ has â„“ as its invariant distribution.
ğœ½ ğœ½
ThenaPDMPsamplerwith:
(i) dynamics for ğœ½ âˆˆ ğ¸ ğ‘–, for ğ‘– = 1,2, that have invariant distribution
ğœ‹(ğ‘–)(ğœ½)ğœ‹ (p);and
p
(ii) forğœ½ âˆˆ Î“hasatransitionthatkeepsğœ½ unchangedbutthat:
(B1) flipsthevelocitypâ€² =p;
(B2) updatesthevelocityaccordingtoQğ‘,i.e.pâ€²â€² âˆ¼Qğ‘(Â·,pâ€²);and
ğœ½ ğœ½
(B3) updatesthestateofthePDMPto (ğœ½,pâ€²â€²);
willhaveinvariantdistributionğœ‹(ğœ½)ğœ‹ (p).
p
Steps (B1) â€“ (B3) of the theorem give appropriate dynamics for the
velocitywhenwehittheboundary,with(B2)statedintermsofatransition
kernelthathasâ„“ asitsinvariantdistribution.
ğœ½
Therearevariouspossiblechoicesofdynamicsduetodifferentchoices
forthetransitionkernel.AtrivialchoiceforQğ‘ istheidentitymap.Inthis
ğœ½
case, the transition at the boundary is to reverse the sign of the velocity,
whichmeansthatthesamplerwillneverleavetheregionthatitstartswith.
Thusthischoiceisonlysuitableforthecasewherewestartthesamplerin
ğ¸ andwhere ğœ‹(2)(ğœ½) = 0,i.e.thereisnoprobabilitymassin ğ¸ .Evenin
1 2178 Continuous-TimeMCMC
thiscase,thischoicemaynotbeagoodone,asitwillforcethesamplerto
retraceitsstepsonceithitstheboundary,whichwillslowdownmixing.
An alternative choice is to define Qğ‘ to be independent of the current
ğœ½
velocity,andjusttoinvolvesamplingfromâ„“ .Theproblemwiththisisthat
ğœ½
sampling from â„“ may be difficult. For both the Coordinate Sampler and
ğœ½
the Zigâ€“Zag Sampler, â„“ is a discrete distribution, and can be calculated
ğœ½
exactly. For the Coordinate Sampler, p can take 2ğ‘‘ possible values, and
this approach can be reasonable. However, for the Zigâ€“Zag Sampler, p
cantake2ğ‘‘ possiblevalues,andthuscalculatingandsimulatingfromâ„“ is
ğœ½
prohibitiveunlessğ‘‘issmall.Incaseswhereâ„“ isdifficulttosamplefromone
ğœ½
can instead use Metropolisâ€“Hastings to define a transition kernel that has
therequiredinvariantdistribution.Thisinvolvesproposinganewvelocity
fromanarbitraryproposaldistributionandthenacceptingorrejectingthat
proposal.Theproblemwiththisisthatiftheacceptanceprobabilityisnot
high then we are likely to reject the proposal, and our new velocity will
justbeminusthevelocitywithwhichwehittheboundary,fromstep(B1),
which will inhibit mixing. A partial solution is to define Qğ‘ to involve
ğœ½
ğ¿ > 1 Metropolisâ€“Hastings steps, though this comes with an increased
computationalcostofsamplingfromQğ‘.
ğœ½
FortheBouncyParticleSampler,thereisasimpleandverynaturalchoice
ofdynamicsattheboundarywhichsatisfiestheconditionofTheorem5.4.
Ifp âˆˆ V+,sowearecurrentlymovingoutofğ¸ thenthedynamicsare:
ğœ½ 1
(R1) Withprobabilitymin{1,ğœ‹(2)(ğœ½)/ğœ‹(1)(ğœ½)}thevelocityisunchanged,i.e.
pâ€²â€² =p;
(R2) Otherwise,wereflectthevelocityinthetangenttotheboundaryatğœ½,i.e.
usingthenotationintroducedforreflectionspâ€²â€² = R (p).
n(ğœ½)
If p âˆˆ Vâˆ’, then the dynamics are as above but with ğœ‹(1) and ğœ‹(2) inter-
ğœ½
changedin(R1).Underthesedynamics,ifthesamplerismovingtoaregion
ofhigherprobabilitydensity,itcontinues.Ifnot,thenwithsomeprobability
itcontinues,otherwiseitreflectsback.Aspecialcasewherewehaveğœ‹(ğœ½)
definedonlyonthecompactregion ğ¸ ,sothat ğœ‹(2)(ğœ½) = 0,inwhichcase
1
thesamplerwillalwaysreflectifithitstheboundary.
We cannot apply similar dynamics for the Zigâ€“Zag Sampler unless the
boundary aligns appropriately with the velocity axes, as the reflected ve-
locity in step (R2), R (p), may no longer be a valid velocity. However,
n(ğœ½)
Chevallieretal.(2021)showthattheabovedynamicsfortheBouncyParti-
cleSamplercanbeviewedasthebehaviouroftheBouncyParticleSampler
ifweapproximatethediscontinuoustargetbyacontinuousone,bysmooth-
ing out the discontinuity, but then consider the limit where we allow the5.5 Extensions 179
transitionbetween ğœ‹(1) and ğœ‹(2) tooccurmorequickly.Bythesamestrat-
egy, we can construct an appropriate transition kernel for Zigâ€“Zag, see
Chevallieretal.(2021)formoredetails.
Example:LogisticRegressionwithConstraints
Asanexampleapplicationforthisalgorithm,considerthelogisticregres-
sion model but with constraints on the parameters. There are two natural
constraints,oneisthatwemayknowthattheeffectofacovariateissuchthat
largervalueswillincrease,say,theprobabilityofobservingaresponseof
1.Iftheğ‘–thcomponentofthexğ‘—sissuchacovariate,thenğœƒ ğ‘– â‰¥ 0.Similarly,
ifanincreaseintheğ‘–thcomponentofthecovariatevectorisknowntolead
to a decrease in the probability, then ğœƒ ğ‘– â‰¤ 0. Alternatively, we may have
someconstraintsonthesizeoftheeffect,e.g.ğœƒ ğ‘– â‰¥ ğœƒ ğ‘™.
For the Bouncy Particle Sampler, the simplest way of including such a
constraintistocalculatethetimewhenthecurrentdeterministicdynamics
will first violate the constraint. If an event does not happen by this time,
thenwejustreflectthevelocityofftheboundaryofğœ½ spaceimpliedbythe
constraint. For the constraint ğœƒ ğ‘– â‰¥ 0 or ğœƒ ğ‘– â‰¤ 0 this would involve flipping
theğ‘–th component of the velocity. For the constraint ğœƒ ğ‘– â‰¥ ğœƒ ğ‘™, this involves
thereflectionR
g
withgdefinedsoğ‘”
ğ‘–
= 1,ğ‘”
ğ‘™
= âˆ’1andallotherentriesset
tozero.
Inthisexample,wecanusethesameadaptiontotheZigâ€“ZagSampler,
as for each constraint the reflection at the boundary will produce a new
velocity that is valid for the sampler. However, this would not be the case
if,forexample,wewantedtoenforceaconstraintsuchasğœƒ > 2ğœƒ .
1 2
5.5.2 ReversibleJumpPDMPSamplers
Another class of distributions that the standard PDMP samplers are not
suitableforaredistributionsdefinedonasetofspacesofdifferentdimen-
sions. In the following, we think of this in terms of a distribution over a
discrete set of models, with a continuous density for each model. Whilst
PDMPscanbeusedtoexplorethedistributiondefinedforeachmodel,we
wouldneedawayofmovingbetweenthesemodelsâ€“whichwouldleadto
atypeofreversiblejumpversionofPDMPsamplers.
Oneapproachtodothisistoaddadditionaleventsthatintroducediscrete
jumpsfromonespacetoanother.Suchmoveshavebeenproposedforother
continuous-time samplers, see Grenander and Miller (1994), Phillips and
Smith(1996)andStephens(2000).However,theycanbehardtoimplement
duetochallengeswithsimulatingthesemoveswiththecorrectrate.180 Continuous-TimeMCMC
Acomputationallymoreefficientprocedureexistsifthedifferentmodels
aredefinedintermsofsomecommonğ‘‘-dimensionalparameterğœ½,buteach
model fixes one or more components of ğœ½ to a specific value. The most
common example of such a distribution is the posterior distribution for
the coefficients of a linear or generalised linear regression model, where
different models correspond to including different sets of covariates in
the model. Thus we can define ğœ½ to be the coefficients for the full set of
covariates, and a given model will fix the coefficients of covariates not in
themodeltozero.
TomotivatetheformofthePDMPsamplerswewillintroduce,consider
first the case where we have a single covariate, so ğ‘‘ = 1. Also, ignore
havinganyinterceptinthelinearorgeneralisedlinearmodel.Wenowhave
twomodels,dependingonwhetherweincludethecovariateornot.Ifâ„“(ğœƒ)
denotes the likelihood as a function of ğœƒ and if we have a prior that is a
mixture of point mass at 0, which we will denote by ğ›¿ (ğœƒ), and a prior
0
definedonR,ğœˆ(ğœƒ),thentheposteriordistributionis
ğœ‹(ğœƒ) âˆ ğ‘¤ğ›¿ (ğœƒ)â„“(ğœƒ)+(1âˆ’ğ‘¤)ğœˆ(ğœƒ)â„“(ğœƒ),
0
whereğ‘¤isthepriorprobabilityofexcludingthecovariate.Whilstwecannot
use a standard PDMP to sample from this target, we can approximate the
prior by replacing the point mass at zero with a distribution concentrated
aroundzero.IfweuseaGaussiandensitywithvarianceğœ2forğœ â‰ˆ0,then
wehavethetarget
ğœ‹ ğœ(ğœƒ) âˆ ğ‘¤N(ğœƒ;0,ğœ2)â„“(ğœƒ)+(1âˆ’ğ‘¤)ğœˆ(ğœƒ)â„“(ğœƒ), (5.17)
whereN(ğœƒ;0,ğœ2) denotesthedensityofaGaussianwithmean0andvari-
anceğœ2.WecannowuseaPDMPtosamplefromthisposteriordistribution.
Alsobylettingğœ â†’0wehavethatthisposteriorwilltend,insomesense,
totheposteriorwiththepointmassat0.Soanaturalapproachistoconsider
the dynamics of the PDMP targeting ğœ‹ ğœ and whether we get well-defined
dynamicsinthelimitofğœ â†’0.
Figure5.7showsthedynamicsforthreedifferentvaluesofğœ.Weseethat
in each case the sampler will spend periods of time in the neighbourhood
of0.Aswereduceğœ,theseneighbourhoodsconcentratecloserto0butthe
time the sampler spends in them seems to be similarly distributed. Away
fromtheneighbourhood,thedynamicsarethoseofsamplingfromadensity
proportionaltoğœˆ(ğœƒ)â„“(ğœƒ).Thissuggeststhelimitingbehaviourwouldbethat
ofaPDMPtargetingğœˆ(ğœƒ)â„“(ğœƒ)butthatifğœƒ ğ‘¡ hitszerothenthesamplerstays
atzeroforarandomamountoftime.
Chevallieretal.(2023)proposesuchaPDMPsampler,andshowthatif5.5 Extensions 181
     
     
     
              
t t t
Figure5.7 ExampleoutputfromPDMPsamplerforatargetthat
isanequalmixtureofaN(0,1)distributionandağ‘(0,ğœ2)
distributionforğœ =0.1(left),ğœ =0.01(middle)andğœ =0.001
(right).Asğœ â†’0thetrajectoriesqualitativelyconvergeto
periodsat,orcloseto0,andperiodswherethetrajectoryis
governedbytheN(0,1)distribution.Thislimitistheformforthe
reversiblejumpPDMPsampler.Thecomputationaladvantageof
usingthelimitingdynamicsisthatitavoidssimulatingthelarger
numberofeventscloseto0â€“whichwasoftheorderof10000for
theright-handplot.
wespecifythedynamicsasgivenbelowitwilltargetthecorrectdistribution
across models. To describe the sampler for a ğ‘‘-dimensional parameter ğœ½,
assumethat
2ğ‘‘
âˆ‘ï¸
ğœ‹(ğœ½) = ğœ‹ ğ‘˜(ğœ½),
ğ‘˜=1
whereweassumethateachmodel ğ‘˜ correspondstoadifferentsetofcom-
ponents of ğœ½ being set to zero. Here, ğœ‹ ğ‘˜(ğœ½) is, up to proportionality, the
densityofğœ½associatedwiththeğ‘˜thmodel.Thesedensitiesmustbedefined
uptoacommonconstantofproportionalityacrossallmodels.
Formodelğ‘˜,letS
ğ‘˜
betheactivesetofmodelğ‘˜,thatisthesetofindices
ofcomponentsof ğœ½ thatarenon-zeroformodel ğ‘˜.TheideaofthePDMP
isthatifwearecurrentlyexploringmodelğ‘˜ wewillsimulateaPDMPthat
targetsğœ‹ ğ‘˜(ğœ½),andthathasnon-zerovelocityonlyforcomponentsofğœ½ that
areinS ğ‘˜.Butinaddition,weallowtwofurtherevents.Thefirstisthatifa
componentofğœ½hitszero,andwedenotethiscomponentbyğ‘–,thenwemove
tothemodelwithactivesetS ğ‘˜\{ğ‘–}.Thesecondisthatforeach ğ‘— âˆ‰ S ğ‘˜ we
have a rate of moving to the model with active set S ğ‘˜ âˆª{ğ‘—}. If we move
tosuchamodelwedonotchangeğœ½,butsimulateanewvelocityp,which
willhaveanon-zerovelocityforcomponent ğ‘—.
To define such a sampler we just need to specify the rate of adding
Î¸ t Î¸ t Î¸ t182 Continuous-TimeMCMC
a component to the model, and the distribution of the velocity after the
transition.WewilldescribethesefortheZigâ€“ZagSamplerandtheBouncy
Particle Sampler. For general results, and generalisations of this sampler
whichdoesnotalwaysmovebetweenmodelswhenacomponentofğœ½ hits
zero,seeChevallieretal.(2023).
FortheZigâ€“ZagSampler,assumingweareinmodelğ‘˜ withcurrentstate
(ğœ½,p),wehavethefollowingprocessforaddingavariabletothemodel.
(Addâ€“ZZ) For each ğ‘— âˆ‰ S ğ‘˜, move to model ğ‘˜â€² with active set S ğ‘˜ âˆª {ğ‘—} at rate
ğœ‹ ğ‘˜â€²(ğœ½)/ğœ‹ ğ‘˜(ğœ½). Set the new velocity, pâ€², such that ğ‘ ğ‘–â€² = ğ‘ ğ‘– forğ‘– â‰  ğ‘— and
ğ‘â€² isdrawnuniformlyatrandomfrom{âˆ’1,1}.
ğ‘—
For the Bouncy Particle Sampler, with standard Gaussian distribution for
the velocity, again assuming we are in model ğ‘˜, with current state (ğœ½,p),
wehavethefollowing
(Addâ€“BPS) Foreach ğ‘— âˆ‰S ğ‘˜,movetomodel ğ‘˜â€² withactivesetS ğ‘˜ âˆª{ğ‘—}atrate
âˆš2 ğœ‹ ğ‘˜â€²(ğœ½)
.
2ğœ‹ ğœ‹ ğ‘˜(ğœ½)
Set the new velocity, pâ€², such that ğ‘ ğ‘–â€² = ğ‘ ğ‘– for ğ‘– â‰  ğ‘— and ğ‘â€² ğ‘— = ğ‘¥ is
simulatedfromadistributionwithdensityfunctionproportionalto
(cid:26) (cid:27)
1
|ğ‘¥|exp âˆ’ ğ‘¥2 ,
2
thisisastandardnormaldensityfunctionscaledby |ğ‘¥|.
TheintuitionforthedensityofthenewvelocitycomponentfortheBouncy
ParticleSampleristhatitisskewed,relativetoitsinvariantdistribution,to
largerabsolutevaluesofthevelocityasthesecorrespondtovelocitiesthat
wouldhitzeromorequickly.
Importantly for both samplers, the rates at which we add components
will often be simple. If our target distribution is defined as a posterior
distribution, with common likelihood for each model, then the likelihood
componentsoftheposteriorswillcancelandtherateswilljustdependon
theratioofpriors.Formanypriors,thedistributionofeachcomponentof
ğœ½ willbeindependent,inwhichcasetheseratesbecomeconstant.
FortheZigâ€“ZagSampler,onecanimproveonthissamplerbyremember-
ing the velocity of each inactive component prior to it becoming inactive.
Then,whenthatcomponentisre-introducedtothemodelwere-usethesame
velocity.ThisistheStickyZigâ€“ZagSamplerofBierkensetal.(2023b).It5.5 Extensions 183
can mix better as it ensures that the dynamics of each component of ğœ½
reflectslessoften.
Example:LogisticRegressionwithModelChoice
AnextensiontothelogisticregressionmodelofSection1.2.1istoinclude
a choice as to which covariates to include in the model. We will consider
twoexamplepriors,andcalculatetherateofaddingacovariatetothemodel
fortheZigâ€“ZagSamplerineachcase.
Acommonpriorwouldbetoassumeindependenceacrosscovariates,so
ğœƒ ğ‘– = 0 with probability ğ‘¤ ğ‘– and is drawn from a normal distribution with
mean0andvarianceğœ ğ‘–2withprobability1âˆ’ğ‘¤ ğ‘–.Inthiscase,becauseofthe
independence, if covariate ğ‘– is not in the current model, the rate at which
weadditwillnotdependonthevalueofğœƒ
ğ‘™
forğ‘™ â‰ ğ‘–.Thus,thisratewillbe
constantandequalto
(1âˆ’ğ‘¤ ğ‘–) 1
,
ğ‘¤ âˆšï¸ƒ
ğ‘– 2ğœ‹ğœ2
ğ‘–
the ratio of the prior probability of a model which includes covariate ğ‘– to
thepriorprobabilityofthesamemodelwithoutcovariateğ‘–,timestheprior
probabilitydensityofğœƒ
ğ‘–
=0undertheformermodel.
What about when we have a prior under which components of ğœ½ are
dependent? Assume we are currently in model ğ‘˜ which does not include
theğ‘–thcovariate,andthataddingthiscovariatewillproducemodel ğ‘˜â€².Let
ğ‘ ğ‘˜ andğ‘ ğ‘˜â€² bethepriorprobabilityofthetwomodelsandassumethatthey
both have Gaussian priors on ğœ½ with mean 0 and covariance matrices on
theactivecomponentsof ğœ½ denotedby ğšº ğ‘˜ and ğšº ğ‘˜â€² respectively.Let ğ‘ ğ‘˜ be
the number of active components of model ğ‘˜, with ğ‘ ğ‘˜â€² = ğ‘ ğ‘˜ +1. We can
introducematricesAğ‘˜ andAğ‘˜â€² sothatthepriorfortheactivecomponents
ofğœ½ underourpriorformodel ğ‘˜ is
(cid:18)
1
(cid:19)ğ‘ ğ‘˜/2 (cid:26)
1
(cid:27)
2ğœ‹
det(ğšº ğ‘˜)âˆ’1/2exp âˆ’ 2ğœ½âŠ¤Ağ‘˜ğœ½ .
This is possible by padding A with zeroes, so if covariate ğ‘™ is not in the
modelthen ğ´ ğ‘™ğ‘— = ğ´ ğ‘—ğ‘™ =0,for ğ‘— =1,...,ğ‘‘.
Withthisdefinitionoftheprior,therateofmovingfrommodel ğ‘˜ to ğ‘˜â€²
asafunctionofğœ½ becomes
ğ‘ ğ‘ğ‘˜ ğ‘˜â€² (cid:18) 21 ğœ‹(cid:19)1/2 (cid:18) dd ee tt (( ğšºğšº ğ‘˜ğ‘˜ â€²) )(cid:19)1/2 exp(cid:26) âˆ’ 21 ğœ½âŠ¤(Ağ‘˜â€² âˆ’Ağ‘˜)ğœ½(cid:27) .184 Continuous-TimeMCMC
Defineğ¶tobetheconstantbeforetheexponentialterm.Ifourcurrentstate
is (ğœ½,p) thentherateuntilwemovetomodel ğ‘˜â€² is
(cid:26) (cid:27)
1
ğ¶exp âˆ’ (ğœ½âŠ¤+ğ‘¡p)(Ağ‘˜â€² âˆ’Ağ‘˜)(ğœ½ +ğ‘¡p) =
2
(cid:26) (cid:27) (cid:26) (cid:27)
1 1
ğ¶exp âˆ’ ğœ½âŠ¤(Ağ‘˜â€² âˆ’Ağ‘˜)ğœ½ exp âˆ’ğœ½âŠ¤(Ağ‘˜â€² âˆ’Ağ‘˜)pğ‘¡âˆ’ pâŠ¤(Ağ‘˜â€² âˆ’Ağ‘˜)pğ‘¡2 .
2 2
Thisisoftheform ğ‘exp{ğ‘ğ‘¡ +ğ‘ğ‘¡2} forsomeconstants ğ‘, ğ‘ and ğ‘.Wecan
simulatethetimeofthenexteventwiththisrateifğ‘ â‰¤ 0astheintegralof
therateisanalyticforğ‘ =0,andcanbeexpressedintermsofprobabilities
ofanormaldistributionforğ‘ < 0.Forğ‘ > 0,wecanusePoissonthinning
withe.g.boundsoftheform ğ´exp{ğµğ‘¡}oversuitableintervalsforğ‘¡.
5.5.3 MoreGeneralVelocityModels
Another possible way of extending PDMP samplers is to consider more
general models for the dynamics. There are two simple ways of doing
this, the first is to alter the distribution of the velocities for the Bouncy
Particle Sampler or the Zigâ€“Zag Sampler so that they are not spherically
symmetric.Theotheristoconsidernon-constantvelocitymodels.Wewill
brieflydescribeeachoftheseinturn.
First,wewillfocusontheZigâ€“ZagSampler.Ifweleteğ‘– betheğ‘–thunit
vector, i.e. the vector whoseğ‘–th component is 1 and all other components
are0,thenthesetofvelocitiesoftheZigâ€“Zigarethevelocitiesoftheform
(cid:205) ğ‘–ğ‘‘ =1ğ‘ ğ‘–eğ‘–, where ğ‘ ğ‘– âˆˆ {âˆ’1,1} forğ‘– = 1,...,ğ‘‘. That is, they are the set of
velocities that one obtains by adding plus or minus each unit vector. The
rateofflippingğ‘ ğ‘– isequaltothemaximumof0andminusthedotproduct
ofğ‘ ğ‘–eğ‘– withâˆ‡logğœ‹(ğœ½).
To generalise this we just need to replace the unit vectors with another
set of vectors that span Rğ‘‘. Denote this set by p 1,...,pğ‘‘. Importantly for
Zigâ€“Zag, the change to the process is trivial â€“ as the event rates are of a
similar form but with e 1,...,eğ‘‘ replaced with p 1,...,pğ‘‘. There are two
naturalapproachestochoosingp 1,...,pğ‘‘.Oneistojustchangethespeed
in each direction, so pğ‘– = ğ‘ ğ‘–eğ‘– for some set of positive scalars ğ‘ 1,...,ğ‘ ğ‘‘.
This can be helpful if different components of ğœ½ under ğœ‹ are on different
scales.Anaturalchoiceistosetğ‘ ğ‘–tobeanestimateofthemarginalstandard
deviationofğœ½ğ‘– underğœ‹.Theotherapproachistoalsochangethedirections
ofthevelocitiesaswell.Ifwehaveanestimateofthevariance-matrixofğœ½
under ğœ‹,sayğšº,thenonechoiceistochoosethepğ‘–stobetheeigenvectors
ofğšº.5.5 Extensions 185
To see why this is a natural choice, consider ğœ‹(ğœ½) being a Gaussian
distributionwithvarianceğšº.Centrethisdistributionsoithasameanof0.
Ifweusep 1,...,pğ‘‘ asourbasisforthevelocities,andp=(cid:205) ğ‘–ğ‘‘ =1ğ‘ ğ‘–pğ‘–,then
therateatwhichweflipğ‘ ğ‘– isequalto
max{0,âˆ’ğ‘ ğ‘–pâŠ¤
ğ‘–
âˆ‡logğœ‹(ğœ½ +pğ‘¡)} =max(cid:8) 0,âˆ’ğ‘ ğ‘–pâŠ¤
ğ‘–
(cid:0) âˆ’ğšºâˆ’1(ğœ½ +pğ‘¡)(cid:1)(cid:9).
But using that pğ‘– is an eigenvector of ğšº, and hence also of ğšºâˆ’1, and if we
assumethecorrespondingeigenvalueofğšºisğ›¾ ğ‘–,wehavethat
(cid:32) ğ‘‘ (cid:33)
âˆ’ğ‘ ğ‘–pâŠ¤
ğ‘–
(cid:0) âˆ’ğšºâˆ’1(ğœ½ +pğ‘¡)(cid:1) = ğ‘ ğ‘–ğ›¾1 pâŠ¤
ğ‘–
ğœ½ +ğ‘¡âˆ‘ï¸ ğ‘ ğ‘—pğ‘— ğ‘¡ = ğ‘ ğ‘–ğ›¾1 (cid:0) pâŠ¤
ğ‘–
ğœ½ +ğ‘ ğ‘–ğ‘¡(cid:1).
ğ‘– ğ‘–
ğ‘—=1
Inthiscase,theeventratedoesnotdependonthevelocityinothercompo-
nentsand essentiallyZigâ€“Zagwill reduceto independentprocessesalong
eachcomponent,pâŠ¤ğœ½,ofğœ½.
ğ‘–
AsimilarideacanbeusedtogeneralisetheBouncyParticleSampler.It
issimplesttodescribethisforthecasewheretheinvariantdistributionfor
p is Gaussian, as the generalisation is to allow a non-identity covariance
matrixforthis invariantdistribution.Inthefollowing, wewillassumethe
invariantdistributionisGaussianwithmean0andvarianceğšº.
Aswechangeğšº,wehavetochangethereflectioneventsofthesampler.
Toseewhy,notethatakeypropertyofthereflectioneventofthestandard
BouncyParticleSampler,whereinstep(BPS2)
pâ€² = R (p), withg= âˆ‡ logğœ‹(ğœ½),
g ğœ½
wasthat||pâ€²||2 = ||p||2,sothistransitiondoesnotchangethedensityofthe
2 2
state under ğœ‹ . This is no longer the case if the variance of p under ğœ‹ is
p p
notamultipleoftheidentity.
Soweneedtogeneralisethereflectionsothatitdependson ğšº.Itturns
outthattheappropriatereflectionis
2gâŠ¤p
Rğšº(p) =pâˆ’ ğšºg.
g (gâŠ¤ğšºg)
Importantly,ifpâ€² = Rğšº(p) foranyg,then
g
pâ€²âŠ¤ğšºâˆ’1pâ€² =pâŠ¤ğšºâˆ’1p,
so it does not change the density under a Gaussian with variance ğšº. Fur-
thermore,westillhavethatifg= âˆ‡logğœ‹(ğœ½) then
pâ€²Â·âˆ‡logğœ‹(ğœ½) =âˆ’pÂ·âˆ‡logğœ‹(ğœ½),
whichistheotherkeyrequirementofthetransitionneededforthevalidity186 Continuous-TimeMCMC
ofthesampler.Usingthesetwopropertiesitisstraightforwardtoshowthat
theBouncyParticleSamplerwith(BPS2)replacedby(BPS2â€™)belowwill
have ğœ‹(ğœ½)ğœ‹ (p) asitsinvariantdistribution,where ğœ‹ (p) isthedensityof
p p
aGaussiandistributionwithmean0andvarianceğšº.
(BPS2â€™) Transition at events. At an event with probability 1 âˆ’ ğœ† r/ğœ† BPS(ğœ½,p),
reflectthevelocity
pâ€² = Rğšº(p), withg= âˆ‡ logğœ‹(ğœ½);
g ğœ½
otherwise sample a new velocity, pâ€² from a normal distribution with
mean0andvarianceğšº.Thepositionisunchangedatanevent.
Asabove,anaturalchoiceofğšºtouseinthedistributionforthevelocityis
tochooseittobeanestimateofthevarianceofğœ½ underğœ‹.Furthermore,for
boththeBouncyParticleSamplerandZigâ€“Zagonecanrelatethechoiceof
distributiononthevelocitytorunningthecanonicalversionofthePDMP
but after applying a linear reparameterisation to the random variable of
thedistributionwewishtosamplefrom.Wewilldescribethelinkforthe
BouncyParticleSampler,thoughasimilarargumentappliestootherPDMP
samplers.
ConsidertheBouncyParticleSamplerfor (ğœ½,p) withtargetdistribution
ğœ‹(ğœ½)andastandardGaussiandistributionforp.Forsomeinvertiblematrix
L define ğ = Lğœ½, and consider the dynamics of the PDMP but viewed in
termsofğ.Ifğœ½ isdrawnfrom ğœ‹(ğœ½),andğ = Lğœ½,thenthedensityofğ is
ğœ‹ (ğ) âˆ ğœ‹(Lâˆ’1ğ),astheJacobianofthetransformationisconstant.Ifwe
ğ
considerderivativesthen
ğœ•logğœ‹ ğ(ğ)
=
ğœ•logğœ‹(Lâˆ’1ğ) =âˆ‘ï¸ğ‘‘ ğœ•logğœ‹(Lâˆ’1ğ)
(cid:0) Lâˆ’1(cid:1) .
ğœ•ğœ“ ğœ•ğœ“ ğœ•ğœƒ ğ‘—ğ‘–
ğ‘– ğ‘– ğ‘—
ğ‘—=1
Thisisjusttheğ‘–thentryofLâˆ’âŠ¤âˆ‡ logğœ‹(Lâˆ’1ğ),whichgivesthat
ğœ½
âˆ‡ ğœ‹ (ğ) =Lâˆ’âŠ¤âˆ‡ logğœ‹(Lâˆ’1ğ). (5.18)
ğ ğ ğœ½
NowletusconsiderthedynamicsoftheBouncyParticleSamplerinğ
space.Wewillconsidereachaspectofthedynamicsinturn:
Deterministic Dynamics: If we transform the constant velocity dynamics
intoğ spacewehave
dğ dğœ½
=L =Lp,
dğ‘¡ dğ‘¡
so these are still constant velocity dynamics but with velocity w = Lp.5.5 Extensions 187
Furthermore, if p has a Gaussian distribution with an identity covariance
matrix,thenwisGaussianwithcovarianceLLâŠ¤.
Rate of Bounce Events: If the current state is (ğœ½,p) then the rate of a
bounceeventismax{0,pÂ·âˆ‡logğœ‹(ğœ½)}.Now
pÂ·âˆ‡logğœ‹(ğœ½) =pâŠ¤âˆ‡logğœ‹(ğœ½) =wâŠ¤(Lâˆ’1)âŠ¤âˆ‡logğœ‹(Lâˆ’1ğ) =wâŠ¤âˆ‡ ğœ‹ (ğ),
ğ ğ
where we have transformed (ğœ½,p) to (ğ,w) and used (5.18). This is the
ratefortheBouncyParticleSamplertargetingğœ‹ (ğ).
ğ
ReflectionatBounceEvents:Ifthecurrentstateis(ğœ½,p)thenatabounce
eventthenewvelocityis
âˆ‡ logğœ‹(ğœ½)
pâ€² =pâˆ’2(pÂ·âˆ‡ logğœ‹(ğœ½)) ğœ½ .
ğœ½ (âˆ‡ logğœ‹(ğœ½)âŠ¤âˆ‡ logğœ‹(ğœ½))1/2
ğœ½ ğœ½
Soifweconsiderthevelocityfortheğprocess,wâ€² =Lpâ€²,anduseğšº =LLâŠ¤,
thisis
Lâˆ‡ logğœ‹(ğœ½)
wâ€² =Lpâˆ’2(pÂ·âˆ‡ logğœ‹(ğœ½)) ğœ½
ğœ½ (âˆ‡ logğœ‹(ğœ½)âŠ¤âˆ‡ logğœ‹(ğœ½))1/2
ğœ½ ğœ½
=wâˆ’2(wâŠ¤Lâˆ’ğ‘‡âˆ‡ logğœ‹(Lâˆ’1ğ))
ğœ½
ğšºLâˆ’ğ‘‡âˆ‡ logğœ‹(Lâˆ’1ğ)
Ã— ğœ½
(âˆ‡ logğœ‹(Lâˆ’1ğ)âŠ¤Lâˆ’1ğšºLâˆ’ğ‘‡âˆ‡ logğœ‹(Lâˆ’1ğ))1/2
ğœ½ ğœ½
ğšºâˆ‡ logğœ‹ (ğ)
=wâˆ’2(wâŠ¤âˆ‡ logğœ‹ (ğ)) ğ ğ .
ğ ğ (âˆ‡ logğœ‹ (ğ)âŠ¤ğšºâˆ‡ logğœ‹ (ğ))1/2
ğ ğ ğ ğ
ThisisjustRğšº(w)withg= âˆ‡log (ğ),thereflectionoftheBouncyParticle
g ğ
Samplerwithcovariancematrixğšº.
RefreshEvents:Theseeventsoccurataconstantrate,whichisunaffected
bythetransformationtoğ.Atarefreshevent,wesimulatepfromastandard
Gaussian,whichcorrespondstosimulatingw = LpfromaGaussianwith
covarianceğšº =LLâŠ¤.
ThustheprocessinğspaceisaBouncyParticleSamplerwithcovariance
matrixğšº =LLâŠ¤ forthevelocity.
Asecondgeneralisationistoaltertheconstantvelocitydynamics.This
hasbeen suggestedinparticular asa wayofgeneralising theBouncyPar-
ticleSamplerwithcovariancematrix ğšº forthevelocity,withtheresulting
algorithm called the Boomerang Sampler (Bierkens et al., 2020), though
similar ideas also appear under the name of Hamiltonian-BPS in Vanetti
etal.(2017).
Consideravelocitymodelwithmarginaldistributionsuchthatlogğœ‹ (p) =
p
âˆ’(1/2)pâŠ¤ğšºâˆ’1p. Write logğœ‹(ğœ½) = ğ‘ˆ(ğœ½) âˆ’ (1/2)(ğœ½ âˆ’ğœ½âˆ—)âŠ¤ğšºâˆ’1(ğœ½ âˆ’ğœ½âˆ—) for188 Continuous-TimeMCMC
somefunctionğ‘ˆ(ğœ½) andconstantvector ğœ½âˆ—.Theideaistohavedetermin-
isticdynamicsthatmovealongcontoursofâˆ’(1/2)(ğœ½âˆ’ğœ½âˆ—)âŠ¤ğšºâˆ’1(ğœ½âˆ’ğœ½âˆ—)âˆ’
(1/2)pâŠ¤ğšºâˆ’1p in (ğœ½,p) space. Such dynamics are given by Hamiltonian
dynamics,whicharetractableinthiscase,andare
dğœ½ dp
=p, = ğœ½ âˆ’ğœ½âˆ—.
dğ‘¡ dğ‘¡
The solution of these dynamics are ğœ½ğ‘¡ = ğœ½âˆ— + (ğœ½
0
âˆ’ğœ½âˆ—)cos(ğ‘¡) +p 0sin(ğ‘¡)
and pğ‘¡ = p 0cos(ğ‘¡) âˆ’ (ğœ½
0
âˆ’ ğœ½âˆ—)sin(ğ‘¡). The rate of bounce events for the
Boomerang Sampler is just max{0,pğ‘¡ Â·âˆ‡ğ‘ˆ(ğœ½ğ‘¡)}, with bounces as per the
Bouncy Particle Sampler when the velocity has covariance matrix ğšº. As
before,wecanalsointroducerefreshevents.
If ğ‘ˆ(ğœ½) = 0, so we are targeting a Gaussian distribution for ğœ½ with
mean ğœ½âˆ— and covariance ğšº, then this sampler just undergoes Hamiltonian
dynamics.Inthiscase,astrictlypositiverefreshrateisneededtoavoidthe
samplerbeingreducible,andtheresultingprocessisaformofrandomised
Hamiltoniandynamics,thatisHMCbutwitharandomrefreshtimeforthe
velocity.Fornon-Gaussiantargets,thissamplerwillhaveadditionalbounce
events,butthehopeisthatifthetargetisclosetoGaussianwithmean ğœ½âˆ—
and covariance ğšº, then the rate of bounce events will be much lower than
forthestandardBouncyParticleSampler.
Care is needed with one aspect of simulating the Boomerang Sampler,
as the different dynamics require slightly different approaches to simulate
the event times. If the current state is (ğœ½ ,p ) then the rate until the next
0 0
eventisnow
ğœ†Ëœ (ğœ½0,p0)(ğ‘¡) =max{0,pğ‘¡ Â·âˆ‡ğ‘ˆ(ğœ½ğ‘¡)} =max{0,
(p cos(ğ‘¡)+(ğœ½ âˆ’ğœ½âˆ—)sin(ğ‘¡))Â·âˆ‡ğ‘ˆ(ğœ½âˆ—+(ğœ½ âˆ’ğœ½âˆ—)cos(ğ‘¡)+p sin(ğ‘¡))},
0 0 0 0
where we have substituted in the definitions of pğ‘¡ and ğœ½ğ‘¡. Bierkens et al.
(2020)givesomegeneralapproachestoboundingthisrate,whichusesthe
property that the deterministic dynamics of the Boomerang Sampler are
such that |ğœ½ğ‘¡ âˆ’ğœ½âˆ—|2 + |pğ‘¡|2 is a constant. To keep the notation simple, we
willshowthisforğœ½âˆ— =0,butthesameargumentappliesmoregenerally.In
thiscase
|ğœ½ğ‘¡|2+|pğ‘¡|2 = (ğœ½ 0cos(ğ‘¡)+p 0sin(ğ‘¡))Â·(ğœ½ 0cos(ğ‘¡)+p 0sin(ğ‘¡))
+(p cos(ğ‘¡)âˆ’ğœ½ sin(ğ‘¡))Â·(p cos(ğ‘¡)âˆ’ğœ½ sin(ğ‘¡))
0 0 0 0
= |ğœ½ |2cos2(ğ‘¡)+|p |2sin2(ğ‘¡)+2ğœ½ Â·p sin(ğ‘¡)cos(ğ‘¡)
0 0 0 0
+|p |cos2(ğ‘¡)+|ğœ½ |2sin(ğ‘¡)âˆ’2ğœ½ Â·p sin(ğ‘¡)cos(ğ‘¡)
0 0 0 0
= |ğœ½ |2(sin2(ğ‘¡)+cos2(ğ‘¡)+|p |2(sin2(ğ‘¡)+cos2(ğ‘¡)) = |ğœ½ |2+|p |2.
0 0 0 05.5 Extensions 189
Howisthisuseful?Thispropertymeansthatwecanboundthedistance
from ğœ½âˆ— that the current deterministic trajectory can take. Thus if we can
bound the Hessian ofğ‘ˆ, which is the derivative of âˆ‡ğ‘ˆ, then this enables
us to bound âˆ‡ğ‘ˆ for the current trajectory based on the value of âˆ‡ğ‘ˆ at ğœ½âˆ—
plus a term that depends on the bound on the Hessian and the distance
the trajectory can be from ğœ½âˆ—. One such bound, that we will use below
is that if the spectral norm of the Hessian of ğ‘ˆ is bounded by ğ‘€, so
that âˆ¥âˆ‡2ğ‘ˆ(ğœ½)xâˆ¥ â‰¤ ğ‘€âˆ¥xâˆ¥ for any vector x with âˆ¥ Â· âˆ¥ denoting Euclidean
2
distance, then for the current deterministic trajectory, we have a constant
bound:
1
ğœ†(ğœ½ğ‘¡,pğ‘¡) â‰¤ |âˆ‡ğ‘ˆ(ğœ½âˆ—)|(|ğœ½ 0âˆ’ğœ½âˆ—|2+|p 0|2)1/2+ 2ğ‘€(|ğœ½ 0âˆ’ğœ½âˆ—|2+|p 0|2). (5.19)
Example:BoomerangforLogisticRegression
Asanexample,consideragainthelogisticregressionmodel.Therearetwo
natural choices for the centring value and covariance of the Boomerang
Sampler.Thefirstistosetthemtothepriormeanandcovariance, ğœ½âˆ— = 0
and ğšº = ğšº ğœ½. The second is to estimate the mode of logğœ‹,(cid:98)ğœ½ğ‘€ğ´ğ‘ƒ say, and
theinverseoftheHessianofâˆ’logğœ‹ at(cid:98)ğœ½ğ‘€ğ´ğ‘ƒ.Wewillcomparethesetwo
options.
Ifwesetthemtothepriorvaluesthenğ‘ˆ(ğœ½) isminusthelog-likelihood.
As described in Section 5.4.1 we can bound the Hessian of minus the
log-likelihoodby (1/4)XâŠ¤X,whereXisthe ğ‘ Ã—ğ‘‘ matrixofcovariates.
What about if we set ğœ½âˆ— and ğšº based on the estimate of the mode of
logğœ‹ and the inverse of the Hessian of âˆ’logğœ‹ at the mode? Denoting the
log-likelihoodofthelogisticmodelbyâ„“(ğœ½;D),andtheHessianofminus
thelog-likelihoodbyH(ğœ½).Thischoicegives
1
ğ‘ˆ(ğœ½) =âˆ’â„“(ğœ½;D)âˆ’ (ğœ½ âˆ’(cid:98)ğœ½ğ‘€ğ´ğ‘ƒ)âŠ¤H((cid:98)ğœ½ğ‘€ğ´ğ‘ƒ)(ğœ½ âˆ’(cid:98)ğœ½ğ‘€ğ´ğ‘ƒ),
2
wherewehaveusedthefactthatthecontributionfromthepriorwillcancel.
Taking second derivatives, the Hessian of this at ğœ½ will be the difference
betweentwomatrices,H(ğœ½)âˆ’H((cid:98)ğœ½ğ‘€ğ´ğ‘ƒ).Thesematricesarebothpositive
semi-definite,withspectralnormboundedby (1/4)XâŠ¤X,thusthespectral
norm of the difference is also bounced by (1/4)XâŠ¤X. This is because the
eigenvalues of H(ğœ½) are bounded between 0 and ğ‘€ for some constant ğ‘€,
andtheeigenvaluesofâˆ’H((cid:98)ğœ½ğ‘€ğ´ğ‘ƒ) areboundedbetweenâˆ’ğ‘€ and0,sothe
eigenvaluesofH(ğœ½)âˆ’H((cid:98)ğœ½ğ‘€ğ´ğ‘ƒ) arebetweenâˆ’ğ‘€ and ğ‘€.
ThuswecanimplementtheBoomerangSamplerforbothchoicesofğœ½âˆ—
and ğšº with the constant bound given by (5.19) using the same value for190 Continuous-TimeMCMC
       
       
       
       
                               
Î¸(1) Î¸(1)
Figure5.8 TraceplotsoftheBoomerangSamplerforthe
posteriorofalogisticregressionmodel.Theheatplotshowsthe
contoursoftheposterior.Examplerealisationwhenğšº =ğšº and
ğœ½
ğœ½âˆ—isthepriormean(left)andwhenğœ½âˆ—isanestimateofthe
posteriormodeandğšºisbasedontheHessianoflogğœ‹atğœ½âˆ—
(right).
ğ‘€. The bounds will differ though due to the different values for ğœ½âˆ— and
ğ‘ˆ and hence for |âˆ‡ğ‘ˆ(ğœ½âˆ—)|. In particular, this will be 0 for ğœ½âˆ— = (cid:98)ğœ½ğ‘€ğ´ğ‘ƒ, or
at least close to 0 if we have a reasonable approximation for the mode of
logğœ‹. Example realisations for the two samplers are shown in Figure 5.8,
fordatawith ğ‘ = 100and ğ‘‘ = 2andwithapriorcovarianceof2foreach
componentofğœ½.
ThemaindifferencebetweentheBoomerangSamplerandtheprevious
PDMPsamplersismostobviouslyseenintheright-handplotofFigure5.8,
aswehaveellipticaltrajectoriesbetweenevents.Thisisreminiscentofthe
trajectoriesforHMC.Fortheleft-handplot,whereÎ£ islargecomparedto
thecurvatureoftheposterior,thecontoursareellipticalbutwithlargerradii
andthustheoutputlooksmoresimilartoourpreviousPDMPsamplers.In
thisexample,oneofthemainadvantagesofbasing ğœ½âˆ— andÎ£ onthemode
and Hessian at the mode is that the computational cost of simulating the
Boomerang Sampler is lower. Both have been simulated with roughly the
samelengthoftrajectory,butusingthepriorvalueshasrequiredproposing
fourtimesasmanyevents.Thisisbecauseofthelooserboundontheevent
ratethatwehaveinthiscase.
)2(Î¸ )2(Î¸5.6 ChapterNotes 191
5.6 ChapterNotes
The initial idea of using PDMP processes for sampling comes from the
physical sciences, see for example Turitsyn et al. (2011), Peters and de
With(2012)andMicheletal.(2014).Thesewereintroducedintostatistics
byBouchard-CoË†teÂ´etal.(2018)andBierkensandRoberts(2017),andoneof
theearlypaperstodescribethelinktoPDMPswasFearnheadetal.(2018).
Thelatterpaperalsogivesanexamplewhereavoidingrefresheventsinthe
Bouncy Particle Sampler can lead to slow mixing. How the subsampling
ideasofSection5.4.3extendtosamplersotherthantheZigâ€“ZagSampler
isalsodiscussedinFearnheadetal.(2018),withrelatedideasforthelocal
BouncyParticleSamplerinBouchard-CoË†teÂ´ etal.(2018).
As well as the PDMP samplers mentioned in the chapter, there have
beenvariouspaperssuggestingextensionstoPDMPmethods.Forexample
Vanettietal.(2017),WuandRobert(2017)andMicheletal.(2020).The
continuous-timemethodscanberelatedtodiscrete-timeMCMCmethods
such as reflective slice sampling (Neal, 2003) and the Discrete Bouncy
ParticleSampler(SherlockandThiery,2022).
The theoretical analysis of PDMP samplers has been active, including
showingergodicity(Deligiannidisetal.,2019;Bierkensetal.,2019a)and
exploring limiting behaviour of the Bouncy Particle Sampler and the Zig
Zagsampler(Deligiannidisetal.,2021;Bierkensetal.,2022;Andrieuetal.,
2021).Particularlystrongresultsareavailablefortheone-dimensionalcase
(BierkensandDuncan,2017;BierkensandVerduynLunel,2022).
ComplementaryresultsonscalingoftheDiscreteBouncyParticleSam-
pler to those shown in Section 5.3.3 are given in Sherlock and Thiery
(2022), which shows similar scaling to the Bouncy Particle Sampler and
alsoprovidessupportingtheorytohelpchoosetherefreshrate.6
Assessing and Improving MCMC
Thedevelopmentofmoresophisticatedand,especially,approximatesam-
plingalgorithms,aimedatimprovingscalabilityinoneormoreofthesenses
already discussed in this book, raises important considerations about how
a suitable algorithm should be selected for a given task, how its tuning
parameters should be determined, and how its convergence should be as-
sessed.Thischapterpresentsrecentsolutionstotheaboveproblems,whose
starting point is to derive explicit upper bounds on an appropriate dis-
tance between the posterior and the approximation produced by MCMC.
Further, we explain how these same tools can be adapted to provide pow-
erfulpost-processingmethodsthatcanbeusedretrospectivelytoimprove
approximationsproducedusingscalableMCMC.
6.1 DiagnosticsforMCMC
TheapproximationsprovidedbyMCMCareonlyusefulifwecanbecon-
fident that the samples collectively form a reasonable approximation to
the intended target. This, however, appears to be a circular requirement â€“
how can we verify that MCMC has worked without access to the limiting
targettocheck?Severaldiagnosticshaveemergedaspragmaticsolutions,
enablingapractitionertodetectcertainfailuremodesofMCMC.Inparticu-
lar,wehighlightconvergencediagnostics,whichaimtodeterminewhether
the Markov chain has converged to some stationary distribution, and bias
diagnostics,whichaimtodetectwhetherthestationarydistributionofthe
Markovchainisindeedthetargetdistributionofinterest.Forcontext,both
classes of diagnostic will be briefly discussed. Throughout this Chapter,
we shall restrict attention to distributions defined on Rğ‘‘ for simplicity of
presentation.
1926.1 DiagnosticsforMCMC 193
6.1.1 ConvergenceDiagnostics
To limit the scope, here we describe the convergence diagnostics that are
most widely used. The Gelmanâ€“Rubin diagnostic is based on realisations
of ğ¿ independentMarkovchains,eachoflengthğ‘›,wherepracticalconsid-
erations typically restrict ğ¿ to be a small number, such as 3, 4 or 5. For
aunivariatetargetdistribution,theGelmanâ€“Rubindiagnosticisdefinedas
thesquarerootoftheratiooftwoestimatorsofthevarianceğœ2ofthetarget
distribution
âˆšï¸‚
ğœ2
ğ‘… (cid:98):= (cid:98) , (6.1)
ğ‘ 2
(cid:98)
where ğ‘ 2 is the (arithmetic) mean of the sample variances ğ‘ 2 along the ğ¿
(cid:98) ğ‘™
samplepaths,
ğ¿
1 âˆ‘ï¸
ğ‘ 2 := ğ‘ 2,
(cid:98) ğ¿ ğ‘™
ğ‘™=1
which typically provides an underestimate of ğœ2, since it is possible that
oneormoreofthe ğ¿ chainshasnotexploredtheposteriorwell,while ğœ2
(cid:98)
isconstructedas
ğ‘›âˆ’1 1 âˆ‘ï¸ğ¿ (cid:32) 1 âˆ‘ï¸ğ¿ (cid:33)2
(cid:98)ğœ2 := ğ‘› (cid:98)ğ‘ 2+ ğ¿âˆ’1 ğ‘š ğ‘™ âˆ’ ğ¿ ğ‘š ğ‘™â€² , (6.2)
ğ‘™=1 ğ‘™â€²=1
where ğ‘š ğ‘™ is the sample mean from the ğ‘™th sample path, which typically
provides an overestimate of the target variance. Indeed, the second term
in (6.2) is an estimate of the asymptotic variance of the sample mean
of the Markov chain, which is typically larger than the variance ğœ2 we
ğ‘›
would obtain if our samples were truly independent; recall the discussion
ofeffectivesamplessizesand(1.15)fromChapter1.ForanergodicMarkov
chain, ğ‘… (cid:98)converges to 1 as ğ‘› â†’ âˆ. In practice, it is common to discard
a burn-in period of length ğ‘›, where ğ‘› is the smallest integer for which
2
ğ‘… (cid:98)< 1+ğ›¿,whereğ›¿isasuitablethreshold.Thesomewhatarbitrarychoices
ofğ›¿ =0.1andğ›¿ =0.01areoftenused.
Convergence diagnostics are widely and successfully used. However,
it remains the case that the performance of ğ‘… (cid:98) and related convergence
diagnosticsdependsstronglyonhowtheindependentrealisationsofMCMC
areinitialised.Indeed,considerthetaskofgeneratingapproximatesamples
fromthemixturedistribution
1 1
ğœ‹(ğ‘¥) = N(ğ‘¥;âˆ’2,0.52)+ N(ğ‘¥;2,0.52). (6.3)
2 2194 AssessingandImprovingMCMC
To avoid the situation where all chains are confined to the same local
high-probabilityregionduetochance,standardpracticeistoinitialisethe
Markov chains by sampling their initial state from a distribution that is
over-dispersed with respect to the target. Thus, we may initialise Markov
chains by sampling from, say, N(0,52). Running ğ¿ = 3 chains of length
ğ‘› =1000leadstothetwosetsofsamplepathsshowninFigure6.1.Inboth
sets of sample paths, the length ğ‘› of the sample paths was insufficient to
enabletheMarkovchainstoexplorebothcomponentsofğœ‹,andeachofthe
chains remained in the component in which it was initialised. On the left
side of the figure, one of the sample paths is clearly qualitatively distinct
fromtheothertwo,sincetheMarkovchainsexploreddifferentcomponents
of ğœ‹, and the Gelmanâ€“Rubin diagnostic correctly detects that the Markov
chainshavenotconverged.Unfortunately,ontherightsideofthefigure,it
so happenedthat eachof the chainswas initialisedin the highprobability
region of the same component. As a result, the Gelmanâ€“Rubin diagnostic
appears to be converging to values below the commonly used thresholds
ğ›¿ = 0.1 and ğ›¿ = 0.01, and fails to detect that the Markov chains have
exploredonlyoneofthecomponentsofğœ‹.
Whatwentwrongwiththeconvergencediagnostic(6.1)inthisexample?
Well, the Markov processes exhibited a form of quasi-stationarity; transi-
tions from one component of the mixture to the other is a rare event, and
conditionalonsuchatransitionnotoccurringthebehaviouroftheMarkov
chainsisarguablyexcellent.Therarityoftransitionsbetweencomponents
makes it fundamentally difficult to distinguish between quasi-stationarity
and convergence of a Markov chain when the sample paths are confined
tothesamecomponent;someknowledgeoftheinvariantdistribution ğœ‹ is
required. This motivates the discussion of an alternative diagnostic which
does indeed leverage information about ğœ‹, a bias diagnostic, which we
describenext.
6.1.2 BiasDiagnostics
Eveninfavourablesituations,suchasthecaseofauni-modaltarget,con-
vergencediagnosticsdonotprovideaguaranteethatMarkovchainsamples
constituteafaithfulapproximationofthetarget.Indeed,convergencediag-
nosticsarenotcapableofdetectingbiasinsampleroutput,forexampleas
introduced when using stochastic gradient methods (Chapter 3), or intro-
duced when a coding error has occurred. Instead, bias diagnostics can be6.1 DiagnosticsforMCMC 195
   
   
   
                     
 L W H U D W L R Q  L W H U D W L R Q
   
     
   
     
         
         
   
     
   
     
                     
 L W H U D W L R Q  L W H U D W L R Q
Figure6.1 ConvergencediagnosticsforMCMC.Three
independentMarkovchainsweresimulatedtogeneratesamples
fromtheGaussianmixturetargetğœ‹in(6.3).Inthefirstscenario
(leftpanels)thechainsexploredifferentcomponentsofğœ‹,andthe
Gelmanâ€“Rubindiagnosticğ‘… (cid:98)correctlydetectsthattheMarkov
chainshavenotconverged.Inthesecondscenario(rightpanels)
thechainsexplorethesamecomponentofğœ‹,andthe
Gelmanâ€“RubindiagnosticdoesnotdetectthattheMarkovchains
havenotconverged.[StarsindicatetheinitialstateofeachMarkov
chain.Thedensityğœ‹isshaded.Dottedlinesindicatethetwo
commonlyusedthresholdsğ›¿ =0.1and0.01forğ‘… (cid:98)âˆ’1.]
usedtoidentifysuchsituations,asimpleexampleofwhichis
(cid:13) ğ‘› (cid:13)
(cid:13)1 âˆ‘ï¸ (cid:13)
ğµ (cid:98):=(cid:13)
(cid:13)ğ‘›
(âˆ‡logğœ‹)(ğ‘‹ ğ‘˜)(cid:13) (cid:13). (6.4)
(cid:13) ğ‘˜=1 (cid:13)
1
R
x
âˆ’
c
1
R
x
âˆ’
c196 AssessingandImprovingMCMC
Providedthatâˆ‡logğœ‹ âˆˆ L1(ğœ‹),whichwerecallmeansthatâˆ« âˆ¥âˆ‡logğœ‹âˆ¥ dğœ‹ <
âˆ from Section 1.1.1, from the strong law of large numbers for Markov
chainstheseriesin(6.4)almostsurelyconvergestothelimit
âˆ« âˆ« (âˆ‡ğœ‹)(ğ‘¥) âˆ«
âˆ‡logğœ‹ dğœ‹ = ğœ‹(ğ‘¥) dğ‘¥ = (âˆ‡ğœ‹)(ğ‘¥) dğ‘¥ =0
ğœ‹(ğ‘¥)
whenever the Markov chain is ergodic and ğœ‹-invariant. The final equality
is integration by parts; a special case of Lemma 6.3 in the sequel. On
the other hand, just as the passing of a convergence diagnostic test does
not guarantee that the MCMC has converged, the convergence of (6.4) to
0 does not guarantee that the Markov chain preserves the correct target
distribution. Surprisingly, bias diagnostics are not widely used, at least
comparedtoconvergencediagnostics,whichmaybedueto(inourexample)
therequirementtocomputeagradient,ormaysimplybebecausetheyhave
beenhistoricallyoverlooked.
Consideragainthemixturedistributionğœ‹ in(6.3)andsupposethat,due
to a coding error, we have implemented a Markov chain whose stationary
distributionisN(ğœ‡,0.52).Running ğ¿ = 3chainsoflengthğ‘› = 1000leads
to the two sets of sample paths shown in Figure 6.2 for ğœ‡ = 2 (left) and
ğœ‡ =0(right).Inbothsetsofsamplepaths,theGelmanâ€“Rubinconvergence
diagnostictestispassed,despitetheMarkovchainsfailingtobeğœ‹-invariant.
On the left side of the figure, the bias diagnostic (6.4) clearly does not
convergetozero,andthusthebiasintheMarkovchainoutputisdetected.
Unfortunately,ontherightsideofthefigure,thebiasdiagnosticappearsto
be decreasing for all chains as the number ğ‘› of samples is increased, and
wedonotdiagnosethefailureofMCMC.
What went wrong with the bias diagnostic (6.4) in this example? Well,
informationaboutafinite-dimensionalgeneralisedmomentâˆ« âˆ‡logğœ‹ dğœˆ âˆˆ
Rğ‘‘ isinsufficienttocharacteriseaprobabilitydistribution;thereareanin-
finitudeofdistributionsğœˆforwhichallğ‘‘componentsofthisgeneralisedmo-
mentare0.Thissuggestsapotentialsolution;findaninfinite-dimensional
generalisedmomentthatfullydetermineswhetherornotğœ‹andğœˆareequal.
Surprisingly,thiscanbeachievedwithoutneedingtoexplicitlydealwithan
infinite-dimensionalgeneralisedmoment,duetothekerneltrickfromma-
chinelearning,whichwasintroducedinSection1.5.3forfinite-dimensional
inner-productspaces,andwillnowbeexploredintheinfinite-dimensional
setting.6.1 DiagnosticsforMCMC 197
   
   
   
                     
   
     
   
     
   
     
   
     
               
                       
 L W H U D W L R Q  L W H U D W L R Q
Figure6.2 BiasdiagnosticsforMCMC.Threeindependent
biasedMarkovchainsweresimulated,sothattheinvariant
distributiondiffersfromtheGaussianmixturetargetğœ‹in(6.3).In
thefirstscenario(leftpanels)thechainsexploreaGaussian
centredatğ‘¥ =2,andthebiasdiagnosticğµ (cid:98)correctlydetectsthat
theMarkovchainshavenotconverged.Inthesecondscenario
(rightpanels)thechainsexploreaGaussiantargetcentredat
ğ‘¥ =0,andthebiasdiagnosticdoesnotdetectthattheMarkov
chainshavenotconverged.[Starsindicatetheinitialstateofeach
Markovchain.Thedensityğœ‹isshaded.]
6.1.3 ImprovedBiasDiagnosticsviatheKernelTrick
Though finite-dimensional bias diagnostics can be misled, the same may
notbetrueofabiasdiagnosticthatisinfinite-dimensional.Theaimofthis
sectionistoindicate,atahighlevel,howsuchaninfinite-dimensionalbias
B
x
c B
x
c198 AssessingandImprovingMCMC
diagnosticcanbeconstructed.Amorerigorousmathematicaltreatmentis
thenprovidedinSection6.2.
Supposethatweareabletowritedownacountableset {ğœ™ ,ğœ™ ,...} of
1 2
functions ğœ™ ğ‘— : Rğ‘‘ â†’ Rsuchthateachofthemomentsâˆ« ğœ™ ğ‘—(x)ğœ‹(x) dxof
ğœ‹canbeanalyticallyevaluated;withoutlossofgeneralitywemaysuppose
thateachgeneralisedmomentofğœ‹isequalto0(sinceifnot,wemaysimply
redefine ğœ™ ğ‘— as ğœ™ ğ‘— âˆ’âˆ« ğœ™ ğ‘—(x)ğœ‹(x) dx). We have already seen examples of
functionsğœ™ ğ‘— thatcanbeused;wecouldtake
ğœ•logğœ‹(x)
ğœ™ ğ‘—(x) =
ğœ•ğ‘¥
ğ‘—
for ğ‘— =1,...,ğ‘‘.Moregenerally,wecanusethegeneratorofanyğœ‹-invariant
Markov process to construct such functions; the details are deferred to
Section6.2.Assumingthattheğœ™ ğ‘—arelinearlyindependentandappropriately
normalised,wecanconstructaHilbertspace
(cid:40) (cid:41)
âˆ âˆ
âˆ‘ï¸ âˆ‘ï¸
H = â„ = ğ‘ ğ‘—ğœ™ ğ‘— : ğ‘2 ğ‘— < âˆ
ğ‘—=1 ğ‘—=1
whoseelementsarefunctionsâ„ :Rğ‘‘ â†’R,equippedwithaninnerproduct
âŸ¨â„,â„â€²âŸ© H = (cid:205)âˆ ğ‘—=1ğ‘ ğ‘—ğ‘â€² ğ‘—, where here â„ = (cid:205)âˆ ğ‘—=1ğ‘ ğ‘—ğœ™ ğ‘— and â„â€² = (cid:205)âˆ ğ‘—=1ğ‘â€² ğ‘—ğœ™ ğ‘—. The
inducednormis âˆ¥â„âˆ¥ := âŸ¨â„,â„âŸ©1/2.BypickingelementsfromthisHilbert
H H
space we can construct an infinitude of bias diagnostics, and the question
isthenwhichdiagnostictopick?
Onesolutionistoadoptanadversarialperspective,whereweselectan
element â„ âˆˆ H thatmaximallydiscriminatesbetween ğœ‹ andtheempirical
approximation to ğœ‹ produced from MCMC. The bias diagnostic obtained
inthiswaycanbewrittenas
(cid:12) ğ‘› (cid:12)
(cid:12)1 âˆ‘ï¸ (cid:12)
ğµ (cid:101):= sup (cid:12)
(cid:12)ğ‘›
â„(Xğ‘˜)(cid:12) (cid:12),
âˆ¥â„âˆ¥Hâ‰¤1(cid:12) ğ‘˜=1 (cid:12)
where the supremum is taken over the unit ball of H, to ensure that the
supremumiscomputedoveraboundedset.Furtherre-writingintermsof
thebasisfunctions,wehave
(cid:40)(cid:12) (cid:12)1 âˆ‘ï¸ğ‘› âˆ‘ï¸âˆ (cid:12) (cid:12) âˆ‘ï¸âˆ (cid:41)
ğµ (cid:101):=sup (cid:12)
(cid:12)ğ‘›
ğ‘ ğ‘—ğœ™ ğ‘—(Xğ‘˜)(cid:12)
(cid:12)
: ğ‘2
ğ‘—
â‰¤ 1 , (6.5)
(cid:12) ğ‘˜=1 ğ‘—=1 (cid:12) ğ‘—=1
whenceweseethemaximisationisequivalenttofindingthepointconthe
surfaceofthe(infinite-dimensional)unithyperspherethatmaximisesthedot6.1 DiagnosticsforMCMC 199
productwiththe(infinite-dimensional)vectorcâ€² withğ‘â€²
ğ‘—
= ğ‘›1 (cid:205)ğ‘› ğ‘˜=1ğœ™ ğ‘—(Xğ‘˜).
The solution of this maximisation problem is to align c to câ€², and upon
properlynormalisingweobtain
ğ‘ =
ğ‘›1 (cid:205)ğ‘› ğ‘˜=1ğœ™ ğ‘—(Xğ‘˜)
.
ğ‘— âˆšï¸ƒ
(cid:205)âˆ
ğ‘—â€²=1
(cid:0) ğ‘›1 (cid:205)ğ‘› ğ‘˜â€²=1ğœ™ ğ‘—â€²(Xğ‘˜â€²)(cid:1)2
Inserting this expression back into (6.5) and rearranging, we obtain the
explicitbiasdiagnostic
(cid:118)(cid:117)
(cid:116) ğ‘› ğ‘› (cid:32) âˆ (cid:33)
1 âˆ‘ï¸âˆ‘ï¸ âˆ‘ï¸
ğµ (cid:101)=
ğ‘›2
ğœ™ ğ‘—(Xğ‘˜)ğœ™ ğ‘—(Xğ‘˜â€²) .
ğ‘˜=1 ğ‘˜â€²=1 ğ‘—=1
Atthispointonecanraiseareasonableobjectionthatevaluatingğµ (cid:101)appears
torequireaninfinitecomputationalbudget,duetothesummationoverthe
functions ğœ™ ğ‘—. Remarkably, there are situations where such infinite series
admitclosed-formanalyticexpressions
âˆ
âˆ‘ï¸
kğœ‹(x,xâ€²) := ğœ™ ğ‘—(x)ğœ™ ğ‘—(xâ€²),
ğ‘—=1
asituationknowninmachinelearningasthekerneltrick.SeeSection1.5for
aprimeronthekerneltrick.Providedthatwehaveaccesstoakerneltrick,
which of course depends on the precise choice we make for the functions
ğœ™
ğ‘—
toensurethatâˆ« ğœ™ ğ‘—(x)ğœ‹(x) dx=0,wecanhopetoobtainaclosed-form
expressionforthebiasdiagnostic(6.5),namely
(cid:118)(cid:116)
ğ‘› ğ‘›
1 âˆ‘ï¸âˆ‘ï¸
ğµ (cid:101)=
ğ‘›2
kğœ‹(Xğ‘˜,Xğ‘˜â€²). (6.6)
ğ‘˜=1 ğ‘˜â€²=1
One would hope that (6.6) converges to 0 as ğ‘› â†’ âˆ if and only if the
Markovchainis ğœ‹-invariant.Itturnsoutthatsuchanideacanbemadeto
work,aswewillexplaininSection6.2.
Tosummarise,wehaveseenthatbothconvergencediagnosticsandcon-
ventionalfinite-dimensionalbiasdiagnosticscanprovideausefulpractical
tool to detect the failure of MCMC, but even taken together they are in-
sufficient to guarantee that output from the sampler provides an accurate
approximation of the intended target distribution. In the next section, we
turnourattentiontotheconstructionofinfinite-dimensionalbiasdiagnos-
tics, of the form (6.6), which attempt to solve the problem of assessing200 AssessingandImprovingMCMC
MCMCoutputbyestablishingexplicitupperboundsonanappropriatedis-
tancebetweentheposteriorandtheapproximationproducedbyMCMCin
termsofdiagnosticsoftheform(6.6).
6.2 ConvergenceBoundsforMCMC
Incontrasttoconvergencediagnosticsandconventionalfinite-dimensional
biasdiagnostics,whichmayfailtodetectinstanceswhereMCMChasfailed,
theaimofthissectionistoseekexplicitandcomputableupperboundson
theerrorbetweentheMCMCoutputandthetargetdistribution.Thistopic
hasreceivedconsiderablerecentinterestfollowingthepioneeringworkof
GorhamandMackey(2015).Tosetthescene,wefirstexplainhowtheuseof
asuitablediffusionprocessenablesexplicitboundsonintegralprobability
metrics,focusingonthe Wasserstein-1metricforclarityinSections6.2.1
and6.2.2.However,theWasserstein-1metricisnotfavourableforcompu-
tationinthiscontext,andweinsteadconsiderintegralprobabilitymetrics
basedonreproducingkernelHilbertspacesinSection6.2.3,notingthatthe
associated kernel Stein discrepancies can also provide valid convergence
bounds in Section 6.2.4. Lastly, in Section 6.2.5 we connect kernel Stein
discrepanciestothestochasticgradientmethodsfromChapter3.
6.2.1 BoundsonIntegralProbabilityMetrics
Our aim here is to arrive at an explicit and computable upper bound on
an appropriate metric between the target distribution ğœ‹ and the empirical
distributionproducedbyMCMC.Let P(Rğ‘‘) denotethesetofprobability
distributions on Rğ‘‘ and consider a metric d : P(Rğ‘‘) Ã—P(Rğ‘‘) â†’ [0,âˆ].
Asausefulconvention,wehaveextendedtherangeofametrictoinclude
the value âˆ, to avoid the need to specify the subset of distributions on
which the metric is defined. Let ğœ‹ âˆˆ P(Rğ‘‘) be the distributional target
of MCMC. For our theoretical development, we will now introduce an
auxiliarydiscretetimeergodicMarkovchain,whichneednotberelatedto
theMarkovprocess(es)underpinningtheMCMCmethod(s)beingassessed.
The role of this auxiliary chain is limited to being a theoretical device in
whatfollows,andwedenoteitstransitionkernelasğ‘‡ ğœ‹,meaningthatğ‘‡ ğœ‹ğœˆis
thedistributionafteronestepoftheauxiliaryMarkovchaininitialisedfrom
X âˆ¼ ğœˆ.Thisauxiliarychainisrequiredtosatisfythecontractionproperty
0
d(ğ‘‡ ğœ‹ğœ‹,ğ‘‡ ğœ‹ğœˆ) â‰¤ ğœŒ d(ğœ‹,ğœˆ) (6.7)6.2 ConvergenceBoundsforMCMC 201
for some ğœŒ âˆˆ [0,1) and all ğœˆ âˆˆ P(Rğ‘‘). From the triangle inequality,
d(ğœ‹,ğœˆ) â‰¤ d(ğœ‹,ğ‘‡ ğœ‹ğœˆ)+d(ğ‘‡ ğœ‹ğœˆ,ğœˆ),combinedwiththecontractiond(ğœ‹,ğ‘‡ ğœ‹ğœˆ) =
d(ğ‘‡ ğœ‹ğœ‹,ğ‘‡ ğœ‹ğœˆ) â‰¤ ğœŒ d(ğœ‹,ğœˆ), it follows that (1âˆ’ ğœŒ)d(ğœ‹,ğœˆ) â‰¤ d(ğ‘‡ ğœ‹ğœˆ,ğœˆ). The
discrepancy
1
ğ· ğœ‹(ğœˆ) :=
1âˆ’ğœŒ
d(ğ‘‡ ğœ‹ğœˆ,ğœˆ)
thereforeconstitutesanupperboundonthemetricd(ğœ‹,ğœˆ),whichcouldin
principlebeusedtoquantifyhowwellagivendistributionğœˆapproximatesğœ‹
insituationswherewedonothavedirectaccesstoğœ‹,butwheretheauxiliary
Markovchaincanbesimulated.Further,sincedisametricandtheMarkov
chain has a unique invariant distribution, ğ· ğœ‹(ğœˆ) = 0 if and only if ğœˆ = ğœ‹.
An ideal scenario would be a fast mixing auxiliary Markov chain, so that
ğœŒ â‰ª 1,ğ‘‡ ğœ‹ğœˆ â‰ˆ ğœ‹,and ğ· ğœ‹(ğœˆ) â‰ˆ d(ğœ‹,ğœˆ).Ontheotherhand,iftheauxiliary
Markovchainmixesslowlythenthevaluestakenbythediscrepancycould
fail to provide a meaningful indication of whether or not ğœˆ is an accurate
approximation to ğœ‹. The utility of this upper bound therefore depends on
themixingpropertiesoftheauxiliaryMarkovchainonwhichitisbased.
Tomovetowardsacomputablebound,letussupposethatdisanintegral
probabilitymetric,meaningthatforanyğœ‹,ğœˆ âˆˆ P(Rğ‘‘)
âˆ« âˆ«
d(ğœ‹,ğœˆ) =sup ğ‘”(x) ğœ‹(dx)âˆ’ ğ‘”(x) dğœˆ(x) (6.8)
ğ‘”âˆˆG
for a suitable symmetric set1 of test functions G. Introducing the linear
operator
âˆ«
(ğ¿ ğœ‹ğ‘”)(Â·) = ğ‘”(xâ€²)ğ‘‡ ğœ‹(Â·,dxâ€²)âˆ’ğ‘”(Â·),
andobservingthat
âˆ« âˆ« âˆ«
(ğ¿ ğœ‹ğ‘”)(x) dğœˆ(x) = ğ‘”(xâ€²)ğ‘‡ ğœ‹(x,dxâ€²) dğœˆ(x)âˆ’ ğ‘”(x) dğœˆ(x)
âˆ« âˆ«
= ğ‘”(x) dğ‘‡ ğœ‹ğœˆ(x)âˆ’ ğ‘”(x) dğœˆ(x),
thediscrepancycanbeexpressedas
âˆ«
1
ğ· ğœ‹(ğœˆ) =
1âˆ’ğœŒ
s ğ‘”u âˆˆp
G
(ğ¿ ğœ‹ğ‘”)(x) dğœˆ(x). (6.9)
However,toactuallyevaluatethisdiscrepancywearerequiredtocompute
1 ThesetGissymmetricifâˆ’ğ‘” âˆˆ Gwheneverğ‘” âˆˆ G;thisallowsustoavoidtaking
absolutevaluesinthedefinitionoftheintegralprobabilitymetric.202 AssessingandImprovingMCMC
expressions involving ğ¿ ğœ‹, which in effect requires simulating all possi-
ble realisations of one step of the auxiliary Markov chain, and is there-
fore intractable in general. To circumvent this issue, we will move from a
discrete-timeauxiliaryMarkovchaintoacontinuous-timeauxiliaryMarkov
process,withtimeğ‘¡ transitionkernelğ‘‡ğ‘¡ andassociatedlinearoperator ğ¿ğ‘¡
ğœ‹ ğœ‹
anddiscrepancy ğ·ğ‘¡ .Thecontractionproperty(6.7)inthiscasereads
ğœ‹
d(ğ‘‡ ğœ‹ğ‘¡ğœ‹,ğ‘‡ ğœ‹ğ‘¡ğœˆ) â‰¤ ğœŒ ğ‘¡ d(ğœ‹,ğœˆ). (6.10)
Consideringtheğ‘¡ â†“0limitwemay,iftheauxiliaryMarkovprocessmixes
rapidly enough, obtain an expression for the discrepancy in terms of the
generatorL ğœ‹oftheauxiliaryMarkovprocess,whichwerecallfromSection
5.2.3isdefinedthroughitsactiononsuitablyregulartestfunctionsğ‘” :Rğ‘‘ â†’
Ras
1
(L ğœ‹ğ‘”)(Â·) :=l ğ‘¡i â†“m
0
ğ‘¡
ğ¿ğ‘¡ ğœ‹ğ‘”(Â·).
Indeed, assume that ğœŒ ğ‘¡ = ğ‘’âˆ’ğ‘ğ‘¡ for some ğ‘ > 0. Then, in a purely formal
manipulation,
ğ· ğœ‹(ğœˆ) :=limğ·ğ‘¡ ğœ‹(ğœˆ) (6.11)
ğ‘¡â†“0
âˆ« âˆ«
1 1
=s ğ‘”u âˆˆp
G
l ğ‘¡i â†“m
0
1âˆ’ğœŒ
ğ‘¡(ğ¿ğ‘¡ ğœ‹ğ‘”)(x) dğœˆ(x) =
ğ‘
s ğ‘”u âˆˆp
G
(L ğœ‹ğ‘”)(x) dğœˆ(x),
wherethefinalstepusesthedefinitionofthegeneratorL ğœ‹ andthefactthat
ğ‘’âˆ’ğ‘ğ‘¡ =1âˆ’ğ‘ğ‘¡+ğ‘œ(ğ‘¡) whenğ‘¡ issmall.Intriguingly,thisformofdiscrepancy
may be computable, up to the rate constant ğ‘, which will be unknown in
general. The remaining challenges appear to be the selection of a suitable
auxiliary Markov process, for which the contraction property (6.10) is
satisfied,andthesolutionoftheoptimisationproblemoverG.Theseissues
areaddressed,respectively,inSections6.2.2and6.2.3.
Remark (Stein discrepancies) The discrepancy that we have introduced
in (6.11) is an instance of Stein discrepancy, as defined in the pioneering
work of Gorham and Mackey (2015). A Stein discrepancy refers to any
discrepancyoftheform
âˆ«
sup (A ğœ‹ğ‘”)(x) dğœˆ (6.12)
ğ‘”âˆˆGâ€²
wherethetheSteinoperatorA
ğœ‹
andtheSteinclassGâ€²areselectedinsuch
a way that (6.12) is zero if and only if ğœ‹ and ğœˆ are equal. The concept of
a Stein discrepancy is more general than the discrepancy ğ· ğœ‹(ğœˆ) we have6.2 ConvergenceBoundsforMCMC 203
constructed, since the Stein operator A ğœ‹ need not arise from considera-
tion of a continuous-time Markov process; see for example the review of
Anastasiouetal.(2023).
6.2.2 ChoiceofAuxiliaryMarkovProcess
To make this argument useful we require a metric d and an auxiliary
continuous-timeMarkovprocessforwhichthecontractionproperty(6.10)
is satisfied. For the auxiliary Markov process, we will consider the over-
dampedLangevindiffusionfromSection1.4:
âˆš
dXğ‘¡ = âˆ‡logğœ‹(Xğ‘¡) dğ‘¡+ 2dWğ‘¡ (6.13)
whose infinitesimal generator is the second order differential operator
(L ğœ‹ğ‘”)(x) = (Î”ğ‘”)(x)+âŸ¨(âˆ‡logğœ‹)(x),(âˆ‡ğ‘”)(x)âŸ©,whereÎ”denotestheLapla-
cian differential operator for Rğ‘‘. To simplify the presentation, we initially
make the assumption that ğœ‹ is strongly log-concave, meaning that (3.18)
holds for some ğ‘™ > 0, and we recall that a sufficient condition for strong
log-concavity is that âˆ’âˆ‡âˆ‡logğœ‹(x) â‰» ğœ–Iğ‘‘ for some ğœ– > 0 and all x âˆˆ Rğ‘‘,
whereâˆ‡âˆ‡denotestheHessiandifferentialoperatorandthenotationA â‰» B
is used to mean that Aâˆ’B is a symmetric positive definite matrix. This
assumptionwillberelaxedinSection6.2.4.Letğ¶ğ‘ (Rğ‘‘,Rğ‘) denotetheset
offunctions ğ‘“ :Rğ‘‘ â†’Rğ‘ forwhichcontinuousderivativesexistoforders
uptoğ‘  âˆˆ {0,1,...}âˆª{âˆ}.Forğ‘” âˆˆğ¶0(Rğ‘‘,Rğ‘),let
âˆ¥ğ‘”(x)âˆ’ğ‘”(xâ€²)âˆ¥
ğ‘€ (ğ‘”) := sup (6.14)
1 âˆ¥xâˆ’xâ€²âˆ¥
x,xâ€²âˆˆRğ‘‘
xâ‰ xâ€²
denote its (possibly infinite) Lipschitz constant. Recall that a function ğ‘”
is called Lipschitz whenever ğ‘€ (ğ‘”) < âˆ. The following is a well-known
1
contractionresultfortheoverdampedLangevindiffusion,whoseproofcan
befoundine.g.vonRenesseandSturm(2005),orseeRemark1inEberle
(2016):
Theorem6.1(ContractionoftheoverdampedLangevindiffusion) Let ğœ‹
bestronglylog-concaveandletâˆ‡logğœ‹beLipschitz.Thentheoverdamped
Langevin diffusion (6.13) satisfies the contraction property (6.10) in the
Wasserstein-1metric
âˆ« âˆ«
dğ‘Š (ğœ‹,ğœˆ) := sup ğ‘”(x) dğœ‹(x)âˆ’ ğ‘”(x) dğœˆ(x) (6.15)
1
ğ‘”âˆˆğ¶0(Rğ‘‘,R)
ğ‘€ 1(ğ‘”)â‰¤1
with ğœŒ ğ‘¡ = ğ‘’âˆ’ğ‘ğ‘¡ forsomeğ‘ > 0andallğ‘¡ âˆˆ [0,âˆ).204 AssessingandImprovingMCMC
The infinitesimal generator L ğœ‹ of the overdamped Langevin diffusion
requiresâˆ‡ğ‘”andÎ”ğ‘”toexist,buttheWasserstein-1integralprobabilitymetric
containsnon-differentiablefunctionsinthetestfunctionsetG.Thisappears
topreventusfromrunningtheformalargumentin(6.11).However,itturns
outthatwemay,withoutlossofgenerality,imposeadditionalsmoothness
ontheWasserstein-1testfunctionset:
Lemma6.2(SmoothertestfunctionsforWasserstein-1) Forğœ‹,ğœˆ âˆˆ P(Rğ‘‘),
âˆ« âˆ«
dğ‘Š (ğœ‹,ğœˆ) = sup ğ‘”(x) dğœ‹(x)âˆ’ ğ‘”(x) dğœˆ(x). (6.16)
1
ğ‘”âˆˆğ¶âˆ(Rğ‘‘,R)
ğ‘€ 1(ğ‘”)â‰¤1
Proof Since the supremum is being computed over a subset of the test
functions in (6.15), it is immediate that the right-hand side of (6.16) is
upper-bounded by dğ‘Š (ğœ‹,ğœˆ). To prove the corresponding lower bound,
1
let ğœ– âˆˆ (0,1). From the definition of dğ‘Š in (6.15), there exists ğ‘” ğœ– with
ğ‘€ 1(ğ‘” ğœ–) â‰¤ 1 such that âˆ« ğ‘” ğœ–(x)dğœ‹(x) âˆ’ âˆ«1 ğ‘” ğœ–(x)dğœˆ(x) > dğ‘Š 1(ğœ‹,ğœˆ) âˆ’ ğœ–.
Let ğ›¿ > 0 and Z âˆ¼ N(0,Iğ‘‘). Set ğ‘” ğœ–,ğ›¿(x) = E[ğ‘” ğœ–(x+ğ›¿Z)]. Then ğ‘” ğœ–,ğ›¿ âˆˆ
ğ¶âˆ(Rğ‘‘,R)andtheLipschitzconstantofğ‘” ğœ–,ğ›¿ isnotgreaterthanthatofğ‘” ğœ–,
sinceforallx,xâ€² âˆˆ Rğ‘‘,
|ğ‘” ğœ–,ğ›¿(x)âˆ’ğ‘” ğœ–,ğ›¿(xâ€²)| = |E[ğ‘” ğœ–(x+ğ›¿Z)âˆ’ğ‘” ğœ–(xâ€²+ğ›¿Z)]|
â‰¤ ğ‘€ 1(ğ‘” ğœ–)âˆ¥xâˆ’xâ€²âˆ¥.
Thusğ‘” ğœ–,ğ›¿isanelementofthetestsetoverwhichthesupremumiscomputed
ontherighthandsideof (6.16).From
|ğ‘” ğœ–,ğ›¿(x)âˆ’ğ‘” ğœ–(x)| = |E[ğ‘” ğœ–(x+ğ›¿Z)âˆ’ğ‘” ğœ–(x)]| â‰¤ ğ›¿E[âˆ¥Zâˆ¥]ğ‘€ 1(ğ‘” ğœ–), (6.17)
itfollowsthat ğ‘” ğœ–,ğ›¿ distinguishesbetween ğœ‹ and ğœˆ almostaswellas ğ‘” ğœ–,in
thesensethat
âˆ« âˆ«
ğ‘” ğœ–,ğ›¿(x) dğœ‹(x)âˆ’ ğ‘” ğœ–,ğ›¿(x) dğœˆ(x)
âˆ« âˆ«
â‰¥ ğ‘” ğœ–(x) dğœ‹(x)âˆ’ ğ‘” ğœ–(x) dğœˆ(x)âˆ’2ğ›¿E[âˆ¥Zâˆ¥]ğ‘€ 1(ğ‘” ğœ–)
> {dğ‘Š (ğœ‹,ğœˆ)âˆ’ğœ– âˆ’2ğ›¿E[âˆ¥Zâˆ¥]},
1
whichcanbemadearbitrarilyclosetodğ‘Š (ğœ‹,ğœˆ) bytakingğœ–,ğ›¿ â†’ 0.Thus
1
thesupremumin(6.16)coincideswithdğ‘Š (ğœ‹,ğœˆ),asclaimed. â–¡
16.2 ConvergenceBoundsforMCMC 205
Tosummarise,ourformalargumenthasledtoabound
âˆ«
1
ğ· ğœ‹(ğœˆ) =
ğ‘
sup Î”ğ‘”(x)+âŸ¨âˆ‡logğœ‹(x),âˆ‡ğ‘”(x)âŸ© dğœˆ(x) (6.18)
ğ‘”âˆˆğ¶âˆ(Rğ‘‘,R)
ğ‘€ 1(ğ‘”)â‰¤1
on the Wasserstein-1 distance between ğœ‹ and ğœˆ that holds in the strongly
log-concave setting of Theorem 6.1. The route to obtaining this bound
is instructive, and the lessons that we learned will be exploited in the
subsequent sections, but unfortunately, the evaluation of this discrepancy
requiresachallengingoptimisationproblemtobesolved.Inthecasewhere
ğœˆ has finite support, the objective function depends on ğ‘” only through its
derivatives at the nodes in the support. This observation enabled Gorham
and Mackey (2015) to cast a closely related optimisation problem as a
collection of linear programmes, which then can be numerically solved.
TheinterestedreaderisreferredtoGorhamandMackey(2015)forfurther
detail.However,therelianceonnumericalmethodstoevaluate(6.18)limits
the utility of (6.18). Instead, we will proceed in Section 6.2.3 to consider
alternativesetsoftestfunctionsforwhichthecorrespondingoptimisation
problemcanbeanalyticallysolved.
6.2.3 KernelSteinDiscrepancy
The aim of this section is to consider alternatives to the Wasserstein-1
distance,correspondingtoalternativesets G oftestfunctionsdefiningthe
integralprobabilitymetric(6.8),forwhichtheoptimisationproblemin(6.9)
can be explicitly solved using the kernel trick advertised in Section 6.1.3.
However,theuseofalternativemetricsleadsustodepartfromtheargument
of Section 6.2.1, which was based on the Wasserstein-1 contraction result
of Theorem 6.1, raising the question of whether the resulting discrepancy
is still a meaningful convergence bound. This question will be answered
positivelyinSection6.2.4.
To simplify the discussion, we start by considering vector fields as test
functions, allowing us to reduce the order of the differential operators
involved.Thus,inthegeneralnotationof (6.12),weconsider
(A ğœ‹g)(x) = (âˆ‡Â·g)(x)+âŸ¨(âˆ‡logğœ‹)(x),g(x)âŸ©, (6.19)
which is a first order differential operator and the elements g are now
vector fields g : Rğ‘‘ â†’ Rğ‘‘. The discussion in Section 6.2.2 corresponds
to g(x) = (âˆ‡ğ‘”)(x) for twice-differentiable ğ‘” : Rğ‘‘ â†’ R. Here, and in
thesequel,foreaseofpresentation,wehavesubsumedtheconstantfactor206 AssessingandImprovingMCMC
1/ğ‘ into the definition of the vector fields g. Now, if we are to consider
alternative test functions g, the minimum requirement on g is that A ğœ‹g
integratesto0withrespecttoğœ‹,toensurethatthediscrepancyweconstruct
vanisheswhenğœ‹andğœˆareequal.Tothisend,wehavethefollowingresult:
Lemma 6.3 Let g : Rğ‘‘ â†’ Rğ‘‘ satisfy g âˆˆ L1(ğœ‹) and A ğœ‹g âˆˆ L1(ğœ‹),
whereA
ğœ‹
isdefinedin(6.19).Thenâˆ« (A ğœ‹g)(x) dğœ‹(x) =0.
Proof Firstnoticethat
âˆ« âˆ« âˆ«
1
(A ğœ‹g)(x) dğœ‹(x) = ğœ‹(x)(âˆ‡Â·(ğœ‹g))(x) dğœ‹(x) = (âˆ‡Â·(ğœ‹g))(x) dx,
whichsuggestsusingthedivergencetheoremtocalculatethisintegral.To
avoid the explicit calculation of surface integrals, which would otherwise
berequiredwhenusingthedivergencetheorem,wewillfirstapproximate
the vector field ğœ‹g using another vector field with compact support. Let
ğœ‘ ğ‘š : Rğ‘‘ â†’ R denote the ğ‘šth term in a sequence of compactly supported
functions with ğœ‘ ğ‘š(x) = 1 for âˆ¥xâˆ¥ â‰¤ ğ‘š, sup xâˆ¥âˆ‡ğœ‘ ğ‘š(x)âˆ¥ < ğ‘šâˆ’1 for each
ğ‘š âˆˆ N, and ğœ‘ ğ‘š(x) â†‘ 1 for each x âˆˆ Rğ‘‘. From the divergence theorem
appliedtoavectorfieldwithcompactsupport,
âˆ«
0= (âˆ‡Â·(ğœ‘ ğ‘šğœ‹g))(x) dx
âˆ« âˆ«
= âŸ¨âˆ‡ğœ‘ ğ‘š(x),(ğœ‹g)(x)âŸ© dx+ ğœ‘ ğ‘š(x)(âˆ‡Â·(ğœ‹g))(x) dx.
Since ğœ‘ ğ‘š â†‘ 1 pointwise and âˆ‡ Â· (ğœ‹g) âˆˆ L1(Rğ‘‘), from the dominated
convergencetheorem
âˆ« âˆ«
ğœ‘ ğ‘š(x)(âˆ‡Â·(ğœ‹g))(x) dxâ†’ (âˆ‡Â·(ğœ‹g))(x) dx.
On the other hand, using Cauchyâ€“Schwarz and the assumption that ğœ‹g âˆˆ
L1(Rğ‘‘),
(cid:12)âˆ« (cid:12) (cid:18) (cid:19)âˆ«
(cid:12) (cid:12) âŸ¨âˆ‡ğœ‘ ğ‘š(x),(ğœ‹g)(x)âŸ© dx(cid:12) (cid:12) â‰¤ supâˆ¥âˆ‡ğœ‘ ğ‘š(x)âˆ¥ âˆ¥(ğœ‹g)(x)âˆ¥ dxâ†’0.
(cid:12) (cid:12)
x
Thuswehaveshownthat
âˆ« âˆ«
(A ğœ‹g)(x) dğœ‹(x) = (âˆ‡Â·(ğœ‹g))(x) dx=0,
asclaimed. â–¡
Our attention now turns to selecting a set of vector fields g for which
Lemma 6.3 holds and for which the optimisation problem in (6.18) can6.2 ConvergenceBoundsforMCMC 207
be explicitly solved. One approach to this task is to use a matrix-valued
reproducingkernel,meaningafunctionK :Rğ‘‘ Ã—Rğ‘‘ â†’Rğ‘‘Ã—ğ‘‘ thatis
1. transpose-symmetric;K(x,xâ€²) =K(xâ€²,x)âŠ¤ forallx,xâ€² âˆˆ Rğ‘‘
2. positivesemi-definite;
ğ‘› ğ‘›
âˆ‘ï¸âˆ‘ï¸
âŸ¨cğ‘˜,K(xğ‘˜,xğ‘˜â€²)cğ‘˜â€²âŸ© â‰¥ 0
ğ‘˜=1 ğ‘˜â€²=1
forallx 1,...,xğ‘› âˆˆ Rğ‘‘,allc 1,...,cğ‘› âˆˆ Rğ‘‘,andallğ‘› âˆˆ N.
For clarity, we emphasise that âŸ¨c,câ€²âŸ© = câŠ¤câ€² is the usual Euclidean inner
product on Rğ‘›; in the sequel we will use subscripts to distinguish other
innerproductsastheyareintroduced.LetK = K(Â·,x),sothatK : Rğ‘‘ â†’
x x
Rğ‘‘Ã—ğ‘‘ is matrix-valued. For vector-valued functions g = (cid:205)ğ‘› ğ‘˜=1K xğ‘˜cğ‘˜ and
gâ€² =(cid:205) ğ‘™ğ‘š =1K
x
ğ‘™â€²c ğ‘™â€²,defineaninnerproduct
ğ‘› ğ‘š
âˆ‘ï¸âˆ‘ï¸
âŸ¨g,gâ€²âŸ©
H(K)
= âŸ¨cğ‘˜,K(xğ‘˜,x ğ‘™â€²)c ğ‘™â€²âŸ©. (6.20)
ğ‘˜=1 ğ‘™=1
ThereisauniqueHilbertspacereproducedbyK,denotedH(K);seePropo-
sition2.1ofCarmelietal.(2006).Thisspaceischaracterisedas
H(K) =span{K c:x,c âˆˆ Rğ‘‘}
x
whereheretheclosureistakenwithrespecttotheinnerproductin(6.20).
TheresultingHilbertspacesatisfiesthereproducingproperty
âŸ¨g,K câŸ© = âŸ¨g(x),câŸ©
x H(K)
forallg âˆˆ H(K) andx,c âˆˆ Rğ‘‘,whichisaparticularinstanceofthekernel
trickdiscussedinSection6.1.3.Inwhatfollows,itisconvenienttooverload
notation,suchthatthereproducingpropertybecomesâŸ¨g,K âŸ© =g(x)in
x H(K)
aninformalshorthand.
Assumingsufficientregularitythat
ğ¹
ğœˆ
:H(K) â†’R
âˆ«
gâ†¦â†’ (A ğœ‹g)(x) dğœˆ(x)
is a bounded linear functional, the Riesz representation theorem tells us
that there is a unique element ğœ‡ ğœˆ such that ğ¹ ğœˆ(Â·) = âŸ¨ğœ‡ ğœˆ,Â·âŸ© H(K). Using our
reproducingpropertyshorthand,
âˆ«
ğœ‡ ğœˆ(xâ€²) = âŸ¨ğœ‡ ğœˆ,K xâ€²âŸ©
H(K)
= ğ¹ ğœˆ(K xâ€²) = Ax ğœ‹K(x,xâ€²)dğœˆ(x),208 AssessingandImprovingMCMC
wherethesuperscriptinAx ğœ‹ indicatestheactionofA ğœ‹ onthexargument,
collapsing the matrix-valued function K into the vector-valued function
x
AxK .Itfollowsthat,ifweconsiderthecollectionofvectorfieldsgwithin
ğœ‹ x
theunitballofH(K),ouroptimisationproblemcanbeexplicitlysolved:
âˆ«
sup (A ğœ‹g)(x) dğœˆ(x) = sup âŸ¨g,ğœ‡ ğœˆâŸ©
H(K)
= âˆ¥ğœ‡ ğœˆâˆ¥ H(K), (6.21)
âˆ¥gâˆ¥H(K)â‰¤1 âˆ¥gâˆ¥H(K)â‰¤1
where,againfromthereproducingpropertyandtheassumptionthat ğ¹ ğœˆ is
aboundedlinearfunctional,
(cid:28)âˆ« âˆ« (cid:29)
âˆ¥ğœ‡ ğœˆâˆ¥2
H(K)
= Ax ğœ‹K
x
dğœˆ(x), Ax ğœ‹â€² K
xâ€²
dğœˆ(xâ€²)
H(K)
âˆ¬
= AxAxâ€²âŸ¨K ,K âŸ© dğœˆ(x)dğœˆ(xâ€²)
ğœ‹ ğœ‹ x xâ€² H(K)
âˆ¬
= AxAxâ€² K(x,xâ€²) dğœˆ(x)dğœˆ(xâ€²).
ğœ‹ ğœ‹
It is convenient to introduce the shorthand ğ‘˜ ğœ‹(x,xâ€²) := Ax ğœ‹Ax ğœ‹â€²K(x,xâ€²),
whenceweobtainthediscrepancy
âˆšï¸„
âˆ¬
D ğ‘˜ (ğœˆ) := ğ‘˜ ğœ‹(x,xâ€²) dğœˆ(x)dğœˆ(xâ€²), (6.22)
ğœ‹
which isexactly ofthe formwe soughtin (6.6).This wastermed akernel
Stein discrepancy in Chwialkowski et al. (2016); Liu et al. (2016), due to
its dependence on a reproducing kernel and its characterisation as a Stein
discrepancy(6.1).Asecondconsequenceof (6.21)isthatwecanviewthe
kernelSteindiscrepancyasageneralisedmoment
(cid:13) ğ‘› (cid:13)
D ğ‘˜ ğœ‹(ğœˆ ğ‘›) =(cid:13) (cid:13) (cid:13) (cid:13)ğ‘›1 âˆ‘ï¸
ğ‘˜=1
Ax ğœ‹K x(cid:12) (cid:12) x=xğ‘˜ dğœˆ(x)(cid:13) (cid:13) (cid:13)
(cid:13)
H(K),
whichtakesasimilarformto(6.4)fromSection6.1.2,albeitthegeneralised
momentcannowbeinfinite-dimensionalbyvirtueoftakingvaluesinH(K).
The function AxK is indeed a member of H(K) due to the differential
ğœ‹ x
reproducing property (see Barp et al., 2022, Appendix C6). The kernel
Stein discrepancy has the potential to be a useful bias diagnostic, but first
weneedtoestablishthatithasourbasicdesiredfunctionality,suchasbeing
equal to 0 if and only if ğœ‹ and ğœˆ are identical. Clearly, then the choice of
kernelKwillbeimportant,soweaddressthispointnext.
Oneofthesimplestformsofmatrix-valuedreproducingkernelisK(x,xâ€²) =6.2 ConvergenceBoundsforMCMC 209
k(x,xâ€²)Iğ‘‘,wherekisascalar-valuedreproducingkernel.Thischoiceleads
totheexplicitformula,duetoOatesetal.(2017):
kğœ‹(x,xâ€²) = âˆ‡ xÂ·âˆ‡ xâ€²k(x,xâ€²)+âŸ¨âˆ‡ xlogğœ‹(x),âˆ‡ xâ€²k(x,xâ€²)âŸ©
+âŸ¨âˆ‡ logğœ‹(xâ€²),âˆ‡ k(x,xâ€²)âŸ©
xâ€² x
+âŸ¨âˆ‡ logğœ‹(x),âˆ‡ logğœ‹(xâ€²)âŸ©k(x,xâ€²) (6.23)
x xâ€²
The function kğœ‹ is automatically a scalar-valued reproducing kernel (see
Barpetal.,2022,Theorem2.6),andkğœ‹(x,xâ€²) = Ax ğœ‹g xâ€²(x)whereg xâ€²(x) :=
Axâ€²K(x,xâ€²) âˆˆ H(K). Thus, if the matrix-valued reproducing kernel K is
ğœ‹
selectedsuchthattheconditionsg âˆˆ L1(ğœ‹) andA ğœ‹g âˆˆ L1(ğœ‹) ofLemma
6.3 are satisfied for each g âˆˆ H(K), it follows that âˆ« kğœ‹(x,xâ€²)dğœ‹(x) =
âˆ« Axg (x) dğœ‹(x) = 0forallxâ€² âˆˆ Rğ‘‘.Sufficientconditionsforsatisfying
ğœ‹ xâ€²
thepreconditionsofLemma6.3willshortlybediscussed.
Inthecasewhereğœˆ =(cid:205)ğ‘› ğ‘˜=1ğ‘¤ ğ‘˜ğ›¿ xğ‘˜isadiscretedistribution,(6.22)reduces
tothedoublesum
(cid:118)(cid:116)
ğ‘› ğ‘›
âˆ‘ï¸âˆ‘ï¸
D kğœ‹(ğœˆ) = ğ‘¤ ğ‘˜ğ‘¤ ğ‘˜â€²kğœ‹(xğ‘˜,xğ‘˜â€²). (6.24)
ğ‘˜=1 ğ‘˜â€²=1
For the degenerate reproducing kernel with k(x,xâ€²) = 1 for all x,xâ€² âˆˆ Rğ‘‘
and uniform weights ğ‘¤ ğ‘˜ = ğ‘›âˆ’1, the kernel Stein discrepancy in (6.24)
reducestothesimpleform
(cid:13) ğ‘› (cid:13)
(cid:13)1 âˆ‘ï¸ (cid:13)
D kğœ‹(ğœˆ) =(cid:13)
(cid:13)ğ‘›
âˆ‡ xlogğœ‹(xğ‘˜)(cid:13) (cid:13),
(cid:13) ğ‘˜=1 (cid:13)
whichispreciselythebiasdiagnosticfrom(6.4).Inthiscase,H(K) isthe
Hilbert space of constant vector fields on Rğ‘‘ with norm âˆ¥gâˆ¥ = âˆ¥ğœ·âˆ¥
H(K)
where g(x) = ğœ· for all x âˆˆ Rğ‘‘, which is insufficiently rich to determine
whetherornotğœ‹ andğœˆ arecloseorequal.However,withasuitablechoice
ofreproducingkernelthekernelSteindiscrepancycandistinguishbetween
differentdistributionsandindeedprovideaformofconvergencecontrol,as
weexplaininSection6.2.4.
First,however,wemustensuretheconditionsofLemma6.3aresatisfied,
sothatD (ğœˆ) =0whenğœ‹andğœˆareequal.Thiscanbeachievedusingthe
kğœ‹
followingresult:
Lemma 6.4 If K(x,xâ€²) = k(x,xâ€²)Iğ‘‘ with k(x,xâ€²) = ğœ™(xâˆ’xâ€²) for some
ğœ™ âˆˆğ¶2(Rğ‘‘,R),thenâˆ‡logğœ‹ âˆˆ L1(ğœ‹)impliesg âˆˆ L1(ğœ‹)andA ğœ‹g âˆˆ L1(ğœ‹)
forallg âˆˆ H(K).210 AssessingandImprovingMCMC
Proof Thereproducingproperty,followedbyCauchyâ€“Schwarz,gives
âˆ« âˆ«
âˆ¥g(x)âˆ¥ dğœ‹(x) = âˆ¥âŸ¨g,K âŸ© âˆ¥ dğœ‹(x)
x H(K)
âˆ«
âˆšï¸ âˆšï¸
â‰¤ âˆ¥gâˆ¥ tr(K(x,x)) dğœ‹(x) = âˆ¥gâˆ¥ ğ‘‘ğœ™(0),
H(K) H(K)
whichisfiniteforallg âˆˆ H(K).Similarly,
âˆ« âˆ«
|(A ğœ‹g)(x)| dğœ‹(x) = |âŸ¨g,Ax ğœ‹K xâŸ© H(K)| dğœ‹(x)
âˆ«
â‰¤ âˆ¥gâˆ¥ âˆšï¸ AxAxâ€²K(x,xâ€²)| dğœ‹(x).
H(K) ğœ‹ ğœ‹ xâ€²=x
Here the assumption ğœ™ âˆˆ ğ¶2(Rğ‘‘,R) ensures the application of AxAxâ€² to
ğœ‹ ğœ‹
K(x,xâ€²) iswell-defined.Specialisingtothetranslation-invariantreproduc-
ingkernelinthestatement,wehave
AxAxâ€² K(x,xâ€²)| =âˆ’(Î”ğœ™)(0)+ğœ™(0)âˆ¥(âˆ‡logğœ‹)(x)âˆ¥2 (6.25)
ğœ‹ ğœ‹ xâ€²=x
whichshowsthatA ğœ‹g âˆˆ L1(ğœ‹)wheneverâˆ‡logğœ‹ âˆˆ L1(ğœ‹),andcompletes
theargument. â–¡
ThekernelSteindiscrepancieswehavejustconstructedarewell-defined
andcomputable,butwehavenotyetaddressedthequestionofifandhow
thevaluesofthediscrepancy D (ğœˆ) arerelatedtotheclosenessof ğœ‹ and
kğœ‹
ğœˆ.Indeed,sincewehaveusedalternativetestfunctionscomparedto(6.18),
wecannotexpect D (ğœˆ) toprovideanupperboundontheWasserstein-1
kğœ‹
distancebetween ğœ‹ and ğœˆ.Thenextsectionexplainstowhatextentkernel
Steindiscrepanciesrelatetotheclosenessofğœ‹andğœˆ.
6.2.4 ConvergenceControl
The aim of this section is to establish whether kernel Stein discrepancies
canprovidecontroloverintegralprobabilitymetrics.Atthesametime,we
willweakenthestronglog-concavityassumptionfromSection6.2.2toan
assumptionthatğœ‹isdistantlydissipative,meaningthat
(cid:26) âŸ¨(âˆ‡logğœ‹)(x)âˆ’(âˆ‡logğœ‹)(xâ€²),xâˆ’xâ€²âŸ©(cid:27)
liminf inf âˆ’ > 0,
ğ‘Ÿâ†’âˆ x,xâ€²âˆˆRğ‘‘ âˆ¥xâˆ’xâ€²âˆ¥2
âˆ¥xâˆ’xâ€²âˆ¥=ğ‘Ÿ
forwhichWasserstein-1contractionoftheoverdampedLangevindiffusion
(6.13) can still be established (see Lindvall and Rogers, 1986; Eberle,
2016).ThenextLemmademonstratesthatdistantdissipativityisindeeda
generalisationofstronglog-concavity:6.2 ConvergenceBoundsforMCMC 211
Lemma 6.5 If âˆ‡logğœ‹ is bounded on a compact set ğ‘† âŠ‚ Rğ‘‘ and ğœ‹ is
stronglylog-concaveontheboundaryofandoutsideofthesetğ‘†,thenğœ‹ is
distantlydissipative.
Proof Let b(x) := (âˆ‡logğœ‹)(x), let ğ‘† be the compact set in the state-
ment,andletint(ğ‘†)denotetheinteriorofğ‘†.Fromthestronglog-concavity
assumption,thereexistsğ‘ > 0suchthatforallx,xâ€² âˆ‰int(ğ‘†) wehave
âŸ¨b(x)âˆ’b(xâ€²),xâˆ’xâ€²âŸ©
âˆ’ > ğ‘. (6.26)
âˆ¥xâˆ’xâ€²âˆ¥2
Since b is bounded on ğ‘†, we may pick ğµ > sup âˆ¥b(x)âˆ¥. Since ğ‘† is
xâˆˆğ‘†
compact, ğ‘† is contained in {x : âˆ¥xâˆ¥ â‰¤ ğ‘Ÿ/2} for some sufficiently large
ğ‘Ÿ > 0,andwemaysupposethatğ‘Ÿ > 2ğµ/ğ‘,soğ‘â€² := ğ‘âˆ’(2ğµ/ğ‘Ÿ) > 0.
Consider arbitrary x,xâ€² such that âˆ¥xâˆ’xâ€²âˆ¥ > ğ‘Ÿ. If x,xâ€² âˆ‰ ğ‘†, condition
(6.26) is satisfied. Thus consider the other case, where without loss of
generality x âˆˆ ğ‘† (and thus xâ€² âˆ‰ ğ‘†). Let xâ€²â€² be the closest point to x that
belongstoğ‘†andiscolinearwithxandxâ€².Then
âˆ’âŸ¨b(x)âˆ’b(xâ€²),xâˆ’xâ€²âŸ© =âˆ’âŸ¨b(x)âˆ’b(xâ€²â€²),xâˆ’xâ€²âŸ©âˆ’âŸ¨b(xâ€²â€²)âˆ’b(xâ€²),xâˆ’xâ€²âŸ©
(cid:28) xâˆ’xâ€²â€² (cid:29)
=âˆ’âˆ¥xâˆ’xâ€²âˆ¥ b(x)âˆ’b(xâ€²â€²),
âˆ¥xâˆ’xâ€²â€²âˆ¥
âˆ¥xâˆ’xâ€²âˆ¥
âˆ’ âŸ¨b(xâ€²â€²)âˆ’b(xâ€²),xâ€²â€²âˆ’xâ€²âŸ©
âˆ¥xâ€²â€²âˆ’xâ€²âˆ¥
> âˆ’âˆ¥xâˆ’xâ€²âˆ¥Â·2ğµ + 1Â·ğ‘âˆ¥xâ€²â€²âˆ’xâ€²âˆ¥2
whereinthefinallinetheCauchyâ€“Schwarzandtriangleinequalitieswere
usedtoboundthefirstterm,andforthesecondterm(6.26)wasappliedto
xâ€²,xâ€²â€² âˆ‰int(ğ‘†).Thus
âŸ¨b(x)âˆ’b(xâ€²),xâˆ’xâ€²âŸ© 2ğµ 2ğµ
âˆ’ > âˆ’ +ğ‘ > âˆ’ +ğ‘ = ğ‘â€².
âˆ¥xâˆ’xâ€²âˆ¥2 âˆ¥xâˆ’xâ€²âˆ¥ ğ‘Ÿ
Combiningthesetworesults,wehaveshownthatforallx,xâ€²withâˆ¥xâˆ’xâ€²âˆ¥ >
ğ‘Ÿ,
âŸ¨b(x)âˆ’b(xâ€²),xâˆ’xâ€²âŸ©
âˆ’ > min(ğ‘,ğ‘â€²) > 0
âˆ¥xâˆ’xâ€²âˆ¥2
andthusthedistantdissipativityofğœ‹isestablished. â–¡
ThemostcommonlyusedkernelSteindiscrepanciesdonotoffercontrol
oftheWasserstein-1distance,thoughitispossible,throughacarefulchoice
ofkernel,toobtainWasserstein-1control;wereturntothispointattheend212 AssessingandImprovingMCMC
ofthepresentsection.Rather,themostcommonkernelSteindiscrepancies
offercontrolofthe(weaker)Dudleymetric
âˆ« âˆ«
dğ·(ğœ‹,ğœˆ) := sup ğ‘”(x) dğœ‹(x)âˆ’ ğ‘”(x) dğœˆ(x)
ğ‘”âˆˆğ¶0(Rğ‘‘,R)
ğ‘€ 0(ğ‘”)+ğ‘€ 1(ğ‘”)â‰¤1
on P(Rğ‘‘), at least in certain scenarios where ğœ‹ is distantly dissipative
andthereproducingkernel ğ‘˜ iscarefullyselected.Foraboundedfunction
ğ‘” : Rğ‘‘ â†’ Rğ‘, let ğ‘€ (ğ‘”) = sup âˆ¥ğ‘”(x)âˆ¥ and recall that ğ‘€ (ğ‘”) denotes
0 xâˆˆRğ‘‘ 1
theLipschitzconstant,from(6.14).
Theorem 6.6 (Weak convergence control; Theorem 8 of Gorham and
Mackey, 2017) Let ğœ‹ be distantly dissipative and âˆ‡logğœ‹ be Lipschitz.
LetK(x,xâ€²) = ğœ™(xâˆ’xâ€²)Iğ‘‘ where ğœ™(z) = (1+âˆ¥z/ğœâˆ¥2)âˆ’ğ›½ forsome ğœ > 0,
ğ›½ âˆˆ (0,1).ThenD kğœ‹(ğœˆ ğ‘›) â†’0impliesthatdğ·(ğœ‹,ğœˆ ğ‘›) â†’0.
Ofcourse,ifâˆ‡logğœ‹ isLipschitz,thenâˆ‡logğœ‹ isautomaticallybounded
onanycompactset.ThesetoftestfunctionsthatdefinetheDudleymetric
issmallerthanthatfortheWasserstein-1metric,andasaresulttheDudley
metricisweakerthantheWasserstein-1metric.Indeed,theDudleymetric
actuallymetrisestheso-calledweakconvergenceofdistributions,meaning
thatğœˆ ğ‘›convergesweakly(orindistribution)toğœ‹ifandonlyifdğ·(ğœ‹,ğœˆ ğ‘›) â†’
0.ThekernelSteindiscrepancyitselfdoesnotprovideanupperboundon
dğ· in this context, but an explicit nonlinear transformation of the kernel
Steindiscrepancydoesstillconstituteanexplicitupperbound.SeeGorham
andMackey(2017)forfulldetails.
The reproducing kernel appearing in Theorem 6.6 is called the inverse
multi-quadricreproducingkernel,anditsusewasnotaccidental.Thecare-
fulanalysisinTheorem6ofGorhamandMackey(2017)demonstratesthat
reproducingkernelswithlightertailscanfailtocontrolweakconvergence,
at least in dimension ğ‘‘ â‰¥ 3. Moreover, the inverse multi-quadric repro-
ducing kernel is computationally straightforward, and in fact the property
of weak convergence control extends to the parametric family of inverse
multi-quadricreproducingkernelsoftheform
K IMQ(x,xâ€²) = (cid:0) 1+âˆ¥ğšºâˆ’1/2(xâˆ’xâ€²)âˆ¥2(cid:1)âˆ’ğ›½ Iğ‘‘, ğšº â‰» 0, ğ›½ âˆˆ (0,1), (6.27)
where ğšº is a symmetric positive definite matrix, with the former case
recovered when ğšº = Iğ‘‘; see Theorem 4 in Chen et al. (2019). For the
extendedfamilyofinversemulti-quadricreproducingkernelsin(6.27),the6.2 ConvergenceBoundsforMCMC 213
explicitformin(6.23)becomes
4ğ›½(ğ›½+1)âˆ¥ğšºâˆ’1(xâˆ’xâ€²)âˆ¥2
kğœ‹(x,xâ€²) =âˆ’
(1+âˆ¥ğšºâˆ’1/2(xâˆ’xâ€²)âˆ¥2)ğ›½+2
(cid:20) tr(ğšºâˆ’1)+âŸ¨(âˆ‡logğœ‹)(x)âˆ’(âˆ‡logğœ‹)(xâ€²),ğšºâˆ’1(xâˆ’xâ€²)âŸ©(cid:21)
+2ğ›½
(1+âˆ¥ğšºâˆ’1/2(xâˆ’xâ€²)âˆ¥2)ğ›½+1
âŸ¨(âˆ‡logğœ‹)(x),(âˆ‡logğœ‹)(xâ€²)âŸ©
+ ,
(1+âˆ¥ğšºâˆ’1/2(xâˆ’xâ€²)âˆ¥2)ğ›½
which can be readily computed provided that the gradient âˆ‡logğœ‹ can be
pointwiseevaluated.
To illustrate the performance of kernel Stein discrepancies, consider
again the Gaussian mixture distribution ğœ‹ from (6.3). This distribution
is distantly dissipative2 and has a log-density that is Lipschitz, meaning
we are in the setting of Theorem 6.6. Proceeding with the inverse multi-
quadric reproducing kernel (6.27) with parameters Î£ = 1, ğ›½ = 0.5, we
thereforehaveaguaranteethatconvergenceofthekernelSteindiscrepancy
D kğœ‹(ğœˆ ğ‘›) to0impliestheweakconvergenceofğœˆ
ğ‘›
toğœ‹.Inwhatfollowswe
let ğœˆ ğ‘› = ğ‘›1 (cid:205)ğ‘› ğ‘˜=1ğ›¿ ğ‘‹
ğ‘˜
be the empirical distribution associated to a Markov
chainsamplepath(ğ‘‹ ğ‘˜) 1â‰¤ğ‘˜â‰¤ğ‘›andusekernelSteindiscrepancytodetermine
whetherornotğœˆ ğ‘›convergestoğœ‹.TheleftpanelofFigure6.3displaystypical
realisations of the Markov chain sample path (top), while underneath the
associated kernel Stein discrepancy (as a function of ğ‘›) is displayed. In
addition,thefigureincludescorrespondingresultsforaMarkovchainthat
leaves only the first component of ğœ‹ invariant (right), and thus does not
provide a consistent approximation of ğœ‹. Asymptotically, it can be seen
that the kernel Stein discrepancy correctly distinguishes between the two
scenarios,inwhichtheMarkovchaindoesanddoesnotleave ğœ‹ invariant.
However, focusing on the biased Markov chain, at small sample sizes the
discrepancy does not detect that the chain has only explored one mixture
component, and the discrepancy appears to decrease smoothly as more
samples are collected. It is only once a sufficient number of samples have
been collected that the failure of the Markov chain to explore the second
mixture component is detected, and the discrepancy ceases decreasing to
reflectthat.
Thesmallğ‘› behaviourofthekernelSteindiscrepancyobservedinFig-
ure 6.3has been termedblindness tomixing proportionsin Wenliangand
Kanagawa (2021), and provides an important note of caution that, when
2 TheclassofdistantlydissipativedistributionsincludesallfiniteGaussianmixtureswith
commoncovariancematrix;seeGorhametal.(2019).214 AssessingandImprovingMCMC
   
   
   
                         
 L W H U D W L R Q  L W H U D W L R Q
   
     
   
     
   
     
       
           
 L W H U D W L R Q  L W H U D W L R Q
Figure6.3 PerformanceofkernelSteindiscrepancy.Three
unbiased(left)andbiased(right)Markovchainsweresimulated.
Intheunbiasedcase,thekernelSteindiscrepancyD kğœ‹(ğœˆ ğ‘›)
correctlydetectsthattheMarkovchainsareconvergingtothe
target.Inthebiasedscenario,thekernelSteindiscrepancydetects
thattheMarkovchainshavenotconvergedtothecorrecttarget,
butthisbecomesclearonlyafterasufficientnumberofiterations
havebeenperformed.[Starsindicatetheinitialstateofeach
Markovchain.Thedensityğœ‹isshaded.]
using kernel Stein discrepancies to assess MCMC output, the failure of
the Markov chain to explore distant high-probability regions may only be
detectedifthelengthğ‘›oftheMarkovchainoutputislargeenough.Ourfor-
mal argument in Section 6.2.1 provides insight into this phenomenon; the
Wasserstein-1contractionrateconstantoftheoverdampedLangevindiffu-
)
Î½(
x
n
Ï€k
D
)
Î½(
x
n
Ï€k
D6.2 ConvergenceBoundsforMCMC 215
sion,denotedğ‘in(6.11),canbeextremelysmallfordistributionssuchasğœ‹
forwhichtheblindnessphenomenonisencountered,sinceforthisdiffusion
a move between the effective support of the distinct mixture components
isarareevent.Asaconsequence,althoughkernelSteindiscrepancydoes
provide convergence control, in unfavourable settings it may provide only
alooseformofcontrol.
In multi-dimensional settings, an appropriate choice of the matrix ğšº
appearing in the inverse multi-quadric reproducing kernel (6.27) can be
important. In situations where ğœˆ ğ‘› can be interpreted as an approximation
of ğœ‹, the present authors continue to recommended the use of ğšº = Iğ‘‘,
followingtheapplicationofadata-dependenttransformation
(xğ‘–,âˆ‡logğœ‹(xğ‘–)) â†¦â†’ (ğšª ğ‘›âˆ’1xğ‘–,ğšª ğ‘›âˆ‡logğœ‹(xğ‘–)), (6.28)
where ğšª ğ‘› is the diagonal matrix whose diagonal entries are the mean
absolutedeviationofthecorrespondingcoordinatesof(xğ‘˜) 1â‰¤ğ‘˜â‰¤ğ‘›,thestates
on which ğœˆ ğ‘› is supported. This transformation amounts to performing the
change of variables x â†¦â†’ x := ğšªâˆ’1x prior to computing the kernel Stein
(cid:101) ğ‘›
discrepancywithğšº =Iğ‘‘.Indeed,denotingby (cid:101)ğœ‹thetransformedprobability
densityfunction,thechange-of-variablesformulagivesthat
âˆ‡ (cid:101)xlog (cid:101)ğœ‹( (cid:101)x) = âˆ‡ (cid:101)xlog[det(ğšª ğ‘›)ğœ‹(x)]
= âˆ‡ logğœ‹(x)
(cid:101)x
= âˆ‡ (cid:101)xlogğœ‹(ğšª ğ‘›(cid:101)x) = ğšª ğ‘›âˆ‡logğœ‹(ğšª ğ‘›(cid:101)x) = ğšª ğ‘›âˆ‡logğœ‹(x).
In this recommendation, the mean absolute deviation is used to provide a
robust estimate for the unknown scale of the standard deviation of each
coordinateinğœ‹.Onemaybetemptedtoconsiderextendingthisrecommen-
dation to the more general class of invertible linear transformations, but
theauthorsofRiabizetal.(2022)cautionedthatifconsiderableadditional
sample-based variability is introduced in estimating a general invertible
lineartransform,thiscanactasanundesirableconfoundingfactorwhenthe
resultingdiscrepanciesaretobeinterpretedforassessmentofMCMC.Ina
similarspirit,so-calledslicedkernelSteindiscrepancieshaverecentlybeen
developedforhigh-dimensionalapplications(Gongetal.,2020);however,
at the time of writing the convergence control of these discrepancies has
yettobeestablished.
Asidefromthespecificlimitationsjustdiscussed,thereareamyriadof
statisticalapplicationswherekernelSteindiscrepanciescanandhavebeen
successfullyapplied.Twodistinctuseswillbediscussedinthischapter;op-
timalweightingofMarkovchainoutput(Section6.3),andoptimalthinning216 AssessingandImprovingMCMC
of Markov chain output (Section 6.4). To close this section, we highlight
thatstrongermodesofconvergencecanalsobecontrolledbykernelStein
discrepancies. The following result, which is a special case of Kanagawa
et al. (2024), indicates how a suitable tilting of the reproducing kernel
enforcesmomentconvergencecontrol:
Theorem 6.7 (Moment convergence control; Corollary 3.4 in Kanagawa
etal.(2024)) Let ğœ‹ bedistantlydissipativeand âˆ‡logğœ‹ beLipschitz.Let
ğ‘ âˆˆ N,x
0
âˆˆ Rğ‘‘,andadopttheshorthandğ‘¤ ğ‘Ÿ(x) := (1+âˆ¥xâˆ’x 0âˆ¥2)(ğ‘Ÿâˆ’1)/2.
Let
K(x,xâ€²) = ğ‘¤ ğ‘(x)ğ‘¤ ğ‘(xâ€²)K IMQ(x,xâ€²)+ğ‘¤ ğ‘âˆ’1(x)ğ‘¤ ğ‘âˆ’1(xâ€²)(1+âŸ¨xâˆ’x 0,xâ€²âˆ’x 0âŸ©)Iğ‘‘
whereK istheinversemulti-quadricreproducingkernelfrom(6.27).Let
IMQ
(ğœˆ ğ‘›) ğ‘›âˆˆN beasequenceofdistributionswhosemomentsuptoorderğ‘ exist.
Then D kğœ‹(ğœˆ ğ‘›) â†’ 0 implies that both dğ·(ğœ‹,ğœˆ ğ‘›) â†’ 0 and the moments of
ğœˆ
ğ‘›
uptoorderğ‘ convergetothoseofğœ‹.
In other words, the kernel Stein discrepancies constructed in this manner
have control over the Wasserstein-ğ‘ distance, which is equivalent to weak
convergenceplustheconvergenceofmomentsuptoğ‘thorder.Theprincipal
requirement for making use of the kernel Stein discrepancies in Theorem
6.7 is to pick a location x âˆˆ Rğ‘‘. Theoretical guidance tells us that this
0
kernelSteindiscrepancyprovidestightestcontrolovermomentswhenx is
0
inaregionofhighprobabilityforğœ‹,sinceotherwisetheweightingsğ‘¤ ğ‘ and
ğ‘¤ ğ‘âˆ’1 become approximately constant and we recover the standard kernel.
Thedifficultyoffindingsuchalocationx willbecontext-dependent.
0
6.2.5 StochasticGradientSteinDiscrepancy
The aim of this section is to discuss how kernel Stein discrepancies may
be extended to the so-called tall data setting, where algorithms such as
stochasticgradientMCMCfromChapter3areused.Theprincipalchallenge
inthissettingisthatcomputationofthegradientâˆ‡logğœ‹isassociatedwith
ahighcomputationalcostğ‘‚(ğ‘) duetotheformofthelikelihood
ğ‘
(cid:214)
ğ¿(x;D) = ğ¿(x;yğ‘—)
ğ‘—=1
asaproductofalargenumberğ‘oftermsthateachneedtobedifferentiated.
PerformingBayesianinferencewithapriorğœ‹ (x),theposteriordistribution
06.2 ConvergenceBoundsforMCMC 217
takestheform
ğ‘
(cid:214)
ğœ‹(x) âˆ ğœ‹ ğ‘—(x), ğœ‹ ğ‘—(x) âˆ ğœ‹ 0(x)1/ğ‘ğ¿(x;yğ‘—),
ğ‘—=1
whereweassumeeachğœ‹
ğ‘—
canbeproperlynormalised.Letğœˆ
ğ‘›
= ğ‘›1 (cid:205)ğ‘› ğ‘˜=1ğ›¿
xğ‘˜
define a sequence (ğœˆ ğ‘›) ğ‘›âˆˆN âŠ‚ P(Rğ‘‘) of discrete distributions in terms
of a sequence (xğ‘˜) ğ‘˜âˆˆN âŠ‚ Rğ‘‘. Fix a batch size ğ‘š â‰ª ğ‘ and, for each
ğ‘˜, independently select a uniformly random subset S ğ‘š(ğ‘˜) of size ğ‘š from
{1,...,ğ‘}.Then
ğ‘ âˆ‘ï¸
(cid:98)bğ‘˜ :=
ğ‘š
âˆ‡logğœ‹ ğ‘—(xğ‘˜)
ğ‘—âˆˆSğ‘š(ğ‘˜)
is a stochastic approximation to the gradient b(xğ‘˜) = âˆ‡logğœ‹(xğ‘˜) that
can be computed at a relatively lower ğ‘‚(ğ‘š) cost. It is then tempting to
replacetheexactgradientsb(xğ‘–)withtheirstochasticcounterparts(cid:98)bğ‘–within
the construction of kernel Stein discrepancy. For reproducing kernels of
the form K(x,xâ€²) = k(x,xâ€²)Iğ‘‘, this construction leads to the following
stochasticapproximationof (6.23):
(cid:68) (cid:69)
(cid:98)kğœ‹(xğ‘–,xğ‘—) := âˆ‡ xÂ·âˆ‡ xâ€²k(x,xâ€²)|
x=xğ‘–,xâ€²=xğ‘—
+ (cid:98)bğ‘–, âˆ‡ xâ€²k(xğ‘–,xâ€²)|
xâ€²=xğ‘—
+(cid:68) (cid:98)bğ‘—, âˆ‡ xk(x,xğ‘—)(cid:12) (cid:12) x=xğ‘–(cid:69) +(cid:68) (cid:98)bğ‘–, (cid:98)bğ‘—(cid:69) k(xğ‘–,xğ‘—)
Gorhametal.(2020)definedthestochastickernelSteindiscrepancyinthis
contextas
(cid:118)(cid:116)
ğ‘› ğ‘›
1 âˆ‘ï¸âˆ‘ï¸
D
kË†
ğœ‹(ğœˆ ğ‘›) =
ğ‘›2
kË† ğœ‹(xğ‘˜,xğ‘˜â€²).
ğ‘˜=1 ğ‘˜â€²=1
An immediate question is whether or not the introduction of stochastic-
ity into the gradients jeopardised the weak convergence control property
established in the case of exact gradients in Theorem 6.6. It turns out
that, provided each ğœ‹ 1,...,ğœ‹ ğ‘ satisfies the conditions of Theorem 6.6,
a form of weak convergence control continues to hold. Specifically, if
each ğœ‹ ğ‘– is distantly dissipative, and each âˆ‡logğœ‹ ğ‘– is Lipschitz, then with
k(x,xâ€²) = (1+âˆ¥(xâˆ’xâ€²)/ğœâˆ¥2)âˆ’ğ›½,ğœ > 0, ğ›½ âˆˆ (0,1),Gorhametal.(2020,
Theorem4)showsthat
D
kË†
ğœ‹(ğœˆ ğ‘›) â†’0 =â‡’ d D(ğœ‹,ğœˆ ğ‘›) â†’0
almost surely. This result justifies the use of stochastic kernel Stein dis-
crepanciesintheirownright,notmerelyasapproximationstokernelStein218 AssessingandImprovingMCMC
discrepancy that becomes exact when ğ‘š = ğ‘. Indeed, in principle, only a
batchsizeofğ‘š =1isrequired.
Figure 6.4 displays stochastic kernel Stein discrepancies computed for
the sequence of empirical distributions ğœˆ ğ‘› produced using stochastic gra-
dient Langevin dynamics applied to the logistic regression example from
Section 3.5.1. It can be seen that, even for a batch size ğ‘š = 100, which is
muchlessthanthesize ğ‘ = 104 ofthedataset,thestochastickernelStein
discrepancyiscapableofprovidingsimilarinformationontheperformance
of the sampler compared to when larger batch sizes, such as ğ‘š = 103 are
used.Thepredictabledecreaseofthediscrepancyindicatesthattheintrinsic
bias of stochastic gradient Langevin dynamics is negligible relative to the
errorincurredbyusingonlyğ‘›ofthesesamplestoconstruct ğœˆ ğ‘›.Neverthe-
less,atthetimeofwriting,thereremainsscopetoimprovethesestochastic
discrepancies,notleastthroughtheuseofreduced-variancestochasticap-
proximationstothegradient.
6.3 OptimalWeightsforMCMC
At this point we have seen how computable discrepancies may be con-
structedandusedtopassivelyassesstheperformanceofMCMC.Nowwe
turn to how such discrepancies might be used to actively improve output
fromMCMC.Specifically,inthissectionweexplorehow,givenarealisa-
tion(xğ‘˜) 1â‰¤ğ‘˜â‰¤ğ‘›ofaMarkovchainandatargetdistributionğœ‹,wemayexploit
thekernelSteindiscrepancytoassignaweightğ‘¤ ğ‘˜toeachxğ‘˜insuchaman-
ner that the discrepancy between the weighted empirical distribution and
ğœ‹ is minimised. This is loosely analogous to importance sampling (c.f.
Section 1.1.5), except here the analogue of the importance distribution is
thedistributionoftheMCMCsamplepathwhich,liketheposterioritself,
is implicitly defined. As such, the methods we will discuss were termed
Black Box Importance Sampling in Liu and Lee (2017). Surprisingly, we
willseethatsuchretrospectivere-weightingcanbeusedtoremovethebias
of approximate sampling algorithms, such as stochastic gradient MCMC
fromChapter3.
Letkğœ‹ : Rğ‘‘ Ã—Rğ‘‘ â†’ Rbeascalar-valuedreproducingkernelforwhich
âˆ« kğœ‹(x,y) dğœ‹(x) =0forally âˆˆ Rğ‘‘;anexamplebeing(6.23).Theweights6.3 OptimalWeightsforMCMC 219
 
  
m=1,000
m=100
 
  
 
  
       
           
 L W H U D W L R Q
Figure6.4 StochasticgradientSteindiscrepancies.Stochastic
gradientLangevindynamicswasusedtogenerateapproximate
samplesfromtheposteriordistributionğœ‹inthelogisticregression
examplefromSection3.5.1,andstochasticgradientStein
discrepancieswereusedtomeasurethediscrepancybetweenthe
empiricaldistributionğœˆ
ğ‘›
oftheapproximatesamplesandğœ‹.Here
ğ‘šindicatesthesizeofthedatasubsetsthatwereusedto
approximatethegradient.
thatweconsiderarethesolutionofthefollowingoptimisationproblem:
ğ‘¤â˜…
wâ˜… :=(cid:169) (cid:173)
(cid:173)
(cid:171)
ğ‘¤. . . â˜…1
ğ‘›
(cid:170) (cid:174)
(cid:174)
(cid:172)
âˆˆ ğ‘¤ğ‘¤a
11
+r ,.g
Â·. Â·. Â·,
+m
ğ‘¤
ğ‘¤ğ‘›i ğ‘›n
â‰¥ =0
1D
kğœ‹
(cid:32) âˆ‘ï¸ ğ‘˜ğ‘› =1ğ‘¤ ğ‘˜ğ›¿ xğ‘˜(cid:33) (6.29)
Letğœˆ ğ‘›bethegeneralweightedempiricaldistributionappearingontheright-
handsideof(6.29).From(6.22)wehaveD kğœ‹(ğœˆ ğ‘›)2 = âŸ¨w,Kğœ‹wâŸ©,whereKğœ‹is
theğ‘›Ã—ğ‘›matrixwithentries[Kğœ‹]
ğ‘–,ğ‘—
=kğœ‹(xğ‘–,xğ‘—).IfthematrixKğœ‹ispositive
definite then wâ˜… is unique and, although not available in closed form, wâ˜…
can be computed by solving a linearly-constrained quadratic optimisation
problemoverthepositiveorthantofRğ‘›.Theoptimallyweighteddistribution
willbedenotedğœˆâ˜…inthesequel.
ğ‘›
A natural first question is whether the weighted approximation to ğœ‹,
)
Î½(
n
Ï€k
D
b220 AssessingandImprovingMCMC
obtained by retrospectively assigning weights to output from MCMC, is
consistent. This turns out to be true, under appropriate assumptions, and
moreover,optimalweightscanprovidebiascorrectioninsettingswherethe
Markov chain is not ğœ‹-invariant. Indeed, the recent work of Riabiz et al.
(2022) established that, in the case of a ğœ‡-invariant, time-homogeneous,
ergodicMarkovchain(Xğ‘˜)
ğ‘˜âˆˆN
âŠ‚ Rğ‘‘,thentheexistenceofcertainmoments
oftheratioğœ‹/ğœ‡canbeusedtodeducethat
(cid:32) ğ‘› (cid:33)
âˆ‘ï¸
D ğ‘¤â˜…ğ›¿ â†’0
kğœ‹ ğ‘˜ Xğ‘˜
ğ‘˜=1
almost surely as ğ‘› â†’ âˆ. Importantly, the biased target ğœ‡ of the Markov
chain(Xğ‘˜) ğ‘˜âˆˆNdoesnotneedtobeknowntoperformBlackBoxImportance
Samplingin(6.29).
Itcansometimesbeconvenienttorelaxthenon-negativityconstraint,to
consider
ğ‘¤â˜…
w (cid:101)â˜… :=(cid:169) (cid:173)
(cid:173)
(cid:171)
ğ‘¤
(cid:101)(cid:101) . . . â˜…1
ğ‘›
(cid:170) (cid:174)
(cid:174)
(cid:172)
âˆˆ ğ‘¤a 1+r wg
Â·Â·âˆˆ
Â·+m
R
ğ‘¤ğ‘›i ğ‘›n =1D
kğœ‹
(cid:32) âˆ‘ï¸ ğ‘˜ğ‘› =1ğ‘¤ ğ‘˜ğ›¿ xğ‘˜(cid:33) . (6.30)
The weights wâ˜… may be negative, and thus the associated ğœˆËœâ˜… is a signed
(cid:101) ğ‘›
measureingeneral.Signedmeasuresmaynotposeaproblemifthegoalof
computationistoapproximateposteriorexpectationsofinterest,butifthe
goalistoapproximateğœ‹itselfthenaproperprobabilitydistributionmaybe
preferred.Themainadvantageoftheformulationin(6.30)isthat,provided
Kğœ‹ â‰» 0,therelaxedoptimisationproblemhasauniqueandexplicitsolution
Kâˆ’11
wâ˜… = ğœ‹ . (6.31)
(cid:101) 1âŠ¤Kâˆ’11
ğœ‹
This formulation is closely related to kernel cubature (also known as
Bayesianquadrature),andspecificallycoincideswiththenormalisedkernel
cubatureofKarvonenetal.(2018).From(6.31),wededucethatthecompu-
tationalcomplexityofobtainingoptimalweightsisingeneralğ‘‚(ğ‘›3).This
canprecludetheuseofoptimalweightsondesktopcomputationalhardware
whenğ‘› islargerthanafewthousand.However,wewillseeinSection6.4
howaccuratesparseapproximationstotheoptimallyweighteddistribution
canbeefficientlyconstructed.
Todemonstratetheeffectofre-weighting,considerthefollowingRosen-
brocktarget
ğœ‹(ğ‘¥,ğ‘¦) âˆexp(âˆ’(ğ‘¥âˆ’ğ‘)2âˆ’ğ‘(ğ‘¦âˆ’ğ‘¥2)2)6.3 OptimalWeightsforMCMC 221
where here we take ğ‘ = 0, ğ‘ = 3. The distribution ğœ‹ might be referred to
as a horseshoe distribution, due to the curved shape of its level sets. To
represent output from a biased sampler, we generate sequence (Xğ‘˜) ğ‘˜âˆˆN of
independent samples from ğœˆ = N(0,I 2) and assign a weight ğ‘¤ ğ‘– to each
stateXğ‘– accordingtoeither(6.29)or(6.30).Fortheseexperimentswetook
ğšº = I , ğ›½ = 0.5, and the transformation in (6.28) was applied. Figure 6.5
2
displaysthequalitativepropertiesoftheweightswâ˜…definedby(6.29)(left)
andtheweightswâ˜… definedby(6.30)(right).Inbothcases,itcanbeseen
(cid:101)
thatstatesXğ‘˜forwhichtheprobabilityunderğœ‹islowaretypicallyassigned
a small weight. On the other hand, optimal weights are not independent,
and the over-representation of states in a local region due to Monte Carlo
samplingvariabilityispartiallymitigated.ComparisonofthekernelStein
discrepanciesD (ğœˆâ˜…)andğ· (ğœˆâ˜…)indicatesthatthenon-negativeweights
kğœ‹ ğ‘› kğœ‹ (cid:101)ğ‘›
wâ˜… perform nearly as well as the signed weights wâ˜…, while both sets of
(cid:101)
weightsleadtoasubstantialdecreaseinkernelSteindiscrepancycompared
totheuseof(inconsistent)uniformweightsinthisexperiment.
Of course, in this toy example, one has access to the sampling density
oftheXğ‘˜ andself-normalisedimportancesamplingcouldtriviallybeused.
Thatis,toeachsampleXğ‘˜weassignweightsproportionaltoğœ‹(Xğ‘˜)/ğœˆ(Xğ‘˜),
and we normalise these weights to sum to 1. The performance of self-
normalisedimportancesamplingisdisplayedinthelowerpanelofFigure
6.5,whereitisseentobeinferiortothediscrepancy-basedmethodswhich
we have discussed. Where has this performance gap come from? Well,
inadditiontobiascorrection,thediscrepancy-basedmethodsadditionally
perform variance reduction, in the sense that the random vectors wâ˜… and
wâ˜…eachcontaincomponentsthatarestronglyinter-dependent.Thismeans
(cid:101)
thatifaregionisover-representedwithsamples,thentheoverallweightof
thesesamplescanbecollectivelyreducedtobetterapproximatethetarget
ğœ‹.Incontrast,self-normalisedimportancesamplinghastorelyonthelong-
run frequency of independent sampling to ensure that different regions of
the domain are assigned an equal amount of probability mass, and this
negativelyaffectsitsfinitesampleperformance.
Thesatisfactoryperformanceofoptimalweightsisobservedinsettings
suchasFigure6.5,wherepathologicalbehavioursofkernelSteindiscrep-
ancy (such as blindness to mixing proportions; see Section 6.2.4) are not
encountered. However, outside this setting the use of optimal weights can
fail.Further,ifthekernelSteindiscrepancyhasweakconvergencecontrol
butnotmomentcontrol,thenthereisnoguaranteethatmomentscomputed
usingtheweightedempiricalapproximationsğœˆâ˜…orğœˆâ˜…willbeconvergentin
ğ‘› (cid:101)ğ‘›222 AssessingandImprovingMCMC
w w <0
i i
w >0
fi
f
 
  
     Î½=Î½
n
Î½=Î½
n
  Î½=Î½
   n
 6 H O I  Q R U P D O L V H G  ,  6 
e
     
        
 Q X P E H U  R I  V D P S O H V
Figure6.5 OptimalweightsforMCMC.Samplesfroma
standardGaussiandistributionwereassignedeithertheoptimal
sign-constrainedweightswâ˜…
(left)ortheoptimalunconstrained
weightswâ˜… (right),toobtainconsistentapproximationsğœˆâ˜… andğœˆâ˜…
(cid:101) ğ‘› (cid:101)ğ‘›
respectivelyofthehorseshoedistributionğœ‹(shaded).These
approximationseachdemonstrateconvergenceinthesenseof
kernelSteindiscrepancyasthenumberofsamplesisincreased,
whilethedistributionğœˆoftheoriginalsamplesdoesnotprovidea
consistentapproximationofğœ‹.
theğ‘› â†’âˆlimit.Theseremarksemphasisethatacertaindegreeofcaution
isneededwhenoptimalweightsareemployed.
)Î½(
Ï€k
D6.4 OptimalThinningforMCMC 223
6.4 OptimalThinningforMCMC
Theoutputfromasamplingalgorithmisoftenusedforsubsequentcompu-
tation,forexample,toapproximatetheposteriorexpectationofaquantityof
interest.Inscenarioswherethissubsequentcomputationincursanon-trivial
computationalcost,itisusuallydesirabletoworkwithassmallanumberğ‘›
ofsamplesaspossible,providedthatthesecontinuetoprovideanaccurate
approximation to the posterior target. Standard practice for MCMC is to
retainthesubsetofstatesvisitedalongthesamplepathwhoseindicesare
(ğœ(ğ‘–)) 1â‰¤ğ‘–â‰¤ğ‘š,whereğœ(ğ‘–) = ğ‘+ğ‘ğ‘–,ğ‘isthedurationofaburn-inperiodand
ğ‘isthethinningperiod.However,thisdoesnotdirectlyattempttoarriveat
acompressedrepresentationoftheposteriortarget.Theaimofthissection
is to discuss how one might select indices (ğœ(ğ‘–)) 1â‰¤ğ‘–â‰¤ğ‘š to optimally ap-
proximatethetarget.Indoingso,wewillalsoarriveataconvenientsparse
approximation to the optimally weighted distributions studied in Section
6.3.
Given output (Xğ‘˜) 1â‰¤ğ‘˜â‰¤ğ‘› from a ğœ‹-invariant MCMC algorithm, we aim
toconstructanapproximationğœˆ
ğ‘›,ğ‘š
= ğ‘š1 (cid:205)ğ‘š ğ‘˜=1ğ›¿
Xğœ(ğ‘˜)
toğœ‹,whichwerequire
is sparse, meaning that ğ‘š â‰ª ğ‘›. For concreteness, we consider the setting
wheretheindexsequenceğœ isgreedilydeterminedaccordingto
(cid:32) ğ‘—âˆ’1 (cid:33)
1 1âˆ‘ï¸
ğœ(ğ‘—) âˆˆ argmin D ğ›¿ + ğ›¿
kğœ‹ ğ‘— Xğ‘˜ ğ‘— Xğœ(ğ‘—â€²)
ğ‘˜=1,...,ğ‘›
ğ‘—â€²=1
foreach ğ‘— âˆˆ N.Using(6.22),andignoringtermsthatdonotdependonXğ‘˜,
thegreedyalgorithmisequivalentto
ğœ(ğ‘—) âˆˆ argmin
kğœ‹(Xğ‘˜,Xğ‘˜) +âˆ‘ï¸ğ‘—âˆ’1
kğœ‹(Xğ‘˜,Xğœ‹(ğ‘—â€²))
ğ‘˜=1,...,ğ‘› 2
ğ‘—â€²=1
where,intheeventofatie,itdoesnotmatterhowastateisselected.The
approximation ğœˆ ğ‘›,ğ‘š, under appropriate regularity conditions, converges to
ğœˆâ˜…intheğ‘š â†’âˆlimit;seeTheorem1ofRiabizetal.(2022).Thus,afinite
ğ‘›
runofthisgreedyalgorithmcouldinprinciplebeusedasasparsealternative
tooptimalweightingofstatesfromSection6.3.Further,thecomputational
complexity of this greedy algorithm is ğ‘‚(ğ‘›ğ‘š2), which would improve on
theğ‘‚(ğ‘›3) oftheoptimalweightsfromSection6.3whenğ‘š â‰ª ğ‘›.Buthow
large should ğ‘š be for ğœˆ ğ‘›,ğ‘š to be a sufficiently accurate approximation of
ğœˆâ˜…tobeuseful?Thisquestionwasansweredwithatheoreticalargumentin
ğ‘›
Riabizetal.(2022),whoestablishedthat
D kğœ‹(ğœˆ ğ‘›,ğ‘š)âˆ’D kğœ‹(ğœˆâ˜… ğ‘›) â†’0224 AssessingandImprovingMCMC
almost surely as ğ‘š,ğ‘› â†’ âˆ, under conditions that include requiring ğ‘š to
increaseatleastasfastas(logğ‘›)2/ğ›½ forsomeğ›½ âˆˆ (0,1).Thisisarelatively
mildconstraintonğ‘š,andinthissensetherelativesizeofğ‘šcomparedtoğ‘›
canbesmall.
Toperformanempiricalcomparisonofoptimalweightingandthegreedy
algorithm just described, we return to the Rosenbrock example from Sec-
tion 6.3. Using the same MCMC output, we contrast the approximations
producedusingtheweightswâ˜…withtheapproximationproducedusingthe
greedyalgorithmjustdescribed.Figure6.6demonstratestheconvergence
of the sparse approximation to the optimally weighted approximation as
ğ‘š is increased. This convergence occurs reasonably quickly, suggesting
thatafaster,sparseapproximationmayoftenbepreferredcomparedtothe
weightedapproximationsfromSection6.3.Fortheseexperiments,wetook
ğšº = I , ğ›½ = 0.5, and the transformation in (6.28) was applied. Although
2
inthistoyexample,samplingwasnotacomputationalbottleneck,inmore
challenging examples the use of these greedy algorithms can provide an
automaticmethodtobothidentifyandremoveaninitialburn-inperiod,and
tocompressthesampleroutput.
6.5 ChapterNotes
The development of sophisticated sampling algorithms, including those
described in this book, should be guided by a qualitative assessment of
theirempiricalperformanceoveravarietyofrealisticdistributionaltargets.
The purpose of this Chapter was to demonstrate how one can construct
explicit upper bounds on the â€œclosenessâ€ of the sampler output to the tar-
get.Inparticular,kernelSteindiscrepanciesemergedasacomputationally
convenient performance measure, which can be computed provided that
the gradient of the target log-density can be evaluated pointwise. Except
forscenarioswheretheposteriorcontainsdistanthigh-probabilityregions,
thekernelSteindiscrepancycanprovideanaccurateindicationofsampler
performance. Further, we described two different scenarios in which out-
putfromMCMCcanbeactivelyimprovedusingthesetechniques;optimal
weightingandoptimalthinningofMCMCoutput.
The literature on diagnostic checks for MCMC is almost as old as the
literatureonMCMC.OurbriefdiscussioninSection6.1barelyscratched
thesurfaceofthistopic,andwerefertheinterestedreadertomoredetailed
treatmentssuchasCowlesandCarlin(1996).Theconvergencediagnostics
we presented are due to Gelman and Rubin (1992); Brooks and Gelman
(1998);Gelmanetal.(2014).Thesomewhatarbitrarychoicesofğ›¿ =0.1and6.5 ChapterNotes 225
    Î½=Î½
n,m
 0 D U N R Y  & K D L Q
Î½=Î½
n
 6 H O H F W H G  6 W D W H V
Î½=Î½
n
 
  
       
           
m
Figure6.6 OptimalthinningforMCMC.Asubsetofsizeğ‘šwas
selectedfromthesamplepath(Xğ‘˜) 1â‰¤ğ‘˜â‰¤ğ‘› ofağœ‹-invariantMarkov
chaininsuchawaythatthekernelSteindiscrepancybetweenthe
associatedempiricaldistribution(circles)andğœ‹(shaded)was
greedilyminimised.Theselectedstatesareshownontheleft
panel,whileontherightpanelthekernelSteindiscrepancyofthe
resultingempiricaldistributionğœˆ ğ‘›,ğ‘šisseentoconvergetothatof
theoptimallyweightedempiricaldistributionğœˆâ˜…
thatusesthefull
ğ‘›
Markovchainoutput.Hereğ‘›=103.
ğ›¿ =0.01wereused,respectively,inGelmanetal.(2014);VatsandKnudson
(2021) and Vehtari et al. (2021). Generalisations of these convergence
diagnostics to the case of a multivariate target, and other improvements,
canbefoundine.g.BrooksandGelman(1998);VatsandKnudson(2021);
Vehtarietal.(2021).
Theconstructionofcomputableconvergenceboundshasreceivedlimited
historicalattention,fromauthorsthatincludeMeynetal.(1994);Rosenthal
(1995);RobertsandTweedie(1999);JonesandHobert(2001).Theconver-
genceboundwepresentedinSection6.2wassomewhatnovel,inthesense
thatearlierworkhastendedtomotivateandderivesuchboundsasaconse-
quence of Steinâ€™s method. Introduced in Stein (1972), this technique from
appliedprobabilityhasbeenextensivelyusedtostudyvariousinstancesof
approximationamongrandomvariables.However,thelastdecadehasseen
an explosion of research investigating the computational uses of Steinâ€™s
method, sparked by the formalisation of the Stein discrepancy in Gorham
and Mackey (2015). A myriad of computational applications of Stein dis-
)Î½(
Ï€k
D226 AssessingandImprovingMCMC
crepancies have now been explored, and a recent overview is provided in
Anastasiouetal.(2023).
The use of reproducing kernels led us to a discrepancy that could be
explicitly computed. However, there are some technical challenges asso-
ciated with the use of the resulting kernel Stein discrepancies. First, the
computational complexity of evaluating the kernel Stein discrepancy be-
tween ğœ‹ and a distribution ğœˆ ğ‘› supported on ğ‘› discrete states isğ‘‚(ğ‘›2); c.f.
(6.24).However,thiscomplexitycaninfactbereducedtonear-linearusing
the random features approach developed in Huggins and Mackey (2018),
whose discussion was beyond the scope of this book. Second, one must
ensure that the required properties of the discrepancy hold in the relevant
appliedcontext.Ourdiscussionfocusedonweakconvergencecontrol,but
other relevant properties include separation, meaning that ğ· ğœ‹(ğœˆ) = 0 if
and only if ğœ‹ = ğœˆ, and convergence detection, meaning that ğ· ğœ‹(ğœˆ ğ‘›) â†’ 0
wheneverğœˆ ğ‘› convergestoğœ‹ inanappropriatesensetobespecified.Adis-
crepancyforwhichbothconvergencecontrolandconvergencedetectionare
satisfiedmaybeusedtocompareandselectbetweencompetingsampling
algorithms, as investigated in Gorham and Mackey (2015, 2017). To this
end, a rigorous technical presentation of kernel Stein discrepancies and
theirtheoreticalpropertiescanbefoundinBarpetal.(2022).
The use of isotropic reproducing kernels can lead to a curse of dimen-
sion, meaning that differences between probability distributions become
more difficult to detect as the dimension ğ‘‘ of the state space is increased.
A generalisation that replaces the overdamped Langevin in (6.13) with a
moregeneralclassofğœ‹-invariantdiffusionprocessesonRğ‘‘ wasstudiedin
Gorham et al. (2019), and in the case of kernel Stein discrepancy, this is
equivalenttotheuseofcertainnon-isotropicreproducingkernels,however,
the selection of a suitable diffusion to address the curse of dimension has
notbeenexplored.Inaconstructiveattempttoimprovetheperformanceof
Steindiscrepancyinthehigh-dimensionalcontext,Grathwohletal.(2020)
proposedtosubstitutethereproducingkernelHilbertspaceintheintegral
probabilitymetric(6.8)withthesetoftestfunctionsspannedbyanappro-
priatelydifferentiableparametricneuralnetwork.Suchanapproachtrades
the potentially better detection properties of the discrepancy with both a
lackoftheoreticalguaranteesandtheadditionalcomputationalcomplexity
involved in the adversarial training of a neural network. Further research
willberequiredtounderstandthistrade-offindetail.
Tolimitthescope,wediscussedonlyalgorithmsforoptimalweighting
andoptimalthinning,ineachcaseforprobabilitydistributionsdefinedon
Rğ‘‘.OptimalweightingwasintroducedinLiuandLee(2017)anditscon-6.5 ChapterNotes 227
sistencywasfirstestablishedinHodgkinsonetal.(2020).Optimalthinning
was introduced and analysed in Riabiz et al. (2022), and mini-batching
strategieswereproposedandstudiedtofurtherreducetheğ‘‚(ğ‘›ğ‘š2) costin
Teymuretal.(2021).Bothalgorithmscanbegeneralisedtonon-Euclidean
domains X through the identification of a suitable Markov process on X
withanexplicitgeneratorL ğœ‹;someMarkovprocessessuitablefordiscrete
domains X are described in e.g. Shi et al. (2022). In related work, Fisher
and Oates (2024) demonstrated how consistent approximation using opti-
mal weights and optimal thinning can even be achieved without access to
gradientsofthetarget,providedthatgradientsofasuitableapproximating
distributioncanbeobtained.References
Ahn, Sungjin, Korattikara, Anoop, Liu, Nathan, Rajan, Suju, and Welling, Max.
2015. Large-scale distributed Bayesian matrix factorization using stochastic gra-
dientMCMC. Pages9â€“18of:Proceedingsofthe21thACMSIGKDDinternational
conferenceonknowledgediscoveryanddatamining. ACM.
Aicher,Christopher,Ma,Yi-An,Foti,NicholasJ,andFox,EmilyB.2019. Stochastic
gradient MCMC for state space models. SIAM Journal on Mathematics of Data
Science,1(3),555â€“587.
Aicher, Christopher, Putcha, Srshti, Nemeth, Christopher, Fearnhead, Paul, and Fox,
Emily.2023.StochasticgradientMCMCfornonlinearstatespacemodels.Bayesian
Analysis,1(1),1â€“23.
Anastasiou,Andreas,Barp,Alessandro,Briol,FrancÂ¸ois-Xavier,Ebner,Bruno,Gaunt,
Robert E, Ghaderinezhad, Fatemeh, Gorham, Jackson, Gretton, Arthur, Ley,
Christophe,Liu,Qiang,Mackey,Lester,Oates,ChrisJ.,Reinert,Gesine,andSwan,
Yvik.2023. Steinâ€™smethodmeetscomputationalstatistics:Areviewofsomerecent
developments. StatisticalScience,38(1),120â€“139.
Andrieu, Christophe, Durmus, Alain, NuÂ¨sken, Nikolas, and Roussel, Julien. 2021.
HypocoercivityofpiecewisedeterministicMarkovprocess-MonteCarlo.TheAnnals
ofAppliedProbability,31(5),2478â€“2517.
Baker,Jack,Fearnhead,Paul,Fox,Emily,andNemeth,Christopher.2018. Large-Scale
StochasticSamplingfromtheProbabilitySimplex. Pages6721â€“6731of:Advances
inNeuralInformationProcessingSystems.
Baker,Jack,Fearnhead,Paul,Fox,EmilyB,andNemeth,Christopher.2019. Control
variatesforstochasticgradientMCMC. StatisticsandComputing,29(3),599â€“615.
Bardenet,ReÂ´mi,Doucet,Arnaud,andHolmes,Chris.2014.TowardsscalingupMarkov
chainMonteCarlo:anadaptivesubsamplingapproach. Pages405â€“413of:Interna-
tionalConferenceonMachineLearning(ICML).
Barp,Alessandro,Simon-Gabriel,Carl-Johann,Girolami,Mark,andMackey,Lester.
2022. Targetedseparationandconvergencewithkerneldiscrepancies. In:NeurIPS
2022WorkshoponScore-BasedMethods.
Beck,Amir,andTeboulle,Marc.2003.Mirrordescentandnonlinearprojectedsubgra-
dientmethodsforconvexoptimization.OperationsResearchLetters,31(3),167â€“175.
Bernardo,JoseÂ´M,andSmith,AdrianFM.2009.BayesianTheory.JohnWiley&Sons.
Besag,Julian.1994.Commentsonâ€Representationsofknowledgeincomplexsystemsâ€
byU.GrenanderandM.I.Miller. JournaloftheRoyalStatisticalSocietySeriesB,
56,591â€“592.
229230 References
Beskos,Alex,Roberts,Gareth,andStuart,Andrew.2009. Optimalscalingsforlocal
Metropolis-Hastings chains on non-product targets in high dimensions. Annals of
AppliedProbability,19(3),863â€“898.
Beskos,Alexandros,Pillai,Natesh,Roberts,Gareth,Sanz-Serna,Jesus-Maria,andStu-
art,Andrew.2013. OptimaltuningofthehybridMonteCarloalgorithm. Bernoulli,
19(5A),1501â€“1534.
Bierkens,Joris.2016. Non-reversibleMetropolis-Hastings. StatisticsandComputing,
26(6),1213â€“1228.
Bierkens,Joris,andDuncan,Andrew.2017. Limittheoremsforthezig-zagprocess.
AdvancesinAppliedProbability,49(3),791â€“825.
Bierkens, Joris, and Roberts, Gareth. 2017. A piecewise deterministic scaling limit
of lifted Metropolisâ€“Hastings in the Curieâ€“Weiss model. The Annals of Applied
Probability,27,846â€“882.
Bierkens,Joris,andVerduynLunel,SjoerdM.2022. Spectralanalysisofthezigzag
process. Pages827â€“860of:Annalesdelâ€™InstitutHenriPoincare(B)Probabiliteset
statistiques,vol.58. InstitutHenriPoincareÂ´.
Bierkens,Joris,Bouchard-CoË†teÂ´,Alexandre,Doucet,Arnaud,Duncan,AndrewB,Fearn-
head,Paul,Lienart,Thibaut,Roberts,Gareth,andVollmer,SebastianJ.2018.Piece-
wisedeterministicMarkovprocessesforscalableMonteCarloonrestricteddomains.
Statistics&ProbabilityLetters,136,148â€“154.
Bierkens, Joris, Roberts, Gareth O, and Zitt, Pierre-AndreÂ´. 2019a. Ergodicity of the
zigzagprocess. TheAnnalsofAppliedProbability,29(4),2266â€“2301.
Bierkens,Joris,Fearnhead,Paul,andRoberts,GarethO.2019b. TheZig-Zagprocess
andsuper-efficientsamplingforBayesiananalysisofbigdata. Annalsofstatistics,
47(3),1288â€“1320.
Bierkens,Joris,Grazzi,Sebastiano,Kamatani,Kengo,andRoberts,Gareth.2020. The
boomerangsampler.Pages908â€“918of:InternationalConferenceonMachineLearn-
ing. PMLR.
Bierkens, Joris, Kamatani, Kengo, and Roberts, Gareth O. 2022. High-dimensional
scalinglimitsofpiecewisedeterministicsamplingalgorithms.TheAnnalsofApplied
Probability,32(5),3361â€“3407.
Bierkens,Joris,Kamatani,Kengo,andRoberts,GarethO.2023a. ScalingofPiecewise
DeterministicMonteCarloforAnisotropicTargets.
Bierkens,Joris,Grazzi,Sebastiano,Meulen,Frankvander,andSchauer,Moritz.2023b.
StickyPDMPsamplersforsparseandlocalinferenceproblems. StatisticsandCom-
puting,33(1),8.
Blei,DavidM,Ng,AndrewY,andJordan,MichaelI.2003.Latentdirichletallocation.
JournalofmachineLearningresearch,3(Jan),993â€“1022.
Bou-Rabee,Nawaf,andSanz-Serna,JesuÂ´sMarÂ´Ä±a.2017. RANDOMIZEDHAMILTO-
NIANMONTECARLO. TheAnnalsofAppliedProbability,27(4),2159â€“2194.
Bouchard-CoË†teÂ´, Alexandre, Vollmer, Sebastian J, and Doucet, Arnaud. 2018. The
bouncyparticlesampler:Anonreversiblerejection-freeMarkovchainMonteCarlo
method. JournaloftheAmericanStatisticalAssociation,113(522),855â€“867.
Brooks,StephenP,andGelman,Andrew.1998. Generalmethodsformonitoringcon-
vergenceofiterativesimulations. Journalofcomputationalandgraphicalstatistics,
7(4),434â€“455.References 231
Brooks,Steve,Gelman,Andrew,Jones,Galin,andMeng,Xiao-Li.2011. Handbookof
MarkovchainMonteCarlo. CRCpress.
Brosse,Nicolas,Durmus,Alain,Moulines,EÂ´ric,andPereyra,Marcelo.2017.Sampling
fromalog-concavedistributionwithcompactsupportwithproximalLangevinMonte
Carlo. Pages319â€“342of:Conferenceonlearningtheory. PMLR.
Brosse,Nicolas,Durmus,Alain,andMoulines,EÂ´ric.2018.Thepromisesandpitfallsof
StochasticGradientLangevinDynamics. Pages8278â€“8288of:AdvancesinNeural
InformationProcessingSystems.
Bubeck, SeÂ´bastien, Eldan, Ronen, and Lehec, Joseph. 2018. Sampling from a log-
concavedistributionwithProjectedLangevinMonteCarlo. Discrete&Computa-
tionalGeometry,59(4),757â€“783.
Cabezas,Alberto,Corenflos,Adrien,Lao,Junpeng,andLouf,ReÂ´mi.2024. BlackJAX:
ComposableBayesianinferenceinJAX. arXivpreprintarXiv:2402.10797.
Caflisch,RusselE.1998.MonteCarloandQuasi-MonteCarloMethods.ActaNumerica,
7,1â€“49.
Carmeli,Claudio,DeVito,Ernesto,andToigo,Alessandro.2006.Vectorvaluedrepro-
ducingkernelHilbertspacesofintegrablefunctionsandMercertheorem. Analysis
andApplications,4(04),377â€“408.
Chatterji,Niladri,Flammarion,Nicolas,Ma,Yian,Bartlett,Peter,andJordan,Michael.
2018.OnthetheoryofvariancereductionforstochasticgradientMonteCarlo.Pages
764â€“773of:InternationalConferenceonMachineLearning. PMLR.
Chen,Fang,LovaÂ´sz,LaÂ´szloÂ´,andPak,Igor.1999. LiftingMarkovchainstospeedup
mixing. Pages275â€“281of:Proceedingsofthethirty-firstannualACMsymposium
onTheoryofcomputing.
Chen,Tianqi,Fox,Emily,andGuestrin,Carlos.2014. StochasticgradientHamiltonian
MonteCarlo. Pages1683â€“1691of:InternationalConferenceonMachineLearning.
Chen,WilsonYe,Barp,Alessandro,Briol,FrancÂ¸ois-Xavier,Gorham,Jackson,Girolami,
Mark,Mackey,Lester,andOates,Chris.2019.SteinpointMarkovchainMonteCarlo.
Pages1011â€“1021of:InternationalConferenceonMachineLearning. PMLR.
Chevallier,Augustin,Power,Sam,Wang,AndiQ,andFearnhead,Paul.2021. PDMP
MonteCarlomethodsforpiecewise-smoothdensities. arXiv:2111.05859.
Chevallier, Augustin, Fearnhead, Paul, and Sutton, Matthew. 2023. Reversible jump
PDMPsamplersforvariableselection. JournaloftheAmericanStatisticalAssocia-
tion,118(544),2915â€“2927.
Christensen,OleF.,Roberts,GarethO.,andRosenthal,JeffreyS.2005. ScalingLimits
for the Transient Phase of Local Metropolis-Hastings Algorithms. Journal of the
RoyalStatisticalSociety.SeriesB(StatisticalMethodology),67(2),253â€“268.
Chwialkowski,Kacper,Strathmann,Heiko,andGretton,Arthur.2016. Akerneltestof
goodnessoffit.Pages2606â€“2615of:Internationalconferenceonmachinelearning.
PMLR.
Conway,JohnB.2010. ACourseinFunctionalAnalysis.Secondedn. Springer.
Corbella,Alice,Spencer,SimonEF,andRoberts,GarethO.2022. AutomaticZig-Zag
samplinginpractice. StatisticsandComputing,32(6),107.
Coullon,Jeremie,andNemeth,Christopher.2022. SGMCMCJax:alightweightJAX
library for stochastic gradient Markov chain Monte Carlo algorithms. Journal of
OpenSourceSoftware,7(72),4113.232 References
Coullon, Jeremie, South, Leah, and Nemeth, Christopher. 2023. Efficient and gener-
alizabletuningstrategiesforstochasticgradientMCMC. StatisticsandComputing,
33(3),66.
Cowles,MaryKathryn,andCarlin,BradleyP.1996. MarkovchainMonteCarlocon-
vergence diagnostics: a comparative review. Journal of the American Statistical
Association,91(434),883â€“904.
Cox,John,IngersollJr,JonathanE,andRoss,StephenA.1985. ATheoryoftheTerm
StructureofInterestRates. Econometrica,53(2),385â€“408.
Creutz, Michael. 1988. Global Monte Carlo algorithms for many-fermion systems.
Phys.Rev.D,38(Aug),1228â€“1238.
Dalalyan, Arnak S, and Karagulyan, Avetik. 2019. User-friendly guarantees for the
Langevin Monte Carlo with inaccurate gradient. Stochastic Processes and their
Applications,129(12),5278â€“5311.
Davis,MarkHA.1984. Piecewise-deterministicMarkovprocesses:Ageneralclassof
non-diffusionstochasticmodels. JournaloftheRoyalStatisticalSociety:SeriesB
(Methodological),46(3),353â€“376.
Deligiannidis, George, Bouchard-CoË†teÂ´, Alexandre, and Doucet, Arnaud. 2019. Ex-
ponential ergodicity of the bouncy particle sampler. The Annals of Statistics, 47,
1268â€“1287.
Deligiannidis,George,Paulin,Daniel,Bouchard-CoË†teÂ´,Alexandre,andDoucet,Arnaud.
2021. RandomizedHamiltonianMonteCarloasscalinglimitofthebouncyparticle
sampleranddimension-freeconvergencerates. TheAnnalsofAppliedProbability,
31(6),2612â€“2662.
Diaconis,Persi,Holmes,Susan,andNeal,RadfordM.2000.Analysisofanonreversible
Markovchainsampler. AnnalsofAppliedProbability,10(3),726â€“752.
Doucet,Arnaud,Johansen,AdamM,etal.2009. Atutorialonparticlefilteringand
smoothing:Fifteenyearslater. Handbookofnonlinearfiltering,12(656-704),3.
Duane,Simon,Kennedy,A.D.,Pendleton,BrianJ.,andRoweth,Duncan.1987.Hybrid
MonteCarlo. PhysicsLettersB,195(2),216â€“222.
Dubey, Kumar Avinava, Reddi, Sashank J, Williamson, Sinead A, Poczos, Barnabas,
Smola,AlexanderJ,andXing,EricP.2016. Variancereductioninstochasticgra-
dient Langevin dynamics. Pages 1154â€“1162 of: Advances in Neural Information
ProcessingSystems.
Eberle,Andreas.2016. Reflectioncouplingsandcontractionratesfordiffusions. Prob-
abilitytheoryandrelatedfields,166(3),851â€“886.
Fearnhead,Paul,Bierkens,Joris,Pollock,Murray,Roberts,GarethO,etal.2018.Piece-
wisedeterministicMarkovprocessesforcontinuous-timeMonteCarlo. Statistical
Science,33(3),386â€“412.
Fisher, Matthew, and Oates, Chris J. 2024. Gradient-free kernel Stein discrepancy.
AdvancesinNeuralInformationProcessingSystems,36.
Gamerman,Dani,andLopes,HedibertF.2006. MarkovchainMonteCarlo:stochastic
simulationforBayesianinference. CRCpress.
Gelman,Andrew,andRubin,DonaldB.1992.Inferencefromiterativesimulationusing
multiplesequences. Statisticalscience,7(4),457â€“472.
Gelman, Andrew, Carlin, John B, Stern, Hal S, Dunson, David B, Vehtari, Aki, and
Rubin,DonaldB.2014. BayesianDataAnalysis. Vol.2. CRCpress.References 233
Geyer,CharlesJ.1992. PracticalMarkovchainMonteCarlo. StatisticalScience,7(4),
473â€“483.
Girolami,Mark,andCalderhead,Ben.2011. RiemannmanifoldLangevinandHamil-
tonian Monte Carlo methods. Journal of the Royal Statistical Society: Series B
(StatisticalMethodology),73(2),123â€“214.
Gong,Wenbo,Li,Yingzhen,andHernaÂ´ndez-Lobato,JoseÂ´Miguel.2020.SlicedKernel-
izedSteinDiscrepancy. In:InternationalConferenceonLearningRepresentations.
Gorham, Jackson, and Mackey, Lester. 2015. Measuring sample quality with Steinâ€™s
method. Pages226â€“234of:AdvancesinNeuralInformationProcessingSystems.
Gorham,Jackson,andMackey,Lester.2017. Measuringsamplequalitywithkernels.
Pages1292â€“1301of:Proceedingsofthe34thInternationalConferenceonMachine
Learning. PMLR.
Gorham,Jackson,Duncan,AndrewB,Vollmer,SebastianJ,andMackey,Lester.2019.
Measuringsamplequalitywithdiffusions.TheAnnalsofAppliedProbability,29(5),
2884â€“2928.
Gorham,Jackson,Raj,Anant,andMackey,Lester.2020.StochasticSteindiscrepancies.
AdvancesinNeuralInformationProcessingSystems,33,17931â€“17942.
Grathwohl, Will, Wang, Kuan-Chieh, Jacobsen, JoÂ¨rn-Henrik, Duvenaud, David, and
Zemel, Richard. 2020. Learning the stein discrepancy for training and evaluating
energy-basedmodelswithoutsampling. Pages3732â€“3747of:InternationalConfer-
enceonMachineLearning. PMLR.
Green, Peter J, and Mira, Antonietta. 2001. Delayed rejection in reversible jump
Metropolisâ€“Hastings. Biometrika,88(4),1035â€“1053.
Grenander,Ulf,andMiller,MichaelI.1994. Representationsofknowledgeincomplex
systems. JournaloftheRoyalStatisticalSociety:SeriesB(Methodological),56(4),
549â€“581.
Gustafson,Paul.1998.AguidedwalkMetropolisalgorithm.StatisticsandComputing,
8(4),357â€“364.
Hastings, W Keith. 1970. Monte Carlo sampling methods using Markov chains and
theirapplications. Biometrika,57,97â€“109.
Heidelberger, Philip, and Welch, Peter D. 1981. A Spectral Method for Confidence
IntervalGenerationandRunLengthControlinSimulations.Communicationsofthe
ACM,24(4),233â€“245.
Hodgkinson,Liam,Salomone,Robert,andRoosta,Fred.2020. ThereproducingStein
kernelapproachforpost-hoccorrectedsampling. arXivpreprintarXiv:2001.09266.
Hoffman, Matthew, Radul, Alexey, and Sountsov, Pavel. 2021. An Adaptive-MCMC
SchemeforSettingTrajectoryLengthsinHamiltonianMonteCarlo. Pages3907â€“
3915of:Banerjee,Arindam,andFukumizu,Kenji(eds),ProceedingsofThe24th
International Conference on Artificial Intelligence and Statistics. Proceedings of
MachineLearningResearch,vol.130. PMLR.
Hoffman,MatthewD,andGelman,Andrew.2014.TheNo-U-Turnsampler:adaptively
setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning
Research,15(1),1593â€“1623.
Horowitz,AlanM.1991.AgeneralizedguidedMonteCarloalgorithm.PhysicsLetters
B,268(2),247â€“252.
Hsieh,Ya-Ping,Kavis,Ali,Rolland,Paul,andCevher,Volkan.2018.MirroredLangevin
Dynamics.Pages2883â€“2892of:AdvancesinNeuralInformationProcessingSystems.234 References
Huggins, Jonathan, and Mackey, Lester. 2018. Random feature Stein discrepancies.
AdvancesinNeuralInformationProcessingSystems,31.
Huggins,Jonathan,andZou,James.2017. Quantifyingtheaccuracyofapproximate
diffusionsandMarkovchains.Pages382â€“391of:ArtificialIntelligenceandStatistics.
PMLR.
Johndrow, James E, Pillai, Natesh S, and Smith, Aaron. 2020. No free lunch for
approximateMCMC. arXiv:2010.12514.
Jones,GalinL,andHobert,JamesP.2001.Honestexplorationofintractableprobability
distributionsviaMarkovchainMonteCarlo. StatisticalScience,16(4),312â€“334.
Kamatani,Kengo.2020. RandomwalkMetropolisalgorithminhighdimensionwith
non-Gaussian target distributions. Stochastic Processes and their Applications,
130(1),297â€“327.
Kanagawa,Heishiro,Barp,Alessandro,Simon-Gabriel,Carl-Johann,Gretton,Arthur,
andMackey,Lester.2024. ControllingMomentswithKernelSteinDiscrepancies.
arXivpreprintarXiv:2211.05408v4.
Karvonen,Toni,Oates,ChrisJ,andSarkka,Simo.2018.ABayes-Sardcubaturemethod.
AdvancesinNeuralInformationProcessingSystems,31.
LeCam,Lucien.1986.Asymptoticmethodsinstatisticaldecisiontheory.Springerseries
instatistics. Springer.
Lewis,PAW,andShedler,GeraldS.1979. SimulationofnonhomogeneousPoisson
processesbythinning. NavalResearchLogisticsQuarterly,26(3),403â€“413.
Li,Wenzhe,Ahn,Sungjin,andWelling,Max.2016.ScalableMCMCformixedmember-
shipstochasticblockmodels.Pages723â€“731of:ArtificialIntelligenceandStatistics.
Lindvall,Torgny,andRogers,LCrisG.1986.Couplingofmultidimensionaldiffusions
byreflection. TheAnnalsofProbability,860â€“872.
Liu,Qiang,andLee,Jason.2017. Black-boximportancesampling. Pages952â€“961of:
ArtificialIntelligenceandStatistics. PMLR.
Liu, Qiang, Lee, Jason, and Jordan, Michael. 2016. A kernelized Stein discrepancy
forgoodness-of-fittests. Pages276â€“284of:InternationalConferenceonMachine
Learning. PMLR.
Livingstone,Samuel,andZanella,Giacomo.2022. TheBarkerProposal:Combining
RobustnessandEfficiencyinGradient-BasedMCMC.JournaloftheRoyalStatistical
SocietySeriesB:StatisticalMethodology,84(2),496â€“523.
Ludkin,M,andSherlock,C.2022.Hugandhop:adiscrete-time,nonreversibleMarkov
chainMonteCarloalgorithm. Biometrika,110(2),301â€“318.
Lâ€™Ecuyer,Pierre,andLemieux,Christiane.2002.Recentadvancesinrandomizedquasi-
MonteCarlomethods. In:Dror,Moshe,Lâ€™Ecuyer,Pierre,andSzidarovszky,Ferenc
(eds), Modeling Uncertainty: An Examination of Stochastic Theory, Methods, and
Applications. Springer.
Ma, Yi-An, Chen, Tianqi, and Fox, Emily. 2015. A complete recipe for stochastic
gradientMCMC. Pages2917â€“2925of:AdvancesinNeuralInformationProcessing
Systems.
Ma, Yi-An, Foti, Nicholas J, and Fox, Emily B. 2017. Stochastic gradient MCMC
methodsforhiddenMarkovmodels. Pages2265â€“2274of:InternationalConference
onMachineLearning. PMLR.References 235
Majka,MateuszB,MijatovicÂ´,Aleksandar,andSzpruch, Lukasz.2020.Non-asymptotic
boundsforsamplingalgorithmswithoutlog-concavity.TheAnnalsofAppliedProb-
ability,30(4),1534â€“1581.
Metropolis, Nicholas, Rosenbluth, Arianna W, Rosenbluth, Marshall N, Teller, Au-
gustaH,andTeller,Edward.1953. Equationofstatecalculationsbyfastcomputing
machines. Thejournalofchemicalphysics,21(6),1087â€“1092.
Meyn,SeanP,andTweedie,RichardL.2012. MarkovChainsandStochasticStability.
SpringerScience&BusinessMedia.
Meyn, Sean P, Tweedie, Robert L, et al. 1994. Computable bounds for geometric
convergenceratesofMarkovchains. TheAnnalsofAppliedProbability,4(4),981â€“
1011.
Michel, Manon, Kapfer, Sebastian C, and Krauth, Werner. 2014. Generalized event-
chainMonteCarlo:Constructingrejection-freeglobal-balancealgorithmsfromin-
finitesimalsteps. TheJournalofChemicalPhysics,140(5).
Michel, Manon, Durmus, Alain, and SeÂ´neÂ´cal, SteÂ´phane. 2020. Forward event-chain
Monte Carlo: Fast sampling by randomness control in irreversible Markov chains.
JournalofComputationalandGraphicalStatistics,29(4),689â€“702.
Nagapetyan,Tigran,Duncan,AndrewB,Hasenclever,Leonard,Vollmer,SebastianJ,
Szpruch, Lukasz, and Zygalakis, Konstantinos. 2017. The true cost of stochastic
gradientLangevindynamics. arXiv:1706.02692.
Neal,RadfordM.2003. Slicesampling. TheAnnalsofStatistics,31(3),705â€“767.
Neal,RadfordM.2004. ImprovingasymptoticvarianceofMCMCestimators:Non-
reversiblechainsarebetter. arXivpreprintmath/0407281.
Neal, Radford M. 2011. MCMC using Hamiltonian dynamics. Pages 113â€“162 of:
Brooks,Steve,Gelman,Andrew,Jones,GalinL,andMeng,Xiao-Li(eds),Handbook
ofMarkovchainMonteCarlo. CRCPress.
Nemeth, Christopher, and Fearnhead, Paul. 2021. Stochastic gradient markov chain
montecarlo. JournaloftheAmericanStatisticalAssociation,116(533),433â€“450.
Nemeth,Christopher,andSherlock,Chris.2018.MergingMCMCsubposteriorsthrough
Gaussian-processapproximations. BayesianAnalysis,13(2),507â€“530.
Nemeth, Christopher, Fearnhead, Paul, and Mihaylova, Lyudmila. 2016. Particle ap-
proximationsofthescoreandobservedinformationmatrixforparameterestimation
instateâ€“spacemodelswithlinearcomputationalcost.JournalofComputationaland
GraphicalStatistics,25(4),1138â€“1157.
Norris,JamesR.1998. MarkovChains. CambridgeUniversityPress.
Oates, Chris J, Girolami, Mark, and Chopin, Nicolas. 2017. Control functionals for
MonteCarlointegration.JournaloftheRoyalStatisticalSociety:SeriesB(Statistical
Methodology),79(3),695â€“718.
Oksendal,Bernt.2013. StochasticDifferentialEquations:AnIntroductionwithAppli-
cations. SpringerScience&BusinessMedia.
Pagani,Filippo,Chevallier,Augustin,Power,Sam,House,Thomas,andCotter,Simon.
2020. NuZZ:numericalZig-Zagsamplingforgeneralmodels. arXiv:2003.03636.
Patterson,Sam,andTeh,YeeWhye.2013. StochasticgradientRiemannianLangevin
dynamics on the probability simplex. Pages 3102â€“3110 of: Advances in Neural
InformationProcessingSystems.
Peters, Elias A J F, and de With, G. 2012. Rejection-free Monte Carlo sampling for
generalpotentials. PhysicalReviewE,85(2),026703.236 References
Phillips,DavidB,andSmith,AdrianFM.1996. Bayesianmodelcomparisonviajump
diffusions.Pages215â€“240of:Gilks,WallyR,Richardson,Sylvia,andSpiegelhalter,
David(eds),MarkovchainMonteCarloinpractice. Chapman&Hall,CRC.
Pollock,Murray,Fearnhead,Paul,Johansen,AdamM,andRoberts,GarethO.2020.
Quasi-stationaryMonteCarloandtheScaLEalgorithm.JournaloftheRoyalStatis-
ticalSocietySeriesB:StatisticalMethodology,82(5),1167â€“1221.
Press,WilliamH,Teukolsky,SaulA,Vetterling,WilliamT,andFlannery,BrianP.2007.
NumericalrecipesinC++:Theartofscientificcomputing. CambridgeUniversity
Press.
Putcha,Srshti,Nemeth,Christopher,andFearnhead,Paul.2023. PreferentialSubsam-
plingforStochasticGradientLangevinDynamics.Pages8837â€“8856of:International
ConferenceonArtificialIntelligenceandStatistics. PMLR.
Raginsky,Maxim,Rakhlin,Alexander,andTelgarsky,Matus.2017.Non-convexlearn-
ing via stochastic gradient langevin dynamics: a nonasymptotic analysis. Pages
1674â€“1703of:ConferenceonLearningTheory. PMLR.
Rasmussen,CarlEdward,andWilliams,ChristopherK.I.2005. GaussianProcesses
forMachineLearning. TheMITPress.
Riabiz,Marina,Chen,WilsonYe,Cockayne,Jon,Swietach,Pawel,Niederer,StevenA,
Mackey, Lester, and Oates, Chris J. 2022. Optimal thinning of MCMC output.
Journal of the Royal Statistical Society Series B: Statistical Methodology, 84(4),
1059â€“1081.
Riou-Durand,Lionel,andVogrinc,Jure.2023.MetropolisAdjustedLangevinTrajecto-
ries:arobustalternativetoHamiltonianMonteCarlo.
Ripley,BrianD.2009. StochasticSimulation. JohnWiley&Sons.
Robbins,Herbert,andMonro,Sutton.1951. Astochasticapproximationmethod. The
annalsofmathematicalstatistics,400â€“407.
Robert,ChristianP.2007. TheBayesianChoice:fromDecision-TheoreticFoundations
toComputationalImplementation. Springer.
Robert, Christian P, and Casella, George. 1999. Monte Carlo Statistical Methods.
Springer.
Roberts,GarethO,andRosenthal,JeffreyS.1998. Optimalscalingofdiscreteapprox-
imationstoLangevindiffusions. JournaloftheRoyalStatisticalSociety:SeriesB
(StatisticalMethodology),60(1),255â€“268.
Roberts, Gareth O, and Rosenthal, Jeffrey S. 2001. Optimal scaling for various
Metropolis-Hastingsalgorithms. Statisticalscience,16(4),351â€“367.
Roberts,GarethO,andRosenthal,JeffreyS.2004. GeneralstatespaceMarkovchains
andMCMCalgorithms. ProbabilitySurveys,1,20â€“71.
Roberts,GarethO,andTweedie,RichardL.1996.ExponentialconvergenceofLangevin
distributionsandtheirdiscreteapproximations. Bernoulli,2(4),341â€“363.
Roberts,GarethO,andTweedie,RichardL.1999. Boundsonregenerationtimesand
convergenceratesforMarkovchains. StochasticProcessesandTheirApplications,
80(2),211â€“229.
Roberts,GarethO.,Gelman,Andrew,andGilks,WalterR.1997. Weakconvergence
andoptimalscalingofrandomwalkMetropolisalgorithms. TheAnnalsofApplied
Probability,7,110â€“120.
Rogers,LeonardCG,andWilliams,David.2000a. Diffusions,MarkovProcesses,and
Martingales:Volume1,Foundations. CambridgeUniversityPress.References 237
Rogers,LeonardCG,andWilliams,David.2000b. Diffusions,MarkovProcesses,and
Martingales:Volume2,ItoCalculus. CambridgeUniversityPress.
Rosenthal,JeffreyS.1995. MinorizationconditionsandconvergenceratesforMarkov
chainMonteCarlo. JournaloftheAmericanStatisticalAssociation,90(430),558â€“
566.
Rubinstein,RY,andKroese,DP.2008.SimulationandtheMonteCarloMethod.John
Wiley&Sons.
Scott,StevenL,Blocker,AlexanderW,Bonassi,FernandoV,Chipman,HughA,George,
EdwardI,andMcCulloch,RobertE.2016.Bayesandbigdata:TheconsensusMonte
Carlo algorithm. International Journal of Management Science and Engineering
Management,11(2),78â€“88.
Sherlock,C.,Thiery,A.H.,Roberts,G.O.,andRosenthal,J.R.2015.Ontheefficiency
ofpseudo-marginalrandomwalkMetropolisalgorithms. AnnalsofStatistics,43(1),
238â€“275.
Sherlock, Chris, and Roberts, Gareth. 2009. Optimal scaling of the random walk
Metropolisonellipticallysymmetricunimodaltargets. Bernoulli,15(3),774â€“798.
Sherlock,Chris,andThiery,AlexandreH.2022. Adiscretebouncyparticlesampler.
Biometrika,109(2),335â€“349.
Sherlock,Chris,Urbas,Szymon,andLudkin,Matthew.2023. Theapogeetoapogee
pathsampler.JournalofComputationalandGraphicalStatistics,32(4),1436â€“1446.
Shi,Jiaxin,Zhou,Yuhao,Hwang,Jessica,Titsias,Michalis,andMackey,Lester.2022.
GradientestimationwithdiscreteSteinoperators. Advancesinneuralinformation
processingsystems,35,25829â€“25841.
Sohl-Dickstein,Jascha,Mudigonda,Mayur,andDeWeese,Michael.2014.Hamiltonian
MonteCarlowithoutdetailedbalance. Pages719â€“726of:InternationalConference
onMachineLearning. PMLR.
Stein,Charles.1972. Aboundfortheerrorinthenormalapproximationtothedistri-
butionofasumofdependentrandomvariables. Pages583â€“603of:Proceedingsof
the6thBerkeleySymposiumonMathematicalStatisticsandProbability,Volume2:
ProbabilityTheory,vol.6. UniversityofCaliforniaPress.
Stephens,Matthew.2000.Bayesiananalysisofmixturemodelswithanunknownnumber
ofcomponents-analternativetoreversiblejumpmethods.AnnalsofStatistics,40â€“74.
Sun, Hongwei. 2005. Mercer theorem for RKHS on noncompact sets. Journal of
Complexity,21(3),337â€“349.
Sun,Yi,Schmidhuber,JuÂ¨rgen,andGomez,Faustino.2010. Improvingtheasymptotic
performanceofMarkovchainMonte-Carlobyinsertingvortices. Pages2235â€“2243
of:Lafferty,J.,Williams,C.K.I.,Shawe-Taylor,J.,Zemel,R.S.,andCulotta,A.(eds),
AdvancesinNeuralInformationProcessingSystems,vol.23.
Sutton,Matthew,andFearnhead,Paul.2023. Concave-convexPDMP-basedsampling.
JournalofComputationalandGraphicalStatistics,32(4),1425â€“1435.
Suwa,Hidemaro,andTodo,Synge.2010. MarkovchainMonteCarlomethodwithout
detailedbalance. PhysicalReviewLetters,105(12),120603.
Teh, Yee Whye, Thiery, Alexandre H, and Vollmer, Sebastian J. 2016. Consistency
andfluctuationsforstochasticgradientLangevindynamics.TheJournalofMachine
LearningResearch,17(1),193â€“225.238 References
Teymur, Onur, Gorham, Jackson, Riabiz, Marina, and Oates, Chris. 2021. Optimal
quantisationofprobabilitymeasuresusingmaximummeandiscrepancy.Pages1027â€“
1035of:InternationalConferenceonArtificialIntelligenceandStatistics. PMLR.
Turitsyn, Konstantin S, Chertkov, Michael, and Vucelja, Marija. 2011. Irreversible
MonteCarloalgorithmsforefficientsampling. PhysicaD:NonlinearPhenomena,
240(4-5),410â€“414.
Vanetti,Paul,Bouchard-CoË†teÂ´,Alexandre,Deligiannidis,George,andDoucet,Arnaud.
2017. Piecewise-deterministicMarkovchainMonteCarlo. arXiv:1707.05296.
Vats,Dootika,andKnudson,Christina.2021.RevisitingtheGelmanâ€“Rubindiagnostic.
StatisticalScience,36(4),518â€“529.
Vehtari,Aki,Gelman,Andrew,Simpson,Daniel,Carpenter,Bob,andBuÂ¨rkner,Paul-
Christian.2021. Rank-normalization,folding,andlocalization:Animproved ğ‘…Ë† for
assessingconvergenceofMCMC. BayesianAnalysis,1(1),1â€“28.
von Renesse, Max-K, and Sturm, Karl-Theodor. 2005. Transport inequalities, gradi-
ent estimates, entropy and Ricci curvature. Communications on pure and applied
mathematics,58(7),923â€“940.
Vyner, Callum, Nemeth, Christopher, and Sherlock, Chris. 2023. SwISS: A scalable
MarkovchainMonteCarlodivide-and-conquerstrategy. Stat,12(1),e523.
Welling,Max,andTeh,YeeW.2011.BayesianlearningviastochasticgradientLangevin
dynamics. Pages681â€“688of:Proceedingsofthe28thInternationalConferenceon
MachineLearning(ICML-11).
Wenliang, Li K, and Kanagawa, Heishiro. 2021. Blindness of score-based methods
to isolated components and mixing proportions. In: Proceedings of the NeurIPS
Workshopâ€œYourModelisWrong:RobustnessandMisspecificationinProbabilistic
Modelingâ€â€™.
Wu, Changye, and Robert, Christian P. 2017. Generalized bouncy particle sampler.
arXiv:1706.04781.
Wu, Changye, and Robert, Christian P. 2020. Coordinate sampler: a non-reversible
Gibbs-likeMCMCsampler. StatisticsandComputing,30(3),721â€“730.
Xifara,T.,Sherlock,C.,Livingstone,S.,Byrne,S.,andGirolami,M.2014. Langevin
diffusionsandtheMetropolis-adjustedLangevinalgorithm. Statistics&Probability
Letters,91,14â€“19.