SIMS: Simulating Human-Scene Interactions with Real World Script Planning
WenjiaWang1 LiangPan1,2 ZhiyangDou1 ZhouyingchengLiao1
YukeLou1 LeiYang2 JingboWang2‚Ä† TakuKomura1‚Ä† ;
1TheUniversityofHongKong 2ShanghaiAILaboratory
loco/getup
sitdown
liedown
reach
Figure1.Ourframeworkenablesphysicallysimulatedcharacterstoperformlong-termdailynarrativesindiverseandcomplex3Dscenes
conditionedonbothlanguageandsceneinputs. Ourcharactercouldperformversatileskillssuchaswalking,sitting,lying,andreaching
skillswithdiversestyleswhileaccomplishingphysical-plausiblecontactsandobstacleavoidance. Left: bedroomandlivingroom. Right:
diningroom,studyroom,andlivingroom.
Abstract clips from existing kinematic datasets to enable our policy
learndiverseskills. Extensiveexperimentsdemonstratethe
Simulating long-term human-scene interaction is a chal- effectiveness of our framework in versatile task execution
lengingyetfascinatingtask. Previousworkshavenoteffec- anditsgeneralizationabilitytovariousscenarios,showing
tively addressed the generation of long-term human scene remarkablyenhancedperformancecomparedwithexisting
interactionswithdetailednarrativesforphysics-basedan- methods.Ourcodeanddatawillbepubliclyavailablesoon.
imation. This paper introduces a novel framework for the
planning and controlling of long-horizon physical plausi-
ble human-scene interaction. On the one hand, films and
showswithstylishhumanlocomotionsorinteractionswith 1.Introduction
scenesareabundantlyavailableontheinternet,providinga
richsourceofdataforscriptplanning. Ontheotherhand, Creating virtual characters with diverse motor skills such
LargeLanguageModels(LLMs)canunderstandandgener- aswalking,sitting,reaching,andenablingrichinteractions
atelogicalstorylines.Thismotivatesustomarrythetwoby withtheirenvironmentsindailylivingscenarios,iscrucial
usinganLLM-basedpipelinetoextractscriptsfromvideos, forroboticsandVR/ARapplications. Especially,depicting
and then employ LLMs to imitate and create new scripts, humans in daily indoor actions is central to animation and
capturingcomplex,time-serieshumanbehaviorsandinter- 3D games, requiring long-term, physically plausible, and
actions with environments. By leveraging this, we utilize controllable interactions with diverse styles and details to
a dual-aware policy that achieves both language compre- bringcharactersandstoriestolife.
hension and scene understanding to guide character mo- Previousworks[12,27,33,36,44]havethoroughlyex-
tions within contextual and spatial constraints. To facili- ploredlong-termmotiongenerationforhuman-sceneinter-
tatetrainingandevaluation,wecontributeacomprehensive actionsinkinematicsrepresentation. However,thesemod-
planning dataset containing diverse motion sequences ex- els still suffer from physical artifacts such as surface pen-
tractedfromreal-worldvideosandexpandthemwithlarge etration and foot skating. To address these issues, recent
language models. We also collect and re-annotate motion studies[13,19,39]havestartedincorporatingphysicssim-
ulators[17]toproducemorephysicallyplausiblemotions.
*‚Ä†:equalmentorship. Despite these advancements, the frameworks are still re-
4202
voN
92
]VC.sc[
1v12991.1142:viXrastrictedtointeractionswithasmallnumberofspecifictask ingalsofollowsthisstrategy.
objectives, as policies trained with reinforcement learning 3. We propose a dual-aware control policy that can per-
inagreedymannersufferfromconstrainedmodelingcapac- ceive the scene information and language descriptions
ities. Moreover, their planning approaches are often sim- from the keyframes. During inference, the finite state
plistic,followingchronologicallists[19]orfocusingsolely machinecouldperformlonghorizontalskillswiththese
oncontacts[39]. Thisstandsincontrasttoreal-worldsitu- twoconditions.
ations where body language in human motion and interac- 4. Concerning datasets, our re-arranged motion clips with
tions directly convey a large number of emotional states. detailed captions, and emotional labels and our short
For example, a person sitting on a chair with their head scriptdatabasecouldserveforstylishinteractiontasks.
down and supporting it with their hands often appears de-
pressed. Whilerecentstudies[16,28]haveexploredusing
text conditions to control humanoid actions such as track- 2.RelatedWorks
ingorstrikingbasedonnaturallanguage,theyfallshortin
modelinginteractionsbetweenhumansandscenes. 2.1.Kinematic-basedHumanSceneInteraction
To address these challenges, we propose a comprehen-
sive framework terms SIMS, (SIMultating huMan Scene Synthesizing realistic human behavior has been a long-
standing challenge. While most methods enhance the
interactions). SIMS utilizes LLMs as high-level planners
quality and diversity of humanoid movements [14, 30‚Äì
and physical policies as low-level controllers. Unlike pre-
32, 42, 45], they often overlook scene interactions. Re-
vious work [39] that relies solely on LLMs for planning,
cently, there‚Äôs been growing interest in integrating human-
ourapproachintegratesreal-worldvideosandthecombined
sceneinteractions,crucialforapplicationslikeembodiedAI
knowledgeofVision-LanguageModels(VLM)andLLMs
and virtual reality. Many previous approaches [12, 15, 27,
to enhance planning during human-scene interaction. To
33,36,37,41,43,44]relyondata-drivenkinematicmod-
avoid repetitive generation by LLMs, we first extract in-
els [7, 10, 29, 34, 35] for static or dynamic interactions.
teractions and emotional changes from real-world videos,
However,theseoftenlackphysicalplausibility,resultingin
compiling them into a short script database. Each short
artifacts like penetration, floating, and sliding, and require
script includes several keyframes, with each keyframe de-
additionalpost-processing,limitingreal-timeuse.
tailing stylish interactions that our control policy can ex-
ecute. We then prompt the LLM to retrieve and combine
these short scripts into long-term scripts based on user-
2.2.Physics-basedHuman-SceneInteraction
providedstorythemes. Wealsostructuralizethe3Dscene
layoutdataintographdataandusegrapheditdistancetore-
Whilepreviousphysics-basedanimationapproachesmainly
trievethemostsuitable3dscenelayout,whichcouldensure
focused on human motion alone [5, 6, 21, 22, 24]. Inter-
thepracticalityofinteraction. Oncewehavethekeyframes,
Phys[13]presentsaframeworkextendingAMPtoinclude
we employ a low-level control policy to execute the de-
character and object dynamics, using a scene-conditioned
tailsineachkeyframe,producingnatural,diverse,andhigh-
discriminator for superior performance compared to pre-
qualityinteractions.Toensurestylishmotionsareadaptable
vious methods. Additionally, InterScene [19] effectively
to various furniture shapes within a complex indoor envi-
synthesizes physically plausible long-term human motions
ronment, we propose a dual-aware control policy, where
in complex 3D scenes by decomposing interactions into
thispolicyisattunedtobothscenegeometriesandtextem-
Interacting and Navigating processes. This method uses
beddings from the CLIP model [25] for high-fidelity mo-
reusablecontrollerstrainedinsimpleenvironmentstogen-
tion generation. We further employ a finite state machine
eralize across diverse scenarios. With the development of
structuretomanagemultiplepoliciesbasedonthespecified
LLMs, UniHSI [39] introduces a unified framework for
keyframes,producingsynthesizedphysics-basedanimation
human-object interaction via language commands, featur-
thatalignswithreal-worlddistributions.
inganLLMPlannerandUnifiedController,whichreduces
Ourcontributionscouldbesummarizedas traininglaborwithLLM-generatedplans.Theeffectiveness
1. We propose a comprehensive framework that enables of this approach is evaluated using the ScenePlan dataset.
physicallysimulatedcharacterstoperformlong-termin- In the realm of humanoid robotics, HumanVLA [40] ad-
teraction tasks with expressive styles in diverse, clut- vances the field with a vision-language-action model that
tered,andunseen3Dscenes. leverages egocentric vision and natural language. Further-
2. Our script planner uses a divide-and-conquer strategy, more,PlaMo[11]combinesscene-awarepathplanningand
whichenablesmorecontrollableandpracticablemotion motioncontrolinphysicalsimulations,efficientlyplanning
synthesisquality. ThuswecouldavoidtheLLM‚Äôsshort- long-horizonpathsforhumanoidsandensuringnavigation
comingofrepeatedgeneration. Ourscenegraphmatch- acrossuneventerrains.
22.3.LanguageConditionedHumanoidControl actiona ‚àà A, sampledfromthepolicy a ‚àº œÄ(a |s ,g).
t t t t
After executing the action a , the environment transitions
The HumanVLA[40] model enables physical humanoids t
to a new state s , and the agent receives a scalar reward
to interpret visual and language inputs to perform tasks. t+1
r = r(s ,a ,s ,g) that reflects the desirability of the
It employs behavior cloning to replicate advanced learn- t t t t+1
statetransitionforthegivengoalg.Theagent‚Äôsobjectiveis
ing techniques and is enhanced by a novel active render-
to learn a policy œÄ that maximizes its expected discounted
ingmethodforimprovedperception. TrainedintheIsaac-
returnJ(œÄ),
Gym [17] with the Human-in-the-Room (HITR) dataset,
thismodeldemonstrateseffectiveobjectrearrangementca-
(cid:34)T‚àí1 (cid:35)
pabilities in diverse environments. UniHSI[39] is a novel J(œÄ)=E E (cid:88) Œ≥tr , (1)
p(g) p(œÑ|œÄ,g) t
unified Human-System Interaction framework that trans-
t=0
lateslanguagecommandsintointeractivetasksusingalarge
T‚àí1
languagemodelplannerandaunifiedcontroller. Thissys- (cid:89)
p(œÑ|œÄ,g)=p(s ) p(s |s ,a )œÄ(a |s ,g). (2)
0 t+1 t t t t
tem effectively executes detailed task plans without exten-
t=0
sive interaction annotations, demonstrating robust control
andadaptabilityinvariousscenariosastestedontheScene- where p(œÑ|œÄ,g) denotes the likelihood of a trajectory
Plandataset. However,theirchain-of-contactdesigncould œÑ = (s ,a ,s ,...,s ) under a policy œÄ given a goal g,
0 0 1 T
notmodelthediversemotionswithemotionaldetails. [28] p(s0) is the initial state distribution, and p(st+1|s ,a )
t t
introduces a method for controlling humanoid robots us- represents the transition dynamics of the environment. T
ingalargelanguagemodel(LLM)refinedwithaCLIPtext is the time horizon of a trajectory, and Œ≥ ‚àà [0,1] is a dis-
encoder and codebook-based vector quantization. The ap-
countfactor.
proachensuresprecise,actionableinstructionsaredelivered
torobots, simplifyingcontrolwithasinglepolicynetwork 3.2.ScriptPlanning
thatusesspecializedrewardsforaccuratemovement. This
innovation enhances the system‚Äôs ability to handle diverse Creatinglong-termscriptswithLLMsischallengingdueto
and unseen instructions, streamlining robotic task execu- potentialredundancyandlackofguidance.Previousworks,
tion. PADL[16]usesnaturallanguagecommandstocontrol like[39],focusongeneratinglimitedkeyframeswithnodi-
characters, mapping high-level tasks to low-level actions verse styles. We discovered that real-world films and TV
through adversarial imitation learning, effectively guiding shows contain fascinating scripts featuring characters nav-
simulatedhumanoidsincomplexskills. igatingdailylifestoriesinvariousmoods(SeeFig.3). To
leveragetheserichresources,weuseanLLM-basedframe-
3.Method work that extracts character emotions, object types, and
contact details from online videos, capturing diverse inter-
We propose a hierarchical framework utilizing LLMs as actions and summarizing story outlines. Using available
high-levelscriptplanners,anddeepreinforcementlearning- human motions and furniture types, we prompt the LLM
basedcontrolpoliciesaslow-levelcharactercontrollers. to generate short scripts that imitate human-made master-
InSec.3.1,weintroducethefundamentalsofreinforce- pieces.Eachscriptcompriseskeyframesdefinedbyspecific
ment learning. Sec. 3.2 details our method for extracting emotions, interactions, and summaries, forming a diverse
short scripts from online video clips and generating new database. The LLM retrieves from this database based on
ones. WethenuseLLMstoretrieveandintegratetheseinto user-provided themes, considering the summaries, and ar-
longerscripts. InSec.3.3,weexplainineachskill,howhu- ranges them chronologically. This approach crafts a long
manoidsarecontrolledusingscene-awareobservationsand storyfrommultipleshortscripts,eachwithdistinctinterac-
language-awareembeddings.Finally,Sec.3.4describesour tions or styles. The keyframes from retrieved short scripts
dual-awarefinitestatemachine,whichdriveshumanoidsby formulateasthelong-horizontalstory. Eachkeyframepro-
multiple skill policies, conditioned on time-series contact duces a set of outputs {c,g,o}, representing the caption,
goals,environmentstates,andtextconditions. goal,andobject,whicharesubsequentlyusedinthepolicy.
The policy drives the humanoid using {z,g,h }, where z
3.1.Preliminary t
denotes the text embedding derived from c, g represents
Our characters are trained using a goal-conditioned rein- theobjectcontactgoal, andh t istheheightmapcomputed
forcement learning framework, where an agent interacts basedonthesurroundingobjects,pleaseseeSec.3.3forde-
with an environment according to a control policy œÄ to tail. Wethenretrievearoomlayoutfromthedatabasethat
achieve a specified goal g ‚àà G, drawn from a goal distri- could satisfy the interaction types. Finally, the LLM syn-
bution g ‚àº p(g). At each time step t, the agent observes thesizesthesesummarieswiththeuser‚Äôsprompttocreatea
the environment‚Äôs state s ‚àà S and responds by taking an cohesivenarrative.
t
3(a) Short Script Generation (b) Long-Term Script Matching
Please generate a script following this theme: ‚ÄúTom
Summaries: Ross goes back home comes back home happily. He rests on the sofa and then
and talk to friends. goes to dinning room for a drink. He then walks
Keyfr {eam moes t: i o[ n: relaxed, drunkenly in the living room.‚Äù Retrieve the short scripts
object: sofa, from the summary list and give me the final story.
contact: lhand-armrest,
Online Videos Extract Details r wh ia tn hd c - a aa p rr t mm i sr o e n os p:t e. s ni }]t on the sofa Script GenT eh rae t w ioh no ble y LLM Retrieve
Script Generation by LLM Available Skills & Objects ‚Äòwalk‚Äô Keyframes ‚Äòwalk‚Äô Final Story
This template script focuses on the ‚Äò ce ox nc ti at ce td‚Äô ‚Ä¶ ‚Äò cd or nu tn ak c‚Äô t T vih ve id w lyh do ele p is ct to s r ay
e inm teo rt aio cn
ti
oo nf { ae nm do eti mon o} t.
i
oF no all lo sw
h
ii ft ts
s to
C oa bp jt ei co tn Time C oa bp jt ei co tn c ish ‚Ä¶aracter who
create a short scriptwith {num_kf}
keyframes set in a {room_type}. The
script should include a summary and (c) Scene Graph Matching
several keyframes, each containing # annotation
the following elements: emotion, skill: sit/lie/loco/touch
contact, object, and caption. The e cm oo nt ti ao cn t: : s ja od i/ ne tx -c pait re td
a av va ai il la ab bl le e s fuk ril nls it a ur re e { insk ci ll uls d} ea sn {d o bth jee c ts}. c oa bp jt ei co tn :: s. t. o. ol/chair/sofa/bed merge GEDR
Generated Scripts with Diverse Emotions Sub-Layouts from Short Scripts
# Script of emotion happy. # Script of emotion angry. (d) Finite state Machine
Summaries: The person is Summaries: The person is ...
resting in living room Keyframes: [
Keyf {r ea mm oe ts i: o n[ : happy, ‚Ä¶ ... ùíâ ‚Ä¶ ùíâ ‚Ä¶ ùíâ loco/getup
object: armchair, sitdown
contact: lhand-armrest. # Script of emotion sad. Policies: actions
chaic ra p wt ii to hn : l egs si t c ro on s st eh de }, S Ku em ym fa rr ai me es s: : [The person is ... ‚Ä¶ ‚Ä¶ liedown
...] ... ùíõ ùíõ ùíõ
reach
Figure2. Ourmainpipeline. (a)ShortScriptGeneration. WeuseaLLM-basedpipelinetoextractkeyframeinformationfromonline
videoclips,andpromptLLMstogeneratenewshortscriptsfollowingtheiremotionandinteractionlogic.(b)Long-TermScriptMatching.
WeaskLLMtoretrieveshortscriptsfromthedatabaseandconcatenatethemasafluentlong-termstory. (c)SceneGraphMatching. We
mergethesub-graphsfromshortscriptsintoalargeoneandusegrapheditdistance(GED)toretrievethemostmatchedroomlayout. (d)
FiniteStateMachine. Thecaptions,contactdetails,andscenegeometryfromeachkeyframewillbeparsedintotaskgoalsandlanguage
embeddingstodrivethelow-levelphysicalcontrolpolicy(Seethesimulationenvironmentontheright).
Short Script Generation To comprehensively analyze a 1 Summary: Rachel cleaned the 4
house in advanceand
videoclip,wefirstextractaframeevery10framesandin- welcomes friends back home. 4
puttheseintoaVision-LanguageModel(GPT4-v)[1]. The KF-1: Run with arms open. Excited.
VLMisqueriedtoidentifycharacteractionsandobjectcat- KF-2: Stand and talk. Neutral.
egorieswithineachframe,whilerecordingthecorrespond- 1 2 KF-3: Run with jum ‚Ä¶ping steps. Excited. 5 5
ing timestamps. Simultaneously, the audio from the clip K knF- e6 e: s S . i Nt eo un t t rh ae l. sofa with hands on
is transcribed into text [9]. This initial set of keyframes, KF-7: Walk with big steps. Relaxed.
together with the transcribed audio, is then processed by 2
Summary: Ross goes back 6 6
a Language Model (GPT4-o) [1]. The LLM analyzes the h seo em te h ew rit oh o t mh e c lf er aie nn ed ds . and
narrativestructureandidentifieswhichframesserveascrit- KF-1: Stand and talk. Neutral.
icaljuncturesinthestory. Oncekeyframesareselected,the KF-2: Walktothesofa.Neutral.
3 3 KF-3: Walktothesofa.Neutral. 7
modelevaluatestheemotionsofthecharactersandensures 7
KF-4: Sit on thesofa with arms open.
thecontinuityofactionsbetweentheseframes,contributing Relaxed. ‚Ä¶
KF-7: Sit on thetable with arms crossed.
totheoverallnarrativecoherence. Thoughtful.
Buildingonthisanalysis,weutilizeourrepositoryofhu-
Figure3. ShortScriptextractedfromonlinevideos. Consistsof
manmotionsandfurnituretypestogeneratenumerousshort
summariesbrieflydescribethecharacters‚Äôactionsandkeyframes
scripts. Eachshortscriptiscraftedfromseveralkeyframes, describethecharacter‚Äôsemotionandinteractions.
eachcharacterizedbyspecificemotions,interactions,furni-
ture types, and concise summaries. This method results in
a diverse array of short scripts, each containing unique se- Long-Term Script Matching To enhance long-term
manticinformation. Thesescriptsarecompiledintoacom- script generation, we utilize an LLM to retrieve and build
prehensivedatabase.Thisintegratedapproachnotonlyaids upon previously generated short scripts, based on user-
inunderstandingandinterpretingthevideocontentbutalso providedstorythemes. WeprovidetheLLMwiththesum-
facilitates the generation of rich, varied narratives that can mariesandemotionsfromeachshortscriptandaskittose-
beusedforfurtherstorytellingapplications. lect and arrange these scripts in a chronological sequence.
4This method enables the creation of a comprehensive long 3.3.Dual-AwareControlPolicy
story, composed of multiple short scripts, each featuring a
Once we have well-planned time-series keyframes and a
unique interaction of stylistic elements. By synthesizing
3D scene, we need to use them to guide the humanoid to
these short script summaries with the user‚Äôs input prompt,
perform the long-term interactions. We next need to train
theLLMconstructsacohesivelong-termnarrative.Thisen-
control policies that enable a physically simulated charac-
suresaconsistentthematicandemotionalflowwhileallow-
ter to perform various high-level tasks in 3D scenes speci-
ingforcreativediversityanddepth. Theintegrationofdis-
fiedbylanguagecommands. Ateachtimestept,thepolicy
tinctinteractionsandstylesenrichesthenarrative,makingit
œÄ(a |s ,h ,g,z)receivesasinputthestateofthecharacter
moreengaginganddynamic. Finally,weextractkeyframes t t t
s ,aegocentricheightmaph ,atask-specificgoalg,anda
from the short scripts, concatenate them, and use them to t t
languageembeddingz. Thegoalgspecifieshigh-leveltask
guideourlow-levelcontrolpolicy.
objectives that the character should achieve, such as mov-
ingtoatargetlocationorcontactingacertainobject.Theh
t
istheegocentricheightmapnearthecharacter,representing
SceneGraphMatching Ineachshortscript,thelayoutof the surrounding environment. The language embedding z
objects is represented as an undirected, unweighted graph. specifies the style that the character should use to achieve
When concatenating these scripts into a long-term layout, the desired goal, such as walking excitedly or sitting with
we need to merge the sub-layouts into a new configura- legs crossed. In order to train a policy to perform a given
tion that includes all necessary objects while maintaining taskusingadesiredskill,weutilizearewardfunctioncon-
apracticalroomdesign. Ouroperationsconsistsof3main sisting of two components: r t = r tskill +Œªtaskr ttask, where
steps.(1). NodeCategorization:Eachfurnitureitemisiden- rskill isaskill-reward,andrtask isatask-rewardwithcoeffi-
t t
tifiedbyacategoryandinstanceindex,e.g.,(c,i),wherethe cientŒªtask.
firstnumberrepresentsthecategoryandthesecondthein-
stance. (2)EdgeIntegration: Integrateallconnectionsfrom Language-AwareEmbedding Tocontrolthepolicylan-
theinputgraphsintothemergedgraph.Bytreatingedgesas guageconstraints,weaimtoconstructanembeddingspace
undirected,weeliminateredundancywhileoptimizingcon- fed into the policy network, where the embedding aligns
nections. Thismethodensuresthe preservationoforiginal motionrepresentationwiththeircorrespondingnaturallan-
connections while minimizing node duplication, achieving guagedescriptions. Todothis,wefollow[16,30],wherea
an optimal balance between connectivity and node count. transformer auto-encoder is trained to encode motion se-
(3) Greedy Node Consolidation: We determine the maxi- quences into a latent representation that aligns with the
mum number of instances needed for each furniture cate- languageembeddingfromapre-trainedCLIPtextencoder
gory across all scripts. This informs the creation of a uni- [25]. GivenamotionclipmÀÜ = (qÀÜ ,...,qÀÜ ),amotionen-
1 n
fiednodesetthatadequatelyrepresentseachcategory. We coder z = Enc (mÀÜ) maps the motion to an embedding
m
then organize the room layouts from the large room lay- z. The embedding is normalized to lie on a unit sphere
outdataset3DFront[8]intoundirected,unweightedgraphs. ‚à•z‚à• = 1. We set the embedding size z to 64 to save the
Thenodesrepresentfurnitureitems. Anedgeisestablished computation cost. For the text embedding, we first extract
betweentwoobjectsiftheyarewithinaspecifieddistance the feature with CLIP Encoder [25] Enc from caption c,
l
andnotobstructedbyotheritems.Objectswithminimalin- thenuseamultilayerperceptionMLP todownsizethe512
d
teractionpossibilities,suchaslampsorvases,aremarkedas dim CLIP feature to 64 dim and use an extra one MLP
u
lessimportantnodes. GraphEditDistance[26]isametric to upsample it to 512 dim to maintain the semantic fea-
usedtomeasurethesimilaritybetweentwographs. Weuse ture. The embedding z should be aligned with the down-
asimplifiedGEDretrieval(GEDR)tofindthemostsimilar sizedCLIPfeature. Following[30],Enc (m)ismodeled
m
scenesfromthe3DFront[8]dataset. Ifnosuitablelayoutis by a bidirectional transformer [4]. The motion decoder is
found,weemployafault-tolerantstrategy,groupinghighly jointlytrainedwiththeencodertoproduceareconstruction
substitutable objects into the same class. E.g, we can re- sequence m = (q ,...,q ) to recover mÀÜ from z. The
1 n
placeastoolwithachair,oradoublebedwithasinglebed. motion representation q we use is a set of character mo-
We also provide random combinations of different type of tion features, following the discriminator observation used
rooms (see in Fig. 1) among the four room types: bed- inAMP[22]. Theauto-encoderistrainedwiththeloss:
room,livingroom,diningroom,andlibrary(studyroom)in
3DFront, to ensure the Human-Scene Interaction in com- L =Lm +Lm,t +Lt . (3)
AE recon align recon
plex and realistic house life simulation. These techniques
exhibit significant efficiency and scalability, making them ThereconstructionlossLm measurestheMSEerrorbe-
recon
ideal for integrating diverse furniture data from multiple tweenthereconstructedsequenceandoriginalmotion. The
scripts. alignmentlossLm,t measuresthecosinedistancebetween
align
5Language Aware Embedding Scene Aware Observation
Control Policy
‚ÄúSitting loosely with legs Contact pairs Ego-Heightmap
crossed.‚Äù CLIP ùíÇ ùíï ùíî ùíï
ùíìùëÆ
ùíï
root height Environment
ùîÉ
root rot
root vel ùíî
root ang vel Enc ùíï
joint pos
Discriminator
ùíì ùíïùë∫
joint vel
Figure4. Dual-AwareControlPolicy. Leftpart: language-awareskillembedding. Theembeddingsarefedintothepolicynetworkand
discriminator.Thediscriminatoristrainedtopredictifagivenstatetransition(s,s‚Ä≤)isfromthemotionclipcorrespondingtotheembedding
z. Rightpart: scene-awareobservation. Thecontactpairsareusedastaskgoalswhileegocentricheightmapsareusedasobservationsto
getawareofthesurroundingenvironment.
themotionembeddingandthedownsizedCLIPfeature: itisessentialtospecifythetargetcoordinateforthepelvis.
ForReach,wespecifythecoordinatestocontactforeither
Lm alig,t
n
=1‚àíd cos(Enc m(mÀÜ),MLP d(Enc l(c))). (4) theleftorrighthand. ForSitandLie,wespecifythepelvis
contact coordinates, as well as detailed contacts like head
ThetextembeddingreconstructionlossLt reconmeasuresthe contactwithabackrestorhandcontactwithanarmrest.
MSE distance between the reconstructed CLIP embedding
andtheoriginalone: 3.4.Dual-AwareFiniteStateMachine
As illustrated in Fig 2, our framework integrates several
Lt =‚à•MLP (MLP (Enc (c))))‚àíEnc (c)‚à• (5)
recon u d l l 2 reusablepolicies,servingaslow-levelcontrollers. Wehave
trainedfivepolicies: theWalkpolicyœÄ ,SitpolicyœÄ ,Lie
The weights of Enc are fixed during training. To main- w s
l
policyœÄ ,ReachpolicyœÄ ,andGetUppolicyœÄ .
tainthesemanticinformation,wefollowthesamplingstrat- l r g
Basedonthesecontrolpolicies,ourFSMprovidesusers
egyusedinMotionCLIP[30]. Wesample300framesfrom
withfivereusableskills:Sitk ,Liek ,GetUpk ,Reachk ,
the30fpsmotiondataanduseskipsamplingforthemotion s s g r
and Walk k . To synthesize human motions described by
clips that are shorter than 10 seconds so that all the infor- w
thescriptof:‚ÄúAmanwalksexcitedlywitharmsopened(z )
mationisincluded. w
to stool, then he touches the stool to get a rest. He then
walks to the sofa tiptoeing carefully and lies on the sofa
Scene-Aware Observation To enhance the humanoid‚Äôs
withlegscrossed(z ). Hestandsupfromthesofaandwalks
l
navigationandinteractioncapabilities,itiscrucialtomain-
tothe diningtablewith largefootsteps andreachesfor the
tain environmental awareness to prevent collisions. We
beer on the dining table. Then he walks to the corner ta-
draw inspiration from methods such as [27, 33, 38, 39],
ble drukenly and sits on it with head bowed and hands on
which utilize environmental sampling for humanoid ob-
thighs(z ). He then gets up and walks drunkenly(z ) to-
s w
servations. A square, ego-centric heightmap is generated
wards the TV stand.‚Äù Our finite state machine will parse
to capture the elevation of surrounding objects. See in
thistaskintothesequenceofskills,goalsandconditions:
Fig. 4. Consistent with UniHSI [39], we pre-generate
heightmaps for each scene to evaluate the height of mark- I ={(k ,h,g ,z ),(k ,h,g ),
w w w r r
ersaroundthehumanoid. However,creatingdetailedscene
(k ,h,g ,z ),(k ,h,g ,z ),(k ,h,g ),
w w w l l l g g
heightmapswhilepreservingsurfaceintricaciesiscomputa-
(k ,h,g ,z ),(k ,h,g ), (6)
tionallyintensive. Toenhancethehumanoid‚Äôsunderstand- w w w r r
ingofcomplexsurfacesforsittingorlying,wepre-generate (k w,h,g w,z w),(k s,h,g s,z s),(k g,h,g g)
heightmapsonlywithintheboundingboxofthetargetob- (k ,h,g ,z )},
w w w
ject. The egocentric heightmap is updated by calculating
thenearestobjectheightonlywhentheobjectissufficiently where (k ,h,g ,z ) denotes that the character performs
s s s
closetothehumanoid‚Äôsrootposition. the sitting skill k conditioned on the given egocentric
s
Following UniHSI [39], we employ a unified contact heightmaph,contactgoalg ,andtextembeddingz . The
s s
goal observation, encompassing 15 joint contact positions FSMtranslatestheseinstructionsintoasequenceofexplicit
andavalidcontactmaskofthe15joints. Thisapproachis controlsignalsandschedulescontrolpoliciestoexecutethe
suitablefortheskillswetrainedall. ForWalkandGetUp, instructionswithoutadditionaltraining.Following[19],the
6FSMalsodetermineswhentotransitionbetweenskills. For ‚Ä¢ Reward. For Walk skill, we use the reward follow
instance,itinitiatesthenextskillwhentheoverlaptimebe- [13, 19, 23]. For contact skills as Reach, Sit, Lie, and
tweenthecharacter‚Äôsrootanditstargetpositionexceedsa GetUp,wefollow[39]. Seethedetailedrewardfunction
specificthreshold.Thissimplerule-basedFSMallowsusers inSupp.Mat.
toachievedesiredlong-termhumanmotionsincomplex3D ‚Ä¢ Reset and early termination conditions. Following
scenes. Compared to the recent work InterScene [19], our [22], we use a fixed episode length and fall detection as
FSMcontainsegocentricheightmapsbyframeandtextem- earlyterminationtriggers. Wealsouseearlytermination
bedding by skill, which could ensure scene understanding when the task is accomplished for a certain time [19] or
andsemanticcontrol. thecontactforcesareextremelylarge[39].
‚Ä¢ Training the get-up policy. We do not use text con-
4.Experiments ditions for the GetUp skill since it is a short transition
betweeninteractionsandwalkingandrarelycontainsdi-
4.1.Dataset
verse styles. Here we follow the multi-step task train-
Following [13, 19, 39], we use the SAMP [12] dataset to ingsettingfollowing[39],wherewetrainSitandGetUp
train our interaction policies. We annotate all the motion policy together, and change the contact goal and reward
clipswithtextdescriptions,containingdetailedmotionsthat whenthelasttaskhasbeenaccomplished.
relatetostyleandemotions. Wealsoprovideeachmotion
4.3.Metrics
clip with suitable interact objects, e.g., some of the sitting
motions require an armrest or backrest, which means the Wefollow[12,39]thatusesSuccessRateandContactEr-
stools are not suitable. We use 100style[18] to train our ror as the main metrics to measure the quality of interac-
stylishlocomotions. Weselect30representativecategories tions quantitatively. Success Rate records the percentage
andannotateeachmotionwithstyledescriptions. Wealso of trials that humanoids successfully complete the contact
provideeachcaptionwith5synonymoussentenceswiththe withinacertainthreshold. Wefollow[13,19,39]tosetthe
help of LLM [1]. Following [39], we use the CIRCLE [2] thresholdofSitas20cm,Reachas20cm,andLieas30cm.
datasettotrainthereachingskill. Besidesneutral, wecat- To evaluate motion diversity, we use two metrics from
egorizetheemotionorstyleoftherestmotionsinto8cat- the previous papers: Fre¬¥chet Inception Distance (FID) [5,
egories: happy, angry, hurried, tired, sad, stressed, drunk, 31] and Average Pairwise Distance (APD) [5, 33]. FID
and relaxed. We left-right flip all the motions so we get measuresthesimilaritybetweenthedistributionsofgener-
doubletheamount.Fortrainingthemotionencoder,weuse atedand realdata inafeature space, reflectingthe realism
alloftheabovemotionswithourannotatedcaptions. andqualityofthegeneratedmotions. LowerFIDvaluesin-
For3dscenes, weusethe80objectsfromPartNet, half dicate closer alignment with real data. APD, on the other
for training and half for testing following [39]. We use hand, quantifiesthediversitywithinthegeneratedmotions
Scannet[3]and3DFront[8]fortestinganddemonstration. bycalculatingtheaveragepairwisedistancebetweensam-
Wechoosethelargest10scenesineachroomcategory(liv- ples. Higher APD values indicate greater diversity in the
ingroom,bedroom,dinningroom,library)from[8]. Since generatedmotions. WecalculateFIDandAPDonjointro-
3DFrontdonotprovidesegmentationinformation,wevox- tationsandpositions.
elizetheobjectmeshesandsegmentthepointcloudstoget
4.4.ComparisonwithBaselines
theaffordancesurface.
Our method achieves comparable results across various
4.2.PolicyTraining
metrics in Sec. 4.4. Unlike previous physics-based meth-
Wetrainthefollowing5skills(1)Walk.(2)Sit. (3)Lie. (4) ods[13,19,39]whichonlycareaboutcontactbutnotstyles,
Reach.(5)GetUp.WeonlyprovideWalk,Sit,andLieskills ourresultisachievedon4096randomtextconditionssam-
with text conditions since they contain diverse interaction pled from the datasets. The previous methods could be
stylesthatrepresentvividemotions. ForReachandGetUp, viewedasjustaspecificsituationofourmodel. Underthis
wedonotusetextconditions. background, we can see from Sec. 4.4 that our results are
‚Ä¢ Initialization. FollowingUniHSI[39],wecreatetheen- only slightly lower than the best methods InterScene [19]
vironmentbyrandomlysamplingobjectsfromthetrain- andUniHSI[39],comparabletoInterPhys[13].
ingsetofPartNetusedin[39]. Forthecharacter,weini-
4.5.DifferentPlanningresults
tialize it using reference state initialization [20] and de-
faultposeinitializationwitharandomglobalrotationand Weevaluatetheperformanceofourpolicyonasetofgen-
location[19,39]nearbytheobject. FortheWalkskill,we eratedshortscripts. Following[39],wecreatescriptswith
randomlysampledonthewholegroundplanewhilecal- varyinglevelsofdifficulty. Specifically,forsimplescripts,
culatingthecollisionwiththeobjects. weprompttheLLMtogeneratescenarioscontaining2in-
7Please generate a script Script Generation by LLM Retrieve Part1: Tom spreads his arms wide, the cool air brushing his cheeks as he joyfully sprints home. His Part2: In an unexpected twist, Tom begins
following this theme: ‚ÄúTom The retrieved keyframes are down heart races with excitement because his girlfriend has agreed to a date that afternoon. Overflowing sleepwalking. He drifts around the coffee
comes back home happily. here and the final story is on the with happiness, he flops onto the chair in his bedroom, catching his breath and smiling to himself. table in the living room, circling it twice with
He received a phone call right, split to 2 parts for better After a brief rest, he jumps up and goes to his wardrobe, rifling through hangers until he finds his a vacant expression, before returning to the
thenbecomesdepressed. demonstration. sharpest outfit‚Äîa crisp blue shirt and his favorite jeans. He changes eagerly, smoothing down the mirror. His steps are slow and dreamlike as he
H fine d f sin ia t l aly d w rea ak mes .‚Äù u Rp e a trn id e ve ùíõùíò ùíõùíì ùíõùíò ùíõùíî f ba eb ar mic i nb gef yo ore u ns gte mpp ai nn .g J uin s tf r to hn ent ,o hf it sh pe h m onir er o br u o zzn e t sh ine hd ir se pss oi cn kg e t ta , ib nl te e. r H ruis p r te inf gle hct isio tn h osh uo gw hts s a . H c eo n af nid se wn et, r s it m ana dk e fas lh lsi s o w nta oy tb ha ec mk t ao t tb re ed ss, .w Th he er je o h lte w tr ai kp ep ss
the short scripts from the while wandering into the living room, settling into the plush armchair. But as he listens, his smile him, and he blinked in confusion, realizing
summary list and give me vanishes. His girlfriend‚Äôs voice is somber as she says she wants to break up. Shocked and heartbroken, with relief it had all been a dream. There was
the final story. ùíõùíò ùíõùíì ùíõùíò ùíõùíç Tom feels the weight of the world on his shoulders. He trudges back to his bedroom, where he no breakup‚Äîbecause he didn‚Äôt have a
collapses at the foot of his bed, the emotional exhaustion pulling him into sleep. girlfriend in the first place.
Part1 Part2
1 3
‚ÄòSit on chair_1 with ‚ÄòWalks forward to the
hands supporting the 3 armchair_0 while talking on
upper body‚Äô 1 4 the phone with right hand.‚Äô
2
2 4
‚ÄòLie flat on
double_bed_0 with left ‚ÄòSleepwalks to the
leg bent.‚Äô dressingtable_0‚Äô
Please generate a script Script Generation by LLM Retrieve Part1ÔºöJerry walks back home, feeling Part2: After a short rest, Jerry remembers the can of beer on the dining table. The thought of it is refreshing,
following this theme: The retrieved keyframes are down utterly exhausted. His legs can barely so he gets up, walks over, and opens it with a satisfying hiss. The first sip is cold and invigorating, but as he
‚ÄúJerry comes back home here and the final story is on the hold him up, so he grabs a chair for drinks more, he starts to feel a bit lightheaded. The room sways slightly, so he decides to sit down again,
tiredly. He rests on the sofa right, split to 2 parts for better support and takes a moment to catch dropping into a nearby chair. As he sits there, a sudden thought hits him: he still has homework to finish.
then gets some drink. He demonstration. his breath. After regaining some The realization jolts him into action. He stands up with a sense of urgency and heads to his study. The room
f ri on oa mlly t osi t rt ei an dg ain b t oh oe k s .t ‚Äùu dy ùíõùíò ùíõùíì ùíõùíò ùíõùíç c ao nm d p coos llu ar pe s, e h se o m nto ov ie ts , co lv oe sr in t go hth ise e s yo ef sa . i ts h l ein de ed s kw cit hh a s irh ,e fl lv ipe ps if nil gle od p w ei nth t hb eo o bk os o. kH te o q tu hi ec k rl iy g hfi tn pd as g t eh .e T o hn ee q h ue ie n t e oe f d ths ea n std u p du y l els n i vt e o lou pt. s J he ir mry , ts he ett tl ie cs k ii nn gto
Retrieve the short scripts The soft cushions seem to absorb his clock on the wall a constant reminder of the deadline. As he reads through the material, he jots down notes,
from the summary list and weariness, and he begins to feel a bit focused and determined to finish his assignment. The task seems daunting, but he is resolved to push
give me the final story. ùíõùíì ùíõùíò ùíõùíî ùíõùíò better. through and get it done.
Part1 Part2
4
1 3
w‚ÄòL sii te uh po l pn e o gm rs t u ib nl et gi n s tte h,a ert i _ g bs h oo t d f a ya r ._ ‚Äôm0 ‚ÄòSit o hn o lc dh ina gir _ a1 n w obit jh e ch ta ‚Äônds
2
1
2 3 4
t‚ÄòW owa alk r df so r tw hea r bd o d or ku sn hk ee lfn _l 0y ‚Äô ‚Äò wSi it t ho n h as nto do s f l as_ u c1 ep, ‚Äôph oe ra td in d go tw hn e
Figure5. Long-termscriptswithdetailedkeyframesandvividfinalstoriesintwocomplex3Dscenesgeneratedbyourcompletesystem.
Upper: character in the bedroom and living room. Lower: character in the living room, dining room, and study room. We briefly
demonstratetheretrievedkeyframesandthefinallongstories.Withfourtext-conditionedinteractionsatbothsides.
teractions (Sit, Lie, Reach). For mid-level scripts, we in- FID between the generated motions and that of reference
clude 3‚Äì4 interactions, while for hard scripts, we require motionsfromSAMP[12]. TheAPDmeasuresthediversity
4‚Äì6 interactions. As shown in Tab. 2, our method demon- amongthegeneratedmotionsequences.AsshowninTab.3,
stratespracticalandeffectiveresultsacrossthesedifficulty ourresultssignificantlyoutperformUniHSIinbothFIDand
levels. Theresultisconductedontheselected3DFront[8] APD metrics. Our method achieves lower FID, indicating
scenes. motions produced from ours are closer to the distribution
of reference motions. Notably, the APD results highlight
4.6.MotionDiversityforDifferentSkills thatthemotionsgeneratedbyUniHSIarenearlyidentical,
demonstratingalackofdiversity.
WecomparedmotiondiversityintheSitandLieskillswith
UniHSI [39]. All experiments were conducted on a single
4.7.UserStudyresultsonScanNet
RTX 4090 GPU, running 1024 sequences and aggregating
theresultsover10trials. Foreachsequence,thetextcondi- Tofurtherevaluatethecontrolcapabilitiesofthelong-term
tionisrandomlysampledfromthedataset. Wemeasurethe scripts, weconductedauserstudyontheScanNetdataset.
8SuccessRate(%)‚Üë ContactError‚Üì ‚Äòsit with hand behind ‚Äòsit with arms support on ‚Äòsit with legs straight, ‚Äòsit with legs open, arms
Methods head, legs crossed‚Äô the seat, legs open‚Äô arms crossed‚Äô loosely‚Äô
Sit Lie Reach Sit Lie Reach
NSM-Sit[27] 75.0 - - 0.19 - -
SAMP-Sit[12] 75.0 - - 0.06 - -
SAMP-Lie[12] - 50.0 - - 0.05 -
InterPhys-Sit[13] 93.7 - - 0.09 - -
‚Äòlie flat with arms on the ‚Äòside-lie to the right, legs ‚Äòlie with left leg bent, ‚Äòlie flat with left leg bent‚Äô
InterPhys-Lie[13] - 80.0 - - 0.30 - belly, left leg bent‚Äô bent‚Äô elbows support the body‚Äô
AMP[22]-Sit 77.3 - - 0.090 - -
AMP-LieDown - 21.3 - - 0.112 -
AMP-Reach - - 98.1 - - 0.016
AMP(VC) 62.5 20.1 90.3 0.093 0.108 0.032
UniHSI[39] 94.3 81.5 97.5 0.032 0.061 0.016
InterScene[19] 97.8 - - 0.04 - - ‚Äòtap chest lightly with ‚Äòwalk with the body ‚Äòwalk excitedly‚Äô ‚Äòrunandspin‚Äô
both hands‚Äô leaning back‚Äô
SIMS(ours) 90.0 79.2 95.2 0.065 0.089 0.026
Table1.ComparisiononBaselineModels.
SuccessRate(%)‚Üë ContactError‚Üì SuccessSteps
Figure 6. Qualitative results for skills with different text condi-
Simple Mid Hard Simple Mid Hard Simple Mid Hard
tions.RowsfromtoptobottomareSit,LieandWalkskills.
74.3 42.2 31.5 0.072 0.128 0.325 1.5 3.1 4.2
Table2.PerformanceEvaluationofSIMSonourScriptMatching SuccessRate(%)‚Üë ContactError‚Üì
Methods
Plannings. Sit Lie Reach Sit Lie Reach
woHeightmap 80.8 75.3 86.0 0.079 0.114 0.051
woTextEmbedding 81.5 73.3 - 0.069 0.094 -
SIMS(ours) 90.0 79.2 95.2 0.065 0.089 0.026
FID‚Üì APD‚Üë
Method
Sit Lie Sit Lie
Table5.AblationStudyonParntnet.
UniHSI[39] 153.84 211.22 1.14¬±0.01 1.35¬±0.02
SIMS(ours) 125.66 164.88 16.55¬±0.54 16.36¬±0.62
Table3.Motiondiversityresults. bedding. Bothvariantsshoweddegradedperformance. The
height map provides essential information about the sur-
rounding environment so the performance becomes worse
Weselectedseveral3Dmeshscenesandusedthesameset
when interacting with objects. When trained without text
ofkeyframestodrivethecharactersinthescenes,withthe
embedding,themodelrevertstoaUniHSI-likestate. How-
distinction that our method allows for control via text em-
ever,unlikeUniHSI,weselectedallofthecomplexinterac-
beddings.12participantswereaskedtoratethephysicalre-
tiondatafromSAMPanddidnotuseitsmulti-steptraining
alismandscriptalignmentofthevideosproducedbyeach
strategy for tasks like Sit and Lie. As a result, the model
method,onascalefrom1(poor)to5(excellent). In Tab.4,
learnslessabouttransitionsbetweendifferentposes.
the results indicate that our approach significantly outper-
formedUniHSI,demonstratingitseffectivenessinenhanc- 4.9.QualitativeResults
ing both realism and narrative alignment in the generated
We show two generated long narratives executed by our
animations.
policies in two large indoor scenes. The details could be
viewedinFig.5. Wealsoshowed8interactionsorlocomo-
Method UniHSI SIMS
tions with emotional characteristics. For more qualitative
PhysicalRealism‚Üë 2.5 4.1
results,seeSupp.Mat.
ScriptAlignment‚Üë 3.1 4.3
5.Conclusion
Table 4. User study on Scannet. SIMS outperforms the SOTA
methodUniHSIbyasignificantmargin.
In this paper, we present a framework that synthesizes
long-term human-scene interactions by using Large Lan-
guage Models as a planner and a dual-aware control pol-
4.8.AblationStudies
icy as a controller. By integrating real-world video data
Weconductedanablationstudyondifferentsettingsofour andleveragingVision-LanguageModels,ourapproachen-
controlpolicy,comparingtheSuccessRateandContactEr- ables diverse and expressive long-term script generation.
ror for variations without heightmap and without text em- We also employ graph edit distance to retrieve scene lay-
9outsandrealizeinteractionsinnumerousscenes. Ourlow-
level dual-aware control policy enables characters to per-
form physical-plausible motions with stylish details in un-
seen3Dscenes.
6.LimitationsandFutureWork
Ourframework‚Äôsmainlimitationistheinsufficientamount
ofstylishinteractionmotiondata,whichlimitsourmodel‚Äôs
generalization ability. In the future, it is necessary to col-
lect more human motion data that expresses realistic emo-
tionsandstyles. Itisalsoneededtodevelopbetterwaysto
structure short scripts. This would provide more temporal
coherenceandalignwithreal-lifelogic.
10References [13] Mohamed Hassan, Yunrong Guo, Tingwu Wang, Michael
Black,SanjaFidler,andXueBinPeng. Synthesizingphys-
[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ah-
icalcharacter-sceneinteractions. InACMSIGGRAPH2023
mad,IlgeAkkaya,FlorenciaLeoniAleman,DiogoAlmeida,
ConferenceProceedings,pages1‚Äì9,2023. 1,2,7,9
JankoAltenschmidt, SamAltman, ShyamalAnadkat, etal.
[14] Biao Jiang, Xin Chen, Wen Liu, Jingyi Yu, Gang Yu, and
Gpt-4 technical report. arXiv preprint arXiv:2303.08774,
Tao Chen. Motiongpt: Human motion as a foreign lan-
2023. 4,7
guage.AdvancesinNeuralInformationProcessingSystems,
[2] JoaoPedroArau¬¥jo,JiamanLi,KarthikVetrivel,RishiAgar-
36:20067‚Äì20079,2023. 2
wal,JiajunWu,DeepakGopinath,AlexanderWilliamClegg,
[15] NanJiang,ZhiyuanZhang,HongjieLi,XiaoxuanMa,Zan
andKarenLiu. Circle: Captureinrichcontextualenviron-
Wang, Yixin Chen, Tengyu Liu, Yixin Zhu, and Siyuan
ments.InProceedingsoftheIEEE/CVFConferenceonCom-
Huang. Scalingupdynamichuman-sceneinteractionmod-
puterVisionandPatternRecognition, pages21211‚Äì21221,
eling.InProceedingsoftheIEEE/CVFConferenceonCom-
2023. 7
puter Vision and Pattern Recognition, pages 1737‚Äì1747,
[3] Angela Dai, Angel X Chang, Manolis Savva, Maciej Hal-
2024. 2
ber, Thomas Funkhouser, and Matthias Nie√üner. Scannet:
[16] Jordan Juravsky, Yunrong Guo, Sanja Fidler, and Xue Bin
Richly-annotated 3d reconstructions of indoor scenes. In
Peng.Padl:Language-directedphysics-basedcharactercon-
ProceedingsoftheIEEEconferenceoncomputervisionand
trol. In SIGGRAPH Asia 2022 Conference Papers, pages
patternrecognition,pages5828‚Äì5839,2017. 7
1‚Äì9,2022. 2,3,5
[4] Jacob Devlin. Bert: Pre-training of deep bidirectional
[17] Viktor Makoviychuk, Lukasz Wawrzyniak, Yunrong Guo,
transformers for language understanding. arXiv preprint
Michelle Lu, Kier Storey, Miles Macklin, David Hoeller,
arXiv:1810.04805,2018. 5
Nikita Rudin, Arthur Allshire, Ankur Handa, et al. Isaac
[5] Zhiyang Dou, Xuelin Chen, Qingnan Fan, Taku Komura,
gym: High performance gpu-based physics simulation for
andWenpingWang. C¬∑ase: Learningconditionaladversar-
robotlearning. arXivpreprintarXiv:2108.10470,2021. 1,3
ial skill embeddings for physics-based characters. In SIG-
[18] IanMason,SebastianStarke,andTakuKomura. Real-time
GRAPHAsia2023ConferencePapers,2023. 2,7
stylemodellingofhumanlocomotionviafeature-wisetrans-
[6] Zhiyang Dou, Xuelin Chen, Qingnan Fan, Taku Komura,
formationsandlocalmotionphases.ProceedingsoftheACM
andWenpingWang. C¬∑ase: Learningconditionaladversar-
onComputerGraphicsandInteractiveTechniques, 5(1):1‚Äì
ial skill embeddings for physics-based characters. In SIG-
18,2022. 7
GRAPHAsia2023ConferencePapers,pages1‚Äì11,2023. 2
[19] LiangPan,JingboWang,BuzhenHuang,JunyuZhang,Hao-
[7] Zhiyang Dou, Qingxuan Wu, Cheng Lin, Zeyu Cao,
fanWang,XuTang,andYangangWang.Synthesizingphys-
Qiangqiang Wu, Weilin Wan, Taku Komura, and Wenping
icallyplausiblehumanmotionsin3dscenes. In2024Inter-
Wang. Tore: Tokenreductionforefficienthumanmeshre-
nationalConferenceon3DVision(3DV),pages1498‚Äì1507.
covery with transformer. In Proceedings of the IEEE/CVF
IEEE,2024. 1,2,6,7,9
InternationalConferenceonComputerVision,pages15143‚Äì
15155,2023. 2 [20] Xue Bin Peng, Pieter Abbeel, Sergey Levine, and Michiel
VandePanne.Deepmimic:Example-guideddeepreinforce-
[8] Huan Fu, Bowen Cai, Lin Gao, Ling-Xiao Zhang, Jiaming
mentlearningofphysics-basedcharacterskills.ACMTrans-
Wang,CaoLi,QixunZeng,ChengyueSun,RongfeiJia,Bin-
actionsOnGraphics(TOG),37(4):1‚Äì14,2018. 7
qiangZhao,etal. 3d-front:3dfurnishedroomswithlayouts
and semantics. In Proceedings of the IEEE/CVF Interna- [21] Xue Bin Peng, Pieter Abbeel, Sergey Levine, and Michiel
tionalConferenceonComputerVision,pages10933‚Äì10942, VandePanne.Deepmimic:Example-guideddeepreinforce-
2021. 5,7,8 mentlearningofphysics-basedcharacterskills.ACMTrans-
[9] Zhifu Gao, Zerui Li, Jiaming Wang, Haoneng Luo, Xian actionsOnGraphics(TOG),37(4):1‚Äì14,2018. 2
Shi, Mengzhe Chen, Yabin Li, Lingyun Zuo, Zhihao [22] Xue Bin Peng, Ze Ma, Pieter Abbeel, Sergey Levine, and
Du, Zhangyu Xiao, et al. Funasr: A fundamental AngjooKanazawa.Amp:Adversarialmotionpriorsforstyl-
end-to-end speech recognition toolkit. arXiv preprint ized physics-based character control. TOG, 2021. 2, 5, 7,
arXiv:2305.11013,2023. 4 9
[10] Yongtao Ge, Wenjia Wang, Yongfan Chen, Hao Chen, and [23] Xue Bin Peng, Yunrong Guo, Lina Halper, Sergey Levine,
Chunhua Shen. 3d human reconstruction in the wild with andSanjaFidler. Ase:Large-scalereusableadversarialskill
synthetic data using generative models. arXiv preprint embeddingsforphysicallysimulatedcharacters.TOG,2022.
arXiv:2403.11111,2024. 2 7
[11] AssafHallak,GalDalal,ChenTessler,KellyGuo,ShieMan- [24] Xue Bin Peng, Yunrong Guo, Lina Halper, Sergey Levine,
nor,andGalChechik.Plamo:Planandmoveinrich3dphys- and Sanja Fidler. Ase: Large-scale reusable adversarial
icalenvironments. arXivpreprintarXiv:2406.18237,2024. skillembeddingsforphysicallysimulatedcharacters. ACM
2 TransactionsOnGraphics(TOG),41(4):1‚Äì17,2022. 2
[12] Mohamed Hassan, Duygu Ceylan, Ruben Villegas, Jun [25] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
Saito,JimeiYang,YiZhou,andMichaelBlack. Samp. In Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,
2021IEEE/CVFInternationalConferenceonComputerVi- AmandaAskell,PamelaMishkin,JackClark,etal.Learning
sion(ICCV),2021. 1,2,7,8,9 transferable visual models from natural language supervi-
11sion.InInternationalconferenceonmachinelearning,pages Computer Vision and Pattern Recognition, pages 433‚Äì444,
8748‚Äì8763.PMLR,2021. 2,5 2024. 2
[26] AlbertoSanfeliuandKing-SunFu. Adistancemeasurebe- [38] Jungdam Won, Deepak Gopinath, and Jessica Hodgins.
tween attributed relational graphs for pattern recognition. Physics-based character controllers using conditional vaes.
IEEEtransactionsonsystems,man,andcybernetics,1983. ACMTransactionsonGraphics(TOG),41(4):1‚Äì12,2022. 6
5 [39] Zeqi Xiao, Tai Wang, Jingbo Wang, Jinkun Cao, Wenwei
[27] Sebastian Starke, He Zhang, Taku Komura, and Jun Saito. Zhang, Bo Dai, Dahua Lin, and Jiangmiao Pang. Unified
Neuralstatemachineforcharacter-sceneinteractions. ACM human-sceneinteractionviapromptedchain-of-contacts. In
TransactionsonGraphics,38(6):178,2019. 1,2,6,9 ICLR,2024. 1,2,3,6,7,8,9
[28] Jingkai Sun, Qiang Zhang, Yiqun Duan, Xiaoyang Jiang, [40] Xinyu Xu, Yizheng Zhang, Yong-Lu Li, Lei Han, and
ChongCheng,andRenjingXu.Prompt,plan,perform:Llm- CewuLu. Humanvla:Towardsvision-languagedirectedob-
basedhumanoidcontrolviaquantizedimitationlearning. In ject rearrangement by physical humanoid. arXiv preprint
2024 IEEE International Conference on Robotics and Au- arXiv:2406.19972,2024. 2,3
tomation(ICRA),pages16236‚Äì16242.IEEE,2024. 2,3 [41] HongweiYi,JustusThies,MichaelJ.Black,XueBinPeng,
[29] QingpingSun,YanjunWang,AilingZeng,WanqiYin,Chen andDavisRempe. Generatinghumaninteractionmotionsin
Wei,WenjiaWang,HaiyiMei,Chi-SingLeung,ZiweiLiu, sceneswithtextcontrol. arXiv:2404.10685,2024. 2
Lei Yang, et al. Aios: All-in-one-stage expressive human [42] Mingyuan Zhang, Zhongang Cai, Liang Pan, Fangzhou
poseandshapeestimation. InProceedingsoftheIEEE/CVF Hong, XinyingGuo, LeiYang, andZiweiLiu. Motiondif-
Conference on Computer Vision and Pattern Recognition, fuse: Text-driven human motion generation with diffusion
pages1834‚Äì1843,2024. 2 model. arXivpreprintarXiv:2208.15001,2022. 2
[30] Guy Tevet, Brian Gordon, Amir Hertz, Amit H Bermano, [43] Wanyue Zhang, Rishabh Dabral, Thomas Leimku¬®hler,
andDanielCohen-Or. Motionclip:Exposinghumanmotion Vladislav Golyanik, Marc Habermann, and Christian
generationtoclipspace. InECCV.Springer,2022. 2,5,6 Theobalt. Roam: Robust and object-aware motion gener-
[31] Guy Tevet, Sigal Raab, Brian Gordon, Yoni Shafir, Daniel ation using neural pose descriptors. In 2024 International
Cohen-or,andAmitHaimBermano. Humanmotiondiffu- Conference on 3D Vision (3DV), pages 1392‚Äì1402. IEEE,
sion model. In The Eleventh International Conference on 2024. 2
LearningRepresentations,2023. 7 [44] Xiaohan Zhang, Bharat Lal Bhatnagar, Sebastian Starke,
[32] Weilin Wan, Zhiyang Dou, Taku Komura, Wenping Wang, Vladimir Guzov, and Gerard Pons-Moll. Couch: Towards
Dinesh Jayaraman, and Lingjie Liu. Tlcontrol: Trajectory controllablehuman-chairinteractions. InEuropeanConfer-
and language control for human motion synthesis. arXiv enceonComputerVision,pages518‚Äì535.Springer,2022.1,
preprintarXiv:2311.17135,2023. 2 2
[33] JingboWang,YuRong,JingyuanLiu,SijieYan,DahuaLin, [45] Wenyang Zhou, Zhiyang Dou, Zeyu Cao, Zhouyingcheng
and Bo Dai. Towards diverse and natural scene-aware 3d Liao,JingboWang,WenjiaWang,YuanLiu,TakuKomura,
humanmotionsynthesis. InProceedingsoftheIEEE/CVF Wenping Wang, and Lingjie Liu. Emdm: Efficient motion
Conference on Computer Vision and Pattern Recognition, diffusionmodelforfastandhigh-qualitymotiongeneration.
pages20460‚Äì20469,2022. 1,2,6,7 InEuropeanConferenceonComputerVision,pages18‚Äì38.
Springer,2025. 2
[34] Jionghao Wang, Yuan Liu, Zhiyang Dou, Zhengming Yu,
YongqingLiang,ChengLin,XinLi,WenpingWang,Rong
Xie, and Li Song. Disentangled clothed avatar generation
from text descriptions. arXiv preprint arXiv:2312.05295,
2023. 2
[35] WenjiaWang,YongtaoGe,HaiyiMei,ZhongangCai,Qing-
pingSun,YanjunWang,ChunhuaShen,LeiYang,andTaku
Komura.Zolly:Zoomfocallengthcorrectlyforperspective-
distortedhumanmeshreconstruction. InProceedingsofthe
IEEE/CVF International Conference on Computer Vision,
pages3925‚Äì3935,2023. 2
[36] ZanWang,YixinChen,TengyuLiu,YixinZhu,WeiLiang,
and Siyuan Huang. Humanise: Language-conditioned hu-
man motion generation in 3d scenes. Advances in Neural
InformationProcessingSystems,35:14959‚Äì14971,2022. 1,
2
[37] Zan Wang, Yixin Chen, Baoxiong Jia, Puhao Li, Jinlu
Zhang, Jingze Zhang, Tengyu Liu, Yixin Zhu, Wei Liang,
and Siyuan Huang. Move as you say interact as you can:
Language-guided human motion generation with scene af-
fordance. In Proceedings of the IEEE/CVF Conference on
12SIMS: Simulating Human-Scene Interactions with Real World Script Planning
Supplementary Material
7.RewardFunctions
Inthissection,weintroducetherewardfunctionsin3parts: rnear =exp(cid:0) ‚àí10.0(cid:88)15 (cid:13) (cid:13)gj ‚àíxj(cid:13) (cid:13)2(cid:1)
t (cid:13) t t(cid:13)
walk reward, contact reward, and get-up reward. Notably, j=1 (13)
thecontactrewardisusedforSit,Lie,andReachskills. gj = min ‚à•p ‚àíxj‚à•
t i
‚Ä¢ WalkReward.ThewalkrewardisdefinedinEquation7. pi‚ààpgoal
Thestylerewardismodeledusingamotiondiscriminator. ‚Ä¢ Getup Reward. The GetUp skill is developed through
Incontrastto[13],wedonotconditionthediscriminator step goals, which combine walk and contact rewards. If
on the object context. The overall reward comprises the thecontactgoalhasnotbeenreached,therewardencour-
far,near,andstandstillrewards. Thestandstillrewarden- agesthehumanoidtositorlieontheobject. Conversely,
suresthatthehumanoidremainsstaticoncethetargetpo- when the contact goal is achieved, the reward motivates
sitionhasbeenreached. Givenatargetpositionofchar- thehumanoidtoelevateitspelvistoastandingposition.
acter‚Äôs root x‚àó, a target direction d‚àó, and a target scalar Theformulationforthisrewardsystemalignswiththatof
t
velocitygvel,thetaskrewardisdefinedas: thecontactreward.
t
8.MoreVisualization
(cid:40) 0.4rnear+0.5rfar+0,(cid:13) (cid:13)x‚àó‚àíxroot(cid:13) (cid:13)2
>0.5
rG = t t t 8.1.InteractionDetails
t 0.4rnear+0.5+0.1rstill,otherwise
t t
(7) We show the following three skills with random text em-
beddings. Eachembeddingisperformedfor8seconds,and
rfar =0.6exp(cid:0) ‚àí0.5(cid:13) (cid:13)x‚àó‚àíxroot(cid:13) (cid:13)2(cid:1) then the humanoid‚Äôs state and text embedding will be ran-
t t
domlyreset.
+0.2exp(cid:0) ‚àí2.0(cid:13) (cid:13)g tvel‚àíd‚àó t ¬∑xÀôr toot(cid:13) (cid:13)2(cid:1) (8)
+0.2
(cid:13) (cid:13)d‚àó¬∑dfacing(cid:13) (cid:13)2 Sitskill. Pleaseseedemo sit.mp4. Thetextdescriptions
(cid:13) t t (cid:13) usedindemo sit.mp4are:
‚Ä¢ armsloosely,legsopen
rnear =exp(cid:0) ‚àí10.0(cid:13) (cid:13)x‚àó‚àíxroot(cid:13) (cid:13)2(cid:1) (9) ‚Ä¢ handsbehindhead,cross-legged,leanback
t t
‚Ä¢ handssupportonseat,legsstraight
‚Ä¢ handssupportonseat,legsstraight
rstill =exp(cid:0) ‚àí2.0(cid:13) (cid:13)xÀôroot‚àíxÀôroot(cid:13) (cid:13)2 ) (10) ‚Ä¢ armsloosely,legsopen
t t t‚àí1
‚Ä¢ legsstraight,handssupportbody
‚Ä¢ ContactReward.ThecontactrewardisdefinedinEq11.
‚Ä¢ handsonthighs
The far reward is to encourage the humanoid‚Äôs pelvis to
‚Ä¢ armscrossed,straightlegs,feetcrossed
reach the target coordinate x‚àó with the target speed gvel
t ‚Ä¢ situprightwithhandsonthighs
and target direction d‚àó. Like UniHSI [39], the near re-
t ‚Ä¢ legsstraight,handssupportbody
ward encourages the humanoid‚Äôs certain joint to contact
‚Ä¢ legsstraight,handssupportbody
thenearestpointinacertainpartpgoalofthetargetobject.
‚Ä¢ handsbehindhead,leanback,cross-legged
Thetaskrewardisdefinedas:
‚Ä¢ handsbehindhead,leanback,feetcrossed
‚Ä¢ handsbehindhead,legsstraight
(cid:40) 0.6rnear+0.4rfar,(cid:13) (cid:13)x‚àó‚àíxroot(cid:13) (cid:13)2
>0.5
rG = t t t Lieskill. Pleaseseedemo lie.mp4. Thetextdescriptions
t 0.6rnear+0.4,otherwise
t usedindemo lie.mp4are:
(11)
‚Ä¢ leftlegbent
‚Ä¢ side-lieonleft,legsbent
rfar =0.5exp(cid:0) ‚àí0.5(cid:13) (cid:13)x‚àó‚àíxroot(cid:13) (cid:13)2(cid:1) ‚Ä¢ side-lieonleft,legscrossed
t t ‚Ä¢ sidelieonleft,righthandonbelly
+0.4exp(cid:0) ‚àí2.0(cid:13) (cid:13)g tvel‚àíd‚àó t ¬∑xÀôr toot(cid:13) (cid:13)2(cid:1) (12) ‚Ä¢ leftlegbent
(cid:13) (cid:13)2 ‚Ä¢ rightlegbent
+0.1 (cid:13) (cid:13)d‚àó t ¬∑df tacing(cid:13) (cid:13) ‚Ä¢ side-lieonright
1‚Ä¢ elbowssupportingbody,leftlegbent again, still in a light-hearted mood, and wandered over
‚Ä¢ handsonbelly to the bookshelf. With a gentle touch of his left hand,
‚Ä¢ side-lieonright,legsbent he picked out a book, feeling the thrill of a new story.
‚Ä¢ side-lieonright,legsbent Finally, he made his way to the dining chair, where he
‚Ä¢ handsonbelly,leftlegbent settledinwiththebookinhand,readytolosehimselfin
‚Ä¢ side-lieonright itspages.
‚Ä¢ handsonbelly,rightlegbent
‚Ä¢ sidelieonleftwithhandsonbelly
Story2. Pleaseseedemo2.mp4.
‚Ä¢ Theme: A person is happy at first, but he is told in the
Walk skill. Please see demo walk.mp4. The text de-
phone that he fails the job interview and becomes very
scriptionsusedindemo walk.mp4are:
depressed.
‚Ä¢ walkwithkneesbent
‚Ä¢ Final story: On a hopeful afternoon, Jake walked with
‚Ä¢ skipstepsrunning
big steps toward the wardrobe, filled with excitement as
‚Ä¢ walkwhiletalkingonthephonewiththelefthand
he prepared for a potential celebration. He touched the
‚Ä¢ walkwiththebodyleaningback
wardrobe with his left hand, imagining the outfit that
‚Ä¢ walkontiptoes
would mark a successful day ahead. After choosing his
‚Ä¢ tapchestlightlywithbothhands
clothes,Jakeheadedtothedressingtabletocheckhisap-
‚Ä¢ runandspin
pearance in the mirror. Just as he was feeling confident,
‚Ä¢ upliftedheadwalking
his phone rang unexpectedly. He quickly walked to the
‚Ä¢ walkwhiletalkingonthephonewiththerighthand
armchair, answering the call, only to receive the disap-
‚Ä¢ walklikeanoldperson
pointingnewsthathehadnotgottenthejobhewashop-
‚Ä¢ rushanxiouslyforward
ingfor. Feelingtheweightoftherejection,Jakemadehis
‚Ä¢ walkingslowly,handsbehindback
waytotheloveseat,hisheaddownandspiritdeflated. He
‚Ä¢ walkwithdepression
satthere,overwhelmedwithsadness. Afteramoment,he
‚Ä¢ walkwithkneesbent
stoodupfromtheloveseat,strugglingtoshakeoffthedis-
‚Ä¢ headbowedandbodybentwhilewalking
appointment. Withaheavyheart,hewalkedtothedining
‚Ä¢ walkingdrunkenly
table,hopingforacomfortingdrink,onlytofinditempty.
‚Ä¢ walkwiththebodyleaningback
Anxiously, he paced the room, searching for solace, be-
forefinallyreturningtotheloveseat. Helaybackdown,
8.2.Long-TermMotions
propping himself up on his elbows, trying to find some
We show 4 long-term motions generated by our pipeline. relieffromtheemotionalturmoil.
We show demos in multi-room scenes by merging short
scriptsfromdifferentroomtypes. Theroomsarecombined
Story3. Pleaseseedemo3.mp4.
byanoffsetdistancewithboundingedgesaswalls.
‚Ä¢ Theme: Apersonenjoysarelaxedafternoonathome.
‚Ä¢ Final story: On a bright Saturday afternoon, Emily felt
Story1. Pleaseseedemo1.mp4.
a surge of childlike joy as she walked over to the book-
‚Ä¢ Theme: A person relaxes at home during the weekend,
shelfwithherarmswideopen. Theexcitementwaspal-
drinkscokes,andreadsbooks.
pableasshetouchedtheshelf,searchingforacomicbook
‚Ä¢ Finalstory: Onaleisurelyweekend,Johndecidedtotake
amongthecolorfulspines. Onceshefoundacomicthat
sometimeforhimselfathome. Hewalkedslowlytothe
caught her eye, she made her way to the loveseat, tak-
first stool, his head bowed and body bent, as if weighed
ingbig,enthusiasticsteps. Sheploppeddownonthesoft
down by the week‚Äôs fatigue. After a brief moment, he
couch,supportingherselfwithherhands,fullyimmersed
touchedthestoolwithhisrighthandandsettledinfora
inthemoment. Afterabriefpause,Emilystoodupfrom
rest. Feeling a bit rejuvenated, John stood up and made
the loveseat, her energy still high. She bounced over to
hiswaytothemulti-seatsofa,stillkeepingarelaxedpos-
thecoffeetable,overflowingwitheagerness. Finally,she
ture. Helaydownonthesofa,stretchingouthisrightleg
satdownonthetable,herrighthandclutchingthecomic
straight, enjoying the comfort it provided. After a short
book,readytodiveintotheadventureswaitingwithinits
while,hegotupandexcitedlywalkedovertothedining
pages.
table.Withaplayfultouchofhislefthand,hereachedfor
a drink on the table, savoring the moment. A little tipsy
from the drink, John ambled back to the first stool, this Story4. Pleaseseedemo4.mp4.
time sitting down with his legs open and leaning back- ‚Ä¢ Theme: A person is dressing up and feels excited about
ward, completely relaxed. After some time, he got up thepicnictomorrow.
2‚Ä¢ Finalstory: Onacheerfulmorning,Sarahwasfilledwith
excitement as she thought about her upcoming picnic.
Shelaycomfortablyonherdoublebed,side-lyingtothe
right,daydreamingabouttheadventuresthatawaitedher.
Afteralittlewhile,shegotup,feelingarushofanticipa-
tion.Withabrightsmile,shewalkedexcitedlytowardthe
wardrobe, eager to find the perfect outfit for the picnic.
Touching the wardrobe with her left hand, she discov-
ered a stylish suit that caught her eye. Energized by her
find,shedashedovertothesecondwardrobe,uncovering
another good-looking suit that made her feel even more
thrilled. Next, Sarah hurried to the dressing table, peer-
ing into the mirror and visualizing how great she would
look in her chosen outfits. Her excitement grew as she
walkedeagerlyintothelivingroom,armswideopen,em-
bracingthejoyofthedayahead. Inaplayfulmood,she
skipped around the living room, her laughter echoing as
shemoved.Finally,shereturnedtothedoublebed,sitting
downwithherarmssupportingherbody,feelingrelaxed
andcontentasshecontinuedtoplanherperfectpicnic.
9.ShortScriptExamples
Weshowsomegeneratedshortscriptexamples. InTab.6,
weshowemotionSadandAngry. InTab.7,weshowemo-
tionDrunk(thisismoreappropriatelydefinedasstyle)and
emotion Relaxed. In Tab. 8, we show emotion Happy and
emotionHurried. InTab.9,weshowemotionStressedand
emotionTired.
10.DirectGenerationvs. ScriptMatching
We compare the long-term scripts generated directly by
the LLM with those produced using our script-matching
method,illustratingourfindingsthroughthreeexamples.
Example1(seeTab.10)featuresashortstoryinwhicha
person wins the lottery and experiences happiness. While
the direct generation includes some basic keyframes, it
lacksthevividdetailsthatourmethodprovides.
Examples2(refertoTab.11andTab.12)depictanarra-
tivewhereanindividualsearchesforjewelry. Thecharacter
becomes excited upon finding it and subsequently drinks
wine. Notably, the direct generation omits the tactile skill
altogether. In contrast, our method adds rich details, such
asthecharacterfirstsearchingthecabinetandthenthebed.
After drinking, the person amusingly attempts to touch a
lamp‚Äîanexampleofthewhimsicalbehavioronemightex-
pectfromsomeonewhoisdrunk.
Examples 3 (see Tab. 13 and Tab. 14) focus on a man
whobecomessadanddrunkwhilereminiscingabouthisde-
ceasedwife. Althoughthedirectgenerationcapturesmost
oftheessentialkeyframes,itfallsshortinprovidingthenec-
essary details and embellishments that enhance the narra-
tive.
3Emotion:Sad Emotion:Angry
Scene:Bedroom Scene:LivingRoom
{ {
‚Äúsummary‚Äù:‚ÄúThecharacterwalksaroundsadlyandliesdown ‚Äúsummary‚Äù:‚ÄúCharacterstompedaroundthebedroom,
onthesofainthelivingroom.‚Äù, feelingbothanxiousandangry,beforesittingon
‚Äúkeyframes‚Äù:[ thebedandcalmingdown.‚Äù,
{ ‚Äúkeyframes‚Äù:[
‚Äúskill‚Äù:‚Äúloco‚Äù, {
‚Äúemotion/style‚Äù:‚Äúdepressed‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúcaption‚Äù:‚Äúwalkwithdepression‚Äù, ‚Äúemotion/style‚Äù:‚Äúanxious,angry‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúcaption‚Äù:‚Äúangrilywalking‚Äù,
}, ‚Äúfurniture‚Äù:‚Äúfloor‚Äù
{ },
‚Äúskill‚Äù:‚Äúsitdown‚Äù, {
‚Äúemotion/style‚Äù:‚Äúpainful,sad‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúcaption‚Äù:‚Äúhandsholdinghead,legsextended‚Äù, ‚Äúemotion/style‚Äù:‚Äúcold,disturbed,anxious‚Äù,
‚Äúfurniture‚Äù:‚Äúarmchair‚Äù ‚Äúcaption‚Äù:‚Äúwalkwitharmscrossedoverchest‚Äù,
}, ‚Äúfurniture‚Äù:‚Äúfloor‚Äù
{ },
‚Äúskill‚Äù:‚Äústandup‚Äù, {
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúskill‚Äù:‚Äútouch‚Äù,
‚Äúcaption‚Äù:‚Äústandup‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúfurniture‚Äù:‚Äúarmchair‚Äù ‚Äúcaption‚Äù:‚ÄúAnactofreachinghigh‚Äù,
}, ‚Äúfurniture‚Äù:‚Äúwardrobe‚Äù
{ }
‚Äúskill‚Äù:‚Äúloco‚Äù, {
‚Äúemotion/style‚Äù:‚Äútired,sad‚Äù, ‚Äúskill‚Äù:‚Äúsitdown‚Äù,
‚Äúcaption‚Äù:‚Äúheadbowedandbodybentwhilewalking‚Äù, ‚Äúemotion/style‚Äù:‚Äúangry‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúcaption‚Äù:‚Äúcrossingarms‚Äù,
}, ‚Äúfurniture‚Äù:‚Äúbed‚Äù
{ },
‚Äúskill‚Äù:‚Äúliedown‚Äù, {
‚Äúemotion/style‚Äù:‚Äúsad,stressed,tired‚Äù, ‚Äúskill‚Äù:‚Äústandup‚Äù,
‚Äúcaption‚Äù:‚ÄúLyingdownwithrightlegbentandhands ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
coveringface‚Äù, ‚Äúcaption‚Äù:‚Äústandup‚Äù,
‚Äúfurniture‚Äù:‚Äúsofa‚Äù ‚Äúfurniture‚Äù:‚Äúbed‚Äù
} },
] ]
} }
Table6.ShortScriptExamplesofEmotionSadandAngry.
4Emotion:Drunk Emotion:Relaxed
Scene:Bedroom Scene:LivingRoom
{ {
‚Äúsummary‚Äù:‚ÄúThecharactergetsdrunkandfallsdown ‚Äúsummary‚Äù:‚ÄúCharacterexperiencesamellowafternoon
inthebedroom.‚Äù, ofrelaxationinthelivingroom.‚Äù,
‚Äúkeyframes‚Äù:[ ‚Äúkeyframes‚Äù:[
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äúsitdown‚Äù,
‚Äúemotion/style‚Äù:‚Äúdrunk‚Äù, ‚Äúemotion/style‚Äù:‚Äúrelaxed,drunk‚Äù,
‚Äúcaption‚Äù:‚Äúwalkingdrunkenly‚Äù, ‚Äúcaption‚Äù:‚Äúleftlegstraightened‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúfurniture‚Äù:‚Äúchair‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äútouch‚Äù, ‚Äúskill‚Äù:‚Äústandup‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚ÄúLowtouchfromaproneposition‚Äù, ‚Äúcaption‚Äù:‚Äústandup‚Äù,
‚Äúfurniture‚Äù:‚Äúcabinet‚Äù ‚Äúfurniture‚Äù:‚Äúchair‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúdrunk‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äúwalkingdrunkenly‚Äù, ‚Äúcaption‚Äù:‚Äúsmoothlyforwardwalk‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúfurniture‚Äù:‚Äúfloor‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúsitdown‚Äù, ‚Äúskill‚Äù:‚Äúliedown‚Äù,
‚Äúemotion/style‚Äù:‚Äúsad,drunk‚Äù, ‚Äúemotion/style‚Äù:‚Äúrelaxed‚Äù,
‚Äúcaption‚Äù:‚Äúrightlegheld,leftlegstretchedout‚Äù, ‚Äúcaption‚Äù:‚ÄúLiedownwithlegscrossedand
‚Äúfurniture‚Äù:‚Äúbed‚Äù rightarmsupportingthehead‚Äù,
}, ‚Äúfurniture‚Äù:‚Äúsofa‚Äù
{ },
‚Äúskill‚Äù:‚Äúloco‚Äù, {
‚Äúemotion/style‚Äù:‚Äúdrunk‚Äù, ‚Äúskill‚Äù:‚Äúgetup‚Äù,
‚Äúcaption‚Äù:‚Äúwalkingdrunkenly‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúcaption‚Äù:‚Äúgetup‚Äù,
}, ‚Äúfurniture‚Äù:‚Äúfloor‚Äù
{ },
‚Äúskill‚Äù:‚Äúgetup‚Äù, {
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúskill‚Äù:‚Äútouch‚Äù,
‚Äúcaption‚Äù:‚Äúgetup‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúcaption‚Äù:‚ÄúLowtouchfromaproneposition‚Äù,
}, ‚Äúfurniture‚Äù:‚Äúlamp‚Äù
{ }
‚Äúskill‚Äù:‚Äúliedown‚Äù, ]
‚Äúemotion/style‚Äù:‚Äútired‚Äù, }
‚Äúcaption‚Äù:‚Äúlyingdown,legsstraight‚Äù,
‚Äúfurniture‚Äù:‚Äúbed‚Äù
}
]
}
Table7.ShortScriptExamplesofEmotionDrunkandRelaxed.
5Emotion:Happy Emotion:Hurried
Scene:Bedroom Scene:LivingRoom
{ {
‚Äúsummary‚Äù:‚ÄúThecharacterdiscoveredahiddentreasure ‚Äúsummary‚Äù:‚ÄúThecharacterhurriedlycleansup
inthebedroomandcelebratedjoyfully.‚Äù, inthelivingroomexpectingguestssoon.‚Äù,
‚Äúkeyframes‚Äù:[ ‚Äúkeyframes‚Äù:[
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúhappy,childish‚Äù, ‚Äúemotion/style‚Äù:‚Äúhurried‚Äù,
‚Äúcaption‚Äù:‚Äúrunandspin‚Äù, ‚Äúcaption‚Äù:‚Äúrushanxiouslyforward‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúfurniture‚Äù:‚Äútable‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äútouch‚Äù,
‚Äúemotion/style‚Äù:‚Äúhappy,childish‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äúskipstepsrunning‚Äù, ‚Äúcaption‚Äù:‚Äútouchmediumheight‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúfurniture‚Äù:‚Äúshelf‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äútouch‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúemotion/style‚Äù:‚Äúhurried‚Äù,
‚Äúcaption‚Äù:‚ÄúAnactofreachinghigh‚Äù, ‚Äúcaption‚Äù:‚Äúwalkwithlargesteps‚Äù,
‚Äúfurniture‚Äù:‚Äúcloset‚Äù ‚Äúfurniture‚Äù:‚Äúsofa‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äútouch‚Äù,
‚Äúemotion/style‚Äù:‚Äúhappy,childish‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äúexcitedwalk‚Äù, ‚Äúcaption‚Äù:‚ÄúAnactofreachinghigh‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúfurniture‚Äù:‚Äúlamp‚Äù
}, }
{ ]
‚Äúskill‚Äù:‚Äútouch‚Äù, }
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äútouchmediumheight‚Äù,
‚Äúfurniture‚Äù:‚Äúcabinet‚Äù
}
]
}
Table8.ShortScriptExamplesofEmotionHappyandHurried.
6Emotion:Stressed Emotion:Tired
Scene:LivingRoom Scene:Bedroom
{ {
‚Äúsummary‚Äù:‚ÄúThecharacterenteredthelivingroom, ‚Äúsummary‚Äù:‚ÄúThecharacterfelttiredandlaydownon
burdenedwithstressandseriousness, thebedinthebedroom.‚Äù,
tryingtofindsolacebysittingandlyingaround.‚Äù, ‚Äúkeyframes‚Äù:[
‚Äúkeyframes‚Äù:[ {
{ ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúemotion/style‚Äù:‚Äúthinking‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúcaption‚Äù:‚Äúupliftedheadwalking‚Äù,
‚Äúcaption‚Äù:‚Äúsmoothlyforwardwalk‚Äù, ‚Äúfurniture‚Äù:‚Äúfloor‚Äù
‚Äúfurniture‚Äù:‚Äúfloor‚Äù },
}, {
{ ‚Äúskill‚Äù:‚Äúsitdown‚Äù,
‚Äúskill‚Äù:‚Äúsitdown‚Äù, ‚Äúemotion/style‚Äù:‚Äúthinking,tired‚Äù,
‚Äúemotion/style‚Äù:‚Äúserious,stressed‚Äù, ‚Äúcaption‚Äù:‚Äúlegsextended,handsonfloorforsupport‚Äù,
‚Äúcaption‚Äù:‚Äúsittingupright,handsplacedonthighs‚Äù, ‚Äúfurniture‚Äù:‚Äúarmchair‚Äù
‚Äúfurniture‚Äù:‚Äúsofa‚Äù },
}, {
{ ‚Äúskill‚Äù:‚Äústandup‚Äù,
‚Äúskill‚Äù:‚Äúgetup‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúcaption‚Äù:‚Äústandup‚Äù,
‚Äúcaption‚Äù:‚Äúgetup‚Äù, ‚Äúfurniture‚Äù:‚Äúarmchair‚Äù
‚Äúfurniture‚Äù:‚Äúsofa‚Äù },
}, {
{ ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúemotion/style‚Äù:‚Äúthinking,stressed‚Äù, ‚Äúcaption‚Äù:‚Äúsmoothlyforwardwalk‚Äù,
‚Äúcaption‚Äù:‚Äúwalkingslowly,handsbehindback‚Äù, ‚Äúfurniture‚Äù:‚Äúfloor‚Äù
‚Äúfurniture‚Äù:‚Äúfloor‚Äù },
}, {
{ ‚Äúskill‚Äù:‚Äúliedown‚Äù,
‚Äúskill‚Äù:‚Äútouch‚Äù, ‚Äúemotion/style‚Äù:‚Äútired‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúcaption‚Äù:‚Äúlyingdown,legsstraight‚Äù,
‚Äúcaption‚Äù:‚Äútouchmediumheight‚Äù, ‚Äúfurniture‚Äù:‚Äúbed‚Äù
‚Äúfurniture‚Äù:‚Äúshelf‚Äù },
}, ]
{ }
‚Äúskill‚Äù:‚Äúliedown‚Äù,
‚Äúemotion/style‚Äù:‚Äústressed,uncomfortable‚Äù,
‚Äúcaption‚Äù:‚Äúlyingflatwithhandsoverbellyandkneesbent‚Äù,
‚Äúfurniture‚Äù:‚Äúsofa‚Äù
},
]
}
Table9.ShortScriptExamplesofEmotionSadandAngry.
7DirectGeneration ScriptMatching
Theme:Acharacterissittingonthechairandbecomesexcitedwhenhefindsthathewonalottery,soherunexcitedlyaroundthe
room.Andherelaxesonthesofa.
[{‚Äùskill‚Äù:‚Äùsitdown‚Äù, [{‚Äôskill‚Äô:‚Äôloco‚Äô,
‚Äùemotion/style‚Äù:‚Äùrelaxed,happy‚Äù, ‚Äôemotion/style‚Äô:‚Äôhappy,childish‚Äô,
‚Äùcaption‚Äù:‚Äùleaningback,legsstraight, ‚Äôcaption‚Äô:‚Äôskipstepsrunning‚Äô,
handssupportinghead‚Äù, ‚Äôfurnitures‚Äô:‚Äôfloor‚Äô},
‚Äùfurniture‚Äù:‚Äùsofa‚Äù}, {‚Äôskill‚Äô:‚Äôsitdown‚Äô,
{‚Äùskill‚Äù:‚Äùstandup‚Äù, ‚Äôemotion/style‚Äô:‚Äôrelaxed,calm‚Äô,
‚Äùemotion/style‚Äù:‚Äùneutral,calm‚Äù, ‚Äôcaption‚Äô:‚ÄôRestinghandsonthearmrests,legsspreadapart‚Äô,
‚Äùcaption‚Äù:‚Äùstandup‚Äù, ‚Äôfurnitures‚Äô:‚Äôarmchair‚Äô},
‚Äùfurniture‚Äù:‚Äùsofa‚Äù}, {‚Äôskill‚Äô:‚Äôstandup‚Äô,
{‚Äùskill‚Äù:‚Äùloco‚Äù, ‚Äôemotion/style‚Äô:‚Äôneutral,calm‚Äô,
‚Äùemotion/style‚Äù:‚Äùhappy,childish‚Äù, ‚Äôcaption‚Äô:‚Äôstandup‚Äô,
‚Äùcaption‚Äù:‚Äùrunwithopenarms‚Äù, ‚Äôfurnitures‚Äô:‚Äôfloor‚Äô},
‚Äùfurniture‚Äù:‚Äùfloor‚Äù}, {‚Äôskill‚Äô:‚Äôloco‚Äô,
{‚Äùskill‚Äù:‚Äùloco‚Äù, ‚Äôemotion/style‚Äô:‚Äôhappy,childish‚Äô,
‚Äùemotion/style‚Äù:‚Äùhappy,childish‚Äù, ‚Äôcaption‚Äô:‚Äôskipstepsrunning‚Äô,
‚Äùcaption‚Äù:‚Äùskipstepsrunning‚Äù, ‚Äôfurnitures‚Äô:‚Äôfloor‚Äô},
‚Äùfurniture‚Äù:‚Äùfloor‚Äù}, {‚Äôskill‚Äô:‚Äôliedown‚Äô,
{‚Äùskill‚Äù:‚Äùsitdown‚Äù, ‚Äôemotion/style‚Äô:‚Äôrelaxed,calm‚Äô,
‚Äùemotion/style‚Äù:‚Äùrelaxed,happy‚Äù, ‚Äôcaption‚Äô:‚Äôlying,leftfootonthefloor‚Äô,
‚Äùcaption‚Äù:‚Äùleaningback,legsstraight, ‚Äôfurnitures‚Äô:‚Äôsofa‚Äô},
handssupportinghead‚Äù, {‚Äôskill‚Äô:‚Äôgetup‚Äô,
‚Äùfurniture‚Äù:‚Äùsofa‚Äù}] ‚Äôemotion/style‚Äô:‚Äôneutral,calm‚Äô,
‚Äôcaption‚Äô:‚Äôgetup‚Äô,
‚Äôfurnitures‚Äô:‚Äôfloor‚Äô},
{‚Äôskill‚Äô:‚Äôloco‚Äô,
‚Äôemotion/style‚Äô:‚Äôhappy,childish‚Äô,
‚Äôcaption‚Äô:‚Äôskipstepsrunning‚Äô,
‚Äôfurnitures‚Äô:‚Äôfloor‚Äô},
{‚Äôskill‚Äô:‚Äôloco‚Äô,
‚Äôemotion/style‚Äô:‚Äôhappy,childish‚Äô,
‚Äôcaption‚Äô:‚Äôskipstepsrunning‚Äô,
‚Äôfurnitures‚Äô:‚Äôfloor‚Äô},
{‚Äôskill‚Äô:‚Äôloco‚Äô,
‚Äôemotion/style‚Äô:‚Äôneutral,calm‚Äô,
‚Äôcaption‚Äô:‚Äôsmoothlyforwardwalk‚Äô,
‚Äôfurnitures‚Äô:‚Äôsofa‚Äô},
{‚Äôskill‚Äô:‚Äôliedown‚Äô,
‚Äôemotion/style‚Äô:‚Äôneutral,calm‚Äô,
‚Äôcaption‚Äô:‚ÄôLegsarebentwhilelyingflat‚Äô,
‚Äôfurnitures‚Äô:‚Äôsofa‚Äô}]
FinalStory
Samsatonhissofa,relaxed,withhislegsstretchedoutandhands Asthesundippedlowerinthesky,castingwarmhuesacrosstheroom,
supportinghishead.Hisheartdidn‚Äôtdaretohope,butwhenheglanced Johnsatinhiscozylivingroomwithaticketthatcouldchangehislifeforever.
atthelotteryticketandthenumbersmatchedperfectly,hiscalmdemeanor Acautiousdialonthephonehadhisheartracing.Hisvoicetrembledwhen
shatteredintopurejoy.Jumpingup,Samstoodupfromthesofa,his theoperatorconfirmed,‚ÄôCongratulations,you‚Äôrethejackpotwinner!‚ÄôEuphoria
excitementundeniable.Heranaroundwithopenarms,likeachildset explodedwithinhimasheleaptupfromhischair,dancingaroundtheliving
free,spinninganddancingaroundtheroominajoyousblur.Hislaughter roomlikeacarefreechild.Hegallopedjoyfully,hisminddizzywithpossibilities.
echoedoffthewalls,therealityofwinningajackpotturninghisdaydreams Theroomechoedwithhislaughterandcheers,ashereveledinthemoment.
intotruth.Finally,utterlycontent,Samfloppedbackontothesofa,reclining Afterhisenergyslowlybegantowane,henestledintotheplushembrace
comfortablyagainwithhislegsstraightout,handsrestingunderhishead, ofthesofa,atranquilafternoonfadingintoasereneevening.Thetension
heartstillracingwiththethrillofhisunexpectedfortune. ofwaitingmeltedaway,leavingbehindarelaxed,fulfilledsenseofcalm.
Finally,Johnlayback,asoftsighescapinghislipsashegazedupattheceiling,
dreamsdancinginhiseyes.
Table10.DirectionGenerationvs.scriptmatching.Example1.
8DirectGeneration ScriptMatching
Theme:Acharacterissearchingforthejewelleryunderthebed.Hefindsitandhebecomesexcited,runaroundthehouse.
Hedecidedtodrinkabottleofwinethecelebrateandbecomesdrunkenandrestsonthesofa..
[ [
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúemotion/style‚Äù:‚Äúhurried‚Äù,
‚Äúcaption‚Äù:‚Äústeadilywalkingforward‚Äù, ‚Äúcaption‚Äù:‚Äúrushanxiouslyforward‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúfurnitures‚Äù:‚Äúcabinet‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äútouch‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äúsidestepping‚Äù, ‚Äúcaption‚Äù:‚ÄúAnactofreachinghigh‚Äù,
‚Äúfurniture‚Äù:‚Äúbed‚Äù ‚Äúfurnitures‚Äù:‚Äúcabinet‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúliedown‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúrelaxed,happy‚Äù, ‚Äúemotion/style‚Äù:‚Äúhurried‚Äù,
‚Äúcaption‚Äù:‚Äúlyingwithhandsunderhead,legscrossed‚Äù, ‚Äúcaption‚Äù:‚Äúwalkwithlargesteps‚Äù,
‚Äúfurniture‚Äù:‚Äúbed‚Äù ‚Äúfurnitures‚Äù:‚Äúbed‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúgetup‚Äù, ‚Äúskill‚Äù:‚Äútouch‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äúgetup‚Äù, ‚Äúcaption‚Äù:‚Äútouchlowheight‚Äù,
‚Äúfurniture‚Äù:‚Äúbed‚Äù ‚Äúfurnitures‚Äù:‚Äúbed‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúemotion/style‚Äù:‚Äúhappy,childish‚Äù,
‚Äúcaption‚Äù:‚Äúsmoothlyforwardwalk‚Äù, ‚Äúcaption‚Äù:‚Äúrunandspin‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúfurnitures‚Äù:‚Äúfloor‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúhappy,childish‚Äù, ‚Äúemotion/style‚Äù:‚Äúhappy,childish‚Äù,
‚Äúcaption‚Äù:‚Äúrunwithopenarms‚Äù, ‚Äúcaption‚Äù:‚Äúskipstepsrunning‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúfurnitures‚Äù:‚Äúfloor‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúhappy,childish‚Äù, ‚Äúemotion/style‚Äù:‚Äúhappy,childish‚Äù,
‚Äúcaption‚Äù:‚Äúrunandspin‚Äù, ‚Äúcaption‚Äù:‚Äúexcitedwalk‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúfurnitures‚Äù:‚Äúfloor‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äútouch‚Äù,
‚Äúemotion/style‚Äù:‚Äúdrunk‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äúwalkingdrunkenly‚Äù, ‚Äúcaption‚Äù:‚Äútouchmediumheight‚Äù,
‚Äúfurniture‚Äù:‚Äúfloor‚Äù ‚Äúfurnitures‚Äù:‚Äúcabinet‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúsitdown‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äútired,depressed,drunk‚Äù, ‚Äúemotion/style‚Äù:‚Äúdrunk‚Äù,
‚Äúcaption‚Äù:‚Äúlyingbackinchair,armsrelaxedatsides‚Äù, ‚Äúcaption‚Äù:‚Äúwalkingdrunkenly‚Äù,
‚Äúfurniture‚Äù:‚Äúsofa‚Äù ‚Äúfurnitures‚Äù:‚Äúfloor‚Äù
} },
]
Table11.DirectionGenerationvs.scriptmatching.Part1ofExample2.
9DirectGeneration ScriptMatching
{
‚Äúskill‚Äù:‚Äúsitdown‚Äù,
‚Äúemotion/style‚Äù:‚Äútired,depressed,drunk‚Äù,
‚Äúcaption‚Äù:‚Äúlyingbackinchair,armsrelaxedatsides‚Äù,
‚Äúfurnitures‚Äù:‚Äúchair‚Äù
},
{
‚Äúskill‚Äù:‚Äústandup‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äústandup‚Äù,
‚Äúfurnitures‚Äù:‚Äúchair‚Äù
},
{
‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúzombielike,drunk‚Äù,
‚Äúcaption‚Äù:‚Äúwalkwiththebodyleaningback‚Äù,
‚Äúfurnitures‚Äù:‚Äúfloor‚Äù
},
{
‚Äúskill‚Äù:‚Äútouch‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äútouchmediumheight‚Äù,
‚Äúfurnitures‚Äù:‚Äúlamp‚Äù
},
{
‚Äúskill‚Äù:‚Äúliedown‚Äù,
‚Äúemotion/style‚Äù:‚Äútired‚Äù,
‚Äúcaption‚Äù:‚Äúlyingdown,legsstraight‚Äù,
‚Äúfurnitures‚Äù:‚Äúsofa‚Äù
},
]
FinalStory
Ethanenteredhiscozybedroom,asenseofcuriosityurginghimtoinvestigate Thomashadbeensearchingfranticallyinthebedroomforthejewelrythat
thespacebeneathhisbed.Steadily,hewalkedforward,sidesteppingaroundthe hadbeencarelesslymisplaced.Hisheartracedasheoverturnedpillows
beduntilhelaydown,reachingforthespothehopedheldthetreasure.With andrummagedthroughdrawers,desperationmountingwitheachunsuccessful
joyinhiseyes,Ethanfeltthecooltouchofahiddenjewelrybox.Hegrinned attempt.Justwhenhethoughtallhopewaslost,Thomasnoticedaglimmer
withtriumph,gotupeagerly,andwalkedwithpurposethroughthehouse. underthebed.Stretchingouthishand,hegraspedthecovetedtreasureand
Hisheartraced,eachsteplighterthantheonebefore.Suddenly,aburst pulleditout,hisfacebreakingintoawidesmile.Elationconsumedhim;
ofexcitementovertookhim,andEthanspreadhisarmswide,runningjoyously hecouldn‚Äôtcontainhisexcitement.Runningaroundthehousewith
andspinningaroundasifhewereachildagain.Realizingthemomentdeserved newfoundenergy,hecelebratedhisdiscoveryjoyfully.Inhisexuberance,
celebration,hereachedforabottleofwine,savoringeachsipwithgratitude. Thomasdecidedtoindulgeinabottleofwine,toastinghimselfforthe
Butsoon,thewinetookitstoll,andhisstepsbegantoswaydrunkenly. successfulfind.Glassafterglass,hisinhibitionsmeltedaway,andhefound
Settinghimselfdownonthesofa,helethisarmsrelaxathissides, himselfstumblingthroughthehouse.Eventually,theeffectsofalcoholtook
feelingawaveofcalmwashoverhimasherestedinblissfulcontentment. theirtoll;hecollapsedontothebedroomfloor,chucklingtohimself,then
staggeredontothebed.Asthenightprogressed,hedriftedaimlesslyintothe
livingroom,theworldswayingaroundhim.Thomasallowedtiredness
toovertakehimandlaydownonthefloor,dreamingoffurtheradventurestocome.
Table12.DirectionGenerationvs.scriptmatching.Part2ofExample2.
10DirectGeneration ScriptMatching
Theme:Thecharacterpondersoveranoldphotographandreflectsonmemoriesinthelivingroom.Hethenremembershisdeadwife
andbecomessad.Hethendecidestodrinkabottleofwineandbecomesdrunkenandrestsonthesofa.
[ [
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúemotion/style‚Äù:‚Äúthinking‚Äù,
‚Äúcaption‚Äù:‚Äúsmoothlyforwardwalk‚Äù, ‚Äúcaption‚Äù:‚Äúupliftedheadwalking‚Äù,
‚Äúfurnitures‚Äù:‚Äúfloor‚Äù ‚Äúfurnitures‚Äù:‚Äúfloor‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúsitdown‚Äù, ‚Äúskill‚Äù:‚Äúsitdown‚Äù,
‚Äúemotion/style‚Äù:‚Äúthinking,stressed‚Äù, ‚Äúemotion/style‚Äù:‚Äúthinking,tired‚Äù,
‚Äúcaption‚Äù:‚Äúsittingwithheadbowed,handsrestingonthighs‚Äù, ‚Äúcaption‚Äù:‚Äúlegsextended,handsonfloorforsupport‚Äù,
‚Äúfurnitures‚Äù:‚Äúarmchair‚Äù ‚Äúfurnitures‚Äù:‚Äúarmchair‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äústandup‚Äù, ‚Äúskill‚Äù:‚Äústandup‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äústandup‚Äù, ‚Äúcaption‚Äù:‚Äústandup‚Äù,
‚Äúfurnitures‚Äù:‚Äúarmchair‚Äù ‚Äúfurnitures‚Äù:‚Äúfloor‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äútouch‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äúsmoothlyforwardwalk‚Äù, ‚Äúcaption‚Äù:‚Äútouchmediumheight‚Äù,
‚Äúfurnitures‚Äù:‚Äúfloor‚Äù ‚Äúfurnitures‚Äù:‚Äútable‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äútouch‚Äù, ‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚ÄúAnactofreachinghigh‚Äù, ‚Äúcaption‚Äù:‚Äúsmoothlyforwardwalk‚Äù,
‚Äúfurnitures‚Äù:‚Äúshelf‚Äù ‚Äúfurnitures‚Äù:‚Äúfloor‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúloco‚Äù, ‚Äúskill‚Äù:‚Äúliedown‚Äù,
‚Äúemotion/style‚Äù:‚Äúdrunk‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äúwalkingdrunkenly‚Äù, ‚Äúcaption‚Äù:‚ÄúLegsarebentwhilelyingflat‚Äù,
‚Äúfurnitures‚Äù:‚Äúfloor‚Äù ‚Äúfurnitures‚Äù:‚Äúsofa‚Äù
}, },
{ {
‚Äúskill‚Äù:‚Äúsitdown‚Äù, ‚Äúskill‚Äù:‚Äúgetup‚Äù,
‚Äúemotion/style‚Äù:‚Äútired,depressed,drunk‚Äù, ‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äúlyingbackinchair,armsrelaxedatsides‚Äù, ‚Äúcaption‚Äù:‚Äúgetup‚Äù,
‚Äúfurnitures‚Äù:‚Äúarmchair‚Äù ‚Äúfurnitures‚Äù:‚Äúsofa‚Äù
} },
] {
‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúconfident,thinking‚Äù,
‚Äúcaption‚Äù:‚Äúwalkingwithhandsplacedonthehips‚Äù,
‚Äúfurnitures‚Äù:‚Äúfloor‚Äù
},
{
‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúdepressed‚Äù,
‚Äúcaption‚Äù:‚Äúwalkwithdepression‚Äù,
‚Äúfurnitures‚Äù:‚Äúfloor‚Äù
},
{
‚Äúskill‚Äù:‚Äúsitdown‚Äù,
‚Äúemotion/style‚Äù:‚Äúsad,stressed‚Äù,
‚Äúcaption‚Äù:‚Äúsupportingheadwithhands,headbowed‚Äù,
‚Äúfurnitures‚Äù:‚Äúchair‚Äù
},
Table13.DirectionGenerationvs.scriptmatching.Part1ofExample3.
11DirectGeneration ScriptMatching
{
‚Äúskill‚Äù:‚Äústandup‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äústandup‚Äù,
‚Äúfurnitures‚Äù:‚Äúchair‚Äù
},
{
‚Äúskill‚Äù:‚Äútouch‚Äù,
‚Äúemotion/style‚Äù:‚Äúneutral,calm‚Äù,
‚Äúcaption‚Äù:‚Äútouchmediumheight‚Äù,
‚Äúfurnitures‚Äù:‚Äútable‚Äù
},
{
‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúdrunk‚Äù,
‚Äúcaption‚Äù:‚Äúwalkingdrunkenly‚Äù,
‚Äúfurnitures‚Äù:‚Äúfloor‚Äù
},
{
‚Äúskill‚Äù:‚Äúloco‚Äù,
‚Äúemotion/style‚Äù:‚Äúdrunk‚Äù,
‚Äúcaption‚Äù:‚Äúwalkingdrunkenly‚Äù,
‚Äúfurnitures‚Äù:‚Äútable‚Äù
},
{
‚Äúskill‚Äù:‚Äúliedown‚Äù,
‚Äúemotion/style‚Äù:‚Äútired‚Äù,
‚Äúcaption‚Äù:‚Äúlyingdown,legsstraight‚Äù,
‚Äúfurnitures‚Äù:‚Äúsofa‚Äù
},
]
FinalStory
Intheserene,mutedlightofthelivingroom,Jamesmovedforwardwitha Johnsatquietlyinthelivingroom,thedimlightcastingsoftshadowsaround
smooth,deliberategrace‚Äîawalkthatmirroredthecalmofhissurroundings. him.Inhishands,heheldanoldphotograph,edgeswornfromyearsoffond
Hepaused,loweringhimselfintotheoldarmchair,hishandsrestingheavily viewing.Itwasofhiswife,Mary,whosepresencehedearlymissed.Wavesof
onhisthighs,hisheadbowedasmemoriesfromaforgottenphotograph memorieswashedoverhim,momentsoflaughter,whispersshared,andthe
floodedback.Theimageofhisdeceasedwifeshimmeredinhismind‚Äôseye, comfortofsilentcompanionship.Apotentwaveofsadnessengulfedhisheart,
rekindlingasad,familiaracheinhischest.Risingwithaneutralcomposure, compellinghimtoseeksolaceinanuntouchedbottleofwine.Theliquidwas
hemadehiswaytotheshelf,reachinghightoretrieveaforgottenvintage atemporarybalm,warminghisthroatandnumbingtheacheinhischest.
bottleofwine.Soon,hisstepsfalteredintoadrunkenstumble,theroom Asthewinetookhold,hemeanderedaimlesslyaroundtheroom,eachstaggered
spinninggentlyaroundhimaslonelinessdrapedoverhisshoulders. stepatributetothelovehe‚Äôdlost.Eventually,exhaustionclaimedhim,and
Finally,hefellbackintothearmchair,hisbodysuccumbingtothetired, hefellontothesofa,surrenderingtothewearinessandwine.There,inthequiet
heavyfeelingofthewineandmemoriesminglingwithinhim.Hisweary sanctuaryoftheirsharedpast,Johnsuccumbedtoadrunkenslumber,cradled
armsfelltohissides,theroom‚Äôsgentlequietenvelopinghiminacomforting, bytheechoesofdaysgoneby.
ifmelancholic,embraceashedriftedintoanostalgicrest.
Table14.DirectionGenerationvs.scriptmatching.Part2ofExample3.
12