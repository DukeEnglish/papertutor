Focal Surface Holographic Light Transport using Learned
Spatially Adaptive Convolutions
ChuanjunZheng YichengZhan LiangShi OzanCakmakci KaanAkÅŸitâˆ—
UniversityCollege UniversityCollege MassachusettsInsti- Google UniversityCollege
London London tuteofTechnology USA London
UnitedKingdom UnitedKingdom USA UnitedKingdom
ABSTRACT simulationsandactualhardware.Ei-
Computer-GeneratedHolography(CGH)isasetofalgorithmic therlearnedorconventional,simulat-
methodsforidentifyinghologramsthatreconstructThree-Dimensi- inglightpropagationamongmulti-
onal(3D)scenesinholographicdisplays.CGHalgorithmsdecom- pleplanesina3Dvolumeiscomputa-
pose3Dscenesintomultiplanesatdifferentdepthlevelsandrely tionallydemanding,asa3Dvolume
onsimulationsoflightthatpropagatedfromasourceplanetoa isrepresentedwithmultipleplanes
targetedplane.Thus,forğ‘›planes,CGHtypicallyoptimizesholo- andeachplanerequiresaseparate
gramsusingğ‘›plane-to-planelighttransportsimulations,leading calculationoflightpropagationtore-
tomajortimeandcomputationaldemands.Ourworkreplacesmul- constructthetargetimage.
tiple planes with a focal surface and introduces a learned light Ourworkintroducesalearnedfo-
transportmodelthatcouldpropagatealightfieldfromasource calsurfacelightpropagationmodel
planetothefocalsurfaceinasingleinference.Ourlearnedlight thatcouldhelpfreelightsimulations
transportmodelleveragesspatiallyadaptiveconvolutiontoachieve fromplanedependence.Specifically,
depth-varyingpropagationdemandedbytargetedfocalsurfaces. our model can propagate a phase-
Theproposedmodelreducesthehologramoptimizationprocess only hologram represented with a
upto1.5x,whichcontributestohologramdatasetgenerationand planetoatargetedfocalsurface,see
thetrainingoffuturelearnedCGHmodels. Fig.1.Inourmodel,weextractSpa-
tially Varying (SV) depth features
CCSCONCEPTS ofafocalsurfacebylearningaset
ofSVkernels.Inaddition,ourmodel
â€¢Hardware Emergingopticalandphotonictechnologies;
â†’ combinestheseSVlearnedkernels
â€¢ Human-centered computing Displays and imagers; â€¢
â†’ withSpatiallyInvariant(SI)kernels
Computingmethodologies Computergraphics.
â†’ usingaSpatiallyAdaptiveConvolu-
Figure 1: Conventional
tion(SAC).Thus,effectivelycaptur-
KEYWORDS LightTransportVS.Proposed
ingSVandSIfeaturesoflightpropa- Focal Surface Light Trans-
Computer-GeneratedHolography,LightTransport,Optimization, gationoverafocalsurface.Ourwork port.(Source image: Tobi 87,
SpatiallyAdaptiveConvolutions,ConvolutionalNeuralNetworks makesthefollowingcontributions: Link:WikimediaCommons)
Learnedfocalsurfacelighttransportmodel.Byuniquely
1 INTRODUCTION â€¢
leveragingSACforCGH,weintroduceanewlearnedlighttrans-
Computer-GeneratedHolography(CGH)isafamilyofalgorithmic portmodel.Ourmodelidentifiesamappingfromaphase-only
methodsusedtogenerateholographicinterferencepatterns.Identi- hologramrepresentedoveraplanetoatargetedfocalsurface.
fyingtheseinterferencepatternsusinglearned[Shietal.2022]and Focal surface-based hologram optimization. To evaluate
â€¢
optimization[KavaklÄ±etal.2023a]CGHmethodsrequireconven- itspracticality,weutilizeourmodelfora3Dphase-onlyholo-
tionalsimulationsoflightpropagationfromplane-to-plane[Mat- gram optimization application. Compared with conventional
sushima and Shimobaba 2009; Shen and Wang 2006]. Recently, lightpropagationbasedhologramoptimizationmethods[KavaklÄ±
learnedproxymethods[Choietal.2021;KavaklÄ±etal.2022]have etal.2023a,b],ourapproachacceleratestheoptimizationpro-
been proposed to replace conventional light propagation meth- cessupto1.5x,leadingtospeedupbenefitsinhologramdataset
ods[MatsushimaandShimobaba2009;ShenandWang2006].As generationandtrainingfuturelearnedCGHmodels.
theselearnedproxymethodsforlightpropagationaretrainedus- ExperimentalValidation.Weevaluateourmethodinsimu-
â€¢
ingcamera-in-the-loopstrategies,theyareabletocaptureimper- lationforvariouspropagationdistancesandvalidatetheresult
fectionsofopticalhardware,closingthegapbetweentheoretical usingabench-topon-axisholographicdisplayprototype.
âˆ—denotescorrespondingauthor
2 FOCALSURFACELIGHTTRANSPORT
WeintroducetheSAC,amodifiedconvolutionstructureforencod-
This work is licensed under a Creative Commons
â€œAttribution-NonCommercial-NoDerivatives4.0Interna- ingSVfeatures.LeveragingtheSAC,ourworkenablesthelearned
tionalâ€license. focalsurfacelighttransportnetwork.
4202
tcO
9
]RG.sc[
1v45860.0142:viXraChuanjunZheng,YichengZhan,LiangShi,OzanCakmakci,andKaanAkÅŸit
Figure2:Ourproposedlearnedfocalsurfacelighttransportmodel.TheprocessstartswithaninputhologramHandafocal
s thu erf Sa pce atD iat lo lyg Aen de ar pa tt ie vesp Mat oi da ull ly ev (a Sr Ay Min )g toke ar cn he il es ve[V fi o] c, aw lh se ur re fağ‘– c= e0 l, ig1, h2 t,3 tri an nd si pca ot re ts .It nhe thin ed Se Ax Mo ,f Vsc 0a ,Vle ğ‘—s ,. VT ğ‘™h ,Vo ğ‘§se rek pe rr en se el ns ta kre eru nti el li sze ud sein
d
3 3 3 3
atdifferentspatiallocations,where0,ğ‘—,ğ‘™,andğ‘§indicatespecificpositions.(Sourceimage:Tobi87,Link:WikimediaCommons)
2.1 SpatiallyAdaptiveConvolution Initially,theSVkernelV R1 Ã—â„ Ã—ğ‘¤ Ã—ğ‘Ëœ Ã—ğ‘˜ Ã—ğ‘˜ isintroduced,theout-
âˆˆ
vS ota lund tia or nd aC lNon ev uo rl au lti No en t. wG oi rv ken (Ca Nn Nin ),p wut hf ee ra etu ğ‘Ëœr ,e â„ËœIËœ ,aâˆˆ nR dğ‘ ğ‘¤Ëœ ËœÃ—â„ rËœ Ã— epğ‘¤Ëœ rein sea ntC to hn e- p tiu at llc yh Aan dn ae pl ti is vese (t St Ao )1 kto err ne ed lu Acet âˆˆhe Rn ğ‘Ë†u Ã—m â„ Ã—b ğ‘¤er Ã—o ğ‘Ëœ Ã—f ğ‘˜p Ã—ar ğ‘˜am ise ct oer ms. pT uh tee dSp ba y-
multiplyingtheWandV,whichdefinedas:
numberofchannels,height,andwidthoftheinputIËœ(inourcase,
ğ‘Ëœ=3,ğ‘¤Ëœ =1080,â„Ëœ=1920),thediscreteconvolutionbasedonaSI A ğ‘,ğ‘¥,ğ‘¦,ğ‘ â€²,ğ‘¥ â€²,ğ‘¦ â€² =V 1,ğ‘¥,ğ‘¦,ğ‘ â€²,ğ‘¥ â€²,ğ‘¦ â€² W ğ‘,ğ‘ â€²,ğ‘¥ â€²,ğ‘¦ â€² , (2)
[ ] [ ]âˆ— [ ]
kernelW
âˆˆRğ‘Ë† Ã—ğ‘Ëœ Ã—ğ‘˜ Ã—ğ‘˜
isdefinedas: where1 â‰¤ğ‘ â‰¤ğ‘Ë†,1 â‰¤ğ‘ â€² â‰¤ğ‘Ëœ,1 â‰¤ğ‘¥ â‰¤â„and1 â‰¤ğ‘¦ â‰¤ğ‘¤.Eq.2en-
hancestheoutputchannelcapacityinVwhilemaintainingspatially
I [(cid:32)ğ‘ (cid:32)(cid:32)(cid:32),ğ‘¥, (cid:32)(cid:32)ğ‘¦ (cid:32)(cid:32)]= W (cid:32)(cid:32)(cid:32)(cid:32)[(cid:32)(cid:32)ğ‘ (cid:32)(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)ğ‘ (cid:32)â€²,ğ‘¥ (cid:32)(cid:32)(cid:32)â€²(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)ğ‘¦ (cid:32)(cid:32)(cid:32)(cid:32)â€²(cid:32)]IËœ [(cid:32)(cid:32)ğ‘ (cid:32)(cid:32)(cid:32)â€²(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)ğ‘¥ (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)+(cid:32)(cid:32)(cid:32)ğ‘¥ â€², (cid:32)(cid:32)(cid:32)ğ‘¦ (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)+(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ğ‘¦ (cid:32)(cid:32)(cid:32)(cid:32)â€²(cid:32)], (1) variant.BothVandWcanbeeitherpre-definedorlearned,making
ğ‘,ğ‘¥,ğ‘¦ thenetworkcontent-adaptive.ByusingA,theSACisdefinedas:
â€²âˆ‘ï¸â€² â€²
output SIKernel input
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)(cid:124) (cid:123)(cid:122) (cid:125) I [ğ‘,ğ‘¥,ğ‘¦ ]= A (cid:32)(cid:32)[(cid:32)(cid:32)ğ‘ (cid:32)(cid:32)(cid:32)(cid:32), (cid:32)(cid:32)ğ‘¥ (cid:32)(cid:32)(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)ğ‘¦ (cid:32)(cid:32),ğ‘ â€²(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)ğ‘¥ (cid:32)(cid:32)(cid:32)(cid:32)â€²(cid:32)(cid:32), (cid:32)(cid:32)(cid:32)ğ‘¦ (cid:32)(cid:32)(cid:32)(cid:32)â€²(cid:32)]IËœ [ğ‘ â€²,ğ‘¥ +ğ‘¥ â€²,ğ‘¦ +ğ‘¦ â€² ]. (3)
whereğ‘Ëœandğ‘Ë†indicatethenumberofinputandoutputchannels. ğ‘ â€², âˆ‘ï¸ğ‘¥ â€²,ğ‘¦ â€²
SAKernel
Theindicessatisfy1 ğ‘ â€² ğ‘Ëœand1 ğ‘ ğ‘Ë†.Thepair ğ‘¥ â€²,ğ‘¦ â€²
belongstothesetÎ© ğ‘˜â‰¤ ,whiâ‰¤ chspecifiesâ‰¤ ağ‘˜ â‰¤ ğ‘˜convolution( alwin) - SACretainsboththedim(cid:124)ensiona(cid:123)l(cid:122)cohere(cid:125)nceoftheSIkernelinCNN
( ) Ã— andisspatiallyvariantatthesametime.NotethatwhenWbecomes
dow.Thesummationoperationactsonallinputchannels,which
anall-onetensor,Eq.3isequivalenttotheSVconvolutioninCNN.
impliesthateachinputchannelcontributestoeveryoutputchannel.
AccordingtoEq.(1),thisoperationischaracterizedbyakernelthat 2.2 LearnedFocalSurfaceLightTransport
isspatiallysharedandcontent-independent.Learning-basedlight
WefirstgenerateSVkernelstoencodedepth-varyingfeaturesof
transportmodelscoulduseEq.(1)asabasicoperation.However,it
thefocalsurface,whicharelaterusedinSACforfocalsurfacelight
ischallengingforthismethodtoprojectahologramontoafocal
transport.Fortheschematicfigureofoursystem,pleaseseeFig.2.
surface.Aseachpixelonthehologramplanemaycorrespondtoa
SpatiallyVaryingKernelGeneration. AsshowninFig.2,theSV
differentdepthonthefocalsurface,whichmakestheSIkernela
s 2u 01b 9-o ],p it nim clual dc inh goi fc oe cuto sic na gp otu rr oe us t-p oa ft -i fa ol cly usva er ffy ei cn tg sdfe ua etu tore ds e[ pS tu he vt ara il -. k foe cr an le sl ug re fan ce era Dtion Rm
1
Ã—o 1d Ã—u â„le Ã—ğ‘¤tak ases int ph ue th s.o Wlo egr aa dm opH tedâˆˆ tR he1 Ã— a3 rÃ— châ„ iÃ— teğ‘¤ cta un rd
e
âˆˆ
ance.Atypicalsolutionistoemployalargenumberofparameters inRSGUNet[Huangetal.2018]forSVkernelgenerationmodule.
forfeatureencoding,resultinginanincreasedmemoryfootprint. Theoutputofeachdecoderlayerisintegratedwithfeaturemaps
Alternatively,wecouldconsiderusingSVconvolution[Suetal. fromdifferentlayersintheencoders.Thencombinedfeatureswill
2 p0 o1 r9 a; teZ sh te wn oge nt ea wl. d2 i0 m21 e] n. sT ioh ne sS â„V ,ğ‘¤ker inn te olV
SIâˆˆ
keR rğ‘Ë† nÃ— eâ„ l,Ã— wğ‘¤ Ã— hğ‘ eËœ Ã— reğ‘˜ Ã— â„ğ‘˜ ai nn dco ğ‘¤r- b oe fSfe Vd kin ert no eS lp sat Via ğ‘–ll ,y wV ha er ry ein Vg ğ‘–Fea Rtu ğ‘›r Ã—e ğ‘Ëœğ‘–( Ã—S ğ‘˜V Ã—F ğ‘˜) ,m ğ‘–o =du 0l ,e 1,t 2o ,l 3ea rern fera ss te ot
[ ] âˆˆ
indicateheight,andwidthoftheoutputfeature.However,relying differentscalelevels,ğ‘Ëœğ‘– denotestheinputchannel,ğ‘˜isthekernel
â„ ğ‘¤
solely on SV kernels may increase model capacity due to extra size,andğ‘› = 2ğ‘–
Ã—
2ğ‘– isthenumberofkernels.TheSVFmodule
parameters,particularlywhenâ„andğ‘¤ arelarge.Thesealternative containsconvolutionlayersandaveragepoolinglayers.Tomitigate
designsalldemandextranetworkcapacity. artifacts,wemodifytheglobalfeaturemodulein[Huangetal.2018]
toanattentionblockandapplyitatthebottleneckoftheU-Net.
SpatiallyAdaptiveConvolutionOperation. Toaddresstheseprob-
lems,weproposetheSAC.Ourmethodreducesthenetworkpa- FocalSurfaceLightTransport. WeleveragethegeneratedSVkernels
rametersbymultiplyingtheSVkernelwiththestandardSIkernel. tobuildourlighttransportmodulebasedonRSGUNet[Huangetal.FocalSurfaceHolographicLightTransportusingLearnedSpatiallyAdaptiveConvolutions
0mm Infocus Outoffocus Infocus 10mm Infocus Outoffocus Infocus
Figure3:Visualcomparisonofsimulatinglighttransportedontoafocalsurface(specifiedinthefirstrowofeachcase)at0mm
and10mmpropagationdistances.ThegroundtruthisobtainedviaASM[MatsushimaandShimobaba2009].Bothfocusedand
defocusedregionsindicatepoorperformanceoftheU-Netmodel.(Sourceimage:MattH.Wade,Link:WikimediaCommons)
2018].ThemoduletakesthehologramHasinputwithoutrequiring lighttransportmodelwithourfocal-surface-basedmodel:
depth,asthedepthfeatureofthefocalsurfaceisinherentlyencoded HË† argmin ğ¹ H,D ,ğ‘ R . (5)
withinthelearnedSVkernels.TointegratetheSVfeaturesinto â† H L( ( ) )
theencoder,weproposeaSpatiallyAdaptiveModule(SAM)based Inthiscase,thehologramoptimizationproblemissimplified.Our
onSAC.AsshowninFig2,wefirstreplacetheSIkernelWtoan approachsimultaneouslyoptimizesholograminthreecolorpri-
all-onestensorinEq.(2),whichignorestheSIkernelsandonly mariesandmaintainsphase-onlyatthesametime.
considerstheSVkernelstocapturetheoriginalSVinformation.
3 EVALUATIONANDDISCUSSION
Inparallel,weintroducetheSIkernelsbacktoEq.(2)asalearn-
ingparameterandmultiplywiththeSVkernelsforbetterdiverse We generate the focal surface light transport dataset based on
featureextraction.Thesefeaturesfromthetwooperationswillbe previous work [KavaklÄ± et al. 2023a,b] at the resolution 1920
Ã—
concatenatedtoformtheoutputofSAM.Finally,theglobalfeature 1080. See Section 1 of the supplementary material for more de-
moduleandthedecoderwillprocesstheoutputtogeneratethe tails. We use Adam optimizer ğ›½1 = 0.9,ğ›½2 = 0.999,ğ›¼ğ‘‘ğ‘’ğ‘ğ‘ğ‘¦ =
(
reconstructionatthegivenfocalsurfacedenotedasR. 0.5ğ‘ğ‘“ğ‘¡ğ‘’ğ‘Ÿ 50ğ‘’ğ‘ğ‘œğ‘â„ğ‘  .Themodelistrainedfor500epochs,with
Lossfunction. Weemploytheğ¿2normtoquantifythediscrepancy
aninitialLearningR) ate(LR)of2 Ã—10âˆ’4.Allexperimentsarecon-
ductedonasingleNVIDIAV10016GGPU.
between the reconstruction R and the target image Râ€². Both R
andRâ€²arefocalsurfacedependedimagereconstructions.SinceR Evaluation. Toassesstheimagequality,weutilizemetricsincluding
containsbothfocusanddefocusregions[KavaklÄ±etal.2023a],we PeakSignal-to-noiseRatio(PSNR),StructuralSimilarity(SSIM),and
utilizeabinarymaskMthathighlightsonlythefocuspartsofthe PerceptualSimilarityMetric(LPIPS)[Zhangetal.2018].First,we
image.Thelossfunctionforthereconstructiononasinglefocal
assessthequalityoflightsimulationonafocalsurface.Asshown
surface ğ· isdefinedas:
L inTbl.1,ourmodeloutperformsU-Net[Ronnebergeretal.2015]
Lğ· =ğ›¼ 0M âˆ¥R âˆ’Râ€² âˆ¥22 +ğ›¼ 1(1 âˆ’M )âˆ¥R âˆ’Râ€² âˆ¥22, (4) across all metrics. Fig. 3 shows that our model preserves more
high-frequency content than U-Net, providing finer details and
whereğ›¼0andğ›¼1representweights(ğ›¼0=1andğ›¼1=0.5).
sharperedges,closertothegroundtruth. Second,weutilizeour
2.3 OptimizingHologramswithFocalSurfaces
Table1:Evaluationofvariouslighttransportmodelsonour
Recently,learning-basedmethodshavebeenproposedtosolve3D dataset.Thespeedistestedbysimulatinganall-in-focus,
hologramgenerationtasks[Choietal.2021;Shietal.2022].How- full-color3Dimagewithsixdepthplanes.Notethathigher
ever,theideal3Dhologramfortheholographicdisplayhasnotyet
PSNR/SSIMandlowerParams/Speedindicatebetterperfor-
beenpreciselydefined[Kimetal.2024].Optimization-basedholo-
mance,denotedby and inthetables.
gramgenerationmethods[KavaklÄ±etal.2023a,b]couldpotentially â†‘ â†“
helpidentifytheideal3Dhologramandgeneratehologramdatasets
PSNR(dB) SSIM Params Speed
forlearning-basedapproaches.Typically,optimizationmethodsare Methods â†‘ â†‘ Stage â†“ â†“
0mm/10mm 0mm/10mm (M) (s)
basedonthemultiplanerepresentation,whereafull-colorholo- ASM(GT)[Matsushima
- - Two - 0.4559
gramissynthesizedbymakinguseofthephasepatternsofthethree andShimobaba2009]
colorprimaries.Followingpreviouswork[KavaklÄ±etal.2023b], U-Net[Ronneberger
29.662/30.112 0.8015/0.7760 Single 7.7760 0.0565
eachsingle-colorphasepatternisobtainedby: etal.2015]
Ours 36.016/34.279 0.9128/0.8470 Single 7.4446 0.0471
3
HË†ğ‘ argmin ğ‘’ğ‘–Hğ‘ Kğ‘2,ğ‘ Rğ‘ , (1) modelfora3Dphase-onlyhologramoptimizationapplicationunder
â† Hp ğ‘ âˆ‘ï¸=1L (cid:16)(cid:12) âŠ— (cid:12) (cid:17) 0ğ‘šğ‘špropagationdistance.Optimizinghologramswithsixtarget
(cid:12) (cid:12)
whereğ‘denotestheindexofacolorprimary,Hğ‘ istheSLMphase, planesusingAngularSpectrumMethod(ASM)[Matsushimaand
HË†ğ‘ istheoptimizedSLMphase,Kğ‘ isthewavelength-dependent Shimobaba2009]isdenotedasASM6,whileOurs4andOurs6
lighttransportkernel[MatsushimaandShimobaba2009],Rğ‘ isthe representoptimizinghologramsusingourmodelwithfourand
targetimageintensity,ğ‘  isanintensityscalingfactor(ğ‘  = 1by sixfocalsurfaces,respectively.Allhologramsarereconstructed
default), denotesconvolution.Wesubstitutetheconventional usingASMforperformanceassessment.AsshowninFig.4and
âŠ—
hturTdnuorG
sruO
teN-UChuanjunZheng,YichengZhan,LiangShi,OzanCakmakci,andKaanAkÅŸit
Ours6 ASM6
Rearfocus Frontfocus Rearfocus Frontfocus
Outoffocus Outoffocus Infocus Infocus Infocus Outoffocus Outoffocus Outoffocus Infocus Infocus Infocus Outoffocus
Figure4:VisualcomparisononsimulatedhologramsoptimizedusingASM6andOurs6under0mmpropagationdistance.All
hologramsarereconstructedusingASMforevaluation.(Sourceimage:JaimiePhillips,Link:WikimediaCommons)
Table2:ComparisonofimagequalityforthesceneinFig.4 comparedtozerodistance 0ğ‘šğ‘š .SeeSection3inthesupplemen-
amongASM6,Ours6,andOurs4acrossdifferentiterations tarymaterialformorecom( pariso) ns.Futureimprovementscould
at0mmpropagationdistance.NotethathigherPSNR/SSIM includeusingafactorizedlargerkernelforlong-distancepropaga-
andlowerLPIPS/Speed indicatebetterperformance. tion.Inaddition,ourmodelfocusesondepth-varyingpropagation
â†‘ â†“
withina3Dvolume,moreinvestigationisneededfordepth-varying
ASM6 /Ours6 Iteration propagationoftheentirevolumeusingconditionalnetworks.
/Ours4 50 100 200
Speed(s) 42.580/30.182/20.869 84.626/61.460/39.792 171.49/119.02/77.878 ACKNOWLEDGMENTS
â†“
PSNR(dB) 27.377/27.501/26.088 27.795/27.598/26.905 27.801/27.625/26.928
SSIM â†‘ 0.7100/0.6868/0.6142 0.7193/0.6933/0.6753 0.7195/0.6890/0.6767 Theauthorsthankreviewersfortheirvaluablefeedback;Louise
â†‘
LPIPS 0.3971/0.4747/0.5431 0.3894/0.4687/0.4707 0.3889/0.4787/0.4689 L.Xieforherfeedbackonthemanuscript;ZiyangChenandDoÄŸa
â†“
YÄ±lmazfortheirdiscussionsandassistance.WealsothankNorth-
Tbl.2,Ours6achievescomparableresultswithabout70%ofthe easternUniversityforcomputingresourcesforearlyexperiments.
optimizationtimecomparedtoASM6.ActualcapturesofOurs6
REFERENCES
andASM6inFig.5demonstratethecapabilityofourmodelfor
generating3Dholograms.Formoredetailsonthedisplayprototype SuyeonChoi,ManuGopakumar,YifanPeng,JonghyunKim,andGordonWetzstein.
2021.Neural3dholography:Learningaccuratewavepropagationmodelsfor3d
andcomparisons,seeSections2and3insupplementarymaterial. holographicvirtualandaugmentedrealitydisplays.ACMTransactionsonGraphics
(TOG)40,6(2021),1â€“12.
JieHuang,PengfeiZhu,MingruiGeng,JiewenRan,XingguangZhou,ChenXing,
PengfeiWan,andXiangyangJi.2018.Rangescalingglobalu-netforperceptual
imageenhancementonmobiledevices.InProceedingsoftheEuropeanconference
oncomputervision(ECCV)workshops.0â€“0.
KorayKavaklÄ±,YutaItoh,HakanUrey,andKaanAkÅŸit.2023a.Realisticdefocusblur
formultiplanecomputer-generatedholography.In2023IEEEConferenceVirtual
Realityand3DUserInterfaces(VR).IEEE,418â€“426.
Ours6 ASM6 KorayKavaklÄ±,LiangShi,HakanUrey,WojciechMatusik,andKaanAkÅŸit.2023b.
Multi-colorHologramsImproveBrightnessinHolographicDisplays.InSIGGRAPH
Figure 5: Comparing experimental captures of ASM 6
Asia2023ConferencePapers.1â€“11.
andOurs6under0mmpropagationdistances.(Sourceimage KorayKavaklÄ±,HakanUrey,andKaanAkÅŸit.2022.Learnedholographiclighttransport.
:JaimiePhillips,Link:WikimediaCommons) AppliedOptics61,5(2022),B50â€“B55.
DongyeonKim,Seung-WooNam,SuyeonChoi,Jong-MoSeo,GordonWetzstein,and
YoonchanJeong.2024. HolographicParallaxImproves3DPerceptualRealism.
ComputationalComplexityAnalysis. First,weassessthecomputa-
arXivpreprintarXiv:2404.11810(2024).
tionalcomplexityofsimulatingafull-color,all-in-focus3Dimage KyojiMatsushimaandTomoyoshiShimobaba.2009.Band-limitedangularspectrum
acrosssixdepthplanes.AsshowninTbl.1,conventionalASM- methodfornumericalsimulationoffree-spacepropagationinfarandnearfields.
Opticsexpress17,22(2009),19662â€“19673.
basedmodel[MatsushimaandShimobaba2009]requireseighteen OlafRonneberger,PhilippFischer,andThomasBrox.2015. U-net:Convolutional
forwardpassestosimulateafull-color,all-in-focus3Dimagewith networksforbiomedicalimagesegmentation.InMedicalimagecomputingand
computer-assistedinterventionâ€“MICCAI2015.Springer,234â€“241.
sixdepthplanes.Incontrast,ourmodelsimulatesthethreecolor-
FabinShenandAnboWang.2006.Fast-Fourier-transformbasednumericalintegration
primaryimagessimultaneouslyontoafocalsurfacewithasingle methodfortheRayleigh-Sommerfelddiffractionformula.Appliedoptics45,6(2006),
forwardpass,reducingsimulationtimeby10xandachievingbetter 1102â€“1110.
LiangShi,BeichenLi,andWojciechMatusik.2022.End-to-endlearningof3dphase-
image quality with fewer parameters compared to U-Net [Ron-
onlyhologramsforholographicdisplay.Light:Science&Applications11,1(2022),
nebergeretal.2015].Second,weevaluatehologramoptimization. 247.
In Tbl. 2, using four focal surfaces (Ours 4) to approximate six HangSu,VarunJampani,DeqingSun,OrazioGallo,ErikLearned-Miller,andJanKautz.
2019.Pixel-adaptiveconvolutionalneuralnetworks.InProceedingsoftheIEEE/CVF
planesforfocusanddefocusguidance,speedingupoptimization ConferenceonComputerVisionandPatternRecognition.11166â€“11175.
byupto2x.Increasingthenumberoffocalsurfacestosix(Ours6) RichardZhang,PhillipIsola,AlexeiAEfros,EliShechtman,andOliverWang.2018.The
unreasonableeffectivenessofdeepfeaturesasaperceptualmetric.InProceedings
achievescomparableresultswithabouta1.5xspeedup.
oftheIEEEconferenceoncomputervisionandpatternrecognition.
ChuanjunZheng,DamingShi,andYukunLiu.2021. Windowingdecomposition
LimitationsandFutureWorks. AsshowninFig.3,theperformance
convolutionalneuralnetworkforimageenhancement.InProceedingsofthe29th
of our model degrades at a long propagation distance 10ğ‘šğ‘š ACMInternationalConferenceonMultimedia.424â€“432.
( )
ï£³ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ï£² ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£± ï£³ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ï£² ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£±Focal Surface Holographic Light Transport using Learned
Spatially Adaptive Convolutions
CHUANJUN ZHENG,UniversityCollegeLondon,UnitedKingdom
YICHENG ZHAN,UniversityCollegeLondon,UnitedKingdom
LIANG SHI,MassachusettsInstituteofTechnology,UnitedStatesofAmerica
OZAN CAKMAKCI,Google,UnitedStatesofAmerica
KAAN AKÅITâˆ—,UniversityCollegeLondon,UnitedKingdom
Fig.1. Basedonpreviousworks[KavaklÄ±etal.2023a],weoptimizethehologramgivenanimageandits
correspondingdepthmap.ThehologramisreconstructedonsixdepthplanesusingASM.Subsequently,
wegeneratethefocalsurfacebyrandomlyassigningdifferentdepthvaluestothein-focusregions.Inthe
in-focusrestorationmodule,wesegmentthe3Dreconstructionsbasedonfocalsurfacesandmergetheminto
atargetimage,withamaskindicatingthefocusedareas.(Sourceimage:Tobi87,Link:WikimediaCommons)
1 DATASETGENERATION
WestartwithanRGBimageanditscorrespondingdepthmaptooptimizethehologramH,following
methodsfrompreviouswork[KavaklÄ±etal.2023a].Theoptimizationiscarriedoutwithtwodifferent
propagationdistances(0ğ‘šğ‘šand10ğ‘šğ‘š)attheresolution1920 1080.Forbothcases,wereducethe
Ã—
iterationcountstointroducenoiseintothehologram,whichisbeneficialforthemodeltolearnthe
high-frequencyinformation.Theoptimizedhologramisthenpropagatedontosixdistinctdepth
planes,producingsixreconstructions.Next,wegeneratethefocalsurfaceDbyrandomlyassigning
different depth values to the focused regions on these six depth planes. These depth values are
selectedfromauniformdistributionrepresentingsixdistinctdepthvalues.AsshowninFig.1,the
focalsurfaceisthenprocessedbytheIn-focusRestorationmodule,whichweextractthefocused
anddefocusedregionsfromthe3DreconstructionsandcombinethemintoasingletargetimageR
withthecorrespondingmaskM.Forthedataset,weuse300RGBimagesasthetrainingsetand
another100imagesforthetestset.ForeachRGBimage,wegeneratefivearbitraryfocalsurfaces,
resultingin1500trainingcasesand500testingcases.
2 DISPLAYPROTOTYPE
Webuildanon-axisholographicdisplayprototype
usingaphase-onlySpatialLightModulator(SLM)
with Fisba ReadyBeam Lasers (420, 520, and 638
nm). The SLM is aJasper Display SLM Research
kit (2400 by 4094 pixels and 3.74Âµm pixel pitch).
WebroughtopticalcomponentsfromThorlabsto
augmentourholographicdisplayprototype.
Fig.2. Animageofourholographicdisplayprototype
âˆ—denotescorrespondingauthor
1Zheng,C.etal.
3 VISUALRESULTS
0mm 10mm
Ours6 ASM6 Ours6 ASM6
Infocus Defocus Defocus Infocus Defocus Defocus Infocus Defocus Defocus Infocus Defocus Defocus
Defocus Defocus Infocus Defocus Defocus Infocus Defocus Defocus Infocus Defocus Defocus Infocus
Defocus Infocus Defocus Defocus Infocus Defocus Defocus Infocus Defocus Defocus Infocus Defocus
Fig.3. VisualcomparisononsimulationsbetweenASM6andOurs6atsixdepthplanesunder0mmand10
mmpropagationdistances.(Sourceimage:MartinKnÃ­Å¾e,Link:WikimediaCommons)
Ours6 ASM6
Fig.4. ComparingexperimentalcapturesofASM6andOurs6under0mmpropagationdistance.(Source
image:MartinKnÃ­Å¾e,Link:WikimediaCommons)
2
ï£³ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´
sucoFtnorF-snoitalumiS
sucoFdiM-snoitalumiS
sucoFraeR-snoitalumiS
ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ï£² ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£± ï£³ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ï£² ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£´ ï£±