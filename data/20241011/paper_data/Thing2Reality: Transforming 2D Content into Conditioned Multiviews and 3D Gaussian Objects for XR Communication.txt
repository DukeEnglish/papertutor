Thing2Reality: Transforming 2D Content into Conditioned
Multiviews and 3D Gaussian Objects for XR Communication
ErzhenHuâˆ— MingyiLi JungtaekHong XunQian
UniversityofVirginia NortheasternUniversity UniversityofVirginia GoogleResearch
Charlottesville,VA,USA Boston,MA,USA Charlottesville,VA,USA MountainView,CA,USA
eh2qs@virginia.edu li.mingyi2@northeastern.edu rsv5fd@virginia.edu xunqian@google.com
AlexOlwal DavidKim SeongkookHeo RuofeiDuâ€ 
GoogleResearch GoogleResearch UniversityofVirginia GoogleResearch
MountainView,CA,USA Zurich,Switzerland Charlottesville,VA,USA SanFrancisco,CA,USA
olwal@acm.org kidavid@google.com seongkook@virginia.edu me@duruofei.com
b
a c
Figure1:AnexampleusecaseofThing2Reality.AliceandCharliearediscussingroomdecorationsinasharedXRspace(b).
Alicebeginsbybringingashelffromherphysicaloffice(a)intothevirtualenvironment.Shethensearchesforacutecatplanter
usingthewebbrowserinterface.WithThing2Reality,shesummons3DGaussianoftheplanterandplacesitontothevirtual
shelf.AliceandCharliethenengageinadiscussionaboutvariousplanterdesigns,projecting3DGaussianrepresentationsof
theplanters(c)ontoawhiteboardinthespace.Thisallowsthemtotransform2Dimagesintointeractive3Dobjects,whichcan
becollectivelyviewed,manipulated,andcomparedinreal-time,facilitatingaseamlessandcollaborativeideationprocess.
ABSTRACT Thing2Reality,anExtendedReality(XR)communicationplatform
Duringremotecommunication,participantsoftensharebothdigital thatenhancesspontaneousdiscussionsofbothdigitalandphysical
andphysicalcontent,suchasproductdesigns,digitalassets,and itemsduringremotesessions.WithThing2Reality,userscanquickly
environments,toenhancemutualunderstanding.Recentadvances materializeideasorphysicalobjectsinimmersiveenvironmentsand
inaugmentedcommunicationhavefacilitateduserstoswiftlycreate sharethemasconditionedmultiviewrenderingsor3DGaussians.
andsharedigital2Dcopiesofphysicalobjectsfromvideofeeds Thing2Reality enables users to interact with remote objects or
intoasharedspace.However,conventional2Drepresentationsof discussconceptsinacollaborativemanner.Ouruserstudyrevealed
digitalobjectsrestrictsusersâ€™abilitytospatiallyreferenceitems thattheabilitytointeractwithandmanipulate3Drepresentations
inasharedimmersiveenvironment.Toaddressthis,wepropose ofobjectssignificantlyenhancestheefficiencyofdiscussions,with
thepotentialtoaugmentdiscussionof2Dartifacts.
âˆ—ProjectconductedwhenthefirstauthorinternedatGooglein2024.
â€ Correspondingauthor.
CCSCONCEPTS
Permissiontomakedigitalorhardcopiesofpartorallofthisworkforpersonalor â€¢Human-centeredcomputingâ†’Collaborativeandsocial
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation computing.
onthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored.
Forallotheruses,contacttheowner/author(s).
Arxivâ€™25, Arxivâ€™25 KEYWORDS
Â©2025Copyrightheldbytheowner/author(s).
extendedreality,augmentedcommunication,image-to-3D,infor-
ACMISBN978-x-xxxx-xxxx-x/YY/MM.
https://doi.org/10.1145/nnnnnnn.nnnnnnn mationartifacts,multi-modal,remotecollaboration
4202
tcO
9
]CH.sc[
1v91170.0142:viXraArxivâ€™25, Arxivâ€™25 ErzhenHu,MingyiLi,JungtaekHong,XunQian,AlexOlwal,DavidKim,SeongkookHeo,andRuofeiDu
1 INTRODUCTION â€¢ Thing2Realityapplications,whichofferinsightsforfu-
Sharedartifacts,includingdigitalresources(e.g.,text,images,videos), tureXRcollaborativeinterfacedesign.
andphysicalobjects(e.g.,prototypes,printouts),playacrucialrole â€¢ Findingsfromacomparativeuserstudy(ğ‘=12)evaluat-
infacilitatingeffectivecommunicationandideageneration.They ingtheeffectivenessofThing2Realityinsupportingspon-
providecommonspatialreferencepointsthatbridgegapsbetween taneous2D-to-3Dobjectgeneration,comparedto2Dsnap-
collaborators,enhancingcreativeexplorationandideation[4].Be- shotsfromdigitalandphysicalsources.
sidesphysicalartifacts,designersfrequentlyuseonlineplatforms
â€¢ Findingsfromanexploratoryuserstudy(ğ‘=18)exam-
likePinterestandGoogletosourcerelevantdigitalartifactsthatcan iningtheuseofThing2Reality(both2D-to-3Dand3D-to-2D
supporttheirdesignprocesses[13].However,usingsharedartifacts workflow)fordiscussingandpresentingboth2Dand3D
inremotemeetingsoftenposechallenges,especiallyinscenarios objectsinXRcommunication.
thatrequirequickandspontaneoussharing,suchasbrainstorming
sessions.First,artifactssharedviaremotemeetingsaretypicallyin 2 RELATEDWORK
2D,whethertheyarecapturedviacameraorretrievedfromonline
Ourworkisinspiredbypriorartonvision-languageinterfaces,
repositories,limitingtheunderstandingcomparedtointeractions
distributedcommunication,andtask-spacecollaboration.
withphysicalobjectsor3Dmodels.Second,inphysicalmeetings,
participantscaneasilyobserveandinteractwithtangibleartifacts,
whichfacilitatescreativeexplorationandideagenerationprocesses 2.1 Vision-LanguageInterfaces
[4].However,inremotemeetings,thislevelofinteractionisoften
2.1.1 GenerativeModels. Text-to-3Dandimage-to-3Dmethods,
unavailableorlimited.
suchasDreamFusion[43],focusonscoredistillationsampling(SDS)
Severalmethodshaveattemptedtoaddressthesechallenges,
thatutilizespretrained2Ddiffusionmodelstogenerate3Dcontent,
suchaspreparing3DmodelsinadvanceviaCADor3Dscanning
butfacesproblemswithspeedanddiversity.Recentadvancesin
[21],oremployingspecializedreal-time3Dcapturesetups[40,55].
largereconstructionmodels[16,29]usenon-SDSmethods.Large
Whileeffective,theseapproacheshavelimitations:pre-made3D
Gaussian Models (LGM) [54] use similar methods to [25], with
assetsdonotsupportspontaneoussharing,andspecializedsetups
algorithmstoconvert3DGaussianintomeshes.Advancesusing
areoftenimpracticalforgeneraluse.RecentadvancesinAI-driven
multi-viewdiffusionmodelsasapriorhavealsomadegeneration
text-to-3Dandimage-to-3Dtechnologies[54]presentanaccessible
ofcomplex,textured3Dmodelspossible.Thesegenerativemodels
andefficientalternative,loweringbarriersto3Dcontentcreation
provideafoundationfortransforming2Dvisualsinto3Drepresen-
andenablingbroaderparticipationincollaborativeefforts.
tations.
Inthispaper,weaimtounderstandhowimage-to-3DAIcan
mediateusersinXRcommunicationandhowthedesignofsuch
2.1.2 Text-BasedandSpatial-OrientedPrompting. Promptinghas
asystemcanbenefitusersandintegrateinteractiveimage-to-3D
been enabled by large language models primarily as a natural
workflowswithinvariousExtendedReality(XR)meetingcontext.
language-orientedwayofinteraction.However,text-basedprompts
WeintroduceThing2Reality,anXRcommunicationplatformthat
areconstrainedbythelevelofcontroltheycanprovide,especially
enablesfluidinteractionswith2Dand3Dartifacts.Thing2Reality
intermsofthespatialaspectsofimages[27].Modernpromptingin
allowsuserstosegmentcontentfromanysource(videostreams,
computervisionandmachinelearninghasevolvedtowardsspatial-
shared digital screens) within the XR environment (Figure 1a),
orientedprompting.Forexample,ControlNet[66]enablesusersto
generatemulti-viewrenderings(Figure1b),andtransformthem
conditionimagegenerationusingadditionalimagessuchasdepth
intoshared3DGaussiansforinteractivemanipulation(Figure1c).
mapsandhumanskeletons.Segment-Anything(SAM)[26]enables
WeevaluatedThing2Realityinauserstudyinvolvingthreetasks:
theuseofpointsandboxesinadditiontotextasawayofprompting
avatardecoration,furniturearrangement,andworkspaceorganiza-
masksegmentation.
tion.Ourfindingssuggestthatwhile3Dobjectsfacilitateintuitive
Toenableuserstograbcontentfromsharedmultimediaartifacts
explanationsandhands-oncollaboration,2Drepresentationsare
andtransformtheminto3Dgeneratedobjects,Thing2Realityuti-
moreoftenusedinfinalpitchdeliverables,suggestingatrade-off
lizesacontrollablepipelinethatallowsuserstoexplicitlyidentify
betweenthetwoformatsdependingonthecontextandpurposeof
areasofinterestusingspatial-orientedprompts,suchaspointsand
thetask.WedemonstrateapplicationsofThing2Realityinvarious
strokes.
workspaceandsocialscenarios,highlightinghowon-the-fly3D
generationcanenrichinteractionandsocialconnectedness,aug-
mentinghuman-humancommunicationregardingshareddigital 2.1.3 VisionandLanguageinComputerInterfaces. Recentwork
andphysicalartifacts. hasexploredvision-languagemethods,suchastext-to-imagegener-
Insummary,wecontribute: ation[32],in3Ddesignworkflowsandimagegenerationfornews
illustration[31],andinmediatinghuman-humanco-creationwith
creativitysupporttools[6,9,53].Forcommunication-relatedareas,
â€¢ Thing2Reality,anXRcommunicationsystemthatpro- VisualCaptions[33]utilizedlanguageinputtoretrieverelevant
videson-the-flyAI-mediated3Dobjectsgenerationbyen- imagesasvisualaidstoaugmenthuman-humancommunication.
abling users to present and share spontaneous thoughts, Theseimagescanbeusedassharedmediabetweenuserstofacili-
andaugmenttheirshareddigitalandphysicalartifactswith tatecommunication.However,theexistingvisualsofsharedmedia
remotepeers. andartifactshavenotbeenfullyexploitedintheseinterfaces.Thing2Reality Arxivâ€™25, Arxivâ€™25
Inthiswork,weusedbothtextpromptingandspatial-oriented thecreation,interaction,andsharingofAI-generated3Dobjectsto
promptingforidentifyingobjectsofinterestandsoughttounder- mediatehuman-humancommunicationinremotesettingsremain
standhowAI-mediated3DartifactscancontributetoXRcommu- under-explored.
nicationandcollaboration. Furthermore,priorworkhasusedextendedrealitytoassistre-
motephysicaltaskguidanceusingvirtualreplicas[39,56],which
2.2 DistributedCommunicationandTaskSpace wasfoundtobemoreefficientthan3Dannotationsinmixed-reality
Collaboration collaborationscenarios[56].However,thesestudiesfocusedmore
onthemanipulationandinteractionofpre-designed3Dvirtual
Peopleincreasinglyuseremoteconferencingplatforms[17â€“19,36]
objectsandthesupportofvirtualreplicasforspatialreferencing
forworkplacemeetings,education,entertainment,andsocialinter-
ratherthanhowthespontaneityof3Dobjectcreationcanenable
actionwithfamiliesandfriends.Thefieldofcomputer-mediated
betterdeliveryofhumanthoughtsandideas.
cooperativeworkhasinvestigatedtheimportanceofsharedme-
dia[8,34,35,42]duringin-personandremotecommunications,
3 DESIGNCONSIDERATIONS
especiallyinunderstandinghowpeopleuse,create,andsharemul-
timediaartifacts.Sharedtaskspacesareessentialforscenariossuch 3.1 DesignSpace
aseducation[37,37,45],creativitysupport[1],tabletopandtablet Wepresentthreedimensionsinarticulatingourdesignspace(Fig-
games[7,64,67],videoediting[38],andphysicaltaskdemonstra- ure2)andsituateThing2Realityintopriorliteratureofdistributed
tion[28,55]. communicationanddemonstrationof2Dand/or3Dartifacts.Prior
workalsoexploresdifferentwaysofcreatingpre-madeorcata-
2.2.1 AI-Augmented2DSharedTaskSpace. IllumiShare[24]en-
logassets,suchasusinggesturestoapproximateandimitatethe
ableduserstosharephysicalanddigitalobjectsonarbitrarysur-
object[15]amongadatabaseofknownobjects,orunderstanding
faces. Recent work such as ThingShare [19] enabled the digital
the role of virtual replicas in communication and remote assis-
copiesofphysicalobjectswithdeepneuralnetworktomediate
tance[39,56].Wedidnotincludethislineofworkbecausewe
remote communication and collaboration. Visual Captions [33]
focusedonthespontaneityofsharingthingsduringthecommuni-
alsosupportedsharedmediabyaugmentinglanguageasvisual
cationphase.
aidsbetweenusersinremoteconferencing.Otherworkhasex-
ploredmobilesharing[23]andreconstructionofmobilephone 3.1.1 Methods:CapturingversusGenerating. Thedistinctionsbe-
videostreams[58],butprovidingastableviewcanbechallenging. tweencapturingandgeneratingmethodsarerepresentedinFig-
TheadvancesingenerativeAIhaveenablednewopportunities ure2:Methods).
forblendingrealityandenablingcoarse-grainedandfine-grained
customizationofenvironments.Forexample,BlendScape[46]en- CapturingasVirtualReplicas. Thislineofworksupports
abledablendedvirtualenvironmentbymeaningfullymergingpeo- spontaneityof2Dand3Dartifactssharingviasnapshot-based,3D
pleâ€™svirtualbackgroundsusingin-paintingandimage-to-image reconstruction,orsearch-basedmethods,whichaimstocaptureand
techniqueswithselectiveregenerationofportionsinthe2Dvideo- reconstructthephysicalrealityasvirtualreplicas[19,20,30,47].
conferencingenvironment.However,priorworkhaseitherfocused Forexample,ThingShare[19]exploressnapshot-basedinteractions
on2Dvisualaidswithimagesretrievedbylanguagetoaugment to facilitate object-focused collaboration. Some other work uti-
communicationor2Dand3Dreconstruction/blendingofcapturing lizedreal-time3Dreconstructionwithsophisticatedcamerasetups
physicalsharedtaskspacesforremotecollaboration.Thepotential (e.g.,[30])orsinglecamerawithNeRF(e.g.,[47]).However,this
oftext-to-3Dandimage-to-3Dworkflowstotransformgenericar- lineofresearchfocusesoncloningthephysicalspaceforphysical
tifactsintointeractive3Dobjectsforcommunicationtasksremains tasksorremoteassistance,whereassharedinformationartifacts
under-explored. suchasdigitalimagesandvideosinthewebwerenotexplored.
2.2.2 EnablingSpatialityinRemoteandVideoConferences. 2.5D GeneratingasOn-the-FlyAssets. Differentfromcapturingor
and3Dvideo-conferencinghasbeenfocusedprimarilyonrecon- reconstructingsurroundingscenesorobjectsasreplicas,GenAIen-
structinganddisplayingoflife-sizedtalkingheads[51],gaze-aware ablednewopportunitiesforremotehuman-humancommunication,
3Dphotos[12],andspace-awarescenerenderingforavatarplace- specificallythetaskspacecommunicationinbothdigitalandphysi-
ment(e.g.,VirtualCube[68],ChatDirector[44]). calspace.Forexample,digitalimages,andsketches[33]canbeused
Differentfrom2.5Dand3Davatars,SharedNeRF[47]leverages foraugmentingspontaneouscommunicationwithLLM-enabled
photo-realisticandview-dependentrenderingwithNeRFandpoint digitalsearch.BlendScape[46]usedstablediffusionandin-painting
clouds,whichenablesanon-the-flyvolumetrictaskspace.Spa- techniquestoblendvirtualbackgroundsofuserstogetherasamean-
tialityinvideoconferencing[11]hasbeenexploredbycombin- ingfulcohabitedspace.Differentfromthesemethodsthatenabled
ingpersonvideoswithimmersivedesktopcollaborativevirtual 2Dvisualaidsor2Dvirtualbackground,Thing2Realityenables
environments.Thesespatialinterfaceswerefoundtopositively both2Dand3Dwith(primarily)image-to-3Dmethods.Further-
influencesocialpresenceandco-presencecomparedto2D,while more,weseparatetheseartifactsasdigitalvs.physicalforthedata
potentiallycompromisingtaskfocusandefficiency.Sousaetal.[49] source-astheseartifactscanbeeithersearched,ordrawninthe
exploredwaystomediateambiguityinworkspaceawarenesswhen digitalinformationspace(asvisualaidslike[33]),orimagestreams
interactingwith3Ddigitalassetsandfoundanincreaseinmental captureddirectlyfromthephysicalenvironment(forphysicaltasks
demandwhenconvertingcoordinatesbetweenframes.However, orobject-focusedcollaboration).Arxivâ€™25, Arxivâ€™25 ErzhenHu,MingyiLi,JungtaekHong,XunQian,AlexOlwal,DavidKim,SeongkookHeo,andRuofeiDu
3.1.2 Representation. Thecolumn(Figure2:Representation)dif-
ferentiatestheobjectrepresentations(2D-only,2D+3D,3D-only)
supportedbythesystem.However,mostobjectsexploredbyprior
individualsorcollaborativeworkandremoteconferencingarerep-
resentedas2D[19,24,33].Remixed-realitysupportsreal-time3D
reconstructionandprovidedscenemodifications[30].Somerecent
worksupport3Dscenesharingduringremotemeetings[47].
Thebidirectionalinteractionsbetween2Dimagesand3Dmodels
havebeenexploredinaugmentedreality[69],yetthe3Dmodels
arepre-loadedratherthanspontaneouslyidentifiedbytheuser,and
arethusnotincludedinthedesignspace.Furthermore,thislineof
workeitherexplorespre-madebidirectional2Dand3Dobjecttrans-
formationfromeitherthephysicalenvironment[10,61]orfrom
digitalassets[62,69].Furthermore,mostofthememphasizedindi-
vidualeditingratherthancollaborativeinteractions.Anexception
isLoki[55]thatprovidesdifferentdatamodalities(both2Dvideos
and3Dpoint-cloudscenes)ofphysicalspacesforscene-level(SL)
interactionswithpointcloudsandvideos,whereasThing2Reality
focusesonobject-level(OL)interactions.
Figure3:Human-humancommunicationmethods:1)textor
speech,2)sketch,3)imagesorvideoscanbeusedasinputto
achieveideal2Dimagesviadigitalsearch,image/videocap-
turing,orGenAI/MLmodels(text-to-image,sketch-to-image),
whichcanthenbeconvertedtoarbitrarysegmentedimage,
conditionedmultiviewrenderings,and3DGaussian.
of2Dartifactsfromdiversedatasourcesinto3Drepresentations.
Theseinputsfromavarietyofsourcesincludesdigitalfiles(such
asimages,andsketches)andphysicalobjectscapturedviacamera
feeds.
Figure2:DesignSpaceofThing2Reality:withtherowsof
DG2Cohabitation:SupportforCo-Habitationof2Dand
Scene-Level(SL)&Object-Level(OL)capturing,Scene-Level
3DObjectsDuringCommunication. Conventionalremotecon-
(SL)&Object-Level(OL)generating,andcolumnsforrep-
ferencingapproachesoftenrelyonasinglemodalityofcapture
resentationsofobjects.Leftrowsofthetableindicatethe
andpresentationdata(e.g.,2Dimages,2Dvideos)toteachorguide
difference between capturing and generating. Right rows
remoteparticipants[2].Loki[55]demonstratesthepotentialbene-
ofthetableindicatethedifferencebetweenscene-leveland
fitofincorporatingmultipledatamodalities.Tofacilitateefficient
object-level.
discussionsandcollaborativesessions,Thing2Realityshouldallow
formultipledatarepresentations.Bysupportinginteractionwith
Inbrief,weemphasizedtheroleofspontaneityinobject-level
multipledatamodalities,userscanchoosethemostappropriate
generationandcohabitationof2Dand3Dartifactsbyhelpingusers
representationfortheircurrentcommunicationneeds,leadingto
identifyobjectsofinterestsfrombothdigitalinformationspaceand
moreeffectivecollaboration.
physicalspacewithgenerativemethods.
DG3Transition:EnableFlexibleBi-DirectionalTransfor-
3.2 DesignGoal mationsAmongDigitalMediaForms(i.e.,2Dimages,videos,
and3D). XRworkspacescanbemoredynamicandopencompared
Basedonthedesignspace,weformulatedthefollowingthreeob-
totraditionalvideoconferencing,andthepresenceofmultipledata
jectivestodirectthedesignofThing2Realitytoenableefficientand
modalitiesmayintroducefrictionforusers.Recognizingthediverse
flexiblediscussionaroundartifactsinXRcommunication.
needsofremotecollaborationwithmultipledatamodalitiesinD2,
DG1 Spontaneity: Enable Spontaneous Communication itisalsoessentialtoallowuserstofrictionlesslyswitchbetween
UsingDigitalandPhysical3DArtifactsAsVisualAids. Ac- differentformsoftheserepresentations(2Dimages,videos,multi-
knowledgingtheimportanceofbothphysicalanddigitalartifactsin viewrepresentations,and3Dmodels)accordingtothecontextof
professionaldiscussions,weaimtofacilitateaseamlessconversion theirdiscussion.ThisrequirementwouldimplythatThing2RealityThing2Reality Arxivâ€™25, Arxivâ€™25
shouldnotonlystoreandorganizevariousformsofmediabutalso object.Furthermore,thiscanbebeneficialforitemswhenpart
allowfortheireasyretrievalandtransformationduringdiscussions. ofanobjectâ€™ssideisnoteasilycapturable,orwhenitâ€™sdifficult
Byenablingflexiblebi-directionaltransitionsbetweendigitalmedia tophotographatcloserange(e.g.,alargeshelf).
forms(2D-to-3D,3D-to-2D),userscanadapttheircommunication Transformingthesevariationsof2Dcontentinto3Dobjects
styletothespecificrequirementsofthetaskathand,leadingto canhelpenhancetheimmediacyandtangibleengagementwith
moreefficientandeffectivecollaboration. abstractconcepts,suchthatuserscangainadeepermutualun-
derstandingduringdiscussions.Furthermore,text-to-imageand
4 THING2REALITYSYSTEMOVERVIEW
sketch-to-imagegenerationmethodsoftenproducelesspredictable
Akeytakeawayfromourdesignspacehighlightedtheeffective- resultsduetothevaguenessoftheinputindescribingexpectedim-
nessofintegrating3Dobjectaffordanceswiththespatialorganiza- ages,makingprecisecontrolchallenging.Incontrast,searchingfor
tionadvantagesof2Dartifacts.Theworkspaceencompassesnot existingimagesorcapturingreal-worldcontentallowsformoredi-
justflatartifactsbutalsothree-dimensionalthings.Wedeveloped rectselectionandaccuracy.Thisdifferenceincontrolstemsfromthe
Thing2Realitytocapitalizeonthestrengthsof3Dartifactstofacili- interpretativenatureofAI-basedgenerationversusthespecificity
tatecommunicationbetweenindividuals,focusingontheutilization ofhuman-curatedordirectlycapturedvisualcontent.Recognizing
ofsurroundinginformationsurfaces(e.g.,tables,whiteboards).This thisdifferenceincontrolbetweenAI-basedgenerationandhuman-
systemintroducesthecapabilitytoseamlesslytransition3Darti- curatedordirectlycapturedvisualcontent,Thing2Realityâ€™sdesign
factsfrom2Ddigitalorphysicalcounterparts.Beforedelvinginto primarilyfocusesondigitalvisualcontentandcapturedreal-
thesystemâ€™sdesign,itiscrucialtoclarifythedefinitionofâ€œThingâ€ worldcontentwithimage-to-3Dapproaches.Thisensuresmore
inthecontextofourwork. precisecontrolovertheimagesusedincommunication,enhancing
thesystemâ€™sreliabilityanduserexperience.
4.1 Whattheâ€œThingâ€?ExploringtheRoleof
OurFocusonSpontaneousHuman-HumanCommunica-
User-Generated3DAssetsinSpontaneous
tioninXR:. Inlightoftheseinsightsfromourdesignspaceand
Communication
priorliterature,ourresearchfocusesontheexplorationofuser-
Inbringinguser-generated3Dassetsintodistributedhuman-human generated3Dassets.Thisfocusisdrivenbytheuniquepotential
communication,bridging2Dand3Dcounterpartsmayshapeanew oftheseassetstodisseminatetheessenceofabstractconceptsto
wayofcommunicationintheimmersiveinformationspace.We distributedXRusers.
aimtooutlinethetypicalapproachesindividualstakewhenspon- Weaimtoexplorethespontaneityofuser-generated3Dobjects
taneouslyincorporatingvariousartifacts(i.e.,sketches,searched fromanysourcesinfacilitatingdistributedXRcommunication.
images,andphysicalobjects)intodiscussionsasasourceofinspi-
ration,explanation,orclarification(Figure3). 4.2 InteractionWorkflow
â€¢ Text-based content (Figure 4 - 1): Text-based content uses Hereweshowthedefaultinteractionworkflowwiththeexample
wordsandlanguagetoconveyideas,includingwrittendescrip- ofdigitalsearch.
tions,transcribedspeech,andnotes.Text-basedcontentscan
InteractiveObjectSegmentation. Theusercanidentifyobject
betransformedinto2Dimagesusetext-to-imagemethodslike
ofinterestbyholdingthegripbuttonofthecontrollerwhilecap-
GeminiImagen.
turingapointdownandpointupeventwiththetriggerbutton,
â€¢ Hand-createdvisualcontent(Figure4-2):Hand-createdvi-
whichresultsinthreepointpositionsidentifiedonthedatasource
sualcontentencompassesmanuallyproducedimages,diagrams,
image(e.g.,awebbrowserview,oracamerafeed).Theobjectof
orvisualrepresentations,eitherphysicalordigital.Thisincludes
interestwillthenbesegmentedfromtheimagesource,andprovide
sketches,drawings,andhand-drawndiagrams,providingintu-
theuserthesegmentedresultsbesidestheirhands.Theusercan
itiveandspontaneousrepresentationsofideas,spatialrelation-
thenconfirmtosendtheimagesformulti-viewrenderingand3D
ships,orabstractconceptsincommunication.Currentmethods
Gaussiancreation.
such as ControlNet [66] use sketches as one of the ways for
controllingimagegeneration. 2D-to-3D:CreationofMulti-viewsand3DGeneratedOb-
â€¢ Digitalvisualcontent(Figure4-1):Imagesfoundthrough jects. Aftertheuserconfirmstheobjectofinterest,themultiple
onlinesearcheslikeGoogleimagesorPinterest,screenshots,and conditionedviewswillberenderedona2DPieMenu(Figure4b)
digitalartworkstockphotostofindimagesthatcloselyalign attachedtotheuserâ€™sleftcontroller.ThecenterofthePieMenu
withtheirdiscussiontopics,utilizingtheseimagesasareference showstheoriginalimagebeingcroppedfromthedatasource(web-
point[13]. views,imagesfromphysicalspace)orgeneratedfromtheimage
â€¢ Capturedreal-worldcontent(Figure4-3):Photographsor generationmodel.Thefourorthogonalviews,generatedwithcon-
scansofphysicalobjectsandenvironments,whichcanserveas ditioneddiffusionmodels,willbedisplayedonthetop(frontview),
apowerfulmeansofconveyingideas,buttheirintegrationposes left(sideviews),right(sideviews)andbottom(backviews)ofthe
challengesfordistributedusers[4,19],whomightopttodigitally outerringofthePieMenu.Selectingthecentralimagealsodisplays
captureandsharetheseitems.Itisimportanttonotethatthese a360Â°videooftheobject.Theusercanshoworhideitbypressing
digital3Drepresentationsofreal-worldcontentdonotalways theâ€œXâ€buttononthecontroller.Thegenerated3Dobjectwillthen
capturethespecificdetailsofanobjectasaccuratelyasavirtual becomeasharedobjectintheenvironment,whichcanbemoved,
replica(e.g.,NeRF).Instead,theyserveasaproxyfortheoriginal grabbed,andre-scaledbyalltheusersviathesemi-transparentArxivâ€™25, Arxivâ€™25 ErzhenHu,MingyiLi,JungtaekHong,XunQian,AlexOlwal,DavidKim,SeongkookHeo,andRuofeiDu
Figure4:Anexampleuserjourney:(a)auserbeginsbyselectingpreferredvisualstobringtoreality.Thisisachievedby
paintingonthedesiredregionwithinthewebbrowserorcamerafeedofthephysicalspace.Theseobjectsaresubsequently
processedthroughprogressivestages:startingfroma2Dsegmentedimage,evolvingintoconditionedmulti-viewrenderings,
andultimately,toa3DGaussianrepresentation.(b)Meanwhile,orthogonalviewsarelaidoutalongtheringsofthePieMenu.
(c)The3DGaussiansaresummonedafter1-2seconds.(d)Theusercanre-positionandre-scaleitviatheSphereProxy.
isdifferentfromthediscreteorthogonalviewsduetothecontinuous
perspectivesa3Dobjectpresents.
Userscanuseraycastingtodragthingsaroundthewhiteboard,
rescalingthingsbyselectingtheobjectandusingtheyaxisofthe
thumbsticktomakeitlargerorsmaller.Theycanalsodeletethe
objectbyselectingitandthenpressingontheâ€œBâ€buttononthe
controller.Userscanalsoselectthediscreteorthogonalviewson
theirprivate2Dmenu,whichcanbeprojectedonthewhiteboard.
Thecentralimagecanbeprojectedonthewhiteboardtoshow
360-degreevideosoftheobject.
Figure 5: 3D-to-2D Process: A user can capture snapshots 5 IMPLEMENTATION
fromdifferentperspectivesofthe3DGaussians,andproject
ThevirtualenvironmentwasdevelopedusingUnity2022.3.19f1
itonthewhiteboard.(a)Third-personperspective;(b)first-
andthefollowingSDKs:OculusInteractionToolkit,MetaAvatar
personperspective.
SDKforrenderingavatars,gestures,andlip-syncing,andPhoton
FusionandVoiceSDKforvoicestreamingbetweenavatars,and
ZEDSDKforphysicalspacesensing.
SystemSetup. ThestudyprogramranonadesktopPCwithan
IntelCorei7-13700KprocessorandanNVIDIARTX4070TiGPUfor
MobileSAM[65],text-conditioned[48]andimage-conditioned[60]
multi-viewdiffusionmodels,andLargeGaussianModels[54]to
fusemultiviewrenderingsintointeractive3DGaussians.
Figure6:Withvideosee-throughmode,userscanbringphys-
Duetotheprivacyissuesofcapturingdatafromphysicalenvi-
icalobjectsandsketchestothesharedspaceinXR.
ronmentsviacurrentpassthroughtechnologiesofVR/MRHMD,a
ZEDMinicamerawasattachedinfrontoftheMetaQuest3.
SphereProxy(Figure4c)asacollider.Theorthogonalviewsofa
3Dobjectonthe2DPieMenuareprivatetotheuserwhocreated
3DObjectRenderingPipeline. Theenhancementofextended
it,butitcanbeconvertedfromanyshared3Dobjectsgeneratedin
reality communication involves a blend of digital and physical
theenvironment.
elements,capturedthroughbothweb-basedsourcesandexternal
3D-to-2D:ProjectingThingstoSurroundingWhiteboard camerafeeds.
andTableforWorkspaceCommunication. Theusercantake Utilizingawebviewfeaturewithinavirtualspaceallowsforthe
a snapshot from any angles of the generated 3D objects, under seamlessincorporationofdigitalcontentinto3Dartifacts.Thisis
the field of view of the user, and project the point of view on achievedbyimplementingaUnitywebbrowserplugin[59].To
collaborativesurfaceslikeawhiteboardoratable(Figure5),which mergephysicalrealityintotheXRexperience,imageframesareThing2Reality Arxivâ€™25, Arxivâ€™25
Figure7:ImplementationDiagramofObject-LevelThing-to-3DbetweenUnityandPythonFlaskServer.
capturedusingtheZEDMinicamera1.Theseframesaretheninte- 6.1.2 3DDesignDiscussionandCo-Creativity. Inearlyprototyping
gratedintotheUnityenvironment,providingareal-worldcontext stages,Thing2Realitycantransform2Dreferencesinto3Dmodels,
thatuserscaninteractwithalongsidedigitalcontent. enhancingdesigndiscussions.Forinstance,aninteriordesigner
Hence,userscanidentifyobjectsinbothweb-basedcontentand couldcreate3Dfurnituremodelsorroomlayoutsfromreference
livecamerafeedscapturingphysicalspacesviaZEDandturnthe images(Figure1).Thisenablesclientstobettervisualizeproposed
identified2Dimagesinto3D.Thisincludestheabilitytoperform designsandcollaboratemoreeffectivelyondecisionsaboutma-
actionssuchasmakingstrokesortakingsnapshots.Interactions terials, colors, and spatial arrangements, fostering co-creativity
within the virtual environment are managed through a custom betweendesignerandclient.
eventlistenerviaaPythonFlaskserver.Theoriginalinput(Fig-
ure7:3)istheselectedimageframewiththethreepointsonthe 6.2 CustomizationforXRAvatars,Virtual
selectedimageframefilteredfromtheuserâ€™sstrokeinteraction Try-ons,and3DEmojis
usingtheraycasteroftheMetaQuest3controller.
6.2.1 AvatarDecorationandVirtualTry-ons. InXRmeetings,per-
The Unity application communicates with the Python Flask
sonalizingavatarsandenvironmentsiscrucialforimmersiveex-
ServerviaHTTPPOSTrequests(Figure7:4),activatingmodelsfor
periences.TraditionalGUI-basedcustomizationcanbelimiting.
quick,gesture-promptedsegmentation.Thisprocessidentifiesob-
Thing2Realityenablesuserstoquicklycreateorcustomize3Dob-
jectsofinterestbasedonuserinteractions.Oncesegmented,objects
jectsforavatarstowearorinteractwith(Figure8c),suchashats,
arevisualizedwithintheUnityenvironmentforuserconfirmation.
bags,orcoffeemugs.Thisfostersamorenaturalandengaging
Multi-viewrenderingand3DGaussianmodelingtechniquesare
environmentforvarioussocialgatheringsinXRspacessuchas
employedtocreatemoreinteractiverepresentationsoftheseob-
coffeechats,familymeetings,andgatheringsaroundfriends.
jects.The3DGaussianoutputwasaâ€œ.plyâ€format,butcanalso
berepresentedasa2Dvideo,oravisualeffectintheUnityenvi-
6.2.2 Personalized3DEmojisandMemes. While2Demojis,GIFs,
ronment.The3DGaussianwerethenimportedandvisualizedin
andmemesarewidelyusedinonlinecommunication,Thing2Reality
UnityasGaussiansplats,surroundedbyasemi-transparentsphere
allowsuserstotransformonlineimagesormemesintothe3Dver-
arounditasaproxycollidertoenableinteractionslikeGrab,Scale,
sion(Figure8d).Thisfeatureenhancessocialgatherings,andVR
andMovewithhandsorcontrollers.
livestreams,movingbeyondpre-designed3Demojislikethosein
MetaWorkroom.DifferentfromAppleâ€™snewestGenmojis2thaten-
6 APPLICATIONSCENARIOS
abled2Dtext-to-emojiintext-baseddigitalinteractions,Thing2Reality
Thing2Realitycanbeusedinadiversesetofapplicationstoele- enabledmoreintuitiveexpressionsduringvrmeetings.
vatetheexperiencesofthehuman-humancommunicationacross
workspaceandsocialgatherings. 6.2.3 Magic Book. Thing2Reality can be used to create a Mag-
icBook effect [3], augmenting book contents to aid discussions
6.1 WorkspaceDiscussion andenhancestorytelling.Forexample,inachildrenâ€™sbookabout
6.1.1 CollaborativeConceptExplanation. Thing2Realityenhances dinosaurs,Thing2Realitycouldbringillustrationstolifeasinterac-
conceptexplanationbyprovidingtangible3Dexplorationsofideas tive3Dmodels,allowingyoungreaderstoexplorethecreaturesâ€™
thatmaybedifficulttoconveywithstatic2Dimages.Forexample, anatomyandinteractwiththeminavirtualenvironment.Thisap-
inaproductpitchmeeting(Figure8a),adesignercouldquickly proachcreatesamoreengagingandimmersivereadingexperience
generatea3Dmodelfromasketchorreferenceimage.Thisal- forlongdistancesocialplay[22,64].
lowsstakeholderstointeractwiththeconceptfromvariousangles,
facilitatingmoreinformedfeedbackandeffectivebrainstorming.
2Genmojis: https://www.apple.com/newsroom/2024/06/introducing-apple-
1ZEDMini:https://store.stereolabs.com/products/zed-mini intelligence-for-iphone-ipad-and-mac/Arxivâ€™25, Arxivâ€™25 ErzhenHu,MingyiLi,JungtaekHong,XunQian,AlexOlwal,DavidKim,SeongkookHeo,andRuofeiDu
7.1 StudyDesign
The study employed a within-subject design that compared 3D
(Thing2Reality)and2D(Baseline)sharedartifactsduringimpromptu
discussions.Bothconditionsallowedformanipulationofobjects
(2Dvs.3D)uponconfirmationof2Dinteractivesegmentationfrom
datainputsources.Twodatasourcesweretestedinalltasks:cap-
turingthingsfromaprivatescreenwithdigitalsearch,andfrom
thevideocamerafeed(DG1).Thedesignofthe2Dconditionwas
inspiredbyThingShare[19],withadifferencethatthe2Dshared
segmentedartifactscouldbemanipulatedinthe3DspaceusingVR
controllers.Inthe3Dcondition,userscanmanipulate3Dshared
GaussianobjectswithVRcontrollers.ThestudywasIRB-approved.
RQ1:Howdothedifferencesbetweenthegenerated
3Dobjectsand2Dvirtualreplicaaffectusersâ€™under-
standing, exploration, and trust of an object when
bothcanbesimilarlymanipulatedinaVRenviron-
ment?
RQ2:Howdocreatingandusing3DGaussianobjects
fromdigitalandphysicalsourcesaffecttheeffective-
Figure8:Applicationscenarios:a)Workspacediscussion;b) nessofdiscussionsabouttheobjects?
Magicbookforcommunicationc)Avatardecoration,andd)
Fordependentvariables,weusedaquestionnairetoassessusersâ€™
3DMemesforsubculture.
experienceswithThing2Realityinsharedtaskspaces.Keymea-
suresincludedsatisfactionwiththeformat,comfortwithobject
control,trustinobjectrepresentation,easeofcommunication,and
effectivenessinconveyingandunderstandingobjectdetails.We
evaluatedthesefactorsforbothsharing(asthepresenter)andun-
derstanding(astheinquirer)objectinformation.Thequestionnaire
alsoaddressedthesystemâ€™simpactonclarifyingcomplexconcepts
andimprovingoverallsubjectunderstanding.Twoauthorscollabo-
rativelyanalyzedthequalitativedatausingAffinityDiagramming
toidentifymainthemesinusersâ€™responsesandstatisticallyan-
alyzedthesurveydatausingapaired-ttestbetween2Dand3D
condition(ğ›¼ =0.05).
7.2 Participants
Werecruited12participants(4female,8male)aspairsfromthe
universityviaemaillists.Participantsreportedmediumfamiliarity
withVR(Median=3,IQR=1;scale1-5).TheirVR/ARexperiences
primarilyinvolvedgaming(ğ‘ =4),onlinebrowsing(ğ‘ =2),and
researchparticipation(ğ‘ =2).Twoparticipantsnotedpriorsocial
meetupexperienceinAR/VRplatforms.Thein-personstudytook
around90minutespersession.Eachparticipantwascompensated
with$20USD.
7.3 StudySetupandProcedure
Pairsofparticipantswereinvitedtotworooms(seeFigure9)so
Figure9:StudySetupforthetworooms(a-b),whereeach
thattheycouldnotseeeachothernorthephysicalobjectsinthe
roomincludesaplanter,abookshelf/cabinet,aelectronic
otherroom.Allthesessionswerevideo-recorded.
object(hairdryer/drill),atoy.
Aftercompletingeachconditionandcontext,participantsre-
spondedtoanintermediatesurveyaboutthedrawbacksandbene-
fitsofthetried2Dor3Dformatandtheeffectivenessofthesystem
7 COMPARATIVEUSERSTUDY
incompletingthetasksusinga5-pointLikertscaleandopen-ended
WeconductedacomparativeuserstudytounderstandhowThing2Reality questions.Aftercompletingalltasks,afinalsurveycollecteduser
improvescommunicationaroundthesharedinformationartifacts preferencesoverdifferentconditionsandsubjectivefeedbackabout
(bothphysicalanddigitalitems),comparedto2Dobjects. thefeatures.Thing2Reality Arxivâ€™25, Arxivâ€™25
Figure10:SummaryofSurveyResults.Statementsweredividedintothreesections:A)general,B)presenterrole,andC)inquirer
role.
TutorialandWalkThrough(30min). Theexperimenterfirst studycompared2Dand3Dconditions.Participantsworkinpairsto
demonstratedhowtousethesystem.AfterexplainingtheVRen- decoratealivingroomusingamini2Dfloormap.Thetaskinvolves
vironmentandbasicinteractions,theexperimenterdemonstrated placingamixofreal-worlditems(suchasplantersandtoys)and
howausercancreate2Dand3Dvirtualobjectsfromanimageon digitallysourcedfurnitureonthemap.Inthe2Dcondition,par-
awebbrowser,andfromthephysicalspacecapturedthroughthe ticipantsbringthreeitems:adigitallysearchedchair,areal-world
ZEDMinicameramountedontheVRheadset.Participantswere bookshelf(subjecttodebate),andadigitalobjectoftheirchoiceto
thenaskedtoreplicatethedemonstrationthemselvestobecome placeonthebookshelf(placement).Afterarrangingtheseonthe
familiarwiththecontrols. mini-floorplan,participantsengageinabriefdebateoverwhich
bookshelftokeep.The3Dconditionfollowsasimilarstructurebut
Task1:ShowcaseandInquiryTask(30min). Theaimof usesdifferentitems.Eachparticipantbringareal-worldplanter,a
thistaskistounderstandhow3Dobjectscompareto2Dimagesin digitallysearchedteatable(fordebate),andareal-worldobjectto
facilitatingcommunication,objectmanipulation,andinformation placeontheteatable(placement).
sharingduringspontaneoussearchesanddiscussions.Thistask
simulatesabrainstormingsessionwhereaPresenterspontaneously
7.4 Findings
developsanideaforanabstractconceptorobject,searchesforit
online,andsharesitwithadistributedInquirer.TheInquirerwas 7.4.1 QuestionnaireData(Figure10). Overall,participantswere
instructedtoaskthePresenterthreespecificquestions:1)Couldyou satisfiedwithusingboth2Dand3Dformatstounderstandand
showmeallthecomponentsoftheobject?2)Couldyoushowme discusstheobjectswiththeirpartners,withthe3Dformathavinga
howyouwouldliketointeractwiththeobject?3)anopen-ended
slightbutnotsignificantadvantage(ğ‘„1:3ğ· :ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›=5,ğ¼ğ‘„ğ‘…=
question.Aftercompletingtheseinquiries,theparticipantsswitch
1)over2Dformat(ğ‘„1:2ğ· :ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›=4.5,ğ¼ğ‘„ğ‘…=1).Participants
roles.Inthe2Dcondition,thefirstPresentercapturesatoyfromthe reportedthatthe2D/3Dobjectrepresentationwasaccurateand
realworldandselectsananimalthroughdigitalsearch.Thesecond
reliable(ğ‘„3:2ğ· :ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›=4,ğ¼ğ‘„ğ‘…=2.5;3ğ· :ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›=4,ğ¼ğ‘„ğ‘…=
Presenterfindsacookingtooldigitallyandadrillfromthereal 2),exploring2D/3Dobjectswassimpleandintuitive,anddiscussing
world.Forthe3Dcondition,thefirstPresenterscansahairdryer themwasalsoanaturalprocess(ğ‘„4 : 2ğ· : ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› = 5,ğ¼ğ‘„ğ‘… =
fromtherealworldandchoosesanycookingtooldigitally.The 1;3ğ· : ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› = 5,ğ¼ğ‘„ğ‘… = 1).Inparticular,thereisasignificant
secondPresentercapturesananimaldigitallyandfindsatoyfrom difference in participantsâ€™ sense of control over 2D/3D objects,
therealworld. whereparticipantsfeltthattheyhadhigherlevelofcontrolover
3Dobjects(ğ‘„2 :ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› = 5,ğ¼ğ‘„ğ‘… = 1,ğ‘ < 0.05)than2Dobjects
Task2:CollaborativeFloorPlanningTask:(30min). The (ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›=4,ğ¼ğ‘„ğ‘…=2).
goalofthiscollaborativetaskistoexplorehowparticipantsinter- WhenparticipantsactedasPresenters,theyfounditeasyand
actandmakedecisionswhenarrangingbothphysicalanddigital effectivetodescribeboth2Dand3Dobjects,withnosignificant
objectsinasimulatedlivingspacefollowedbypriorwork[41].This challengeincommunication(ğ‘„7:2ğ· :ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›=2.5,ğ¼ğ‘„ğ‘…=2;3ğ· :Arxivâ€™25, Arxivâ€™25 ErzhenHu,MingyiLi,JungtaekHong,XunQian,AlexOlwal,DavidKim,SeongkookHeo,andRuofeiDu
Figure11:Thissequenceshowshowtheuseof3Dgeneratedobjectsalloweduserstointeractanddemonstrateobjectsintuitively;
andhowtheuseof3Dgeneratedobjectsenableda-b)(Inonedeployment)showcasinghuggingactionswith3DGaussian
objectsfromtherealworldtothevirtualspace;c)enlargingtheobject;d-g)anotherdeployment:showcasingtheuseofreal
lifeobjects(ahairdryer).
ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› = 2,ğ¼ğ‘„ğ‘… = 3.5),andwereabletoclarifyobject-related FacilitatingEffectiveCommunicationviaContextualVisu-
information (ğ‘„8 : 2ğ· : ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› = 4,ğ¼ğ‘„ğ‘… = 2; 3ğ· : ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› = alizationandSharedPerspectives. Inboth3Dand2Dsettings,
5,ğ¼ğ‘„ğ‘… = 1.5).Althoughnotstatisticallysignificant,participants participantscommentedthatthegeneratedobjecthelpedmakecon-
found3Dobjectsmoreeffectivefordescriptionandcommunication, versationsmoreengagedandeffectivebyestablishingin-contextvi-
andinteractionswereshownmoreaccuratelywith3D(ğ‘„6:2ğ· : sualization(3D)andcreatingsharedviews(2D).Participantsfound
ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› =4,ğ¼ğ‘„ğ‘… =2;3ğ· :ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› =5,ğ¼ğ‘„ğ‘… =1;ğ‘ <0.05).While that3Dobjectshelpedsimulatethereal-lifescenariobyproviding
participantsweresatisfiedwiththelevelofdetailinbothformats depthunderstandingandpreviewofhowobjectswouldbesituated
(ğ‘„5 : 2ğ· : ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› = 4,ğ¼ğ‘„ğ‘… = 2;3ğ· : ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› = 5,ğ¼ğ‘„ğ‘… = 1), inspace.Forexample,intheFloorPlanningTask,participantswere
theyfelt2Dobjectsmatchedexpecteddetailsbetter(ğ‘„9 : 2ğ· : abletoquicklyhaveasenseofthefurniturearrangementandits
ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› = 4.5,ğ¼ğ‘„ğ‘… = 1) than 3D objects (ğ‘„9 : 3ğ· : ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› = spatialconfiguration.P11describeditasanintuitiveprocess:â€œIcan
4,ğ¼ğ‘„ğ‘…=2).Here,wepresentfindingsoncommunicationdynamics, quicklyhaveasenseofhowtheroomâ€™sgonnalooklikewhenweput
expectationsregarding2Dversus3Dobjects,andthecomparative thefurniturethere,veryintuitiveâ€.
effectivenessofdigitalversusphysicalobjects. Furthermore,ourobservationsrevealedthatusersnaturallyem-
WhenparticipantsactedasInquirer,theyreportedthatboth2D ployed3Dobjectstoshowcaseactionsinthevirtualenvironment.
and3Dobjectsimprovedtheirunderstandingofthesubject(Q10; Forinstance,thesequence(Figure11)illustratesthefunctionalityof
2D:Median=4,IQR=1;3D:Median=5,IQR=1).Participantswere Thing2Reality,andsomeofitsusesbyparticipants.Forashowcase
satisfiedwiththelevelofdetails(Q11;2D:Median=4,IQR=3;3D: taskwith3Dcondition,P9capturedatoyduckfromherphysical
Median=4,IQR=1)andwereabletograspkeyfeaturesquickly.The environmenttoshowcasehowshewouldinteractwithittoher
3Drepresentationshowedaslightbutnotsignificantadvantage partner(P10).P9firstperformedahugginggesturewiththevirtual
onsuchobjectunderstanding.Inparticular,3Dobjects(ğ‘„12:3ğ· : duck(Figure11a),whichwasshownfromtheP10â€™sperspective
ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› =5,ğ¼ğ‘„ğ‘… =0;ğ‘ < 0.005)weresignificantlymoreflexible (Figure11b).P9thenenlargedthetoyducktohugagiantversion
insupportingparticipantslearningaboutdifferentobjectaspects ofit,sayingthatshe"...wouldmake[thetoy]thisbigandhugitâ€if
than2Dobjects(ğ‘„12 : 2ğ· : ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘› = 4,ğ¼ğ‘„ğ‘… = 3).Thiscould itwerepossibletodosoinreallife(Figure11c).Duringanother
beattributedtothecomprehensive3Dviewandflexibleobject deployment,P7foundawoodenspoon(Figure11d)fromGoogle
manipulation,suchasrotation. Search.Hethendemonstratedafeedingactiondirectedtowards
P8bymovinghishandtowardstheP8â€™smouth(Figure11e-f).He
startedanotherinteraction,mimingtheuseofahairdryeronthe
7.4.2 GeneralFeedback. Overall,intheShowcaseandInquirytask, P8.Hewavedthevirtualhairdryerwithside-to-sidemotiontypical
whenparticipantswerePresenter,10outof12participantspreferred ofreal-lifehairdrying(Figure11g). Differentfromdeploymentsof
using3Dformatover2Dtocommunicatewiththeirpartnersand 3Dconditionsthatshowcasedactions,participantsmainlypointed
whentheywereInquirer,9participantspreferred3Dformat.In tothe2Dimageswhenholdingthemintheirhand.
theCollaborativeFloorPlanningtask,10participantspreferred Inparticular,3Dobjectsweresignificantlymoreflexibleinsup-
interactingwith3Dobjects. portingparticipantslearningaboutdifferentobjectaspects(3ğ· :Thing2Reality Arxivâ€™25, Arxivâ€™25
ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›=5,ğ¼ğ‘„ğ‘…=0;ğ‘ <0.005âˆ—âˆ—)than2Dobjects(2ğ· :ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›= 3DGaussiansfor2D-to-3DGeneration:Digitalvs.Physical
4,ğ¼ğ‘„ğ‘…=3)(Q12).The3Dnatureoftheobjectsprovedparticularly Effectiveness. Participants reported varying experiences when
beneficial,offeringacomprehensiveviewthatcoveredallaspects convertingcaptureddigitalandphysicalitemsinto3DGaussian
oftheitemwithcontinuousrotations.Thisfeatureenhancedthe representations.Ingeneral,theyappreciatedthespontaneitythat
experienceforbothpresentersandinquirers,e.g.,P2explained,â€œI theycanturnbothphysicalanddigitalobjectsinto3DGaussian
couldturntheobjectaroundandlookatthedifferentfeaturesofitand artifacts as visual aids, which is aligned with our design goals
showhowIcaninteractwithitbetter.â€Forparticipantsactingthe (DG1).However,theeffectivenessoftheresulting3DGaussian
Inquirerrole,the3Drepresentationhelpedinoverallunderstanding objectsonsupportingcommunicationdifferednotablybetween
andresolvedpotentialconfusions.P9noted,â€œIcouldalsounderstand digitalandphysicalitems,withparticipantshighlightingdistinct
betterwhenthepresenterwaspointingatsomepartoftheobject.â€ considerationsforeachapproach.
Thissuggeststhatthe3Dformatfacilitatedclearercommunication Turningdigitalsearcheditemsinto3Dofferedparticipantsthe
andmoreeffectiveobjectexplorationbetweenparticipantsthat flexibilityofonlinesearch,unrestrictedbytheirphysicalsurround-
â€œmimicstherealworld...â€(P8). ings.Intheseinstances,participantswerelessconcernedabout
Despite the constraints of depth and volume for 2D objects, unexpectedresults,astheycouldnoteasilyfindalternativeperspec-
participantslikedthesharedviewof2Dwithlessdimensionsthat tivesofthe2Dobject,wheregeneratedviewpointsof3DGaussian
helpedparticipantspresentandunderstandideas.AsaPresenter, objectswereperceivedhighlyuseful.Thiswasparticularlyusefulin
P2statedthatâ€œLookingatthepictureandhavingthepersonseeittoo theFloorPlanningTask,whereparticipantscouldcompareonline
madeiteasiertobesuretheyhaveagoodideawhatIampresenting objectswithexistingitemsintheirspace.AsP1noted-â€œitâ€™shelpful
aboutâ€(P2).Duringinquiring,mostparticipantsalsofeltthatthe tobringinanyobjectsfromamazonforexampleandseewherei
2Dformatwaseasytounderstandandhelpedthemquicklyget wantitâ€(P1).However,someparticipantscomplainedaboutthe
anideaoftheobject,yetmostofthemconcernedaboutthatthey unpredictablesizeratio,eithertheoutputmadetheonlineobject
cannotseeitfromalltheviewpointsduringthepresentation. lookedmuchbiggeroritgotsmallerthantheythought.
Incontrast,theprocessofconvertingphysicalitemsintodigital
3DGaussianrepresentations,whilelimitedtoavailablereal-life
2DObjectReplicasvs.3DObjectGenerationswithUserEx- items,resultedinhigheruserexpectationsfordetailretentionand
pectations. Althoughparticipantsfound3Dgeneratedobjectsre- accuracycomparedtothedigitalitems.Participantsappreciatedits
alisticandhelpedmutualunderstanding,theyrecognizedtheweak- abilitytogenerate2D/3Doutputsfromreal-lifeobjects,especially
ness that the generated objects missed some features that they foritemsthatishardtomove,orlargeitemthatisimpossibleto
expected,orcontainedinaccurateorblurreddetails,makingthe capturesomeviewpointsatadistance.However,theycouldbe
resultmisalignedwiththeirexpectations.Thisisalsoalignedwith disappointedifimportantdetailsweremissingorthequalitywas
thesurveyfindingswhereparticipantsreportedthat2Dobjectscon- low,e.g.,P5statedthatâ€œthedetailsoftheobjectsgettingomittedâ€
tainedmoreexpectedandrelevantdetails(ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›=4.5,ğ¼ğ‘„ğ‘…=1) (P5). Despite these issues, participants valued the ability to use
than3Dobjects(ğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›=4,ğ¼ğ‘„ğ‘…=2)(Q9). physicalobjectsasreferencesandtocheckhowdigitalitemsmight
P9articulatedthischallenge-â€œThegeneratedpartontheback fitwiththeirexistingpossessions.Italsosupportedparticipantsto
fromthedigitalscanningandthesidepartoftheactualitemwasnot usephysicalobjectsasareferenceandcheckwhetherotherdigital
veryclearandithadatotallydifferentcolorfromwhatIexpected, itemsfitit.P9emphasizedthisadvantage-â€œIlikethatIcouldmix
whichmadeitalittledifficultformetoexplainthatitoriginally thephysicalobjectwiththedigitalobjectssinceIcanconsiderwhat
shouldnâ€™tbethiswayandhadtotellwhatisdifferentfromthemy couldgoalongwiththeactualstuffthatIalreadyownbyplacing
expectationsâ€(P9).Thisdisparitystemmedfromthe3DGaussian digitalitemsnexttotheactualobjectsâ€(P9).
modelâ€™sattempttopredictunscannedsidesofphysicalobjectsor
completepartialdigitalimages,sometimesresultinginunexpected 8 EXPLORATORYUSERSTUDY
additionsoromissionsofimportantfeatures.
Togaininsightsaboutthecommunicationdynamicsanduserbe-
Incontrast,2Dobjectrepresentationsdemonstratedgreateref-
haviorsaffordedbyThing2Reality,weconductedanIRB-approved
fectivenessinretainingcrucialdetailsfrombothphysicalobjects studywithanotherninepairsofusers(ğ‘ =18).Differentfromour
anddigitalimages.Thisresultedinrepresentationsthatarealigned
comparativestudyinunderstandingtheprosandconsofseparating
withtheoriginalitems.P3notedthatâ€œTheobjectresembledthe
3Dand2D(2Dversus2D-to-3D),thisstudyfocusedonhowthe
actualobjectsmorecloselyanddidnotloseimportantdetailsâ€(P3).A
coexistenceof2Dand3Dartifactssupportscommunicationdynam-
fewparticipantsmentionedthatthepreservationofthesedetails
ics.Weusedtaskslikeavatardecoration,furniturearrangement,
in2Dformatfacilitatedclearercommunication,e.g.,â€œitwassimple
andworkspacedemonstration,whichrequire3Dartifactsfortask
formeandhertocommunicateourobjectsanddetailswiththehelp
completion,weredesignedtoinvokethesedynamics.
ofobjectsinthesceneâ€(P1).
RQ3Howdousersuse2Dand3Dartifactsforspa-
Thesefindingssuggestthatwhile3DGaussianobjectsofferthe
tialarrangements,object-centereddiscussions,and
advantage of 3D visualization, they face challenges in meeting
presentationtasks?
userexpectationsforaccuracyanddetailpreservation.Incontrast,
2Drepresentations,thoughlackingindimensionality,provemore Furthermore,thestudyaimedtoevaluatetheentireworkflow
effectiveinmaintainingobjectfidelityandsupportingclearcom- ofThing2Realityâ€™s2D-to-3Dand3D-to-2Dprocesses,aswellasto
munication. understandusersâ€™comprehension,mentalefforts,conversationalArxivâ€™25, Arxivâ€™25 ErzhenHu,MingyiLi,JungtaekHong,XunQian,AlexOlwal,DavidKim,SeongkookHeo,andRuofeiDu
experience,andcommunicationandinteractionaround2Dand3D hasbeenusedbypriorwork[14]inunderstandingobject-focused
artifactsinanXRenvironment.Sincewefocusedonunderstand- interactionandcommunicationinvirtualenvironment.
ingthecommunicationdynamicsanduserbehaviorsaffordedby
8.2.3 IdeationandPitchTask(20min,Figure12d). Thetwopar-
Thing2Reality,whereuserswilluseboth2Dand3Dartifacts(DG2)
ticipantsengagedinaspontaneousdiscussionabouttoydesign
andfreelytransition(DG3)betweenthem(2D-to-3Dand3D-to-2D)
thatmimicsaworkspacescenario.Therewerethreephasesofthe
forcommunicationanddiscussioninthevirtualenvironment,re-
workspacetask:selectionphase,preparationphase,andpitchphase.
gardlessoftheinput(eitherbedigitalorcapturedphysicalcontent).
First,eachofthemsearchedatoyfromGoogleImagesanddecided
Weusedâ€œdigitalsearchâ€asanexamplefortheinputmethodto
whichtoytopitch.Theythenpreparedanelevatorpitchabout
maintaintheconsistentfidelityforinputmethods.
howtoplaywiththetoy.Weprovidedseveralexamplestothe
participantsasreference.Afterthepreparation,theyperformed
8.1 Participants
acollaborative2-minutepitch.Duringbothpreparationandpre-
Werecruited18participants(7female,11male)agedbetween22- sentationphases,theycouldusethewhiteboardand3Dobjectsas
29(ğ‘¥Â¯ = 26.1)throughtheuniversitymailinglist.Mostofthem assistance.
(ğ‘ =16)reportedbeingsomewhatormoderatelyfamiliarwithVR
technologies(Median=2,IQR=1,onascalefrom1to5).Regarding 8.3 Results
interactingwith2DartifactsinVR,themostcommon2Dartifacts ThequantitativeresultsarereportedinsubsectionA.1.Overall,
theyinteractedwithwerethroughwebpages(ğ‘ =4)andonline
participantslikedthattheycanspontaneouslyturnanyimages
searchesinabrowser(ğ‘ = 3).Thestudytookaround70to90 into3D,whichismorehelpfulthandedicatedmodels,e.g.,P10
minutespersession,andeachparticipantwascompensatedwith articulated-â€œ...usingonlineimageswashelpfulratherthansearch
$20USD. fordedicatedmodels.â€P18commented-â€œIlikeitsabilitytotake2D
thingsonthewebpageandconvertthemto3D,Ithinkitincreases
8.2 Procedure,Apparatus,andStudySetup myoptionstofindobjectsalotmore.â€Furthermore,twoparticipants
Ninepairsofparticipants(ğ‘ =18)wereinvitedtoaroomparti- mentionedthatthe2Dcroppingand3Dobjectgenerationhelped
preservetheprivacycomparedtosharingthewholescreen-P9
tionedintotwosections.Thestudyimplementationandappara-
mentioned-â€œyoucanseewhatyourpartneristalkingaboutevenif
tuscanbereferredtosection5.Uponcompletionoftheconsent
youcanâ€™tseethebrowser.itâ€™sgoodprivacyâ€
form,participantswereinstructedtostartwithawarm-uptask
andthencompletetwotasksthatcoverdifferentusecasescenarios 8.3.1 PreferencesandTrade-offsBetween2DMultiviews
ofThing2Reality.Figure12showsthesceneconfigurationandthe and3DGaussianRepresentations. Mostparticipants(ğ‘›=16)
tasks.Afterfinishingeachtask,participantswereaskedtofillout preferred3Dobjectsoverthe2DPieMenu(ğ‘›=2)withorthogonal
atask-relatedsurvey.Attheendofthestudy,weconductedsemi- views(Figure13).However,2DorthogonalviewsonthePieMenu
structuredinterviewswithparticipantstogainmoreinsightsonthe wereperceivedasbeingeasiertofollow,havingbetterimagequality,
benefits,limitations,experienceswith2Dand3Drepresentationof andbeingmorefamiliartointeractwith.Theâ€œunfoldedeffectâ€of
objects,andpotentialapplicationsofThing2Reality.Weconducted seeingdifferentperspectivestogetherinthePieMenuwasseenas
statisticalanalysisonthesurveyanswers,anddistilledinsights usefulandefficientbyoverhalfoftheparticipants,asitrequired
togetherwithparticipantsâ€™subjectivefeedback.Allthesessions lessmanipulationthan3Dobjects,e.g.,P2commented,â€œ2Dmenu
werevideo-recordedasfirst-personandthird-personviewsforthe gavemeaquickpreviewofviewsandtooklesseffortthanthe3D
post-studyanalysis. manipulationâ€.
Weprobedparticipantsâ€™perceivedcomprehensionandmental
8.2.1 Walkthrough&AvatarDecorationTask(30min,Figure12a-
effortsfortwophases:(P1)thephaseoftheirself-cognitiveand
b). Thetutorialprocedurewassimilartothecontrolledstudy.In
examinationprocesswhenorthogonalviewsand3DGaussians
addition,thetwoparticipantswereinstructedtosearchforper-
weregeneratedfromtheirselectedimage(astheobjectsaresponta-
sonalizedthingssuchashats,bags,umbrellas,andcoffeemugs
neouslygeneratedratherthanpre-prepared);(P2)thephasewhen
online,converttheminto3Dobjects,andusethemtodecorate
theyuse2Dsnapshotsand3DGaussianstocommunicatewiththeir
theiravatars.Wechosethistofamiliarizetheparticipantswithhow
partners.
basicimagescanbeusedtogeneratemulti-viewsand3DGaussians.
Afterdemonstratingwithseveralexamples,weencouragedthe P1:PersonalComprehensionPhase. Theparticipantsexpressed
participantstoconducttheirownsearchesforobjectstoconvert dividedopinionsoverthementaleffortsrequiredforcomprehen-
anduseasdecorationfortheiravatars. sionusingthePieMenuand3Dobjects.Whilemostparticipants
found3Dobjectsrequiringlessmentaleffect,afewparticipants
8.2.2 FurnitureArrangementTask(10min,Figure12c). Thetwo feltthat2Dorthogonalviewsmadeiteasiertounderstanddifferent
participantscollaboratedinasharedvirtualroomandsearched perspectives.Forexample,P10expressed,â€œEasiestisthe2Dmenu
online platforms for desired images of furniture. These images withorthogonalviews.Lesseasyis2Dscreenshots(snapshots)sinceI
werethenconvertedinto3Dobjectsandplacedwithinthevirtual havetoselecttherightviewandmoveitaround.Hardestis3Dview
environment.Throughverbalcommunicationanddiscussion,par- sincemovingchangeshowtheitemactuallylooks.â€Incontrast,P17
ticipantswererequiredtocollaborativelydecideontheselection stated,â€œ3Dobjectisquiteeasytounderstand,the2Dsnapshotsand
andplacementoffurnitureitems,andreachconsensus.Thistask orthogonalviewstakesomeefforttouse,andIdonâ€™tthinktheyareThing2Reality Arxivâ€™25, Arxivâ€™25
Figure12:StudySceneandTasksofThing2Realityfromfirst-personandthird-personviews:a)Overviewoftheimmersive
environment;b)Warm-uptask:avatardecoration;c)Furniturearrangementtask;d)Workspacetask:Toypitch.
ashelpfulas3Dobjects.â€Theremainingparticipantsfoundboth hands-onexperiencesandagreatersenseofrealism.P1mentioned,
optionseasytounderstand,withP4expressing,â€œ2Dissameasusing â€œitismuchmoredetailedthatithasallperspectives,soitiseasierto
computer,and3Disclosertoreality.â€ explainobjectsintuitively.Idonâ€™thavetotakemultiplescreenshotsof
Forpersonalcomprehensionofthegeneratedobjects,10partic- alltheperspectivestoexplainsomepartsoftheobject.â€Thisindicates
ipantsthoughtthat3Dobjectsweremoreintuitiveandstraight- thatwhile2Dmulti-viewsprovideaquickandeffortlesswayto
forward,while4preferred2Dsnapshotscontinuouslytakenfrom previewdifferentangles,themanipulable3DGaussianenablemore
anyangle,and2preferredorthogonalviewsdisplayedonthePie detailedandintuitiveexplanationsofobjectfeatures.
Menu(Figure13:Right-Top).Participantswholikedtheorthogonal
viewsonthePieMenumentionedthatitwasmoreunderstandable 8.3.2 Observation of Actual Usage of 2D and 3D During
astheycouldclearlyobservefoursidesoftheobject:â€œseethetop, PresentationPhase. Duringthestudy,weobservedthatpartici-
left,right,andbottommakesiteasiertoretrieve.â€Somepreferred2D pantsnotonlyused3Dobjectsfordiscussionbutalsofrequently
snapshotssincetheyfeltitwasfamiliarandeasiertoselectimages employedthemasaproxyforcreating2Dsnapshots.Thisfind-
fromdifferentsides,e.g.,â€œIthinkitâ€™seasytoselect2Dsnapshotsfrom ingalignswithourdesigngoalofenablingflexiblebi-directional
differentanglesâ€ (P14).Themajorityofparticipantswhopreferred transitionsinXRworkspaces(DG3).
3Dobjectsappreciatedtheauthenticity(ğ‘›=4),interactivity(ğ‘›=4), Intheworkspacetask,participantsgenerallypreferred3Dob-
andcomprehensiveperspectives(ğ‘› = 3)that3Drepresentations jectsfordiscussionduringtheirpitchpreparation.However,they
offer,whichlargelyoverlapwiththegeneralfeedbackthatthey oftenuse2Drepresentationsintheirfinalpitchdeliverables.Only
provided.Forexample,whilecompletingthetasks,twoparticipants threeoutoftheninepairsused3Dobjectsintheirfinalpitches,
specificallymentionedthedesiretohold3Dobjectsintheirhands mainlytodemonstrateobjectmotion,suchasshowcasingatoy
forbetterclarificationandpresentation,e.g.,P1shared,â€œThiswas carâ€™smovement.The3pairsswitchedbetween3Dobjectshowcase
demonstratedmorefullywhenconductingaworkspaceexperiment. toreferencing2Dartifactspinnedtothewhiteboard.
WhenIneedtopresentatoy,holdingitinmyhandismoresales- P2commentedonthecomplementaryrolesof3Dand2Drep-
orientedâ€,andP5discussed,â€œitâ€™seasiertoarguewhenyouhavethe resentationsinpresentations,stating,â€œForpresentation,3Dobjects
objectinhandâ€. arebetterforcommunicatingtheactionsorinteractionswithobjects,
while2Dcansupportabetterorganization.â€Thishighlightstheim-
P2:CommunicationPhase. Whenitcametothecollaboration portanceofhavingtheflexibilitytochoosethemostappropriate
andcommunicationphase,mostparticipants(ğ‘› = 12)preferred representationbasedonthespecificcommunicationneeds.Two
participantsmentionedthatincorporatingboth3Dand2Delements
3Dobjectsastheyfacilitatedintuitiveexplanationsandhands-on
inapresentationmightincreasethementaleffortrequiredfromthe
experiences.However,afewparticipantspreferred2Dsnapshots
(ğ‘›=2)forcollaboration,astheyprovidethesameperspectiveto presenter.However,mostofthemrecognizedthatthiscombination
couldbeavaluableadditionfortheaudience,asithelpsthembetter
everyonewithoutnavigatingaroundtheobject(Figure13:Right-
Bottom).P10commented,â€œThewaythingslookfromanyangleisthe understandthecontentbeingpresented.
same.Youdonâ€™thavetobestandinginonespecificspottoseewhat In brief, by allowing users to seamlessly switch between 3D
Iamseeing.â€Furthermore,2Dsnapshotswereseenasusefulfor and2Drepresentations,Thing2Realityempowersthemtoadapt
theircommunicationstyletothespecificrequirementsofthetask
professionaluseslikepresentations,astheymadeiteasiertoexplain
athand,whichleadstomoreeffectivecollaborationandclearer
particularpartsofanobjectwithoutmanipulatingthe3Dview.One
participantmentioned,â€œithelpedusprovidethebusinesspersonwith presentations.
multipleviewsoftheobjectâ€(P6),andP2added,â€œwhentryingto
explainaparticularpartoftheobject,Ithinkthesnapshotmadeit 9 DISCUSSION
easiertodosincewedidnâ€™thavetoturnthe3Dobjectandshowitto OurfindingsdemonstrateThing2Realityâ€™sabilitytoenhancecom-
theaudienceâ€™sperspective.â€ municationandcollaborationbytransforming2Dcontentintomul-
Ontheotherhand,theparticipantsfoundthat3Dobjectsfacili- tiviewrenderingsandinteractive3Dmodels,whichopensupnew
tatedcommunicationandmadeiteasiertoexplainthings,providing possibilitiesforengagingandimmersiveexperiences.Thing2RealityArxivâ€™25, Arxivâ€™25 ErzhenHu,MingyiLi,JungtaekHong,XunQian,AlexOlwal,DavidKim,SeongkookHeo,andRuofeiDu
notonlyfunctionsasaprototype,butalsoadvancesourunder- nothavephysicalcopiesintheirhand.Thesefindingshighlightthe
standingofhow2D-3Dcohabitationandtransformationenhances needforaccuratesizeestimationindigitalgenerationandimproved
communicationinXRmeetings. detailretentioninphysicalcapture.
Forphysicalobjectscanning,comparedtoexistingmethodslike
9.1 Is3DMoreEffectiveandEfficientfor NeRFandtraditional3Dreconstruction[47],ourapproachusing3D
Communication? Gaussiansplattingandmulti-viewdiffusionmodels,whilelacking
insomeaccuracy(sinceotherthreeviewpointsweregenerated),
Forthecomparativestudythatcompares2Dand3Dformats,partic-
demonstratedbettersupportforquickideademonstrationwithreal-
ipantsgenerallypreferred3DobjectsgeneratedbyThing2Reality
worlditems.Italsoshowedsuperiorperformanceandefficiency
over2Drepresentations,valuingtheirauthenticity,immersion,dif-
ingeneratingperspectivesoflargeobjects(e.g.,shelves)thatare
ferent perspectives, and interactivity. Furthermore, participants
challengingtocapture(whencertainsidesareoccluded,orneedto
showcasedhowtousetheobjectmoreintuitivelyin3Dcondition
captureatadistancetogetthewholepicture)withconventional
thanthe2Dcondition.
scanningmethods.
Duringtheexploratorystudythatexplorestheuseofboth2D
Theflexibilityofinputsourcesprovedcrucial,allowingusers
and3Dobjects,2Dorthogonalviewsandsnapshotswereperceived
toincorporatebothphysicalanddigitalobjectsintoconversations
aseasiertofollow,offeringbetterimagequality,andgreaterfamil-
seamlessly.However,balancinguserexpectationsforoutputqual-
iarity.Someparticipantsreportedthat3Dobjectscanpotentially
ity, particularly in size and detail accuracy for physical objects
occludeanotheruserâ€™sview,especiallyforface-to-faceconfigura-
intheirsurroundingspaces,remainsakeychallengeforfuture
tions,reflectingpriorfindingson2Dversus3Dspaces[11],whereas
development.
2Dsnapshotsontheinteractivewhiteboardcoercesaconsistent
perspectiveforallusers.
9.3 ThePotentialofGenerativeAIin
Furthermore,ourfindingssuggestthatthe2DPieMenuwith
fourorthogonalviewseffectivelysupportsanunfoldedspatialper- EnhancingObject-CentricXR
ceptionof3Dobjects.ExtendingthePieMenutoincludeadditional CommunicationExperiences
views,suchasthoseat45Â°intervalsforatotalofeightperspec-
The study highlights the potential of Generative AI in creating
tives,couldpotentiallyenhancespatialunderstandingbutincrease
authentic,immersive,andinteractiveobjectsharingexperiences.
cognitiveloads.
Participantsappreciatedtheabilitytospontaneouslyturn2Dim-
While3Dobjectsweregenerallypreferredfortheirintuitive-
ages into 3D objects, which expanded their options for finding
ness,realisticdetail,andspatialinteractivity,2Drepresentations
andsharingobjects.Generated3Dobjectsalloweduserstobetter
excelledinquickperspective-switching,consistentviewpointsfor
understandthefunctionalityanduserexperienceofthesharedob-
collaboration,andstaticpresentationformats.Ourfindingsindicate
jects,asiftheywerereal.ThisfindingsuggeststhatGenerativeAI
thatusersvaluedaccesstoboth2Dand3Drepresentations,aseach
couldsignificantlyenhanceobject-sharingexperiencesbyoffering
fulfillsdistinctpurposesandusecases.Thissuggeststhatbalancing
moreengagingandintuitivewaystocommunicateandcollaborate
2Dand3Drepresentationscanoptimaluserexperiencesinobject
aroundobjects.
sharingandcollaborationscenarios.
Someparticipantsnotedthatthecroppingand3Dobjectgener-
Furthermore,2Dartifactsprovedparticularlyusefulduringthe
ationfeaturesofthesystemhelpedpreserveprivacycomparedto
pitchphaseoftheworkspacetask.Thesefindingshighlightthe
sharingthewholescreen.ThishighlightsthepotentialofThing2Reality
potentialforflexiblebi-directionaltransitionsamongdigitalmedia
inaddressingprivacyconcernsincollaborativeenvironments.How-
formsinXRworkspaces.Byenablinguserstoseamlesslyswitch
ever,participantsalsomentionedunexpectedeffectsfromThing2Reality,
between3Dand2Drepresentations,Thing2Realityallowsusersto
particularlytheGenAImodels,suchastheadditionofunclearor
adapttheircommunicationstyletothespecificrequirementsofthe
unexpectedelementstothegenerated3Dobjects.Thispointsto
task,fosteringmoreeffectivecollaborationandclearerpresenta-
challengesrelatedtotheaccuracyandinterpretabilityofgenerated
tions.
content.
9.2 ExpectationofGeneratedObjectsfor
10 LIMITATIONSANDFUTUREWORK
Physicalvs.DigitalObjects
VisualizationofAbstractIdeas. Thing2Realityhaslimitationsin
Weexploredtwodatasourcesincludingphysicalobjectcapturing visualizingabstractideasandconceptsthatlacksclearphysical
anddigitalsearchasinputtechniquesforcreating2Dor3Darti- representations. This can pose challenges and lead to potential
facts.Participantsfoundbothmethodsintuitiveandappreciatedthe inaccuraciesinprofessionalcommunicationscenarios,suchasa
flexibilitytosourceobjectsfromonlinesearchesandtheirphysical delicatemedicaldiagnosis[50].Futureworkcouldexplorewaysto
surroundings.Theabilitytocombinephysicalanddigitalobjects representabstractconceptsmoreeffectively,perhapsthroughthe
enhancedengagementandcommunicationeffectiveness. useofmetaphorsorsymbolicrepresentations.
Whilephysicalobjectcapturingofferedrealisticreferences,par-
ticipantsdesiredmoredetailandaccuracy.Convertingdigitalob- FidelityofObjects. Thefidelityofgenerated3DGaussianscanbe
jects(fromdigitalsearch)into3Dprovidedawidevarietyofitems improvedbyincreasingtheinputdensity.However,thatwillresult
sincemostitemsonlyhaveoneperspective/viewpointavailable in more time spent on the rendering for the current state [63].
only,butunpredictablesizingwasachallenge,sinceparticipantsdo FutureworkcouldinvestigatetheintegrationofthesemethodsThing2Reality Arxivâ€™25, Arxivâ€™25
withThing2Realitytoimprovethevisualqualityofthegenerated 3Dobjectrepresentationshasthepotentialtosignificantlyenhance
objectswhilemaintaininginteractiveperformance. discussions.
Priorworkexploredfabricatingon-screenvirtualobjects[57] Thing2Realityisoneofmanynecessarybuildingblockstowards
forgamesettings,whichalsoshowsthepotentialofthissystem. increasinglyrealisticco-presenceinXR,andwehopethatourwork
Oncethegenerated3DGaussiansareturnedintomesh,theycan willinspirecontinuedworkinthisexcitingdomain.
potentiallybeconvertedintoreal,tangible,3D-printedobjectsin
thephysicalreality.Thisopensupexcitingpossibilitiesforrapid REFERENCES
prototypingandphysicalvisualization,butisnotunderthescope
[1] Sang-GyunAn,YongkwanKim,JoonHyubLee,andSeok-HyungBae.2017.
ofthiswork. CollaborativeExperiencePrototypingofAutomotiveInteriorinVRwith3D
SketchingandHapticHelpers.InProceedingsofthe9thInternationalConference
Object-LevelversusScene-Level3DGaussian. Whileoursystemex-
onAutomotiveUserInterfacesandInteractiveVehicularApplications(Oldenburg,
Germany)(AutomotiveUIâ€™17).AssociationforComputingMachinery,NewYork,
plored3Dobject-levelinteractions,Gaussiansplattingcanalsobe
NY,USA,183â€“192. https://doi.org/10.1145/3122986.3123002
usedtogenerate3Dscenes[25].Thiscanbeextendedtotheexplo- [2] FraserAnderson,ToviGrossman,JustinMatejka,andGeorgeFitzmaurice.2013.
rationoftheworldofminiatures[5,52]utilizingthecurrentstate YouMove:enhancingmovementtrainingwithanaugmentedrealitymirror.In
Proceedingsofthe26thAnnualACMSymposiumonUserInterfaceSoftwareand
oftheart.However,thiswouldrequiremoreexplorationintothe Technology(St.Andrews,Scotland,UnitedKingdom)(UISTâ€™13).Associationfor
manipulationandpotentialprosandconsofinteractingwith3D ComputingMachinery,NewYork,NY,USA,311â€“320. https://doi.org/10.1145/
2501988.2502045
scenescomparedtoindividualobjects.Futureworkcouldinves-
[3] MarkBillinghurst,HirokazuKato,andIvanPoupyrev.2001.MagicBook:transi-
tigatethescalabilityofThing2Realitytohandlelargerandmore tioningbetweenrealityandvirtuality.InCHIâ€™01ExtendedAbstractsonHuman
complex3Dsceneswhilemaintainingusabilityandperformance.
FactorsinComputingSystems(Seattle,Washington)(CHIEAâ€™01).Association
forComputingMachinery,NewYork,NY,USA,25â€“26. https://doi.org/10.1145/
634067.634087
AutomationofHumanInput. Inthiswork,fromanHCIperspective, [4] MargotBreretonandBenMcGarry.2000.Anobservationalstudyofhowobjects
wewanttoexploreawaytouseimages(orobjectsofinterest) supportengineeringdesignthinkingandcommunication:implicationsforthe
asamiddleground tobindapersonâ€™sinput(text,sketches,and d Fae cs ti og rn sio nf Cta on mg pib ul te inm ge Sd yi sa te. mIn s.P 2r 1o 7c â€“ee 2d 2i 4n .gsoftheSIGCHIconferenceonHuman
digitalsearch)andtheirintentiontocommunicatewithvarious [5] KurtisDanyluk,BarrettEns,BernhardJenny,andWesleyWillett.2021. A
andflexiblyconvertabledatarepresentationsspontaneouslyshown Design Space Exploration of Worlds in Miniature. In Proceedings of the
2021 CHI Conference on Human Factors in Computing Systems (<conf-loc>,
toothers(between2Dand3D)tofacilitatecommunicationwith <city>Yokohama</city>,<country>Japan</country>,</conf-loc>)(CHIâ€™21).As-
otherpeople.However,thecurrentsystemrequiresmanualinputof sociationforComputingMachinery,NewYork,NY,USA,Article122,15pages.
text,sketches,andimagestogenerate3Dobjects.Whilethisallows https://doi.org/10.1145/3411764.3445098
[6] ManojDeshpande.2020. TowardsCo-Build:AnArchitectureMachineforCo-
forgreatercontrolandcustomization,itmaylimitthesystemâ€™s CreativeForm-Making.Ph.D.Dissertation.TheUniversityofNorthCarolinaat
efficiency.Futureworkcouldexplorewaystoautomateorstream- Charlotte. https://doi.org/10.1145/3519026
[7] FlorianEchtler,VitusMaierhÃ¶fer,NicolaiBrodersenHansen,andRaphaelWim-
linetheinputprocess,suchasusingcomputervisiontechniques mer. 2023. SurfaceCast: Ubiquitous, Cross-Device Surface Sharing. Proc.
toautomaticallyextractobjectinformationfromimagesorvideos. ACMHum.-Comput.Interact7,ISS,Article439(nov2023),23pages. https:
Additionally,thesystemcouldbeenhancedtoadaptivelyunder- //doi.org/10.1145/3626475
[8] MartinFeick,TerranceMok,AnthonyTang,LoraOehlberg,andEhudSharlin.
standtheconversationcontextandsuggestrelevant3Dobjectsor
2018.PerspectiveonandRe-orientationofPhysicalProxiesinObject-Focused
visualizationsbasedontheongoingdiscussion.Thiswouldrequire RemoteCollaboration.InProceedingsofthe2018CHIConferenceonHuman
thedevelopmentofadvancednaturallanguageprocessingandma-
FactorsinComputingSystems(MontrealQC,Canada)(CHIâ€™18).Association
forComputingMachinery,NewYork,NY,USA,1â€“13. https://doi.org/10.1145/
chinelearningalgorithmstoanalyzeandinterprettheconversation 3173574.3173855
inreal-time. [9] ArnabGhosh,RichardZhang,PuneetKDokania,OliverWang,AlexeiAEfros,
PhilipHSTorr,andEliShechtman.2019. InteractiveSketch&Fill:Multiclass
Sketch-to-ImageTranslation.InProceedingsoftheIEEE/CVFInternationalConfer-
11 CONCLUSION enceonComputerVision.1171â€“1180. https://doi.org/10.1145/223904.223910
[10] JeremyHartmann,Yen-TingYeh,andDanielVogel.2020.AAR:Augmentinga
WebelievethatXRcommunicationhastremendouspromisefor WearableAugmentedRealityDisplayWithanActuatedHead-MountedProjector.
co-presenceandforbridgingdistancesbetweenhumans,yetmuch
InProceedingsofthe33rdAnnualACMSymposiumonUserInterfaceSoftwareand
Technology(VirtualEvent,USA)(UISTâ€™20).AssociationforComputingMachinery,
focustodayisonrealisticrenderingofavatarsandremotepartici-
NewYork,NY,USA,445â€“458. https://doi.org/10.1145/3379337.3415849
pants.However,asXRsystemsmatureandbecomeincreasingly [11] JÃ¶rgHauber,HolgerRegenbrecht,MarkBillinghurst,andAndyCockburn.2006.
realistic,itwillalsobecomeincreasinglyimportanttosupportasim- SpatialityinVideoconferencing:Trade-OffsBetweenEfficiencyandSocialPres-
ence.InProceedingsofthe200620thAnniversaryConferenceonComputerSup-
ilarlevelofspontaneitywithobjectsandartifacts,aswhatpeople portedCooperativeWork.413â€“422. https://doi.org/10.1145/1180875.1180937
experienceinrealenvironments. [12] ZhenyiHe,KeruWang,BrandonYushanFeng,RuofeiDu,andKenPerlin.2021.
GazeChat:EnhancingVirtualConferencesWithGaze-Aware3DPhotos.InThe
Inthispaper,wepresentedThing2Reality,anXRcommunication 34thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology(Virtual
systemthatallowsuserstoinstantlymaterializeideasorphysical Event,USA)(UISTâ€™21).AssociationforComputingMachinery,NewYork,NY,
objectsandsharethemasinteractiveconditionedmultiviewren- USA,769â€“782. https://doi.org/10.1145/3472749.3474785
[13] ScarlettRHerring,Chia-ChenChang,JesseKrantzler,andBrianPBailey.2009.
deringsor3DGaussiansforrealistic3Drendering.Ourfirststudy
GettingInspired!UnderstandingHowandWhyExamplesAreUsedinCreative
(ğ‘ = 12)underscoredThing2Realityâ€™seffectivenessinelevating DesignPractice.InProceedingsoftheSIGCHIConferenceonHumanFactorsin
discussionsbyconvertingbothphysicalanddigitalitemsintointer- ComputingSystems.87â€“96. https://doi.org/10.1145/1518701.1518717
[14] JonHindmarsh,MikeFraser,ChristianHeath,SteveBenford,andChrisGreen-
active3DGaussians,offeringamoredynamicandcomprehensive halgh.2000.Object-FocusedInteractioninCollaborativeVirtualEnvironments.
experience,comparedtotraditional2Drepresentations.Wefurther ACMTransactionsonComputer-HumanInteraction(TOCHI)7,4(2000),477â€“509.
reportonfindingsfromourexploratoryuserstudy(ğ‘ =18)that https://doi.org/10.1145/365058.365088
[15] ChristianHolzandAndrewWilson.2011.Datamiming:inferringspatialobject
showshowtheabilitytointeractwith,andmanipulate,both2Dand descriptionsfromhumangesture.InProceedingsoftheSIGCHIConferenceonArxivâ€™25, Arxivâ€™25 ErzhenHu,MingyiLi,JungtaekHong,XunQian,AlexOlwal,DavidKim,SeongkookHeo,andRuofeiDu
HumanFactorsinComputingSystems.811â€“820. 2023ACMDesigningInteractiveSystemsConference.1955â€“1977. https://doi.org/
[16] YicongHong,KaiZhang,JiuxiangGu,SaiBi,YangZhou,DifanLiu,FengLiu, 10.1145/3563657.3596098
KalyanSunkavalli,TrungBui,andHaoTan.2023.Lrm:LargeReconstruction [33] Xingyu"Bruce"Liu,VladimirKirilyuk,XiuxiuYuan,AlexOlwal,PeggyChi,
ModelforSingleImageto3d. ArXivPreprintArXiv:2311.04400(2023). https: Xiang"Anthony"Chen,andRuofeiDu.2023. VisualCaptions:Augmenting
//arxiv.org/pdf/2311.04400 VerbalCommunicationWithOn-the-FlyVisuals.InProceedingsofthe2023CHI
[17] ErzhenHu,MdAashikurRahmanAzim,andSeongkookHeo.2022.FluidMeet: ConferenceonHumanFactorsinComputingSystems.1â€“20. https://doi.org/10.
EnablingFrictionlessTransitionsBetweenIn-Group,Between-Group,andPrivate 1145/3544548.3581566
ConversationsDuringVirtualBreakoutMeetings.InProceedingsofthe2022CHI [34] JenniferMarlow,ScottCarter,NathanielGood,andJung-WeiChen.2016.Beyond
ConferenceonHumanFactorsinComputingSystems(NewOrleans,LA,USA) TalkingHeads:MultimediaArtifactCreation,Use,andSharinginDistributed
(CHIâ€™22).AssociationforComputingMachinery,NewYork,NY,USA,Article Meetings.InProceedingsofthe19thACMConferenceonComputer-SupportedCo-
511,17pages. https://doi.org/10.1145/3491102.3517558 operativeWork&SocialComputing.1703â€“1715. https://doi.org/10.1145/2818048.
[18] ErzhenHu,JensEmilSlothGrÃ¸nbÃ¦k,AustinHouck,andSeongkookHeo.2023. 2819958
OpenMic:UtilizingProxemicMetaphorsforConversationalFloorTransitions [35] TerranceMokandLoraOehlberg.2017. CritiquingPhysicalPrototypesfora
inMultipartyVideoMeetings.InProceedingsofthe2023CHIConferenceon RemoteAudience.InProceedingsofthe2017ConferenceonDesigningInteractive
HumanFactorsinComputingSystems(Hamburg,Germany)(CHIâ€™23).Association Systems(Edinburgh,UnitedKingdom)(DISâ€™17).AssociationforComputing
forComputingMachinery,NewYork,NY,USA,Article793,17pages. https: Machinery,NewYork,NY,USA,1295â€“1307. https://doi.org/10.1145/3064663.
//doi.org/10.1145/3544548.3581013 3064722
[19] ErzhenHu,JensEmilSlothGrÃ¸nbÃ¦k,WenYing,RuofeiDu,andSeongkookHeo. [36] ArchanaNarayanan,ErzhenHu,andSeongkookHeo.2022.EnablingRemote
2023.ThingShare:Ad-HocDigitalCopiesofPhysicalObjectsforSharingThings HandGuidanceinVideoCallsUsingDirectionalForceIllusion.InCompanion
inVideoMeetings.InProceedingsofthe2023CHIConferenceonHumanFactorsin Publicationofthe2022ConferenceonComputerSupportedCooperativeWorkand
ComputingSystems(CHIâ€™23).AssociationforComputingMachinery,NewYork, SocialComputing(VirtualEvent,Taiwan)(CSCWâ€™22Companion).Associationfor
NY,USA,Article365,22pages. https://doi.org/10.1145/3544548.3581148 ComputingMachinery,NewYork,NY,USA,135â€“139. https://doi.org/10.1145/
[20] XinchengHuangandRobertXiao.2024.SurfShare:LightweightSpatiallyCon- 3500868.3559470
sistentPhysicalSurfaceandVirtualReplicaSharingwithHead-mountedMixed- [37] MichaelNebeling,ShwethaRajaram,LiweiWu,YifeiCheng,andJaylinHer-
Reality.Proc.ACMInteract.Mob.WearableUbiquitousTechnol.7,4,Article162 skovitz.2021. XRStudio:AVirtualProductionandLiveStreamingSystem
(jan2024),24pages. https://doi.org/10.1145/3631418 forImmersiveInstructionalExperiences.InProceedingsofthe2021CHICon-
[21] ShahramIzadi,AndrewDavison,AndrewFitzgibbon,DavidKim,OtmarHilliges, ferenceonHumanFactorsinComputingSystems (CHIâ€™21).Associationfor
DavidMolyneaux,RichardNewcombe,PushmeetKohli,JamieShotton,Steve ComputingMachinery,NewYork,NY,USA,Article107,12pages. https:
Hodges,andDustinFreeman.2011.KinectFusion:Real-Time3DReconstruction //doi.org/10.1145/3411764.3445323
andInteractionUsingaMovingDepthCamera.InProceedingsofthe24thAnnual [38] CuongNguyen,StephenDiVerdi,AaronHertzmann,andFengLiu.2017.CollaVR:
ACMSymposiumonUserInterfaceSoftwareandTechnology-UIST'11.ACM. CollaborativeIn-HeadsetReviewforVRVideo.InProceedingsofthe30thAnnual
https://doi.org/10.1145/2047196.2047270 ACMSymposiumonUserInterfaceSoftwareandTechnology(QuÃ©becCity,QC,
[22] QiaoJin,YeYuan,andSvetlanaYarosh.2023.Socio-technicalOpportunitiesin Canada)(UISTâ€™17).AssociationforComputingMachinery,NewYork,NY,USA,
Long-DistanceCommunicationBetweenSiblingswithaLargeAgeDifference.In 267â€“277. https://doi.org/10.1145/3126594.3126659
Proceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems [39] OhanOda,CarmineElvezio,MenguSukan,StevenFeiner,andBarbaraTversky.
(Hamburg,Germany)(CHIâ€™23).AssociationforComputingMachinery,NewYork, 2015.VirtualReplicasforRemoteAssistanceinVirtualandAugmentedReality.In
NY,USA,Article94,15pages. https://doi.org/10.1145/3544548.3580720 Proceedingsofthe28thAnnualACMSymposiumonUserInterfaceSoftware&Tech-
[23] StevenJohnson,MadeleineGibson,andBilgeMutlu.2015.HandheldorHands- nology(Charlotte,NC,USA)(UISTâ€™15).AssociationforComputingMachinery,
free?RemoteCollaborationviaLightweightHead-MountedDisplaysandHand- NewYork,NY,USA,405â€“415. https://doi.org/10.1145/2807442.2807497
heldDevices.InProceedingsofthe18thACMConferenceonComputerSup- [40] SergioOrts-Escolano,ChristophRhemann,SeanFanello,WayneChang,Adarsh
portedCooperativeWork&SocialComputing(Vancouver,BC,Canada)(CSCW Kowdle,YuryDegtyarev,DavidKim,PhilipLDavidson,SamehKhamis,Ming-
â€™15).AssociationforComputingMachinery,NewYork,NY,USA,1825â€“1836. songDou,etal.2016. Holoportation:Virtual3dteleportationinreal-time.In
https://doi.org/10.1145/2675133.2675176 Proceedingsofthe29thannualsymposiumonuserinterfacesoftwareandtechnology.
[24] SasaJunuzovic,KoriInkpen,TomBlank,andAnoopGupta.2012.IllumiShare: 741â€“754.
sharinganysurface.InProceedingsoftheSIGCHIConferenceonHumanFactors [41] ThammathipPiumsomboon,GunA.Lee,JonathonD.Hart,BarrettEns,RobertW.
inComputingSystems(Austin,Texas,USA)(CHIâ€™12).AssociationforComputing Lindeman,BruceH.Thomas,andMarkBillinghurst.2018.Mini-Me:AnAdaptive
Machinery,NewYork,NY,USA,1919â€“1928. https://doi.org/10.1145/2207676. AvatarforMixedRealityRemoteCollaboration.InProceedingsofthe2018CHI
2208333 ConferenceonHumanFactorsinComputingSystems(MontrealQC,Canada)
[25] BernhardKerbl,GeorgiosKopanas,ThomasLeimkÃ¼hler,andGeorgeDrettakis. (CHIâ€™18).AssociationforComputingMachinery,NewYork,NY,USA,1â€“13.
2023. 3dGaussianSplattingforReal-TimeRadianceFieldRendering. ACM https://doi.org/10.1145/3173574.3173620
TransactionsonGraphics42,4(2023),1â€“14. https://doi.org/10.1145/3592433 [42] EmranPoh,AnthonyTang,JeannieS.Lee,andZhaoShengdong.2023.Supporting
[26] AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,Laura ArtefactAwarenessinPartially-ReplicatedWorkspaces.In2023IEEEInternational
Gustafson,TeteXiao,SpencerWhitehead,AlexanderC.Berg,Wan-YenLo,Piotr SymposiumonMixedandAugmentedRealityAdjunct(ISMAR-Adjunct).55â€“59.
DollÃ¡r,andRossGirshick.2023. SegmentAnything. ArXiv:2304.02643(2023). https://doi.org/10.1109/ISMAR-Adjunct60411.2023.00019
https://doi.org/10.48550/arXiv.2304.02643 [43] BenPoole,AjayJain,JonathanT.Barron,andBenMildenhall.2022.DreamFusion:
[27] ChunyuanLi,ZheGan,ZhengyuanYang,JianweiYang,LinjieLi,LijuanWang, Text-to-3DUsing2DDiffusion.ArXiv(2022). https://arxiv.org/pdf/2209.14988.
andJianfengGao.2023. MultimodalFoundationModels:FromSpecialiststo [44] XunQian,FeitongTan,YindaZhang,BrianCollins,DavidKim,AlexOlwal,
General-PurposeAssistants.ArXivPreprintArXiv:2309.100201,2(2023),2. KarthikRamani,andRuofeiDu.2024.ChatDirector:EnhancingVideoConferenc-
[28] JiannanLi,MaurÃ­cioSousa,ChuLi,JessieLiu,YanChen,RavinBalakrishnan, ingwithSpace-AwareSceneRenderingandSpeech-DrivenLayoutTransition.In
andToviGrossman.2022.ASTEROIDS:ExploringSwarmsofMini-Telepresence Proceedingsofthe2024CHIConferenceonHumanFactorsinComputingSystems.
RobotsforPhysicalSkillDemonstration.InProceedingsofthe2022CHIConference 1â€“16. https://doi.org/10.1145/3613904.3642110
onHumanFactorsinComputingSystems(NewOrleans,LA,USA)(CHIâ€™22). [45] ShwethaRajaramandMichaelNebeling.2022.PaperTrail:AnImmersiveAu-
AssociationforComputingMachinery,NewYork,NY,USA,Article111,14pages. thoringSystemforAugmentedRealityInstructionalExperiences.InProceedings
https://doi.org/10.1145/3491102.3501927 ofthe2022CHIConferenceonHumanFactorsinComputingSystems(NewOrleans,
[29] JiahaoLi,HaoTan,KaiZhang,ZexiangXu,FujunLuan,YinghaoXu,Yicong LA,USA)(CHIâ€™22).AssociationforComputingMachinery,NewYork,NY,USA,
Hong,KalyanSunkavalli,GregShakhnarovich,andSaiBi.2023.Instant3D:Fast Article382,16pages. https://doi.org/10.1145/3491102.3517486
Text-to-3DWithSparse-ViewGenerationandLargeReconstructionModel.ArXiv [46] ShwethaRajaram,NelsNuman,BalasaravananThoraviKumaravel,NicolaiMar-
PreprintArXiv:2311.06214(2023). https://doi.org/10.48550/arXiv.2311.06214 quardt,andAndrewDWilson.2024.BlendScape:EnablingUnifiedandPersonal-
[30] DavidLindlbauerandAndyD.Wilson.2018. RemixedReality:Manipulating izedVideo-ConferencingEnvironmentsThroughGenerativeAI.ArXivPreprint
SpaceandTimeinAugmentedReality.InProceedingsofthe2018CHIConference ArXiv:2403.13947(2024).
onHumanFactorsinComputingSystems(CHIâ€™18).AssociationforComputing [47] MoseSakashita,BalaKumaravel,NicolaiMarquardt,andAndrewD.Wilson.
Machinery,NewYork,NY,USA,1â€“13. https://doi.org/10.1145/3173574.3173703 2024.SharedNeRF:LeveragingPhotorealisticandViewDependentRenderingfor
[31] VivianLiu,HanQiao,andLydiaChilton.2022.Opal:MultimodalImageGenera- Real-TimeandRemoteCollaboration.InProceedingsofthe2024CHIConference
tionforNewsIllustration.InProceedingsofthe35thAnnualACMSymposiumon onHumanFactorsinComputingSystems(CHI),2024. https://doi.org/10.1145/
UserInterfaceSoftwareandTechnology.1â€“17. https://doi.org/10.1145/3526113. 3544548.3581444
3545621 [48] YichunShi,PengWang,JianglongYe,MaiLong,KejieLi,andXiaoYang.2023.Mv-
[32] VivianLiu,JoVermeulen,GeorgeFitzmaurice,andJustinMatejka.2023.3DALL- dream:Multi-ViewDiffusionfor3dGeneration.ArXivPreprintArXiv:2308.16512
E:IntegratingText-to-ImageAIin3DDesignWorkflows.InProceedingsofthe (2023).Thing2Reality Arxivâ€™25, Arxivâ€™25
[49] MaurÃ­cioSousa,DanielMendes,RafaelKdosAnjos,DanielSimÃµesLopes,and [66] LvminZhang,AnyiRao,andManeeshAgrawala.2023. AddingConditional
JoaquimJorge.2019.NegativeSpace:WorkspaceAwarenessin3dFace-to-Face ControltoText-to-ImageDiffusionModels.InProceedingsoftheIEEE/CVFIn-
RemoteCollaboration.InProceedingsofthe17thInternationalConferenceon ternationalConferenceonComputerVision.3836â€“3847. https://doi.org/10.1109/
Virtual-RealityContinuumandItsApplicationsinIndustry.1â€“2. https://doi.org/ CVPR52729.2023.01368
10.1145/3359997.3365744 [67] YongxinZhang,CharlotteMejlvangGuldbÃ¦k,ChristianFogDalsgaardJensen,
[50] MaurÃ­cioSousa,DanielMendes,SoraiaPaulo,NunoMatela,JoaquimJorge,and NicolaiBrodersenHansen,andFlorianEchtler.2024.TableCanvas:RemoteOpen-
DanielSimÃµesLopes.2017.VRRRRoom:VirtualRealityforRadiologistsinthe EndedPlayinPhysical-DigitalEnvironments.InProceedingsoftheEighteenth
ReadingRoom.InProceedingsofthe2017CHIConferenceonHumanFactorsin InternationalConferenceonTangible,Embedded,andEmbodiedInteraction(TEI
ComputingSystems(Denver,Colorado,USA)(CHIâ€™17).AssociationforComputing â€™24).AssociationforComputingMachinery,NewYork,NY,USA,Article74,
Machinery,4057â€“4062. https://doi.org/10.1145/3025453.3025566 7pages. https://doi.org/10.1145/3623509.3635255
[51] MichaelStengel,KokiNagano,ChaoLiu,MatthewChan,AlexTrevithick,Shalini [68] YizhongZhang,JiaolongYang,ZhenLiu,RuichengWang,GuojunChen,Xin
DeMello,JonghyunKim,andDavidLuebke.2023.AI-Mediated3DVideoConfer- Tong,andBainingGuo.2022.Virtualcube:AnImmersive3dVideoCommuni-
encing.InACMSIGGRAPH2023EmergingTechnologies(LosAngeles,CA,USA) cationSystem.IEEETransactionsonVisualizationandComputerGraphics28,5
(SIGGRAPHâ€™23).AssociationforComputingMachinery,NewYork,NY,USA, (2022),2146â€“2156. https://doi.org/10.1109/TVCG.2022.3150512
Article4,2pages. https://doi.org/10.1145/3588037.3595385 [69] FengyuanZhuandToviGrossman.2020. BISHARE:ExploringBidirectional
[52] RichardStoakley,MatthewJ.Conway,andRandyPausch.1995.Virtualrealityon InteractionsBetweenSmartphonesandHead-MountedAugmentedReality.In
aWIM:interactiveworldsinminiature.InProceedingsoftheSIGCHIConference Proceedingsofthe2020CHIConferenceonHumanFactorsinComputingSystems
onHumanFactorsinComputingSystems(Denver,Colorado,USA)(CHIâ€™95).ACM (CHIâ€™20).AssociationforComputingMachinery,NewYork,NY,USA,1â€“14.
Press/Addison-WesleyPublishingCo.,USA,265â€“272. https://doi.org/10.1145/ https://doi.org/10.1145/3313831.3376233
223904.223938
[53] Minhyang(Mia)Suh,EmilyYoungblom,MichaelTerry,andCarrieJCai.2021.
A APPENDIX
AIAsSocialGlue:UncoveringtheRolesofDeepGenerativeAIDuringSocial
MusicComposition.InProceedingsofthe2021CHIConferenceonHumanFactors
A.1 QuantitativeResultsofExploratoryStudy
inComputingSystems(CHIâ€™21).AssociationforComputingMachinery,Article
582,11pages. https://doi.org/10.1145/3411764.3445219 Inbothtasks(FurnitureArrangementandWorkspace),thepartici-
[54] JiaxiangTang,ZhaoxiChen,XiaokangChen,TengfeiWang,GangZeng,and
ZiweiLiu.2024.LGM:LargeMulti-ViewGaussianModelforHigh-Resolution pantsreportedhighsystemusabilityscore:easytocommunicate
3DContentCreation.ArXivPreprintArXiv:2402.05054(2024). https://arxiv.org/ withthepartner(Median=5,IQR=0.5;onascalefrom1[â€œDis-
pdf/2402.05054.
agreeâ€]to5[â€œAgreeâ€]),easytocompletethetaskwiththeinterface
[55] BalasaravananThoraviKumaravel,FraserAnderson,GeorgeFitzmaurice,Bjoern
Hartmann,andToviGrossman.2019.Loki:FacilitatingRemoteInstructionof (Median=5,IQR=1),andeasytousetheinterface(Median=5,IQR
PhysicalTasksUsingBi-DirectionalMixed-RealityTelepresence.InProceedings
=1).Theyfeltconfidentinbothshowingthe3Dobjecteffectivelyto
ofthe32ndAnnualACMSymposiumonUserInterfaceSoftwareandTechnology
(NewOrleans,LA,USA)(UISTâ€™19).AssociationforComputingMachinery,New theirpartners(Median=5,IQR=1)andunderstandingwhichpart
York,NY,USA,161â€“174. https://doi.org/10.1145/3332165.3347872 oftheobjecttheirpartnerswerereferringto(Median=5,IQR=1).
[56] HuayuanTian,GunALee,HuidongBai,andMarkBillinghurst.2023. Us- Whencomparingdifferentobjectrepresentations,theparticipants
ingVirtualReplicastoImproveMixedRealityRemoteCollaboration. IEEE
TransactionsonVisualizationandComputerGraphics29,5(2023),2785â€“2795. generallybelievedthattheycoulddelivertheirideasmoreclearly
https://doi.org/10.1109/TVCG.2023.3247113 with3Dobjects(Median=5,IQR=1)thanthePieMenuofmultiple
[57] DishitaG.Turakhia,HarrisonMitchellAllen,KaylaDesPortes,andStefanie
views(Median=4,IQR=2).
Mueller.2021.FabO:IntegratingFabricationWithaPlayerâ€™sGameplayinExisting
DigitalGames.InProceedingsofthe13thConferenceonCreativityandCognition
(VirtualEvent,Italy)(C&Câ€™21).AssociationforComputingMachinery,NewYork,
NY,USA,Article21,10pages. https://doi.org/10.1145/3450741.3465239
[58] RishiVanukuru,SuibiChe-ChuanWeng,KrithikRanjan,TorinHopkins,Amy
Banic,MarkDGross,andEllenYi-LuenDo.2023.DualStream:SpatiallySharing
SelvesandSurroundingsUsingMobileDevicesandAugmentedReality.In2023
IEEEInternationalSymposiumonMixedandAugmentedReality(ISMAR).IEEE,
IEEE,138â€“147.
[59] Vuplex.2024.Vuplex.3dWebview:TheUltimateCross-PlatformWebBrowser
forUnity. https://www.vuplex.com/
[60] PengWangandYichunShi.2023. ImageDream:Image-PromptMulti-View
Diffusionfor3DGeneration.ArXivPreprintArXiv:2312.02201(2023).
[61] TianyiWang,XunQian,FengmingHe,XiyunHu,YuanzhiCao,andKarthik
Ramani.2021.GesturAR:AnAuthoringSystemforCreatingFreehandInteractive
AugmentedRealityApplications.InThe34thAnnualACMSymposiumonUser
InterfaceSoftwareandTechnology(VirtualEvent,USA)(UISTâ€™21).Associationfor
ComputingMachinery,NewYork,NY,USA,552â€“567. https://doi.org/10.1145/
3472749.3474769
[62] HaijunXia,SebastianHerscher,KenPerlin,andDanielWigdor.2018.Spacetime:
EnablingFluidIndividualandCollaborativeEditinginVirtualReality.InProceed-
ingsofthe31stAnnualACMSymposiumonUserInterfaceSoftwareandTechnology
(UISTâ€™18).AssociationforComputingMachinery,NewYork,NY,USA,853â€“866.
https://doi.org/10.1145/3242587.3242597
[63] YinghaoXu,ZifanShi,WangYifan,HanshengChen,CeyuanYang,SidaPeng,Yu-
junShen,andGordonWetzstein.2024.Grm:Largegaussianreconstructionmodel
forefficient3dreconstructionandgeneration.arXivpreprintarXiv:2403.14621
(2024).
[64] YeYuan,PeterGenatempo,QiaoJin,andSvetlanaYarosh.2024.FieldTrialof
aTablet-basedARSystemforIntergenerationalConnectionsthroughRemote
Reading. ProceedingsoftheACMonHuman-ComputerInteraction8,CSCW1
(2024),1â€“28.
[65] ChaoningZhang,DongshenHan,YuQiao,JungUkKim,Sung-HoBae,Seungkyu
Lee,andChoongSeonHong.2023.FasterSegmentAnything:TowardsLight-
weightSAMforMobileApplications. ArXivPreprintArXiv:2306.14289(2023).
https://doi.org/10.48550/arXiv.2306.14289Arxivâ€™25, Arxivâ€™25 ErzhenHu,MingyiLi,JungtaekHong,XunQian,AlexOlwal,DavidKim,SeongkookHeo,andRuofeiDu
Figure13:SurveyResults.Ontheleft,twostackedbarchartsshowtheparticipantsâ€™responsesinusingThing2Realityfor
thefurnitureandworkspacetasksrespectively.Inbothtasks,mostparticipantsreportedThing2Realitybeingeasytouse
andeffectiveincommunicationandpresentationofideasthrough3Dobjects.Ontheright,thestackedbargraphshows
participantsâ€™preferencesof2D/3Drepresentationswhenconsideringpersonalcomprehensionoftheobjectandtheabilityto
understandtheircollaborators.3Dobjectswerefavoredinbothcases.