PuzzleAvatar: Assembling 3D Avatars from Personal Albums
YULIANGXIU,MaxPlanckInstituteforIntelligentSystems,Germany
YUFEIYE,MaxPlanckInstituteforIntelligentSystems,GermanyandCarnegieMellonUniversity,USA
ZHENLIU,MaxPlanckInstituteforIntelligentSystems,GermanyandMila,Universit√©deMontr√©al,Canada
DIMITRIOSTZIONAS,UniversityofAmsterdam,Netherlands
MICHAELJ.BLACK,MaxPlanckInstituteforIntelligentSystems,Germany
‚Ä¶
‚Äú<B> shirt‚Äù Personal ‚ÄúOOTD‚Äù Photo Collection (Subject B)
PuzzleBooth ‚Äú<A> shirt‚Äù
+SDS
Personal ‚ÄúOOTD‚Äù Photo Collection (Subject A) Textured 3D Human A Virtual Try-On (A+B) Text-guided Editing ‚Äú<A> shirt‚Äù ‚Üí ‚Äú<A> coat‚Äù
Fig.1. PuzzleAvatarreconstructsafaithful,personalized,textured3Dhumanavatarfromapersonalphotocollection.Thatis,ittakesasinputasetof‚ÄúOOTD‚Äù
(OutfitOfTheDay)personalphotoswithunconstrainedbodyposes,cameraposes,framing,lightingandbackgrounds,albeitwithaconsistentoutfitand
hairstyle.Alltheseconsistentfactorsarelearnedasseparateuniquetokens<asset X>inacompositionalmanner,likepiecesofapuzzle.PuzzleAvatar
allowsuseasilyinter-changetokensfordownstTreexatumred t3aDs Hkusm,asn uBchasforcustomizingavatarsandperformingvirtualtry-onwhilepreservingidentity,seevideo.
1 INTRODUCTION
Generatingpersonalized3DavatarsiscrucialforAR/VR.However,recent
text-to-3Dmethodsthatgenerateavatarsforcelebritiesorfictionalchar-
Inallchaosthereisacosmos,inalldisorderasecretorder.
acters,strugglewitheverydaypeople.Methodsforfaithfulreconstruction
typicallyrequirefull-bodyimagesincontrolledsettings.Whatifuserscould CarlJung
justuploadtheirpersonal‚ÄúOOTD‚Äù(OutfitOfTheDay)photocollection
Advancesintext-guideddigitalhumansynthesisopenthedoor
andgetafaithfulavatarinreturn?Thechallengeisthatsuchcasualphoto
to 3D avatar creation with arbitrary skin tones, clothing styles,
collectionscontaindiverseposes,challengingviewpoints,croppedviews,
andocclusion(albeitwithaconsistentoutfit,accessories‚Ä¶alonngd shhirta‚Ä¶irstyle‚Ä¶)b.luWe jeaens‚Ä¶ ‚Ä¶h yea lloi wr hs att ‚Ä¶ylesandaccessories.Whiletheseadvanceshavedemonstrated
addressthisnovel‚ÄúAlbum2Human‚ÄùtaskbydevelopingPuzzleAvatar,a greatpotentialbygeneratingiconicfigures(suchasSupermanor
Text-guided Attributes Editing
novelmodelthatgeneratesafaithful3Davatar(inacanonicalpose)from BruceLee)andeditingspecifichumanfeatures(suchaswavyhair
apersonalOOTDalbum,bypassingthechallengingestimationofbody orfullbeards),theproblemofcraftingone‚Äôspersonalizedfull-body
andcamerapose.Tothisend,wefine-tuneafoundationalvision-language avatarisrelativelyunexplored.Imaginethatyouaregivenaper-
model(VLM)onsuchphotos,encodingtheappearance,identity,garments, sonal‚Äúoutfitoftheday‚Äù(OOTD)photoalbumincasualsnapshots:
hairstyles,andaccessoriesofapersonintoseparatelearnedtokens,instill-
strollingthroughapark,crouchingtotieashoelace,seatedatacafe,
ingthesecuesintotheVLM.Ineffect,weexploitthelearnedtokensas
etc.Thesesnapshots,capturingfull-bodyactions,upper-bodyposes
‚Äúpuzzlepieces"fromwhichweassembleafaithful,personalized3Davatar.
andclose-upselfieswithdiversebackgrounds,lightingandcam-
Importantly,wecancustomizeavatarsbysimplyinter-changingtokens.As
erasettings,formarichphotocollection.Notably,thiscollectionis
abenchmarkforthisnewtask,wecreateanewdataset,calledPuzzleIOI,
with41subjectsinatotalofnearly1kOOTDconfigurations,inchalleng- relatively‚Äúunconstrained‚Äù,thatis,itsonlyconstraintishavingacon-
ingpartialphotoswithpairedground-truth3Dbodies.Evaluationshows sistentidentity,outfit,hairstyleandaccessories,whileeveryother
thatPuzzleAvatarnotonlyhashighreconstructionaccuracy,outperforming factorcanvaryarbitrarily;seeFig.1.Canweeffectivelyconstruct
TeCHandMVDreamBooth,butalsoauniquescalabilitytoalbumphotos, fromthisalbumapersonalized3Davatarthatvividlycharacterizes
andhasdemonstratingstrongrobustness.Ourmodelanddatawillbepublic. theuser‚Äôsclothes,physique,andfacialdetails?Inthiswork,we
CCSConcepts:‚Ä¢Computingmethodologies‚ÜíAppearanceandtexture investigatethisnoveltask,whichwecall‚ÄúAlbum2Human‚Äù,that
representations;Reconstruction;Shapeinference. transformseverydayalbumcollectionsintotextured3Dhumans.
Comparedtoworkthatreconstructsgeneral3Dscenesfrompho-
AdditionalKeyWordsandPhrases:Text-to-ImageDiffusionModel,Image-
toswithvaryinglightingconditions,croppingratio,background
basedModeling,Text-guided3DGeneration,DigitalHuman
andcamerasettings[Martin-Bruallaetal.2021;Sunetal.2022],
Authors‚Äôaddresses:YuliangXiu,yuliang.xiu@tuebingen.mpg.de,MaxPlanckInstitute Album2Humanismorechallengingduetotheadditionalfactor
forIntelligentSystems,Germany;YufeiYe,yeyf13.judy@gmail.com,MaxPlanckInsti-
ofvaryingbodyarticulation.Ontheotherhand,Album2Human
tuteforIntelligentSystems,GermanyandCarnegieMellonUniversity,USA;ZhenLiu,
zhen.liu@tuebingen.mpg.de,MaxPlanckInstituteforIntelligentSystems,Germanyand drasticallydiffersfrompriorwork[Alldiecketal.2018b;Pengetal.
Mila,Universit√©deMontr√©al,Canada;DimitriosTzionas,d.tzionas@uva.nl,University 2023;Vlasicetal.2009]thatcreatespersonalizedavatarsfromim-
ofAmsterdam,Netherlands;MichaelJ.Black,black@tuebingen.mpg.de,MaxPlanck
agescapturedinlaboratorysettings[Chengetal.2023;I≈üƒ±ketal.
InstituteforIntelligentSystems,Germany.
4202
yaM
32
]VC.sc[
1v96841.5042:viXra2 ‚Ä¢ Xiu,etal.
Full-body image or video Multi-view video w/ calibrated cameras PuzzleIOI Benchmark Real in-the-wild photos
Monocular video w/ standard (T/A) body pose
Previous Settings Our Settings
Fig.2. Imagesettingsforavatarcreation.Pastwork(left)requiresimageswithfull-bodyvisibility,knowncameracalibration,orsimplehumanposes.Our
PuzzleAvatarmethodoperatesonin-the-wildphotos(right);itassumesaconsistentoutfit,hairstyleandaccessories,butdealswithunconstrainedhuman
poses,camerasettings,lightingandbackground).OurPuzzleIOIdatasetcontainsmulti-viewimageswithchallengingcropspairedwith3Dgroundtruth.
2023;Maetal.2020;Shenetal.2023;Xiongetal.2024;Yuetal. learnedtokensareusedaspuzzlepiecestoassembleavatars,guided
2021;Zhengetal.2019],inwhichfullhumanbodiesinlimitedbody bytextprompts.Thus,wecallourmethod‚ÄúPuzzleAvatar‚Äù.
posesarecapturedusingwellcalibratedandsynchronizedcameras SincethereexistsnobenchmarkforournewAlbum2Human
withcontrolledlightingandsimplebackgrounds;seeFig.2. task,wecollectanewdataset,calledPuzzleIOI,of41subjectsina
Whileitispossibletocreateavatarsfrommonocular(imageor totalofroughly1kconfigurations(outfits,accessories,hairstyles).
video)inputasshownbysomemethods[Habermannetal.2020; Ourevaluationmetricsincludeboth3Dreconstructionerrors(e.g.,
Xiuetal.2022;Yangetal.2023],suchmethodsperformpoorlyfor Chamferdistances,P2Sdistances)betweenreconstructedshapes
unusualbodyposes,motionblur,andocclusions,becausetheyrely and ground-truth 3D scans, as well as 2D image similarity mea-
onaccuratehumanandcameraposeestimationfromfull-bodyshots. sures (e.g.,PSNR,SSIM)betweenrenderedmulti-viewimagesof
Instead,webypassposeestimation,andfollowthenewparadigmof the reconstructed surface and ground-truth textured scans. Our
‚Äúreconstructionasconditionalgeneration‚Äù,asrecentlydemonstrated PuzzleAvatariscompatiblewithdifferenttypesofdiffusionmodels.
forText-to-Image(T2I)generation[Gaoetal.2023;Huangetal. WeevaluatethisonPuzzleIOIusingtwodiffusionmodels,namely
2024b;Wuetal.2024;Yangetal.2024;Zhangetal.2023].Specifi- single-viewStableDiffusion[Rombachetal.2022]andmulti-view
cally,theseworkscastreconstructionfrompartialobservationsas MVDream[Shietal.2024].Moreover,weevaluatethecontribution
‚Äúinpainting‚Äùunobservedregionsthroughfoundational-modelpri- ofeachmodelcomponentbothqualitativelyandquantitativelywith
ors,whileimposingcross-viewconsistency.WeadaptexistingT2I anin-depthablationanalysis(Section4.4).
work[Avrahamietal.2023]tolearnsubject-specificpriorsfrom Insummary,herewemakethefollowingmaincontributions:
apersonalOOTDimagecollection,byfinetuningT2Imodelson Task:Weintroduceanoveltask,called‚ÄúAlbum2Human‚Äù,forrecon-
suchimagestocaptureidentity,piecesofclothing,accessories,and structinga3Davatarfromapersonalphotoalbumwithaconsistent
hairstyleintouniqueandinter-exchangeabletokens,andextracting outfit,hairstyleandaccessories,butunconstrainedhumanpose,
3DgeometryandtexturewithScoreDistillationSampling(SDS) camerasettings,framing,lightingandbackground.
basedtechniques[Pooleetal.2023].Metaphorically,ourmodelswal- Benchmark:Forevaluationofournoveltask,wecollectanew
lowsrelatively‚Äúunstructured‚Äùdataanddigeststhisintoa‚Äústructured dataset, called PuzzleIOI, with challenging cropped images and
library‚Äù;thatis,‚Äúseekingorderinchaos,findingharmonyinturmoil.‚Äù paired3Dgroundtruth.Thisfacilitatesquantitativelyevaluating
OurinsighttotreatT2Imodelsaspersonalizedpriorsenablesus methodsonboth3Dreconstructionandview-synthesisquality.
tonotonlyavoidexplicitper-pixelcorrespondencestoacanonical Methodology:PuzzleAvatarfollowsthefreshparadigmof‚Äúrecon-
humanspace,butalsotobuildavatarsinacompositionalmanner.To structionasconditionalgeneration‚Äù,thatis,itperformsimplicit
thisend,givenaphotocollectionofaperson,variousassetsareex- humancanonicalizationusingapersonalizedT2Imodeltobypass
tractedviaanopen-vocabularysegmentor[Renetal.2024],suchas explicitposeestimation,orre-projectionpixellosses.
theface,garments,accessories,andhairstyles.Eachoftheseassetsis Analysis:Weconductdetailedevaluationandablationstudiesto
labeledbyauniquetokenas‚Äú<asset X>‚Äù.Weexploitthesetoken- analyzetheeffectivenessandscalabilityofPuzzleAvatarandeach
assetpairs,tofinetuneapre-trainedT2Imodel,sothatitlearns ofitscomponents,sheddinglightonpotentialfuturedirections.
togenerate‚Äúpersonalized‚Äùassetsgivenarespectivetoken.Based Downstreamapplications:WeshowthatPuzzleAvatar‚Äôshighly-
onthispersonalizedT2Imodel,weproducea3Dhumanavatar modular tokens and text guidance facilitates downstream tasks
viaScoreDistillationSampling(SDS)givenadescriptiveandcom- throughtwoexamples: charactereditingandvirtualtry-on.
positional text prompt, e.g., ‚Äúa DSLR photo of a man, with Pleasecheckoutmorequalitativeresultsanddemosofappli-
<asset1> face, wearing <asset0> shirt, ...‚Äù(seeFig.1). cationsinvideo.PuzzleAvatarisasteptowardspersonalizing3D
Here,eachuniqueassetislikeapuzzlepiece,characterizingthe avatars.Todemocratizethis,codeandPuzzleIOIdatasetwillbe
identity,hairstyleanddressingstyleoftheperson.Inasense,the madepublicforonlyresearchpurpose.PuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums ‚Ä¢ 3
2 RELATEDWORK
beexploitedfordownstreamtasks.Inparticular,Score-Distillation-
3DHumanCreation.Manyworkshaveexploredhowtorecon- Samplingtechniquesstandout[Pooleetal.2023;Wangetal.2023a]
structclothedhumansfromvisualcueslikemulti-viewimages[Lin fordistilling‚Äúcommonknowledge"fromtext-to-imagemodelsto-
etal.2024;Pengetal.2023;Saitoetal.2019]orfull-shotmonocu- wardscreating3Dobjects.Workonmodelcustomizationinjects
larvideo[Alldiecketal.2018a,b;Lietal.2020;Wengetal.2022]. new concepts via fine-tuning (partial or whole) pre-trained net-
Recently,alotofworksstrivetocreatehumanavatarscharacter- works[Avrahamietal.2023;Jainetal.2022;Kumarietal.2023;Liu
ized by language. Initial work guided by language uses a CLIP etal.2024b;Ruizetal.2023].Otherworkre-purposesthediffusion
embedding[Hongetal.2022]tosculptcoarsebodyshape.Recent modelstonewtasks[Fuetal.2024b;Keetal.2024;Kocsisetal.2024].
work[Caoetal.2024;Huangetal.2023a;Kolotourosetal.2023; Weleveragealltheabovetechniquesforfaithful3Dhuman-avatar
Liaoetal.2024;Wangetal.2023b]capturesfinergeometryand generationfromnaturalimages,achallengingtaskinvolvingwidely
texture for a clothed human, or multiple humans, by exploiting varyingappearance,lighting,backgrounds,bodyandcameraposes.
large-scaletext-to-imagemodelsandScoreDistillationSampling
(SDS) [Poole et al. 2023; Wang et al. 2023a]. In addition to text, 3 METHOD
whensubjectimagesareavailable,theyareusedtofinetunethe
pretrainedmodel[Ruizetal.2023]andtoencouragefidelityvia
Givenanimagecollection{I 1,I 2,...IùëÅ}ofaperson,weaimto
re-projectionlosses[Gaoetal.2023;Huangetal.2023b,2024b;Yang
builda3Davatarthatcapturestheperson‚Äôsshapeùúì ùëîandappearance
etal.2024].WhileSDSframeworkstypicallytakeafewthousand
ùúì ùëê.Notably,personaldaily-lifephotosareunconstrained(seeFig.2)
as humans (1) appear in diverse poses and scales, (2) are often
iterations,otherwork[Chenetal.2024]speedsuptheprocessby
occludedorlargelytruncated,and(3)arecapturedfromunknown
one-stepgenerationconditionedonagivenimageinput.However,
viewpointsindiversebackgrounds.Thus,cameracalibrationand
allimage-conditionedmethodsassumereliablehumanposeesti-
posecanonicalizationforthesephotosareextremelychallenging,
mation[Pavlakosetal.2019]asaproxyrepresentationtodraw
makingdirectreconstructionofhumanavatarsdifficult.
correspondencesbetweentheinputimageandthereconstructed3D
Ourkeyinsightistocircumventestimatinghumanbodyposes
avatar.Hence,theyrequireimageswithcleanbackgrounds,com-
andcameras,and,instead,toperformimplicithumancanonical-
monbodyposes,andfull-bodyviewswithoutcrops.Furthermore,
izationviaafoundationvision-languagemodel(e.g.,StableDiffu-
externalcontrollers(e.g.,ControlNet[ZhangandAgrawala2023],
sion[Rombachetal.2022]).Ourmethodissummarizedvisuallyin
Zero123[Liuetal.2023])andadditionalgeometricregularizers(e.g.,
Fig.3,andhastwomainstages.Specifically,wefirst‚Äúdecompose‚Äù
LaplacianandEikonal[Chenetal.2023])appearessentialtoachieve
photosintomultipleassets(e.g.,garments,accessories,faces,hair),
high-qualityoutput.Incontrast,PuzzleAvatardoesnotrequireany
allofwhicharelinkedwithuniquelearnedtokensbyapersonalized
ofthese,thus,itisuniquelycapableofoperatingonunconstrained
T2Imodel,PuzzleBooth(Sec.3.1),thatisùê∫ inFig.3.Then,we
personal-albumphotos. puzzle
Pose-FreeReconstructioninthewild.Inourwork,theterm ‚Äúcompose‚Äùthesemultipleassetsintoa3Dfull-bodyrepresentation
‚Äúpose‚Äùrefersnotonlytocameraposebutalsotobodyarticulation. ùúì ùëî,ùúì ùëê viaScoreDistillationSampling(SDS)(Sec.3.2).
Cameraposeplaysacrucialrolein3Dreconstruction,asit‚Äúanchors‚Äù
3Dgeometryonto2Dimages[Mildenhalletal.2021],however,es- 3.1 PuzzleBooth‚ÄìPersonalizePuzzlePieces
timatingitforin-the-wildimagesishighlychallenging.Thus,to
Ourfirststepistosegmentsubjectimagesintomultipleassetsrepre-
accountforcameraestimationerrors,someworkleveragesjointop-
sentingdifferenthumanpartssuchastrousers,shoes,andhairstyle.
timizationbetweentheobjectandcamera[Linetal.2021;Wangetal.
Whileonecouldbuildeachassetindividually,weadaptthe‚ÄúBreak-
2021;Xiaetal.2022],off-the-shelfgeometriccueestimates[Bian
A-Scene‚Äù[Avrahamietal.2023],whichshowsthatjointlylearning
etal.2023;Fuetal.2024a;Meulemanetal.2023],orlearning-based
multipleconceptssignificantlyboostsperformance,possiblybe-
cameraestimation[Wangetal.2024c,b;Zhangetal.2024].Body
causethisfacilitatesglobalreasoningwhenmultipleregionsare
poseisalsohardtoestimatefromin-the-wildimagesandismuch
simultaneouslygenerated.Suchastrategyisevenmorebeneficialin
higherdimensionalthancamerapose.Someworkcanreconstruct
oursettingsincehuman-relatedconcepts,suchasfaceandhair,are
staticscenesfromin-the-wildimageswithchallengingillumination
hardertolearnastheirpropertiesarestronglycorrelatedcompared
conditionsandbackgrounds[Martin-Bruallaetal.2021;Sunetal.
toclearlydistinctobjectsinthesettingof‚ÄúBreak-A-Scene.‚Äù
2022],butthesecannotbeappliedtoarticulatedobjects,likehu-
AssetCreation.Allimagesaresegmentedintomultipleassets
mans.Inourwork,wetackleallabovechallengesfor‚Äúpose-free‚Äù
humanreconstruction.Thatis,wetacklein-the-wildphotoswith
ùëâ ùëò,eachofwhichisassociatedwithasegmentationmaskMùëò,a
unknowncameraposes,unknownbodyposes,possiblytruncated
dedicatedlearnabletoken[ùë£ ùëò],anditstextualname[ùëê ùëò],suchas
‚Äúpants‚Äùor‚Äúskirt.‚ÄùInaddition,wealsoobtainacoarseviewdirection
images(e.g.headshots),anddiversebackgroundsandillumination
ùëëforeachimage.Allsuchinformationisobtainedautomaticallyby
conditions,whicharehighlychallengingforexistingmethods.
Grounded-SAM[Renetal.2024]andGPT-4V[OpenAI2023].Specif-
LargeVision-LanguageModels.Largefoundationmodelshave
ically,wequeryGPT-4Vwithanimagetodirectlygettheproperty
achievedgreatprogressinvisualunderstanding[Kirillovetal.2023;
Lietal.2022;Radfordetal.2021]andgeneration[Athanasiouetal.
ofeachasset[ùëê ùëò]andcoarseviewdirectionùëë.Then,giventhefull
2023;Brooksetal.2024;Rombachetal.2022].Astheyaretrained listofqueriedassetnames{[ùëê ùëò]} ùëòùêæ =1,Grounded-SAMoutputsseg-
onatremendousamountofdata,theirstronggeneralizabilitycan mentationmasksiftheyarepresent.PleaserefertoAppendixAfor
ourfullprompttemplate.4 ‚Ä¢ Xiu,etal.
< asset 01 > < asset 02 >
Nvdiffrast
Grounded-SAM PuzzleBooth
Geometry
GPT-4V < asset 03 > < asset 04 >
‚Ä¶‚Ä¶
Texture
Personal ‚ÄúOOTD‚Äù Photo Collections Asset Creation
Stage 1 (Sec 3.1) ‚Äî Break Human into Puzzle Pieces to Train PuzzleBooth Stage 2 (Sec 3.2) ‚Äî Put Puzzle Pieces Together via SDS
‚ÄúDSLR photo of a man‚Äù + wearing <asset 03> pants, and <asset 04> sneakers <asset 04>
- wearing <asset 02> T-shirts
- with <asset 01> face,
Cross-
- ww ee aa rr ii nn gg < <a as ss se et t 0 04 2> > s Tn -sea hk ire tr ss , + T2I A Mtte an st kio sn <asset 03>
<asset 03> pants, and Diffuser
<asset 04> sneakers
Synthetic Paired Prior
Union-Sampling Diffusion Model Fine-tuning (Text-Encoder, UNet)
Fig.3. OverviewofPuzzleAvatar.Theupperfigureshowsthetwomainstages:(1)PuzzleBooth(Section3.1),wheretheunconstrainedphotocollections Textured 3D Human
arecaptionedandsegmentedtocreatepersonalizedpuzzlepieces,fortrainingPuzzleBooth,ùê∫ puzzle,and(2)Create-3D-Avatar (Section3.2),wherethe
T-posedtexturedtetrahedralbodymeshisoptimizedusingamulti-viewSDSlossL .ThebottomfigureillustratesthetrainingdetailsofPuzzleBooth;the
SDS
Text-EncoderandtheUNetofT2IDiffuser(i.e.,StableDiffusion)arefine-tunedusingthemaskeddiffusionloss,L (Eq.(1)),cross-attentionloss,L
rec attn
(Eq.(2)),andpriorpreservationloss,L (Eq.(3)).Componentsmarkedinlightbluearetrainableoroptimizable.
prior
Two-StagePersonalization.Wefinetunethepretrainedtext-to- whereM‚à™istheunionmask,andùúñ ùúÉ(ùëß ùë°,ùë°,ùëù ‚à™)isthedenoisedoutput
imagediffusionmodel[Rombachetal.2022;Shietal.2024]sothat atdiffusionstepùë° giventheunionprompt,ùëù ‚à™.
itadaptstothenewassets.Following‚ÄúBreak-A-Scene‚Äù[Avrahami Todisentangledifferentlearnedassets,weuseaCross-Attention
etal.2023],weoptimizethe‚Ä¶l ‚Äúong t s ehirt x‚Ä¶ t‚Äùp‚Ä¶ ablue r je tan ,s‚Ä¶ i.e.,‚Ä¶y tell how h eat‚Ä¶ textembeddingof Loss[Avrahamietal.2023]toencourageeachofthenewly-added
Text-guided Attributes Editing
assettoken[ùë£ ùëó],andthe‚Äúvisual‚Äùpart,i.e.,theweightsofthediffu- tokenstobeexclusivelyassociatedwithonlythetargetasset:
s oi fo tn hem ao sd se el t, ti on kt ew nso [s ùë£t ùëòa ]ge as r: eI on pt th ime ifi zr es dt wst ia tg he a,o lan rl gy et le ex at re nm inb ge rd ad tein .g Ins L attn=E ùëß,ùëó,ùë°(cid:2) ‚à•CAùúÉ(ùë£ ùëó,ùëß ùë°)‚àíMùëó‚à•2 2(cid:3), (2)
thesecondstage,boththe‚Äútext‚Äùand‚Äúvisual‚Äùpartareoptimized whereCAùúÉ(ùë£ ùëó,ùëß ùë°)isthecross-attentionmapinthediffusionU-Net
withasmalllearningrate.Thisstrategyeffectivelypreventsguid- betweenthenewly-addedtoken,[ùë£ ùëó],andthevisualfeature,ùëß ùë°.
ancecollapse[Gaoetal.2024]betweennewlyintroducedtokens Lastly,weapplyaPriorPreservationLoss [Ruizetal.2023]to
[ùë£ ùëò]andexistingassetnames[ùëê ùëò],or,equivalently,preservesthe retainthegeneralizationcapabilityofthevanillaT2Imodel‚ÄîSta-
compositionalityofvisualconcepts. bleDiffusion(SD-2.1).Themodelistrainedtoreconstructimages
Duringtraining,werandomlyselect,foreveryimageI,asubset withgeneralconceptswhenthespecialtokensareremovedfrom
ofassetsthatappearintheimageandtrainthemodelontheunion prompts.Generalhumanimagescomefromtwosources:(1)Gen-
setoftheseselectedassets.Thisunionsamplingstrategy,originally erated images, I gp er n, come from SD. (2) Synthetic color-normal
introduced in [Avrahami et al. 2023], is crucial for effective pairs(seeFig.4),Ipr ,renderedfrommultipleviews,comefrom
syn
assetdisentanglement.Specifically,themaskunionisdoneviaa THuman2.0[Yuetal.2021].Thelatteristoimprovethegeometry
pixel-wiseunionoperationM‚à™=‚à™ ùëñùëó =1Mùëñ,whiletheimageunion qualityandcolor-normalconsistency[Huangetal.2024a].Instead
appliestheunionmaskontheimage,I‚à™=I‚äôM‚à™.Theuniontext ofapplyingpriorpreservationlossforindividualconceptssepa-
promptùëù ‚à™isconstructedbyconcatenatingselectedassets,i.e.‚Äúa rately,wefinditbeneficialtocomputethelossontheentirehuman
high-resolution DSLR colored image of a man/woman images.
w .i .t .h
,
[ [ùë£ ùë£1 ùëó]
]
[ [ùëê ùëê1 ùëó] ],
,
. [. ùëë. ], v[ iùë£ e2 w] ‚Äù.[ùëê 2], and wearing [ùë£ 3] [ùëê 3], L prior=E ùëßpr,ùúñ‚àºN(0,1),ùë°(cid:2) ‚à•[ùúñ‚àíùúñ ùúÉ(ùëß ùë°pr,ùë°,ùëù ‚à™‚àó)]‚à•2 2(cid:3) (3)
Losses.Inbothoptimizationstages,themodelistrainedtoen- whereùëù ‚à™‚àó isthetextpromptwithoutspecialtokens.
courageconceptseparationwhilestillretainingitsgeneralization
3.2 PuzzleAvatar‚ÄìPutPuzzlePiecesTogether
capability.Todoso,themodelisoptimizedwiththreelossterms:
aMaskedDiffusionLoss, L rec,Cross-AttentionLoss, L attn,and Withthefine-tuneddiffusionmodelcustomizedforallprovided
PriorPreservationLoss, L prior.Theoveralltrainingobjectiveis assets,weareabletodistilladescriptive3DavatarviaSDS.
L total=L rec+ùúÜ attnL attn+L priorwhereùúÜ attn=0.01.
Score Distillation Sampling (SDS). A pretrained diffusion
TheMaskedDiffusionLossencouragesfidelityinreplicatingeach
modeloverimagesùê∑(z) capturesthedatadistributionlogùëù(zùúì).
conceptviaapixel-wisereconstructionwithinthesegmentedmask:
SDS[Pooleetal.2023]isatechniquethatguidessomeparameteri-
L rec=E ùëß,ùúñ‚àºN(0,1),ùë°(cid:2) ‚à•[ùúñ‚àíùúñ ùúÉ(ùëß ùë°,ùë°,ùëù ‚à™)]‚äôM‚à™‚à•2 2(cid:3), (1) zationofimagesz(ùúì)(rawpixels,neuralnetworks,etc.)togeneratePuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums ‚Ä¢ 5
Table1. DatasetsrelatedtoPuzzleIOI.‚Äú‚Äì‚Äùmeansimagecapturesare
Prompt (GPT-4V): ‚Äúa high-resolution DSLR colored image / detailed sculpture of (the headshot of) a woman, with
oval face, eyes with visible epicanthic folds, and medium length, straight, dark brown haircut, wearing loose-fitting, unavailable.‚ÄúScan‚ÄùisA-posed,and‚ÄúSMPL-X‚ÄùisitsrespectiveSMPL-Xfits.
teal-colored with long sleeves shirt, wide-legged, dark gray or black pants and black, ankle-high boots‚Äù
Dataset Reference #Views#ID#Outfits#ActionsSMPL-XScanTextTexture
ActorsHQ [I≈üƒ±ketal.2023] 160 8 8 52 ‚úì ‚úì ‚úó ‚úì
MVHumanNet [Xiongetal.2024] 48 4500 9000 500 ‚úì ‚úó ‚úì ‚úì
HuMMan [Caietal.2022] 10 1000 1000 500 ‚úó ‚úó ‚úó ‚úì
DNA-Rendering[Chengetal.2023] 60 500 1500 1187 ‚úó ‚úó ‚úó ‚úì
THuman2.0 [Yuetal.2021] ‚Äì 200 500 ‚Äì ‚úó ‚úó ‚úó ‚úì
CAPE [MaetParol.m2p0t 2(G0]PT-4V): ‚Äú‚Äìa high-1re5solution8 DSLR col6o0r0ed image / ‚úìdetailed ‚úìsculptu‚úóre of the‚úó headshot of a woman, with
BUFF [Zhanogveatl faalc.e2, 0e1ye7s] with ‚Äìvisible e5picanthi2c folds, and 3medium leng‚úìth, straig‚úìht, dar‚úók brown‚úì haircut, wearing loose-fitting,
teal-colored with long sleeves shirt, wide-legged, dark gray or black pants and black, ankle-high boots‚Äù
PuzzleIOI(Ours) 22 41 933 40 ‚úì ‚úì ‚úì ‚úì
Fig.4. Color-NormalSyntheticPrior.Thecorrespondingdescriptionsare
generatedviaGPT-4V[OpenAI2023],wherethepromptofRGBimagestarts
with‚Äúa high-resolution DSLR colored image‚Äù,whilethatof
thenormalimagestartswith‚Äúa detailed sculpture of‚ÄùThezoom- theysample3Davatarsfromarelativelysmallcollectionofprompts
inheadimagesaregeneratedbyappending‚Äúthe headshot of‚Äù andevaluatethequalityoftheseavatarsthroughperceptualstudies
withalimitednumberofparticipants.
WhilePuzzleAvataradopts‚ÄúText-to-3D‚Äùtechniques,itsgoalisto
imagestowardshigherlikelihood.Thecoreideaistoapproximate reconstructavatarsfromphotosofaspecificpersoninaspecificout-
theparametergradient‚àáùúìLasaweightedreconstructionresidual. fit,ratherthantorandomlygenerateavatars.Asaresult,anatural
Asthevanillamethodsuffersfromcoloroversaturation,weusean andreliablewaytobenchmarkPuzzleAvataristoexploita4Dscan-
improvedSDS‚ÄìNoise-FreeDistillationSampling(NFDS)[Katzir ners(syncedwithIOIcolorcameras1)forcapturingground-truth
etal.2024].Thismodifiestheguidancefromasinglereconstruction 3Dshapeandappearance,andtomeasurethereconstructionerror
residualintotwocomposedresidualtermsùõø ùê∂ andùõø ùê∑.Specifically, betweenthereconstructedandground-truthshapeandappearance.
bydenotingthederivedgradientofanetworkùúì fromNFSDas Wethusbuildadataset,calledPuzzleIOI(Section4.1),onwhichwe
‚àáL NFDS[x,ùúì]: evaluatePuzzleAvatarandablateitscomponents.
ùúïz
‚àáùúìL NFDS[z,ùúì] =ùë§(ùë°)(ùõø ùê∑ +ùë†ùõø ùê∂) ùúïùúì, where (4) 4.1 PuzzleIOIDataset
WecreatePuzzleIOI(seestatisticsinTable1)tosimulatereal-world
ùõø C(ùëß ùë°,ùëù,ùë°)=ùúñ ùúÉ(ùëß ùë°;ùëù,ùë°)‚àíùúñ ùúÉ(ùëß ùë°;‚àÖ,ùë°), albumphotosofhumans,which:(1)coverawiderangeofhuman
(cid:40) identities(#IDcolumninTable1)anddailyoutfits(#Outfits),(2)
ùõø D(ùëß ùë°,ùë°)= ùúñ ùúñùúÉ ùúÉ( (ùëß ùëßùë° ùë°; ;‚àÖ ‚àÖ, ,ùë° ùë°) ),
‚àíùúñ ùúÉ(ùëß ùë°;ùëùneg,ùë°),
i of tùë° he‚â§ rw20 is0
e,
(5) s op ca cln usn iu om n,e or uo tu -s ofv -i fe rw ams e(# cV roie pw pis n) gt )o ,am ni dm (i 3c )r inea cl l- uw deor tl ed xc ta dp et su cr re ips t( ie o. ng s.,
Inourcase,zisthe(latentof)diffusionoutput(humanimagesor (Text),andground-truthtexturedA-posedscans(Scan,Texture)
normals)andùúì denotesthe3Davatarrepresentation(bothùúì ùëî,ùúì ùëê), andtheirSMPL-Xfits(SMPL-X)forshapeinitializationpurposes.
ùë†istheguidancescale,wefollowNFDSandsetùë† =7.5. A-Pose SMPL-X & Scan. Almost all ‚ÄúText-to-Avatar‚Äù meth-
RepresentationandInitialziation.The3Dhumanavataris ods [Cao et al. 2024; Huang et al. 2024a; Kolotouros et al. 2023;
parameterizedwithDMTet[Gaoetal.2020;Shenetal.2021],a Liaoetal.2024;Yuanetal.2023]useanA-posebodyforshape
flexibletetrahedron-based3Dneuralrepresentation.Thegeometry, initializationduetoitsminimalself-occlusions.Thus,weadhereto
ùúì g,andappearance,ùúì c,areoptimizable,andcanbedifferentially thisempiricalsettinginPuzzleIOI.Foreachsubject(ID+Outfit),we
renderedintonormal,n,andcoloredimages,c.Thegeometryùúì ùëîis captureaground-truthA-posed3DscanandfitaSMPL-Xmodel
firstinitializedtoanA-posedSMPL-Xbody[Pavlakosetal.2019]. toit,asinAGORA[Pateletal.2021].
Optimization.Weusethefull-textdescriptionofthehuman MultipleViews.Tosimulatethediversityandimperfectionsof
ùëùallasaguidingprompt.Itisaconcatenationoftextpromptsfrom real-worldphotos,foreachsubject(ID+outfit)werandomlysample
allassetsi.e.,(ùë£ ùëñ,ùëê ùëñ),...,(ùë£ ùêæ,ùëê ùêæ).Weoptimizegeometryandcolor 120photosfromthemulti-viewhumanactionsequence(approx.760
separatelyintwooptimizationstages,bothusingNoise-Free-Score frames/subject)capturedby22cameras;seeFig.2.Thecaptured
Distillation(NFSD).Inthefirststage,theavatar‚Äôsgeometryisguided imagesaresegmentedandshuffledtobuildthetrainingdatasetfor
inthesurfacenormalspace,‚àáLnorm ‚â° ‚àáL NFDS[n,ùúì ùëî].Weaddi- PuzzleBooth(Section3.1).
tionallyprepend‚Äúa detailed sculpture of‚Äùtothefull-textto Text Description. Similar to how image captioning is done
indicatetheguidancespace.Inthesecondstage,itsappearance inSection3.1,herewerandomlyselecttwofrontalfull-bodyim-
is guided by ‚àáLcolor ‚â° ‚àáL NFDS[c,ùúì ùëê]. The camera settings for agesanduseGPT-4Vtoquerytheassetnamesandcorresponding
multi-viewSDSareinAppendixB. descriptionsofvisibleassets.Weusethepositionoftheground
truthcameratocategorizethephotosinto4viewgroups{front,
4 EXPERIMENTS back, side, overhead}inPuzzleIOI,whileweuseGPT-4Vto
automaticallylabelviewpointsfromin-the-wildimages.
Ithasbeenalong-standingchallengeinthefieldof‚ÄúText-to-3D‚Äù
(including‚ÄúText-to-Avatar‚Äù)toquantitativelybenchmarknewal-
gorithms.Existingbenchmarksaretypicallylessreliablebecause 1https://www.ioindustries.com/cameras6 ‚Ä¢ Xiu,etal.
4.2 2Dand3DMetrics
non-humanartifactsarisewhensegmentationornormalmapesti-
We conduct quantitative evaluation on the PuzzleIOI dataset
mationfails.(3)Improvedgeometry-texturedisentanglement,where
(Sec. 4.1). To evaluate the quality of shape reconstruction we PuzzleAvatarexcelsinseparatingshirtstripescomparedtoTeCH
reportthreemetrics:(1)Chamferdistance(bidirectionalpoint-to- Thismainlyattributestothefailednormalmapestimatedfromthe
surface,cmasunit),(2)P2Sdistance(1-directionalpoint-to-surface, inputimage(seeFig.73throw,rightmostnormalestimate).,which
cmasunit)distance,and(3)L2errorforNormalmapsrendered reliesonoftenincorrectlyestimatednormalmapsfromtheinput
forfourviews({0‚ó¶,90‚ó¶,180‚ó¶,270‚ó¶})tocapturelocalsurfacedetails. image. Notably, MVDreamBooth highlights PuzzleAvatar‚Äôs profi-
Toevaluatethequalityofappearancereconstruction,weren- ciencyinproducingintricategeometricdetailsandtextures.We
dermulti-viewcolorimagesasabove,andreportthreeimage-quality alsocomparewithAvatarBooth[Zengetal.2023],whichaddresses
metrics:PSNR(PeakSignal-to-NoiseRatio),SSIM(StructuralSimi- thesimilarproblem.Sinceitscodeandtrainedmodelshavenotbeen
larity)andLPIPS(LearnedPerceptualImagePathSimilarity). releasedyet,wetestPuzzleAvataronthesamephotocollections
usedbyAvatarBooth,andshowtheresultsinFig.10andvideo.
4.3 Benchmark
4.4 Ablations
PuzzleAvatarisageneralframework,compatiblewithdifferentdif-
Ablation:CommonPractices.InTable3-B,weanalyzetheeffect
fusionmodels.InTable2webenchmarkvariantsofPuzzleAvatar
of common practices that have been shown to be beneficial for
with twodifferent backbones:(1) vanilla StableDiffusion [Rom-
bachetal.2022],i.e.,SD-2.12,and(2)MVDream[Shietal.2024]3 generalscenes,includingview-specificprompt[Ruizetal.2023],
NFSDovervanillaSDS[Katziretal.2024],andpriorpreservation
fine-tuned from vanilla SD using multi-view images rendered
loss[Huangetal.2024a;Ruizetal.2023].Theperformancegain
from Objaverse [Deitke et al. 2023]. The shared basic pipeline
confirmsthatourproblemalsobenefitsfromthesepractices.Some
for our PuzzleAvatar, the state-of-the-art image-to-3D methods
qualitativecomparisonsareshowninFigs.8and9.Ourablation
TeCH[Huangetal.2024b]andMVDreamBooth[Shietal.2024]is:
resultsshowtheeffectivenessofPuzzleIOImetricsinmeasuring
1)firsttofinetunethesebackboneswithsubjectimagesand2)later
theperformanceofdifferentmethodsinoursetting,andalsohelp
toextractavatarswithtext-guidedSDSoptimization.
usanswerthefollowingquestions.
QuantitativeEvaluation.Table2showsthatPuzzleAvatarison
parwithTeCHon3Dmetrics,whileoutperformingitonall2D
Doestheviewprompt[ùëë]helpsthereconstruction?Yes.This
metrics.Notethat,toenhanceshapequality,TeCHemploysmultiple isacommonpracticeofnumerousexistingworks[Chenetal.2023;
supervisionsignalsandregluarizationterms,includingnormalmaps Huang et al. 2024b; Liao et al. 2024; Poole et al. 2023], and has
predictedfromtheinputimageviaECON[Xiuetal.2023],silhouette notyetbeenquantitativelyjustified.AsdetailedinTable3(B.w/o
masksproducedbySegFormer[Xieetal.2021]andaLaplacian viewprompt),thenormalerrorincreasedby+9.3%.Apartfromview
regularizer.Intermsoftexturequality,TeCHusesanRGB-based promptscaptionedbyLLM,thereisstillroomtogrowwithimproved
chamferlosstominimizecolorshiftbetweentheinputimageand representativesforcameras,suchascameraposeembeddingused
the backside texture, while its front-side texture is achieved by inLGM[Tangetal.2024]andCameras-as-Rays[Zhangetal.2024].
back-projectingtheinputimage.Incontrast,PuzzleAvatarachieves DoesNSFDoutperformsvanillaSDS?Yes.Forfaircomparison,
on-par3Daccuracyandbettertexturequalitywithoutanyofthese wesettheguidancescaleùë† = 7.5forbothNSFDandvanillaSDS.
auxiliarylosses,regularizers,orpixelback-projection. AsdetailedinTable3(B.w/oNFSD),comparedwithNFSD(Noise-
As for the MVDream-based comparison, PuzzleAvatar outper- FreeScoreDistillation[Katziretal.2024]),vanillaSDSdegrades
formsMVDreamBoothontexturequalitybyalargemargin(PSNR thegeometryqualityabitby+2.2%,whileconsiderablydegrading
+10.09%,LPIPS-8.79%),andongeometryquality(measuredbyCham- thetexturequality(PSNR+17.3%,LPIPS+16.4%),astheSDSoften
ferandP2S),whileshowingcomparativeperformancewiththebase- crashes,leadingtofull-gray/yellowtextures.
linesonnormalconsistency.ThekeydifferenceofPuzzleAvatar,
comparedtoMVDreamBoothandTeCH,isitspuzzle-wisetraining Doesthesynthetichumanpriorhelps?Yes,anditsignificantly
strategy.Withoutthis,2Ddiffusionmodelsfine-tunedonhuman improvesthereconstructionquality,inboththegeometry(chamfer
photoswithcomplexposesandcroppingmightproducecompletely error-38.1%,P2Serror-58.8%,Normalerror-73.3%),andtexture
flawed3Dhumans,withlow-quality(evenfullblack)texturesor (PSNR+11.2%,LPIPS-27.9%).Andsyntheticnormalsappeartocon-
overlysmoothshapes;seeFig.7. tributemorethansyntheticRGB(chamfererror-31.5%vs.-5.7%,
LPIPS-21.3%vs.-3.3%).Introducingphotorealisticsyntheticdata
QualitativeEvaluation.AsdepictedinFig.7,PuzzleAvatarhas
duringfine-tuningprovesbeneficial,andtheperformanceboost
variousadvantagesoverTeCH:(1)Enhancedfront-backconsistency,
fromcolor-normalpairssurpassesthatfromonlyusingsinglemode
becausePuzzleAvatartreatallviewswithID-consistentgeneration,
(color/normal)ofdata,suchaschamfer(+38.1%>+31.5%++5.7%)
whileTeCHintroducesinconsistencybetweenthefrontviewcre-
andLPIPS(+27.9%>+21.3%++3.3%),seeFig.5,weattributesuch
atedbyreconstructionandthebackviewcreatedbyimagination.
‚Äú1+1>2effect‚Äùtotheenhancedgeometry-texturealignment,which
(2)Reducednon-humanartifacts,PuzzleAvatarbypassthedepen-
benefitsfromsuchpairwisetraining.PleasecheckoutFig.8for
denceonnumerousoff-the-shelfestimatorsusedinTeCH,forwhich
morequalitativeablationresults.
2huggingface.co/stabilityai/stable-diffusion-2-1-base Can token[ùë£ ùëñ] encodethe identity andfeatures of assets?
3huggingface.co/ashawkey/mvdream-sd2.1-diffusers Yes.AsshowninTable3(A.w/detailedGPT-4Vdescription),bothPuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums ‚Ä¢ 7
Table2. EvaluationonfullPuzzleIOI(933OOTD).‚Ä†meansusingSMPL-Xfitsofground-truthscanstoinitializeDMTetandfactoroutposeerror(unlike
thevanillaTeCH[Huangetal.2024b]thatestimatesSMPL-XusingPIXIE[Fengetal.2021]).Thebestresultsaremarkedwith‚Äúbold‚Äù.‚ÄúRatio%‚Äùistherelative
performancedrop,while‚Äúratio%‚Äùistherelativeperformancegain,w.r.t.thecompetitors,i.e.TeCHandMVDreamBooth[Shietal.2024].
Method Backbone 3DMetrics(Shape) 2DMetrics(Color)
Chamfer‚Üì P2S‚Üì Normal‚Üì PSNR‚Üë SSIM‚Üë LPIPS‚Üì
TeCH‚Ä† SD-2.1-base 1.646 1.590 0.076 23.635 0.919 0.065
PuzzleAvatar SD-2.1-base 1.617-1.76% 1.613+1.45% 0.077+1.32% 24.687+4.45% 0.930+1.20% 0.062-4.62%
MVDreamBooth‚Ä† MVDream 1.705 1.835 0.100 19.401 0.909 0.091
PuzzleAvatar MVDream 1.697-0.47% 1.811-1.31% 0.101+1.00% 21.361+10.09% 0.906-0.33% 0.083-8.79%
Table3. AblationstudyonsubsetofPuzzleIOI(120OOTD).Thebestresultsaremarkedwith‚Äúbold‚Äù,thesecondbestresultsaremarkedwithand
underline.The‚Äúratio%‚Äùistherelativeperformancedrop,and‚Äúratio%‚Äùistherelativeperformancegain,w.r.t. PuzzleAvatar,wherethedroplargerthan20%
aremarkedwith‚Äúbold‚Äù.Group-Asummarizesthefailedattempts,Group-Bjustifiesthekeycomponents,andGrounp-Canalysesthescalabilityofourmethod.
Group Method 3DMetrics(Shape) 2DMetrics(Color)
Chamfer‚Üì P2S‚Üì Normal‚Üì PSNR‚Üë SSIM‚Üë LPIPS‚Üì
TeCH‚Ä† 1.600 1.541 0.073 23.665 0.919 0.065
PuzzleAvatar 1.589 1.570 0.075 24.718 0.931 0.061
A. w/detailedGPT-4Vdescription 1.604+0.9% 1.607+2.4% 0.079+5.3% 24.208-2.1% 0.929-0.2% 0.062+1.6%
w/oviewprompt 1.641+3.3% 1.653+5.3% 0.082+9.3% 23.929-3.2% 0.928-0.3% 0.064+4.9%
w/oNFSD(vanillaSDS) 1.624+2.2% 1.604+2.2% 0.072-4.0% 20.441-17.3% 0.923-0.9% 0.071+16.4%
B. w/osyntheticnormal+color 2.194+38.1% 2.493+58.8% 0.130+73.3% 21.940-11.2% 0.912-2.0% 0.078+27.9%
w/osyntheticnormal 2.089+31.5% 2.335+48.7% 0.123+64.0% 23.684-4.2% 0.919-1.3% 0.074+21.3%
w/osyntheticcolor 1.680+5.7% 1.687+7.5% 0.084+12.0% 23.813-3.7% 0.927-0.4% 0.063+3.3%
C. multi-subjecttraining(5subjects/model) 1.809+13.8% 1.560-0.6% 0.080+6.7% 24.990+1.1% 0.929-0.2% 0.062+1.6%
w/ofull-bodyimages 1.603+0.9% 1.580+0.6% 0.073-2.7% 23.703-4.1% 0.9310.0% 0.062+1.6%
50%trainingdata 1.590+0.1% 1.569-0.1% 0.074-1.3% 24.095-2.5% 0.930-0.1% 0.0610.0%
10%trainingdata 1.583-0.4% 1.531-2.5% 0.069-8.0% 23.477-5.0% 0.928-0.3% 0.062+1.6%
(i.e.,completeimages),slightlydecreasesthequalityofbothge-
Fig.5. ‚Äú1+1>2Effect‚ÄùofSyntheticPriors.Allthenumbersrefertothe
ometryandtexture(Chamfer+0.9%andPSNR-4.1%;Table3,C.
performancegain(%),whereFullmeanstrainingwithcolor-normalpairs,
w/ofull-bodyimages)..Nevertheless,itisunsurprisingtofindthat
andRGBandNormalmeanstrainingwithsinglemodality.
PuzzleAvatarwithouttrainingonfull-bodyimagesstilloutperforms
Chamfer P2S Normal thebestTeCHsetting(bettertexturepluson-pargeometryquality).
Full RGB Normal Full RGB Normal Full RGB Normal
40 60 80
30 60 HowmuchdatadoesPuzzleAvatarneed?Withjustafraction
40
20 40 ofthetrainingdata(10%),PuzzleAvatarcanalreadyachievesat-
20
10 20 isfactoryreconstructionperformance.Asthenumberoftraining
0 0 0 imagesincreasing,theviewsynthesisperformanceinitiallykeeps
chamfer chamfer (full) P2S P2S (full) Normal Normal (full)
PSNR SSIM LPIPS improvinginbothtextureandgeometryquality(showninTable3,
Full RGB Normal Full RGB Normal Full RGB Normal
12 2.5 30 C.50%/10%trainingdata)butinterestinglystartstodeterioratein
10 2 geometryquality.WehypothesizethattrainingPuzzleBoothusing
8 20
1.5 moreRGBimagescouldimpairthequaliyofSDSgradientsinthe
6
4 1 10 spaceofnormalmaps,thusdegradingthegeometryoptimizedvia
2 0.5 SDS.Wefindsomeempiricalevidencesupportingthishypothesis
0 PSNR PSNR (full) 0 SSIM SSIM (full) 0 LPIPS LPIPS (full) Table3(B.withoutsyntheticnormal),wheretheabsenceofnormal
priorsleadstoanotabledeclineingeometryqualitycomparedto
shape and color quality slightly decrease when too-detailed de- texture(P2S+48.7%vs.SSIM-1.3%).
scriptionsareusedintheprompt,suchas‚Äúwearing sleeveless
<asset1> t-shirts, and fitted <asset2> jeans‚Äù,instead
DoesPuzzleAvatarsupportmulti-subjecttraining?Yes.Infact,
of ‚Äúwearing <asset1> t-shirts, and <asset2> jeans‚Äù.
andperhapssurprisingly,multi-subjecttrainingevenslightlyim-
Surprisingly,moredetailedpromptscanintroducebias,conflicting
provesreconstructionquality(Table3-C).Thisdemonstratesthe
withtheoriginalidentityandharmingperformance;seeFig.9.
powerofStableDiffusiontoprocessandintegratenumeroushuman
DoesPuzzleAvatarworkwithoutusinganyfull-bodyshots? identitiessimultaneously,andtherobustnessofourpuzzle-based
Yesbutwithsomeperformancedrop.Excludingthefull-bodyshots trainingstrategyinlearningdisentangledhumanidentities.8 ‚Ä¢ Xiu,etal.
PuzzleAvatar
Wrong Garment Type ‚Üí Long or Short Coat? Garment Hallucination ‚Üí Black or White Pants?
TeCH
Conflict ‚Üí predicted normal vs. SDS Thin structures‚Üí Hat or ahoge? Guidance Collapse ‚Üí White or Red Pants?
(a) TeCH may create non-human noisy artifacts (b) PuzzleAvatar creates realistic 3D humans, but struggles from ‚Ä¶
Fig.6. FailureCases.Non-humanartifactsmainlycauseerrorsinTeCH(seea),whereaserrorsinPuzzleAvatarstemfromhallucinationandflawedDMTet
modelingofthinstructures.Fortheright-topcase,theblackpantsshowingthroughthewhitecoat,whilerealistic,deviatesfromtheoriginalinput.Asaresult
ofthishallucination,thefailuresofPuzzleAvatararedistinctfromground-truth,butnotcompletelycatastrophic(seeb).
03626-02 03588-24
5 APPLICATIONS
PotentialNegativeEffect.AsdiscussedinSec.4.4,theperfor-
ThecompositionalityofPuzzleAvatarthroughitstokensandtext manceofPuzzleAvatarreliesheavilyonexistingpublic/commercial
promptssupportsdiverseapplicationslikeVirtualTry-Onandtext- syntheticdatasetsandthereforemayinherittheirgender,racialand
guidedavatarediting,asshownin Fig.1andvideo.Moreover,the agebiases.Onemayaddresssuchanissuebycuratingbalanced
A-Po03 s6 e17 d-0 o5 utputcansimplifytheriggingandskinni0 n3 g607 p-0 r2
ocess.With
‚Äú<assetd Aa>t sahsiret‚Äùtsfromreal-wo03 r6 l2 d‚Äú<1a-0 ism2set aBg> sehsirt(‚Äùwithoff-the-shelfmethodstoes-
theunderlyingSMPL-Xparametricbody,the3Doutputcouldbe timatenormals[BaeandDavison2024;Saitoetal.2020;Xiuetal.
easilyanimatedwithSMPL-Xmotiondata,likeAMASS[Mahmood 2023,2022])orbysimplybuildingbettersyntheticdatasets.
etal.2019]andAIST++[Lietal.2021],asthecommonpractice ContributionstotheCommunity.PuzzleAvatarpavestheway Unconstrained Photo Collections B
in[Huangetal.2020;Xiuetal.2022;Zhengetal.2021]. inreconstructingarticulatedhumansfrompersonal,naturalphoto
collections ‚Äì introducing the new ‚ÄúAlbum2Human‚Äù task. Mean-
6 CONCLUSION while,PuzzleIOIoffersanewbenchmarkthatfacilitatesobjective
evaluationofvariousdiffusion-model-basedtechniques,including
Limitations&FutureWork.SincePuzzleAvatarbuildsonPuz-
butnotlimitedtomodelcustomization,modelpersonalizationand
zleBoothandScoreDistillationSampling(SDS),whileusingnore-
distillationsampling.Webelievethatournewtask,Album2Human,
projecUtnioconnstterarimneds ,Pshootmo Ceolhleactlilounsc Ainationisinevitable.AsTFexitgur.e6d 3sDh Houwmsa,n A Virtual Try-On (A+B) Textured 3D Human B
togetherwithournewbenchmark,PuzzleIOI,couldpushthebound-
PuzzleAvatarmayincorrectlyhallucinategarmenttextureortypes,
ary of the field of AI-Generated Content (AIGC). Furthermore,
andsufferfromdescriptioncontamination,acommonissueinT2I
PuzzleAvatar offers a simple yet scalable reconstruction system,
models.Despitebeingtrainedwithsyntheticpaireddata,ourmodel
withwhichusersmayignorethetechnicaldetailsofreconstruction
sometimesstrugglestoperfectlydisentangleshapeandcolor,lead-
parameters.Moreimportantly,webelievethatPuzzleAvatardemon-
ingtobaked-intexture.Additionally,preservingfacialidentityis stratesanewandpracticalparadigmfor‚Äúpuzzle-assembledclothed
challengingwithouthigh-resolutionheadshotselfiesinthetraining humanreconstruction‚Äù thatproducesa3Davatarfromeveryday
data.Potentialsolutionsforbetteridentitypreservationmayinclude
photosinascalableandconstraint-freemanner.
enhancingsegmentedfaceswithsuper-resolutiontechniques[Wang
‚Ä¶long shirt‚Ä¶ ‚Ä¶blue jeans‚Ä¶ ‚Ä¶yellow hat‚Ä¶
etal.2022],conductingpersonalizedrestoration[Charietal.2023],
orincorporatingfaceIDembeddings[Wangetal.2024a]. Text-guided Attributes Editing
Acknowledgments.WethankPeterKulitsandYandongWenfor
PuzzleAvatar‚Äôsmainissuecurrentlyisitscomputationalcomplex-
proofreading,YifeiZengforprovidingtheresultsofAvatarBooth,
ity,asspendingroughly4hourstotrainPuzzleBoothandperform
YameiChenandKexinWangforteaserphotos,JiaxiangTang,Yangyi
SDS-basedoptimizationisimpracticalforcertainapplications.In
Huang,NikosAthanasiou,YaoFengandWeiyangLiuforfruitfuldis-
thefuturewewillexplorebettertraining-freestrategies[Lietal.
cussions, Jinlong Yang and Tsvetelina Alexiadis for data capture.
2024;Teweletal.2024]andbettersamplingmethodsfordiffusion
ThisprojecthasreceivedfundingfromtheEuropeanUnion‚ÄôsHori-
models[Luoetal.2023;Songetal.2023].Besides,thecomposi-
zon 2020 research and innovation programme under the Marie
tional3Dcouldbeachievedthroughnon-watertightandmulti-layer
Sk≈Çodowska-CuriegrantagreementNo.860768(CLIPEproject).Yufei
representations[Fengetal.2022;Liuetal.2024a;Sonetal.2024].
Ye‚ÄôsPhDresearchispartiallysupportedbyaGoogleGift.
Multi-subjecttrainingwithPuzzleAvatarseemspromising.Thus,
itmightbefeasibletoextendPuzzleAvatartodecentralizedtrain- Disclosure.MJBhasreceivedresearchgiftfundsfromAdobe,Intel,
ingsettings.Byfine-tuningasharedT2Imodelthroughfederated Nvidia,Meta/Facebook,andAmazon.MJBhasfinancialinterests
learning[LiangzeandLin2023],usersacrosstheglobecouldupload in Amazon and Meshcapade GmbH. While MJB is a co-founder
theirpersonalalbumstobuildaglobal‚Äústyleset‚Äùofreallydiverse andChiefScientistatMeshcapade,hisresearchinthisprojectwas
clothing,accessories,andhairstyles,forcustomizingavatars. performedsolelyat,andfundedsolelyby,theMaxPlanckSociety.PuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums ‚Ä¢ 9
PuzzleAvatar (Geometry) PuzzleAvatar (Texture)
(03626-20) Reference
Training Data
TeCH (Geometry) TeCH (Texture)
(03618-17)
PuzzleAvatar (Geometry) PuzzleAvatar (Texture)
Reference
Training Data
TeCH (Geometry) TeCH (Texture)
(03633-15)
PuzzleAvatar (Geometry) PuzzleAvatar (Texture)
Reference
Training Data
TeCH (Geometry) TeCH (Texture)
Image2Normal
(ECON)
(03590-16)
PuzzleAvatar (Geometry) PuzzleAvatar (Texture)
Reference
Training Data
MVDreamBooth (Geometry) MVDreamBooth (Texture)
Fig.7. QualitativeResults.WecomparePuzzleAvatar,TeCHandMVDreamBoothonrandomlysampledsubjects.PuzzleAvataroffersvariousadvantagesover
TeCH:(1)Enhancedfront-backconsistency.(2)Reducednon-humanartifacts.(3)Improvedgeometry-texturedisentanglement.Atthebottom,MVDreamBooth
highlightsPuzzleAvatar‚Äôsproficiencyinproducingintricategeometricdetailsandtextures.(cid:252)Zoomintoseemore3Dandcolordetails.03626-02 Wrong Garment Type ‚Üí Long or Short Coat? 03588-24 Garment Hallucination ‚Üí Black or White Pants?
10 ‚Ä¢ Xiu,etal.
03607-02 Thin Structure ‚Üí Hat or Dyeing Hair? 03621-02 Description Contamination ‚Üí White or Red Pants?
(b) Failure cases of TeCH (b) Failure cases of PuzzleAvatar
PuzzleAvatar (Body) PuzzleAvatar (Head)
03584-25
PuzzleAvatar w/o Synthetic Prior (Body) PuzzleAvatar w/o Synthetic Prior (Head)
PuzzleAvatar (Body) PuzzleAvatar (Head)
03626-02 Wrong Garment Type ‚Üí Long or Short Coat? 03588-24 Garment Hallucination ‚Üí Black or White Pants?
03626-16
PuzzleAvatar w/o Synthetic Prior (Body) PuzzleAvatar w/o Synthetic Prior (Head)
Fig.8. HowSyntheticPriorHelps?SeeFig.5formorein-de03p607t-h02analyThsini Sstr.ucture ‚Üí Hat or Dyeing Hair? 03621-02 Description Contamination ‚Üí White or Red Pants?
(b) Failure cases of TeCH (b) Failure cases of PuzzleAvatar
PuzzleAvatar (‚Äú<asset 01> haircut‚Äù ) PuzzleAvatar (‚Äú<asset 02> face‚Äù )
‚Ä¶long shirt‚Ä¶ ‚Ä¶blue jeans‚Ä¶
Unconstrained Photo Collections A Textured 3D Human A Virtual Try-On (A+B)
PuzzleAvatar w/ Detailed Description (‚Äú<asset 01> short haircut‚Äù ) PuzzleAvatar w/ Detailed Description (‚Äú<asset 02> oval face‚Äù )
Fig.9. Detailedvs.PlainPromptToken<assetX>sufficestomaintaintheappearanceofassets.Elaboratepromptscouldintroducebiasandhallucination.
PuzzleAvatar (Geometry) PuzzleAvatar (Texture)
Training Data AvatarBooth (Geometry) AvatarBooth (Texture)
(AvatarBooth)
Fig.10. AvatarBooth[Zengetal.2023]vs.Pu‚Ä¶zlozng lsehirAt‚Ä¶vata‚Ä¶rbluAe jevanas‚Ä¶tarBoothintroducesasimilartask,butoverlooksthecompositionalityofgarmentsand
utilizestwoseparateDreamBooths(Head,Body)alongwithControlNet,makingitmorecomplexandlessscalablethanPuzzleAvatar.
Unconstrained Photo Collections A Textured 3D Human A Virtual Try-On (A+B)PuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums ‚Ä¢ 11
REFERENCES
realistic3dhumangeneration. ComputerVisionandPatternRecognition(CVPR)
ThiemoAlldieck,MarcusA.Magnor,WeipengXu,ChristianTheobalt,andGerard (2024).
Pons-Moll.2018a.DetailedHumanAvatarsfromMonocularVideo.InInternational YukunHuang,JiananWang,AilingZeng,HeCao,XianbiaoQi,YukaiShi,Zheng-Jun
Conferenceon3DVision(3DV). Zha,andLeiZhang.2023a.DreamWaltz:MakeaScenewithComplex3DAnimatable
ThiemoAlldieck,MarcusA.Magnor,WeipengXu,ChristianTheobalt,andGerard
Avatars.InConferenceonNeuralInformationProcessingSystems(NeurIPS).
Pons-Moll.2018b.VideoBasedReconstructionof3DPeopleModels.InComputer YangyiHuang,HongweiYi,WeiyangLiu,HaofanWang,BoxiWu,WenxiaoWang,
VisionandPatternRecognition(CVPR). BinbinLin,DebingZhang,andDengCai.2023b. One-shotImplicitAnimatable
NikosAthanasiou,MathisPetrovich,MichaelJ.Black,andG√ºlVarol.2023. SINC:
AvatarswithModel-basedPriors.InInternationalConferenceonComputerVision
SpatialCompositionof3DHumanMotionsforSimultaneousActionGeneration.
(ICCV).
InternationalConferenceonComputerVision(ICCV)(2023). YangyiHuang,HongweiYi,YuliangXiu,TingtingLiao,JiaxiangTang,DengCai,and
OmriAvrahami,KfirAberman,OhadFried,DanielCohen-Or,andDaniLischinski.2023. JustusThies.2024b.TeCH:Text-guidedReconstructionofLifelikeClothedHumans.
Break-A-Scene:ExtractingMultipleConceptsfromaSingleImage.InSIGGRAPH InInternationalConferenceon3DVision(3DV).
Asia2023ConferencePapers(SA‚Äô23). ZengHuang,YuanluXu,ChristophLassner,HaoLi,andTonyTung.2020. ARCH:
GwangbinBaeandAndrewJ.Davison.2024.RethinkingInductiveBiasesforSurface
AnimatableReconstructionofClothedHumans.InComputerVisionandPattern
NormalEstimation.InComputerVisionandPatternRecognition(CVPR). Recognition(CVPR).
WenjingBian,ZiruiWang,KejieLi,Jia-WangBian,andVictorAdrianPrisacariu.2023. MustafaI≈üƒ±k,MartinR√ºnz,MarkosGeorgopoulos,TarasKhakhulin,JonathanStarck,
Nope-nerf:Optimisingneuralradiancefieldwithnoposeprior.InComputerVision LourdesAgapito,andMatthiasNie√üner.2023. HumanRF:High-FidelityNeural
andPatternRecognition(CVPR). RadianceFieldsforHumansinMotion.TransactionsonGraphics(TOG)(2023).
TimBrooks,BillPeebles,ConnorHolmes,WillDePue,YufeiGuo,LiJing,DavidSchnurr, AjayJain,BenMildenhall,JonathanT.Barron,PieterAbbeel,andBenPoole.2022.
JoeTaylor,TroyLuhman,EricLuhman,ClarenceNg,RickyWang,andAditya
Zero-ShotText-GuidedObjectGenerationwithDreamFields.InComputerVision
Ramesh.2024.Videogenerationmodelsasworldsimulators.(2024).
andPatternRecognition(CVPR).
ZhongangCai,DaxuanRen,AilingZeng,ZhengyuLin,TaoYu,WenjiaWang,Xiangyu OrenKatzir,OrPatashnik,DanielCohen-Or,andDaniLischinski.2024. Noise-free
Fan,YangGao,YifanYu,LiangPan,FangzhouHong,MingyuanZhang,ChenChange
ScoreDistillation.InInternationalConferenceonLearningRepresentations(ICLR).
Loy,LeiYang,andZiweiLiu.2022.HuMMan:Multi-modal4Dhumandatasetfor BingxinKe,AntonObukhov,ShengyuHuang,NandoMetzger,RodrigoCayeDaudt,
versatilesensingandmodeling.InEuropeanConferenceonComputerVision(ECCV). andKonradSchindler.2024. Repurposingdiffusion-basedimagegeneratorsfor
YukangCao,Yan-PeiCao,KaiHan,YingShan,andKwan-YeeKWong.2024.DreamA- monoculardepthestimation. ComputerVisionandPatternRecognition(CVPR)
vatar:Text-and-ShapeGuided3DHumanAvatarGenerationviaDiffusionModels. (2024).
ComputerVisionandPatternRecognition(CVPR)(2024). AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,Laura
PradyumnaChari,SizhuoMa,DaniilOstashev,AchutaKadambi,GurunandanKrishnan, Gustafson,TeteXiao,SpencerWhitehead,AlexanderCBerg,Wan-YenLo,etal.
JianWang,andKfirAberman.2023.PersonalizedRestorationviaDual-PivotTuning.
2023.Segmentanything.InInternationalConferenceonComputerVision(ICCV).
arXivpreprintarXiv:2312.17234(2023). PeterKocsis,VincentSitzmann,andMatthiasNie√üner.2024.IntrinsicImageDiffusion
MingjinChen,JunhaoChen,XiaojunYe,Huan-angGao,XiaoxueChen,ZhaoxinFan,
forSingle-viewMaterialEstimation.InComputerVisionandPatternRecognition
andHaoZhao.2024.Ultraman:SingleImage3DHumanReconstructionwithUltra
(CVPR).
SpeedandDetail.arXivpreprintarXiv:2403.12028(2024). NikosKolotouros,ThiemoAlldieck,AndreiZanfir,EduardGabrielBazavan,Mihai
RuiChen,YongweiChen,NingxinJiao,andKuiJia.2023.Fantasia3D:Disentangling Fieraru,andCristianSminchisescu.2023.DreamHuman:Animatable3DAvatars
GeometryandAppearanceforHigh-qualityText-to-3DContentCreation.InInter- fromText.InConferenceonNeuralInformationProcessingSystems(NeurIPS).
nationalConferenceonComputerVision(ICCV). NupurKumari,BingliangZhang,RichardZhang,EliShechtman,andJun-YanZhu.
WeiCheng,RuixiangChen,WanqiYin,SimingFan,KeyuChen,HonglinHe,Huiwen
2023.Multi-ConceptCustomizationofText-to-ImageDiffusion.ComputerVision
Luo,ZhongangCai,JingboWang,YangGao,ZhengmingYu,ZhengyuLin,Daxuan
andPatternRecognition(CVPR)(2023).
Ren,LeiYang,ZiweiLiu,ChenChangeLoy,ChenQian,WayneWu,DahuaLin,Bo JunnanLi,DongxuLi,CaimingXiong,andStevenHoi.2022. Blip:Bootstrapping
Dai,andKwan-YeeLin.2023.DNA-Rendering:ADiverseNeuralActorRepository language-imagepre-trainingforunifiedvision-languageunderstandingandgenera-
forHigh-FidelityHuman-centricRendering.InInternationalConferenceonComputer tion.InInternationalConferenceonMachineLearning(ICML).PMLR.
Vision(ICCV). RuilongLi,YuliangXiu,ShunsukeSaito,ZengHuang,KyleOlszewski,andHaoLi.
MattDeitke,DustinSchwenk,JordiSalvador,LucaWeihs,OscarMichel,EliVanderBilt,
2020.Monocularreal-timevolumetricperformancecapture.InEuropeanConference
LudwigSchmidt,KianaEhsani,AniruddhaKembhavi,andAliFarhadi.2023.Obja-
onComputerVision(ECCV).
verse:Auniverseofannotated3dobjects.InComputerVisionandPatternRecognition RuilongLi,ShanYang,DavidARoss,andAngjooKanazawa.2021.Aichoreographer:
(CVPR). Musicconditioned3ddancegenerationwithaist++.InInternationalConferenceon
YaoFeng,VasileiosChoutas,TimoBolkart,DimitriosTzionas,andMichaelJ.Black.2021.
ComputerVision(ICCV).
CollaborativeRegressionofExpressiveBodiesusingModeration.InInternational ZhenLi,MingdengCao,XintaoWang,ZhongangQi,Ming-MingCheng,andYingShan.
Conferenceon3DVision(3DV). 2024.PhotoMaker:CustomizingRealisticHumanPhotosviaStackedIDEmbedding.
YaoFeng,JinlongYang,MarcPollefeys,MichaelJ.Black,andTimoBolkart.2022.Cap-
InComputerVisionandPatternRecognition(CVPR).
turingandAnimationofBodyandClothingfromMonocularVideo.InSIGGRAPH JiangLiangzeandTaoLin.2023. Test-TimeRobustPersonalizationforFederated
Asia2022ConferencePapers(SA‚Äô22). Learning.InInternationalConferenceonLearningRepresentations(ICLR).
XiaoFu,WeiYin,MuHu,KaixuanWang,YuexinMa,PingTan,ShaojieShen,Dahua TingtingLiao,HongweiYi,YuliangXiu,JiaxiangTang,YangyiHuang,JustusThies,and
Lin,andXiaoxiaoLong.2024b.GeoWizard:UnleashingtheDiffusionPriorsfor3D
MichaelJ.Black.2024.TADA!TexttoAnimatableDigitalAvatars.InInternational
GeometryEstimationfromaSingleImage.arXivpreprintarXiv:2403.12013(2024). Conferenceon3DVision(3DV).
YangFu,SifeiLiu,AmeyKulkarni,JanKautz,AlexeiAEfros,andXiaolongWang.2024a. Chen-HsuanLin,Wei-ChiuMa,AntonioTorralba,andSimonLucey.2021.Barf:Bundle-
COLMAP-Free3DGaussianSplatting. ComputerVisionandPatternRecognition adjustingneuralradiancefields.InInternationalConferenceonComputerVision
(CVPR)(2024). (ICCV).
GegeGao,WeiyangLiu,AnpeiChen,AndreasGeiger,andBernhardSch√∂lkopf.2024. LixiangLin,SongyouPeng,QijunGan,andJiankeZhu.2024.FastHuman:Reconstruct-
GraphDreamer:Compositional3DSceneSynthesisfromSceneGraphs.InComputer ingHigh-QualityClothedHumaninMinutes.InInternationalConferenceon3D
VisionandPatternRecognition(CVPR). Vision,3DV.
JunGao,WenzhengChen,TommyXiang,AlecJacobson,MorganMcGuire,andSanjaFi- RuoshiLiu,RundiWu,BasileVanHoorick,PavelTokmakov,SergeyZakharov,andCarl
dler.2020.Learningdeformabletetrahedralmeshesfor3dreconstruction.Conference Vondrick.2023. Zero-1-to-3:Zero-shotOneImageto3DObject.InInternational
onNeuralInformationProcessingSystems(NeurIPS)(2020). ConferenceonComputerVision(ICCV).
XiangjunGao,XiaoyuLi,ChaopengZhang,QiZhang,YanpeiCao,YingShan,and WeiyangLiu,ZejuQiu,YaoFeng,YuliangXiu,YuxuanXue,LonghuiYu,HaiwenFeng,
LongQuan.2023.ConTex-Human:Free-ViewRenderingofHumanfromaSingle ZhenLiu,JuyeonHeo,SongyouPeng,YandongWen,MichaelJ.Black,AdrianWeller,
ImagewithTexture-ConsistentSynthesis.arXivpreprintarXiv:2311.17123(2023). andBernhardSch√∂lkopf.2024b. Parameter-EfficientOrthogonalFinetuningvia
MarcHabermann,WeipengXu,MichaelZollhoefer,GerardPons-Moll,andChristian
ButterflyFactorization.InternationalConferenceonLearningRepresentations(ICLR)
Theobalt.2020. DeepCap:MonocularHumanPerformanceCaptureUsingWeak (2024).
Supervision.InComputerVisionandPatternRecognition(CVPR).IEEE. ZhenLiu,YaoFeng,YuliangXiu,WeiyangLiu,LiamPaull,MichaelJ.Black,and
FangzhouHong,MingyuanZhang,LiangPan,ZhongangCai,LeiYang,andZiweiLiu. BernhardSch√∂lkopf.2024a.GhostonTheShell:AnExpressiveRepresentationof
2022. Avatarclip:Zero-shottext-drivengenerationandanimationof3davatars. General3DShapes. InternationalConferenceonLearningRepresentations(ICLR)
TransactionsonGraphics(TOG)(2022). (2024).
XinHuang,RuizhiShao,QiZhang,HongwenZhang,YingFeng,YebinLiu,andQing SimianLuo,YiqinTan,LongboHuang,JianLi,andHangZhao.2023. LatentCon-
Wang.2024a.HumanNorm:Learningnormaldiffusionmodelforhigh-qualityand sistencyModels:SynthesizingHigh-ResolutionImageswithFew-StepInference.12 ‚Ä¢ Xiu,etal.
arXiv:2310.04378 InInternationalConferenceonComputerGraphicsandInteractiveTechniques(SIG-
QianliMa,JinlongYang,AnuragRanjan,SergiPujades,GerardPons-Moll,SiyuTang, GRAPH).
andMichaelJ.Black.2020.LearningtoDress3DPeopleinGenerativeClothing.In Daniel Vlasic, Pieter Peers, Ilya Baran, Paul Debevec, Jovan Popoviƒá, Szymon
ComputerVisionandPatternRecognition(CVPR). Rusinkiewicz,andWojciechMatusik.2009.Dynamicshapecaptureusingmulti-view
NaureenMahmood,NimaGhorbani,NikolausF.Troje,GerardPons-Moll,andMichaelJ. photometricstereo.InACMSIGGRAPHAsia2009Papers.
Black.2019.AMASS:ArchiveofMotionCaptureasSurfaceShapes.InInternational HaochenWang,XiaodanDu,JiahaoLi,RaymondAYeh,andGregShakhnarovich.
ConferenceonComputerVision(ICCV). 2023a. ScoreJacobianChaining:LiftingPretrained2DDiffusionModelsfor3D
RicardoMartin-Brualla,NohaRadwan,MehdiSMSajjadi,JonathanTBarron,Alexey Generation.InComputerVisionandPatternRecognition(CVPR).
Dosovitskiy,andDanielDuckworth.2021.Nerfinthewild:Neuralradiancefields JionghaoWang,YuanLiu,ZhiyangDou,ZhengmingYu,YongqingLiang,XinLi,Wen-
forunconstrainedphotocollections.InComputerVisionandPatternRecognition pingWang,RongXie,andLiSong.2023b.DisentangledClothedAvatarGeneration
(CVPR). fromTextDescriptions.arXivpreprintarXiv:2312.05295(2023).
AndreasMeuleman,Yu-LunLiu,ChenGao,Jia-BinHuang,ChangilKim,MinHKim, PengWang,HaoTan,SaiBi,YinghaoXu,FujunLuan,KalyanSunkavalli,Wenping
andJohannesKopf.2023.Progressivelyoptimizedlocalradiancefieldsforrobust Wang,ZexiangXu,andKaiZhang.2024c.PF-LRM:Pose-FreeLargeReconstruction
viewsynthesis.InComputerVisionandPatternRecognition(CVPR). ModelforJointPoseandShapePrediction.InInternationalConferenceonLearning
BenMildenhall,PratulPSrinivasan,MatthewTancik,JonathanTBarron,RaviRa- Representations(ICLR).
mamoorthi,andRenNg.2021.Nerf:Representingscenesasneuralradiancefields QixunWang,XuBai,HaofanWang,ZekuiQin,andAnthonyChen.2024a. In-
forviewsynthesis.Commun.ACM(2021). stantID:Zero-shotIdentity-PreservingGenerationinSeconds. arXivpreprint
OpenAI.2023.GPT-4V(ision)systemcard. arXiv:2401.07519(2024).
PriyankaPatel,Chun-HaoPaulHuang,JoachimTesch,DavidHoffmann,Shashank ShuzheWang,VincentLeroy,YohannCabon,BorisChidlovskii,andRevaudJerome.
Tripathi,andMichaelJ.Black.2021.AGORA:AvatarsinGeographyOptimizedfor 2024b. DUSt3R:Geometric3DVisionMadeEasy. ComputerVisionandPattern
RegressionAnalysis.InComputerVisionandPatternRecognition(CVPR). Recognition(CVPR)(2024).
GeorgiosPavlakos,VasileiosChoutas,NimaGhorbani,TimoBolkart,AhmedAA XintaoWang,LiangbinXie,KeYu,KelvinC.K.Chan,ChenChangeLoy,andChao
Osman,DimitriosTzionas,andMichaelJBlack.2019.Expressivebodycapture:3d Dong.2022.BasicSR:OpenSourceImageandVideoRestorationToolbox.
hands,face,andbodyfromasingleimage.InComputerVisionandPatternRecognition ZiruiWang,ShangzheWu,WeidiXie,MinChen,andVictorAdrianPrisacariu.2021.
(CVPR). NeRF‚Äì:Neuralradiancefieldswithoutknowncameraparameters.arXivpreprint
SidaPeng,ChenGeng,YuanqingZhang,YinghaoXu,QianqianWang,QingShuai, arXiv:2102.07064(2021).
XiaoweiZhou,andHujunBao.2023.ImplicitNeuralRepresentationswithStructured Chung-YiWeng,BrianCurless,PratulP.Srinivasan,JonathanT.Barron,andIra
LatentCodesforHumanBodyModeling. TransactionsonPatternAnalysisand Kemelmacher-Shlizerman.2022.HumanNeRF:Free-ViewpointRenderingofMoving
MachineIntelligence(TPAMI)(2023). PeopleFromMonocularVideo.InComputerVisionandPatternRecognition(CVPR).
BenPoole,AjayJain,JonathanTBarron,andBenMildenhall.2023. DreamFusion: RundiWu,BenMildenhall,PhilippHenzler,KeunhongPark,RuiqiGao,DanielWatson,
Text-to-3dusing2ddiffusion.InInternationalConferenceonLearningRepresentations PratulP.Srinivasan,DorVerbin,JonathanT.Barron,BenPoole,andAleksander
(ICLR). Holynski.2024.ReconFusion:3DReconstructionwithDiffusionPriors.Computer
AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,Sandhini VisionandPatternRecognition(CVPR).
Agarwal,GirishSastry,AmandaAskell,PamelaMishkin,JackClark,Gretchen YitongXia,HaoTang,RaduTimofte,andLucVanGool.2022.Sinerf:Sinusoidalneural
Krueger,andIlyaSutskever.2021. LearningTransferableVisualModelsFrom radiancefieldsforjointposeestimationandscenereconstruction.InBritishMachine
NaturalLanguageSupervision.InInternationalConferenceonMachineLearning VisionConference(BMVC).
(ICML).PMLR. EnzeXie,WenhaiWang,ZhidingYu,AnimaAnandkumar,JoseMAlvarez,andPing
TianheRen,ShilongLiu,AilingZeng,JingLin,KunchangLi,HeCao,JiayuChen, Luo.2021.SegFormer:Simpleandefficientdesignforsemanticsegmentationwith
XinyuHuang,YukangChen,FengYan,ZhaoyangZeng,HaoZhang,FengLi,Jie transformers.InConferenceonNeuralInformationProcessingSystems(NeurIPS).
Yang,HongyangLi,QingJiang,andLeiZhang.2024.GroundedSAM:Assembling ZhangyangXiong,ChenghongLi,KenkunLiu,HongjieLiao,JianqiaoHu,JunyiZhu,
Open-WorldModelsforDiverseVisualTasks. arXiv:2401.14159[cs.CV] ShuliangNing,LingtengQiu,ChongjieWang,ShijieWang,etal.2024. MVHu-
RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBj√∂rnOmmer. manNet:ALarge-scaleDatasetofMulti-viewDailyDressingHumanCaptures.In
2022.High-resolutionimagesynthesiswithlatentdiffusionmodels.InComputer ComputerVisionandPatternRecognition(CVPR).
VisionandPatternRecognition(CVPR). YuliangXiu,JinlongYang,XuCao,DimitriosTzionas,andMichaelJ.Black.2023.ECON:
NatanielRuiz,YuanzhenLi,VarunJampani,YaelPritch,MichaelRubinstein,andKfir ExplicitClothedhumansOptimizedviaNormalintegration.InComputerVisionand
Aberman.2023.DreamBooth:Finetuningtext-to-imagediffusionmodelsforsubject- PatternRecognition(CVPR).
drivengeneration.InComputerVisionandPatternRecognition(CVPR). YuliangXiu,JinlongYang,DimitriosTzionas,andMichaelJ.Black.2022.ICON:Implicit
ShunsukeSaito,ZengHuang,RyotaNatsume,ShigeoMorishima,HaoLi,andAngjoo ClothedhumansObtainedfromNormals.InComputerVisionandPatternRecognition
Kanazawa.2019.PIFu:Pixel-AlignedImplicitFunctionforHigh-ResolutionClothed (CVPR).
HumanDigitization.InInternationalConferenceonComputerVision(ICCV). XiheYang,XingyuChen,DaihengGao,ShaohuiWang,XiaoguangHan,andBaoyuan
ShunsukeSaito,TomasSimon,JasonSaragih,andHanbyulJoo.2020.PIFuHD:Multi- Wang.2024. HAVE-FUN:HumanAvatarReconstructionfromFew-ShotUncon-
LevelPixel-AlignedImplicitFunctionforHigh-Resolution3DHumanDigitization. strainedImages.InComputerVisionandPatternRecognition(CVPR).
InComputerVisionandPatternRecognition(CVPR). XuetingYang,YihaoLuo,YuliangXiu,WeiWang,HaoXu,andZhaoxinFan.2023.
KaiyueShen,ChenGuo,ManuelKaufmann,JuanZarate,JulienValentin,JieSong,and D-IF:Uncertainty-awareHumanDigitizationviaImplicitDistributionField.In
OtmarHilliges.2023.X-Avatar:ExpressiveHumanAvatars.InComputerVisionand InternationalConferenceonComputerVision(ICCV).
PatternRecognition(CVPR). TaoYu,ZerongZheng,KaiwenGuo,PengpengLiu,QionghaiDai,andYebinLiu.2021.
TianchangShen,JunGao,KangxueYin,Ming-YuLiu,andSanjaFidler.2021. Deep InComputerVisionandPatternRecognition(CVPR).
marchingtetrahedra:ahybridrepresentationforhigh-resolution3dshapesynthesis. YeYuan,XuetingLi,YangyiHuang,ShaliniDeMello,KokiNagano,JanKautz,and
ConferenceonNeuralInformationProcessingSystems(NeurIPS)(2021). UmarIqbal.2023.GAvatar:Animatable3DGaussianAvatarswithImplicitMesh
YichunShi,PengWang,JianglongYe,LongMai,KejieLi,andXiaoYang.2024.MV- Learning.arXivpreprintarXiv:2312.11461(2023).
Dream:Multi-viewDiffusionfor3DGeneration.InternationalConferenceonLearning YifeiZeng,YuanxunLu,XinyaJi,YaoYao,HaoZhu,andXunCao.2023.AvatarBooth:
Representations(ICLR)(2024). High-QualityandCustomizable3DHumanAvatarGeneration.arXiv:2306.09864
Sanghyun Son, Matheus Gadelha, Yang Zhou, Zexiang Xu, Ming C. Lin, and (2023).
YiZhou.2024. DMesh:ADifferentiableRepresentationforGeneralMeshes. ChaoZhang,SergiPujades,MichaelBlack,andGerardPons-Moll.2017. Detailed,
arXiv:2404.13445[cs.CV] accurate,humanshapeestimationfromclothed3Dscansequences.InComputer
YangSong,PrafullaDhariwal,MarkChen,andIlyaSutskever.2023.Consistencymodels. VisionandPatternRecognition(CVPR).
InInternationalConferenceonMachineLearning(ICML). JingboZhang,XiaoyuLi,QiZhang,YanpeiCao,YingShan,andJingLiao.2023.Hu-
JiamingSun,XiChen,QianqianWang,ZhengqiLi,HadarAverbuch-Elor,Xiaowei manRef:SingleImageto3DHumanGenerationviaReference-GuidedDiffusion.
Zhou,andNoahSnavely.2022.Neural3DReconstructionintheWild.InSIGGRAPH arXivpreprintarXiv:2311.16961(2023).
ConferenceProceedings. JasonYZhang,AmyLin,MoneishKumar,Tzu-HsuanYang,DevaRamanan,and
JiaxiangTang,ZhaoxiChen,XiaokangChen,TengfeiWang,GangZeng,andZiwei ShubhamTulsiani.2024.CamerasasRays:PoseEstimationviaRayDiffusion.In
Liu.2024.LGM:LargeMulti-ViewGaussianModelforHigh-Resolution3DContent InternationalConferenceonLearningRepresentations(ICLR).
Creation.arXivpreprintarXiv:2402.05054(2024). LvminZhangandManeeshAgrawala.2023.AddingConditionalControltoText-to-
YoadTewel,OmriKaduri,RinonGal,YoniKasten,LiorWolf,GalChechik,andYuval ImageDiffusionModels.InInternationalConferenceonComputerVision(ICCV).
Atzmon.2024. ConsiStory:Training-FreeConsistentText-to-ImageGeneration.PuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums ‚Ä¢ 13
ZerongZheng,TaoYu,YebinLiu,andQionghaiDai.2021.PaMIR:ParametricModel-
conditionedImplicitRepresentationforimage-basedhumanreconstruction.Trans-
actionsonPatternAnalysisandMachineIntelligence(TPAMI)(2021).
ZerongZheng,TaoYu,YixuanWei,QionghaiDai,andYebinLiu.2019.DeepHuman:
3DHumanReconstructionFromaSingleImage.InInternationalConferenceon
ComputerVision(ICCV).14 ‚Ä¢ Xiu,etal.
A GPT-4VPROMPTFORPUZZLEBOOTH
To ensure complete coverage of the entire body and face, we
QueriedPrompt.‚ÄúAnalyzetheprovidedimages,eachfeaturingan samplevirtualcameraposesaroundthefullbodyandzoominon
individual.Identifyanddescribetheindividual‚Äôsgender,facialfeatures thefaceregion.Toreducetheoccurrenceofmirroredappearance
(excludinghair),haircut,andspecificclothingitemssuchasshirts, artifacts(e.g.,Janus-head),weincorporatedview-awareprompts
hats,pants,shoes,dresses,skirts,scarves,etc.Returntheresultsina (i.e.,‚Äúfront/side/back/overhead view‚Äù),regardingtheview-
dictionaryformatwithkeysfor"gender","face","haircut",andeach ingangleduringthegenerationprocess.Theeffectivenessofthis
typeofclothing.Thecorrespondingvalueshouldprovide1-3adjective approachhasbeendemonstratedinDreamFusion[Pooleetal.2023].
ornounwords,whichdescribethetopologicalorgeometricfeatures, Toensurefullcoverageoftheentirebodyandthehumanface,
suchaslength(e.g.,short,long,midi,mini,knee-length,floorlength, wesamplevirtualcameraposesintotwogroups:1)K bodycameras
ankle-length,hip-length,calf-length),shape(e.g.,oval,round,square, withafieldofview(FOV)coveringthefullbodyorthemainbody
heart-shaped,diamond-shaped,rectangular,voluminous,razor-cut, parts,and2)zoom-incamerasK facefocusingthefaceregion.
tousled,layered,messy),tightness(e.g.,tight,snug,fitted,skin-tight, TheratioP bodydeterminestheprobabilityofsamplingk‚ààK body,
loose,tight-fitting,clingy),style(e.g.,modern,casual,sporty,classic, while the height‚Ñé body, radiusùëü body, elevation angle ùúô body, and
formal,vintage,bohemian,avant-garde),orhaircuttypes(e.g.,long, azimuth rangesùúÉ body are adjusted relative to the SMPL-X body
short,wavy,straight,curly,bald,medium-length,ponytail,bun,plaits, scale.Empirically,wesetP body =0.5,‚Ñé body = [‚àí0.4,0.4],ùëü body =
beard, sideburns, dreadlocks, goatee), without referencing color or (0.7,1.3),ùúÉ body = [60‚ó¶,120‚ó¶],ùúô body = [0‚ó¶,360‚ó¶],withtheùëÄ body
texturepattern.Excludeaccessoriesanddon‚Äôtincludeanyclothing proportionallyscaledtoa[‚àí0.5,0.5]unitspace.
iteminthedescriptionofanother.Omitanykeysforwhichtheclothing Toenhancefacialdetails,wesampleadditionalvirtualcameras
itemdoesnotappearorthedescriptionisempty.Theresponseshould positionedaroundthefacek‚ààK face,togetherwiththeadditional
beadictionaryonly,withoutanyadditionalsentences,explanations, prompt‚Äúface of‚Äù.WithaprobabilityofP face=1‚àíP body=0.5,the
ormarkdownssyntax(likejson)‚Äù samplingparametersincludetheviewtargetùëê face,radiusrangeùëü face,
rotationrangeùúÉ ,andazimuthrangeùúô .Empirically,weset
face face
B CAMERASETTING ùëê tothe3DpositionofSMPL-Xheadkeypoint,ùëü = [0.3,0.4],
face face
ùúÉ = [90‚ó¶,90‚ó¶]andùúô = [‚àí90‚ó¶,90‚ó¶].
Tofamiliarizethediffusionmodelwiththecamerapositionssampled face face
Regardingthesyntheticdata,weuseallthesubjects(525textured
duringSDSoptimization,werenderedthesyntheticcolor-normal
scans)inTHuman2.0.Foreachsubject,werender8full-bodyviews
imagepairsintheexactsamemannerastheSDSsamplingstrategy.
and8headviews,asshowninFig.4,andquerytheirdescriptive
Thisrendereddatawillbeusedinpreservingsynthetichumanprior
promptsviaGPT-4V[OpenAI2023].Thisgivesus525√ó8√ó2=8400
(L prior),whiletrainingthe2Dgeneratorùê∫ puzzle.
color-normalpairsintotal.