Reliable Confidence Intervals for
Information Retrieval Evaluation Using Generative A.I.
HarrieOosterhuisâˆ—â€ â€¡ RolfJagermanâˆ—â€  ZhenQinâ€ 
GoogleResearch GoogleResearch GoogleResearch
RadboudUniversity Amsterdam,TheNetherlands NewYork,US
Amsterdam,TheNetherlands jagerman@google.com zhenqin@google.com
harrie.oosterhuis@ru.nl
XuanhuiWangâ€  MichaelBenderskyâ€ 
GoogleResearch GoogleResearch
MountainView,US MountainView,US
xuanhui@google.com bemike@google.com
Abstract Keywords
Thetraditionalevaluationofinformationretrieval(IR)systemsis InformationRetrievalEvaluation,LargeLanguageModels,Confi-
generallyverycostlyasitrequiresmanualrelevanceannotation denceIntervals,GenerativeA.I.,ConformalPrediction
fromhumanexperts.Recentadvancementsingenerativeartificial
ACMReferenceFormat:
intelligenceâ€“specificallylargelanguagemodels(LLMs)â€“cangen-
HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichael
eraterelevanceannotationsatanenormousscalewithrelatively
Bendersky.2024.ReliableConfidenceIntervalsforInformationRetrievalEval-
smallcomputationalcosts.Potentially,thiscouldalleviatethecosts uation Using Generative A.I.. In Proceedings of the 30th ACM SIGKDD
traditionallyassociatedwithIRevaluationandmakeitapplicableto ConferenceonKnowledgeDiscoveryandDataMining(KDDâ€™24),August
numerouslow-resourceapplications.However,generatedrelevance 25â€“29,2024,Barcelona,Spain.ACM,NewYork,NY,USA,11pages.https:
annotationsarenotimmuneto(systematic)errors,andasaresult, //doi.org/10.1145/3637528.3671883
directlyusingthemforevaluationproducesunreliableresults.
In this work, we propose two methods based on prediction-
1 Introduction
poweredinferenceandconformalriskcontrolthatutilizecomputer-
generatedrelevanceannotationstoplacereliableconfidencein- Theevaluationofinformationretrieval(IR)systemsisanimpor-
tervals(CIs)aroundIRevaluationmetrics.Ourproposedmethods tantandlong-establishedpartoftheIRfield[30,71,73].Thegoal
requireasmallnumberofreliableannotationsfromwhichthemeth- ofstandardIRsystemsistoretrieveandrankdocumentsaccord-
odscanstatisticallyanalyzetheerrorsinthegeneratedannotations. ingtotheirrelevancetoaqueryanduser.Accordingly,standard
Usingthisinformation,wecanplaceCIsaroundevaluationmetrics IRevaluationmetrics(e.g.,precision,recall,discountedcumula-
withstrongtheoreticalguarantees.Unlikeexistingapproaches,our tivegain(DCG),etc.)measurehowrelevantthetoprankeditems
conformalriskcontrolmethodisspecificallydesignedforrank- are for a set of known queries [12, 35, 36]. Accordingly, tradi-
ing metrics and can vary its CIs per query and document. Our tionalevaluationrequiresadatasetwithexamplesofdocuments,
experimentalresultsshowthatourCIsaccuratelycaptureboththe queriesandannotationsthatindicatetherelevanceofdocuments
varianceandbiasinevaluationbasedonLLMannotations,better toqueries[39,40,57,69].Whilstdocumentsandqueriesareoften
thanthetypicalempiricalbootstrappingestimates.Wehopeour gatheredbylogginguserinteractions,relevanceannotationsare
contributionsbringreliableevaluationtothemanyIRapplications traditionallycreatedthroughthelabourofhumanexperts,whoare
wherethiswastraditionallyinfeasible. trainedforthespecificlabellingtask[6,17,30,47].Consequently,
creatinganewdatasetforIRevaluationpurposesisgenerallyvery
CCSConcepts costly,andasaresult,nolargedatasetshavebeencreatedformany
IRsettings[19,34,63,74].Thus,fortheselow-resourcesettings
â€¢Informationsystems Evaluationofretrievalresults;â€¢
Computingmethodologâ†’ ies Semi-supervisedlearningsettings. traditionalevaluationisnotavailableinpractice.
â†’ Despitethelargecostsinvolved,therehasbeenacontinuous
âˆ—Authorscontributedequallytothiswork. effort,oftendrivenbyinitiativeslikeTRECandCLEF,tocreate
â€ NowatGoogleDeepMind. newdatasetsfordifferentIRtasks[9,14,31,38,43,52â€“54,62,65,
â€¡WorkdonewhileHarrieOosterhuiswasworkingatGoogleResearch.
67,68,70].SincethefoundationalCranfieldcollection[67],many
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor datasets have been created for ad-hoc retrieval [31, 38, 52, 70].
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed However,tomatchthelargevarietyofIR-relatedtasks,manyother
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
datasetsweresubsequentlyintroduced,accordingly;Forexample,
onthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored.
Forallotheruses,contacttheowner/author(s). datasetswithnumericalIRfeaturesforlearning-to-rank[14,53,54],
KDDâ€™24,August25â€“29,2024,Barcelona,Spain
orlargecollectionsofnaturallanguagequestion-answeringexam-
Â©2024Copyrightheldbytheowner/author(s).
plessuchasMSMARCO[47]andBioASQ[65].Similarly,recent
ACMISBN979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671883 yearshaveseentheintroductionoftheTREC-DL[17],BEIR[62]
1
4202
luJ
2
]RI.sc[
1v46420.7042:viXraKDDâ€™24,August25â€“29,2024,Barcelona,Spain HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichaelBendersky
andIstella22[20],amongothers[9,68],specificallyfortheevalua- theconfidenceofthegenerativemodel.Thesepredictionscanbe
tionofneuralIRsystems.Consequently,mostofthesubsequent propagatedtoformanintervalaroundmetricsonthequeryor
advancementsinneuralIRwereonlypossiblebecauseoftheavail- datasetlevel.ThroughCRC,ourapproachcalibratestheintervals
abilityofthesedatasetsandthereliablebenchmarkingthatthey toguaranteethatthetruevalueliesbetweenthemwithamini-
enable[29,45,46,48].Thishighlightstheimportanceandimpact mumprobability.Inotherwords,ourmethodputslowerandup-
ofreliableevaluationontheIRfield[30,57,69]. perboundsaroundtherelevanceofeachdocumentthatnaturally
Itisthusnosurprisethatpotentialnoveldatasourcesarere- translatetoreliableCIonqueryanddataset-levelmetrics.Thereby,
ceivedwithgreatexcitement.Inthepasttwoyears,newadvance- unlikePPI,ourCRCapproachdoesutilizetheconfidenceofthe
mentsingenerativeartificialintelligence[18,28,37,41,51],espe- generativemodelandcanprovideCIonquery-levelperformance.
ciallythearrivaloflargelanguagemodels(LLMs)[11,49,61],are OurresultsonseveralIRbenchmarksshowthatbothourmeth-
speculatedtobringpotentiallygroundbreakingsourcesforIReval- odsprovideCIsaroundLLM-basedmetricpredictionsthataccu-
uation[15,25].LLMsaretrainedonextremelylargecorporaofdi- ratelycapturethetruevalues,whilealsobeingsignificantlyless
versetextsforthetaskofgeneratingfluentnaturallanguage[42,60]. widethanthoseofpreviousCImethods[16,73].Moreover,unlike
Importantly,LLMsarealsocapableatperformingnumerousmis- otherapproaches[3],ourCRCmethodcanvaryCIsperdocument,
cellaneoustaskssuchasquestion-answering,text-summarization queryorcollectionofqueriesandcanthusbetterindicatewherea
andtext-annotation[1,15,27,61,64].Comparedtoannotationby generativemodelismoreorlessreliable.
humanexperts,annotationviaLLMscanbeperformedrelatively Tothebestofourknowledge,ournovelapproachesarethefirst
cheaplyandatmuchlargerscale[44,63].Severalexistingstud- thatleveragescomputer-generatedrelevanceannotationstopro-
ies have already investigated the application of LLM-generated ducereliableCIsforIRevaluation.Wehopethiscontributionopens
relevanceannotationstoIRevaluation[15,25,44].Inparticular, upnovelpossibilitiesforreliablebenchmarkingoflow-resourceIR
Thomasetal.[63]foundthat,whenappliedcorrectlytospecific tasksthathavebeentraditionallyinfeasible.
settings,LLMscanproducebetterlabelsthanthird-partyassessors
at a fraction of the costs. Thus, there is a clear potential for IR
evaluationbasedoncomputer-generatedrelevanceannotations.
However,afundamentalissuewithevaluationbasedonLLMs,
or other generative models, is that they are bound to make er- 2 RelatedWork
rors[8,15,63].Partoftheseerrorsarecoincidental,sinceperfect
2.1 ConfidenceintervalsforIRevaluation
relevancepredictionisinfeasibleinpractice,butothererrorsare
systematic[25].Forinstance,anLLMcouldsystematicallymisesti- Evaluationisawell-establishedcorepartoftheIRfield[30,52,
materelevanceincertaindomainsorondocumentswithparticular 67,71,73].Generally,itaimstomeasurehowwellaretrievalsys-
attributes[8,63].Inturn,theseerrorscouldaffectthefinalevalu- temcanproducealistofrankeddocumentsinresponsetoauser
ationmetricsandresultinincorrectassessmentsofperformance. query[30,58,69].ThemostprevalentformofIRevaluationrelies
Unfortunately,generativemodelscannotgivetrustworthyinsight ondatasetscontainingexamplequeries,documentsandhuman-
into their own reliability [37, 51]. Thus when solely relying on annotatedrelevancelabels[30,57,67,69].Accordingly,thereis
LLM-basedevaluation,onecannotbecertainhowreliabletheir alonghistoryofeffortstocreatesuchdatasetsintheIRcommu-
conclusionsare. nity,suchasTREC[17,31,68,70,71],CLEF[52],NTCIR[38]and
Inthiswork,weinvestigatehowcomputer-generatedrelevance many others [9, 14, 20, 43, 53, 54, 62, 65, 67]. Despite the enor-
annotationscanbeusedforreliableevaluation,byconstructing mousimportanceofthesedatasets,theyareknowntohavelimi-
confidenceintervals(CIs)aroundrankingmetricswiththem[56, tations.Forinstance,expertannotatorscangiveconflictingrele-
73].Ourapproachrequiresasmallnumberofreliablegroundtruth vanceassessments,andtheactualusersofanIRapplicationcan
annotations,inordertostatisticallyanalyzethedistributionofer- disagreewiththeexpertsaswell[57].Furthermore,theconstruc-
rorsthatexistinthegeneratedannotations.Subsequently,weapply tionsofthesedatasetsisoftencostlywhichputsconstraintson
twostate-of-the-artmethodologies[3,4]withastrongtheoretical theirsize[13,14,67,70].Asaresult,IRdatasetscanonlyrepresent
groundingtofindreliableCIs.Inthiswork,weprovidetwomain alimitedsliceofthequeriesthatarealIRsystemreceives[13,73].
methodologicalcontributions: Accordingly,statisticalapproachestoIRevaluationhavebeen
Our first contribution is the novel application of prediction- developedtodealwiththeselimitations.Forexample,ithasbe-
poweredinference(PPI)toIRevaluation[3].PPIappliesclassical come common practice to use significance tests to ensure that
methods for building CIs but builds them around the error be- observeddifferencesinIRmetricsare,withhighprobability,not
tweenthepredictedandtruevaluesofametric.Thereby,somewhat- theresultofrandomchance[26,59,66].Confidenceintervals(CIs)
reasonablepredictionscanleadtosubstantiallysmallerCIsthan have been used to express the uncertainty that comes from us-
classicalCIaroundjustthemetricvalue.ThelimitationsofPPIis ingthedatasetsampleofqueriestoestimateperformanceoverall
thatitdoesnotutilizetheuncertaintyofthegenerativemodel,and queries[16,56].Furthermore,previousworkhasalsoappliedCIfor
thatitonlyprovidesaCIaroundthefinalmetricvalue. relevanceannotatordisagreement[21,33]andmissingrelevance
Oursecondcontributionaddressestheselimitationsbypropos- annotations[5,72,75].ThestatisticalmethodsusedtoconstructCI
inganovelconformalriskcontrol(CRC)approach[2,4].Wein- bypreviousworkinIRhavebeenbasedonempiricalbootstrapping
troduceanovelmethodtoplaceanoptimisticandapessimistic techniques[22,23,32].Tothebestofourknowledge,ourworkis
predictionaroundeachgeneratedrelevancelabel,whichfollows thefirsttoconsiderPPIandCRCmethodsforIRevaluation[3,4].
2ReliableConfidenceIntervalsforInformationRetrievalEvaluationUsingGenerativeA.I. KDDâ€™24,August25â€“29,2024,Barcelona,Spain
2.2 LLMsforrelevanceannotationgeneration 3.2 Problemsetting
RecentadvancesinLLMshavedemonstratedimpressivecapabil- Inoursetting,wemakethestandardassumptionthatalargeset
itiesonabroadrangeoftasks[1,27,61,64].Previousworkhas ofsampleduserqueriesandadocumentcollectionareavailable.
specificallyconsideredusingLLMsforrelevanceannotationinan However,wedonotassumethattherearehumanrelevanceanno-
IRcontext[15,25,44,63].Thomasetal.[63]proposeusingground tationsforeverydocument-querypair,andinstead,weassumethat
truthrelevancelabelsfromhumanannotators,tofindapromptthat groundtruthannotationsareonlyavailableforasmallsubset:the
resultsinthemostaccurateLLMgeneratedlabels.Theyclaimthat firstğ‘›queriesoutofatotalofğ‘ queries.Uniquetoourproblem
thismethodproducesrelevanceannotationsatthesamequality settingisthatagenerativemodelisavailabletopredictrelevance
asthird-partyhumanassessorsbutatafractionofthecosts[63]. annotations.Furthermore,ouraimisnottogiveapointestimateof
Clarkeetal.[15]proposethatLLMrelevance-annotationshould thetrueperformanceofasystem,insteadourgoalistoconstructa
beapproachedasaspectrum,sincetheinvolvementofhumanscan reliableCIaroundthetruevalueofanIRmetric.Thereby,weutilize
bevaried.Forinstance,onecoulddelegatemostworktoanLLM thegeneratedrelevanceannotations,butstillexplicitlyindicatethe
butaddsomehumanverification,asacompromiseofreducedcosts resultinguncertaintyinourevaluationwithCIs.
andreliability.Faggiolietal.[25]supportthisapproach,astheysee Informalterms,letğ›¼ 0,1 beaconfidenceparameter,we
âˆˆ [ ]
severeriskinblindlyfollowingLLMgeneratedrelevancelabels(at desiretofindalowerboundğ‘ˆË† andanupperboundğ‘ˆË† s.t:
low high
leastforthecurrentstate-of-the-artLLMs).Thedangerforeseenby ğ‘ƒ(cid:0) ğ‘ˆË† ğ‘ˆ ğ‘ˆË† (cid:1) 1 ğ›¼. (3)
bothisthatgeneratedlabelscanmakesystematicerrorsthatlead low â‰¤ (Q) â‰¤ high â‰¥ âˆ’
toincorrectandunreliableevaluationofIRsystems[8,15,25].Our Accordingly,ğ›¼canbechosentomatchthedesiredconfidence,i.e.,
workaddressesthisproblem,andisthusveryrelated;specifically, ğ›¼ =0.05leadstoa95%CI.Additionally,inSection6,wepropose
ourcontributioncanbeseenasanapproachofhumanverification a CRC method that can also bound the performance per query,
designedtoquantifyuncertaintystemmingfromLLMusage. thereby,itcanmeetthefollowingquery-levelCIgoal:
(cid:16) (cid:17)
ğ‘ƒ ğ‘ˆË† ğ‘ ğ‘ˆ ğ‘ ğ‘ˆË† ğ‘ ğ‘ 1 ğ›¼. (4)
3 Preliminaries low ( ) â‰¤ ( ) â‰¤ high ( ) | âˆ¼Q â‰¥ âˆ’
Weassumethattheavailablegenerativemodelpredictsadistribu-
3.1 Evaluationmetricsforretrievalsystems
tionoverpossiblerelevancelabelsperquery-documentpair[44,63].
Thegeneralapproachtotheevaluationofaretrievalsystemisto Letğ‘ƒË† ğ‘…=ğ‘Ÿ ğ‘‘,ğ‘ indicatethepredictedprobabilityforrelevance
considertheexpectedvalueofarankingmetricacrossthequeries ( | )
valueğ‘Ÿ forthecombinationofdocumentğ‘‘andqueryğ‘,themean
it will receive [30]. Standard ranking metrics assume that each
predictedrelevanceisthen:
documenthascertainrelevancetoaquery[39].Forasetoflabels
âˆ‘ï¸
,weuseğ‘ƒ ğ‘… =ğ‘Ÿ ğ‘‘,ğ‘ todenotetheprobabilitythatahuman ğœ‡Ë† ğ‘‘ = ğ‘ƒË† ğ‘…=ğ‘Ÿ ğ‘‘,ğ‘ ğ‘Ÿ. (5)
R ( | ) ( ) ( | )
raterwouldgiveratingğ‘Ÿ ,tothecombinationofdocumentğ‘‘and ğ‘Ÿ
queryğ‘.WedefinerelevaâˆˆncReastheexpectedratingvalueoverthis Usingthesepredictedrelevaâˆˆ nR
ces,wecanconstructapredictionof
distribution:ğœ‡ ğ‘‘ ğ‘ =(cid:205) ğ‘Ÿ ğ‘ƒ ğ‘…=ğ‘Ÿ ğ‘‘,ğ‘ ğ‘Ÿ.Instandardranking performanceonthedataset-levelfromasampledsetofqueriesğ‘„.
settings,theg( oal| is) toplaâˆˆcRem( orerel| evan)
tdocumentsathigher Thisresultsinthefollowingpredictedmetricvalue:
ranks[36].Rankingmetricscapturethisgoalbygivingaweightto
1 âˆ‘ï¸ âˆ‘ï¸
eachrank,whichindicateshowmuchtherelevanceofadocument ğ‘ˆË† ğ‘„ = ğœ” rank ğ‘‘ ğ‘, ğ‘ ğœ‡Ë† ğ‘‘ ğ‘ . (6)
( ) ğ‘„ ( ( | D )) ( | )
placedatthatrankshouldcontributetothemetric[35].Wewill | |ğ‘ ğ‘„ğ‘‘ ğ‘
âˆˆ âˆˆD
useğœ”todenoteourweightingfunctionwhichtakestherankofa
Asdiscussedinpreviouswork[15,25],basingğ‘ˆË† ğ‘„ onstate-of-the-
documentasitsinput.Forexample,Precision@Khasthefollowing ( )
artLLMscouldgreatlyreducecosts[63],buttherearemanyrisks
wc tho eer ir gpe hos tp p so u an la nd r din Dg C ğ‘w G ,e t[i h3g e5h ] st : eğœ”f tu D on C fc Gt ai @ vo an K i: ( lğ‘¥ ağœ” b)P lr = eec dl@ o1 ogK c[ 2ğ‘¥ u( (â‰¤ğ‘¥ ğ‘¥ mğ¾ +) e1]= n). tsGğ¾1 fi1 ov re[ğ‘¥ n quaâ‰¤ ec rhğ¾ yo] ğ‘i; c ,a e tn hod ef i c mn ov omo dpl ev l lee .td Teli hyn udr se e ,p p wl ea in tc hdin s og uo th nu ft um h rea thn p era ren d kn i nco t ot ia v wt eo lecr ds a gp[ ea8 b] a. il bT i oth i uee s ta o tc hfc eu thr ra e ec lg iy ae bo nf ie lrğ‘ˆ iË† ta yt( iğ‘„ v oe)
f
D
metricvalueforasinglequeryis: thepredictions,onehasnoindicationofitstrustworthiness.Our
proposedmethodologiesusetheavailableğ‘›groundtruthquery-
âˆ‘ï¸
ğ‘ˆ ğ‘ = ğœ” rank ğ‘‘ ğ‘, ğ‘ ğœ‡ ğ‘‘ ğ‘ . (1) levelperformancestogetherwiththemanygeneratedrelevance
( ) ( ( | D )) ( | )
ğ‘‘ ğ‘ predictionstoconstructreliableCIsthatquantifytheserisks.
âˆˆD
Letğ‘ƒ ğ‘ denotethenaturalquerydistribution;theperformanceof 4 Method1:Prediction-PoweredInferencefor
( )
asystemintermsofthemetricis:
InformationRetrievalEvaluation
ğ‘ˆ =E ğ‘ˆ ğ‘ = âˆ‘ï¸ ğ‘ƒ ğ‘ ğ‘ˆ ğ‘ . (2) Our first proposed method applies the prediction-powered infer-
(Q) ğ‘ âˆ¼Q[ ( )] ( | Q) ( ) ence(PPI)frameworktoIRevaluation.PPIisaveryrecentadvance-
ğ‘
âˆˆQ mentinCIconstructionintroducedbyAngelopoulosetal.[3].It
Inpractice,ğ‘ˆ canneverbecomputedexactly,sinceğ‘ƒ ğ‘ andğ‘ƒ ğ‘…= utilizescomputer-generatedpredictionstocreatesmallerCIwhen
( ) (
ğ‘Ÿ ğ‘‘,ğ‘ areneverdirectlyavailable.Thus,generally,anestimateof thesepredictionsaresomewhataccurate.Thecoreideaistoavoid
| )
ğ‘ˆ ismadeonalargesetofsampleduserqueriesandafewrelevance estimatingavariableonlabelleddatadirectly,andinstead,buildan
judgementsperdocument-querypair[57,73]. estimatearoundthepredictionswhichisthencorrectedbasedon
3KDDâ€™24,August25â€“29,2024,Barcelona,Spain HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichaelBendersky
thelabelleddata[10].Ifthepredictionsarefoundtobeaccurateon moreaccurate,whilstğœË†2 shrinksasmoreunlabelleddatabe-
pred
thelabelleddata,thenthisincreasesourconfidencethatitspredic- comesavailable(asğ‘ increases).ComparingğœË†2 withğœË†2 reveals
tionsonunlabelleddataarealsoaccurate.Aspredictionsbecome PPI emp
thatPPIcangivealowervarianceestimate,butonlyifpredictions
availableinmuchlargerquantities,thiscanincreaseourconfidence
aresomewhataccurate.Conversely,whentheyareinaccuratethe
furtherintheoverallestimate.Tothebestofourknowledge,we
variancecouldactuallybegreater.
arethefirsttoapplyPPItoIRevaluation.
Finally,inordertoturntheestimatedmeanandvarianceintoa
CI,wefollowAngelopoulosetal.[3]andassumeğ‘ˆË† PPI ğ‘„ follows
4.1 Classicalempiricalmeanestimation ( )
anormaldistribution.The95%confidenceintervalisthen:
BeforewedetailourapplicationofPPI,itiseasiesttostartwith âˆšï¸„
classicalempiricalestimates.AsstatedinSection3.2,ouraimisto ğ‘ˆË† ğ‘„ =ğ‘ˆË†PPI ğ‘„ 1.96 ğœË† e2 rror ğœË† p2 red . (11)
placeareliableCIaroundthetrueperformanceğ‘ˆ ğ‘„ ,andrelevance high/low ( ) ( )Â± ğ‘› + ğ‘
( )
annotationsareavailableforthefirstğ‘›queriesinğ‘„.Therefore,we Accordingly,onecanuseadifferentz-scorethan1.96tochoosea
canmakeanempiricalestimateofthemeanmetricperformance differentlevelofconfidence.Wenotethatthisimplicitlyassumes
basedonthesequeries: thepredictionerrorfollowsasymmetricdistribution.
ğ‘ˆË†emp ğ‘„ =
(cid:205)ğ‘› ğ‘–=1ğ‘ˆ (ğ‘ğ‘–
), ğœË†2 =
(cid:205)ğ‘› ğ‘–=1(cid:0) ğ‘ˆË†emp (ğ‘„ )âˆ’ğ‘ˆ (ğ‘ğ‘– )(cid:1)2
, (7)
advT ah ni ts agc eon iscl iu tsd se is mo pu lir cid tyes ac nri dp sti to ran igo hf tfo ou rr wP aP rdIm ape pt lh ico ad t. ioI nts ,mbi ag kg ie ns gt
( ) ğ‘› emp ğ‘› 1
itattractiveforpracticalusage.Alimitationisthatitonlygivesa
âˆ’
whereğœË†2 istheestimatedvarianceoftheempiricalestimate,and CIoftheoverallperformance(dataset-level).Therefore,PPIcannot
emp
ğ‘ˆ ğ‘ğ‘– themetricvalueforthesinglequeryğ‘ğ‘– (Eq.1).Wenotethat beusedtoplaceCIaroundindividualqueryperformances,and
( )
itsvarianceissolelyreflectiveofthegroundtruthdata.Obviously, similarly,itcannotvaryitsconfidencefordifferentqueries.
thisestimatedoesnotfullyutilizeourproblemssetting,asitignores
thequerieswithoutgroundtruthrelevanceannotationsandtheir 5 Background:ConformalPredictionand
correspondingcomputer-generatedrelevanceannotations. ConformalRiskControl
Thissectionprovidesthenecessarybackgroundonconformalpre-
4.2 Prediction-poweredinference
dictionandconformalriskcontrol(CRC)[2,4,7,50],beforeSec-
Incontrast,PPImeanestimationcombinesgroundtruthandpre- tion6introducesourCRCapproachforIRevaluation.
dictedvaluestocreateanestimatorthathaspotentiallymuchlower
variance.Inoursetting,thePPIestimatorisacombinationofthe 5.1 Conformalprediction
estimatedmeanpredictedqueryperformanceandtheestimated Conformalpredictionprovidesauniqueapproachtouncertainty
meanpredictionerror: quantificationinpredictions[7,50].Thekeycharacteristicofcon-
ğ‘ˆË†PPI ğ‘„ =
(cid:205) ğ‘–ğ‘ =1ğ‘ˆË† (ğ‘ğ‘–
)
(cid:205)ğ‘› ğ‘–=1ğ‘ˆ (ğ‘ğ‘– )âˆ’ğ‘ˆË† (ğ‘ğ‘–
) . (8)
f so etr sm oa fl lp ar be ed lsic .t Fio on rii ns st th aa nt ci ets ,tp hr eed mic ot sio tn bs asa ir ce vn eo rt sii on ndi ov fid tu ha isll aa pb pe rls oab cu ht
( ) ğ‘ + ğ‘›
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) constructsapredictionset byincludingalllabelsthathaveapre-
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) C
meanprediction meanpredictionerror dictedprobabilityaboveathresholdğœ† 0,1 [2].Letğ‘ƒË†indicatea
âˆˆ [ ]
predictedprobability,ğ‘‹ contextualfeaturesandğ‘Œ acorresponding
Inotherwords,PPIconstructsanestimateofthequeryperformance
label,thisbasicpredictionsetisthen:
basedonthepredictedrelevanceannotations,andcorrectsitby
theestimatederrorbasedonthedifferencebetweenthepredicted basic ğ‘‹ ğœ† = ğ‘¦:ğ‘ƒË† ğ‘Œ =ğ‘¦ ğ‘‹ >ğœ† . (12)
C ( | ) { ( | ) }
andgroundtruthannotations.Asaresult,itisunbiased:
Givenasetofi.i.d.calibrationdata,conformalpredictioncansetğœ†
E
ğ‘„
(cid:2) ğ‘ˆË†PPI ğ‘„ (cid:3) =E
ğ‘„
(cid:2) ğ‘ˆË†emp ğ‘„ (cid:3) =ğ‘ˆ , (9) sothat Cbasiccontainsthetruelabelwithhighprobability:
âˆ¼Q ( ) âˆ¼Q ( ) (Q) ğ‘ƒ(cid:0) ğ‘Œ ğ‘‹ ğœ† (cid:1) >1 ğ›¼. (13)
WhilsttheempiricalandPPIestimateshavethesameexpected âˆˆCbasic ( | ) âˆ’
value,thekey-differenceistheirvariances.Assumingthequeries Thereby, cancapturetheuncertaintyinthepredictionof
basic
C
arei.i.d.,theestimatedvarianceofPPIcanbedecomposedinto ğ‘‹,withstrongtheoreticalguarantees,whenappliedtothesame
apartstemmingfromthemeanpredictionandanotherfromthe distributionfromwhichthecalibrationdatawassampled[2].
predictionerror:
5.2 Conformalriskcontrol
ğœË†2 ğ‘„ =ğœË†2 ğ‘„ ğœË†2 ğ‘„ ,
PPI( ) pred( )+ error( ) Forpurposesotherthanlabelprediction,thereisamoregeneral
ğœË†2 ğ‘„
=âˆ‘ï¸ğ‘ (ğ‘ˆË† (ğ‘ğ‘–
)âˆ’
ğ‘1 (cid:205)ğ‘ ğ‘—=1ğ‘ˆË† (ğ‘ğ‘— ))2
, (10)
versionofthisapproach:conformalriskcontrol(CRC)[4].Let C(ğ‘‹
|
pred( ) ğ‘ 1 ğœ† beanarbitraryfunctionthatconstructssetsthatincreasewith
ğ‘–=1 âˆ’ ğœ†) , aboundedlossfunctionthatshrinksas grows,andinthis
ğœË†2 ğ‘„
=âˆ‘ï¸ğ‘› (ğ‘ˆ (ğ‘ğ‘– )âˆ’ğ‘ˆË† (ğ‘ğ‘– )âˆ’ğ‘›1 (cid:205)ğ‘› ğ‘—=1(ğ‘ˆ (ğ‘ğ‘— )âˆ’ğ‘ˆË† (ğ‘ğ‘— )))2
.
conL textğ›¼ âˆˆR,CRCaimstoguaranteetheexpeC ctedlossisbounded:
error( ) ğ‘–=1 ğ‘› âˆ’1 E (ğ‘¥,ğ‘¦ )âˆ¼ğ‘ƒ (ğ‘‹,ğ‘Œ )[L(C(ğ‘‹ =ğ‘¥ |ğœ† ),ğ‘Œ =ğ‘¦
)]
<1 âˆ’ğ›¼. (14)
ThisrevealshowPPIcanbenefitfrompredictionsandunlabelled Wecanseethatthisisageneralizedversionofconformalprediction,
data.WeseethatğœË†2 shrinksaspredictedperformancesbecome sinceitisequivalenttoEq.13when: ,ğ‘Œ =1 ğ‘Œ âˆ‰ [2].
error L(C ) [ C]
4ReliableConfidenceIntervalsforInformationRetrievalEvaluationUsingGenerativeA.I. KDDâ€™24,August25â€“29,2024,Barcelona,Spain
0.4 15
0.3 10
0.2
5
0.1
0
0
0 1 3 7 15 0 1 3 7 15 0 1 3 7 15 1 0.5 0 0.5 1
âˆ’ âˆ’
Gain(2ğ‘Ÿ 1) Pessimism/optimismparameter:ğœ†
âˆ’
Figure1:Threedifferentpredictedrelevancedistributions(left)andtheircorrespondingğœ‡Ë† CRC(ğ‘‘,ğœ† )curves(right).
CRCcanguaranteeEq.14,byfindingavalueofğœ†basedonaset producethevalidprobabilitydistributions;ğ‘ƒË† andğ‘ƒË† :
high low
ofğ‘›i.i.d.calibrationdata-pointssuchthat:
ğ‘„Ë† ğ‘…=ğ‘Ÿ ğ‘‘,ğœ†
ğ‘›1âˆ‘ï¸ğ‘› L(C(ğ‘‹ğ‘– |ğœ† ),ğ‘Œğ‘–
)
<ğ›¼
âˆ’
ğµ âˆ’ ğ‘›ğ›¼ , (15) ğ‘ƒË† high/low (ğ‘…=ğ‘Ÿ |ğ‘‘,ğœ† )= (cid:205) ğ‘Ÿ â€²âˆˆRhi ğ‘„g Ë†h h/ il go hw /l( ow (ğ‘…=| ğ‘Ÿ â€² |) ğ‘‘,ğœ† ). (17)
ğ‘–=1 Duetopossiblebiasinthepredictedrelevanceannotations,e.g.,
whereğµisthemaximumpossiblevalueof .Undertheassumption allpredictionscouldbesevereoverorunderestimates,wewantto
L
thatthecalibrationdatawassampledfromthesamedistribution enablebothboundariesofCIstobeoptimisticorpessimistic.For
(ğ‘ƒ ğ‘‹,ğ‘Œ ),CRCisproventoprovidetheboundguaranteestatedin elegance,weletğœ† 1,1 andourperturbeddistributioniseither
( ) âˆˆ (âˆ’ )
Eq.14[2,4].Wenotethatitispossiblethatnoğœ†valueexiststhat optimisticorpessimisticbasedonthesignofğœ†:
cansatisfyEq.15becausethenumberofdata-pointsğ‘›istoosmall. (cid:40) ğ‘ƒË† ğ‘…=ğ‘Ÿ ğ‘‘,ğœ† ifğœ† 0,
Inthiscase,themethodexplicitlyfailstoprovideaCI,thereby,CRC ğ‘ƒË† CRC (ğ‘…=ğ‘Ÿ |ğ‘‘,ğœ† )= ğ‘ƒË†high (
ğ‘…=ğ‘Ÿ
|
ğ‘‘,
ğœ†) otheâ‰¥
rwise.
(18)
indicateswhenitisunabletoguaranteereliableCIs.Thegenerality low ( | âˆ’ )
andflexibilityoftheCRCframeworkenablesustobuildourown Thefinaloptimisticorpessimisticestimatesaretheexpectedvalues
CImethodforIRevaluationontopofit. overtheseperturbeddistributions:
âˆ‘ï¸
6 Method2:ConformalRiskControlfor ğœ‡Ë†CRC (ğ‘‘,ğœ† )= ğ‘ƒË† CRC (ğ‘…=ğ‘Ÿ |ğ‘‘,ğœ† )ğ‘Ÿ. (19)
ğ‘Ÿ
InformationRetrievalEvaluation âˆˆR
Oursecondproposedmethodusesconformalriskcontrol(CRC)for
Figure1visualizeshowğœ‡Ë†CRCvariesoverdifferentğœ†valuesfor
threedifferentpredictedrelevancedistributions.Weseethatlow
CIconstruction[4].IncontrastwithPPI,itcanprovidebothCI
predictedprobabilitiesforthelargestlabelsmeanthatğœ†hastobe
aroundmeanperformanceandperqueryperformance.Italsorelies
greaterforğœ‡Ë†CRCtoreachhighvalues,andviceversa,ğœ†hastobe
ondifferentassumptionsthanPPIandempiricalbootstrapping.
lowerforlowprobabilitiesforthelowestlabelvaluestoreachlow
Ourdescriptionofthemethodisdividedintothreeparts:firstly,
values.Inotherwords,ittakesmoreextremeğœ†valuesforğœ‡Ë†CRCto
weintroduceour function,secondly,wedescribehowcalibra-
C beheavilyoptimisticwhenthegenerativemodelisveryconfidently
tiondataisgathered,andthirdly,weproposeouralternativedual-
pessimistic,andviceversa.
calibrationapproachspecificforCIs.
Thedocument-level ğœ‡Ë†CRC aretranslatedtoperformanceesti-
matesfollowingEq.1&6butwithğœ‡Ë† ğ‘‘ replacedbyğœ‡Ë†CRC ğ‘‘,ğœ† .
6.1 Optimisticandpessimisticestimation ( ) ( )
Finally,toconstructCIs,weusetwoparameters:ğœ† 1,1
high
âˆˆ (âˆ’ )
F ino dr ivo iu dr uap lu dr op co us mes e, nC t,tw hi al tl ac ro en ts ht eru nc tt raC nI ss laf to er dt ih ne tore Cle Isv oa nnc qe uo erf ye aa nch d ğ‘ˆa Ë†n Cd RCğœ† lo ğ‘„w ,ğœ†âˆˆ hig(âˆ’ h1 .,1 T) h, es.t p. rğœ† el do iw cte< dğœ† Chi Igh is,t to heob rt aa nin geğ‘ˆË† bC eR tC w(ğ‘„ ee, nğœ† lo thw e) pan erd
-
dataset-levelperformance.Thus,ourCRCmethodtreatseachCIas ( )
turbedestimates:
asetthatincludesallvaluesbetweenitsminimumandmaximum.
Accordingly,wemustpredicttheboundariesofCIsonadocument- ğ‘„,ğœ† high,ğœ† low = ğ‘ˆË† CRC ğ‘„,ğœ† low ,ğ‘ˆË† CRC ğ‘„,ğœ† high . (20)
C( ) [ ( ) ( )]
level, therefore, we propose two functions: ğœ‡Ë† high and ğœ‡Ë† low, that Ourproposed functionhasseveralsignificantpropertiesthat
providemoreoptimisticandpessimisticpredictionsthanğœ‡Ë†,respec- enableittofunC ctionwellasCI:Whenğœ† = ğœ† = 0,itonly
low high
t oi fv te hly e. gW ene ew rai ts ih veth me oo dp et li ,m this um s,/ wpe ess taim keis tm heto prf eo dll io ctw edth de isc tro in bufi td ie on nc ğ‘ƒe Ë† containsthepredictedğ‘ˆË† (ğ‘„ )value,since:ğ‘ˆË† CRC (ğ‘„,0 )=ğ‘ˆË† (ğ‘„ ).As
theğœ†approachoneandminusone,theperturbedestimatesbecome
andremoveğœ†probabilityfromthetoporbottomlabels:1
theminimumandmaximalpossiblemetricvalues:
(cid:16) âˆ‘ï¸ (cid:17)
ğ‘„ ğ‘„Ë† Ë†h li og wh ( ğ‘…ğ‘… == ğ‘Ÿğ‘Ÿ | ğ‘‘ğ‘‘ ,, ğœ†ğœ† ) == ğ‘ƒğ‘ƒ Ë†Ë† ( ğ‘…ğ‘… == ğ‘Ÿğ‘Ÿ | ğ‘‘ğ‘‘ )âˆ’ mm aa xx
(cid:16)
00 ,, ğœ†ğœ† âˆ’ ğ‘Ÿ âˆ‘ï¸â€²âˆˆR ğ‘ƒğ‘ƒ Ë†Ë† :ğ‘Ÿ( â€² ğ‘…ğ‘… <ğ‘Ÿ == ğ‘Ÿğ‘Ÿ â€²â€² | ğ‘‘ğ‘‘ ) (cid:17), .(16) Conğœ†h si egh qâ†’ uel 1i n,m ğœ† tlo lyw ,â†’ thâˆ’ e1 reC a( lğ‘„ w, ağœ† yh sig eh x, iğœ† stlo sw v) al= ue[ sm foa rx ğœ†ğ‘ˆ hi( gÂ· h), am ndin ğœ†ğ‘ˆ low(Â·) t] o. bou(2 n1 d)
( | ) ( | )âˆ’ âˆ’ ( | ) thetrueperformanceğ‘ˆ ,sinceitmustliebetweentheminimal
ğ‘Ÿ â€²âˆˆR:ğ‘Ÿ â€²>ğ‘Ÿ andmaximalpossiblem( eQ tr)
icvalues:
Wenotethatwhenğœ†isgreaterthanthepredictedprobabilityfor
ğœ† 1,1 ,ğœ† 1,ğœ† ; ğ‘ˆ ğ‘„,ğœ† ,ğœ† .
thelowest/highestlabel,theremainderissubtractedfromthenext âˆƒ high âˆˆ (âˆ’ ) low âˆˆ (âˆ’ high ] (Q) âˆˆC( high low )
lowest/highestlabel,andsoforth.Theresultsarenormalizedto Tosummarize,wehaveproposedanovel ğ‘„,ğœ† functionthat
C( )
createsaCIbasedontherelevanceannotationsofagenerative
1Forbrevity,weomitğ‘fromournotation:ğ‘ƒË† ğ‘…=ğ‘Ÿğ‘‘,ğ‘ =ğ‘ƒË† ğ‘…=ğ‘Ÿğ‘‘ . model.Itfollowstheconfidenceoftheunderlyinggenerativemodel
( | ) ( | )
5
ğ‘‘
ğ‘Ÿ=ğ‘…
Ë†ğ‘ƒ
)
|
(
ğœ†,ğ‘‘
CRCË†ğœ‡
)
(KDDâ€™24,August25â€“29,2024,Barcelona,Spain HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichaelBendersky
byperturbingthepredictedrelevancedistributionsinanoptimistic Table1:DCG@10performanceofdifferentrankersasmea-
orpessimisticmanner.Theremainderofthissectionexplainshow suredbyhuman-annotatedlabelsandLLM-generatedlabels.
wedeterminethevaluesofğœ† andğœ† suchthatareliableCIis Eachapproachranksthetop-100resultsretrievedbyBM25.
high low
foundthatcapturesthetruemetricvaluewithhighconfidence.
TREC-DL Robust04
Human LLM Human LLM
6.2 Datasamplingandbootstrapping
Random 3.16 6.86 0.99 2.96
InordertoperformCRCcalibration,asetofgroundtruthexamples
BM25 8.25 12.93 2.71 4.32
isrequiredtoserveascalibrationdata.Inoursetting,weaimto
LLM 12.81 23.73 3.23 7.17
estimatethemeanoverthetruequery-distribution basedonthe
Q Perfect 19.00 17.44 5.70 4.65
sampledsetofqueriesğ‘„.Accordingly,asetofexamplesofmean
estimatesbasedonsampledsetfrom isrequired;wecreateğ‘€
Q
examplesbysamplingfromtheğ‘›queriesinğ‘„withgroundtruth
annotations:ğ‘„Â¯ ğ‘– ğ‘1,ğ‘2,...ğ‘ğ‘› .Thecollectionoftheseğ‘€ sets Accordingly,weassumethatthis(Eq.26)impliesthefollowing:
sho Tu hld erm eaim reic mt ah neâŠ‚ yd oi{ s ptr tii ob nut sio ton co of n} Q st: rQ uÂ¯ ct= Â¯{ğ‘„ ,Â¯ f1 o, rğ‘„Â¯ in2, s. ta.. n, cğ‘„ eÂ¯ ,ğ‘€ o} n.
ecould
ğ‘ƒ(cid:16) ğ‘ˆË† CRC (ğ‘„,ğœ† low )â‰¤ğ‘ˆ (Q)â‰¤ğ‘ˆË† CRC (ğ‘„,ğœ† high )|ğ‘„ âˆ¼Q(cid:17) >1 âˆ’ğ›¼. (27)
Q
samplequerieswithorwithoutreplacement,thesizeofthesampled ThisisaverystandardassumptionmadeinCIliterature,andat
setscouldbevaried,etc.Moreover,ifonewantstocreateCIsaround thecoreofmanybootstrappingmethods[22,24].If Â¯ iscreatedby
Q
theperformanceofeachquery,theycanchoosethesetstocontain standardsamplingfromğ‘„,thenthisisarelativelysafeassumption.
asinglequery:ğ‘„Â¯ ğ‘– = ğ‘ğ‘– .Anotheroptionistosamplequeriesand
{ }
subsetsofthedocumenttoberanked,toartificiallyincreasethe 6.4 Overview
varietyincandidatedocumentsavailableperquery.Choicesthat
Finally,wegiveanoverviewofthedifferentcomponentsinour
increasethenumberofexamplesğ‘€havethepotentialtodecrease
CIwidth.However,iftheresulting Â¯ isnolongerrepresentative CRCapproach:OurCIarecreatedwiththe CCRC (ğ‘„,ğœ† high,ğœ† low )
Q function(Eq.20),whereğ‘„areallavailablequeries(nogroundtruth
ofthetruedistribution ,thereliabilityoftheCIswilldecrease.
Q annotations required). We note that when the setğ‘„ contains a
singlequery,itproducesaCIforquery-levelperformance.
6.3 Dual-calibrationforconfidenceintervals
TheresultingCIareonlyreliableifğœ† andğœ† areproperly
high low
Withourdefinitionof ğ‘„,ğœ† high,ğœ† low andthecalibrationdata Â¯, calibrated.Wedosobyfirstsamplingacollectionofquery-sets Â¯
allthatremainsistocC al( ibrateğœ† highan) dğœ† low.However,standarQ d (Section6.2)andcalibratingeachparameterindependently(Eq.24Q ).
CRCisdesignedforthecalibrationofasingleparameter.Luckily, DuetothenatureofCI(Eq.22),thisguaranteestheCRCrequire-
forthepurposeofconstructionaCI,wecanapplyCRCcalibration mentismet(Eq.25),andassuming Â¯ isrepresentativeof ,this
sequentially.Becauseforanyğ‘ˆË† low <ğ‘ˆË† high,thefollowingholds: guaranteesthatourCIarereliablewiQ thagivenprobability(Q Eq.27).
(cid:16) ğ›¼ ğ›¼(cid:17)
ğ‘ƒ ğ‘ˆ ğ‘ˆË† ğ‘ƒ ğ‘ˆ ğ‘ˆË†
low high
( â‰¤ ) â‰¤ 2 âˆ§ ( â‰¥ ) â‰¤ 2 (22)
ğ‘ƒ ğ‘ˆË† ğ‘ˆ ğ‘ˆË† 1 ğ›¼. 7 ExperimentalSetup
low high
âˆ’â†’ ( â‰¤ â‰¤ ) â‰¤ âˆ’
Ourexperimentscomparetheconfidenceintervalsproducedby
Therefore,wecanfirstcalibrateoneoftheboundswithCRC,and PPI,CRCandclassicalempiricalbootstrappingonbenchmarkIR
theotherafterwards.Accordingly,weproposetwolossfunctions: datasets,byansweringthefollowingresearchquestions:2
high(cid:0)
CRC
ğ‘„,ğœ†
high
,ğ‘ˆ ğ‘„ (cid:1) =1(cid:2) ğ‘ˆË†
CRC
ğ‘„,ğœ†
high
<ğ‘ˆ ğ‘„ (cid:3) , RQ1: Howmanyhuman-annotatedlabelsarerequiredtoproduce
L Llow(cid:0)C CCRC( (ğ‘„,ğœ† low) ),ğ‘ˆ( (ğ‘„) )(cid:1) =1(cid:2) ğ‘ˆË† CRC( (ğ‘„,ğœ†
low
)) >ğ‘ˆ (( ğ‘„ )) (cid:3) . (23)
RQ2:
i Hn ofo wrm rea st ii lv iee nc to an refid the enc ce onin fit de er nv ca els i?
ntervalstosystematicmis-
Throughapplyingtwobinarysearchprocedures,wefindthevalues takesmadebyLLMlabelers?
forğœ† 1,1 andğœ† 1,1 suchthatğœ† <ğœ† and: RQ3: WhatbenefitscouldPPIandCRCgetfrompotentialimprove-
high low low high
âˆˆ (âˆ’ ) âˆˆ (âˆ’ )
mentsintheaccuracyoflabelgeneration?
ğ‘€1 âˆ‘ï¸ğ‘€ Lhigh/low(cid:0) CCRC (ğ‘„Â¯ ğ‘–,ğœ† high/low ),ğ‘ˆ (ğ‘„Â¯ ğ‘– )(cid:1)<1 2(cid:18) ğ›¼
âˆ’
1 ğ‘€âˆ’ğ›¼(cid:19) . (24) RQ L4 L: MC -a gn enC eR rC atc ea dpt ru er le ed vi aff ne cr een lc ae bs ei ln s.u Fn oc rer et aa ci hnt qy up ee rr y-q du oe cr uy m?
ent
ğ‘–=1
pair,apromptisconstructedthataskstheLLMtoassesstherele-
Consequently,accordingtoEq.22,itmustbethecasethattheCRC
vanceaccordingtotherelevancescalesofthedataset,inourcase:
requirementforthecompleteintervalholds:
0â€“2 (Robust04) and 0â€“3 (TREC-DL). The LLM is provided with
ğ‘€ cleardefinitionsofthedifferentrelevancelabels,similarto[63].
ğ‘€1 âˆ‘ï¸ 1(cid:2) ğ‘ˆ (ğ‘„Â¯ ğ‘–
)
âˆˆCCRC (ğ‘„Â¯ ğ‘–,ğœ† high,ğœ† low )(cid:3) <ğ›¼
âˆ’
1 ğ‘€âˆ’ğ›¼ . (25) Specifically,instructionsthatgivedefinitionsforrelevancelabels
ğ‘–=1 in each prompt. We chose prompts that mimic the instructions
forhumanannotatorsascloselyaspossible,hereby,wehopeto
Therefore,theresultingCIhasthedesiredreliability,whenapplied
tothedistributionunderlying Â¯:
Q 2OurexperimentalimplementationandourdatasetofgeneratedLLMlabelsare
ğ‘ƒ(cid:16) ğ‘ˆË† CRC (ğ‘„Â¯,ğœ† low )â‰¤ğ‘ˆ (ğ‘„Â¯ )â‰¤ğ‘ˆË† CRC (ğ‘„Â¯,ğœ† high )|ğ‘„Â¯ âˆ¼QÂ¯(cid:17) >1 âˆ’ğ›¼. (26) a cov nai fila db el ne ca et _: irh _t etp vs a: l/ _/ ugi st ih nu gb _. gc eo nm a/ igoogle-research/google-research/tree/master/high_
6ReliableConfidenceIntervalsforInformationRetrievalEvaluationUsingGenerativeA.I. KDDâ€™24,August25â€“29,2024,Barcelona,Spain
TREC-DL Robust04 TREC-DL Robust04
3.25
12 5 Bootstrap 3.00 1.00 Bootstrap
10 4 PPI 2.75 0.95 PPI
8 3 CRC 2.50 0.90 CRC
46 2 2.25 0.85
2 1 2.00 0.80
0 0 1.75 0.75
0 20 40 60 80 100 0 20 40 60 80 100 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
Adversarialbiasğ›½ Adversarialbiasğ›½
1.00 1.00
0.95 0.95 3.00 1.00
0.90 0.90 0.75
0.85 0.85 2.00
0.50
0.80 0.80 1.00
0.25
0.75 0.75
0 20 40 60 80 100 0 20 40 60 80 100 0.00 0.00
Nr.human-labeledqueries Nr.human-labeledqueries 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
Oracleweightğœ Oracleweightğœ
Figure2:Width(top)andcoverage(bottom)oftheconfidence
intervalsproducedbythemethods.Thedashedlineinthe Figure3:Widthoftheconfidenceintervalsforincreasing
bottomplotsisthe95%coveragetarget.Shadedareasindicate levelsofLLMbias(ğ›½,top-row)andoracle-enhancedLLMac-
95%predictionintervalsover500independentruns. curacy(ğœ 1,bottomrow)withğ‘› = 112onTREC-DLand
â†’
ğ‘› = 125onRobust04.Shadedareasindicate95%prediction
preciselysimulatethemanuallabelingprocessforeachdataset. intervalsover500independentruns.Coverageplotsareomit-
TheexactpromptsareprovidedinAppendixA. tedsinceallmethodsmaintain>95%coverage.
Toobtainrelevancelabels,weruntheLLMsinâ€˜scoringmodeâ€™[76].
Thatis,foreachrelevancelabelğ‘Ÿ ,wecomputethelog-probability thatonlyconsiderstheavailablehuman-labeleddata,thisisastan-
âˆˆR
oftheLLMoutputtingtherelevanceratingğ‘Ÿ.Thelog-probabilities dardapproachinpreviousIRliterature[5,56,72,73,75].Allour
arethennormalizedviaasoftmaxfunctionsothatweobtaina empiricalbootstrapCIarebasedon10,000bootstrapsamples.PPI
probabilitydistributionthatrepresentstheLLMâ€™sconfidencein iscomputedbyapplyingEq.11toboththevalidationset(thefirst
assigningeachrelevancelabeltothequery-documentpair. ğ‘›queries)andthetestset(theremainingğ‘ ğ‘›queries),itutilizes
AsourLLMmodel,wechoosetouseFlan-UL2[42,60],because bothhumanandLLM-generatedlabels.Finaâˆ’ lly,ourCRCapproach
itisopensourceandhasdemonstratedstrongperformanceonrank- alsoutilizesboth,weusethevalidationsettocalibratetheğœ†param-
ingtasks[55].Itisworthnotingthatlarger,morepowerful,LLMs etersandthencomputetheCIusingonlytheLLM-generatedlabels
exist[61],andthatwedonotutilizeanyprompt-engineering[63]. onthetest-set.Forcalibration,CRCisprovidedğ‘€ =10,000batches
Thesechoicesweremadebecausethegoalofourexperimentsisnot eachconsistingofğ‘›queriesthatweresampledwithreplacement
tofindthebestLLM-generatedlabels,buttoconfirmwhetherthe fromthevalidationset(seeSection6.2).Wenotethatthebatch
confidenceintervalsproposedbyourmethodsaccuratelycapture sizedependsonthenumberofavailablequerieswithhumanan-
theuncertaintyinLLM-generatedrelevancelabels.Sinceadvance- notations,whichisvariedinourexperiments.FortheCIstobe
mentsinLLMtechniquesresultinrapidchangesinthestate-of- evaluated,theCIisappliedtotheentiretest-settoobtainadataset-
the-art,wechoosetofocusontheestablishedhumanannotator levelCI,i.e.,wecompute ğ‘„test,ğœ† high,ğœ†
low
(Eq.20).Someofour
settinginstead[17,71]. experimentsconsiderCRCC C( Isaroundquery) -levelperformance,in
Datasets.Ourevaluationisbasedontwoestablishedbenchmark thesecases,ğœ†isnotcalibratedonbootstrappedbatchesbutonğ‘›
datasets:TREC-DL[17]andTREC-Robust04[71].Bothdatasets batchesthateachcontainasinglequery.
are comprised of documents and queries together with human- WeevaluatetheCIsproducedbyeachmethodbyconsidering
annotatedrelevancejudgments.Foreachdataset,weperforma theirwidthandcoverage.Thewidthmeasureshowwideandthus
random50:50splittoobtainavalidationandtestsetwherethe howinformativeorspecifictheCIis,whereasmallerwidthisbetter.
validationsetisusedforcalibrationofthemethods.(Atraining ThecoveragemeasureshowfrequenttheCIcoversthetrueperfor-
setisnotrequiredinoursetting.)Toavoiddistributionshifts,for manceonthetest-setover500independentlyrepeatedexperiment
TREC-DL, we create a stratified sample over four years (2019 - runs,thusthehigherthebetter.Thetargetforallthemethodsisa
2022)thatensureseachyearisequallyrepresentedineachsplit.As coverageof95%orhigherandwesetğ›¼ =0.05accordingly.
therankertoevaluate,wechooseBM25,asthemetricwechoose
DCG@10 [35]. In other words, our methods will construct CIs 8 Results
aroundtheDCG@10ofBM25onbothdatasets.Table1displays
8.1 Numberofrequiredhuman-annotations
therankingperformanceofBM25andtheLLM-generatedlabels.
TomatchthegainfunctionofDCGalllabelsweretransformed OurmainresultsaredisplayedinFigure2.Hereweseehowthe
accordingly:ğ‘Ÿ â€² =2ğ‘Ÿ 1,forallperformanceestimations. widthandcoverageofthedifferentmethodsvary,astheyarepro-
âˆ’
Methodsincomparison.Themethodsincludedinourcom- videdwithğ‘›querieswithhumanannotationssampledfromthe
parisonare:(i)empiricalbootstrapping[22],(ii)prediction-powered validationset.Asexpected,allmethodsprovidesbetterCIswhen
inference (PPI) (Section 4), and (iii) conformal risk control (CRC) providedwithlargerportionhuman-annotatedqueries,i.e.,asğ‘›
(Section6).Theempiricalbootstrapapproachactsasabaseline increasescoverageincreasesandwidthdecreases.
7
egarevoC
htdiW htdiW
htdiWKDDâ€™24,August25â€“29,2024,Barcelona,Spain HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichaelBendersky
ğœ =0 ğœ =0.25 ğœ =0.50 ğœ =0.75
30
20
10
0
15
10
5
0
Figure4:95%CIproducedper-querybyCRCusingLLMpredictedrelevanceannotations(ğœ =0)andoracle-enhancedLLM
annotations(ğœ >0).ThequeriesaresortedbytheirtrueDCGperformance(accordingtohuman-annotations),indicatedbyred
andgreendots.GreendotsarecoveredbytheirCIwhereasreddotsarenot.BluedotsindicatethepredictedDCGperformance
(accordingtoLLM-generatedannotations).Clearly,theCIsshrinkconsiderablyasannotationsbecomemoreaccurate(ğœ 1).
â†’
Westartbyconsideringtheperformanceoftheempiricalboot- Figure3showsthewidthsas ğ›½ isvaried(ğ‘› = 112onTREC-
strapbaseline.OntheTREC-DLdataset,weseethatitrequires DLandğ‘› = 125onRobust04).Wedonotreportcoverageasall
atleast40labeledqueriestoachieve95%coverage.Furthermore, methodsobtainameancoverageofatleast95%.Whenğ›½ <0.5,CRC
onRobust04,with100labeledqueriesitalmostreaches95%cover- consistentlyprovidesbetterwidthsthanempiricalbootstrap,whilst
age.However,theplottedpredictionintervalsaroundthereported PPIhasinconsistentimprovements.Asexpected,whenğ›½ > 0.5
coveragerevealthatmanyofitsrunsdidnotreach95%coverage. bothmethodsdoworsethanempiricalbootstrapintermsofwidth.
Incontrast,bothourPPIandCRCapproacheshavestronger Thus,wecananswerRQ2:thecoverageofbothPPIandCRC-
coveragewithlessqueries:PPIneedslessthan20queriesonTREC- bootstrap are robust to systematic mistakes made by the LLM,
DLandlessthan40onRobust04.Similarly,CRCneedslessthan30 however,improvementsinwidthsaredependentonLLMaccuracy.
onTREC-DLandlessthan50onRobust04.Intermsofwidth,CRC
clearlyprovidesthesmallestwidthofallthemethods,whilstPPIis 8.3 Potentialfrommoreaccuratelabels
worsethanempiricalbootstraponTREC-DLandcomparableon WerunadditionalexperimentstounderstandhowtheCIsbehave
Robust04.Thiscomparisonisnotentirelyfair,i.e.,thereisgenerally underanoracleLLM:onethatcanperfectlygeneraterelevance
atradeoffbetweencoverageandwidth,itappearsPPIdoesbetter labels.InFigure3,weincreasinglyinterpolatebetweentheLLM-
intermsofcoveragebutthatresultsinwiderCIs.Thus,PPIhas generated relevance labels and the true (human-annotated) rel-
aclearadvantageoverempiricalbootstraponRobust04whereit evance labels using a parameterğœ 0,1 . Asğœ increases, the
hasthesamewidthbutmuchbettercoverage.Nevertheless,when performanceoftheLLMlabelsbecomâˆˆ es[ bett] er.First,wenotethat
CRCandPPIhavethesamecoverage,CRChassmallerwidths,with allmethodsretainaperfect100%coverageinthesescenarios,so
anespeciallylargedifferenceonTREC-DL.Therefore,itappears weomittheplotsforcoverage.Theempiricalbootstrapapproach
that CRC has the most informative CI, whilst PPI needs fewer doesnotusetheLLM-generatedlabelsanditsCIisthusnotim-
queriestoreach95%coverage.Bothmethodsprovidesubstantial pactedbytheincreasinglystrongerLLMlabels.ThePPImethodis
improvementsoverempiricalbootstrapping. abletoleveragethestrongerLLMlabelsandisabletosignificantly
ThusweanswerRQ1asfollows:bothPPIandCRCrequireas outperformtheempiricalbootstrapmethod.ThefactthatitsCIis
fewas30human-labeledqueriestoproduceinformativeandreli- placedaroundtheoverallperformance(dataset-level),preventsit
ableconfidenceintervals.Whilstempiricalbootstrappingrequires fromfurtherimprovingthewidth,asitisinherentlylimitedbythe
significantlymorehuman-labeledqueriestoachievesimilarresults. numberofqueries.TheCRCapproachesareabletoworkaround
thislimitationbyefficientlyidentifyingthattheLLM-generated
labelsaremoreaccurateasğœ 1ontheper-documentlevel.Their
â†’
per-queryCIscorrespondinglyshrinkandapproach0astheLLM-
8.2 SensitivitytoLLMaccuracy
generatedlabelsbecomebetter.ThisanswersRQ3:BothPPIand
OurPPIandCRCmethodscanbenefitfromaccurateLLMlabels, CRCbenefitfromimprovementsinlabelgenerationaccuracy.
butinordertobereliable,itisalsoimportantthattheyarero-
busttoinaccuratelabels.WeinvestigatetheeffectofLLMaccu- 8.4 Query-performanceconfidenceintervals
racy by adding adversarial bias to the predicted relevance dis-
WeplottheconfidenceintervalsproducedbyCRConindividual
tributions, with ğ›½ 0,1 , change the predictions as follows:
(cid:16)âˆˆ [ ] (cid:17) queriesinFigure4.EachplotinthefigureshowsthetrueDCG
ğ‘ƒË† ğ›½ (ğ‘… =ğ‘Ÿ |ğ‘‘,ğ‘
)
= ğ‘1 (1 âˆ’ğ›½ )ğ‘ƒË† (ğ‘…=ğ‘Ÿ |ğ‘‘,ğ‘ )+ğ›½ (1 âˆ’ğ‘ƒË† (ğ‘…=ğ‘Ÿ |ğ‘‘,ğ‘
))
, (basedonhuman-annotatedrelevancelabels)andthepredicted
whereğ‘ isanormalizingfactortoensuretheresultisavalidproba- DCG(basedonLLM-generatedlabels)ofallqueriesinthetestsplit.
bilitydistribution.Forğ›½ =0thisleavespredictionsunaltered,with ThequeriesaresortedbytheirtrueDCG,thatis,querieswhere
ğ›½ =0.5thisisauniformdistributionandatğ›½ =1itproducesthe therankerperformsbestappearontheleftandprogressivelythe
inverseoftheoriginalpredictions. queryperformancegoesdown.Furthermore,weplottheper-query
8
LD-CERT
40tsuboR
01@GCD
01@GCDReliableConfidenceIntervalsforInformationRetrievalEvaluationUsingGenerativeA.I. KDDâ€™24,August25â€“29,2024,Barcelona,Spain
CIforvaryingvaluesofğœ,toindicatehowtheconfidenceintervals inthisworkarethoseoftheauthorsandarenotnecessarilyshared
behaveastheLLM-generatedlabelsbecomemoreaccurate,similar orendorsedbytheirrespectiveemployersorsponsors.
toSection8.3.First,forallplots,weobservethattheCIsvaryper
query:CRCcapturestheuncertaintythroughoutLLM-generated
References
labels.Second,fortheLLM-generatedlabels(ğœ = 0),weobserve
[1] MeysamAlizadeh,MaÃ«lKubli,ZeynabSamei,ShirinDehghani,JuanDiego
thatwhentheLLMpredictsthattherankerperformspoorlyona Bermeo,MariaKorobeynikova,andFabrizioGilardi.2023.Open-sourcelarge
query,theboundstendtobesmallerforthatquery.Similarly,when languagemodelsoutperformcrowdworkersandapproachChatGPTintext-
annotationtasks.arXivpreprintarXiv:2307.02179(2023).
thepredictedperformanceoftherankerislarge,theboundstendto
[2] AnastasiosNAngelopoulosandStephenBates.2021.Agentleintroductionto
bewider.ThisindicatesthattheLLM-generatedlabelsaregenerally conformalpredictionanddistribution-freeuncertaintyquantification. arXiv
betteratidentifyingquerieswithpoorrankingperformance.Third,
preprintarXiv:2107.07511(2021).
[3] AnastasiosNAngelopoulos,StephenBates,ClaraFannjiang,MichaelIJordan,and
asğœ
â†’
1,weseethatCRCisabletoidentifythatthelabelsare TijanaZrnic.2023.Prediction-poweredinference.arXivpreprintarXiv:2301.09633
moreaccurateanditsper-queryCIsbecomesignificantlytighter. (2023).
ThisshowsthatCRCisnotonlyabletovaryitsCIperquery,but [4] AnastasiosNAngelopoulos,StephenBates,AdamFisch,LihuaLei,andTal
Schuster.2022.Conformalriskcontrol.arXivpreprintarXiv:2208.02814(2022).
isalsoabletoestablishbetterper-queryCIsasLLMlabelsbecome [5] JavedAAslam,VirgilPavlu,andEmineYilmaz.2006.Astatisticalmethodfor
moreaccurate.Thisisespeciallynoticeableintheğœ =0.75plotfor systemevaluationusingincompletejudgments.InProceedingsofthe29thannual
internationalACMSIGIRconferenceonResearchanddevelopmentininformation
TREC-DL(top-rightplotinFigure4).Inthisplotthereisasingle retrieval.541â€“548.
outlierqueryontheleftwheretheLLMiswronganditspredicted [6] PeterBailey,NickCraswell,IanSoboroff,PaulThomas,ArjenPdeVries,and
labelsareuncertain.AsaresulttheCRCmethodcorrectlyplacesa EmineYilmaz.2008.Relevanceassessment:arejudgesexchangeableanddoesit
matter.InProceedingsofthe31stannualinternationalACMSIGIRconferenceon
verywideCIaroundthisparticularquery,whilekeepingtheCIson Researchanddevelopmentininformationretrieval.667â€“674.
otherqueriestight.Finally,onbothdatasetstheempiricalcoverage [7] VineethBalasubramanian,Shen-ShyangHo,andVladimirVovk.2014.Confor-
of95%isreached,indicatingtheCIsarereliable.Thus,weanswer
malpredictionforreliablemachinelearning:theory,adaptationsandapplications.
Newnes.
RQ4positively:CRCisabletoconstructCIsonaper-querybasis.
[8] EmilyMBender,TimnitGebru,AngelinaMcMillan-Major,andShmargaret
Shmitchell.2021. Onthedangersofstochasticparrots:Canlanguagemodels
betoobig?.InProceedingsofthe2021ACMconferenceonfairness,accountability,
9 Conclusion andtransparency.610â€“623.
[9] LuizBonifacio,HugoAbonizio,MarziehFadaee,andRodrigoNogueira.2022.
InthispaperwestudyreliableevaluationofIRsystemsusingLLM- Inpars:Unsuperviseddatasetgenerationforinformationretrieval.InProceedings
generatedrelevancelabels.Obtaininghuman-annotatedrelevance ofthe45thInternationalACMSIGIRConferenceonResearchandDevelopmentin
labelsiscostly,especiallyinlow-resourcesettings.WhileLLMscan
InformationRetrieval.2387â€“2392.
[10] FJayBreidtandJeanDOpsomer.2017.Model-assistedsurveyestimationwith
helpgeneraterelevancelabelsatscale,theyarepronetomakesys- modernpredictiontechniques.(2017).
tematicerrorsandmaybeunreliable.Weresolvethisbyintroducing [11] TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan,
PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,Amanda
twomethodsthatconstructconfidenceintervals(CIs)aroundrank-
Askell,etal.2020.Languagemodelsarefew-shotlearners.Advancesinneural
ingmetricsproducedbyLLM-generatedrelevancelabels:PPIand informationprocessingsystems33(2020),1877â€“1901.
CRC.Theseapproachesrequireasmallamountofreliableground [12] MichaelBucklandandFredricGey.1994.Therelationshipbetweenrecalland
precision. JournaloftheAmericansocietyforinformationscience45,1(1994),
truthannotationstostatisticallyanalyzethedistributionoferrors
12â€“19.
andcorrectthoseerrors. [13] BenCarterette,JamesAllan,andRameshSitaraman.2006.Minimaltestcollec-
Ourresultsdemonstratethattheproposedmethodscancorrect
tionsforretrievalevaluation.InProceedingsofthe29thannualinternationalACM
SIGIRconferenceonResearchanddevelopmentininformationretrieval.268â€“275.
errorsinLLM-generatedlabelsandproducereliableCIs.Compared [14] OlivierChapelleandYiChang.2011.Yahoo!learningtorankchallengeoverview.
tootherCIapproaches,wecanproduceCIsofsuperiorcoverage InProceedingsofthelearningtorankchallenge.PMLR,1â€“24.
[15] CharlesLAClarke,GianlucaDemartini,LauraDietz,GuglielmoFaggioli,Matthias
withtighterbounds,leadingtomoreinformativeevaluation.Fur-
Hagen,ClaudiaHauff,NorikoKando,EvangelosKanoulas,MartinPotthast,Ian
thermore,theCIsproducedbyCRCcanbecomputedper-query, Soboroff,etal.2023.4.2HMC:ASpectrumofHumanâ€“Machine-Collaborative
providingfurtherinsightsintoloworhighperformingqueries. RelevanceJudgmentFrameworks.FrontiersofInformationAccessExperimentation
forResearchandEducation(2023),41.
Ourworkisnotwithoutlimitations.First,wenotethatourmeth-
[16] GordonVCormackandThomasRLynam.2006.Statisticalprecisionofinfor-
odsrequireanLLMwithscoring-modetoproduceadistribution mationretrievalevaluation.InProceedingsofthe29thannualinternationalACM
overLLMlabels.ForLLMswithoutscoring-modeonecouldgener-
SIGIRconferenceonResearchanddevelopmentininformationretrieval.533â€“540.
[17] NickCraswell,BhaskarMitra,EmineYilmaz,DanielCampos,EllenMVoorhees,
atemultiplelabelsstochasticallytoapproximateapredicteddistri- andIanSoboroff.2021.TRECdeeplearningtrack:Reusabletestcollectionsinthe
bution.Second,ourresultssuggestthatapplyingsomesmoothing largedataregime.InProceedingsofthe44thinternationalACMSIGIRconference
onresearchanddevelopmentininformationretrieval.2369â€“2375.
totheLLM-generatedlabeldistributionisbeneficialtotheresulting
[18] AntoniaCreswell,TomWhite,VincentDumoulin,KaiArulkumaran,BiswaSen-
CIs.Howtosystematicallyoptimizetheamountofsmoothingisan gupta,andAnilABharath.2018.Generativeadversarialnetworks:Anoverview.
openquestion.Similarly,fine-tuningorprompt-engineeringcould IEEEsignalprocessingmagazine35,1(2018),53â€“65.
[19] JiaCui,BrianKingsbury,BhuvanaRamabhadran,AbhinavSethy,KartikAu-
alsoleadtodistributionsbettersuitedforCIconstruction.Third,we
dhkhasi,XiaodongCui,EllenKislal,LidiaMangu,MarkusNussbaum-Thom,
onlyusetheFlan-UL2asanLLMlabeler.Ourworkcanbeextended MichaelPicheny,etal.2015. Multilingualrepresentationsforlowresource
tousedifferentandpotentiallymorepowerfulLLMs.Futurework
speechrecognitionandkeywordsearch.In2015IEEEworkshoponautomatic
speechrecognitionandunderstanding(ASRU).IEEE,259â€“266.
couldexploreallofthesedirectionsfurther. [20] DomenicoDato,SeanMacAvaney,FrancoMariaNardini,RaffaelePerego,and
NicolaTonellotto.2022.TheIstella22Dataset:BridgingTraditionalandNeural
LearningtoRankEvaluation.InProceedingsofthe45thInternationalACMSIGIR
Acknowledgements ConferenceonResearchandDevelopmentinInformationRetrieval.3099â€“3107.
[21] ThomasDemeester,RobinAly,DjoerdHiemstra,DongNguyen,andChrisDe-
ThisresearchwassupportedbytheGoogleVisitingResearcher
velder.2016.Predictingrelevancebasedonassessordisagreement:analysisand
program.Anyopinions,findingsandrecommendationsexpressed practicalapplicationsforsearchevaluation. InformationRetrievalJournal19
9KDDâ€™24,August25â€“29,2024,Barcelona,Spain HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichaelBendersky
(2016),284â€“312. [49] LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,Pamela
[22] ThomasJDiCiccioandBradleyEfron.1996. Bootstrapconfidenceintervals. Mishkin,ChongZhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal.2022.
Statisticalscience11,3(1996),189â€“228. Traininglanguagemodelstofollowinstructionswithhumanfeedback.Advances
[23] ThomasJDiciccioandJosephPRomano.1988.Areviewofbootstrapconfidence inNeuralInformationProcessingSystems35(2022),27730â€“27744.
intervals.JournaloftheRoyalStatisticalSocietySeriesB:StatisticalMethodology [50] HarrisPapadopoulos.2008.Inductiveconformalprediction:Theoryandapplica-
50,3(1988),338â€“354. tiontoneuralnetworks.InToolsinartificialintelligence.Citeseer.
[24] BradleyEfron.1987.Betterbootstrapconfidenceintervals.JournaloftheAmeri- [51] JohnVPavlik.2023.CollaboratingwithChatGPT:Consideringtheimplicationsof
canstatisticalAssociation82,397(1987),171â€“185. generativeartificialintelligenceforjournalismandmediaeducation.Journalism
[25] GuglielmoFaggioli,LauraDietz,CharlesLAClarke,GianlucaDemartini,Matthias &MassCommunicationEducator78,1(2023),84â€“93.
Hagen,ClaudiaHauff,NorikoKando,EvangelosKanoulas,MartinPotthast, [52] CarolPeters.2001.Cross-LanguageInformationRetrievalandEvaluation:Work-
BennoStein,etal.2023. Perspectivesonlargelanguagemodelsforrelevance shopofCross-LanguageEvaluationForum,CLEF2000,Lisbon,Portugal,September
judgment.InProceedingsofthe2023ACMSIGIRInternationalConferenceon 21-22,2000,RevisedPapers.Vol.2069.SpringerScience&BusinessMedia.
TheoryofInformationRetrieval.39â€“50. [53] TaoQinandTie-YanLiu.2013.IntroducingLETOR4.0datasets.arXivpreprint
[26] NorbertFuhr.2018.SomecommonmistakesinIRevaluation,andhowtheycan arXiv:1306.2597(2013).
beavoided.InAcmsigirforum,Vol.51.ACMNewYork,NY,USA,32â€“41. [54] TaoQin,Tie-YanLiu,JunXu,andHangLi.2010.LETOR:Abenchmarkcollection
[27] FabrizioGilardi,MeysamAlizadeh,andMaÃ«lKubli.2023.Chatgptoutperforms forresearchonlearningtorankforinformationretrieval.InformationRetrieval
crowd-workersfortext-annotationtasks.arXivpreprintarXiv:2303.15056(2023). 13(2010),346â€“374.
[28] IanGoodfellow,JeanPouget-Abadie,MehdiMirza,BingXu,DavidWarde-Farley, [55] ZhenQin,RolfJagerman,KaiHui,HongleiZhuang,JunruWu,JiamingShen,
SherjilOzair,AaronCourville,andYoshuaBengio.2020.Generativeadversarial TianqiLiu,JialuLiu,DonaldMetzler,XuanhuiWang,etal.2023.Largelanguage
networks.Commun.ACM63,11(2020),139â€“144. modelsareeffectivetextrankerswithpairwiserankingprompting.arXivpreprint
[29] JiafengGuo,YixingFan,LiangPang,LiuYang,QingyaoAi,HamedZamani,Chen arXiv:2306.17563(2023).
Wu,WBruceCroft,andXueqiCheng.2020.Adeeplookintoneuralranking [56] TetsuyaSakai.2014.Statisticalreformininformationretrieval?.InACMSIGIR
modelsforinformationretrieval. InformationProcessing&Management57,6 Forum,Vol.48.ACMNewYork,NY,USA,3â€“12.
(2020),102067. [57] MarkSandersonetal.2010. Testcollectionbasedevaluationofinformation
[30] DonnaHarman.2011. Informationretrievalevaluation. Morgan&Claypool retrievalsystems.FoundationsandTrendsÂ®inInformationRetrieval4,4(2010),
Publishers. 247â€“375.
[31] DonnaKHarman.2005.TheTRECtestcollections.(2005). [58] MarkSandersonandJustinZobel.2005.Informationretrievalsystemevaluation:
[32] TimHesterberg.2011.Bootstrap.WileyInterdisciplinaryReviews:Computational effort,sensitivity,andreliability.InProceedingsofthe28thannualinternational
Statistics3,6(2011),497â€“526. ACMSIGIRconferenceonResearchanddevelopmentininformationretrieval.162â€“
[33] GeorgeHripcsakandAdamSRothschild.2005.Agreement,thef-measure,and 169.
reliabilityininformationretrieval.JournaloftheAmericanmedicalinformatics [59] MarkDSmucker,JamesAllan,andBenCarterette.2007. Acomparisonof
association12,3(2005),296â€“298. statisticalsignificancetestsforinformationretrievalevaluation.InProceedings
[34] ZhiqiHuang,PuxuanYu,andJamesAllan.2023.ImprovingCross-lingualInfor- ofthesixteenthACMconferenceonConferenceoninformationandknowledge
mationRetrievalonLow-ResourceLanguagesviaOptimalTransportDistillation. management.623â€“632.
InProceedingsoftheSixteenthACMInternationalConferenceonWebSearchand [60] YiTay,MostafaDehghani,VinhQTran,XavierGarcia,DaraBahri,TalSchus-
DataMining.1048â€“1056. ter,HuaixiuStevenZheng,NeilHoulsby,andDonaldMetzler.2022.Unifying
[35] KalervoJÃ¤rvelinandJaanaKekÃ¤lÃ¤inen.2002.Cumulatedgain-basedevaluation languagelearningparadigms.arXivpreprintarXiv:2205.05131(2022).
ofIRtechniques.ACMTransactionsonInformationSystems(TOIS)20,4(2002), [61] GeminiTeam,RohanAnil,SebastianBorgeaud,YonghuiWu,Jean-Baptiste
422â€“446. Alayrac,JiahuiYu,RaduSoricut,JohanSchalkwyk,AndrewMDai,AnjaHauth,
[36] KalervoJÃ¤rvelinandJaanaKekÃ¤lÃ¤inen.2017.IRevaluationmethodsforretrieving etal.2023.Gemini:afamilyofhighlycapablemultimodalmodels.arXivpreprint
highlyrelevantdocuments.InACMSIGIRForum,Vol.51.ACMNewYork,NY, arXiv:2312.11805(2023).
USA,243â€“250. [62] NandanThakur,NilsReimers,AndreasRÃ¼cklÃ©,AbhishekSrivastava,andIryna
[37] MladanJovanovicandMarkCampbell.2022.Generativeartificialintelligence: Gurevych.2021.Beir:Aheterogenousbenchmarkforzero-shotevaluationof
Trendsandprospects.Computer55,10(2022),107â€“112. informationretrievalmodels.arXivpreprintarXiv:2104.08663(2021).
[38] NorikoKando,KazukoKuriyama,ToshihikoNozue,KojiEguchi,HiroyukiKato, [63] PaulThomas,SethSpielman,NickCraswell,andBhaskarMitra.2023. Large
andSouichiroHidaka.1999.OverviewofIRtasksatthefirstNTCIRworkshop. languagemodelscanaccuratelypredictsearcherpreferences. arXivpreprint
InProceedingsofthefirstNTCIRworkshoponresearchinJapanesetextretrieval arXiv:2309.10621(2023).
andtermrecognition.11â€“44. [64] PetterTÃ¶rnberg.2023. Chatgpt-4outperformsexpertsandcrowdworkersin
[39] JaanaKekÃ¤lÃ¤inenandKalervoJÃ¤rvelin.2002.Usinggradedrelevanceassessments annotatingpoliticaltwittermessageswithzero-shotlearning. arXivpreprint
inIRevaluation. JournaloftheAmericanSocietyforInformationScienceand arXiv:2304.06588(2023).
Technology53,13(2002),1120â€“1129. [65] GeorgeTsatsaronis,GeorgiosBalikas,ProdromosMalakasiotis,IoannisPartalas,
[40] MichaelELeskandGerardSalton.1968.Relevanceassessmentsandretrieval MatthiasZschunke,MichaelRAlvers,DirkWeissenborn,AnastasiaKrithara,Ser-
systemevaluation.Informationstorageandretrieval4,4(1968),343â€“359. giosPetridis,DimitrisPolychronopoulos,etal.2015.AnoverviewoftheBIOASQ
[41] YueLiu,ZhengweiYang,ZhenyaoYu,ZituLiu,DahuiLiu,HailongLin,Mingqing large-scalebiomedicalsemanticindexingandquestionansweringcompetition.
Li,ShuchangMa,MaximAvdeev,andSiqiShi.2023.Generativeartificialintel- BMCbioinformatics16,1(2015),1â€“28.
ligenceanditsapplicationsinmaterialsscience:Currentsituationandfuture [66] JuliÃ¡nUrbano,HarlleyLima,andAlanHanjalic.2019. Statisticalsignificance
perspectives.JournalofMateriomics(2023). testingininformationretrieval:anempiricalanalysisoftypeI,typeIIandtypeIII
[42] ShayneLongpre,LeHou,TuVu,AlbertWebson,HyungWonChung,YiTay, errors.InProceedingsofthe42ndInternationalACMSIGIRconferenceonResearch
DennyZhou,QuocVLe,BarretZoph,JasonWei,etal.2023.Theflancollection: anddevelopmentininformationretrieval.505â€“514.
Designingdataandmethodsforeffectiveinstructiontuning. arXivpreprint [67] CornelisJoostVanRijsbergenandWBruceCroft.1975.Documentclustering:An
arXiv:2301.13688(2023). evaluationofsomeexperimentswiththeCranfield1400collection.Information
[43] ClaudioLucchese,FrancoMariaNardini,RaffaelePerego,SalvatoreOrlando,and Processing&Management11,5-7(1975),171â€“182.
SalvatoreTrani.2018.Selectivegradientboostingforeffectivelearningtorank. [68] Ellen Voorhees, Tasmeer Alam, Steven Bedrick, Dina Demner-Fushman,
InThe41stInternationalACMSIGIRConferenceonResearch&Developmentin WilliamRHersh,KyleLo,KirkRoberts,IanSoboroff,andLucyLuWang.2021.
InformationRetrieval.155â€“164. TREC-COVID:constructingapandemicinformationretrievaltestcollection.In
[44] SeanMacAvaneyandLucaSoldaini.2023. One-ShotLabelingforAutomatic ACMSIGIRForum,Vol.54.ACMNewYork,NY,USA,1â€“12.
RelevanceEstimation.arXivpreprintarXiv:2302.11266(2023). [69] EllenMVoorhees.2019.Theevolutionofcranfield.InformationRetrievalEvalua-
[45] BhaskarMitraandNickCraswell.2017.Neuralmodelsforinformationretrieval. tioninaChangingWorld:LessonsLearnedfrom20YearsofCLEF(2019),45â€“69.
arXivpreprintarXiv:1705.01509(2017). [70] EllenMVoorheesetal.2003.OverviewoftheTREC2003robustretrievaltrack..
[46] BhaskarMitra,NickCraswell,etal.2018.Anintroductiontoneuralinformation InTrec.69â€“77.
retrieval.FoundationsandTrendsÂ®inInformationRetrieval13,1(2018),1â€“126. [71] EllenMVoorhees,DonnaKHarman,etal.2005.TREC:Experimentandevaluation
[47] TriNguyen,MirRosenberg,XiaSong,JianfengGao,SaurabhTiwary,Rangan ininformationretrieval.Vol.63.MITpressCambridge.
Majumder,andLiDeng.2016.MSMARCO:Ahumangeneratedmachinereading [72] WilliamWebber.2013.Approximaterecallconfidenceintervals.ACMTransac-
comprehensiondataset.choice2640(2016),660. tionsonInformationSystems(TOIS)31,1(2013),1â€“33.
[48] KezbanDilekOnal,YeZhang,IsmailSengorAltingovde,MdMustafizurRahman, [73] WilliamEdwardWebber.2010.Measurementininformationretrievalevaluation.
PinarKaragoz,AlexBraylan,BrandonDang,Heng-LuChang,HennaKim,Quin- Ph.D.Dissertation.UniversityofMelbourne,DepartmentofComputerScience
tenMcNamara,etal.2018.Neuralinformationretrieval:attheendoftheearly andSoftwareEngineering.
years.InformationRetrievalJournal21(2018),111â€“182.
10ReliableConfidenceIntervalsforInformationRetrievalEvaluationUsingGenerativeA.I. KDDâ€™24,August25â€“29,2024,Barcelona,Spain
[74] MahsaYarmohammadi,XutaiMa,SoramiHisamoto,MuhammadRahman,Yim- Listing1:PromptforTREC-DL.
ingWang,HainanXu,DanielPovey,PhilippKoehn,andKevinDuh.2019.Robust
documentrepresentationsforcross-lingualinformationretrievalinlow-resource Assess the relevance of the passage to the query on a four-point
settings.InProceedingsofMachineTranslationSummitXVII:ResearchTrack. scale:
12â€“20. [0] Irrelevant: The passage has nothing to do with the query.
[75] EmineYilmaz,EvangelosKanoulas,andJavedAAslam.2008. Asimpleand [1] Related: The passage seems related to the query but does not
efficientsamplingmethodforestimatingAPandNDCG.InProceedingsofthe answer it.
31stannualinternationalACMSIGIRconferenceonResearchanddevelopmentin [2] Highly relevant: The passage has some answer for the query, but
informationretrieval.603â€“610. the answer may be a bit unclear, or hidden amongst extraneous
[76] HongleiZhuang,ZhenQin,KaiHui,JunruWu,LeYan,XuanhuiWang,and information.
MichaelBerdersky.2023.Beyondyesandno:Improvingzero-shotllmrankers [3] Perfectly relevant: The passage is dedicated to the query and
viascoringfine-grainedrelevancelabels.arXivpreprintarXiv:2310.14122(2023). contains the exact answer.
Query: {query}
A Prompts Passage: {passage}
Relevance:
Theexactpromptsusedinourexperimentsarelistedhere.We
notethatthesepromptsaretailoredtowardseachdatasetanduse
Listing2:PromptforRobust04.
therelevancelabeldefinitionsthathumanlabelersusedforeach
dataset.The{query}and{passage}/{document}areplaceholders Assess the relevance of the document to the query on a three-point
scale:
thatareformattedwiththeactualqueryandpassage/document
[0] Not relevant: The document is not relevant to the query.
duringinference. [1] Relevant: Parts of the document may be relevant to the query.
Weobservedthatthemodelissensitivetotheparticularprompt [2] Highly Relevant: The document is highly relevant to the query.
anddatasetduringscoringmode.ForTREC-DLwescorethesuffixes Query: {query}
"0","1","2"and"3".ForRobust04wefoundthatscoringthesuffixes Document: {document}
Relevance:
withbracketsismoreeffective:"[0]","[1]"and"[2]".
11