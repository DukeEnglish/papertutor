Chasing Convex Functions with Long-term Constraints
AdamLechowiczâˆ— NicolasChristiansonâ€  BoSunâ€¡ NomanBashirÂ§
MohammadHajiesmailiÂ¶ AdamWiermanâˆ¥ PrashantShenoyâˆ—âˆ—
February22,2024
Abstract
We introduce and study a family of online metric problems with long-term constraints. In these
problems,anonlineplayermakesdecisionsxğ‘¡ inametricspace(ğ‘‹,ğ‘‘)tosimultaneouslyminimizetheir
hittingcostğ‘“ ğ‘¡(xğ‘¡)andswitchingcostasdeterminedbythemetric.Overthetimehorizonğ‘‡,theplayer
mustsatisfyalong-termdemandconstraint(cid:205) ğ‘¡ğ‘(xğ‘¡) â‰¥ 1,whereğ‘(xğ‘¡)denotesthefractionofdemand
satisfiedattimeğ‘¡.Suchproblemscanfindawidearrayofapplicationstoonlineresourceallocationin
sustainable energy and computing systems. We devise optimal competitive and learning-augmented
algorithmsforspecificinstantiationsoftheseproblems,andfurthershowthatourproposedalgorithms
performwellinnumericalexperiments.
1 Introduction
This paper introduces and studies a novel class of online metric problems with long-term demand con-
straintsmotivatedbyemergingapplicationsinthedesignofsustainablesystems. Inconvexfunctionchas-
ingwithalong-termconstraint,anonlineplayeraimstosatisfyademandbymakingdecisionsinanormed
vector space, paying a hitting cost based on time-varying convex cost functions which are revealed on-
line,andswitchingcostdefinedbythenorm. Theplayerisconstrainedtoensurethattheentiredemand
is satisfied at or before the time horizonğ‘‡ ends, and their objective is to minimize their total cost. The
generality of this problem makes it applicable to a wide variety of online resource allocation problems;
in this paper, we consider one such special case, discussing its connections to other online settings and
suggestionstowardsbroadnewareasofinquiryinonlineoptimizationwithlong-termconstraints.
Our motivation to introduce these problems is rooted in an emerging class of carbon-aware control
problems for sustainable systems. A shared objective involves minimizing carbon emissions by shifting
flexible workloads temporally and/or spatially to better leverage low-carbon electricity generation (e.g.,
renewablessuchassolarandwind).Exampleswhichhaverecentlyseensignificantinterestincludecarbon-
aware electric vehicle (EV) charging [CBS+22] and carbon-aware compute shifting [WBS+21; BGH+21;
RKS+22;ALK+23;HLB+23].
âˆ—UniversityofMassachusettsAmherst.Email:alechowicz@cs.umass.edu
â€ CaliforniaInstituteofTechnology.Email:nchristianson@caltech.edu
â€¡UniversityofWaterloo.Email:bo.sun@uwaterloo.ca
Â§MassachusettsInstituteofTechnology.Email:nbashir@mit.edu
Â¶UniversityofMassachusettsAmherst.Email:hajiesmaili@cs.umass.edu
âˆ¥CaliforniaInstituteofTechnology.Email:adamw@caltech.edu
âˆ—âˆ—UniversityofMassachusettsAmherst.Email:shenoy@cs.umass.edu
1
4202
beF
12
]SD.sc[
1v21041.2042:viXraTheproblemsweintroduceinthispaperbuildonalonglineofrelatedworkinonlinealgorithms.Most
existingworkcanberoughlyclassifiedintotwotypes:onlinemetricproblems,wheremanyworksconsider
multidimensional decision spaces and switching costs but do not consider long-term constraints [BLS92;
Kou09; CGW18; BKL+19; BCL+21; BC22; BCR23], and online search problems, which feature long-term
demand constraints but do not consider multidimensional decision spaces or switching costs [EFK+01;
LPS08;MAS14;SZL+21].
Webrieflyreviewthedirectprecursorsofourworkbelow. Intheonlinemetricliterature,theproblem
we study is an extension of convex function chasing (CFC) introduced by Friedman and Linial [FL93],
where an online player makes online decisions xğ‘¡ in a normed vector space (ğ‘‹,âˆ¥Â·âˆ¥) over a sequence of
time-varyingcostfunctionsinordertominimizetheirtotalhittingandswitchingcost.Intheonlinesearch
literature, the problem we study is a generalization of one-way trading (OWT) introduced by El-Yaniv et
al. [EFK+01], in which an online player must sell an entire asset in fractional shares over a sequence of
time-varyingpriceswhilemaximizingtheirprofit.
Despite extensive existing work in the online metric and online search tracks, few works simultane-
ouslyconsiderlong-termdemandconstraints(asinOWT)andmovement/switchingcosts(asinCFC).The
existing prior works [LCZ+23; LCS+24] that consider both components are restricted to unidimensional
decision spaces, as is typical in the online search literature. However, generalizing from the unidimen-
sionalcaseishighlynon-trivial;e.g.,inconvexfunctionchasingwithalong-termconstraint,theproblem
cannotsimplybedecomposedoverdimensionsduetothesharedcapacityconstraintandmultidimensional
switchingcost. Thus,inthisworkwetacklethefollowingquestion:
Is it possible to design online algorithms for the studied problems that operate in multidimen-
sionaldecisionspaceswhilesimultaneouslyconsideringlong-termconstraints,hittingcosts,and
switchingcosts?
Although the aforementioned literature focuses on competitive algorithms in adversarial settings,
there has recently been significant interest in moving beyond worst-case analysis, which can result in
overlypessimisticalgorithms. Thefieldoflearning-augmentedalgorithms [LV18; PSK18]hasemergedas
aparadigmfordesigningandanalyzingalgorithmsthatincorporateuntrustedmachine-learnedadviceto
improveaverage-caseperformancewithoutsacrificingworst-caseperformancebounds. Suchalgorithms
areevaluatedthroughthemetricsofconsistencyandrobustness(seeDef.2.1).Recentstudieshaveproposed
learning-augmented algorithms for related problems, including convex function chasing [CHW22], one-
waytrading[SLH+21], metricaltasksystems[CSW23], andonlinesearch[LSH+24]. Whiletheliterature
ineachofthesetracksconsidersaspectrumofdifferentadvicemodels,theirresultspromptanaturalopen
question:
Canwedesignalgorithmsforonlinemetricproblemswithlong-termconstraintsthateffectively
utilizeuntrustedadvice(suchasmachine-learnedpredictions)toimproveperformancewhilepre-
servingworst-casecompetitiveguarantees?
Contributions. Despite extensive prior literature on adjacent problems, the problems we propose in
this paper are the first online settings to combine long-term demand constraints with multidimensional
decision spaces and switching costs. We introduce convex function chasing with a long-term constraint,
andaspecialcasecalledonlinemetricallocationwithalong-termconstraint. Thegeneralformsofbothare
independentlyinterestingforfurtherstudy.
We obtain positive results for both of the questions posed above under problem instantiations that
are especially relevant for motivating applications. We provide the first competitive results for online
problemsofthisforminSection3,andshowthatourproposedalgorithm(Algorithm1)achievesthebest
2possiblecompetitiveratio. InSection4,weproposealearning-augmentedalgorithm,CLIP(Algorithm2),
andshowitachievestheprovablyoptimaltrade-offbetweenconsistencyandrobustness.
Toachievetheseresults,theproposedalgorithmsmusttackletechnicalchallengesdistinctfromprior
work studying adjacent problems. We build on a generalization of the threshold-based designs used for
simpledecisionspacesintheonlinesearchliteraturecalledpseudo-costminimization.Weintroduceanovel
application of this framework to multidimensional decision spaces (see Section 3), and show that it sys-
tematicallyaddressesthecompetitivedrawbacksoftypicalalgorithmdesignsforonlinemetricproblems.
Weevaluateourproposedalgorithmsinnumericalexperimentsandshowthatouralgorithmsoutperform
asetofbaselineheuristicsonsyntheticinstancesofconvexfunctionchasingwithalong-termconstraint.
Our learning-augmented algorithm CLIP (see Section 4) introduces a novel projected consistency con-
straint which is designed to guarantee (1 +ğœ–)-consistency against the provided advice ADV by continu-
ously comparing their solutions in terms of the cost incurred so far, the switching cost trajectories, and
the projected worst-case cost required to complete the long-term constraint. To solve both convex func-
tion chasing and online metric allocation with long-term constraints, we derive a transformation result
thatdirectlyrelatestheperformanceofanalgorithmontheformerproblemwithitsperformanceonthe
latter(seeSection2).
2 Problem Formulation and Preliminaries
Thissectionformalizesconvexfunctionchasingandonlinemetricallocationwithlong-termconstraints,
motivating them with a sustainability application. We also provide preliminaries used throughout the
paper,andgiveinitialresultstobuildalgorithmicconnectionsbetweenbothproblems.
Convex function chasing with a long-term constraint. A player chooses decisions xğ‘¡ âˆˆ ğ‘‹ âŠ† Rğ‘‘
onlinefromanormedvectorspace (ğ‘‹,âˆ¥Â·âˆ¥) inordertominimizetheirtotalcost(cid:205)ğ‘‡ ğ‘¡=1ğ‘“ ğ‘¡(xğ‘¡) +(cid:205)ğ‘‡ ğ‘¡=+ 11 âˆ¥xğ‘¡ âˆ’
xğ‘¡âˆ’1âˆ¥, where ğ‘“ ğ‘¡(Â·) : ğ‘‹ â†’ R is a convex â€œhittingâ€ cost that is revealed just before the player chooses xğ‘¡,
and âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥ isaswitchingcostassociatedwithchangingdecisionsbetweenrounds. Additionally,the
player must satisfy a long term constraint of the form (cid:205)ğ‘‡ ğ‘¡=1ğ‘(xğ‘¡) = 1, whereğ‘(x) : ğ‘‹ â†’ [0,1] gives the
fractionoftheconstraintsatisfiedbyadecisionx. Wedenotetheutilizationattimeğ‘¡ byğ‘§(ğ‘¡) = (cid:205) ğœğ‘¡ =1ğ‘(xğœ),
whichgivesthetotalfractionofthelong-termconstraintsatisfieduptoandincludingtimeğ‘¡. Theoffline
versionofthisproblemcanbeformalizedasfollows:
min
âˆ‘ï¸ğ‘‡
ğ‘“ ğ‘¡(xğ‘¡)
+âˆ‘ï¸ğ‘‡+1
âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥ s.t.
âˆ‘ï¸ğ‘‡
ğ‘(xğ‘¡) â‰¥ 1, xğ‘–
ğ‘¡
âˆˆ [0,1] âˆ€ğ‘– âˆˆ [ğ‘‘], âˆ€ğ‘¡ âˆˆ [ğ‘‡]. (1)
{xğ‘¡}ğ‘¡âˆˆ[ğ‘‡] (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ğ‘¡ (cid:32)(cid:32)(cid:32)=1 (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ğ‘¡ (cid:32)(cid:32)=(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ğ‘¡ (cid:32)(cid:32)=(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Convexhittingcost Switchingcost Long-termconstraint
Assumptions. Here,wedescribetheprecisevariantofconvexfunctionchasingwithalong-termcon-
straintforwhichwedesignalgorithmsintheremainderofthepaper. Let âˆ¥xâˆ’xâ€²âˆ¥ (cid:66) âˆ¥xâˆ’xâ€²âˆ¥ â„“ 1(w),where
âˆ¥Â·âˆ¥ â„“ 1(w) denotestheweightedâ„“ 1 normwithweightvectorw âˆˆ Rğ‘‘ .
Wedefinethelong-termconstraintsuchthatğ‘(x) (cid:66) âˆ¥xâˆ¥ â„“ 1(c),i.e.,theweightedâ„“ 1normwithweightvector
c âˆˆ Rğ‘‘ . Thenletthemetricspaceğ‘‹ betheâ„“ 1 balldefinedbyğ‘‹ (cid:66) {x âˆˆ Rğ‘‘ :ğ‘(x) â‰¤ 1}. Forallcostfunctions
ğ‘“ ğ‘¡(Â·) : ğ‘‹ â†’ R, weassumeboundedgradientssuchthatğ¿ â‰¤ [âˆ‡ğ‘“ ğ‘¡]ğ‘–/ cğ‘– â‰¤ ğ‘ˆ âˆ€ğ‘– âˆˆ [ğ‘‘],ğ‘¡ âˆˆ [ğ‘‡], whereğ‘– denotes
theğ‘–thdimensionofthecorrespondingvector,andğ¿,ğ‘ˆ areknownpositiveconstants.
Letting 0 denote the origin in Rğ‘‘ (w.l.o.g), we have the property ğ‘“ ğ‘¡(0) = 0 for all ğ‘¡ âˆˆ [ğ‘‡], i.e., that
â€œsatisfying none of the long-term constraint costs nothingâ€, sinceğ‘(0) = 0. We assume the player starts and
endsattheorigin,i.e.,x0 = 0andxğ‘‡+1 = 0,toenforceswitchingâ€œonâ€andâ€œoff.â€Theseassumptionsareintuitive
andreasonableinpractice,e.g.,inourexamplemotivatingapplicationbelow.
For analysis, it will be useful to establish a shorthand for the magnitude of the switching cost. Let
ğ›½ (cid:66) max(cid:0) wğ‘–/ cğ‘–(cid:1) , which gives the greatest magnitude of the switching cost coefficient when normalized by
3theconstraintfunction. Weassumethatğ›½ isboundedontheinterval [0,ğ‘ˆâˆ’ğ¿/2);ifğ›½ isâ€œlargeâ€(i.e., > ğ‘ˆâˆ’ğ¿/2),
1
wecanshowthattheplayershouldprioritizeminimizingtheswitchingcost.
Recall the player must fully satisfy the long-term constraint before the sequence ends. If the player has
satisfiedğ‘§(ğ‘¡) fraction of the constraint at timeğ‘¡, we assume a compulsory trade begins at time ğ‘— as soon as
(ğ‘‡ âˆ’(ğ‘— +1)) Â· cğ‘– < (cid:0)1âˆ’ğ‘§(ğ‘—)(cid:1) âˆ€ğ‘– âˆˆ [ğ‘‘] (i.e., when the time steps after ğ‘— are not sufficient to satisfy the
constraint). During this compulsory trade, a cost-agnostic algorithm takes over, making maximal decisions
to satisfy the constraint. To ensure that the problem remains technically interesting, we assume that the
2
compulsorytradeisasmallportionofthesequence.
Forbrevity,wehenceforthuseCFLtorefertothevariantofconvexfunctionchasingwithalong-term
constraintundertheassumptionsoutlinedabove.
Anexamplemotivatingapplication. CFLcanmodelavarietyofapplications,includingspecificap-
plications that motivate this study. Consider a carbon-aware temporal load shifting application with het-
erogeneous servers. Here, each of theğ‘‘ dimensions corresponds to one ofğ‘‘ heterogeneous servers. An
algorithm makes decisions xğ‘¡ âˆˆ Rğ‘‘, where xğ‘–
ğ‘¡
âˆˆ [0,1] denotes the load of theğ‘–th server at time ğ‘¡. The
long-term constraint (cid:205)ğ‘‡ ğ‘¡=1ğ‘(xğ‘¡) â‰¥ 1 enforces that an entire workload should be finished before timeğ‘‡,
andeachcoefficientcğ‘– representsthethroughputoftheğ‘–thserver. Eachcostfunctionğ‘“ ğ‘¡(xğ‘¡)representsthe
carbonemissionsduetotheelectricityusageoftheserversconfiguredaccordingtoxğ‘¡,andtheswitching
cost âˆ¥Â·âˆ¥ captures the carbon emissions overhead (e.g., extra latency) of pausing, resuming, scaling,
â„“ 1(w)
andmovingtheworkloadbetweenservers.
Online metric allocation with a long-term constraint. Bansal and Coester [BC22] introduced the
online metric allocation problem (MAP), which connects several online metric problems. MAP on a star
metricisequivalenttoCFCwhencostfunctionsareseparableoverdimensionsandsupportedontheunit
simplexÎ” ğ‘›.3 Furthermore,therandomizedmetricaltasksystemsproblem(MTS)isaspecialcaseofMAP
whencostfunctionsarelinearandincreasing.
We build on this formulation in our setting and introduce online metric allocation with a long-term
constraint,whichcapturesaparticularlyinterestingspecialcaseofCFL.Thegeneralversionoftheproblem
considersanğ‘›-pointmetricspace (ğ‘‹,ğ‘‘),andaunitresourcewhichcanbeallocatedinarbitraryfractions
tothepointsofğ‘‹. Ateachtimeğ‘¡ âˆˆ [ğ‘‡],convexcostfunctions ğ‘“ğ‘(Â·) : [0,1] â†’ Rarriveateachpointğ‘ in
ğ‘¡
themetricspace. Theonlineplayerchoosesanallocationğ‘¥ğ‘ toeachpointğ‘inthemetricspace,suchthat
ğ‘¡
(cid:205)ğ‘› ğ‘¥ğ‘ = 1forallğ‘¡ âˆˆ [ğ‘‡]. Whenchangingthisallocationbetweentimesteps,theplayerpaysaswitching
ğ‘=1 ğ‘¡
costdefinedbyğ‘‘(ğ‘,ğ‘) foranydistinctpointsğ‘,ğ‘ âˆˆ ğ‘‹. AsinCFL, thelong-termconstraintenforcesthat
(cid:205)ğ‘‡ ğ‘¡=1ğ‘(xğ‘¡) â‰¥ 1,whereğ‘(x) isalinearandseparablefunctionoftheformğ‘(x) = (cid:205)ğ‘› ğ‘=1cğ‘ğ‘¥ğ‘. Aspreviously,
theplayerâ€™sobjectiveistominimizethetotalcost(hittingplusswitchingcosts)incurredwhilesatisfying
thelong-termconstraint.
Assumptions. In the rest of the paper, we consider an instantiation of online metric allocation with
a long-term constraint on weighted star metrics that is particularly relevant to a wide class of resource
allocationproblems.
Toensurethelong-termconstraintisnon-trivial,wedenoteatleastonepointğ‘â€²inthemetricspaceastheâ€œOFF
stateâ€,wherecğ‘â€² = 0and ğ‘“ğ‘â€²(ğ‘¥) = 0 âˆ€ğ‘¡ âˆˆ [ğ‘‡],âˆ€ğ‘¥ âˆˆ [0,1]. Forallothercostfunctions,wecarryforwardthe
ğ‘¡
assumptionsthatğ¿ â‰¤ ğ‘‘ğ‘“ ğ‘¡ğ‘/ğ‘‘ğ‘¥ğ‘ â‰¤ ğ‘ˆ,ğ‘“ ğ‘¡ğ‘(0) = 0 âˆ€ğ‘¡ âˆˆ [ğ‘‡]. Wedefine ğ›½ (cid:66) max ğ‘â€²,ğ‘ğ‘‘(ğ‘â€²,ğ‘), i.e., themaximum
1Asbriefjustificationfortheboundsonğ›½,considerthatafeasiblesolutionmayhaveobjectivevalueğ¿+2ğ›½. Ifğ›½ > ğ‘ˆâˆ’ğ¿/2,
ğ¿+2ğ›½ >ğ‘ˆ,andwearguethattheincurredswitchingcostismoreimportantthanthecostfunctionsaccepted.
2We assume the first time ğ‘—â€² where (ğ‘‡ âˆ’(ğ‘—â€²+1))cğ‘– < 1 âˆ€ğ‘– satisfies ğ‘—â€² â‰« 1, which implies thatğ‘‡ and c are both sized
appropriatelyfortheconstraint. Thisisreasonableforanapplicationsuchascarbon-awareloadshifting,sinceshortdeadlines
(smallğ‘‡)orlowthroughput(smallcğ‘– âˆ€ğ‘–)implythatevenofflinesolutionssufferalackofflexibilityinreducingtheoverallcost.
3Givenmetricspaceğ‘‹,considerÎ”(ğ‘‹),whichrepresentsthesetofprobabilitymeasuresoverthepointsofğ‘‹.Sinceğ‘‹ isfinite,
wehavethat|ğ‘‹|=ğ‘›andÎ”(ğ‘‹)isdenotedasÎ” ğ‘›.
4distancebetweentheOFFstateandanyotherstateintheweightedstar,inheritingthesameassumptionthat
ğ›½ âˆˆ [0,ğ‘ˆâˆ’ğ¿/2). Forbrevity,wehenceforthuseMALtorefertotheproblemonweightedstarmetricswith
theassumptionsdescribedabove.
Competitive analysis. Our goal is to design an algorithm that guarantees a small competitive ra-
tio [MMS88; BLS92], i.e., performs nearly as well as the offline optimal solution. Formally, let I âˆˆ Î©
denote a valid input sequence, where Î© is the set of all feasible inputs for the problem. Let OPT(I)
denote the cost of an optimal offline solution for instance I, and let ALG(I) denote the cost incurred
by running an online algorithm ALG over the same instance. The competitive ratio is then defined as
CR(ALG) (cid:66) max IâˆˆÎ©ALG(I)/OPT(I) =ğœ‚,andALGissaidtobeğœ‚-competitive. NotethatCR(ALG) isalways
â‰¥ 1,andalower competitiveratioimpliesthattheonlinealgorithmisguaranteedtobecloser totheoffline
optimalsolution.
Learning-augmentedconsistencyandrobustness. Intheemergingliteratureonlearning-augmented
algorithms, competitive analysis is interpreted via the notions of consistency and robustness, introduced
by[LV18;PSK18].
Definition 2.1. Let LALG denote a learning-augmented online algorithm provided with advice denoted by
ADV. Then LALG is said to beğ‘-consistent if it isğ‘-competitive with respect to ADV. Conversely, LALG isğ‘Ÿ-
robust if it isğ‘Ÿ-competitive with respect to OPT when given any ADV (i.e., regardless of the performance of
ADV).
AconnectionbetweenCFLandMAL. BelowwestatetwousefulresultsconnectingtheCFLandMAL
settingsthatinfluenceouralgorithmdesignforeachproblem.
Lemma2.2. ForanyMALinstanceonaweightedstarmetric (ğ‘‹,ğ‘‘),thereisacorrespondingCFLinstance
on (Rğ‘›âˆ’1,âˆ¥Â·âˆ¥ â„“ 1(wâ€²)) whichpreserves ğ‘“ ğ‘¡ğ‘(Â·) âˆ€ğ‘¡,ğ‘(Â·) âˆ€ğ‘ âˆˆğ‘‹,andupperboundsğ‘‘(ğ‘,ğ‘), âˆ€(ğ‘,ğ‘) âˆˆğ‘‹.
LeveragingLemma2.2,thefollowingresultexplicitlyconnectsthecompetitiveresultsoftheCFLand
MALsettings.
Proposition 2.3. Given an algorithm ALG for CFL, any competitive bound for ALG gives an identical com-
petitiveboundforMALwithparameterscorrespondingtotheCFLinstanceconstructedinLemma2.2.
The proofs of both are deferred to Appendix B.3. At a high-level, Proposition 2.3 shows that if ALG
isğœ‚-competitiveagainstOPTwhichpaysnoswitchingcost,Lemma2.2impliesitisalsoğœ‚-competitiveon
MAL. Inthenextsection,ourproposedalgorithmswillbepresentedusingCFLnotation,buttheseresults
providethenecessaryconditionwhichallowsthemtosolveMALaswell.
3 Designing Competitive Algorithms
Inthissection,wepresentourrobustalgorithmdesign. Westartbydiscussingsomeinherentchallenges
in the problem, highlighting reasons why existing algorithms (e.g., for CFC) fail. Next, we introduce a
generalizationofexistingtechniquesfromonlinesearchcalledpseudo-costminimization,whichunderpins
our competitive algorithm, ALG1 (Algorithm 1). Finally, we state (and prove in Appendix B) two bounds,
whichjointlyimplythatALG1achievestheoptimalcompetitiveratioforCFLandMAL.
5Algorithm1Pseudo-costminimizationalgorithm(ALG1)
input: long-termconstraintfunctionğ‘(Â·),distancemetricâˆ¥Â·âˆ¥ â„“ 1(w),pseudo-costthresholdfunctionğœ™(ğ‘§)
initialize:ğ‘§(0) = 0;
whilecostfunction ğ‘“ ğ‘¡(Â·) isrevealedandğ‘§(ğ‘¡âˆ’1) < 1do
solvepseudo-costminimizationproblem:
âˆ« ğ‘§(ğ‘¡âˆ’1)+ğ‘(x)
xğ‘¡ = argmin ğ‘“ ğ‘¡(x)+âˆ¥xâˆ’xğ‘¡âˆ’1âˆ¥ â„“ 1(w) âˆ’ ğœ™(ğ‘¢)ğ‘‘ğ‘¢ (2)
xâˆˆğ‘‹:ğ‘(x)â‰¤1âˆ’ğ‘§(ğ‘¡âˆ’1) ğ‘§(ğ‘¡âˆ’1)
updateutilizationğ‘§(ğ‘¡) =ğ‘§(ğ‘¡âˆ’1) +ğ‘(xğ‘¡)
Challenges. Canonical algorithms for CFC [CGW18; Sel20; ZJL+21] make decisions that attempt to
minimize (or nearly minimize) the hitting cost of cost functions ğ‘“ (Â·) and switching cost across all time
ğ‘¡
steps.Asdiscussedintheintroduction,thestructureoftheproblemwithalong-termconstraintmeansthat
suchmyopiccost-minimizationalgorithmswillfailingeneral. Toillustratethis,considertheactionsofa
minimizer-drivenalgorithmonanarbitrarysequencewithlengthğ‘‡.Foreachğ‘¡ <ğ‘‡,thealgorithmchooses
apointatornear0,since0istheminimizerofeach ğ‘“ ğ‘¡. However,sinceğ‘(0) = 0,suchanalgorithmmust
subsequentlysatisfyalloralmostallofthelong-termconstraintduringthecompulsorytrade,incurringan
arbitrarilybadhittingcost.
This challenge motivates an algorithm design that balances between the two extremes of finishing
the long-term constraint â€œimmediatelyâ€ (i.e., at the first or early time steps), and finishing the long-term
constraintâ€œwhenforcedtoâ€(i.e.,duringthecompulsorytrade). Bothextremesresultinapoorcompetitive
ratio. Many algorithms in the online search literature (e.g., online knapsack, OWT) leverage a threshold-
baseddesigntoaddresspreciselythisproblem,asin[ZCL08;SZL+21;LCS+24]. However,suchthreshold-
basedalgorithmsaretraditionallyderivedforsingle-dimensionaldecisionspaceswithnoswitchingcosts.
Inwhatfollows,wedescribeapseudo-costminimizationapproach,whichgeneralizesthethreshold-based
designtooperateinthesettingofCFL.
Algorithmdescription. Recallthatğ‘§(ğ‘¡) givesthefractionofthelong-termconstraintsatisfiedattime
ğ‘¡. Building off of the intuition of threshold-based design, we define a functionğœ™, which will be used to
computeapseudo-costminimizationproblemcentraltoourrobustalgorithm.
Definition3.1(Pseudo-costthresholdfunctionğœ™ forCFL). Foranyutilizationğ‘§ âˆˆ [0,1],ğœ™ isdefinedas:
ğœ™(ğ‘§) =ğ‘ˆ âˆ’ğ›½ +(ğ‘ˆ/ğ›¼ âˆ’ğ‘ˆ +2ğ›½)exp(ğ‘§/ğ›¼), (3)
whereğ›¼ isthecompetitiveratioandisdefinedin(4).
Then our algorithm (Algorithm 1, referred to as ALG1) solves the pseudo-cost minimization problem
definedin(2)toobtainadecisionxğ‘¡ ateachtimestep. Atahighlevel, theinclusionofğœ™ inthispseudo-
cost problem enforces that, upon arrival of a cost function, the algorithm satisfies â€œjust enoughâ€ of the
long-termconstraint. Concretely,thestructureoftheğœ™ functionenforcesthatğœ™(ğ‘§(ğ‘¡))âˆ’ğ›½ correspondsto
the â€œbest cost function seen so farâ€. Then, if a good cost function arrives, the pseudo-cost minimization
problemsolvesforthexğ‘¡ whichguaranteesacompetitiveratioofğ›¼ againstthecurrentestimateofOPT.
Ataglance,itisnotobviousthattheminimizationproblemin(2)istractable;however,inAppendixB.1,
weshowthattheproblemisconvex,implyingthatitcanbesolvedefficiently. InTheorem3.2,westatethe
competitiveresultforALG1. Wediscussthesignificanceoftheresultbelow,andrelegatethefullproofto
AppendixB.2.
6Theorem3.2. ALG1isğ›¼-competitiveforCFL,whereğ›¼ isthesolutionto ğ‘ˆâˆ’ğ¿âˆ’2ğ›½ = exp(1/ğ›¼),givenby
ğ‘ˆâˆ’ğ‘ˆ/ğ›¼âˆ’2ğ›½
(cid:20) (cid:18)(cid:18)2ğ›½ ğ¿ (cid:19) (cid:19) 2ğ›½ (cid:21)âˆ’1
ğ›¼ (cid:66) ğ‘Š + âˆ’1 ğ‘’2 ğ‘ˆğ›½ âˆ’1 âˆ’ +1 , (4)
ğ‘ˆ ğ‘ˆ ğ‘ˆ
whereğ‘Š istheLambertğ‘Š function[CGH+96].
Intuitively,parametersofCFL(ğ¿,ğ‘ˆ,and ğ›½)appearinthecompetitivebound. WhileresultsforOWT
and CFC are not directly comparable, we discuss connections and the relative order of ğ›¼. When ğ›½ â†’
0, ğ›¼ matches the optimal competitive ratio of (cid:2)ğ‘Š (cid:0) (ğ¿/ğ‘ˆ âˆ’1)ğ‘’âˆ’1(cid:1) +1(cid:3)âˆ’1 for the minimization variant of
OWT[LPS08;SLH+21]. Intheintermediatecase(i.e.,whenğ›½ âˆˆ (0,ğ‘ˆâˆ’ğ¿/2)),CFLaddsanewlinear depen-
denceonğ›½ comparedtoOWT. Furthermore,whenğ›½ â†’ğ‘ˆâˆ’ğ¿/2,ğ›¼ approachesğ‘ˆ/ğ¿,whichisthecompetitive
ratioachievablebye.g.,amyopiccostminimizationalgorithm. Sinceğ›¼ doesnotfeatureadependenceon
the dimensionğ‘‘ of the vector space, we note a connection with CFC: it is known that â€œdimension-freeâ€
boundsareachievableinCFCwithstructuralassumptionsonthehittingcost[CGW18;AGG20]thatare
evocativeofourboundedgradientassumptionsinCFL.
ViaProposition2.3,weobtainanimmediatecorollarytoTheorem3.2whichgivesthefollowingcom-
petitive bound when ALG1 is used to solve MAL. The full proof of Corollary 3.3 can be found in Ap-
pendixB.3.
Corollary3.3. ALG1isğ›¼-competitiveforMAL.
Onthetightnessofcompetitiveratios. ItisimportanttohighlightthattheboundsinTheorem3.2
and Corollary 3.3 are the first competitive bounds for any variant of convex function chasing or online
metricallocationimbuedwithlong-termconstraints. Anaturalfollow-upquestionconcernswhetherany
online algorithm for CFL (or MAL) can achieve a better competitive bound. In the following, we answer
this question in the negative, showing that ALG1â€™s competitive ratio is the best that any deterministic
online algorithm for CFL and/or MAL can achieve. We state the result here, and defer the full proof to
AppendixB.4.
Theorem3.4. ThereexistsafamilyofCFLinstancessuchthatanydeterministiconlinealgorithmforCFL
isatleastğ›¼-competitive,whereğ›¼ isasdefinedin(4).
Since ALG1 isğ›¼-competitive by Theorem 3.2, this implies that ALG1 achieves the optimal competitive
ratio for CFL. Furthermore, by leveraging Lemma 2.2, this result gives an immediate corollary result in
theMALsettingbyconstructingacorrespondingfamilyofMALinstances,whichforcesanyalgorithmto
achieveacompetitiveratioofğ›¼. Westatetheresulthere,deferringthefullprooftoAppendixB.5.
Corollary3.5. TheCFLinstancesinTheorem3.4correspondtoinstancesofMALsuchthatanydeterministic
onlinealgorithmforMALisatleastğ›¼-competitive.
As previously, since ALG1 isğ›¼-competitive by Corollary 3.3, it achieves the optimal competitive ratio
for MAL. We note that beyond the settings of CFL and MAL considered in this paper, Theorem 3.4 and
Corollary 3.5 are the first lower bound results for convex function chasing and online metric allocation
with long-term constraints, and may thus give useful insight into the achievable competitive bounds for
differentormoregeneralsettingsoftheseproblems.
4 Learning-augmented Algorithms
In this section, we leverage techniques from the growing literature on learning-augmented algorithms to
considerhowuntrustedblack-boxadvice canhelpimprovetheaverage-caseperformanceofanalgorithm
7Algorithm2ConsistencyLimitedPseudo-costminimization(CLIP)
input:
consistencyparameterğœ–,long-termconstraintfunctionğ‘(Â·),pseudo-costthresholdğœ™ğœ–(Â·)
initialize:ğ‘§(0) = 0; ğ‘(0) = 0; ğ´(0) = 0; CLIP0 = 0; ADV0 = 0
whilecostfunction ğ‘“ ğ‘¡(Â·) isrevealed,untrustedadviceağ‘¡ isrevealed,andğ‘§(ğ‘¡âˆ’1) < 1do
updateadvicecostADVğ‘¡ = ADVğ‘¡âˆ’1+ğ‘“ ğ‘¡(ağ‘¡)+âˆ¥ağ‘¡âˆ’ağ‘¡âˆ’1âˆ¥ â„“ 1(w) andadviceutilizationğ´(ğ‘¡) =ğ´(ğ‘¡âˆ’1)+ğ‘(ağ‘¡)
solveconstrained pseudo-costminimizationproblem:
âˆ« ğ‘(ğ‘¡âˆ’1)+ğ‘(x)
xğ‘¡ = xâˆˆğ‘‹:ğ‘a (r xg )â‰¤m 1i âˆ’n ğ‘§(ğ‘¡âˆ’1)ğ‘“ğ‘¡(x)+âˆ¥xâˆ’xğ‘¡âˆ’1âˆ¥â„“1(w) âˆ’
ğ‘(ğ‘¡âˆ’1)
ğœ™ğœ–(ğ‘¢)ğ‘‘ğ‘¢ (5)
suchthat
CLIPğ‘¡âˆ’1+ğ‘“ğ‘¡(x)+âˆ¥xâˆ’xğ‘¡âˆ’1âˆ¥â„“1(w)+âˆ¥xâˆ’ağ‘¡âˆ¥â„“1(w)+âˆ¥ağ‘¡âˆ¥â„“1(w)+(1âˆ’ğ‘§(ğ‘¡âˆ’1) âˆ’ğ‘(x))ğ¿+max((ğ´(ğ‘¡) âˆ’ğ‘§(ğ‘¡âˆ’1) âˆ’ğ‘(x)), 0)(ğ‘ˆ âˆ’ğ¿) (6)
â‰¤ (1+ğœ–)[ADVğ‘¡+âˆ¥ağ‘¡âˆ¥â„“1(w)+(1âˆ’ğ´(ğ‘¡))ğ¿]
updatecostCLIPğ‘¡ = CLIPğ‘¡âˆ’1+ğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥ â„“ 1(w) andutilizationğ‘§(ğ‘¡) =ğ‘§(ğ‘¡âˆ’1) +ğ‘(xğ‘¡)
solveunconstrained pseudo-costminimizationproblem:
âˆ« ğ‘(ğ‘¡âˆ’1)+ğ‘(x)
xÂ¯ ğ‘¡ = xâˆˆğ‘‹:ğ‘a (r xg )â‰¤m 1i âˆ’n ğ‘§(ğ‘¡âˆ’1)ğ‘“ğ‘¡(x)+âˆ¥xâˆ’xğ‘¡âˆ’1âˆ¥â„“1(w) âˆ’
ğ‘(ğ‘¡âˆ’1)
ğœ™ğœ–(ğ‘¢)ğ‘‘ğ‘¢ (7)
updatepseudo-utilizationğ‘(ğ‘¡) =ğ‘(ğ‘¡âˆ’1) +min(ğ‘(xÂ¯ ğ‘¡),ğ‘(xğ‘¡))
for CFL and MAL while retaining worst-case guarantees. We first consider a sub-optimal â€œbaselineâ€ al-
gorithm that directly combines advice with a robust algorithm such as ALG1. We then propose a unified
algorithmcalledCLIP,whichintegratesadvicemoreefficientlyandachievestheoptimaltrade-offbetween
consistency androbustness(Definition2.1).
Advicemodel. ForaCFLorMALinstanceI âˆˆ Î©,letADVdenoteuntrustedblack-boxdecisionadvice,
i.e., ADV (cid:66) {ağ‘¡ âˆˆ ğ‘‹ : ğ‘¡ âˆˆ [ğ‘‡]}. If the advice is correct, it achieves the optimal objective value (i.e.,
ADV(I) = OPT(I)).
A simple baseline. Lechowicz et al. [LCS+24] show that a straightforward â€œfixed-ratioâ€ learning-
augmentedapproachworkswellinpracticeforunidimensionalonlinesearchwithswitchingcosts. Here
weshowthatasimilartechnique(playingaconvexcombinationofthesolutionschosenbytheadviceand
arobustalgorithm)achievesboundedbutsub-optimalconsistencyandrobustnessforCFL.
Let ROB (cid:66) {xËœ ğ‘¡ : ğ‘¡ âˆˆ [ğ‘‡]} denote the actions of a robust algorithm for CFL (e.g., ALG1). For any
valueğœ– âˆˆ (0,ğ›¼ âˆ’1], thefixed-ratioalgorithm(denotedasBaselineforbrevity)setsafixedcombination
factor ğœ† (cid:66) ğ›¼ ğ›¼âˆ’ âˆ’1âˆ’ 1ğœ–. Then at each time step, Baseline chooses a combination decision according to xğ‘¡ =
ğœ†ağ‘¡+(1âˆ’ğœ†)xËœ ğ‘¡. WepresentconsistencyandrobustnessresultsforBaselinebelow,deferringthefullproof
toAppendixC.1.
Lemma 4.1. Letting ROB denote the actions of ALG1 and setting a parameter ğœ– âˆˆ (0,ğ›¼ âˆ’ 1], Baseline is
(cid:16) (cid:17)
(1+ğœ–)-consistentand (ğ‘ˆ+2ğ›½)/ğ¿(ğ›¼âˆ’1âˆ’ğœ–)+ğ›¼ğœ– -robustforCFL.
(ğ›¼âˆ’1)
Although this fixed-ratio algorithm verifies that an algorithm for CFL can utilize untrusted advice
to improve performance, it remains an open question of whether the trade-off between consistency and
robustness given in Lemma 4.1 is optimal. Thus, we study whether a learning-augmented algorithm for
CFLcanbedesignedwhichdoesachievetheprovablyoptimalconsistency-robustnesstrade-off.Inthenext
section, we start by considering a more sophisticated method of incorporating advice into an algorithm
design.
8An optimal learning-augmented algorithm. We present CLIP (Consistency-Limited Pseudo-cost
minimization,Algorithm2)whichachievestheoptimaltrade-offbetweenconsistencyandrobustnessfor
CFL. Tostart,foranyğœ– âˆˆ (0,ğ›¼âˆ’1],wedefineacorrespondingtargetrobustnessfactorğ›¾ğœ–,whichisdefined
astheuniquepositivesolutiontothefollowing:
ğ‘ˆ ğ›¾ğœ– (cid:18) ğ‘ˆ âˆ’ğ¿âˆ’2ğ›½ (cid:19)
ğ›¾ğœ– =ğœ– + âˆ’ (ğ‘ˆ âˆ’ğ¿)ln . (8)
ğ¿ ğ¿ ğ‘ˆ âˆ’ğ‘ˆ/ğ›¾ğœ– âˆ’2ğ›½
Notethatğ›¾ğ›¼âˆ’1 = ğ›¼, andğ›¾0 = ğ‘ˆ/ğ¿. Weuseğ›¾ğœ– todefineapseudo-costthresholdfunctionğœ™ğœ– whichwillbe
usedinaminimizationproblemtochooseadecisionateachstepoftheCLIPalgorithm.
Definition4.2(Pseudo-costthresholdfunctionğœ™ğœ–). Givenğ›¾ğœ– from(8),ğœ™ğœ–(ğ‘) forğ‘ âˆˆ [0,1] isdefinedas:
ğœ™ğœ– (ğ‘) =ğ‘ˆ âˆ’ğ›½ +(ğ‘ˆ/ğ›¾ğœ– âˆ’ğ‘ˆ +2ğ›½)exp(ğ‘/ğ›¾ğœ–). (9)
For each time step ğ‘¡ âˆˆ [ğ‘‡], we define a pseudo-utilization ğ‘(ğ‘¡) âˆˆ [0,1], where ğ‘(ğ‘¡) â‰¤ ğ‘§(ğ‘¡) âˆ€ğ‘¡, and
ğ‘(ğ‘¡) describes the fraction of the long-term constraint which been satisfied â€œrobustlyâ€ (as defined by the
pseudo-cost)attimeğ‘¡.
ThenCLIP(seeAlgorithm2)solvesaconstrained pseudo-costminimizationproblem(definedin(5))to
obtainadecisionxğ‘¡ ateachtimestep. TheobjectiveofthisproblemismostlyinheritedfromALG1,butthe
inclusionofaconsistencyconstraint allowstheframeworktoaccommodateuntrustedadviceforbounded
consistencyandrobustness.
The high-level intuition behind this consistency constraint (defined in (6)) is to directly compare the
solutions of CLIP and ADV so far, while â€œhedgingâ€ against worst-case scenarios which may cause CLIP
to violate the desired (1+ğœ–)-consistency. We introduce some notation to simplify the expression of the
constraint. WeletCLIPğ‘¡ denotethecostofCLIPuptotimeğ‘¡,i.e.,CLIPğ‘¡ (cid:66) (cid:205) ğœğ‘¡ =1ğ‘“ ğœ(xğœ)+âˆ¥xğœ âˆ’xğœâˆ’1âˆ¥
â„“
1(w).
Similarly, weletADVğ‘¡ (cid:66) (cid:205) ğœğ‘¡ =1ğ‘“ ğœ(ağœ) + âˆ¥ağœ âˆ’ağœâˆ’1âˆ¥
â„“ 1(w)
denotethecostofADVuptotimeğ‘¡. Additionally,
weletğ´(ğ‘¡) denotetheutilizationofADVattimeğ‘¡,i.e.,ğ´(ğ‘¡) (cid:66) (cid:205) ğœğ‘¡ =1ğ‘(ağœ)
The constraint defined in (6) considers the cost of both CLIP and ADV so far, and the current hitting
and switching cost ğ‘“ ğ‘¡(x) + âˆ¥x âˆ’ xğ‘¡âˆ’1âˆ¥
â„“
1(w), ensuring that (1 + ğœ–)-consistency is preserved. Both sides
of the constraint also include terms which consider the cost of potential future situations. First, âˆ¥x âˆ’
ağ‘¡âˆ¥
â„“ 1(w)
+ âˆ¥ağ‘¡âˆ¥
â„“ 1(w)
ensuresthatifCLIPpaysaswitchingcosttofollowADVand/orpaysaswitchingcost
toâ€œswitchoffâ€(moveto0)ine.g.,thenexttimestep,thatcosthasbeenpaidforâ€œinadvanceâ€. Asxğ‘‡+1 = 0,
the constraint also charges ADV in advance for the mandatory switching cost at the end of the sequence
(cid:0)
âˆ¥ağ‘¡âˆ¥
â„“
1(w)(cid:1);thisensuresthatthereisalwaysafeasiblesettingofxğ‘¡.
In the term (cid:0)1âˆ’ğ´(ğ‘¡)(cid:1)ğ¿, the consistency constraint assumes that ADV can satisfy the rest of the long-
termconstraint atthebest marginalcostğ¿. Respectively, inthe term (1âˆ’ğ‘§(ğ‘¡âˆ’1) âˆ’ğ‘(x))ğ¿ +max((ğ´(ğ‘¡) âˆ’
ğ‘§(ğ‘¡âˆ’1) âˆ’ğ‘(x)), 0)(ğ‘ˆ âˆ’ğ¿),theconstraintassumesCLIPcansatisfyupto (cid:0)1âˆ’ğ´(ğ‘¡)(cid:1) oftheremaininglong-
term constraint at the best cost ğ¿, but any excess (i.e., (ğ´(ğ‘¡) âˆ’ğ‘§(ğ‘¡))) must be satisfied at the worst cost
ğ‘ˆ (e.g.,duringthecompulsorytrade). Thisworst-caseassumptionensuresthatwhenactualhittingcosts
replacetheaboveterms,thedesired (1+ğœ–)-consistencyholds.
Ateachstep,CLIPalsosolvesanunconstrained pseudo-costminimizationproblemtoobtainxÂ¯ ğ‘¡,which
updatesthepseudo-utilizationğ‘(ğ‘¡). ThisensuresthatwhenADVhasacceptedacostfunctionwhichwould
notbeacceptedbytheunconstrainedpseudo-costminimization,thethresholdfunctionğœ™ğœ– canâ€œstartfrom
zeroâ€insubsequenttimesteps.
At a high level, CLIPâ€™s consistency constraint combined with the pseudo-cost minimization gener-
ates decisions which are as robust as possible while preserving consistency. In Theorem 4.3, we state the
consistencyandrobustnessofCLIP;werelegatethefullprooftoAppendixC.2.
9Theorem4.3. Foranyğœ– âˆˆ [0,ğ›¼ âˆ’1],CLIPis (1+ğœ–)-consistentandğ›¾ğœ– -robustforCFL(ğ›¾ğœ– asdefinedin(8)).
The previous result gives an immediate corollary when CLIP is used to solve MAL, which we state
below. ThefullproofofCorollary4.4canbefoundinAppendixC.3.
Corollary4.4. Foranyğœ– âˆˆ [0,ğ›¼ âˆ’1],CLIPis (1+ğœ–)-consistentandğ›¾ğœ– -robustforMAL.
Optimal trade-offs between robustness and consistency. Although the trade-off given by CLIP
implies that achieving 1-consistency requires a large robustness bound of ğ‘ˆ/ğ¿ in the worst-case, in the
followingtheoremweshowthatthisisthebestwecanobtainfromanyconsistentandrobustalgorithm.
Westatetheresultanddiscussitssignificancehere,deferringthefullprooftoAppendixC.4.
Theorem 4.5. Given untrusted advice ADV andğœ– âˆˆ (0,ğ›¼ âˆ’1], any (1+ğœ–)-consistent learning-augmented
algorithmforCFLisatleastğ›¾ğœ– -robust,whereğ›¾ğœ– isdefinedin(8).
This result implies that CLIP achieves the optimal trade-off between consistency and robustness for
CFL. Furthermore, via Lemma 2.2, this result immediately gives Corollary 4.6, which we state here and
proveinAppendixC.5.
Corollary4.6.
Any(1+ğœ–)-consistentlearning-augmentedalgorithmforMALisatleastğ›¾ğœ– -robust(ğ›¾ğœ–
defined
by (8)).
As previously, this implies CLIP achieves the optimal consistency-robustness trade-off for MAL. Be-
yondthesettingsofCFLandMAL,thesePareto-optimalityresultsmaygiveusefulinsightintotheachiev-
ableconsistency-robustnesstrade-offsformoregeneralsettings.
5 Numerical Experiments
In this section, we conduct numerical experiments on synthetic CFL instances. We evaluate ALG1 and
CLIP against the offline optimal solution, three heuristics adapted from related work, and the learning-
augmentedBaseline.
Setup. Herewegiveanoverviewofourexperimentsetupandcomparisonalgorithms. Weconstructa
ğ‘‘-dimensional decision space, whereğ‘‘ is picked from the set {5,7,...,21}. The competitive ratio of our
proposed algorithms depends on both ğ‘ˆ/ğ¿ and ğ›½ = max ğ‘–wi, as the switching cost. Hence, we evalu-
ate their performance over the range of these parameters. We set different cost fluctuation ratiosğ‘ˆ/ğ¿ âˆˆ
{50,150,...,1250} by setting ğ¿ andğ‘ˆ accordingly, and ğ›½ is picked from the set ğ›½ âˆˆ {0,5,...,ğ‘ˆ/2.5}. We
also set a parameterğœ âˆˆ {0,10,...,ğ‘ˆ/2}, which controls the dimension-wise variability of generated cost
functions ğ‘“ ğ‘¡. Acrossallexperiments,ğ‘(x) = âˆ¥xâˆ¥1.
For a given setting ofğ‘‘,ğ‘ˆ/ğ¿, and ğ›½, we generate 1,000 random instances as follows. First, each term
of the weight vector w for the weighted â„“ 1 norm is drawn randomly from the uniform distribution on
[0,ğ›½]. Next, the time horizonğ‘‡ is generated randomly from a uniform distribution on [6,24]. For each
time ğ‘¡ âˆˆ [ğ‘‡], a cost function is generated as follows: Let ğ‘“ ğ‘¡(x) = f ğ‘¡âŠº x, where fğ‘¡ is ağ‘‘-dimensional cost
vector. Togeneratefğ‘¡,wefirstdraw ğœ‡
ğ‘¡
fromtheuniformdistributionon [ğ¿,ğ‘ˆ],andthendraweachterm
of fğ‘¡ from a normal distribution centered at ğœ‡ ğ‘¡ with standard deviationğœ (i.e., f ğ‘¡ğ‘– âˆ¼ N(ğœ‡ ğ‘¡,ğœ)). Any terms
whichareoutsidetheassumedinterval [ğ¿,ğ‘ˆ] (i.e. fğ‘– < ğ¿ orfğ‘– >ğ‘ˆ)aretruncatedappropriately. Foreach
ğ‘¡ ğ‘¡
instance, we report the empirical competitive ratios as the evaluation metric, comparing the tested algo-
rithmsagainstanofflineoptimalbenchmark. Wegiveresultsfortheaverageempiricalcompetitiveratio
in the main body, with supplemental results for the 95th percentile (â€œworst-caseâ€) empirical competitive
ratioinAppendixA.1.
10Inthesettingwithadvice,weconstructsimulatedadviceasfollows:Letğœ‰ âˆˆ [0,1]denoteanadversarial
factor. When ğœ‰ = 0, ADV gives the optimal solution, and when ğœ‰ = 1, ADV is fully adversarial. Formally,
letting{xâ˜…
ğ‘¡
:ğ‘¡ âˆˆ [ğ‘‡]}denotethedecisionsmadebyanoptimalsolution,andletting{xË˜
ğ‘¡
:ğ‘¡ âˆˆ [ğ‘‡]}represent
thedecisionsmadebyasolutionwhichmaximizestheobjective(ratherthanminimizingit),wehavethat
ADV = {(1âˆ’ğœ‰)xâ˜… ğ‘¡ +ğœ‰xË˜ ğ‘¡ :ğ‘¡ âˆˆ [ğ‘‡]}. Wenotethatalthough{xË˜ ğ‘¡ :ğ‘¡ âˆˆ [ğ‘‡]}isadversarialfromtheperspective
oftheobjective,itisstillafeasiblesolutionfortheproblem(i.e.,itsatisfiesthelong-termconstraint).
Comparison algorithms. We use CVXPY [DB16] to compute the offline optimal solution for each
instanceusingaconvexoptimizationsolverwithaccesstoallcostfunctionsinadvance. Thisprovidesthe
empirical competitive ratio for each algorithm. We consider three online heuristic techniques based on
theliteratureforrelatedproblems. Thefirsttechniqueistermedâ€œagnosticâ€,whichchoosestheminimum
dimension of the cost function in the first time stepğ‘¡ = 1 (i.e.,ğ‘˜ = argmin ğ‘–âˆˆ[ğ‘‘]cğ‘– 1), sets xğ‘˜
1
= 1, and xğ‘¡ =
0âˆ€ğ‘¡ > 1. Thesecondtechniqueistermedâ€œmovetominimizerâ€,whichtakesinspirationfromalgorithms
for CFC [ZJL+21] and satisfies 1/ğ‘‡ fraction of the long-term constraint at each time step by moving to
the minimum dimension of each cost function. Formally, at each time stepğ‘¡, lettingğ‘˜ ğ‘¡ = argmin ğ‘–âˆˆ[ğ‘‘]cğ‘– ğ‘¡,
â€œmovetominimizerâ€setsxğ‘˜ ğ‘¡ = 1/ğ‘‡.Finally,thethirdtechniqueistermedâ€œsimplethresholdâ€,whichtakes
ğ‘¡ âˆš
inspiration from algorithms for online search [EFK+01]. This algorithm sets a fixed thresholdğœ“ = ğ‘ˆğ¿,
and completes the long-term constraint at the first time step and dimension where the hitting cost does
not exceedğœ“. Formally, at the first time step ğœ satisfying âˆƒ ğ‘˜ âˆˆ [ğ‘‘] : fğ‘˜ â‰¤ ğœ“, â€œsimple thresholdâ€ sets
ğœ
xğ‘˜ = 1. Importantly,noneoftheseheuristicsareaccompaniedbytraditionalcompetitiveguarantees,since
ğœ
ourworkisthefirsttoconsiderCFL. Inthesettingwithadvice,wecompareourproposedCLIPlearning-
augmented algorithm against the Baseline learning-augmented algorithm described in Section 4 (e.g.,
Lemma4.1).
Experimental results. Figure 1 summa-
rizes the main results for ALG1, the compari- 1.0 20 baseline[ =10]
sonalgorithms,andonesettingofCLIP(ğœ– = 2) 0.8 15 b ba as se el li in ne e[ [ = =5 2] ]
CLIP[ =10] in a CDF plot of the empirical competitive ra- 0.6 CLIP[ =5]
ALG1 10 ADV
tios across several experiments. Here we fix 0.4 agnostic
ğ‘ˆ/ğ¿ = 250, ğœ‰ = 0, ğœ = 50, while varying 0.2 s mim ovp ele t oth mre is nh imol id zer 5
ğ›½ and ğ‘‘. ALG1 outperforms in both average- 0.0 CLIP[ =2] 0
0 10 20 30 40 0.0 0.1 0.2 0.3 0.4 0.5
case and worst-case performance, improving empirical competitive ratio
on the closest â€œsimple thresholdâ€ by an aver- Figure1: CDFsofempirical Figure2: Varyingadversar-
ageof18.2%,andoutperformingâ€œagnosticâ€and competitive ratios for vari- ialfactorğœ‰,withğ‘ˆ/ğ¿=250,ğ›½
â€œmove to minimizerâ€ by averages of 56.1% and ousalgorithms. =50,ğ‘‘ =5,andğœ =50.
71.5%, respectively. With correct advice, CLIP
seessignificantperformancegainseverywhere.
In Figure 3-6, we investigate the impact of parameters on the average empirical competitive ratio
for each algorithm. In Appendix A.1, we give corresponding plots for the 95th percentile (â€œworst-caseâ€)
results. Figure 3 plots competitive ratios for different values ofğ‘ˆ/ğ¿. We fix ğ›½ = ğ‘ˆ/5,ğ‘‘ = 5,ğœ‰ = 0,ğœ = ğ‘ˆ/5,
whilevaryingğ‘ˆ/ğ¿. Sincethereisadependenceonğ‘ˆ/ğ¿inourcompetitiveresults,theperformanceofALG1
degrades asğ‘ˆ/ğ¿ grows, albeit at a favorable pace compared to the heuristics. Figure 4 plots competitive
ratiosfordifferentvaluesofğ›½. Wefixğ‘ˆ/ğ¿ = 250,ğ‘‘ = 5,ğœ‰ = 0,ğœ = 50. Asğ›½ grows,theâ€œagnosticâ€andâ€œmove
tominimizerâ€heuristicsimprovebecausetheswitchingcostpaidbyOPTgrows.
InFigure5,weplotcompetitiveratiosfordifferentvaluesofğ‘‘. Wefixğ‘ˆ/ğ¿ = 250,ğ›½ = 50,ğœ‰ = 0,ğœ = 50,
whilevaryingğ‘‘. Asğ‘‘ grows,ALG1andCLIPâ€™sperformancedegradesslowercomparedtotheheuristics,as
predictedbytheirdimension-freetheoreticalbounds. Finally,Figure6plotscompetitiveratiosfordifferent
11
ytisned
evitalumuc
laciripme
.gva
oitar
evititepmoc20 20 20 20
15 15 15 15
10 10 10 10
5 5 5 5
0 0 0 0
200 400 600 800 1000 0 20 40 60 80 100 5 10 15 20 0 20 40 60 80 100 120
Figure 3: VaU r/L ying ğ‘ˆ/ğ¿, Figure4: Varyingğ›½,with Figure 5: Varydingğ‘‘ with Figure6: Varyingğœ,with
withğ›½ =ğ‘ˆ/5,ğ‘‘ = 5,ğœ‰ = 0, ğ‘ˆ/ğ¿ = 250,ğ‘‘ = 5,ğœ‰ = 0, ğ›½ = 50,ğ‘ˆ/ğ¿ = 250,ğœ = 50, ğ›½ = 50,ğ‘ˆ/ğ¿ = 250,ğ‘‘ = 5,
andğœ =ğ‘ˆ/5. andğœ = 50. andğœ‰=0. andğœ‰ =0.
values of ğœ. We fix ğ‘ˆ/ğ¿ = 250,ğ›½ = 50,ğ‘‘ = 5,ğœ‰ = 0, while varying ğœ. As cost functions become more
variable, the performance of all algorithms degrades, with the exception of CLIP. There is a plateau asğœ
grows,becausealargeğœ impliesthatmoretermsineachfğ‘¡ mustbetruncatedtotheinterval [ğ¿,ğ‘ˆ].
Figure2plotstheeffectofpredictionerroronthelearning-augmentedalgorithmsCLIPandBaseline.
Wetestseveralvaluesofğœ‰ âˆˆ [0,1/2] (recallthatğœ‰ = 0recoverscorrectadvice),whilefixingğ‘ˆ/ğ¿ = 250,ğ›½ =
50,ğ‘‘ = 5, andğœ = 50. We also test Baseline and CLIP for several values ofğœ– âˆˆ {2,5,10} (note that ADV
correspondstoBaselineandCLIPwithğœ– = 0). Notably,wefindthatCLIPsignificantlyoutperformsthe
Baseline algorithm as ğœ‰ grows, showing an average improvement of 60.8% when ğœ‰ > 0.1. This result
impliesthatCLIPismoreempiricallyrobusttopredictionerrorsthanthesimplefixedratiotechniqueof
Baseline.
6 Conclusion
Westudyonlinemetricproblemswithlong-termconstraints,motivatedbyemergingproblemsinsustain-
ability. These are the first such problems to concurrently incorporate multidimensional decision spaces,
switchingcosts,andlong-termdemandconstraints. OurmainresultsinstantiatetheCFLandMALprob-
lemstowardsamotivatingapplication. Wedesigncompetitiveandlearning-augmentedalgorithms,show
thattheirperformanceboundsaretight,andvalidatetheminnumericalexperiments. Severalinteresting
openquestionsarepromptedbyourwork. Specifically,(i)whatisachievableinnon-â„“ vectorspacese.g.,
1
theEuclideansetting,and(ii)canourresultsforMALinformalgorithmdesignsfore.g.,treemetrics,and
byextension,arbitrarymetricspaces?
References
[AGG20] C. J. Argue, Anupam Gupta, and Guru Guruganesh. â€œDimension-Free Bounds for Chasing
ConvexFunctionsâ€.In:ProceedingsofThirtyThirdConferenceonLearningTheory.PMLR,July
2020,pp.219â€“241.(Visitedon02/04/2022).
[ALK+23] Bilge Acun, Benjamin Lee, Fiodar Kazhamiaka, Kiwan Maeng, Udit Gupta, Manoj Chakkar-
avarthy,DavidBrooks,andCarole-JeanWu.â€œCarbonExplorer:AHolisticFrameworkforDe-
signingCarbonAwareDatacentersâ€.In:Proceedingsofthe28thACMInternationalConference
on Architectural Support for Programming Languages and Operating Systems, Volume 2. ASP-
LOS2023.Vancouver,BC,Canada:AssociationforComputingMachinery,2023,pp.118â€“132.
isbn: 9781450399166. doi: 10.1145/3575693.3575754. url: https://doi.org/10.1145/
3575693.3575754.
12
laciripme
.gva
oitar
evititepmoc
laciripme
.gva
oitar
evititepmoc
laciripme
.gva
oitar
evititepmoc
laciripme
.gva
oitar
evititepmoc[BC22] Nikhil Bansal and Christian Coester. â€œOnline Metric Allocation and Time-Varying Regular-
izationâ€.In:30thAnnualEuropeanSymposiumonAlgorithms(ESA2022).Ed.byShiriChechik,
GonzaloNavarro,EvaRotenberg,andGrzegorzHerman.Vol.244.LeibnizInternationalPro-
ceedingsinInformatics(LIPIcs).Dagstuhl,Germany:SchlossDagstuhlâ€“Leibniz-ZentrumfÃ¼r
Informatik, 2022, 13:1â€“13:13. isbn: 978-3-95977-247-1. doi: 10.4230/LIPIcs.ESA.2022.13.
url:https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ESA.2022.13.
[BCL+21] SÃ©bastien Bubeck, Michael B. Cohen, James R. Lee, and Yin Tat Lee. â€œMetrical Task Systems
on Trees via Mirror Descent and Unfair Gluingâ€. In: SIAM Journal on Computing 50.3 (Jan.
2021),pp.909â€“923.issn:0097-5397,1095-7111.doi:10.1137/19M1237879.
[BCR23] SÃ©bastien Bubeck, Christian Coester, and Yuval Rabani. â€œThe Randomized $k$-Server Con-
jecture Is False!â€ In: Proceedings of the 55th Annual ACM Symposium on Theory of Comput-
ing(STOC2023).STOC2023.Orlando,FL,USA:AssociationforComputingMachinery,2023,
pp.581â€“594.isbn:9781450399135.doi:10.1145/3564246.3585132.url:https://doi.org/
10.1145/3564246.3585132.
[BGH+21] Noman Bashir, Tian Guo, Mohammad Hajiesmaili, David Irwin, Prashant Shenoy, Ramesh
Sitaraman,AbelSouza,andAdamWierman.â€œEnablingSustainableClouds:TheCaseforVir-
tualizing the Energy Systemâ€. In: Proceedings of the ACM Symposium on Cloud Computing.
SoCCâ€™21.Seattle,WA,USA:AssociationforComputingMachinery,2021,pp.350â€“358.isbn:
9781450386388. doi: 10.1145/3472883.3487009. url: https://doi.org/10.1145/
3472883.3487009.
[BKL+19] SÃ©bastien Bubeck, Boâ€™az Klartag, Yin Tat Lee, Yuanzhi Li, and Mark Sellke. â€œChasing Nested
ConvexBodiesNearlyOptimallyâ€.In:Proceedingsofthe2020ACM-SIAMSymposiumonDis-
crete Algorithms (SODA). Proceedings. Society for Industrial and Applied Mathematics, Dec.
2019,pp.1496â€“1508.doi:10.1137/1.9781611975994.91.
[BLS92] AllanBorodin,NathanLinial,andMichaelE.Saks.â€œAnOptimalOn-LineAlgorithmforMet-
rical Task Systemâ€. In: J. ACM 39.4 (Oct. 1992), pp. 745â€“763. issn: 0004-5411. doi: 10.1145/
146585.146588.url:https://doi.org/10.1145/146585.146588.
[CBS+22] Kai-WenCheng,YuexinBian,YuanyuanShi,andYizeChen.â€œCarbon-AwareEVChargingâ€.In:
2022 IEEE International Conference on Communications, Control, and Computing Technologies
for Smart Grids (SmartGridComm). 2022, pp. 186â€“192. doi: 10.1109/SmartGridComm52983.
2022.9960988.
[CGH+96] RobertMCorless,GastonHGonnet,DavidEGHare,DavidJJeffrey,andDonaldEKnuth.â€œOn
theLambertWfunctionâ€.In:AdvancesinComputationalmathematics5(1996),pp.329â€“359.
[CGW18] NiangJunChen,GautamGoel,andAdamWierman.â€œSmoothedOnlineConvexOptimization
in High Dimensions via Online Balanced Descentâ€. In: Proceedings of the 31st Conference On
LearningTheory.PMLR,July2018,pp.1574â€“1594.
[CHW22] Nicolas Christianson, Tinashe Handina, and Adam Wierman. â€œChasing Convex Bodies and
FunctionswithBlack-BoxAdviceâ€.In:Proceedingsofthe35thConferenceonLearningTheory.
Vol.178.PMLR,July2022,pp.867â€“908.
[CSW23] Nicolas Christianson, Junxuan Shen, and Adam Wierman. â€œOptimal robustness-consistency
tradeoffsforlearning-augmentedmetricaltasksystemsâ€.In:InternationalConferenceonArti-
ficialIntelligenceandStatistics.2023.
[DB16] Steven Diamond and Stephen Boyd. â€œCVXPY: A Python-embedded modeling language for
convexoptimizationâ€.In:JournalofMachineLearningResearch17.83(2016),pp.1â€“5.
13[EFK+01] Ran El-Yaniv, Amos Fiat, Richard M. Karp, and G. Turpin. â€œOptimal Search and One-Way
Trading Online Algorithmsâ€. In: Algorithmica 30.1 (May 2001), pp. 101â€“139. doi: 10.1007/
s00453-001-0003-0.url:https://doi.org/10.1007/s00453-001-0003-0.
[FL93] Joel Friedman and Nathan Linial. â€œOn convex body chasingâ€. In: Discrete & Computational
Geometry 9.3(Mar.1993),pp.293â€“321.doi:10.1007/bf02189324.url:https://doi.org/
10.1007/bf02189324.
[HLB+23] WalidA.Hanafy,QianlinLiang,NomanBashir,DavidIrwin,andPrashantShenoy.â€œCarbon-
Scaler:LeveragingCloudWorkloadElasticityforOptimizingCarbon-Efficiencyâ€.In:Proceed-
ings of the ACM on Measurement and Analysis of Computing Systems 7.3 (Dec. 2023). arXiv:
2302.08681[cs.DC].
[Kou09] EliasKoutsoupias.â€œThek-serverproblemâ€.In:ComputerScienceReview3.2(May2009),pp.105â€“
118.doi:10.1016/j.cosrev.2009.04.002.url: https://doi.org/10.1016/j.cosrev.
2009.04.002.
[LCS+24] AdamLechowicz,NicolasChristianson,BoSun,NomanBashir,MohammadHajiesmaili,Adam
Wierman,andPrashantShenoy.â€œOnlineConversionwithSwitchingCosts:RobustandLearning-
augmented Algorithmsâ€. In: Proceedings of the 2024 SIGMETRICS/Performance Joint Interna-
tional Conference on Measurement and Modeling of Computer Systems. Venice, Italy: Associa-
tionforComputingMachinery,June2024.arXiv:2310.20598[cs.DS].
[LCZ+23] AdamLechowicz,NicolasChristianson,JinhangZuo,NomanBashir,MohammadHajiesmaili,
AdamWierman,andPrashantShenoy.â€œTheOnlinePauseandResumeProblem:OptimalAl-
gorithmsandAnApplicationtoCarbon-AwareLoadShiftingâ€.In:ProceedingsoftheACMon
MeasurementandAnalysisofComputingSystems7.3(Dec.2023).arXiv:2303.17551[cs.DS].
[LPS08] Julian Lorenz, Konstantinos Panagiotou, and Angelika Steger. â€œOptimal Algorithms for k-
Search with Application in Option Pricingâ€. In: Algorithmica 55.2 (Aug. 2008), pp. 311â€“328.
doi:10.1007/s00453-008-9217-8.
[LSH+24] Russell Lee, Bo Sun, Mohammad Hajiesmaili, and John C. S. Lui. â€œOnline Search with Pre-
dictions: Pareto-optimal Algorithm and its Applications in Energy Marketsâ€. In: Proceedings
of the 15th ACM International Conference on Future Energy Systems. e-Energy â€™24. Singapore,
Singapore:AssociationforComputingMachinery,June2024.
[LV18] ThodorisLykourisandSergeiVassilvtiskii.â€œCompetitiveCachingwithMachineLearnedAd-
viceâ€.In:Proceedingsofthe35thInternationalConferenceonMachineLearning.Ed.byJennifer
DyandAndreasKrause.Vol.80.ProceedingsofMachineLearningResearch.PMLR,July2018,
pp.3296â€“3305.url:https://proceedings.mlr.press/v80/lykouris18a.html.
[MAS14] EstherMohr,IftikharAhmad,andGÃ¼nterSchmidt.â€œOnlinealgorithmsforconversionprob-
lems:Asurveyâ€.In:SurveysinOperationsResearchandManagementScience 19.2(July2014),
pp. 87â€“104. doi: 10.1016/j.sorms.2014.08.001. url: https://doi.org/10.1016/j.
sorms.2014.08.001.
[MMS88] MarkManasse,LyleMcGeoch,andDanielSleator.â€œCompetitiveAlgorithmsforOn-LineProb-
lemsâ€.In:ProceedingsoftheTwentiethAnnualACMSymposiumonTheoryofComputing.STOC
â€™88. Chicago, Illinois, USA: Association for Computing Machinery, 1988, pp. 322â€“333. isbn:
0897912640.doi:10.1145/62212.62243.
[MPF91] DragoslavS.Mitrinovic,JosipE.PeÄariÄ‡,andA.M.Fink.InequalitiesInvolvingFunctionsand
TheirIntegralsandDerivatives.Vol.53.SpringerScience&BusinessMedia,1991.
14[PSK18] ManishPurohit,ZoyaSvitkina,andRaviKumar.â€œImprovingOnlineAlgorithmsviaMLPre-
dictionsâ€.In:AdvancesinNeuralInformationProcessingSystems.Ed.byS.Bengio,H.Wallach,
H.Larochelle,K.Grauman,N.Cesa-Bianchi,andR.Garnett.Vol.31.CurranAssociates,Inc.,
2018.
[RKS+22] AnaRadovanovic,RossKoningstein,IanSchneider,BokanChen,AlexandreDuarte,BinzRoy,
DiyueXiao,MayaHaridasan,PatrickHung,NickCare,etal.â€œCarbon-AwareComputingfor
Datacentersâ€.In:IEEETransactionsonPowerSystems(2022).
[Sel20] Mark Sellke. â€œChasing Convex Bodies Optimallyâ€. In: Proceedings of the Thirty-First Annual
ACM-SIAM Symposium on Discrete Algorithms. SODA â€™20. USA: Society for Industrial and
AppliedMathematics,Jan.2020,pp.1509â€“1518.
[SLH+21] Bo Sun, Russell Lee, Mohammad Hajiesmaili, Adam Wierman, and Danny Tsang. â€œPareto-
OptimalLearning-AugmentedAlgorithmsforOnlineConversionProblemsâ€.In:Advancesin
Neural Information Processing Systems. Ed. by M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S.
Liang,andJ.WortmanVaughan.Vol.34.CurranAssociates,Inc.,2021,pp.10339â€“10350.
[SZL+21] Bo Sun, Ali Zeynali, Tongxin Li, Mohammad Hajiesmaili, Adam Wierman, and Danny H.K.
Tsang.â€œCompetitiveAlgorithmsfortheOnlineMultipleKnapsackProblemwithApplication
to Electric Vehicle Chargingâ€. In: Proceedings of the ACM on Measurement and Analysis of
Computing Systems 4.3 (June 2021). doi: 10.1145/3428336. url: https://doi.org/10.
1145/3428336.
[WBS+21] Philipp Wiesner, Ilja Behnke, Dominik Scheinert, Kordian Gontarska, and Lauritz Thamsen.
â€œLetâ€™sWaitAWhile:HowTemporalWorkloadShiftingCanReduceCarbonEmissionsinthe
Cloudâ€.In:Proceedingsofthe22ndInternationalMiddlewareConference.NewYork,NY,USA:
AssociationforComputingMachinery,2021,pp.260â€“272.doi:10.1145/3464298.3493399.
[ZCL08] YunhongZhou,DeeparnabChakrabarty,andRajanLukose.â€œBudgetConstrainedBiddingin
Keyword Auctions and Online Knapsack Problemsâ€. In: Lecture Notes in Computer Science.
SpringerBerlinHeidelberg,2008,pp.566â€“576.
[ZJL+21] Lijun Zhang, Wei Jiang, Shiyin Lu, and Tianbao Yang. Revisiting Smoothed Online Learning.
2021.arXiv:2102.06933[cs.LG].url:https://arxiv.org/abs/2102.06933.
15Appendix
A Numerical Experiments (continued)
Inthissection,wegivesupplementalresultsexaminingthe95thpercentile(â€œworst-caseâ€)empiricalcom-
petitiveratioresults,followingthesamegeneralstructureasinthemainbody.
100 100 100 100
75 75 75 75
50 50 50 50
25 25 25 25
0 200 400 600 800 1000 0 0 20 40 60 80 100 0 5.0 7.5 10.0 12 d.5 15.0 17.5 20.0 0 0 25 50 75 100 125
Figure 7: VarU/yLing ğ‘ˆ/ğ¿, Figure8: Varyingğ›½,with Figure 9: Varyingğ‘‘ with Figure 10: Varying ğœ,
withğ›½ =ğ‘ˆ/5,ğ‘‘ = 5,ğœ‰ = 0, ğ‘ˆ/ğ¿ = 250,ğ‘‘ = 5,ğœ‰ = 0, ğ›½ = 50,ğ‘ˆ/ğ¿ = 250,ğœ = 50, withğ›½ =50,ğ‘ˆ/ğ¿=250,ğ‘‘ =
andğœ =ğ‘ˆ/5. andğœ = 50. andğœ‰=0. 5,andğœ‰ =0.
A.1 SupplementalResults
TocomplementtheresultsfortheaverageempiricalcompetitiveratioshowninSection5,inthissection
weplotthe95thpercentileempiricalcompetitiveratiosforeachtestedalgorithm, whichprimarilyserve
to show that the improved performance of our proposed algorithm holds in both average-case and tail
(â€œworst-caseâ€)scenarios.
In Figure 7-10, we investigate the impact of different parameters on the performance of each algo-
rithm. In Figure 7, we plot 95th percentile empirical competitiveness for different values ofğ‘ˆ/ğ¿ â€“ in this
experiment, we fix ğ›½ = ğ‘ˆ/5,ğ‘‘ = 5,ğœ‰ = 0, and ğœ = ğ‘ˆ/5, while varyingğ‘ˆ/ğ¿ âˆˆ {50,...,1250}. As observed
in the average competitive ratio plot (Figure 3), the performance of ALG1 degrades as ğ‘ˆ/ğ¿ grows, albeit
at a favorable pace compared to the comparison algorithms. Figure 8 plots the 95th percentile empirical
competitiveness for different values of ğ›½ â€“ in this experiment, we fixğ‘ˆ/ğ¿ = 250,ğ‘‘ = 5,ğœ‰ = 0, andğœ = 50.
Aspreviouslyintheaveragecompetitiveresults(Figure4),â€œagnosticâ€andâ€œmovetominimizerâ€heuristics
performbetterwhenğ›½ grows,becausetheswitchingcostpaidbytheoptimalsolutiongrowsaswell.
InFigure9,weplotthe95thpercentileempiricalcompetitivenessfor
differentvaluesofğ‘‘ â€“inthisexperiment,wefixğ‘ˆ/ğ¿ = 250,ğ›½ = 50,ğœ‰ = 0,
andğœ = 50, while varyingğ‘‘. Mirroring the previous results (Figure 5), 100 baseline[ =10]
ALG1 and CLIPâ€™s competitive performance degrades slower asğ‘‘ grows baseline[ =5]
75 baseline[ =2]
comparedtothecomparisonheuristics,aspredictedbytheirdimension- CLIP[ =10]
CLIP[ =5]
free theoretical bounds. Finally, Figure 10 plots the 95th percentile em- 50 ADV
piricalcompetitivenessfordifferentvaluesofğœ,whichisthedimension-
25
wisevariabilityofeachcostfunction. Herewefixğ‘ˆ/ğ¿ = 250,ğ›½ = 50,ğ‘‘ =
5, and ğœ‰ = 0, while varying ğœ âˆˆ {0,...,ğ‘ˆ/2}. Intuitively, as cost func- 0 0.0 0.1 0.2 0.3 0.4 0.5
tions become more variable, the competitive ratios of all tested algo- Figure 11: Varying adversarial
rithmsdegrade,withtheexceptionofourlearning-augmentedalgorithm factorğœ‰,withğ‘ˆ/ğ¿=250,ğ›½=50,ğ‘‘
CLIP. This degradation plateaus asğœ grows, as a large standard devia- =5,ğœ =50.
tion forces more of the terms of each cost vector cğ‘¡ to be truncated to
theinterval [ğ¿,ğ‘ˆ].
In Figure 11, we plot the 95th percentile empirical competitive ratio companion to Figure 2, which
measures the effect of prediction error on the learning-augmented algorithms CLIP and Baseline. We
16
laciripme
eli%
ht59
oitar
evititepmoc
laciripme
eli%
ht59
oitar
evititepmoc
laciripme
eli%
ht59
oitar
evititepmoc
laciripme
eli%
ht59
oitar
evititepmoc
laciripme
eli%
ht59
oitar
evititepmoctestseveralvaluesofğœ‰ âˆˆ [0,1],theadversarialfactor(recallthatğœ‰ = 0impliestheadviceiscorrect),while
fixingğ‘ˆ/ğ¿ = 250,ğ›½ = 50,ğ‘‘ = 5,ğœ = 50. WetestBaselineandCLIPforseveralvaluesofğœ– âˆˆ {2,5,10}(note
that ADV corresponds to running either Baseline or CLIP withğœ– = 0). Notably, in these 95th percentile
â€œworst-caseâ€results,wefindthatCLIPcontinuestosignificantlyoutperformstheBaselinealgorithmas
ğœ‰ grows,furthervalidatingthatCLIPismoreempiricallyrobusttopredictionerrorsthanthesimplefixed
ratiotechniqueofBaseline.
B Proofs for Section 3 (Competitive Algorithms)
B.1 Convexityofthepseudo-costminimizationprobleminALG1
In this section, we show that the pseudo-cost minimization problem central to the design of ALG1 is a
convexminimizationproblem,implyingthatitcanbesolvedefficiently.
Defineâ„ ğ‘¡(x) : ğ‘¡ âˆˆ [ğ‘‡] to represent the pseudo-cost minimization problem for a single arbitrary time
step:
âˆ« ğ‘§(ğ‘¡âˆ’1)+ğ‘(x)
â„ ğ‘¡(Â·) = ğ‘“ ğ‘¡(x)+ğ‘‘(x,xğ‘¡âˆ’1)âˆ’ ğœ™(ğ‘¢)ğ‘‘ğ‘¢. (10)
ğ‘§(ğ‘¡âˆ’1)
TheoremB.1. UndertheassumptionsoftheCFLandMALproblemsettings,â„ ğ‘¡(Â·) isalwaysconvex.
Proof. Weprovetheabovestatementbycontradiction.
Bydefinition,weknowthatthesumoftwoconvexfunctionsgivesaconvexfunction. Sincewehave
thatğ‘‘(x,xâ€²)isdefinedassomenorm,bydefinitionandbyobservingthatxâ€²isfixed,ğ‘‘(x,xâ€²)isconvex. We
havealsoassumedaspartoftheproblemsettingthateach ğ‘“ ğ‘¡(x) isconvex. Thus, ğ‘“ ğ‘¡(x) +ğ‘‘(x,xâ€²) mustbe
convex.
We turn our attention to the term
âˆ’âˆ«ğ‘§(ğ‘¡âˆ’1)+ğ‘(x)ğœ™(ğ‘¢)ğ‘‘ğ‘¢.
Let ğ‘˜(ğ‘(x)) =
âˆ«ğ‘§(ğ‘¡âˆ’1)+ğ‘(x)ğœ™(ğ‘¢)ğ‘‘ğ‘¢.
By the
ğ‘§(ğ‘¡âˆ’1) ğ‘§(ğ‘¡âˆ’1)
fundamentaltheoremofcalculus,âˆ‡ğ‘˜(ğ‘(x)) =ğœ™(ğ‘§(ğ‘¡âˆ’1) +ğ‘(x))âˆ‡ğ‘(x)
Letğ‘”(ğ‘(x)) = ğœ™(ğ‘§(ğ‘¡âˆ’1) +ğ‘(x)). Then âˆ‡2ğ‘˜(ğ‘(x)) = âˆ‡2ğ‘(x)ğ‘˜(ğ‘(x)) +âˆ‡ğ‘(x)ğ‘”â€²(ğ‘(x))âˆ‡ğ‘(x)âŠº. Sinceğ‘(x)
is piecewise linear (CFL and MAL both assume it is linear), we know that âˆ‡2ğ‘(x)ğ‘”(ğ‘(x)) = 0. Sinceğœ™ is
monotonicallydecreasingontheinterval[0,1],weknowthatğ‘”â€²(ğ‘(x)) < 0,andthusâˆ‡ğ‘(x)ğ‘”â€²(ğ‘(x))âˆ‡ğ‘(x)âŠº
isnegativesemidefinite. Thisimpliesthatğ‘˜(ğ‘(x)) isconcaveinx.
Sincethenegationofaconcavefunctionisconvex,thiscausesacontradiction,becausethesumoftwo
convexfunctionsgivesaconvexfunction.
Thus,â„ ğ‘¡(Â·) = ğ‘“ ğ‘¡(x) +ğ‘‘(x,xğ‘¡âˆ’1)
âˆ’âˆ« ğ‘§ğ‘§ (ğ‘¡( âˆ’ğ‘¡âˆ’ 1)1)+ğ‘(x)ğœ™(ğ‘¢)ğ‘‘ğ‘¢
is always convex under the assumptions ofCFL
andMAL. â–¡
By showing thatâ„ ğ‘¡(Â·) is convex, it follows that the pseudo-cost minimization (2) in ALG1 is a convex
minimizationproblem(i.e.,itcanbesolvedefficientlyusingnumericalmethods).
B.2 ProofofTheorem3.2
Inthissection,weproveTheorem3.2,whichshowsthatğ›¼ asgivenby(4)isanupperboundontheworst-
casecompetitiveratioofALG1(givenbyAlgorithm1)fortheCFLproblem.
ProofofTheorem3.2. Letğ‘§(ğ‘—) = (cid:205) ğ‘¡âˆˆ[ğ‘‡]ğ‘(xğ‘¡) denote the fraction of the long-term constraint satisfied by
ALG1beforethecompulsorytradeonanarbitraryCFLinstanceI âˆˆ Î©. Alsonotethatğ‘§(ğ‘¡) = (cid:205) ğ‘šâˆˆ[ğ‘¡]ğ‘(xğ‘š)
isnon-decreasingoverğ‘›.
LemmaB.2. TheofflineoptimalsolutionOPT(I)foranyCFLinstanceI âˆˆ Î©islowerboundedbyğœ™(ğ‘§(ğ‘—))âˆ’ğ›½.
17Proof of Lemma B.2. We prove this lemma by contradiction. Note that the offline optimum will stay
at 0 whenever possible, and satisfy the long-term constraint using the cost functions with the minimum
gradient(i.e.,thebestmarginalcost). AssumethatOPT(I) <ğœ™(ğ‘§(ğ‘—))âˆ’ğ›½,andthatğ‘§(ğ‘—) < 1(implyingthat
OPT(I) > ğ¿).
Recall that any cost function ğ‘“ ğ‘¡(Â·) : ğ‘‹ â†’ R is minimized exactly at 0, since ğ‘“ ğ‘¡(0) = 0 âˆ€ğ‘¡ âˆˆ [ğ‘‡]. By
convexityofthecostfunctions,thisimpliesthatthegradientofsomecostfunctionğ‘“ issimilarlyminimized
ğ‘¡
atthepoint0,andthusthebestmarginalcost forğ‘“
ğ‘¡
canbeobtainedbytakinganinfinitesimallysmallstep
awayfrom0inatleastonedirection,whichwedenote(withoutlossofgenerality)asğ‘– âˆˆ [ğ‘‘]. Forbrevity,
wedenotethisbestmarginalcostin ğ‘“ by [âˆ‡ğ‘“ ]ğ‘–.
ğ‘¡ ğ‘¡
TheassumptionthatOPT(I) <ğœ™(ğ‘§(ğ‘—))âˆ’ğ›½ impliesthatinstanceI mustcontainacostfunction ğ‘“ ğ‘š(Â·)
atsomearbitrarytimestepğ‘š (ğ‘š âˆˆ [ğ‘‡])whichsatisfies [âˆ‡ğ‘“ ]ğ‘– <ğœ™(ğ‘§(ğ‘—))âˆ’ğ›½ foranydimensionğ‘– âˆˆ [ğ‘‘].
ğ‘š
Priorwork[LPS08;SZL+21]hasshownthattheworst-caseforonlinesearchproblemswithlong-term
demandconstraintsoccurswhencostfunctionsarriveonlineindescendingorder,sowehenceforthadopt
thisassumption. Recallthatateachtimestep,ALG1solvesthepseudo-costminimizationproblemdefined
in(2). Withoutlossofgenerality,assumethatğ‘§(ğ‘šâˆ’1) =ğ‘§(ğ‘—),i.e. thecostfunction ğ‘“ ğ‘š(Â·) arriveswhenALG1
hasalreadyreacheditsfinalutilization(beforethecompulsorytrade).Thisimpliesthatxğ‘š = 0,andfurther
thatğ‘(xğ‘š) = 0. This implies that ğ‘“ ğ‘š(x) + âˆ¥xâˆ’xğ‘šâˆ’1âˆ¥ â„“ 1(w) >
âˆ« ğ‘§ğ‘§ (ğ‘š(ğ‘š âˆ’âˆ’ 1)1)+ğ‘(x)ğœ™(ğ‘¢)ğ‘‘ğ‘¢,
since the pseudo-cost
minimizationproblemshouldbeminimizedwhenALG1setsxğ‘š = 0.
Thepseudo-costminimizationproblemattimestepğ‘š canbeexpressedasfollows:
âˆ« ğ‘§(ğ‘šâˆ’1)+ğ‘(x)
xğ‘š = argmin ğ‘“ ğ‘š(x)+âˆ¥xâˆ’xğ‘šâˆ’1âˆ¥ â„“ 1(w) âˆ’ ğœ™(ğ‘¢)ğ‘‘ğ‘¢.
xâˆˆRğ‘‘:ğ‘(x)â‰¤1âˆ’ğ‘§(ğ‘šâˆ’1) ğ‘§(ğ‘šâˆ’1)
Wenotethatâˆ¥xâˆ’xğ‘šâˆ’1âˆ¥
â„“ 1(w)
isupperboundedbyğ›½(ğ‘§(ğ‘šâˆ’1)+ğ‘(x)),sinceintheworstcase,theprevious
online decision xğ‘šâˆ’1 built up all of ALG1â€™s utilization (ğ‘§(ğ‘šâˆ’1)) so far, and in the next step it will have to
switchdimensionstorampuptox.
Since the function ğœ™ is monotonically decreasing on ğ‘§ âˆˆ [0,1], the xğ‘š solving the true pseudo-
costminimizationproblemislower-boundedbythexË˜
ğ‘š
solvingthefollowingminimizationproblem(i.e.,
ğ‘(xË˜ ğ‘š) â‰¤ğ‘(xğ‘š)):
âˆ« ğ‘§(ğ‘šâˆ’1)+ğ‘(x)
xË˜ ğ‘š = argmin ğ‘“ ğ‘š(x)+ğ›½(ğ‘§(ğ‘šâˆ’1) +ğ‘(x))âˆ’ ğœ™(ğ‘¢)ğ‘‘ğ‘¢.
xâˆˆRğ‘‘:ğ‘(x)â‰¤1âˆ’ğ‘§(ğ‘šâˆ’1) ğ‘§(ğ‘šâˆ’1)
Thisfurthergivesthefollowing:
âˆ« ğ‘§(ğ‘šâˆ’1)+ğ‘(x)
ğ‘“ ğ‘š(x)+ğ›½(ğ‘§(ğ‘¡) +ğ‘(x))âˆ’ ğœ™(ğ‘¢)ğ‘‘ğ‘¢
ğ‘§(ğ‘šâˆ’1)
âˆ« ğ‘§(ğ‘šâˆ’1)+ğ‘(x) (cid:20) (cid:18)ğ‘ˆ (cid:19) (cid:21)
ğ‘“ ğ‘š(x)+ğ›½(ğ‘§(ğ‘¡) +ğ‘(x))âˆ’ ğ‘ˆ âˆ’ğ›½ +
ğ›¼
âˆ’ğ‘ˆ +2ğ›½ exp(ğ‘¢/ğ›¼) ğ‘‘ğ‘¢
ğ‘§(ğ‘šâˆ’1)
(cid:18) (cid:18)ğ‘§(ğ‘šâˆ’1) +ğ‘(x)(cid:19) (cid:18)ğ‘§(ğ‘šâˆ’1)(cid:19)(cid:19)
ğ‘“ ğ‘š(x)âˆ’(ğ‘ˆ âˆ’ğ›½)ğ‘(x)+ğ›½(ğ‘§(ğ‘¡) +ğ‘(x))âˆ’ [ğ‘ˆ âˆ’ğ‘ˆğ›¼ +2ğ›½ğ›¼] exp
ğ›¼
âˆ’exp
ğ›¼
By assumption, since ğ‘“ ğ‘š(Â·) is convex and satisfies [âˆ‡ğ‘“ ğ‘š]ğ‘– < ğœ™(ğ‘§(ğ‘—)) âˆ’ğ›½ at x = 0, there must exist a
dimensionğ‘– in ğ‘“
ğ‘š
whereanincrementalstepawayfrom0indirectionğ‘– satisfiesthefollowinginequality:
ğ‘“ ğ‘š(x) â‰² [âˆ‡ğ‘“ ğ‘š]ğ‘– Â·ğ‘(x) < [ğœ™(ğ‘§(ğ‘—))âˆ’ğ›½]ğ‘(x) forsomexwhereğ‘(x) > 0. Thus,wehavethefollowinginthe
pseudo-costminimizationproblem:
(cid:18) (cid:18)ğ‘§(ğ‘šâˆ’1) +ğ‘(x)(cid:19) (cid:18)ğ‘§(ğ‘šâˆ’1)(cid:19)(cid:19)
([âˆ‡ğ‘“ ğ‘š]ğ‘– âˆ’ğ‘ˆ +ğ›½)ğ‘(x)+ğ›½(ğ‘§(ğ‘¡) +ğ‘(x))âˆ’ [ğ‘ˆ âˆ’ğ‘ˆğ›¼ +2ğ›½ğ›¼] exp
ğ›¼
âˆ’exp
ğ›¼
18Lettingğ‘(ğ‘¥) besome scalarğ‘¦ (whichis validsince weassume thereis atleastone dimensionin ğ‘“ (Â·)
ğ‘¡
wherethecostfunctiongrowthrateisatmostâˆ‡ğ‘“ ),thepseudo-costminimizationproblemfindsthevalue
ğ‘š
ğ‘¦ whichminimizesthefollowingquantity:
(cid:18) (cid:18)ğ‘§(ğ‘šâˆ’1) +ğ‘¦(cid:19) (cid:18)ğ‘§(ğ‘šâˆ’1)(cid:19)(cid:19)
([âˆ‡ğ‘“ ]ğ‘– âˆ’ğ‘ˆ +ğ›½)ğ‘¦+ğ›½(ğ‘§(ğ‘¡) +ğ‘¦)âˆ’ [ğ‘ˆ âˆ’ğ‘ˆğ›¼ +2ğ›½ğ›¼] exp âˆ’exp
ğ‘š ğ›¼ ğ›¼
Takingthederivativeoftheabovewithrespecttoğ‘¦ yieldsthefollowing:
ğ‘‘ (cid:20) (cid:18) (cid:18)ğ‘§(ğ‘šâˆ’1) +ğ‘¦(cid:19) (cid:18)ğ‘§(ğ‘šâˆ’1)(cid:19)(cid:19)(cid:21)
ğ‘‘ğ‘¦
([âˆ‡ğ‘“ ğ‘š]ğ‘– âˆ’ğ‘ˆ +ğ›½)ğ‘¦+ğ›½(ğ‘§(ğ‘¡) +ğ‘¦)âˆ’ [ğ‘ˆ âˆ’ğ‘ˆğ›¼ +2ğ›½ğ›¼] exp
ğ›¼
âˆ’exp
ğ›¼
=
(ğ‘ˆğ›¼ âˆ’2ğ›¼ğ›½
âˆ’ğ‘ˆ)exp(cid:16)ğ‘§(ğ‘šâˆ’1)+ğ‘¦(cid:17)
ğ›¼
= [âˆ‡ğ‘“ ğ‘š]ğ‘– +2ğ›½ âˆ’ğ‘ˆ +
ğ›¼
Ifğ‘¦ = 0,wehavethefollowingbyassumptionthat [âˆ‡ğ‘“ ğ‘š]ğ‘– <ğœ™(ğ‘§(ğ‘—))âˆ’ğ›½ andthatğ‘§(ğ‘—) =ğ‘§(ğ‘šâˆ’1):
(cid:18)ğ‘§(ğ‘šâˆ’1)(cid:19) (cid:18)ğ‘§(ğ‘šâˆ’1)(cid:19)
[âˆ‡ğ‘“ ]ğ‘– +2ğ›½ âˆ’ğ‘ˆ +(ğ‘ˆ âˆ’2ğ›½ âˆ’ğ‘ˆ/ğ›¼)exp <ğœ™(ğ‘§(ğ‘—))+ğ›½ âˆ’ğ‘ˆ +(ğ‘ˆ âˆ’2ğ›½ âˆ’ğ‘ˆ/ğ›¼)exp
ğ‘š ğ›¼ ğ›¼
(cid:16) (cid:17)
<ğœ™(ğ‘§(ğ‘—))âˆ’ ğœ™(ğ‘§(ğ‘šâˆ’1)) = 0
Theabovederivationimpliesthatthederivativeofthecostminimizationproblematğ‘(x) = 0(which
corresponds to the case where x = 0) is strictly less than 0. This further implies that xË˜ ğ‘š must be non-
zero,sincetheminimizermustsatisfyğ‘(xË˜ ğ‘š) > 0. Sinceğ‘(xË˜ ğ‘š) lowerboundsthetrueğ‘(xğ‘š),thiscausesa
contradiction,asitwasassumedthattheutilizationaftertimestepğ‘š wouldsatisfyğ‘§(ğ‘š) =ğ‘§(ğ‘šâˆ’1) =ğ‘§(ğ‘—),
butifğ‘(xğ‘š) > 0,ğ‘§(ğ‘š) mustsatisfyğ‘§(ğ‘š) >ğ‘§(ğ‘šâˆ’1).
ItthenfollowsbycontradictionthatOPT(I) â‰¥ğœ™(ğ‘§(ğ‘—))âˆ’ğ›½.
LemmaB.3. ThecostofALG1onanyvalidCFLinstanceI âˆˆ Î© isupperboundedby
âˆ« ğ‘§(ğ‘—)
ALG1(I) â‰¤ ğœ™(ğ‘¢)ğ‘‘ğ‘¢ +ğ›½ğ‘§(ğ‘—) +(1âˆ’ğ‘§(ğ‘—))ğ‘ˆ. (11)
0
ProofofLemmaB.3. First,recallthatğ‘§(ğ‘¡) = (cid:205) ğœâˆˆ[ğ‘¡]ğ‘(xğœ) isnon-decreasingoverğ‘¡ âˆˆ [ğ‘‡].
Observethatwheneverğ‘(xğ‘¡) > 0,weknowthatğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡âˆ’xğ‘¡âˆ’1âˆ¥
â„“1(w)
<
âˆ« ğ‘§ğ‘§ (ğ‘¡( âˆ’ğ‘¡âˆ’ 1)1)+ğ‘(xğ‘¡)ğœ™(ğ‘¢)ğ‘‘ğ‘¢.
Then,
ifğ‘(xğ‘¡) = 0,whichcorrespondstothecasewhenxğ‘¡ = 0,wehavethefollowing:
âˆ« ğ‘§(ğ‘¡âˆ’1)+ğ‘(xğ‘¡)
ğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥ â„“1(w) âˆ’ ğœ™(ğ‘¢)ğ‘‘ğ‘¢ = 0+âˆ¥âˆ’xğ‘¡âˆ’1âˆ¥ â„“1(w) âˆ’0 â‰¤ ğ›½ğ‘(xğ‘¡âˆ’1)
ğ‘§(ğ‘¡âˆ’1)
Thisgivesthatforanytimestepwhereğ‘(xğ‘¡) = 0,wehavethefollowinginequality:
ğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥ â„“1(w) â‰¤ ğ›½ğ‘(xğ‘¡âˆ’1),âˆ€ğ‘¡ âˆˆ [ğ‘‡] :ğ‘(xğ‘¡) = 0. (12)
Andthus,sinceanytimestepwhereğ‘(xğ‘¡) > 0implies ğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥
â„“1(w)
<
âˆ« ğ‘§ğ‘§ (ğ‘¡( âˆ’ğ‘¡âˆ’ 1)1)+ğ‘(xğ‘¡)ğœ™(ğ‘¢)ğ‘‘ğ‘¢,we
havethefollowinginequalityforalltimesteps(i.e.,anupperboundontheexcesscostnotaccountedforin
thepseudo-costthresholdfunctionorcompulsorytrade)
âˆ« ğ‘§(ğ‘¡âˆ’1)+ğ‘(xğ‘¡)
ğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥
â„“1(w)
âˆ’ ğœ™(ğ‘¢)ğ‘‘ğ‘¢ â‰¤ ğ›½ğ‘(xğ‘¡âˆ’1),âˆ€ğ‘¡ âˆˆ [ğ‘‡]. (13)
ğ‘§(ğ‘¡âˆ’1)
19Thus,wehave
âˆ‘ï¸ âˆ‘ï¸
(cid:34) âˆ« ğ‘§(ğ‘¡âˆ’1)+ğ‘(xğ‘¡) (cid:35)
ğ›½ğ‘§(ğ‘—) = ğ›½ğ‘(xğ‘¡âˆ’1) â‰¥ ğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥ â„“1(w) âˆ’ ğœ™(ğ‘¢)ğ‘‘ğ‘¢ (14)
ğ‘¡âˆˆ[ğ‘—] ğ‘¡âˆˆ[ğ‘—]
ğ‘§(ğ‘¡âˆ’1)
âˆ« ğ‘§(ğ‘—)
= âˆ‘ï¸ (cid:2)ğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥ â„“1(w)(cid:3) âˆ’ ğœ™(ğ‘¢)ğ‘‘ğ‘¢ (15)
0
ğ‘¡âˆˆ[ğ‘—]
âˆ« ğ‘§(ğ‘—)
= ALG1âˆ’(1âˆ’ğ‘§(ğ‘—))ğ‘ˆ âˆ’ ğœ™(ğ‘¢)ğ‘‘ğ‘¢. (16)
0
CombiningLemmaB.2andLemmaB.3gives
ALG1(I)
âˆ«ğ‘§(ğ‘—)
ğœ™(ğ‘¢)ğ‘‘ğ‘¢ +ğ›½ğ‘§(ğ‘—) +(1âˆ’ğ‘§(ğ‘—))ğ‘ˆ
â‰¤ 0 â‰¤ ğ›¼, (17)
OPT(I) ğœ™(ğ‘§(ğ‘—))âˆ’ğ›½
wherethelastinequalityholdssinceforanyğ‘§ âˆˆ [0,1]
âˆ« ğ‘§ âˆ« ğ‘§
ğœ™(ğ‘¢)ğ‘‘ğ‘¢ +ğ›½ğ‘§+(1âˆ’ğ‘§)ğ‘ˆ = [ğ‘ˆ âˆ’ğ›½ +(ğ‘ˆ/ğ›¼ âˆ’ğ‘ˆ +2ğ›½)exp(ğ‘§/ğ›¼)] +ğ›½ğ‘§+(1âˆ’ğ‘§)ğ‘ˆ (18)
0 0
= (ğ‘ˆ âˆ’ğ›½)ğ‘§+ğ›¼(ğ‘ˆ/ğ›¼ âˆ’ğ‘ˆ +2ğ›½)[exp(ğ‘§/ğ›¼)âˆ’1] +ğ›½ğ‘§+(1âˆ’ğ‘§)ğ‘ˆ (19)
=ğ›¼(ğ‘ˆ/ğ›¼ âˆ’ğ‘ˆ +2ğ›½)[exp(ğ‘§/ğ›¼)âˆ’1] +ğ‘ˆ (20)
=ğ›¼ [ğ‘ˆ âˆ’2ğ›½ +(ğ‘ˆ/ğ›¼ âˆ’ğ‘ˆ +2ğ›½)exp(ğ‘§/ğ›¼)] (21)
=ğ›¼[ğœ™(ğ‘§)âˆ’ğ›½]. (22)
Thus,weconcludethatALG1isğ›¼-competitiveforCFL. â–¡
B.3 ProofofCorollary3.3
Inthissection,weproveCorollary3.3,whichshowsthattheworst-casecompetitiveratioofALG1forMAL
isagainupperboundedbyğ›¼ asdefinedin(4).
ProofofCorollary3.3. Toshowthisresult,wefirstprovearesultstatedinthemainbody,namelyLemma
2.2, which states the following: For any MAL instance on a weighted star metric (ğ‘‹,ğ‘‘), there is a cor-
responding CFL instance on (Rğ‘›âˆ’1,âˆ¥Â·âˆ¥ â„“ 1(wâ€²)) which preserves ğ‘“ ğ‘¡ğ‘(Â·) âˆ€ğ‘¡,ğ‘(Â·) âˆ€ğ‘ âˆˆ ğ‘‹, and upper bounds
ğ‘‘(ğ‘,ğ‘) âˆ€(ğ‘,ğ‘) âˆˆğ‘‹.
Beforetheproof,wenotethatBansalandCoester[BC22]showedonlinemetricallocationonaweighted
star metric (ğ‘‹,ğ‘‘) is identical to convex function chasing (with separable cost functions) on the normed
vector space (Î” ğ‘›,âˆ¥Â·âˆ¥ â„“ 1(w)), where Î” ğ‘› is theğ‘›-point simplex in Rğ‘› and âˆ¥Â·âˆ¥ â„“ 1(w) is the weighted â„“ 1 norm,
withweightsgivenbythecorrespondingedgeweightintheunderlyingstarmetricasfollows:
âˆ‘ï¸
âˆ¥xâˆ¥ â„“ 1(w) = wğ‘ |xğ‘ |.
ğ‘âˆˆğ‘‹
ProofofLemma2.2. Recallthatbyassumption,theMALinstancecontainsatleastoneOFFpointdenoted
by ğ‘â€² âˆˆ ğ‘‹ in the MAL instance, where cğ‘â€² = 0. Without loss of generality, let the first dimension in Î” ğ‘›
correspondtothisOFFpoint.
We define a linear map Î¦ : Î” â†’ Rğ‘›âˆ’1, where Î¦ hasğ‘› âˆ’1 rows andğ‘› columns, and is specified as
ğ‘›
follows:
(cid:40)
1ifj=i+1
Î¦ ğ‘–,ğ‘— =
0otherwise
20ItisstraightforwardtoseethatÎ¦x âˆˆ Rğ‘›âˆ’1, âˆ€x âˆˆ Î” ğ‘›.
RecallthataCFLdecisionspaceistheâ„“ 1balldefinedbythelong-termconstraintfunctioninRğ‘›âˆ’1. For
anyMALinstancewithconstraintfunctionğ‘(x) : Î”
ğ‘›
â†’ R,wecandefinealong-termconstraintfunction
ğ‘â€²(xâ€²) : Rğ‘›âˆ’1 â†’ R as follows. The MAL constraint function ğ‘(x) is defined as âˆ¥Â·âˆ¥ â„“ 1(c) for some vector
c âˆˆ Rğ‘›âˆ’1. Then
câ€² = Î¦c
ğ‘â€²(xâ€²) = âˆ¥xâ€²âˆ¥ â„“ 1(câ€²) âˆ€xâ€² âˆˆ Rğ‘›âˆ’1
Furthermore,foranyğ‘§ âˆˆ [0,1],letx âˆˆ Î”
ğ‘›
:ğ‘(x) < 1âˆ’ğ‘§. ThenitfollowsthatÎ¦xisinRğ‘›âˆ’1 :ğ‘â€²(xâ€²) < 1âˆ’ğ‘¤.
RecallthatcostfunctionsintheMALinstanceareconvexandlinearlyseparableasfollows:
âˆ‘ï¸
ğ‘“ ğ‘¡(x) = ğ‘“ ğ‘¡ğ‘ (xğ‘ )
ğ‘âˆˆğ‘‹
Next,againlettingx âˆˆ Î” ğ‘›,notethattheğ‘–thterminxisidenticaltothe (ğ‘–âˆ’1)thterminÎ¦x(excludingthe
firstterminx). ThenwecanconstructcostfunctionsintheCFLinstanceasfollows:
ğ‘“â€²(xâ€²) = âˆ‘ï¸ ğ‘“ğ‘–+1 (xğ‘– )
ğ‘¡ ğ‘¡
ğ‘–âˆˆ[ğ‘›âˆ’1]
UnderthemappingÎ¦,notethatitisstraightforwardtoshowthat ğ‘“ ğ‘¡(x) = ğ‘“ ğ‘¡â€²(Î¦x) foranyx âˆˆ Î” ğ‘›.
Finally,considerthedistancesintheMALinstanceâ€™sweightedstarmetric,whichcanbeexpressedasa
weightedâ„“ 1normdefinedbyw,wherethetermsofwcorrespondtotheweightededgesofthestarmetric.
Recall that ğ›½ (cid:66) max ğ‘â€²,ğ‘âˆ¥ğ‘â€² âˆ’ğ‘âˆ¥ â„“ 1(w), i.e., the maximum distance between the OFF point and any other
pointintheweightedstar.
ThenwedefineacorrespondingdistancemetricintheCFLinstance,whichisanâ„“
1
normweightedby
wâ€² âˆˆ Rğ‘›âˆ’1,whichisdefinedasfollows:
wâ€²ğ‘–
=
wğ‘–+1 +w0.
Notethatw0 istheedgeweightassociatedwiththeOFFpoint. Thenforany (x,y) âˆˆ Î” ğ‘›,itisstraightfor-
wardtoshowthefollowing:
âˆ¥xâˆ’yâˆ¥
â„“ 1(w)
â‰¤ âˆ¥Î¦xâˆ’Î¦yâˆ¥
â„“ 1(wâ€²)
This follows since for any (x,y) âˆˆ Î” ğ‘› where x0 = 0 and y0 = 0 (i.e., allocations which do not allocate
anythingtotheOFFpoint), âˆ¥Î¦xâˆ’Î¦yâˆ¥ â„“ 1(wâ€²) = âˆ¥xâˆ’yâˆ¥ â„“ 1(w) +âˆ¥xâˆ’yâˆ¥ â„“ 1 Â·w0.
Conversely, if either x or y have x0 > 0 or y0 > 0, we have âˆ¥x âˆ’ yâˆ¥ â„“ 1(w) â‰¤ âˆ¥Î¦x âˆ’ Î¦yâˆ¥ â„“ 1(wâ€²) â‰¤
âˆ¥xâˆ’yâˆ¥ â„“ 1(w) +âˆ¥xâˆ’yâˆ¥ â„“ 1 Â·w0. Finally,supposingthat(withoutlossofgenerality)xhasx0 = 1,wehavethat
âˆ¥xâˆ’yâˆ¥ â„“ 1(w) = âˆ¥Î¦xâˆ’Î¦yâˆ¥ â„“ 1(wâ€²).
Thus, âˆ¥Î¦xâˆ’Î¦yâˆ¥
â„“ 1(wâ€²)
upperbounds âˆ¥xâˆ’yâˆ¥
â„“
1(w). Furthermore,theconstructeddistancemetricpreserves
ğ›½,i.e. given (ğ‘â€²,ğ‘) = argmax ğ‘â€²,ğ‘âˆ¥ğ‘â€²âˆ’ğ‘âˆ¥ â„“ 1(w),wehavethat âˆ¥Î¦ğ‘â€²âˆ’Î¦ğ‘âˆ¥ â„“ 1(wâ€²) = ğ›½.
Next, we show that the transformation Î¦ is bijective. We define the affine map Î¦âˆ’1 : Rğ‘›âˆ’1 â†’ Î” as
ğ‘›
follows:Î¦âˆ’1hasğ‘›rowsandğ‘›âˆ’1columns,wherethefirstrowisallâˆ’1,andthebottomğ‘›rowsaretheğ‘›Ã—ğ‘›
identitymatrix. Letb âˆˆ Rğ‘›âˆ’1 denotethevectorwithb0 = 1andallothertermsarezero,i.e.,bğ‘– = 0âˆ€ğ‘– â‰¥ 1.
Foranyxâ€² âˆˆ Rğ‘›âˆ’1 :ğ‘â€²(xâ€²) â‰¤ 1,itisstraightforwardtoshowthatÎ¦âˆ’1 xâ€²+bisinÎ” ğ‘›,sincebydefinition
wehavethat(cid:205)
ğ‘–âˆˆ[ğ‘›+1]
(cid:0)Î¦âˆ’1 xâ€²+b(cid:1)
ğ‘–
= 1. Furthermore,bydefinitionofğ‘â€²(xâ€²),wehavethatğ‘(Î¦âˆ’1 xâ€² +b) =
ğ‘â€²(xâ€²), because theğ‘–thterm (excludingthefirstterm) ofÎ¦âˆ’1 xâ€² +bisidentical tothe (ğ‘– âˆ’1)thterm ofxâ€².
Similarly,bydefinitionof ğ‘“ ğ‘¡â€²,wehavethat ğ‘“ ğ‘¡(Î¦âˆ’1 xâ€²+b) = ğ‘“ ğ‘¡â€²(xâ€²).
21Finally,consideringthedistancemetric,wehavethatforany (xâ€²,yâ€²) âˆˆ Rğ‘›âˆ’1 :ğ‘â€²(xâ€²) â‰¤ 1:
âˆ¥(Î¦âˆ’1 xâ€²+b)âˆ’(Î¦âˆ’1 yâ€²+b)âˆ¥
â„“ 1(w)
â‰¤ âˆ¥xâ€²âˆ’yâ€²âˆ¥
â„“
1(wâ€²).
Thisfollowsbyconsideringthatforanyxâ€²,Î¦âˆ’1 xâ€² +baddsadimension(correspondingtotheOFFpoint)
andsets (cid:0)Î¦âˆ’1 xâ€²+b(cid:1) = 1âˆ’âˆ¥xâ€²âˆ¥1. Thenthedistancebetweenanytwopointswhichallocateanon-negative
fraction to the OFF point in Î” ğ‘› is â‰¤ the distance in Rğ‘›âˆ’1 by definition of the weight vector wâ€², and the
distancebetweene.g.,theallocationfullyintheOFFpoint(ğ‘â€²)andanyotherallocationisexactlypreserved.
Furthermore,notethatifw0 = 0(i.e.,theweightoftheOFFstateintheweightedstarmetricis0),Î¦is
abijectiveisometrybetween (Î” ,âˆ¥Â·âˆ¥ ) and (Rğ‘›âˆ’1,âˆ¥Â·âˆ¥ ). â–¡
ğ‘› â„“ 1(w) â„“ 1(wâ€²)
ThetransformationdefinedbyÎ¦inLemma2.2allowsustoputdecisionsontheCFLinstance(Rğ‘›âˆ’1,âˆ¥Â·âˆ¥
â„“
1(wâ€²))
inone-to-onecorrespondencewithdecisionsin (Î” ,âˆ¥Â·âˆ¥ ).
ğ‘› â„“ 1(w)
Below, we formalize this by proving a result stated in the main body (Proposition 2.3) which states
thefollowing: GivenanalgorithmALGforCFL,anyperformanceboundonALGwhichassumesOPTdoes
not pay any switching cost will translate to an identical performance bound for MAL whose parameters
dependonthecorrespondingCFLinstanceconstructedaccordingtoLemma2.2.
ProofofProposition2.3. The cost of ALG on the CFL instance is an upper bound on the cost of the ALGâ€™s
decisions mapped into the MAL instance. This follows since the cost functions are preserved exactly
betweenthetwoinstances,thelong-termconstraintfunctionispreservedexactly,andtheCFLswitching
costisbydefinitionanupperboundontheMALswitchingcost.
If the CFL performance bound assumes that OPT does not pay any switching cost (e.g., as in Theo-
rem3.2),lowerboundingthecostofOPTontheCFLinstanceisequivalenttolowerboundingthecostof
OPTontheMALinstance,asthecostfunctionsandconstraintfunctionsarepreservedexactly.
Thus,wehavethatanysuchperformanceboundforALGontheCFLinstanceconstructedappropriately
(as in Lemma 2.2) immediately gives an identical performance bound for the MAL instance, yielding the
result. â–¡
ByLemma2.2,wehavethatsinceALG1isğ›¼-competitiveforCFL(Theorem3.2),ALG1isğ›¼-competitive
foranyCFLinstanceconstructedbasedonaMALinstance. Furthermore,byProposition2.3,ALG1isalso
ğ›¼-competitiveontheunderlyingMALinstance,whereğ›¼ isgivenby(4). â–¡
B.4 ProofofTheorem3.4
In this section, we prove Theorem 3.4, which shows that ğ›¼ as given by (4) is the best competitive ratio
achievableforCFL.
To show this lower bound, we first define a family of special adversaries, and then show that the
competitiveratioforanydeterministicalgorithmislowerboundedundertheinstancesprovidedbythese
adversaries.
Priorworkhasshownthatdifficultinstancesforonlinesearchproblemswithaminimizationobjective
occurwheninputsarriveatthealgorithminandecreasingorderofcost[EFK+01;LPS08;SZL+21;LCZ+23].
ForCFL,weadditionallyconsiderhowanadaptiveadversarycanessentiallyforceanalgorithmtoincura
largeswitchingcostintheworst-case. Wenowformalizesuchafamilyofadversaries{A } ,where
ğ‘¦ ğ‘¦âˆˆ[ğ¿,ğ‘ˆ]
A
ğ‘¦
iscalledağ‘¦-adversary.
DefinitionB.4(ğ‘¦-adversaryforCFL). Letğ‘¤,ğ‘š âˆˆ Zbesufficientlylarge,andğ›¿ := (ğ‘ˆâˆ’ğ¿)/ğ‘¤.
Without loss of generality, let ğ‘˜ = argmax ğ‘–âˆˆ[ğ‘‘]wğ‘–, where w is the weight vector for âˆ¥Â·âˆ¥ â„“ 1(w), and
let ğ›½ = max ğ‘–âˆˆ[ğ‘‘]wğ‘–. Forğ‘¦ âˆˆ [ğ¿,ğ‘ˆ], an adaptive adversary A ğ‘¦ sequentially presents two types of cost
functions ğ‘“ ğ‘¡(Â·) tobothALGandOPT.
22ThesetypesofcostfunctionsareUp(x) =ğ‘ˆ1xâŠº,andDownğ‘–(x) = (cid:205)ğ‘‘ ğ‘ˆxğ‘— +(ğ‘ˆ âˆ’ğ‘–ğ›¿)xğ‘˜.
ğ‘—â‰ ğ‘˜
The adversary sequentially presents cost functions from these two types in an alternating, â€œcontinu-
ouslydecreasingâ€order. Specifically,theystartbypresentingcostfunctionUp(x),uptoğ‘š times.
Then,theypresentDown1(x),whichhaslinearcostcoefficientğ‘ˆ ineverydirectionexceptdirection
ğ‘˜,whichhascostcoefficient (ğ‘ˆ âˆ’1Â·ğ›¿). Down1(x) ispresenteduptoğ‘štimes. IfALGeverâ€œacceptsâ€acost
function Down1(x) (i.e., if ALG makes a decision x whereğ‘(x) > 0), the adaptive adversary immediately
presents Up(x) starting in the next time step until either ALG moves to the origin (i.e. online decision
x = 0)orALGâ€™sutilizationğ‘§ = 1.
Theadversarycontinuesalternatinginthismanner,presentingDown2(x) uptoğ‘štimes,followedby
Up(x) ifALGacceptsanything,followedbyDown3(x) uptoğ‘š times,andsoon. Thiscontinuesuntilthe
adversarypresentsDownğ‘¤ ğ‘¦(x),whereğ‘¦ (cid:66) (ğ‘ˆ âˆ’ğ‘¤ ğ‘¦ğ›¿),uptoğ‘š times. AfterpresentingDownğ‘¤ ğ‘¦(x),A
ğ‘¦
will present Up(x) until either ALG moves to the origin or has utilization ğ‘§ = 1. Finally, the adversary
presentsexactlyğ‘š costfunctionsoftheform(cid:205)ğ‘‘ ğ‘ˆxğ‘— +(ğ‘¦+ğœ€)xğ‘˜,followedbyğ‘š costfunctionsUp(x).
ğ‘—â‰ ğ‘˜
Themechanismofthisadaptiveadversaryisdesignedtopresentâ€œgoodcostfunctionsâ€(i.e.,Downğ‘–(x))
inaworst-casedecreasingorder,interruptedbyblocksofâ€œbadcostfunctionsâ€Up(x) whichforcealarge
switchingcostintheworstcase.
A issimplyastreamofğ‘š costfunctionsğ‘ˆ,andthefinalcostfunctionsinanyğ‘¦-adversaryinstance
ğ‘ˆ
arealwaysUp(x).
ProofofTheorem3.4. Let ğ‘”(ğ‘¦) denote a conversion function [ğ¿,ğ‘ˆ] â†’ [0,1], which fully describes the
progress towards the long-term constraint (before the compulsory trade) of a deterministic ALG playing
against adaptive adversary A . Note that for largeğ‘¤, the adaptive adversary A is equivalent to first
ğ‘¦ ğ‘¦âˆ’ğ›¿
playingA (besidesthelasttwobatchesofcostfunctions),andthenprocessingbatcheswithcostfunctions
ğ‘¦
Downğ‘¤ ğ‘¦+1(x)andUp(x). SinceALGisdeterministicandtheconversionisunidirectional(irrevocable),we
musthavethatğ‘”(ğ‘¦âˆ’ğ›¿) â‰¥ğ‘”(ğ‘¦),i.e.ğ‘”(ğ‘¦) isnon-increasingin [ğ¿,ğ‘ˆ]. Intuitively,theentirecapacityshould
besatisfiediftheminimumpossiblepriceisobserved,i.eğ‘”(ğ¿) = 1.
Note that for ğœ€ â†’ 0, the optimal solution for adversary A ğ‘¦ is OPT(A ğ‘¦) = ğ‘¦ + 2ğ›½/ğ‘š, and for ğ‘š
sufficientlylarge,OPT(A ğ‘¦) â†’ğ‘¦.
Duetotheadaptivenatureofeachğ‘¦-adversary,anydeterministicALGincursaswitchingcostpropor-
tionaltoğ‘”(ğ‘¦),whichgivestheamountofutilizationobtainedbyALGbeforetheendofA ğ‘¦â€™ssequence.
WheneverALGacceptssomecostfunctionwithcoefficientğ‘ˆ âˆ’ğ‘–ğ›¿ indirectionğ‘˜,theadversarypresents
Up(x) starting in the next time step. Any ALG which does not switch away immediately obtains a com-
petitiveratiostrictlyworsethananalgorithmwhichdoesswitchaway(ifanalgorithmacceptsğ‘ fraction
of a good price and switches away immediately, the switching cost it will pay is 2ğ›½ğ‘. An algorithm may
continue acceptingğ‘ fraction of coefficientğ‘ˆ in the subsequent time steps, but a sequence exists where
this decision will take up too much utilization to recover when better cost functions are presented later.
Intheextremecase, ifanalgorithmcontinuesacceptingğ‘ fractionoftheseğ‘ˆ coefficients, itmightfillits
utilizationandthenOPTcanacceptacostfunctionwhichisarbitrarilybetter).
Sinceacceptinganypricebyafactorofğ‘ incursaswitchingcostof2ğ›½ğ‘,theswitchingcostpaidbyALG
onadversaryA
ğ‘¦
is2ğ›½ğ‘”(ğ‘¦). WeassumethatALGisnotifiedofthecompulsorytrade,anddoesnotincura
significantswitchingcostduringthefinalbatch.
Thenthetotalcostincurredbyanğ›¼â˜…-competitiveonlinealgorithmALGonadversaryA ğ‘¦isALG(A ğ‘¦) =
âˆ« ğ‘¦
ğ‘”(ğ‘ˆ/ğ›¼â˜…)ğ‘ˆ/ğ›¼â˜…âˆ’ ğ‘¢ğ‘‘ğ‘”(ğ‘¢)+2ğ›½ğ‘”(ğ‘¦)+(1âˆ’ğ‘”(ğ‘¦))ğ‘ˆ,whereğ‘¢ğ‘‘ğ‘”(ğ‘¢) isthecostofbuyingğ‘‘ğ‘”(ğ‘¢) utilizationat
ğ‘ˆ/ğ›¼â˜…
costcoefficientğ‘¢,thelasttermisfromthecompulsorytrade,andthesecondtolasttermistheswitching
costincurredbyALG. NotethatanydeterministicALGwhichmakesconversionswhenthepriceislarger
thanğ‘ˆ/ğ›¼â˜…canbestrictlyimprovedbyrestrictingconversionstoprices â‰¤ğ‘ˆ/ğ›¼â˜….
23For any ğ›¼â˜…-competitive online algorithm, the corresponding conversion function ğ‘”(Â·) must satisfy
ALG(A ğ‘¦) â‰¤ ğ›¼â˜…OPT(A ğ‘¦) = ğ›¼â˜…ğ‘¦,âˆ€ğ‘¦ âˆˆ [ğ¿,ğ‘ˆ]. This gives a necessary condition which the conversion
functionmustsatisfyasfollows:
âˆ« ğ‘¦
ALG(A ğ‘¦) =ğ‘”(ğ‘ˆ/ğ›¼â˜…)ğ‘ˆ/ğ›¼â˜…âˆ’ ğ‘¢ğ‘‘ğ‘”(ğ‘¢)+2ğ›½ğ‘”(ğ‘¦)+(1âˆ’ğ‘”(ğ‘¦))ğ‘ˆ â‰¤ ğ›¼â˜…ğ‘¦, âˆ€ğ‘¦ âˆˆ [ğ¿,ğ‘ˆ].
ğ‘ˆ/ğ›¼â˜…
By integral by parts, the above implies that the conversion function must satisfy ğ‘”(ğ‘¦) â‰¥
ğ‘ˆâˆ’ğ›¼â˜…ğ‘¦ âˆ’ 1 âˆ« ğ‘¦ ğ‘”(ğ‘¢)ğ‘‘ğ‘¢. ByGrÃ¶nwallâ€™sInequality[MPF91,Theorem1,p. 356],wehavethat
ğ‘ˆâˆ’ğ‘¦âˆ’2ğ›½ ğ‘ˆâˆ’ğ‘¦âˆ’2ğ›½ ğ‘ˆ/ğ›¼â˜…
ğ‘ˆ âˆ’ğ›¼â˜…ğ‘¦ 1 âˆ« ğ‘¦ ğ‘ˆ âˆ’ğ›¼â˜…ğ‘¢ (cid:18)âˆ« ğ‘¦ 1 (cid:19)
ğ‘”(ğ‘¦) â‰¥ âˆ’ Â·exp ğ‘‘ğ‘Ÿ ğ‘‘ğ‘¢
ğ‘ˆ âˆ’ğ‘¦âˆ’2ğ›½ ğ‘ˆ âˆ’ğ‘¦âˆ’2ğ›½ ğ‘ˆ âˆ’ğ‘¢ âˆ’2ğ›½ ğ‘ˆ âˆ’ğ‘Ÿ âˆ’2ğ›½
ğ‘ˆ/ğ›¼â˜… ğ‘¢
ğ‘ˆ âˆ’ğ›¼â˜…ğ‘¦ âˆ« ğ‘¦ ğ‘ˆ âˆ’ğ›¼â˜…ğ‘¢
â‰¥ âˆ’ ğ‘‘ğ‘¢
ğ‘ˆ âˆ’ğ‘¦âˆ’2ğ›½ (ğ‘ˆ âˆ’ğ‘¢ âˆ’2ğ›½)2
ğ‘ˆ/ğ›¼â˜…
ğ‘ˆ âˆ’ğ›¼â˜…ğ‘¦ (cid:20)ğ‘ˆğ›¼â˜…âˆ’ğ‘ˆ âˆ’2ğ›½ğ›¼â˜… (cid:21)ğ‘¦
â‰¥ âˆ’ âˆ’ğ›¼â˜…ln(ğ‘¢ +2ğ›½ âˆ’ğ‘ˆ)
ğ‘ˆ âˆ’ğ‘¦âˆ’2ğ›½ ğ‘¢ +2ğ›½ âˆ’ğ‘ˆ
ğ‘ˆ/ğ›¼â˜…
â‰¥ ğ›¼â˜…ln(ğ‘¦+2ğ›½ âˆ’ğ‘ˆ)âˆ’ğ›¼â˜…ln(ğ‘ˆ/ğ›¼â˜…+2ğ›½ âˆ’ğ‘ˆ), âˆ€ğ‘¦ âˆˆ [ğ¿,ğ‘ˆ].
ğ‘”(ğ¿) = 1 by the problem definition â€“ we can combine this with the above constraint to give the fol-
lowingconditionforanğ›¼â˜…-competitiveonlinealgorithm:
ğ›¼â˜…ln(ğ¿+2ğ›½ âˆ’ğ‘ˆ)âˆ’ğ›¼â˜…ln(ğ‘ˆ/ğ›¼â˜…+2ğ›½ âˆ’ğ‘ˆ) â‰¤ğ‘”(ğ¿) = 1.
The optimal ğ›¼â˜… is obtained when the above inequality is binding, so solving for the value of ğ›¼â˜… which
solves ğ›¼â˜…ln(ğ¿+2ğ›½ âˆ’ğ‘ˆ) âˆ’ğ›¼â˜…ln(ğ‘ˆ/ğ›¼â˜…+2ğ›½ âˆ’ğ‘ˆ) = 1 yields that the best competitive ratio for any ALG
solvingCFLisğ›¼â˜… â‰¥ (cid:104) ğ‘Š (cid:16) ğ‘’2ğ›½/ğ‘ˆ(ğ¿/ğ‘ˆ+2ğ›½/ğ‘ˆâˆ’1)(cid:17) âˆ’ 2ğ›½ +1(cid:105)âˆ’1 . â–¡
ğ‘’ ğ‘ˆ
B.5 ProofofCorollary3.5
In this section, we prove Corollary 3.5, which shows that ğ›¼ as given by (4) is the best competitive ratio
achievableforMAL.
Toshowthislowerbound,webuildoffofthefamilyofadversariesinDefinitionB.4,whicharedesigned
toforceanalgorithmtoincuralargeswitchingcostwhilesatisfyingthelong-termconstraint.InDefinition
B.5wedefinethisfamilyofadversarialinstancestailoredforMAL.
DefinitionB.5(ğ‘¦-adversaryforMAL). Letğ‘¤,ğ‘š âˆˆ Zbesufficientlylarge,andğ›¿ := (ğ‘ˆâˆ’ğ¿)/ğ‘¤.
Recallthatwdenotesthevectorofedgeweightsforeachpointintheweightedstarmetricğ‘‹,andthe
OFF point is defined (without loss of generality) as the pointğ‘â€² âˆˆ ğ‘‹ where cğ‘â€² = 0 and ğ‘“ğ‘â€²(xğ‘) = 0âˆ€ğ‘¡ âˆˆ
ğ‘¡
[ğ‘‡],âˆ€xğ‘ âˆˆ [0,1]. Wewillassumethatcğ‘ = 1âˆ€ğ‘ âˆˆğ‘‹ :ğ‘ â‰ ğ‘â€².
Thenwesetwğ‘â€² = 0,i.e.,theOFFpointisconnectedtotheinteriorvertexoftheweightedstarwithan
edgeofweight0. Withoutlossofgenerality,weletğ‘˜ = argmax wğ‘ denotethelargestedgeweightof
ğ‘âˆˆ[ğ‘›]
anyother(non-OFF)pointinthemetric. Bydefinition,recallthatğ›½ = wğ‘˜.
Forğ‘¦ âˆˆ [ğ¿,ğ‘ˆ], an adaptive adversary A sequentially presents two different sets of cost functions
ğ‘¦
ğ‘“ğ‘(Â·) ateachpointinthemetricspace.
ğ‘¡
These sets of cost functions are Up = {ğ‘“ğ‘(ğ‘¥) = ğ‘ˆxğ‘ âˆ€ğ‘ âˆˆ ğ‘‹ \ {ğ‘â€²}}, and Downğ‘– = {ğ‘“ğ‘˜(xğ‘˜) =
(ğ‘ˆ âˆ’ğ‘–ğ›¿)xğ‘˜}âˆ©{ğ‘“ğ‘(xğ‘) =ğ‘ˆxğ‘ âˆ€ğ‘ âˆˆğ‘‹ \{ğ‘â€²,ğ‘˜}}. Notethattheadversaryonlyeverpresentscostfunctions
withacoefficient<ğ‘ˆ atthepointğ‘˜ whichcorrespondstothelargestedgeweight.
Theadversarysequentiallypresentseitherofthesetwosetsofcostfunctionsinanalternating,â€œcon-
tinuouslydecreasingâ€order. Specifically,theystartbypresentingUp,uptoğ‘š times.
24Then,theypresentDown,whichhascostcoefficientğ‘ˆ ineverypointexceptpointğ‘˜,whichhascost
coefficient (ğ‘ˆ âˆ’1Â·ğ›¿). Down1 ispresenteduptoğ‘š times. IfALGeverâ€œacceptsâ€acostfunctioninDown1
(i.e.,ifALGmakesadecisionğ‘¥ whereğ‘(ğ‘¥) > 0),theadaptiveadversaryimmediatelypresentsUpstarting
inthenexttimestepuntileitherALGmovesentirelytotheOFFpoint(i.e. onlinedecisionğ‘¥ğ‘â€² = 1)orALGâ€™s
utilizationğ‘§ = 1.
Theadversarycontinuesalternatinginthismanner,presentingDown2uptoğ‘štimes,followedbyUp
ifALGacceptsanything,followedbyDown3 uptoğ‘š times,andsoon. Thiscontinuesuntiltheadversary
presentsDownğ‘¤ ğ‘¦,whereğ‘¦ = (ğ‘ˆâˆ’ğ‘¤ ğ‘¦ğ›¿),uptoğ‘štimes. AfterpresentingDownğ‘¤ ğ‘¦,A ğ‘¦ willpresentUp(ğ‘¥)
untileitherALGmovestotheOFFpointorhasutilizationğ‘§ = 1. Finally, theadversarypresentsthesetof
costfunctions{ğ‘“ğ‘˜(xğ‘˜) = (ğ‘¦+ğœ€)xğ‘˜}âˆ©{ğ‘“ğ‘(xğ‘) =ğ‘ˆxğ‘ âˆ€ğ‘ âˆˆğ‘‹ \{ğ‘â€²,ğ‘˜}}ğ‘š times,followedbyUpğ‘š times.
The mechanism of this adaptive adversary is designed to present â€œgood cost functionsâ€ (i.e., Downğ‘–)
in a worst-case decreasing order, interrupted by blocks of â€œbad cost functionsâ€ Up which force a large
switchingcostintheworstcase.
AsinTheorem3.4, A
ğ‘ˆ
issimplyastreamofğ‘š Upsetsofcostfunctions,andthefinalcostfunctions
inanyğ‘¦-adversaryinstancearealwaysUp.
ProofofCorollary3.5. Aspreviously,weletğ‘”(ğ‘¦) denoteaconversionfunction [ğ¿,ğ‘ˆ] â†’ [0,1],whichfully
describestheprogresstowardsthelong-termconstraint(beforethecompulsorytrade)ofadeterministic
ALGplayingagainstadaptiveadversaryA ğ‘¦. SinceALGisdeterministicandtheconversionisunidirectional
(irrevocable),ğ‘”(ğ‘¦) isnon-increasingin [ğ¿,ğ‘ˆ]. Intuitively,theentirelong-termconstraintshouldbesatis-
fiediftheminimumpossiblepriceisobserved,i.eğ‘”(ğ¿) = 1. Forğœ€ â†’ 0,theoptimalsolutionforadversary
A
ğ‘¦
isOPT(A ğ‘¦) =ğ‘¦+2ğ›½/ğ‘š,andforğ‘š sufficientlylarge,OPT(A ğ‘¦) â†’ğ‘¦.
As in Theorem 3.4, the adaptive nature of eachğ‘¦-adversary forces any deterministic ALG to incur a
switchingcostof2ğ›½ğ‘”(ğ‘¦) onadversaryA ğ‘¦,andweassumethatALGdoesnotincurasignificantswitching
costduringthefinalbatch(i.e.,duringthecompulsorytrade).
Thenthetotalcostincurredbyanğ›¼â˜…-competitiveonlinealgorithmALGonadversaryA ğ‘¦isALG(A ğ‘¦) =
âˆ« ğ‘¦
ğ‘”(ğ‘ˆ/ğ›¼â˜…)ğ‘ˆ/ğ›¼â˜…âˆ’ ğ‘¢ğ‘‘ğ‘”(ğ‘¢)+2ğ›½ğ‘”(ğ‘¦)+(1âˆ’ğ‘”(ğ‘¦))ğ‘ˆ,whereğ‘¢ğ‘‘ğ‘”(ğ‘¢) isthecostofbuyingğ‘‘ğ‘”(ğ‘¢) utilizationat
ğ‘ˆ/ğ›¼â˜…
costcoefficientğ‘¢,thelasttermisfromthecompulsorytrade,andthesecondtolasttermistheswitching
costincurredbyALG. NotethatthisexpressionforthecostisexactlyasdefinedinTheorem3.4.
Thus by Theorem 3.4, for any ğ›¼â˜…-competitive online algorithm, the conversion function ğ‘”(Â·) must
satisfy ALG(A ğ‘¦) â‰¤ ğ›¼â˜…OPT(A ğ‘¦) = ğ›¼â˜…ğ‘¦,âˆ€ğ‘¦ âˆˆ [ğ¿,ğ‘ˆ]. Via integral by parts and GrÃ¶nwallâ€™s Inequality
[MPF91,Theorem1,p. 356],wehavethefollowingconditiononğ‘”(ğ‘¦):
ğ‘”(ğ‘¦) â‰¥ ğ›¼â˜…ln(ğ‘¦+2ğ›½ âˆ’ğ‘ˆ)âˆ’ğ›¼â˜…ln(ğ‘ˆ/ğ›¼â˜…+2ğ›½ âˆ’ğ‘ˆ), âˆ€ğ‘¦ âˆˆ [ğ¿,ğ‘ˆ].
ğ‘”(ğ¿) = 1 by the problem definition â€“ combining this with the previous condition gives the following
conditionforanğ›¼â˜…-competitiveonlinealgorithm:
ğ›¼â˜…ln(ğ¿+2ğ›½ âˆ’ğ‘ˆ)âˆ’ğ›¼â˜…ln(ğ‘ˆ/ğ›¼â˜…+2ğ›½ âˆ’ğ‘ˆ) â‰¤ğ‘”(ğ¿) = 1.
AsinTheorem3.4,theoptimalğ›¼â˜…isobtainedwhentheaboveinequalityisbinding,yieldingthatthebest
competitiveratioforanyALGsolvingMALisğ›¼â˜… â‰¥ (cid:104) ğ‘Š (cid:16) ğ‘’2ğ›½/ğ‘ˆ(ğ¿/ğ‘ˆ+2ğ›½/ğ‘ˆâˆ’1)(cid:17) âˆ’ 2ğ›½ +1(cid:105)âˆ’1 . â–¡
ğ‘’ ğ‘ˆ
C Proofs for Section 4 (Learning-Augmentation)
C.1 ProofofLemma4.1
In this section, we prove Lemma 4.1, which shows that the baseline fixed-ratio combination algorithm
(cid:16) (cid:17)
(Baseline)is(1+ğœ–)-consistentand (ğ‘ˆ+2ğ›½)/ğ¿(ğ›¼âˆ’1âˆ’ğœ–)+ğ›¼ğœ– -robustforCFL,givenanyğœ– âˆˆ [0,ğ›¼âˆ’1]andwhere
(ğ›¼âˆ’1)
25ğ›¼ isasdefinedin(4).RecallthatLemma4.1specifiesALG1astheâ€œrobustalgorithmâ€touseforthefollowing
analysis.
ProofofLemma4.1. UndertheassumptionthatADVsatisfiesthelong-termconstraint,(i.e.,that(cid:205)ğ‘‡ ğ‘¡=1ğ‘(ağ‘¡) â‰¥
1),wefirstobservethattheonlinesolutionofBaselinemustalsosatisfythelong-termconstraint.
UndertheassumptionsofCFL,notethatğ‘(x) islinear(i.e.,aweightedâ„“
1
normwithweightvectorc).
Bydefinition,denotingthedecisionsofALG1byxËœ ğ‘¡,weknowthat(cid:205)ğ‘‡ ğ‘¡=1ğ‘(xËœ ğ‘¡) â‰¥ 1.
Thus,wehavethefollowing:
ğ‘‡ ğ‘‡ ğ‘‡ ğ‘‡
âˆ‘ï¸ âˆ‘ï¸ âˆ‘ï¸ âˆ‘ï¸
ğ‘(xğ‘¡) = ğ‘ (ğœ†ağ‘¡ +(1âˆ’ğœ†)xËœ ğ‘¡) =ğœ† ğ‘(ağ‘¡)+(1âˆ’ğœ†) ğ‘ (xËœ ğ‘¡) â‰¥ ğœ†+(1âˆ’ğœ†) = 1.
ğ‘¡=1 ğ‘¡=1 ğ‘¡=1 ğ‘¡=1
Let I âˆˆ Î© be an arbitrary valid CFL sequence. We denote the hitting and switching costs of the robust
advicebyALG1hitting andALG1switch,respectively. Likewise,thehittingandswitchingcostoftheblack-box
adviceADVisdenotedbyADVhitting andADVswitch.
ThetotalcostofBaselineisupperboundedbythefollowing:
ğ‘‡ ğ‘‡+1
âˆ‘ï¸ âˆ‘ï¸
Baseline(I) = ğ‘“ ğ‘¡(xğ‘¡)+ âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥ â„“ 1(w),
ğ‘¡=1 ğ‘¡=1
ğ‘‡ ğ‘‡+1
âˆ‘ï¸ âˆ‘ï¸
= ğ‘“ ğ‘¡ (ğœ†ağ‘¡ +(1âˆ’ğœ†)xËœ ğ‘¡)+ âˆ¥ğœ†ağ‘¡ +(1âˆ’ğœ†)xËœ ğ‘¡ âˆ’ğœ†ağ‘¡âˆ’1âˆ’(1âˆ’ğœ†)xËœ ğ‘¡âˆ’1âˆ¥ â„“ 1(w),
ğ‘¡=1 ğ‘¡=1
ğ‘‡ ğ‘‡ ğ‘‡+1 ğ‘‡+1
âˆ‘ï¸ âˆ‘ï¸ âˆ‘ï¸ âˆ‘ï¸
â‰¤ ğœ† ğ‘“ ğ‘¡(ağ‘¡)+(1âˆ’ğœ†) ğ‘“ ğ‘¡(xËœ ğ‘¡)+ âˆ¥ğœ†ağ‘¡ âˆ’ğœ†ağ‘¡âˆ’1âˆ¥
â„“ 1(w)
+ âˆ¥(1âˆ’ğœ†)xËœ
ğ‘¡
âˆ’(1âˆ’ğœ†)xËœ ğ‘¡âˆ’1âˆ¥
â„“
1(w),
ğ‘¡=1 ğ‘¡=1 ğ‘¡=1 ğ‘¡=1
ğ‘‡+1 ğ‘‡+1
âˆ‘ï¸ âˆ‘ï¸
â‰¤ ğœ†ADVhitting(I)+(1âˆ’ğœ†)ALG1hitting(I)+ğœ† âˆ¥ağ‘¡ âˆ’ağ‘¡âˆ’1âˆ¥
â„“ 1(w)
+(1âˆ’ğœ†) âˆ¥xËœ
ğ‘¡
âˆ’xËœ ğ‘¡âˆ’1âˆ¥
â„“
1(w),
ğ‘¡=1 ğ‘¡=1
â‰¤ ğœ†ADVhitting(I)+(1âˆ’ğœ†)ALG1hitting(I)+ğœ†ADVswitch(I)+(1âˆ’ğœ†)ALG1switch(I),
â‰¤ ğœ†ADV(I)+(1âˆ’ğœ†)ALG1(I).
SinceALG1 â‰¤ ğ›¼ Â·OPT â‰¤ ğ›¼ Â·ADV,thisgivesthefollowing:
Baseline(I) â‰¤ ğœ†ADV(I)+(1âˆ’ğœ†)ğ›¼ADV(I), (23)
Baseline(I) â‰¤ (ğœ†+(1âˆ’ğœ†)ğ›¼) Â·ADV(I) (24)
Baseline(I) â‰¤ (1+ğœ–) Â·ADV(I). (25)
Furthermore,sinceADV â‰¤ğ‘ˆ +2ğ›½ â‰¤ OPT ,wehave:
ğ¿/(ğ‘ˆ+2ğ›½)
OPT(I)
Baseline(I) â‰¤ ğœ† +(1âˆ’ğœ†)ğ›¼OPT(I), (26)
ğ¿/(ğ‘ˆ+2ğ›½)
(cid:20)ğœ†(ğ‘ˆ +2ğ›½) (cid:21)
Baseline(I) â‰¤ +(1âˆ’ğœ†)ğ›¼ Â·OPT(I), (27)
ğ¿
(cid:18) (ğ‘ˆ+2ğ›½)/ğ¿(ğ›¼ âˆ’1âˆ’ğœ–)+ğ›¼ğœ–(cid:19)
Baseline(I) â‰¤ Â·OPT(I). (28)
(ğ›¼ âˆ’1)
Bycombining(25)and(28),weconcludethatBaselineis (1+ğœ–)-consistentwithrespecttoblack-box
(cid:16) (cid:17)
adviceADV,and (ğ‘ˆ+2ğ›½)/ğ¿(ğ›¼âˆ’1âˆ’ğœ–)+ğ›¼ğœ– -robust. â–¡
(ğ›¼âˆ’1)
26C.2 ProofofTheorem4.3
Inthissection,weproveTheorem4.3,whichshowsthatCLIPis (1+ğœ–)-consistentandğ›¾ğœ–-robustforCFL,
whereğ›¾ğœ– isdefinedasthesolutiontothefollowing(asin(8)):
ğ‘ˆ ğ›¾ğœ– (cid:18) ğ‘ˆ âˆ’ğ¿âˆ’2ğ›½ (cid:19)
ğ›¾ğœ– =ğœ– + âˆ’ (ğ‘ˆ âˆ’ğ¿)ln .
ğ¿ ğ¿ ğ‘ˆ âˆ’ğ‘ˆ/ğ›¾ğœ– âˆ’2ğ›½
ProofofTheorem4.3. We show the above result by separately considering consistency (the competitive
ratiowhenadviceiscorrect)androbustness(thecompetitiveratiowhenadviceisnotcorrect)inturn.
Recallthattheblack-boxadviceADVisdenotedbyadecisionağ‘¡ ateachtimeğ‘¡.Throughoutthefollowing
proof, we use shorthand notation CLIPğ‘¡ to denote the cost of CLIP up to timeğ‘¡, and ADVğ‘¡ to denote the
costofADVuptotimeğ‘¡. Westartwiththefollowinglemmatoproveconsistency.
LemmaC.1. CLIPis (1+ğœ–)-consistent.
Proof. First, we note that the constrained optimization enforces that the possible cost so far plus a com-
pulsory term is always within (1+ğœ–) of the advice. Formally, if time step ğ‘— âˆˆ [ğ‘‡] denotes the time step
marking the start of the compulsory trade, we have that the constraint given by (6) holds for every time
stepğ‘¡ âˆˆ [ğ‘—].
Thus,toshow(1+ğœ–)consistency,wemustresolvethecostduringthecompulsorytradeandshowthat
thefinalcumulativecostofCLIPisupperboundedby (1+ğœ–)ADV.
Let I âˆˆ Î© be an arbitrary valid CFL sequence. If the compulsory trade begins at time step ğ‘— < ğ‘‡,
bothCLIPandADVmustgreedilyfilltheirremainingutilizationduringthelastğ‘štimesteps [ğ‘—,ğ‘‡]. Thisis
assumedtobefeasible,andtheswitchingcostisassumedtobenegligibleaslongasğ‘šissufficientlylarge.
Let (1âˆ’ğ‘§(ğ‘—âˆ’1)) denotetheremaininglong-termconstraintthatmustbesatisfiedbyCLIPatthefinal
timestep,andlet (1âˆ’ğ´(ğ‘—âˆ’1)) denotetheremaininglong-termconstrainttobesatisfiedbyADV.
Weconsiderthefollowingtwocases,whichcorrespondtothecaseswhereCLIPhasunder-andover-
provisionedwithrespecttoADV,respectively.
Case1: CLIP(I) hasâ€œunderprovisionedâ€((1âˆ’ğ‘§(ğ‘—âˆ’1)) > (1âˆ’ğ´(ğ‘—âˆ’1))). Inthiscase,CLIPmustsatisfy
moreofthelong-termconstraintduringthecompulsorytradecomparedtoADV.
Fromtheprevioustimestep,weknowthatthefollowingconstraintholds:CLIPğ‘—âˆ’1+âˆ¥xğ‘—âˆ’1âˆ’ağ‘—âˆ’1âˆ¥
â„“
1(w)+
âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+(1âˆ’ğ´(ğ‘—âˆ’1))ğ¿+(ğ´(ğ‘—âˆ’1) âˆ’ğ‘§(ğ‘—âˆ’1))ğ‘ˆ â‰¤ (1+ğœ–) (cid:2) ADVğ‘—âˆ’1+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+(1âˆ’ğ´(ğ‘—âˆ’1))ğ¿(cid:3).
Let{xğ‘¡}
ğ‘¡âˆˆ[ğ‘—,ğ‘‡]
and{ağ‘¡}
ğ‘¡âˆˆ[ğ‘—,ğ‘‡]
denotethedecisionsmadebyCLIPandADVduringthecompulsorytrade,
respectively. Bydefinition,wehavethat(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(xğ‘¡) = (1âˆ’ğ‘§(ğ‘—âˆ’1)) and(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(ağ‘¡) = (1âˆ’ğ´(ğ‘—âˆ’1)).
Considering {ğ‘“ ğ‘¡(Â·)} ğ‘¡âˆˆ[ğ‘—,ğ‘‡], we know that by definition (cid:205)ğ‘‡
ğ‘¡=ğ‘—
ğ‘“ ğ‘¡(ağ‘¡) â‰¥ ğ¿(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(ağ‘¡), and by convex as-
sumptionsonthecostfunctions,(cid:205)ğ‘‡
ğ‘¡=ğ‘—
ğ‘“ ğ‘¡(xğ‘¡) â‰¤ (cid:205)ğ‘‡
ğ‘¡=ğ‘—
ğ‘“ ğ‘¡(ağ‘¡)+ğ‘ˆ((cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(xğ‘¡)âˆ’(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(ağ‘¡)).
NotethattheworstcaseforCLIPoccurswhen(cid:205)ğ‘‡
ğ‘¡=ğ‘—
ğ‘“ ğ‘¡(ağ‘¡) = ğ¿(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(ağ‘¡),asADVisabletosatisfythe
restofthelong-termconstraintatthebestpossibleprice.
27Bytheconstraintintheprevioustimestep,wehavethefollowing:
CLIPğ‘—âˆ’1+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+(1âˆ’ğ´(ğ‘—âˆ’1))ğ¿+(ğ´(ğ‘—âˆ’1) âˆ’ğ‘§(ğ‘—âˆ’1))ğ‘ˆ
â‰¤ (1+ğœ–)[ADVğ‘—âˆ’1+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+(1âˆ’ğ´(ğ‘—âˆ’1))ğ¿],
ğ‘‡ (cid:32) ğ‘‡ ğ‘‡ (cid:33)
âˆ‘ï¸ âˆ‘ï¸ âˆ‘ï¸
CLIPğ‘—âˆ’1+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+ğ¿ ğ‘(ağ‘¡)+ğ‘ˆ ğ‘(xğ‘¡)âˆ’ ğ‘(ağ‘¡)
ğ‘¡=ğ‘— ğ‘¡=ğ‘— ğ‘¡=ğ‘—
(cid:34) ğ‘‡ (cid:35)
âˆ‘ï¸
â‰¤ (1+ğœ–) ADVğ‘—âˆ’1+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+ğ¿ ğ‘(ağ‘¡) ,
ğ‘¡=ğ‘—
CLIP(I) â‰¤ (1+ğœ–) [ADV(I)].
Case2: CLIP(I) hasâ€œoverprovisionedâ€((1âˆ’ğ‘§(ğ‘—âˆ’1)) â‰¤ (1âˆ’ğ´(ğ‘—âˆ’1))). Inthiscase, CLIPmustsatisfy
lessofthelong-termconstraintduringthecompulsorytradecomparedtoADV.
Fromtheprevioustimestep,weknowthatthefollowingconstraintholds:CLIPğ‘—âˆ’1+âˆ¥xğ‘—âˆ’1âˆ’ağ‘—âˆ’1âˆ¥
â„“
1(w)+
âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+(1âˆ’ğ´(ğ‘—âˆ’1))ğ¿+(ğ´(ğ‘—âˆ’1) âˆ’ğ‘§(ğ‘—âˆ’1))ğ‘ˆ â‰¤ (1+ğœ–) (cid:2) ADVğ‘—âˆ’1+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+(1âˆ’ğ´(ğ‘—âˆ’1))ğ¿(cid:3).
Let{xğ‘¡}
ğ‘¡âˆˆ[ğ‘—,ğ‘‡]
and{ağ‘¡}
ğ‘¡âˆˆ[ğ‘—,ğ‘‡]
denotethedecisionsmadebyCLIPandADVduringthecompulsorytrade,
respectively. Bydefinition,wehavethat(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(xğ‘¡) = (1âˆ’ğ‘§(ğ‘—âˆ’1)) and(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(ağ‘¡) = (1âˆ’ğ´(ğ‘—âˆ’1)).
Considering {ğ‘“ ğ‘¡(Â·)} ğ‘¡âˆˆ[ğ‘—,ğ‘‡], we know that by definition, (cid:205)ğ‘‡
ğ‘¡=ğ‘—
ğ‘“ ğ‘¡(xğ‘¡) â‰¥ ğ¿(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(xğ‘¡), and (cid:205)ğ‘‡
ğ‘¡=ğ‘—
ğ‘“ ğ‘¡(ağ‘¡) â‰¥
ğ¿(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(ağ‘¡). Byconvexity,because(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(xğ‘¡) â‰¤ (cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(ağ‘¡),(cid:205)ğ‘‡
ğ‘¡=ğ‘—
ğ‘“ ğ‘¡(xğ‘¡) â‰¤ (cid:205)ğ‘‡
ğ‘¡=ğ‘—
ğ‘“ ğ‘¡(ağ‘¡).
Bytheconstraintintheprevioustimestep,wehave:
CLIPğ‘—âˆ’1+âˆ¥xğ‘—âˆ’1âˆ’ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+(1âˆ’ğ‘§(ğ‘—âˆ’1))ğ¿
=
ADVğ‘—âˆ’1+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+(1âˆ’ğ´(ğ‘—âˆ’1))ğ¿
CLIPğ‘—âˆ’1+âˆ¥xğ‘—âˆ’1âˆ’ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+ğ¿(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(xğ‘¡)
â‰¤ (1+ğœ–).
ADVğ‘—âˆ’1+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+ğ¿(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(ağ‘¡)
Letğ‘¦ = (cid:205)ğ‘‡
ğ‘¡=ğ‘—
ğ‘“ ğ‘¡(xğ‘¡) âˆ’ğ¿(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(xğ‘¡), and letğ‘¦â€² = (cid:205)ğ‘‡
ğ‘¡=ğ‘—
ğ‘“ ğ‘¡(ağ‘¡) âˆ’ğ¿(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(ağ‘¡). By definition,ğ‘¦ â‰¥ 0 and
ğ‘¦â€² â‰¥ 0.
Note that CLIPğ‘—âˆ’1 + âˆ¥xğ‘—âˆ’1 âˆ’ ağ‘—âˆ’1âˆ¥ â„“ 1(w) + âˆ¥ağ‘—âˆ’1âˆ¥ â„“ 1(w) + (1 âˆ’ğ‘§(ğ‘—âˆ’1))ğ¿ +ğ‘¦ â‰¥ CLIP(I) and ADVğ‘—âˆ’1 +
âˆ¥ağ‘—âˆ’1âˆ¥ â„“ 1(w) +ğ¿(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(ağ‘¡)+ğ‘¦â€² = ADV(I).
Furthermore,bydefinitionandconvexityofthecostfunctions ğ‘“ (Â·),wehavethatğ‘¦ â‰¤ğ‘¦â€².
ğ‘¡
Combinedwiththeconstraintfromtheprevioustimestep,wehavethefollowingbound:
CLIP(I)
â‰¤
CLIPğ‘—âˆ’1+âˆ¥xğ‘—âˆ’1âˆ’ağ‘—âˆ’1âˆ¥ â„“ 1(w) +âˆ¥ağ‘—âˆ’1âˆ¥ â„“ 1(w) +(1âˆ’ğ‘§(ğ‘—âˆ’1))ğ¿+ğ‘¦
ADV(I) ADVğ‘—âˆ’1+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+(1âˆ’ğ´(ğ‘—âˆ’1))ğ¿+ğ‘¦â€²
â‰¤
CLIPğ‘—âˆ’1+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+ğ¿(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(xğ‘¡)
â‰¤ (1+ğœ–).
ADVğ‘—âˆ’1+âˆ¥ağ‘—âˆ’1âˆ¥
â„“ 1(w)
+ğ¿(cid:205)ğ‘‡ ğ‘¡=ğ‘—ğ‘(ağ‘¡)
Thus, by combining the bounds in each of the above two cases, the result follows, and we conclude
thatCLIPis (1+ğœ–)-consistentwithaccurateadvice. â–¡
HavingprovedtheconsistencyofCLIP,weproceedtoshowrobustnessinthenextlemma.
LemmaC.2. CLIPisğ›¾ğœ– -robust,whereğ›¾ğœ– isasdefinedin(8).
Proof. Letğœ– âˆˆ (0,ğ›¼ âˆ’1] bethetargetconsistency(recallingthatCLIPis (1+ğœ–) consistent),andletI âˆˆ Î©
denoteanarbitraryvalidCFLsequence.
ToprovetherobustnessofCLIP,weconsidertwoâ€œbadcasesâ€fortheadviceADV(I),andshowthatin
theworst-case,CLIPâ€™scompetitiveratioisboundedbyğ›¾ğœ–.
28Case1: ADV(I) isâ€œinactiveâ€. ConsiderthecasewhereADVacceptsnothingduringthemainsequence
andinsteadsatisfiestheentirelong-termconstraintinthefinaltimestep. Intheworst-case,thisgivesthat
ADV(I) =ğ‘ˆ +2ğ›½.
Basedontheconsistencyconstraint(andusingthefactthatCLIPwillalwaysbeâ€œoverprocuringâ€w.r.t.
ADVthroughoutthemainsequence),wecanderiveanupperboundontheamountthatCLIPisallowedto
acceptfromtherobustpseudo-costminimization. Recallthefollowingconstraint:
CLIPğ‘¡âˆ’1+ğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥
â„“ 1(w)
+âˆ¥xğ‘¡ âˆ’ağ‘¡âˆ¥
â„“ 1(w)
+âˆ¥ağ‘¡âˆ¥
â„“ 1(w)
+(1âˆ’ğ‘§(ğ‘¡âˆ’1) âˆ’ğ‘(xğ‘¡))ğ¿
(cid:104) (cid:105)
â‰¤ (1+ğœ–) ADVğ‘¡ +âˆ¥ağ‘¡âˆ¥ â„“ 1(w) +(1âˆ’ğ´(ğ‘¡))ğ¿ .
Proposition C.3. ğ‘§ is an upper bound on the amount that CLIP can accept from the pseudo-cost mini-
PCM
mizationwithoutviolating (1+ğœ–) consistency,andisdefinedas:
(cid:20) ğ‘ˆ âˆ’ğ¿âˆ’2ğ›½ (cid:21)
ğ‘§ =ğ›¾ğœ–ln
PCM ğ‘ˆ âˆ’ğ‘ˆ/ğ›¾ğœ– âˆ’2ğ›½
Proof. Consider an arbitrary time step ğ‘¡. When CLIP is not allowed to accept anything more from the
robust pseudo-cost minimization, we have thatğ‘(xğ‘¡) is restricted to be 0 (recall that ağ‘¡ = 0 for any time
stepsbeforeğ‘‡,becausetheadviceisassumedtobeinactive).
Bydefinition,sinceanycostfunctionsacceptedinCLIPğ‘¡âˆ’1canbeattributedtotherobustpseudo-cost
minimization,wehavethefollowingintheworst-case:
âˆ« ğ‘§(ğ‘¡âˆ’1)
CLIPğ‘¡âˆ’1 = ğœ™ğœ– (ğ‘¢)ğ‘‘ğ‘¢ +ğ›½ğ‘§(ğ‘¡âˆ’1).
0
Combiningtheabovewiththeleft-handsideoftheconsistencyconstraint,wehavethefollowingby
observingthatxğ‘¡ = 0andağ‘¡ = 0,andtheswitchingcosttoâ€œramp-upâ€isabsorbedintothepseudo-costğœ™:
âˆ« ğ‘§(ğ‘¡âˆ’1)
CLIPğ‘¡âˆ’1+(1âˆ’ğ‘§(ğ‘¡âˆ’1))ğ¿ = ğœ™ğœ– (ğ‘¢)ğ‘‘ğ‘¢ +ğ›½ğ‘§(ğ‘¡âˆ’1) +(1âˆ’ğ‘§(ğ‘¡âˆ’1))ğ¿.
0
Asstated,letğ‘§(ğ‘¡âˆ’1) =ğ‘§ PCM. Thenbypropertiesofthepseudo-cost,
âˆ« ğ‘§ PCM
CLIPğ‘¡âˆ’1+(1âˆ’ğ‘§ PCM)ğ¿ = ğœ™(ğ‘¢)ğ‘‘ğ‘¢ +ğ›½ğ‘§ PCM+(1âˆ’ğ‘§ PCM)ğ‘ˆ +(1âˆ’ğ‘§ PCM)ğ¿âˆ’(1âˆ’ğ‘§ PCM)ğ‘ˆ,
0
=ğ›¾ğœ– [ğœ™ğœ– (ğ‘§ PCM)âˆ’ğ›½] +(1âˆ’ğ‘§ PCM)ğ¿âˆ’(1âˆ’ğ‘§ PCM)ğ‘ˆ,
(cid:18) (cid:20) ğ‘ˆ âˆ’ğ¿âˆ’2ğ›½ (cid:21)(cid:19)
=ğ›¾ğœ–ğ¿+(ğ¿âˆ’ğ‘ˆ) 1âˆ’ğ›¾ğœ–ln ,
ğ‘ˆ âˆ’ğ‘ˆ/ğ›¾ğœ– âˆ’2ğ›½
(cid:20) ğ‘ˆ âˆ’ğ¿âˆ’2ğ›½ (cid:21)
=ğ›¾ğœ–ğ¿+ğ¿âˆ’ğ‘ˆ âˆ’(ğ¿âˆ’ğ‘ˆ)ğ›¾ğœ–ln .
ğ‘ˆ âˆ’ğ‘ˆ/ğ›¾ğœ– âˆ’2ğ›½
Substitutingforthedefinitionofğ›¾ğœ–,weobtain:
(cid:20) ğ‘ˆ âˆ’ğ¿âˆ’2ğ›½ (cid:21)
CLIPğ‘¡âˆ’1+(1âˆ’ğ‘§ PCM)ğ¿ =ğ›¾ğœ–ğ¿+ğ¿âˆ’ğ‘ˆ âˆ’(ğ¿âˆ’ğ‘ˆ)ğ›¾ğœ–ln
ğ‘ˆ âˆ’ğ‘ˆ/ğ›¾ğœ– âˆ’2ğ›½
,
(cid:20) (cid:20) ğ‘ˆ âˆ’ğ¿âˆ’2ğ›½ (cid:21)(cid:21) (cid:20) ğ‘ˆ âˆ’ğ¿âˆ’2ğ›½ (cid:21)
= ğœ–ğ¿+ğ‘ˆ âˆ’ğ›¾ğœ– (ğ‘ˆ âˆ’ğ¿)ln +ğ¿âˆ’ğ‘ˆ +(ğ‘ˆ âˆ’ğ¿)ğ›¾ğœ–ln ,
ğ‘ˆ âˆ’ğ‘ˆ/ğ›¾ğœ– âˆ’2ğ›½ ğ‘ˆ âˆ’ğ‘ˆ/ğ›¾ğœ– âˆ’2ğ›½
=ğœ–ğ¿+ğ¿ = (1+ğœ–)ğ¿.
Thiscompletestheproposition,since(1+ğœ–)ğ¿isexactlytheright-handsideoftheconsistencyconstraint
(notethat (1+ğœ–) (cid:2) ADVğ‘¡ +âˆ¥ağ‘¡âˆ¥ â„“ 1(w) +(1âˆ’ğ´ ğ‘¡)ğ¿(cid:3) = (1+ğœ–)ğ¿). â–¡
29If CLIP is constrained to use at most ğ‘§ PCM of its utilization to be robust, the remaining (1 âˆ’ğ‘§ PCM)
utilization must be used for the compulsory trade and/or to follow ADV. Thus, we have the following
worst-casecompetitiveratioforCLIP,specificallyforCase2:
CLIP(I)
âˆ« 0ğ‘§ PCMğœ™ğœ–(ğ‘¢)ğ‘‘ğ‘¢ +ğ›½ğ‘§ PCM+(1âˆ’ğ‘§ PCM)ğ‘ˆ
â‰¤
OPT(I) ğ¿
Bythedefinitionofğœ™ğœ–(ğ‘),wehavethefollowing:
CLIP(I)
âˆ« 0ğ‘§ PCMğœ™ğœ–(ğ‘¢)ğ‘‘ğ‘¢ +ğ›½ğ‘§ PCM+(1âˆ’ğ‘§ PCM)ğ‘ˆ
â‰¤
OPT(I) ğ¿
â‰¤
ğ›¾ğœ– [ğœ™ğœ–(ğ‘§ PCM)âˆ’ğ›½]
â‰¤
ğ›¾ğœ– [ğ¿+ğ›½ âˆ’ğ›½]
â‰¤
ğ›¾ğœ–.
ğ¿ ğ¿
Case2: ADV(I) isâ€œoveractiveâ€. WenowconsiderthecasewhereADVacceptsbadcostfunctionswhich
which it â€œshould notâ€ accept (i.e. ADV(I) â‰« OPT(I)). Let ADV(I) = ğ‘£ â‰« OPTğ‘‡ (i.e. the final total hitting
andswitchingcostofADVisğ‘£ forsomeğ‘£ âˆˆ [ğ¿,ğ‘ˆ +2ğ›½],andthisismuchgreaterthantheoptimalsolution).
This is without loss of generality, since we can assume thatğ‘£ is the â€œbest cost functionâ€ accepted by
ADVandtheconsistencyratiochangesstrictlyinfavorofADV. Basedontheconsistencyconstraint,wecan
derivealowerboundontheamountthatCLIPmust acceptfromADVinordertostay (1+ğœ–)-consistent.
Todothis,weconsiderthefollowingsub-cases:
â€¢Sub-case2.1: Letğ‘£ â‰¥ ğ‘ˆ+ğ›½.
1+ğœ–
Inthissub-case,CLIPcanfullyignoretheadvice,becausethefollowingconsistencyconstraintisnever
binding(notethatADVğ‘¡ â‰¥ ğ‘ˆ 1++ ğœ–ğ›½ğ´(ğ‘¡)):
CLIPğ‘¡âˆ’1+ğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥
â„“ 1(w)
+âˆ¥xğ‘¡ âˆ’ağ‘¡âˆ¥
â„“ 1(w)
+âˆ¥ağ‘¡âˆ¥
â„“ 1(w)
+(1âˆ’ğ´(ğ‘¡))ğ¿+(ğ´(ğ‘¡) âˆ’ğ‘§(ğ‘¡âˆ’1) âˆ’ğ‘(xğ‘¡))ğ‘ˆ
(cid:104) (cid:105)
â‰¤ (1+ğœ–) ADVğ‘¡ +âˆ¥ağ‘¡âˆ¥ â„“ 1(w) +(1âˆ’ğ´(ğ‘¡))ğ¿ ,
(cid:104) (cid:105)
(1âˆ’ğ´(ğ‘¡))ğ¿+(ğ´(ğ‘¡))ğ‘ˆ +âˆ¥ağ‘¡âˆ¥ â„“ 1(w) â‰¤ (1+ğœ–) ADVğ‘¡ +âˆ¥ağ‘¡âˆ¥ â„“ 1(w) +(1âˆ’ğ´(ğ‘¡))ğ¿ ,
(cid:20)ğ‘ˆ +ğ›½ (cid:21)
(1âˆ’ğ´(ğ‘¡))ğ¿+ğ‘ˆğ´(ğ‘¡) +ğ›½ğ´(ğ‘¡) â‰¤ (1+ğœ–) ğ´(ğ‘¡) +(1âˆ’ğ´(ğ‘¡))ğ¿
1+ğœ–
â€¢Sub-case2.2: Letğ‘£ âˆˆ (ğ¿, ğ‘ˆ+ğ›½ ).
1+ğœ–
Toremain (1+ğœ–) consistent,CLIPmustacceptsomeoftheseâ€œbadcostfunctionsâ€denotedbyğ‘£ inthe
worst-case. We would like to derive a lower bound ğ‘§ , such that ğ‘§ describes the minimum amount
ADV ADV
thatCLIPmustacceptfromADVinordertoalwayssatisfythe (1+ğœ–) consistencyconstraint.
Basedontheconsistencyconstraint,wehavethefollowing:
CLIPğ‘¡âˆ’1+ğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥
â„“ 1(w)
+âˆ¥xğ‘¡ âˆ’ağ‘¡âˆ¥
â„“ 1(w)
+âˆ¥ağ‘¡âˆ¥
â„“ 1(w)
+(1âˆ’ğ´(ğ‘¡))ğ¿+(ğ´(ğ‘¡) âˆ’ğ‘§(ğ‘¡âˆ’1) âˆ’ğ‘(xğ‘¡))ğ‘ˆ
(cid:104) (cid:105)
â‰¤ (1+ğœ–) ADVğ‘¡ +âˆ¥ağ‘¡âˆ¥ â„“ 1(w) +(1âˆ’ğ´(ğ‘¡))ğ¿ .
Welet ğ‘“ ğ‘¡(xğ‘¡)+âˆ¥xğ‘¡ âˆ’xğ‘¡âˆ’1âˆ¥
â„“ 1(w)
+âˆ¥xğ‘¡ âˆ’ağ‘¡âˆ¥
â„“ 1(w)
+âˆ¥ağ‘¡âˆ¥
â„“ 1(w)
â‰¤ ğ‘£ğ‘(xğ‘¡) foranyxğ‘¡ :ğ‘(xğ‘¡) <ğ‘(ağ‘¡),which
holdsbyconvexityofthecostfunctions ğ‘“ ğ‘¡(Â·) andaprevailingassumptionthatğ‘(xğ‘¡) â‰¤ ğ‘(ağ‘¡) fortheâ€œbad
costfunctionsâ€acceptedbyADV. Notethatğ‘£ âˆ’ğ‘ˆ isnegative(bytheconditionofSub-case1.2):
30(cid:104) (cid:105)
CLIPğ‘¡âˆ’1+ğ‘£ğ‘(xğ‘¡)+ğ¿âˆ’ğ¿ğ´(ğ‘¡) +ğ‘ˆğ´(ğ‘¡) âˆ’ğ‘ˆğ‘§(ğ‘¡âˆ’1) âˆ’ğ‘ˆxğ‘¡ â‰¤ (1+ğœ–) ğ‘£ğ´(ğ‘¡âˆ’1) +ğ‘£ğ‘(ağ‘¡)+ğ¿âˆ’ğ¿ğ´(ğ‘¡) ,
(cid:104) (cid:105)
ğ‘£ğ‘(xğ‘¡)âˆ’ğ‘ˆxğ‘¡ â‰¤ (1+ğœ–) ğ‘£ğ´(ğ‘¡âˆ’1) +ğ‘£ğ‘(ağ‘¡)+ğ¿âˆ’ğ¿ğ´(ğ‘¡) âˆ’CLIPğ‘¡âˆ’1âˆ’ğ¿+ğ¿ğ´(ğ‘¡) âˆ’ğ‘ˆğ´(ğ‘¡) +ğ‘ˆğ‘§(ğ‘¡âˆ’1),
(cid:104) (cid:105)
ğ‘£ğ‘(xğ‘¡)âˆ’ğ‘ˆxğ‘¡ â‰¤ ğ‘£ğ´(ğ‘¡) âˆ’ğ‘ˆğ´(ğ‘¡) âˆ’CLIPğ‘¡âˆ’1+ğ‘ˆğ‘§(ğ‘¡âˆ’1) +ğœ– ğ‘£ğ´(ğ‘¡âˆ’1) +ğ‘£ğ‘(ağ‘¡)+ğ¿âˆ’ğ¿ğ´(ğ‘¡) ,
ğ‘£ğ´(ğ‘¡) âˆ’ğ‘ˆğ´(ğ‘¡) âˆ’CLIPğ‘¡âˆ’1+ğ‘ˆğ‘§(ğ‘¡âˆ’1) +ğœ– (cid:2)ğ‘£ğ´(ğ‘¡) +ğ¿âˆ’ğ¿ğ´(ğ‘¡)(cid:3)
xğ‘¡ â‰¥
ğ‘£ âˆ’ğ‘ˆ
.
Intheeventthatğ´(ğ‘¡âˆ’1) = 0(i.e. nothinghasbeenacceptedsofarbyeitherADVorCLIP),wehavethe
following:
xğ‘¡ â‰¥
ğ‘£ğ‘(ağ‘¡)âˆ’ğ‘ˆğ‘(ağ‘¡)+ ğ‘£ğœ– âˆ’[ğ‘£ ğ‘ˆğ‘(ağ‘¡)+ğ¿âˆ’ğ¿ğ‘(ağ‘¡)]
,
xğ‘¡ â‰¥ ağ‘¡ âˆ’
ğœ– [ğ‘£ğ‘(ağ‘¡) ğ‘ˆ+ âˆ’ğ¿ ğ‘£âˆ’ğ¿ğ‘(ağ‘¡)]
.
Througharecursivedefinition,wecanshowthatforanyğ´(ğ‘¡),giventhatCLIPhasacceptedğ‘§(ğ‘¡âˆ’1) of
ADVâ€™ssuggestedpricessofar,itmustsetxğ‘¡ suchthat:
ğ‘§(ğ‘¡) â‰¥ğ‘§(ğ‘¡âˆ’1) +ağ‘¡ âˆ’
ğœ– [ğ‘£ğ‘(ağ‘¡) ğ‘ˆ+ âˆ’ğ¿ ğ‘£âˆ’ğ¿ğ‘(ağ‘¡)]
.
Continuingtheassumptionthatğ‘£isconstant,ifCLIPhasacceptedğ‘§(ğ‘¡âˆ’1) thusfar,wehavethefollowing
ifweassumethattheacceptanceuptothispointhappenedinasingleprevioustimestepğ‘š:
ğ‘(xğ‘¡) â‰¥ ğ´(ğ‘¡)
+ğ‘ˆğ‘(xğ‘š)âˆ’CLIPğ‘¡âˆ’1 ğ‘£+ âˆ’ğœ– ğ‘ˆ(cid:2)ğ‘£ğ´(ğ‘¡) +ğ¿âˆ’ğ¿ğ´(ğ‘¡)(cid:3)
,
ğ‘(xğ‘¡)
â‰¥ğ‘(ağ‘¡)+ğ‘(ağ‘š)+ğ‘ˆğ‘(xğ‘š)âˆ’ğ‘£ğ‘(xğ‘š)+ğœ– [ğ‘£(ğ‘(ağ‘¡ ğ‘£)+ âˆ’ğ‘ ğ‘ˆ(ağ‘š))+ğ¿âˆ’ğ¿(ğ‘(ağ‘¡)+ğ‘(ağ‘š))]
,
ğ‘(xğ‘¡) â‰¥ğ‘(ağ‘¡)+ğ‘(ağ‘š)âˆ’xğ‘š +
ğœ– [ğ‘£(ğ‘(ağ‘¡)+ğ‘(ağ‘š)) ğ‘£+ âˆ’ğ¿ ğ‘ˆâˆ’ğ¿(ğ‘(ağ‘¡)+ğ‘(ağ‘š))]
,
ğ‘(xğ‘¡)+ğ‘(xğ‘š) â‰¥ğ‘(ağ‘¡)+ğ‘(ağ‘š)+
ğœ– [ğ‘£(ğ‘(ağ‘¡)+ğ‘(ağ‘š)) ğ‘£+ âˆ’ğ¿ ğ‘ˆâˆ’ğ¿(ğ‘(ağ‘¡)+ğ‘(ağ‘š))]
,
ğœ– (cid:2)ğ‘£ğ´(ğ‘¡) +ğ¿âˆ’ğ¿ğ´(ğ‘¡)(cid:3)
ğ‘§(ğ‘¡) â‰¥ ğ´(ğ‘¡) + .
ğ‘£ âˆ’ğ‘ˆ
Thisgivesintuitionintothedesiredğ‘§ bound. Theabovedescribesandmotivatesthattheaggregate
ADV
acceptancebyCLIPatanygiventimestepğ‘¡ mustsatisfyalowerbound. Considerthattheworstcasefor
Sub-case 1.2 occurs when all of theğ‘£ prices accepted by ADV arrive first, before any prices which would
beconsideredbythepseudo-costminimization. Thenletğ´(ğ‘¡) = 1forsomearbitrarytimestepğ‘¡, andwe
havethefollowinglowerboundonğ‘§ :
ADV
ğ‘£ğœ–
ğ‘§ â‰¥ 1âˆ’ .
ADV ğ‘ˆ âˆ’ğ‘£
If CLIP is forced to useğ‘§ of its utilization to be (1+ğœ–) consistent against ADV, that leaves at most
ADV
(1âˆ’ğ‘§ ) utilizationforrobustness.
ADV
Wedefineğ‘§â€² = min(1âˆ’ğ‘§ ADV,ğ‘§ PCM) andconsiderthefollowingtwocases.
31â€¢Sub-case2.2.1: ifğ‘§â€² =ğ‘§ PCM,theworst-casecompetitiveratioisboundedbythefollowing. Notethatif
ğ‘§â€² =ğ‘§ PCM,theamountofutilizationthatCLIPcanusetoâ€œberobustâ€isexactlythesameasinCase1:
CLIP(I)
â‰¤
âˆ« 0ğ‘§ PCMğœ™(ğ‘¢)ğ‘‘ğ‘¢ +ğ›½ğ‘§ PCM+(1âˆ’ğ‘§ ADVâˆ’ğ‘§ PCM)ğ‘ˆ +ğ‘§ ADVğ‘£
,
OPT(I) ğ¿
â‰¤
âˆ« 0ğ‘§ PCMğœ™(ğ‘¢)ğ‘‘ğ‘¢ +ğ›½ğ‘§ PCM+(1âˆ’ğ‘§ PCM)ğ‘ˆ
â‰¤ğ›¾ğœ–.
ğ¿
â€¢ Sub-case 2.2.2: if ğ‘§â€² = 1 âˆ’ğ‘§ , the worst-case competitive ratio is bounded by the following. Note
ADV
that CLIP cannot useğ‘§ PCM of its utilization for robustness, so the following bound assumes that the cost
functions accepted by CLIP are bounded by the worst (1 âˆ’ ğ‘§ ) fraction of the pseudo-cost threshold
ADV
functionğœ™ğœ– (whichfollowssinceğœ™ğœ– isnon-decreasingonğ‘§ âˆˆ [0,1]):
CLIP(I)
â‰¤
âˆ« 01âˆ’ğ‘§
ADVğœ™(ğ‘¢)ğ‘‘ğ‘¢ +ğ›½(1âˆ’ğ‘§ ADV)+ğ‘§ ADVğ‘£
.
OPT(I) ğ¿
Notethatifğ‘§â€² = 1âˆ’ğ‘§ ADV,weknowthat1âˆ’ğ‘§
ADV
<ğ‘§ PCM,whichfurthergivesthefollowingbydefinition
ofğ‘§ :
ADV
ğ‘£ğœ–
1âˆ’ğ‘§
PCM
< 1âˆ’ ,
ğ‘ˆ âˆ’ğ‘£
ğ‘£ğœ– < (ğ‘ˆ âˆ’ğ‘£)ğ‘§ PCM,
ğ‘ˆ
ğ‘£ < .
(1+ ğœ– )
ğ‘§
PCM
(cid:18) (cid:19)
Sinceğ‘§ ğ‘£ = (1âˆ’ğ‘§ PCM)ğ‘ˆ ,wehavethefollowing:
ADV 1+ ğœ–
ğ‘§PCM
(cid:18) (cid:19)
âˆ« 1âˆ’ğ‘§ ADVğœ™(ğ‘¢)ğ‘‘ğ‘¢ +ğ›½(1âˆ’ğ‘§ )+ (1âˆ’ğ‘§ PCM)ğ‘ˆ
CLIP(I)
â‰¤
0 ADV 1+ ğ‘§Pğœ–
CM ,
OPT(I) ğ¿
â‰¤
âˆ« 0ğ‘§ PCMğœ™(ğ‘¢)ğ‘‘ğ‘¢ +ğ›½ğ‘§ PCM+(1âˆ’ğ‘§ PCM)ğ‘ˆ
â‰¤ğ›¾ğœ–.
ğ¿
Thus, by combining the bounds in each of the above two cases, the result follows, and we conclude
thatCLIPisğ›¾ğœ–-robustforanyadviceADV. â–¡
Having proven Lemma C.1 (consistency) and Lemma C.2 (robustness), the statement of Theorem 4.3
followsâ€“CLIPis (1+ğœ–)-consistentandğ›¾ğœ–-robustgivenanyadviceforCFL. â–¡
C.3 ProofofCorollary4.4
Inthissection,weproveCorollary4.4,whichshowsthatCLIPis(1+ğœ–)-consistentandğ›¾ğœ–-robustforMAL,
whereğ›¾ğœ– isdefinedin(8).
ProofofCorollary4.4. We show the above result by separately considering consistency (the competitive
ratiowhenadviceiscorrect)androbustness(thecompetitiveratiowhenadviceisnotcorrect),relyingon
theproofofTheorem4.3.
Consistency. Bydefinition,MALonaweightedstarmetricisidenticaltoaninstanceofconvexfunction
chasingwithalong-termconstrainton (Î” ,âˆ¥Â·âˆ¥ ),whereÎ” istheğ‘›-pointsimplexinRğ‘› and âˆ¥Â·âˆ¥
ğ‘› â„“ 1(wâ€²) ğ‘› â„“ 1(wâ€²)
32istheweightedâ„“
1
norm,withweightswâ€² givenbythecorrespondingedgeweightintheunderlyingstar
metric.
ObservethattheconsistencyproofgiveninLemmaC.1holdswhentheconsistencyconstraintateach
timestepisdefinedasfollows:
CLIPğ‘¡âˆ’1+ğ‘“ğ‘¡(x)+âˆ¥xâˆ’xğ‘¡âˆ’1âˆ¥â„“1(wâ€²)+âˆ¥xâˆ’ağ‘¡âˆ¥â„“1(wâ€²)+âˆ¥ağ‘¡âˆ¥â„“1(wâ€²)+(1âˆ’ğ‘§(ğ‘¡âˆ’1) âˆ’ğ‘(x))ğ¿+max((ğ´(ğ‘¡) âˆ’ğ‘§(ğ‘¡âˆ’1) âˆ’ğ‘(x)), 0)(ğ‘ˆ âˆ’ğ¿)
(29)
â‰¤ (1+ğœ–)[ADVğ‘¡+âˆ¥ağ‘¡âˆ¥â„“1(wâ€²)+(1âˆ’ğ´(ğ‘¡))ğ¿],
where x and a denote decisions by CLIP and ADV (respectively) supported on Î” ğ‘›. Thus, since the consis-
tencyproofinLemmaC.1exactlyholdsundertheCFLvectorspacecorrespondingtoMAL,weconclude
thatCLIPis (1+ğœ–)-consistentforMAL.
Robustness. First, we note that the robustness proof given in Lemma C.2 assumes OPT does not pay
any switching cost. This implies that the proof of Lemma C.2 meets the conditions of Proposition 2.3,
which states that any performance bound for an arbitrary ALG solving CFL which assumes OPT pays no
switchingcosttranslatestoanidenticalboundforMAL,wheretheproblemâ€™sparameterscanberecovered
byconstructingacorrespondingCFLinstanceaccordingtoLemma2.2.
Thus,byProposition2.3,weconcludethatCLIPisğ›¾ğœ–-robustforMAL,whereğ›¾ğœ– isdefinedin(8).
Bycombiningthetworesults,thestatementofCorollary4.4followsâ€“CLIPis (1+ğœ–)-consistentand
ğ›¾ğœ–-robustgivenanyadviceADVforMAL. â–¡
C.4 ProofofTheorem4.5
In this section, we prove Theorem 4.5, which shows that any (1+ğœ–)-consistent algorithm for CFL is at
leastğ›¾ğœ–-robust,whereğ›¾ğœ– isasdefinedin(8).
ProofofTheorem4.5. To show this result, we leverage the same special family ofğ‘¦-adversaries for CFL
definedinDefinitionB.4,whereğ‘¦ âˆˆ [ğ¿,ğ‘ˆ]. Recallthatğ‘˜ = argmax ğ‘–âˆˆ[ğ‘‘]wğ‘–,wherewistheweightvector
for âˆ¥Â·âˆ¥ .
â„“ 1(w)
AsintheproofofTheorem3.4,wenotethatforadversaryA ğ‘¦,theoptimalofflinesolutionisOPT(A ğ‘¦) =
ğ‘¦+2ğ›½/ğ‘š,andthatasğ‘š growslarge,OPT(A ğ‘¦) â†’ğ‘¦.
Againsttheseadversaries,weconsidertwotypesofadviceâ€“thefirstisbad advice,whichsetsağ‘¡ = 0
foralltimestepsğ‘¡ <ğ‘‡ (i.e.,beforethecompulsorytrade),incurringafinalcostofğ‘ˆ +2ğ›½.
Ontheotherhand,goodadvicesetsağ‘¡ = 0foralltimestepsuptothefirsttimestepwhenğ‘¦isrevealed,
atwhichpointitsetsağ‘˜
ğ‘¡
= 1/ğ‘š toachievefinalcostADV(A ğ‘¦) = OPT(A ğ‘¦) =ğ‘¦+2ğ›½/ğ‘š.
We let ğ‘”(ğ‘¦) denote a robust conversion function [ğ¿,ğ‘ˆ] â†’ [0,1], which fully quantifies the actions
of a learning-augmented algorithm LALG playing against adaptive adversary A ğ‘¦, where ğ‘”(ğ‘¦) gives the
progresstowardsthelong-termconstraintundertheinstanceA before(either)thecompulsorytradeor
ğ‘¦
theblack-boxadvicesetsağ‘˜
ğ‘¡
> 0. Notethatforlargeğ‘¤,theadaptiveadversaryA
ğ‘¦âˆ’ğ›¿
isequivalenttofirst
playingA (besidesthelasttwobatchesofcostfunctions),andthenprocessingbatcheswithcostfunctions
ğ‘¦
Downğ‘¤ ğ‘¦+1(x) and Up(x). Since LALG is deterministic and the conversion is unidirectional (irrevocable),
wemusthavethatğ‘”(ğ‘¦âˆ’ğ›¿) â‰¥ğ‘”(ğ‘¦),i.e.ğ‘”(ğ‘¦) isnon-increasingin [ğ¿,ğ‘ˆ].
AsintheproofofTheorem3.4,theadaptivenatureofeachğ‘¦-adversaryforcesanyalgorithmtoincur
aswitchingcostproportionaltoğ‘”(ğ‘¦),specificallydenotedby2ğ›½ğ‘”(ğ‘¦).
Foranyğ›¾-robustonlinealgorithmLALGgivenanyarbitraryblack-boxadvice,thefollowingmusthold:
LALG(A ğ‘¦) â‰¤ğ›¾OPT(A ğ‘¦) =ğ›¾ğ‘¦, âˆ€ğ‘¦ âˆˆ [ğ¿,ğ‘ˆ].
âˆ« ğ‘¦
ThecostofLALGwithconversionfunctionğ‘”onaninstanceA ğ‘¦isLALG(A ğ‘¦) =ğ‘”(ğ‘ˆ/ğ›¾)ğ‘ˆ/ğ›¾âˆ’ ğ‘¢ğ‘‘ğ‘”(ğ‘¢)+
ğ‘ˆ/ğ›¾
2ğ›½ğ‘”(ğ‘¦)+(1âˆ’ğ‘”(ğ‘¦))ğ‘ˆ,whereğ‘¢ğ‘‘ğ‘”(ğ‘¢) isthecostofbuyingğ‘‘ğ‘”(ğ‘¢) utilizationatpriceğ‘¢,thelasttermisfrom
thecompulsorytrade,andthesecondtolasttermistheswitchingcostincurredbyLALG.
33Thisimpliesthatğ‘”(ğ‘¦) mustsatisfythefollowing:
âˆ« ğ‘¦
ğ‘”(ğ‘ˆ/ğ›¾)ğ‘ˆ/ğ›¾ âˆ’ ğ‘¢ğ‘‘ğ‘”(ğ‘¢)+2ğ›½ğ‘”(ğ‘¦)+(1âˆ’ğ‘”(ğ‘¦))ğ‘ˆ â‰¤ğ›¾ğ‘¦, âˆ€ğ‘¦ âˆˆ [ğ¿,ğ‘ˆ].
ğ‘ˆ/ğ›¾
By integral by parts, the above implies that the conversion function must satisfy ğ‘”(ğ‘¦) â‰¥ ğ‘ˆâˆ’ğ›¾ğ‘¦ âˆ’
ğ‘ˆâˆ’ğ‘¦âˆ’2ğ›½
1 âˆ« ğ‘¦ ğ‘”(ğ‘¢)ğ‘‘ğ‘¢. ByGrÃ¶nwallâ€™sInequality[MPF91][Theorem1,p. 356],wehavethat
ğ‘ˆâˆ’ğ‘¦âˆ’2ğ›½ ğ‘ˆ/ğ›¾
ğ‘ˆ âˆ’ğ›¾ğ‘¦ 1 âˆ« ğ‘¦ ğ‘ˆ âˆ’ğ›¾ğ‘¢ (cid:18)âˆ« ğ‘¦ 1 (cid:19)
ğ‘”(ğ‘¦) â‰¥ âˆ’ Â·exp ğ‘‘ğ‘Ÿ ğ‘‘ğ‘¢ (30)
ğ‘ˆ âˆ’ğ‘¦âˆ’2ğ›½ ğ‘ˆ âˆ’ğ‘¦âˆ’2ğ›½ ğ‘ˆ âˆ’ğ‘¢ âˆ’2ğ›½ ğ‘ˆ âˆ’ğ‘Ÿ âˆ’2ğ›½
ğ‘ˆ/ğ›¾ ğ‘¢
ğ‘ˆ âˆ’ğ›¾ğ‘¦ âˆ« ğ‘¦ ğ‘ˆ âˆ’ğ›¾ğ‘¢
â‰¥ âˆ’ ğ‘‘ğ‘¢ (31)
ğ‘ˆ âˆ’ğ‘¦âˆ’2ğ›½ (ğ‘ˆ âˆ’ğ‘¢ âˆ’2ğ›½)2
ğ‘ˆ/ğ›¾
ğ‘ˆ âˆ’ğ›¾ğ‘¦ (cid:20)ğ‘ˆğ›¾ âˆ’ğ‘ˆ âˆ’2ğ›½ğ›¾ (cid:21)ğ‘¦
â‰¥ âˆ’ âˆ’ğ›¾ln(ğ‘¢ +2ğ›½ âˆ’ğ‘ˆ) (32)
ğ‘ˆ âˆ’ğ‘¦âˆ’2ğ›½ ğ‘¢ +2ğ›½ âˆ’ğ‘ˆ
ğ‘ˆ/ğ›¾
â‰¥ğ›¾ln(ğ‘¦+2ğ›½ âˆ’ğ‘ˆ)âˆ’ğ›¾ln(ğ‘ˆ/ğ›¾ +2ğ›½ âˆ’ğ‘ˆ), âˆ€ğ‘¦ âˆˆ [ğ¿,ğ‘ˆ]. (33)
Inaddition,tosimultaneouslybeğœ‚-consistentwhentheadviceiscorrect,LALGmustsatisfyLALG(A ğ¿) â‰¤
ğœ‚OPT(A ğ¿) =ğœ‚ğ¿.Iftheadviceiscorrect(andğ‘šissufficientlylarge),weassumethatLALGpaysnoswitching
costtosatisfythelong-termconstraintatthebestcostfunctionsğ¿. Itmuststillpayforswitchingincurred
bytherobustalgorithm(recallthatOPTpaysnoswitchingcost).
âˆ« ğ¿
ğ‘”(ğ‘¢)ğ‘‘ğ‘¢ +2ğ›½ğ‘”(ğ¿) â‰¤ğœ‚ğ¿âˆ’ğ¿. (34)
ğ‘ˆ/ğ›¾
By combining equations (33) and (34), the conversion functionğ‘”(ğ‘¦) of anyğ›¾-robust andğœ‚-consistent
onlinealgorithmmustsatisfythefollowing:
âˆ« ğ¿ (cid:18) ğ‘¢ +2ğ›½ âˆ’ğ‘ˆ (cid:19) (cid:20) (cid:18) ğ‘¢ +2ğ›½ âˆ’ğ‘ˆ (cid:19)(cid:21)
ğ›¾ ln ğ‘‘ğ‘¢ +2ğ›½ ğ›¾ln â‰¤ğœ‚ğ¿âˆ’ğ¿. (35)
ğ‘ˆ/ğ›¾
ğ‘ˆ/ğ›¾ +2ğ›½ âˆ’ğ‘ˆ ğ‘ˆ/ğ›¾ +2ğ›½ âˆ’ğ‘ˆ
Whenallinequalitiesarebinding,thisequivalentlygivesthat
ğ‘ˆ ğ›¾(ğ‘ˆ âˆ’ğ¿) (cid:18) ğ‘ˆ âˆ’ğ¿âˆ’2ğ›½ (cid:19)
ğœ‚ â‰¥ğ›¾ +1âˆ’ + ln . (36)
ğ¿ ğ¿ ğ‘ˆ âˆ’ğ‘ˆ/ğ›¾ğœ– âˆ’2ğ›½
Wedefineğœ‚ suchthatğœ‚ (cid:66) (1+ğœ–). Bysubstitutingforğœ‚ into(36),werecoverthedefinitionofğ›¾ğœ– asgiven
by(8),whichsubsequentlycompletestheproof. Thus,weconcludethatany (1+ğœ–)-consistentalgorithm
forCFLisatleastğ›¾ğœ–-robust. â–¡
C.5 ProofofCorollary4.6
In this section, we prove Corollary 4.6, which shows that any (1+ğœ–)-consistent algorithm for MAL is at
leastğ›¾ğœ–-robust,whereğ›¾ğœ– isasdefinedin(8).
ProofofCorollary4.6. To show this result, we leverage the same special family ofğ‘¦-adversaries for CFL
defined in Definition B.5, whereğ‘¦ âˆˆ [ğ¿,ğ‘ˆ]. Recall thatğ‘˜ = argmax wğ‘, deonotes the largest edge
ğ‘âˆˆ[ğ‘›]
weightofany(non-OFF)pointinthemetricspace,andğ›½ = wğ‘˜.
AsintheproofofTheorem3.4,wenotethatforadversaryA ğ‘¦,theoptimalofflinesolutionisOPT(A ğ‘¦) =
ğ‘¦+2ğ›½/ğ‘š,andthatasğ‘š growslarge,OPT(A ğ‘¦) â†’ğ‘¦.
34Againsttheseadversaries,weconsidertwotypesofadviceâ€“thefirstisbad advice,whichsetsağ‘â€² = 1
ğ‘¡
(i.e.,ADVstaysintheOFFpoint)foralltimestepsğ‘¡ <ğ‘‡ (i.e.,beforethecompulsorytrade),incurringafinal
costofğ‘ˆ +2ğ›½.
Ontheotherhand,goodadvicesetsağ‘â€² = 1foralltimestepsuptothefirsttimestepwhenğ‘¦isrevealed,
ğ‘¡
atwhichpointitsetsağ‘˜
ğ‘¡
= 1/ğ‘š toachievefinalcostADV(A ğ‘¦) = OPT(A ğ‘¦) =ğ‘¦+2ğ›½/ğ‘š.
As previously, we letğ‘”(ğ‘¦) denote a robust conversion function [ğ¿,ğ‘ˆ] â†’ [0,1], which fully quantifies
the actions of a learning augmented algorithm LALG playing against adaptive adversary A ğ‘¦. Since LALG
is deterministic and the conversion is unidirectional (irrevocable),ğ‘”(ğ‘¦) is non-increasing in [ğ¿,ğ‘ˆ]. Intu-
itively, the entire long-term constraint should be satisfied if the minimum possible price is observed, i.e
ğ‘”(ğ¿) = 1.
As in Theorem 4.5, the adaptive nature of eachğ‘¦-adversary forces any deterministic ALG to incur a
switchingcostof2ğ›½ğ‘”(ğ‘¦) onadversaryA ğ‘¦,andweassumethatALGdoesnotincurasignificantswitching
costduringthefinalbatch(i.e.,duringthecompulsorytrade).
Foranyğ›¾-robustLALGgivenanyarbitraryblack-boxadvice,thefollowingmusthold:
LALG(A ğ‘¦) â‰¤ğ›¾OPT(A ğ‘¦) =ğ›¾ğ‘¦, âˆ€ğ‘¦ âˆˆ [ğ¿,ğ‘ˆ].
âˆ« ğ‘¦
ThecostofLALGwithconversionfunctionğ‘”onaninstanceA ğ‘¦isLALG(A ğ‘¦) =ğ‘”(ğ‘ˆ/ğ›¾)ğ‘ˆ/ğ›¾âˆ’ ğ‘¢ğ‘‘ğ‘”(ğ‘¢)+
ğ‘ˆ/ğ›¾
2ğ›½ğ‘”(ğ‘¦)+(1âˆ’ğ‘”(ğ‘¦))ğ‘ˆ,whereğ‘¢ğ‘‘ğ‘”(ğ‘¢) isthecostofbuyingğ‘‘ğ‘”(ğ‘¢) utilizationatpriceğ‘¢,thelasttermisfrom
the compulsory trade, and the second to last term is the switching cost incurred by LALG. Note that this
expressionforthecostisexactlyasdefinedinTheorem4.5.
ThusbyTheorem4.5,foranylearning-augmentedalgorithmLALGwhichissimultaneouslyğœ‚-consistent
andğ›¾-robust,theconversionfunctionğ‘”(Â·) mustsatisfythefollowinginequality(viaintegralbypartsand
GrÃ¶nwallâ€™sInequality[MPF91,Theorem1,p. 356]):
âˆ« ğ¿ (cid:18) ğ‘¢ +2ğ›½ âˆ’ğ‘ˆ (cid:19) (cid:20) (cid:18) ğ‘¢ +2ğ›½ âˆ’ğ‘ˆ (cid:19)(cid:21)
ğ›¾ ln ğ‘‘ğ‘¢ +2ğ›½ ğ›¾ln â‰¤ğœ‚ğ¿âˆ’ğ¿. (37)
ğ‘ˆ/ğ›¾
ğ‘ˆ/ğ›¾ +2ğ›½ âˆ’ğ‘ˆ ğ‘ˆ/ğ›¾ +2ğ›½ âˆ’ğ‘ˆ
Whenallinequalitiesarebinding,thisequivalentlygivesthattheoptimalğœ‚ andğ›¾ satisfy:
ğ‘ˆ ğ›¾(ğ‘ˆ âˆ’ğ¿) (cid:18) ğ‘ˆ âˆ’ğ¿âˆ’2ğ›½ (cid:19)
ğœ‚ â‰¥ğ›¾ +1âˆ’ + ln . (38)
ğ¿ ğ¿ ğ‘ˆ âˆ’ğ‘ˆ/ğ›¾ğœ– âˆ’2ğ›½
Wedefineğœ‚ suchthatğœ‚ (cid:66) (1+ğœ–). Bysubstitutingforğœ‚ into(36),werecoverthedefinitionofğ›¾ğœ– asgiven
by(8),whichsubsequentlycompletestheproof. Thus,weconcludethatany (1+ğœ–)-consistentalgorithm
forCFLisatleastğ›¾ğœ–-robust. â–¡
35