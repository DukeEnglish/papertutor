PenSLR: Persian end-to-end Sign Language Recognition
Using Ensembling
AMIRPARSASALMANKHAHâˆ—,
AmirkabirUniversityofTechnology(TehranPolytechnic),Iran
AMIRREZARAJABIâˆ—,
AmirkabirUniversityofTechnology(TehranPolytechnic),Iran
NEGINKHEIRMANDâˆ—,
AmirkabirUniversityofTechnology(TehranPolytechnic),Iran
ALIFADAEIMANESHâˆ—,
AmirkabirUniversityofTechnology(TehranPolytechnic),Iran
AMIRREZATARABKHAHâˆ—,
AmirkabirUniversityofTechnology(TehranPolytechnic),Iran
AMIRREZAKAZEMZADEHâˆ—,
AmirkabirUniversityofTechnology(TehranPolytechnic),Iran
HAMEDFARBEHâ€ ,
AmirkabirUniversityofTechnology(TehranPolytechnic),Iran
SignLanguageRecognition(SLR)isafast-growingfieldthataimstofillthecommunicationgapsbetweenthe
hearing-impairedandpeoplewithouthearingloss.ExistingsolutionsforPersianSignLanguage(PSL)are
limitedtoword-levelinterpretations,underscoringtheneedformoreadvancedandcomprehensivesolutions.
Moreover,previousworkonotherlanguagesmainlyfocusesonmanipulatingtheneuralnetworkarchitectures
orhardwareconfigurationsinsteadofbenefitingfromtheaggregatedresultsofmultiplemodels.Inthis
paper,weintroducePenSLR,aglove-basedsignlanguagesystemconsistingofanInertialMeasurementUnit
(IMU)andfiveflexiblesensorspoweredbyadeeplearningframeworkcapableofpredictingvariable-length
sequences.Weachievethisinanend-to-endmannerbyleveragingtheConnectionistTemporalClassification
(CTC)lossfunction,eliminatingtheneedforsegmentationofinputsignals.Tofurtherenhanceitscapabilities,
weproposeanovelensemblingtechniquebyleveragingamultiplesequencealignmentalgorithmknown
asStarAlignment.Furthermore,weintroduceanewPSLdataset,including16PSLsignswithmorethan
3000time-seriessamplesintotal.Weutilizethisdatasettoevaluatetheperformanceofoursystembased
onfourword-levelandsentence-levelmetrics.OurevaluationsshowthatPenSLRachievesaremarkable
wordaccuracyof94.58%and96.70%insubject-independentandsubject-dependentsetups,respectively.These
achievementsareattributabletoourensemblingalgorithm,whichnotonlybooststheword-levelperformance
by0.51%and1.32%intherespectivescenariosbutalsoyieldssignificantenhancementsof1.46%and4.00%,
respectively,insentence-levelaccuracy.
CCSConcepts:â€¢Human-centeredcomputingâ†’Ubiquitousandmobiledevices;â€¢Computingmethod-
ologiesâ†’Ensemblemethods;â€¢Hardwareâ†’Signalprocessingsystems.
âˆ—Theseauthorscontributedequallytothisresearch.
â€ HamedFarbehisthecorrespondingauthor.
Authorsâ€™ContactInformation:AmirparsaSalmankhah,amirparsa.s@aut.ac.ir,AmirkabirUniversityofTechnology(Tehran
Polytechnic),DepartmentofComputerEngineering,Tehran,Iran;AmirrezaRajabi,dr.mrajabi.mr@aut.ac.ir,Amirkabir
UniversityofTechnology(TehranPolytechnic),DepartmentofComputerEngineering,Tehran,Iran;NeginKheirmand,
neginkheirmand@gmail.com,AmirkabirUniversityofTechnology(TehranPolytechnic),DepartmentofComputerEngi-
neering,Tehran,Iran;AliFadaeimanesh,alifadaeimanesh@aut.ac.ir,AmirkabirUniversityofTechnology(TehranPoly-
technic),DepartmentofComputerEngineering,Tehran,Iran;AmirrezaTarabkhah,tarabkhah2@aut.ac.ir,Amirkabir
UniversityofTechnology(TehranPolytechnic),DepartmentofComputerEngineering,Tehran,Iran;AmirrezaKazemzadeh,
ar.kazemzade@gmail.com,AmirkabirUniversityofTechnology(TehranPolytechnic),DepartmentofComputerEngineering,
Tehran,Iran;HamedFarbeh,farbeh@aut.ac.ir,AmirkabirUniversityofTechnology(TehranPolytechnic),Departmentof
ComputerEngineering,Tehran,Iran.
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfee
providedthatcopiesarenotmadeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthe
fullcitationonthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthantheauthor(s)mustbehonored.
Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requires
priorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org.
Â©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
ACM1551-6865/2024/6-ART
https://doi.org/XXXXXXX.XXXXXXX
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.
4202
nuJ
42
]CH.sc[
1v88361.6042:viXra2 Salmankhahetal.
AdditionalKeyWordsandPhrases:SignLanguageRecognition,GestureRecognition,EnsembleMethods,
MultipleSequenceAlignment
ACMReferenceFormat:
AmirparsaSalmankhah,AmirrezaRajabi,NeginKheirmand,AliFadaeimanesh,AmirrezaTarabkhah,Amirreza
Kazemzadeh,andHamedFarbeh.2024.PenSLR:Persianend-to-endSignLanguageRecognitionUsingEnsem-
bling.ACMTrans.MultimediaComput.Commun.Appl.1,1(June2024),20pages.https://doi.org/XXXXXXX.
XXXXXXX
1 INTRODUCTION
Therearemorethan72millionusersworldwidewhomakeuseofsignlanguageonadailybasis.In
Iran,thenumberofdeafandhard-of-hearingindividualsisestimatedtobeover3millionasof2019
[17].Thesepeoplefacecommunicationproblems,leadingtosocialisolation,whichcanimpact
theirqualityoflife.Thetwomainsolutionsforcommunicationbetweensignlanguageusersand
therestofthepopulationareeitherthroughhandwritingoraninterpreter,whichcansometimes
beneitherfeasibleineverydayscenariosnorfastorinteractive.Moreover,signlanguagescanbe
diverse,withmultiplevariationsexistinginasingleregionorcountry.Thiscouldleadtodifficulties
incommunication,evenbetweensignlanguageusers.
SignLanguageRecognition(SLR)hasemergedasarapidlydevelopingfieldwithintheresearch
community. It focuses on addressing the problem of recognizing sentence-level sign language
glosses.SLRcanhelpbridgecommunicationgapsbetweendeaforhard-of-hearingindividuals
who use sign language and those who do not, enabling more inclusive interactions in various
settings.Inunderstandingsignlanguages,PersianSignLanguage(PSL),likeothers,consistsofa
combinationofintricatefingerpositions,handmovements,andfacemimicsthatcollectivelydefine
itsuniquecharacteristics.Thesegesturesfallintotwocategories:manualandnon-manualmarkers.
Theformerindicatesthefingerpositionsandtrajectoryofthehandthroughoutthegesture,andthe
latterreferstofacialexpressionsorheadmotion.Giventhecriticalroleofmanualandnon-manual
markers in SLR, any effective SLR system must incorporate as many of these features into its
recognitionprocessaspossible.
AnumberofapproachesexisttotackletheSLRproblem,eachwithitsownsetofprosandcons.
Themainmethodsarevision-basedandwearable-basedSLRsystems.Thevision-basedapproach
consistsofanalyzingvisualsignalsthroughtheuseofcamerasorothervisualsensors,andithas
theadvantageofconsideringbothmanualandnon-manualmarkers[6,9,14,25,29].However,this
approachalsocomeswithitssetofdrawbacks,suchasitsunderminingofprivacy,complexityof
thedatagatheringprocess,andsensitivitytolightingconditions.Thesecondapproachinvolves
wearable-basedsystemsthatdependonagloveoranyothertypeofwearabledeviceattachedto
differentpartsofthehandsorhead.Theembeddedsensorsprovidethedatathatwillbeprocessed
andtranslatedintosignlanguageglosses.Anumberofthesemethodsmakeuseoftraditional
machinelearningapproaches[10,11,13,24,28]whileothersleveragethepowerofdeeplearning
[1,4,12,20,22,23,26,27]torecognizeandtranslatesignlanguage.Althoughthesesystemsmostly
come with the disadvantage of not taking into account the non-manual markers and depend
onindividualanatomy,theirprivacy-preservingnature,portability,andaffordabilitymakethem
suitablechoicesforSLR.Recentresearchinthisfieldhasalsointroducedanewapproachbasedon
wirelesssensing[7,8,18,19].ThesetypesofSLRsystemsdependontheanalysisofacousticornon-
acousticwavesandusuallyhavetheadvantageoflesscomputationalcomplexityandportability.
However,thesesolutionsmayexperienceinterferencefromexternalwavesandunderperformin
environmentswhereobstacleshinderwavepropagation.
ResearchersmayfaceseveralchallengeswhiledevelopinganSLRsystem.Firstly,theinputdatais
dependentonbothspatialandtemporalfeatures.Theformerisduetothespatialnatureofthistask,
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.PenSLR:Persianend-to-endSignLanguageRecognitionUsingEnsembling 3
whilethelatteroriginatesfromthecomplexityofglossesaswellasthevariationsinsignlanguage
usersâ€™speed.Secondly,Itcanbechallengingtodistinguishbetweensomesignlanguagegestures
duetotheirsimilaritiesinhandmovements,fingerpositions,orfacialexpressions.Moreover,dueto
variationsinthewaythatsignlanguageusersperformgestures,thetrainedmodelmustgeneralize
trainingdatatomaintainaccuracywheninputfromanewuserisfedintothemodel.Thisalsomust
betakenintoaccountwhenpredictingapreviouslyunseensequencefromauserinthetraining
set.Lastly,themodelmustbecapableofdetectingthetransitionsbetweentheglossestoachieve
highaccuracywhenfacingnewsentenceswithmuchhigherlengthsthanthetrainingsamples.
Inthispaper,weproposeaglove-basedSLRsystemtodetectvariable-lengthsentencesfromPSL
usinganend-to-enddeeplearningframework.Weleverageacustomizedsignlanguageglovewitha
low-costInertialMeasurementUnit(IMU)attachedtothebackofthehandandfiveflexiblesensors
mountedonfingers.Wecollecttwoshort-lengthandlong-lengthdatasetstoprovetheabilityof
ourframeworktogeneralizeinlongerunseensentences.Ourdeeplearningframeworkconsistsof
twomainparts.Firstly,wedesignaConvolutionalRecurrentNeuralNetwork(CRNN)toextract
thespatio-temporalfeaturesfromthegiveninputsequenceandpredictthecorrespondinglabel.We
achievethisbyutilizingthewidely-usedConnectionistTemporalClassification(CTC)lossfunction
[5],whichallowsustooptimizethealignmentsbetweentheinputsequencesandthegroundtruth
withoutanypriorknowledgeaboutthealignmentsoranysegmentationscheme.Secondly,we
proposeanovelapproachforensemblingthatmakesuseofmultipletrainedmodelsandperforms
avotingprocesstoobtainthefinalresult.OurensemblingalgorithmutilizesStarAlignment,a
popularmultiplesequencealignmentalgorithm,toalignthepredictedsequencesofthemodels,
ensuringtheyareofequallength.Itwillthentakeamajorityvotebetweenthealignedsequences
ateachpositiontogeneratethefinalprediction.Ourframeworkleadstobenefitsregardingunseen
sentences,specificallylongerones.Furthermore,thisschemeimprovesthesystemâ€™srobustness
inadaptingtonewindividuals.Inaddition,sincetheensemblingmethoddoesnotrelyonany
particularcharacteristicofPSL,futureworkinthisdomaincouldtakeadvantageofittoenhance
theirresult.Ultimately,itsapplicabilityextendstootherdomainslikegesturerecognition,givenits
independencefromlinguisticattributes.
Inordertoassesstheeffectivenessofoursystem,wegatheredadatasetcomprisingover3000
samples from 16 commonly used PSL glosses. The dataset was collected with the help of five
volunteersandincludessentencesofuptothreewordsfromtheselectedglosses.Anotherdataset,
containing4to8-wordsentences,wasgatheredwiththeaimofevaluatingthemodelâ€™sability
torecognizelongersentences.Sinceitisnotarealisticscenariototrainanewmodelforeach
newuser,weconductasubject-independentanalysistoguaranteethepracticalityofoursystem.
Wecomparethetwobestmodelsobtainedbyanablationstudyintermsoffourword-leveland
sentence-levelevaluationmetrics.Theresultsdepictthatoursystemachievesalmost94%word-level
accuracyinbothdatasets,showcasingitsproficiencyindetectingbothshortandlongsequences.
Themodeliscapableofpredictingthelengthofthesequencesinapproximately95%ofsamples,
andasentence-levelexactmatchratioofalmost88%and80%isachievedfortheshort-lengthand
long-lengthdatasets,respectively.
Tosumup,ourmaincontributionsaresummarizedasfollows:
â€¢ Wedesignalow-costsignlanguagegloveusinganIMUandfiveflexiblesensorscapableof
capturingawiderangeoffingerbendingsandhandmovements.
â€¢ Wecollecttwodatasetscontainingshort-lengthandlong-lengthtime-seriesdatafromPSL
sentencescontaining16widely-usedPSLglosses.Wemakeourdatasetpubliclyavailable1in
1https://github.com/Persian-Sign-Language/PenSLR-dataset
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.4 Salmankhahetal.
ordertomakeitaccessibletoresearchersinthefieldofSLR,especiallytheonesworkingon
PSL.
â€¢ We develop a CRNN architecture with the ability to process variable-length signals and
predictcompletesignlanguagesentencesinanend-to-endfashion.
â€¢ WeproposeabrandnewensemblingschemeusingStarAlignmentasitsbackbone,whichis
adaptabletootherSLRorsequence-to-sequencetasks.
Therestofthepaperisorganizedasfollows.Section2presentsthepreviousworkinthefieldof
SLRandprovidesdetailsaboutmultiplesequencealignmentalgorithmsrelatedtoourensembling
method.Section3describesourdatasetaswellasthedatagatheringprocess.Section4deeply
investigatesdifferentpartsofPenSLR,includingthedesignedglove,thearchitectureofthemodel,
andourensemblingscheme.InSection5,theperformanceofthesystemisdiscussedusingmultiple
experimentsandevaluationmetrics.Then,inSection6weinvestigatethelimitationsofoursystem
andexplorepossibleavenuesforfutureresearch.Finally,theconclusionofthepaperisdrawnin
Section7.
2 RELATEDWORK
Inthissection,weexploretherelatedworksinthefieldofsignlanguagerecognitionandprovidea
briefexplanationofmultiplesequencealignmentalgorithms.
2.1 SignLanguageRecognition
Twoleadingsolutionsexisttotackletheproblemofsignlanguagerecognition(SLR)basedon
sensing technologies: vision-based and mobile/wearable solutions. Also, a recently emerging
approachisbasedonwirelesssensing.
2.1.1 Vision-basedMethods. Vision-basedmethodsusuallyutilizecamerasetupandvisualsignals,
thushavetheadvantageofconsideringnon-manualmarkers.Anearlywork[9]inthisareaforPSL
consistsoftheuseofDiscreteWaveletTransform(DWT)forfeatureextractionandaMulti-layer
Perceptron(MLP)neuralnetworkforcategorizingsignlanguagegestures.Inanotherstudy,C2ST
[25]takesintoaccountthelinguisticfeaturesofglosssequencesusingalinguisticmodel.Later
researchinthevisionfieldensuresspatialattentionconsistencyusingakeypoint-guidedspatial
attentionmodule[29].Anotherworkinthisfieldalsotakesintoaccountnon-manualmarkersusing
acustom-developedGlobal-localenhancementnetwork(GLE-Net)architecture[6].Moreover,[14]
suggestsusingaLeapMotionsensortoextractthecoordinatesofdifferentpartsofthehands.It
alsoproposeamodifiedversionofLongShortTermMemory(LSTM),introducinganewresetgate
thatresetsthememoryofLSTMwheneveranon-activesituationisdetected.
2.1.2 Wirelesssensing-basedMethods. Thefollowingmethodsintroducewirelesssensing-based
SLRsystemsthatuseelectromagneticoracousticwavestodetectbodymovements.In[19],aWi-Fi
receiverandtwoWi-fitransmittersareusedtocollectdata,andthenaKernel-basedSupportVector
Machine(SVM)modelisusedtoclassifygesturesondifferentsystems.Anotherwork,mmASL[18],
takesadvantageofmillimeterwavesandamulti-taskdeeplearningmodeltorecognizeAmerican
SignLanguage(ASL)gestures.Additionally,SonicASL[7],areal-timegesturerecognitionsystem,
identifiessignlanguagethroughtheuseofearphoneswithbuilt-inmicrophonesandspeakers,
achievinghighaccuracyratesinbothwordandsentencerecognition.Inalaterwork,SmartASL
[8] not only utilizes earbud signals but also employs IMU sensors to detect both manual and
non-manualmarkers.ThelasttwomentionedworksemployCRNNarchitecturealongwithCTC
lossfunctiontoperformsignlanguagerecognitioninreal-time.
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.PenSLR:Persianend-to-endSignLanguageRecognitionUsingEnsembling 5
2.1.3 Wearable-basedMethods. Mobile/Wearablesystemsdesignedtorecognizehandorbody
gestures are another approach to the SLR task. Although these solutions do not consider non-
manualmarkers,theycanhelpsolvetherangeoffailurepointsthatthepreviouslymentioned
vision-basedandwirelesssensing-basedsolutionshave.
Anearlyworkinthisfieldusedcustomizedbendingsensors,accelerometers,andHalleffect
sensorsinordertodetectgesturesofdigits(0to9)throughlogisticregression[3].Furthermore,
authorsin[15]suggesta5-bitrepresentationofthewordsorsentencesandassignabittotheoutput
ofeachflexiblesensoronfingerstopredictthegesturesbasedontheperceivedvalues.Another
study involves using a combination of IMU and sEMG sensors to gather data [24]. The sEMG
sensorsmakeitpossibleforthemtoautomaticallysplittheinputsignalsintosegmentsthatare
fedtoanSVMclassifierforthefinalprediction.Moreover,astudyonPSLsuggestsusingasimilar
sensorsettingalongwithaKNNclassifierandK-foldcross-validationtodetect20commonlyused
isolatedsigngestures[10].However,itdidnotprovideasolutionforrecognizingPSLsentences.In
[28],ayarn-basedstretchablesensorwasintroduced,whichisnotonlycapableofcapturinghand
gesturesbutcanalsobeattachedtoeyebrowsandmouth.Then,anSVMmodelwasusedtoperform
theclassificationtask.Authorsin[13]tookauniqueapproachbystoringpredefinedsentencesina
databasewhileharnessingacustomizedglovewithanIMUandflexiblesensors.Duringthetesting
phase,anovelDTWdistancewasproposedtofindthenearestdatainthedatabaseandpredictthe
labelofthenewinputsignal.In[11],theauthorssuggestedanapproachtocalculatethemovement
trajectoriesofgesturesandtookadvantageofanothercustomizedDTWdistancetoclassifythe
signals.
Laterworksleveragethepowerofdeeplearningtoachievebetterresultsandaccomplishmore
complextasks.AworkonPSL[1]collectedatime-seriesdatasetof15wordswith600samplesin
total.Thecollecteddatawerevirtuallyaugmentedto30000imagesusingtheState-Imageapproach,
andaCNNnetworkwasproposedtotrainontheseimages.Similarto[10],thisstudylackedthe
abilitytopredictcontinuoussentences.Anotherstudysuggestsusingasliding-windowapproach
to segment the input signals and construct the predicted sentence by feeding the segments to
aCNN-basedneuralnetwork[23].Thisenabledthemodeltoachievehighresultsindetecting
50 words and 20 predefined sentences, as well as new sentences that could be constructed by
differentcombinationsofthosewords.Authorsin[12]utilizedasimilarCNN-basednetworkwith
acustomizedglovecontaininganIMUandstrainsensorstodetect48ChineseSignLanguage(CSL)
gestures.Theytookadvantageofmultipleslidingwindowswithdifferentlengthsandaggregated
theirresultsforsentence-levelprediction.Inanotherstudy,aglovewasdesignedusingconductive
knitfabricandanaccelerometer[4].Togeneratetheoutput,anLSTMnetworkwasproposedto
trainonadatasetcontaining12distinctclassesfromASLusingasliding-windowapproach.
ThemostrecentapproachesinvolveusingCRNNmodelsalongwithCTClossfunctionoran
extensionoftheminvolvingattention-basednetworks.Myosign[27]suggestsanarmbandcapable
ofcollectingdatafromdifferentmodalities,i.e.,accelerometer,gyroscope,orientation,andEMG.
TheyproposeaCRNNnetworkconsistingofmultimodalCNNandBidirectionalLSTM(BiLSTM)
layers to build an end-to-end system for predicting ASL sentences. They achieve this through
the use of CTC loss, which enables them to perform SLR without any prior knowledge of the
alignments between input and output. In [20], a transfer learning scheme was employed on a
similararchitectureasMyosign,enablingthesystemtoconvergefasterwhilemaintainingaccuracy.
TheirwearablesystemconsistedofmultipleIMUsensorsonbothforearms.BuildingonMyosign,
Wearsign[26]introducesanencoder-decoderframeworkthattakesadvantageoftheattention
mechanismtotranslatethesignlanguageglossestothespokentext.Moreover,theyutilizedthe
back-translationtechniquetoaugmentandextendtheirASLdataset.Similarly,HearSign[22]
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.6 Salmankhahetal.
proposesanattention-basedencoder-decoderapproachwithamulti-channelCNNtotrainonthe
datacollectedbytwoMYOarmbandseffectively.
2.2 MultipleSequenceAlignment
Due to the increase of data in todayâ€™s era, especially sequence data, various algorithms have
beendesignedtoalignmultiplesequencestogether.Theapplicationofthesealgorithmsismainly
inthefieldofbioinformatics.Forexample,understandingthefunctionalsignificanceofgenetic
variationsacrossdiversespeciescountsasoneoftheirprimaryapplications.Thetaskofaligningtwo
sequences,pairwisesequencealignment,servesasthefoundationforaligningmultiplesequences.
Pairwise alignment is primarily categorized into local alignment and global alignment. Local
alignmentfocusesonidentifyingandaligningsimilarlocalregions,whileglobalalignmentinvolves
aligningsequencesinanend-to-endmanner[2].Inthissection,ourprimaryfocusreliesonglobal
alignmentbecauseitistheapproachweuseinourproposedalgorithm.
TheNeedleman-Wunsch(NW)algorithm[16]isawidelyemployedglobalalignmentalgorithm
thatleveragesadynamicprogrammingapproachtocalculatepairwisesequencealignment,taking
advantageoftheoptimalsubstructureofthisproblem.However,usingthisalgorithmformultiple
sequencealignmentisnotfeasibleduetoitstimecomplexity.Inordertotacklethisproblem,two
mainstrategiesaresuggested:staralignmentandprogressivealignment.Staralignmentworksby
automaticallyselectingoneofthesequencesasthecenterandaggregatingtheresultsofpairwise
alignmentbetweenthecenterandtheothersequencestoobtainthefinalalignment.Thisapproach
considerablyreducesthetimeneededtocomputethefinalalignments,thusmakingitasuitable
choiceforreal-timetasks.Ontheotherhand,progressivealignmentalgorithms,suchasClustalW
[21],arebasedonaguidetreethatdeterminestheorderbywhichthesequencesshouldgetaligned.
Therearetwomaindrawbackstotheprogressivealignmentalgorithms.First,thefinalresultis
highly dependent on the quality of the guide tree. Second, they need more time to execute as
hierarchicalclusteringisneededtoconstructtheguidetree,andinternalnodesofthetreerequire
morecomplexoperationsforcomputingthealignments[2].
3 DATASET
Wecollectedourowndatasetfortworeasons.First,asmentionedinSection2.1.3,therewasonly
onepublicPSLdataset[1]available,whichwasneitherlargeenoughnorcontainedsentence-level
data.Second,noneofthepreviousworkonPSLusedourhardwaresettings,forcingustocollect
newdatatoensurethecompatibilityofourglove-baseddesignwithourdataset.Unlikemany
conductedstudiesintheareaofSLR,whichusedseparatedword-levelandsentence-leveldatasets
totrainthemodel,wecollectedaunifieddatasetcontainingwordcombinations(sentences)ofup
tothreewords.SentencesarerandompermutationsoftheselectedPSLsignsanddonotnecessarily
conveymeaning.Moreover,thereasonforlimitingthenumberofwordsinsentenceswastoshow
thecapabilityofourSeq2Seqmodeltopredictsentencescontainingmorethanthreewordswithout
beingtrainedonthem.
Todemonstratetheeffectivenessofourmodel,wecherry-picked16wordsfromPSL,categorizing
themintofivesimilaritygroups.Table1demonstratesthegroupsandtherelationshipbetweenthe
similarwords.Thewordswithinthesametupleingroups1and2mutuallysharethecharacteristics
ofthegroup.Thatis,theysharesimilaritiesinatleastoneaspect,eitherthroughhandmovements
orfingerpositions,makingthemindistinguishablewithouttheconcurrentuseofbothsensors.
Ontheotherhand,groups3to5featurethewordsthathavefixed,dynamic,orrotationalhand
movements,respectively.Asaresult,achievinghighaccuracyinthissetupcouldshowcasethe
modelâ€™sproficiencyindetectinganddistinguishingminorvariationsbetweensimilargestures.For
clearerunderstanding,Figure1depictstheexecutionoftwopairsofourPSLwordsdistinguished
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.PenSLR:Persianend-to-endSignLanguageRecognitionUsingEnsembling 7
ID GroupCharacteristic Members
1 Samefingerpositionbutdifferenthandmovement (Agreement,Disagreement)-(Yesterday,Father,Luck,Year)-(is,Very,Hopeful)
2 Samehandmovementbutdifferentfingerposition (Luck,Summer)
3 Fixedhandmovementandfingerposition Good-Agreement-Disgreement
4 Dynamichandmovementandfingerposition Day-Forget-Mother
5 Rotationalmovements Blue-Green-Year
Table1. OurselectedPSLwordscategorizedintofivegroups
bydifferentcolors.Theredgroupshowsapairofgestures("Blue"and"Year")withrotationalhand
movementsondifferentaxes.Thebluegroupillustratesgestures("is"and"Very"),whichshare
fingerpositionsbuthaveminordifferencesinhandmovement.
Weaskedfivevolunteerstoperformsignlanguagegestures.Althoughrecordinghand-picked
sentencesmultipletimesbydifferentvolunteersisacommonwaytobuildasignlanguagedataset,
werandomlygeneratedthesentencesinourdataset,ensuringnohumanbiasisinvolvedinthe
selectionprocess.Forourprimarydataset(Dataset1-3),eachvolunteerrecorded,onaverage,100
one-wordsentences,300two-wordsentences,and200three-wordsentences.Moreover,weasked
eachvolunteertorecord20extrasentencescontaining4to8wordstoevaluatetheabilityofour
modelinlongerunseensentences(Dataset4-8).Additionally,aGUIapplicationwasdesignedand
implementedtoincreasethespeedandeaseoftherecordingprocess.
Eachdatainthedatasetisasequenceofvaluesreceivedfromthesensorsatarateof100Hz.
IMUfeaturesincludetotalacceleration,linearacceleration,gyroscope,andgravityaccelerationin
theX,Y,andZaxes.Combiningthesefeatureswithfivefeaturesreturnedfromflexiblesensors
forms17distinctfeaturesperdatapoint.Therefore,everysampleinthedatasetisatimeseries
datathatcanhavedifferentlengthsdependingontheexecutiontimeofeachgesture.
Table2depictstheaveragenumberofdatapointsderivedfromsequencescontainingoneto
threewordsacrossdifferentsubjects.Accordingtothetable,firstly,theaverageamountoftime
toexecutesentenceswiththesamelengthisdifferentfordifferentsubjects.Secondly,subjects
showdifferentbehaviorsfordifferentsentencelengthsanddonothaveaconstantspeedwhile
Blue
Year
is
Very
Fig.1. Illustrationofstep-by-stepexecutionoftwopairsofPSLglosses("Blue","Year")and("is","Very")
belongingtotwodistinctsimilaritygroups.Theblueglosseshavesimilarfingerpositionsbutdifferenthand
movements,whiletheredonesareexamplesofrotationalgestures.
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.8 Salmankhahetal.
Subject1 Subject2 Subject3 Subject4 Subject5 Average
Length1 13.0 11.7 11.6 9.7 10.7 11.34
Length2 19.0 19.1 18.2 19.8 20.2 19.26
Length3 25.4 28.0 27.3 30.2 26.5 27.48
Table2. TheaveragenumberofsamplelengthsinDataset1-3groupedbydifferentsubjects.Theslowestand
thefastestsubjectsineachrowaredenotedbygreenandred,respectively.
Fig.2. OursignlanguagegloveequippedwithanAdafruitBNO055IMUmountedonthebackofthehand
andfiveflexiblesensorsoneachfinger.
performinggestures.Forexample,onaverage,subject4hasperformedsingle-wordsentencesin
theleastamountoftimebutexhibitstheslowestpacefor3-wordsentences.Thesevariationspose
achallengeforthemodelindetectingwordtransitionswithinsentences.
ThedatasetisintendedtofacilitatetheresearchtowardPSLoranyothersignlanguagevariation.
Toensurethereproducibilityandaccessibilityofourwork,wehavemadethedatasetpublicly
available2.Weencourageotherresearchers,especiallytheonesworkingonPSL,touseourdataset
tobecomefamiliarwiththechallengesthatmayarisewhileworkingwithsignlanguagedatasets
ortoproposenewarchitecturesthatcouldachievebetterresultsthanourmodel.
4 PROPOSEDMETHOD
Inthissection,wedescribedifferentpartsofPenSLR.Thisincludesthedesignofthesignlanguage
glove,thedatacollectionprocess,preprocessingtechniques,thedeeplearningframework,andthe
proposedensemblingmethod.
4.1 GloveDesign
As depicted in Figure 2, our designed glove incorporates two types of sensors: an IMU sensor
mountedonthebackofthehandandfiveflexiblesensorsattachedtoeachfinger.Weutilized
ArduinoMegatocollectthesensorsâ€™data.TheIMUsensorsendsitsdatatothemicrocontrollervia
I2Cprotocol,whereastheflexiblesensorsachievethisbyanaloginputpins.
Oneofthemaingoalsofourresearchwastodesignalow-costbutaccurateglove.Asaresult,
weusedtheaffordableAdafruitBNO055IMU,whichcandeliveravarietyofmetrics,including
acceleration,orientation,andgravity,alongthreedistinctaxes.Capturingthesefeaturesenablesus
2https://github.com/Persian-Sign-Language/PenSLR-dataset
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.PenSLR:Persianend-to-endSignLanguageRecognitionUsingEnsembling 9
Temporal Feature Extractor
MLP Classifier
SpatFioea-tteumrepsoral
B Ã— n2
Feature Fusion
Sample (B Ã— Nf Ã— Tinp) Output (B Ã— Nc Ã— Tout)
Fig.3. ArchitectureofourSeq2Seqmodel
todistinguishbetweendifferenthandmovementsbasedonorientationpatterns.flexiblesensors,
ontheotherhand,aresensitivetobending;thus,theirvalueschangewiththeclosingandopening
offingers.Consideringthesetupabove,ourgloveiscapableofcoveringawiderangeofhand
gestureswhilebeingcost-effectiveandeasilyrepairable.
4.2 Seq2SeqModel
Thissectiondescribesthespecificsofourmodel,suchaspreprocessingsteps,themodelarchitecture
andthelossfunctionweuseinourmodel.
4.2.1 Preprocessing. Since errors (caused by human or hardware factors) may affect the data
collectionprocess,itisnecessarytoidentifyoutliersandremovethemfromthedatasetbefore
usingthem.Toachievethis,weusedtheInterquartileRange(IQR)method.Inthismethod,thefirst
quartileğ‘„ 1,ğ‘“ andthethirdquartileğ‘„ 3,ğ‘“ ofdataarecalculatedforeachfeatureandthedifference
betweenthemğ¼ğ‘„ğ‘… ğ‘“ isusedtodeterminearangefornon-outlierdata.Tobeprecise,whenadata
pointfallsoutsidetherangeof [ğ‘„ 1,ğ‘“ âˆ’1.5Â·ğ¼ğ‘„ğ‘… ğ‘“,ğ‘„ 3,ğ‘“ +1.5Â·ğ¼ğ‘„ğ‘… ğ‘“] foratleastonefeature,the
wholesampleisconsideredasanoutlierandwillberemovedfromthedataset.
Datanormalizationwasanotherstepinourpreprocessingpipeline.Tonormalizethedata,we
calculatedtheminimumvalueğ‘¥ ğ‘šğ‘–ğ‘›,ğ‘“ andthemaximumvalueğ‘¥ ğ‘šğ‘ğ‘¥,ğ‘“ ofeachfeaturebasedonthe
trainingdata.Then,wenormalizedthevalueofeachfeatureğ‘¥ ğ‘“ intrainingandvalidationdataas
follows:
ğ‘¥
ğ‘“
âˆ’ğ‘¥
ğ‘šğ‘–ğ‘›,ğ‘“
ğ‘¥ ğ‘“ = ğ‘¥
ğ‘šğ‘ğ‘¥,ğ‘“
âˆ’ğ‘¥
ğ‘šğ‘–ğ‘›,ğ‘“
(1)
Duringthetestingphase,thetestdatawerenormalizedwithrespecttothevalueswecalculated
beforehandusingthetrainingdataset.
4.2.2 ModelArchitecture. AsillustratedinFigure3,weemployedthreemaincomponentsinour
neuralnetworkmodel:afeaturefusion(FF)moduletocombineinputfeatures,atemporalfeature
extractor(TFE)todetecttemporalpatternsofeachsignlanguagegesture,andanMLPclassifierto
outputthepredictedgestureusingthefeaturesobtainedfromthepreviouscomponents.
Aswehadsamplesofvaryinglengthsinourdataset,weaddedzeropaddingtothesamples
inthesamebatch.Moreformally,weformedağµÃ—ğ‘ ğ‘“ Ã—ğ‘‡ ğ‘–ğ‘›ğ‘ matrixforeachbatch,whereğµ is
thebatchsize,ğ‘ ğ‘“ isthenumberoffeatures,andğ‘‡ ğ‘–ğ‘›ğ‘ isthelengthofthelongestsequenceinthe
batch.Bydoingthis,wewereabletoleveragetheefficiencyofbatchgradientdescent,thereby
acceleratingtheprocess.
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.
... ... ... ... ... ... ... ... ...10 Salmankhahetal.
TheFFcomponentaimstocombinethefeatureswitheachother.Itisessentialtoextractthe
dependenciesbetweenthevaluesofdifferentfeaturesbeforefeedingthemtotheTFEmodule,which
extractstemporaldependenciesbetweenthem.Moreover,FFextractslocaltemporaldependencies,
whichguidesTFEinfindingmorecomplexpatterns.Inotherwords,therawvaluesofdifferent
featuresinFFarecombinedwiththehelpofaconvolutionlayertocreatehigher-levelfeatures.
For this purpose, we used a 2D convolutional layer with a kernel size of 3Ã—3 to extract local
time-relateddependencieswhilecombiningdifferentfeatures.
ThefeaturesgeneratedbytheFFcomponententertheTFEmodule,whichincludestwoconsecu-
tiveBidirectionalLSTM(BiLSTM)layerswithhiddenstatesizesğ‘› =64andğ‘› =128,respectively.
1 2
Eachhiddenstateunitâ„ ğ‘¡ inBiLSTMcontainsinformationfromthepastandfutureoftheinput
sequenceattimeğ‘¡;thus,ithelpsusdistinguishsignlanguagegestureswiththesamebeginning
butdifferentendings.Ultimately,eachhiddenstateunitinthelastBiLSTMlayeryieldsanoutput
intheformofamatrixwithsizeğµÃ—ğ‘› ,representingthespatio-temporalfeaturesdistilledfrom
2
thesequencesofeachbatch.
The final step in our model is when the generated spatio-temporal feature matrices are fed
intoanMLPclassifiertoproducethepredictedsequence.Weusedashared3-layeredperceptron
networkcontaining64,32,andğ‘ ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’ğ‘ +1perceptronsalongwiththeCTClossfunctiontopredict
theoutputlabelatanytimestep.SincetheCTClossfunctionrequiresanextrablanklabel,we
addedanextraunittothelastlayer,resultinginatotalof17distinctclasses.Wefurtherdiscuss
thedetailsoftheCTClossfunctioninSection4.2.3.
Toimprovetheperformanceofourneuralnetwork,weusedbatchnormalizationanddropout
techniques.Batchnormalizationcontributessignificantlytothefasterconvergenceofthenetwork
bypreventingthecovariantshift.Therefore,weuseditaftertheconvolutionlayeroftheFFmodule
andbetweeneachtwolayersoftheMLPclassifier.Later,inSection5.2,wewillexaminetheeffect
ofaddingbatchnormalizationbetweendifferentlayersofournetwork.Finally,weplacedadropout
layer with a probability of 0.3 after each of the BiLSTM layers. This prevents the model from
overfittingandallowsittolearngeneralizablepatternswhiletraining.
4.2.3 CTC Loss. The Connectionist Temporal Classification (CTC) loss function is one of the
mostpopularlossfunctionsinsequence-to-sequencetasks,suchasopticalcharacterrecognition
andspeechrecognition.Themainadvantageofthisfunctionisitscapabilitytoaligntheinput
sequencestothetargetsequence,especiallyinscenarioswherethisalignmentisnotone-to-one.In
otherwords,thisfunctionisusedwhenthelengthofinputandtargetsequencesdonotmatch,and
theexactlocationofeachoutputeventintheinputsequenceisnotspecified.Duetotheinherent
variabilityintheexecutionofsignlanguagegestures,usingtheCTClossfunctioninSLRcanbean
effectivesolutiontoimprovetheperformanceofdeeplearningmodelsinthisfield.Thatisbecause
peopleexecutewordsatdifferentspeeds,andtheremaybelongpausesbetweenmovements,which
canposeachallengeinaccuratelyrecognizingsignlanguagegestures.
CTCintroducesablanksymbolandallowstheneuralnetworktooutputrepeatedoccurrences
betweentheactualsymbols,thusenablingvariable-lengthoutputsequences.Forexample,both
(AA-B-C-CC)and(A-Bâ€“CC-C)representthesequenceABCC.Duringtraining,theCTCalgorithm
alignstheseoutputsequenceswiththetargetsequences,consideringallpossiblealignmentsusing
adynamicprogrammingapproach.Finally,itcomputesalossfunctionbasedonthenegativelog
probabilityofthesealignments,guidingthenetworktoproduceoutputsequencesthatarelikelyto
matchthetargetsequences.
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.PenSLR:Persianend-to-endSignLanguageRecognitionUsingEnsembling 11
4.3 SequenceAlignment
Inthissection,weproposeanovelmethodbasedonensemblingtoimprovetheperformanceof
SLR Seq2Seq models. One way to improve the modelsâ€™ performance in deep learning is to use
ensembling.Inensemblemethods,severalmodelsaretrainedonthedata,andtheiroutputsare
usedtoproducethefinalprediction.Onewaytobuildeachofthesemodelsistosplitthedatainto
ğ‘˜ foldsandtrainğ‘˜ differentmodelswhereeachmodelistrainedonğ‘˜âˆ’1foldsandvalidatedusing
theremainingfold(K-foldcross-validation).IntheSLRtask,however,givenasinglesample,the
outputsofthemodelstrainedusingK-foldcross-validationcouldhavevariablelengths,makingit
challengingtocombinethemtogeneratethefinalresult.Toovercomethisproblem,wesuggest
usingmultiplesequencealignment(MSA)algorithmstomaketheoutputofthemodelsequalin
lengthandthenperformavotingprocesstoproducethefinalprediction.
Needleman-Wunsch(NW)isanalgorithmthatusesdynamicprogrammingtocomputeoptimal
globalalignment(GA)betweentwostrings.AsshowninAlgorithm1,NWcreatesatableofsize
ğ‘š+1byğ‘›+1toaligntwostringsoflengthğ‘šandğ‘›.Then,thefirstrowandthefirstcolumnare
initializedasfollows:
ğ· 0,ğ‘– =ğ· ğ‘–,0 =ğ‘–âˆ—ğ‘† ğ‘”ğ‘ğ‘ (2)
whereğ‘† ğ‘”ğ‘ğ‘ isthepenaltyforcreatingagapinoneofthesequences.Finally,itfillsthetableusing
Eq.3andEq.4:
ğ· ğ‘–ğ‘—
=maxï£±ï£´ï£´ï£´ï£² ğ·ğ· ğ‘–ğ‘– âˆ’âˆ’ 11 ,, ğ‘—ğ‘—âˆ’ +1 ğ‘†+ ğ‘”ğ‘ğ‘† ğ‘(ğ‘‹ ğ‘–,ğ‘Œ ğ‘—)
(3)
ï£´ï£´ï£´ğ· ğ‘–,ğ‘—âˆ’1+ğ‘†
ğ‘”ğ‘ğ‘
ï£³
(cid:40)
ğ‘†(ğ‘ ,ğ‘ ) =
ğ‘†
ğ‘šğ‘ğ‘¡ğ‘â„
ifğ‘
1
=ğ‘
2 (4)
1 2 ğ‘† ğ‘šğ‘–ğ‘  o.w
whereğ‘‹ andğ‘Œ are the input sequences,ğ‘† ğ‘šğ‘ğ‘¡ğ‘â„ is the score of matching two characters in the
sequences,andğ‘† ğ‘šğ‘–ğ‘  isthepenaltyofmismatchbetweentwocharacters.Then,thefinalalignment
scoreandthealignedsequencescanbeobtainedbybacktrackingfromthefinalposition [ğ‘š,ğ‘›]
Algorithm1PairwiseGlobalAlignment
1: Input: Sequencesğ‘  1[0,...,ğ‘šâˆ’1] andğ‘  2[0,...,ğ‘›âˆ’1]
2: Parameters: ğ‘† ğ‘šğ‘–ğ‘ ,ğ‘† ğ‘šğ‘ğ‘¡ğ‘â„,ğ‘† ğ‘”ğ‘ğ‘
3: Output: 2AlignedSequences,TheAlignmentScore
4: Initializeğ‘‘ğ‘[ğ‘š+1,ğ‘›+1] withzeros
5:
Initializeğ‘‘ğ‘[ğ‘–,0] =ğ‘–Ã—ğ‘†
ğ‘”ğ‘ğ‘
6:
forğ‘– from1toğ‘šdo
7: for ğ‘— from1toğ‘›do
8: ifğ‘  1[ğ‘–] =ğ‘  2[ğ‘—] then
9: ğ‘‘ğ‘[ğ‘–,ğ‘—] =max{ğ‘‘ğ‘[ğ‘–âˆ’1,ğ‘— âˆ’1]+ğ‘† ğ‘šğ‘ğ‘¡ğ‘â„,ğ‘‘ğ‘[ğ‘–âˆ’1,ğ‘—]+ğ‘† ğ‘”ğ‘ğ‘,ğ‘‘ğ‘[ğ‘–,ğ‘— âˆ’1]+ğ‘† ğ‘”ğ‘ğ‘}
10: else
11: ğ‘‘ğ‘[ğ‘–,ğ‘—] =max{ğ‘‘ğ‘[ğ‘–âˆ’1,ğ‘— âˆ’1]+ğ‘† ğ‘šğ‘–ğ‘ ,ğ‘‘ğ‘[ğ‘–âˆ’1,ğ‘—]+ğ‘† ğ‘”ğ‘ğ‘,ğ‘‘ğ‘[ğ‘–,ğ‘— âˆ’1]+ğ‘† ğ‘”ğ‘ğ‘}
12: endif
13: endfor
14: endfor
15:
ğ´ğ‘™ğ‘–ğ‘”ğ‘›ğ‘’ğ‘‘ ğ‘ 1,ğ´ğ‘™ğ‘–ğ‘”ğ‘›ğ‘’ğ‘‘ ğ‘ 2=Backtrack(ğ‘‘ğ‘)
16:
returnğ´ğ‘™ğ‘–ğ‘”ğ‘›ğ‘’ğ‘‘ ğ‘ 1,ğ´ğ‘™ğ‘–ğ‘”ğ‘›ğ‘’ğ‘‘ ğ‘ 2,ğ‘‘ğ‘[ğ‘š,ğ‘›]
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.12 Salmankhahetal.
Algorithm2StarAlignment
1:
Input:ğ‘˜ sequencesğ‘  0toğ‘ 
ğ‘˜âˆ’1
2: Output:ğ‘˜ AlignedSequences,TheAlignmentScore
3: Calculatepairwisealignmentsandscoresbetweenallpairs(ğ‘  ğ‘–,ğ‘  ğ‘—)whereğ‘– â‰  ğ‘—
(cid:16) (cid:17)
4: Choosethesequenceğ‘  ğ‘ asthecenter,whereğ‘ =argmaxğ‘— (cid:205)ğ‘˜ ğ‘–=âˆ’ 01Score(ğ‘  ğ‘—,ğ‘  ğ‘–)
5: Sortindicesğ‘– â‰ ğ‘ indecreasingorderwithrespecttoScore(ğ‘  ğ‘,ğ‘  ğ‘–)
6: foreachindexğ‘– inthesortedindicesdo
7: Utilizethealignmentsbetweenğ‘  ğ‘andğ‘  ğ‘–toupdatethegaplocationsofthealignedsequences
ğ‘  ğ‘â€² andğ‘ â€²
ğ‘—
where ğ‘— â‰¤ğ‘–
8: endfor
9:
returnTheAlignedSequencesğ‘  ğ‘–â€²,TotalAlignmentScore
to the starting position [0,0]. Although this method can be extended to alignğ‘˜ sequences, its
exponentialcomputationalcomplexitypreventsusfromusingitinareal-timesystem.Therefore,a
methodwithlesscomputationalcomplexityispreferabletoalignthesequences.
StarAlignment(SA)isaheuristicmethodforapproximatingGA,primarilyappliedinbioin-
formatics for aligning DNA sequences. Algorithm 2 shows how SA aligns multiple sequences.
First,itcallsNWalgorithmoneachpairofinputsequencestocomputetheiralignmentsandthe
correspondingsimilarityscores.Then,thesequenceexhibitingthemaximumcumulativesimilarity
isdesignatedasthecentralsequence.Subsequently,othersequencesarearrangedindescending
orderbasedontheirsimilaritytothecentralsequence.Finally,traversingthesequencesinorder,
somegapsareaddedtothecentralstringandallpreviouslytraversedstrings(ifnecessary)to
equalize their lengths, using the alignments calculated in the first step. For instance, Figure 4
illustratesanstep-by-stepprogressofrunningSAonfivearbitrarysequences.
WeutilizeSAalongwithK-foldcross-validationtoenhancetheaccuracyofoursystem.Algorithm
3providesadetailedoverviewofourmethod.Inthetrainingphase,weuse5-foldcross-validation
totrainfivedistinctmodelsonDataset1-3,andwhentesting,weusethosemodelstopredictfive
S 2: A B - C B B C
S':A B - C B B C
S1 S2 S3 S4 S5 S 5:A B E F B B C S'2
:A B E F B B C
S' 2:A B - C B B C
S1 - 9 8 4 7 S 2:A B C B B C S'5 :A B - C F B - S' 5:A B E F B B C S' 2:A B - C B B C
S2 9 - 9 5 12 S1:A B C F B - 1 S' 1: A B - C F B - S' 5:A B E F B B C
S3 8 9 - 7 7 S': A - - C F B C S' 1: A B - C F B -
S4 4 5 7 - 3 S 2: A B C B B C 3 S' 3: A - - C F B C
S5 7 12 7 3 - S3: A - C F B C S' 3: - B - C F C C
28 35 31 19 29 S 2:A B C B B C
S 4:- B C F C C
Fig.4. AnillustrationofhowStarAlignmentalgorithmcomputesthesimilaritymatrixbetween5sequences
(ğ‘† 1=â€ğ´ğµğ¶ğ¹ğµâ€,ğ‘† 2=â€ğ´ğµğ¶ğµğµğ¶â€,ğ‘† 3=â€ğ´ğ¶ğ¹ğµğ¶â€,ğ‘† 4=â€ğµğ¶ğ¹ğ¶ğ¶â€,ğ‘† 5=â€ğ´ğµğ¸ğ¹ğµğµğ¶â€)anduseittoprogressively
alignthem.Sequenceğ‘† isdesignatedasthecentersincethesumofsimilaritiesinthesecondcolumnisthe
2
highest.(ğ‘†
ğ‘šğ‘ğ‘¡ğ‘â„
=3,ğ‘†
ğ‘”ğ‘ğ‘
=âˆ’2,andğ‘†
ğ‘šğ‘–ğ‘ 
=âˆ’1)
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.PenSLR:Persianend-to-endSignLanguageRecognitionUsingEnsembling 13
Algorithm3OurEnsemblingAlgorithm
1:
Input:Sampleğ‘¥,MappingTfromthechosensignlanguagewordstoarbitrarycharacters
2: Output:ThePredictedSequence
3: Train5modelsvia5-foldcross-validation
4:
Predicttheoutputs(ğ‘  0toğ‘  4)fortheinputğ‘¥
5:
Replaceeachcharacterğ‘â„inğ‘ 
ğ‘–
withğ‘‡[ğ‘â„]
6:
Passsequencesğ‘ 
ğ‘–
toStarAignmenttogetsequencesğ‘  ğ‘–â€²
7:
forğ‘¡ from0toğ‘ â€².ğ‘™ğ‘’ğ‘›ğ‘”ğ‘¡â„âˆ’1do
0
8:
ğ‘œğ‘¢ğ‘¡ =ğ‘œğ‘¢ğ‘¡ +Vote(ğ‘  0[ğ‘¡],...,ğ‘  4[ğ‘¡])
9: endfor
10:
Removegapsfromğ‘œğ‘¢ğ‘¡
11:
Usetheinversemappingofğ‘‡ toupdateğ‘œğ‘¢ğ‘¡ğ‘ğ‘¢ğ‘¡
12:
returnğ‘œğ‘¢ğ‘¡
sequencesğ‘  toğ‘  foreachinputsample.Next,weusethepredictedsequencesastheinputsofthe
0 4
SAalgorithmtoobtainalignedsequencesğ‘ â€² toğ‘ â€².Thefinalstepincludesvotingateachtimestep
0 4
ğ‘¡ ofthefinalalignments.Inotherwords,themostprevalentcharacteratğ‘¡ isaddedtothefinal
resultunlessthecharacterisagap.ItshouldbenotedthatbeforeusingSA,itisnecessarytomap
thesignlanguagewordstoarbitrarycharacters.Therefore,werestorethewordsusinginverse
mappingafterthefinalvoting.Figure5depictstheexecutionoftheexplainedprocess.
Theintuitionbehindourmodelreliesonthefactthatthemodelstrainedondistinctfoldstend
tolearndifferentpatterns,especiallywhenthedatasetisnotverylarge.Thatis,theiraccuracyin
detectingdifferentclassesmayvary,andeachcouldmanagetopredictsegmentsoftheground
Model 1 A B C F B
Model 2 A B C B B C A B - C F B -
A B - C B B C
Sequence
A - - C F B C
Alignment
- B - C F C C
Model 3 A C F B C
A B E F B B C
Sample (Nf Ã— T) Voting
Label: A B C F B C
A B - C F B C
Model 4 B C F C C Gap Ignoring
Predicted Sequence: A B C F B C
Model 5 A B E F B B C
Fig.5. Anexampleoftheexecutionofourensemblingalgorithm.Theoutputsproducedbyallmodelsare
alignedusingStarAlignment,afterwhichavotingprocessisperformedtoobtainthemostprobablegesture
(denotedbycharactersAtoF)ateachposition.Finally,thegapsareignored,andthefinalresultisgenerated.
Thisexampleisasituationwhenthebestmodel(Model1)cannotcompletelypredictthegroundtruth
sequence,buttheensemblingmethodhelpsthesystemtogenerateitsuccessfully.
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.14 Salmankhahetal.
truthsequence.Asaresult,byaligningtheirpredictionsandvotingbetweenthem,thefinalresult
isexpectedtohavealowererrorratethanthepredictionofthebestone.Aswillbeexplainedin
Section5.3,thismethoddoesnotalwaysimprovetheaccuracy.Thissituationoccurswhenthebest
modelhasmuchhigheraccuracythanothersorwhenallmodelsdonothaveenoughaccuracy,
sotheperformancedropsbyvotingbetweenthepredictions.However,theresultsdepictthat,on
average,themethodcouldsignificantlyimprovetheperformanceofthesystem.Furthermore,since
ourensemblingtechniquedoesnotdependonanylinguisticfeature,itcanbeadaptedforstudies
onothervariationsofsignlanguageorlanguage-independentsequence-to-sequencetaskssuchas
gesturerecognition.
5 EXPERIMENTSETUPANDRESULTS
Inthissection,weexaminetheperformanceoftheproposedmodelandourensemblingalgorithm.
Weuseasubject-independentapproachinallexperimentsunlesswhereitismentionedexplicitly.
Byusingleave-one-subject-outcross-validation,wetraineachmodelonthedataof4subjectsand
testitwiththedataoftheremainingsubject.Inthetrainingphase,weuseDataset1-3,mentioned
in Section 3, which includes sentences with up to three words. In addition, we use the 5-fold
cross-validationapproachtoapplyourensemblingalgorithm,whereeachfoldcontains20%of
thedata.Also,weusetheAdamWoptimizerwithabatchsizeof9andlearningratescheduling
in 3 steps to optimize the cost function as much as possible. On the other hand, when testing,
our experiment settings involve both Dataset1-3 and Dataset4-8, enabling us to evaluate user-
independentgeneralizationaswellasgeneralizationinlongersentences,respectively.Furthermore,
in the testing phase, we assigns scores to gap penalties, mismatches, and matches as follows:
ğ‘† ğ‘”ğ‘ğ‘ = âˆ’1,ğ‘† ğ‘šğ‘–ğ‘  = âˆ’1,andğ‘† ğ‘šğ‘ğ‘¡ğ‘â„ = 0.Thisconfigurationwasdeterminedtobeoptimalforour
recognitiontaskthroughrigorousexperimentation,resultinginthebestperformance.
5.1 EvaluationMetrics
Weusethefollowingfourmetricstoanalyzetheperformanceofourmodels:
SequenceLengthAccuracy(SLAcc):Itdepictsthepercentageofsequenceswhoselengthsare
accuratelypredictedbythemodelrelativetothetotalnumberofsequences.
SequenceAccuracy(SAcc):Itindicatesthepercentageofsequencesthatexactlymatchtheir
groundtruthoutofthetotalnumberofsequences.Sinceachievinghighresultsinthismetricis
quitechallenging,mainlywhenthedatasetcontainslengthysequences,manypreviouslyconducted
studieshavenotreportedtheirresultsbasedonthismetric.Despitethis,wereportourresultsto
showtheeffectivenessofourensemblingapproachincorrectingthemispredictedsequences.
WordAccuracy(WAcc):ThismetricisdefinedbasedonanothermetriccalledWordErrorRate
(WER),whichisusedintaskswherethelengthofthepredictedsentencescouldbedifferentfrom
theiractuallength.TocalculateWERforagivenpairofgroundtruthandpredictedsequences,we
usethefollowingequation:
ğ‘† +ğ·+ğ¼
ğ‘Šğ¸ğ‘… = Ã—100 (5)
ğ¿
whereğ¿isthelengthofthegroundtruthsequence,ğ‘†isthenumberofsubstitutions,ğ¼ isthenumber
ofinsertions,andğ· isthenumberofdeletionsneededtoconvertthegroundtruthsequenceto
the predicted sequence. In fact, the numerator is the widely used Levenshtein distance, which
calculatestheminimumnumberofsingle-charactereditsneededtotransformonesequenceinto
another.Inourtask,eachindividualsignlanguagegestureinpredictedsequencescorrespondstoa
characterintheLevenshteindistancecalculation.Then,wecomputewordaccuracytoshowthe
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.PenSLR:Persianend-to-endSignLanguageRecognitionUsingEnsembling 15
similarityofthepredictedsequencetothecorrespondinggroundtruth:
WAcc=100âˆ’WER (6)
Finally,wecalculatetotalwordaccuracyasfollows:
(cid:205)
WAccğ‘–
TotalWAcc= (7)
ğ‘
whereğ‘Šğ´ğ‘ğ‘ ğ‘– isthewordaccuracyfortheğ‘–-thsampleinthedataset,andğ‘ isthetotalnumberof
samples.
WeightedWordAccuracy(WWAcc):Insteadofcomputingasimpleaverageovertheobtained
wordaccuracies,wecantakeaweightedaveragetoamplifytheimpactoflengthysentencesinthe
finalresult.Thus,wecancalculateweightedwordaccuracyusingthefollowingequation:
(cid:205) WAccğ‘–.ğ¿
ğ‘–
WWAcc= (8)
(cid:205)ğ¿
ğ‘–
Contrastingtheseresultswiththepreviousmetriccanshowcasetheextendabilityofourapproach
tolongersentences.
5.2 AblationStudy
AsmentionedinSection4.2.2,ourmodelincludesa3Ã—3convolutionallayer,twoBiLSTMlayers,
andanMLPclassifierwithbatchnormalizationbetweenanytwolayers.Toshowtheimpactof
differentcomponentsintheproposedarchitecture,weremoveorchangedifferentpartsofthe
model.Table3showstheresultsofthisworkwithoutapplyingourensemblingmethod.Inthe
lastcolumnofthistable,theaccuraciesobtainedfromtheperformanceoftheproposedmodelare
shown.Othercolumnsdepicttheamountofchangeinthemodelâ€™sperformanceafterremoving
orchangingoneofthemodelâ€™scomponents.Itshouldbenotedthatthenumbersshownarethe
averagetestresultsofthemodelacrossdifferentsubjectswhilehavingtrainedonaspecificfoldof
Dataset1-3withoutapplyingourensemblingmethod.
The modelachievesa WAccof 90.39% and aWWAcc of 90.85%, resultingin an exact match
ratioof81.69%.Moreover,themodelisabletoproducesequenceswiththesamelengthasthe
groundtruthin91.47%ofsamples.Duetothenegativenessofothernumbersinthetable,applying
anyofthementionedchangesinthearchitecturecausestheperformanceofthemodeltodrop.
AvoidingtheuseoftheconvolutionalorBiLSTMlayershasasignificantimpactonthemodelâ€™s
performance,whichrespectivelyindicatesthehighimportanceoftheFeatureFusioncomponent
andtheroleofthebidirectionalLSTMindetectinggestureswiththesameopeningmovements.
Also,usingjustoneLSTMlayerinsteadoftwolayersorusinga5Ã—5kernelfortheconvolution
layerreducestheperformance.TheformerisduetothefactthatusingtwolayersofLSTMcan
helpusdetectmorecomplexpatternsinthedata,andthelatterisbecausethe3Ã—3kernelallows
CNN LSTM Bidirectional BatchNorm OurModel
No 5Ã—5 1 No 0 1
SLAcc -4.92 -3.05 -4.22 -12.33 -1.50 -1.86 91.47
SAcc -15.12 -2.51 -1.55 -12.09 -4.41 -0.23 81.69
WAcc -8.91 -2.07 -1.24 -6.97 -2.71 -0.39 90.39
WWAcc -8.71 -1.38 -0.70 -6.01 -2.56 -0.11 90.85
Average -9.41 -2.25 -1.93 -9.35 -2.79 -0.65 88.60
Table3. Thepercentageofperformancedegradationofmodelsresultingfromthedeletionormodificationof
eachcomponentwithinourproposedarchitecture.
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.16 Salmankhahetal.
featurestobecombinedinmoreways.Finally,theuseofbatchnormalizationbetweeneachpairof
perceptronlayersmakesthelengthofthepredictedsentencesmuchclosertotheiractualvalue,
whichultimatelyincreasestheaccuracyofthemodel.
5.3 EnsemblingPerformance
Inthissection,weexaminetheperformanceoftheproposedensemblingmethodanditseffectiveness
inimprovingaccuracy.AccordingtoTable3,sincetheresultsofthemodelthatusesonebatch
normalizationlayer(ğ‘€ )are,onaverage,closetoourproposedmodel(ğ‘€ ),wewillcomparethese
1 2
models in our experiments. Also, in addition to Dataset1-3, we use Dataset4-8 to evaluate the
performanceofthemodelinlongersentences.
Thetablesinthissectionshowtheperformanceofğ‘€ andğ‘€ beforeandafterapplyingensem-
1 2
blingondifferentdatasetsandwithdifferentapproaches.ThemodelsrelatedtoTable4andTable
5weretrainedonthedataof4subjectsfromDataset1-3andtestedonthedataoftheremaining
subjectfromDataset1-3andDataset4-8,respectively.Ontheotherhand,Table6showstheperfor-
manceofthemodelsbybeingtrainedonthedataof4subjectsfromDataset1-3andtestedonall
thedataofDataset4-8;therefore,theresultsinthistablearenotbasedonthesubject-independent
approach.Itshouldbenotedthatineachcell,thenumbersontheleftindicatetheperformance
ofthebestmodelamongthefivemodelstrainedusing5-foldcross-validationbeforeapplying
ensembling.Incontrast,thenumbersontherightshowtheperformanceoftheensembledmodels.
Althoughsomecellsinthetablesshowminordegradation,intheaveragecolumn,eitheroneof
theensembledmodelsoutperformsothersacrossall12cases.Notably,ineightcases,thetoptwo
ranksarealsosecuredbyensembledmodels.Intheremainingfourcases,ğ‘€ aloneoutperformsthe
2
ensembledmodelofğ‘€ duetoitsinherentexcellence.Byassigningnumericalvaluesfrom1to4to
1
thespectrumofcolors,rangingfromredtogreen,andsubstitutingthemwiththecorresponding
valuesineachcell,wecancomputeanaveragerankforeachmodel.Thisprovidesanoverallview
of the effect of the ensembling method. The result of this analysis is represented in Table 7. It
illustratesasimilarpatternintheresultsofTable4andTable6,wheretheensembledmodelsof
ğ‘€ andğ‘€ areinthefirstandsecondplace,respectively.Onthecontrary,theresultsofTable5
2 1
showğ‘€ anditsensembleyieldingthebestresults.Thisobservationindicatesthattheuseofbatch
2
normalizationbetweenalllayersintheclassifierimprovestheperformanceofğ‘€ ,suchthatitcan
2
performevenbetterthantheensembledversionofğ‘€ .Inotherwords,batchnormalizationenables
1
Subject1 Subject2 Subject3 Subject4 Subject5 Average
Metric Model
1 93.22/90.58 91.54/95.34 96.01/95.51 95.45/97.56 97.55/96.73 94.79/95.15
SLAcc
2 86.94/90.91 96.03/97.58 95.85/93.69 96.10/97.89 96.73/98.85 94.33/95.78
1 82.31/82.98 86.87/89.64 89.04/90.70 83.77/85.39 91.82/91.16 86.76/87.95
SAcc
2 78.02/82.81 89.12/91.88 86.38/85.71 87.01/87.50 91.82/91.82 86.46/87.92
1 91.32/91.76 93.09/94.39 94.38/95.60 90.34/91.31 95.34/95.74 92.89/93.75
WAcc
2 89.39/91.76 94.27/95.54 93.27/92.91 91.75/92.32 95.74/95.72 92.87/93.63
1 91.10/91.48 93.68/95.00 93.82/94.94 92.22/93.13 95.94/95.72 93.35/94.04
WWAcc
2 89.43/91.33 94.77/96.02 92.45/92.37 93.66/94.18 96.17/96.02 93.29/93.97
Table4. Evaluationofmodelsbasedonthesubject-independentapproachonDataset1-3.Eachcolumn
(excepttheaveragecolumn)illustratestheresultsobtainedbytestingthemodelforthecorrespondingsubject
whilehavingtrainedonthedatafromothersubjects.Thenumbersinthefirstandsecondrowsofeach
cellrepresentmodelsğ‘€ andğ‘€ ,respectively.Thenumbersontheleftindicatetheperformancebefore
1 2
ensembling,whilethenumbersontherightindicatetheperformanceafterensembling.
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.PenSLR:Persianend-to-endSignLanguageRecognitionUsingEnsembling 17
Subject1 Subject2 Subject3 Subject4 Subject5 Average
Metric Model
1 55.00/75.00 75.00/90.00 100.0/100.0 95.00/100.0 85.00/85.00 82.00/90.00
SLAcc
2 90.00/90.00 85.00/90.00 100.0/100.0 100.0/100.0 95.00/95.00 94.00/95.00
1 45.00/60.00 55.00/60.00 90.00/95.00 85.00/90.00 55.00/70.00 66.00/75.00
SAcc
2 75.00/75.00 45.00/55.00 95.00/95.00 95.00/95.00 65.00/75.00 75.00/79.00
1 82.04/88.90 90.20/90.73 94.38/95.00 96.92/98.33 89.49/93.87 90.61/93.37
WAcc
2 94.88/93.88 86.68/88.90 95.00/95.00 99.17/99.17 94.61/95.95 94.07/94.58
1 83.33/90.83 90.83/90.83 93.33/94.17 97.50/98.33 90.83/94.17 91.16/93.67
WWAcc
2 95.83/95.00 87.50/89.17 94.17/94.17 99.17/99.17 94.17/95.83 94.17/94.67
Table5. Evaluationofmodelsbasedonthesubject-independentapproachonDataset4-8
Subject1 Subject2 Subject3 Subject4 Subject5 Average
Metric Model
1 86.00/91.00 84.00/95.00 89.00/92.00 84.00/94.00 87.00/94.00 86.00/93.20
SLAcc
2 90.00/94.00 88.00/94.00 87.00/95.00 93.00/96.00 91.00/97.00 89.80/95.20
1 74.00/81.00 73.00/86.00 79.00/90.00 75.00/88.00 73.00/84.00 74.80/85.80
SAcc
2 79.00/86.00 77.00/84.00 79.00/88.00 87.00/92.00 82.00/90.00 80.80/88.00
1 92.46/95.21 92.40/96.15 95.30/97.05 94.27/97.03 93.21/96.08 93.53/96.30
WAcc
2 95.55/96.50 94.14/95.28 94.78/96.66 96.46/97.70 95.99/97.37 95.38/96.70
1 92.17/95.33 92.83/96.17 95.33/97.17 94.33/97.00 93.67/96.17 93.67/96.37
WWAcc
2 95.50/96.50 94.17/95.50 95.00/96.83 96.67/97.67 96.00/97.33 95.47/96.77
Table6. Evaluationofmodelsbasedonthesubject-dependentapproachonDataset4-8.Eachcolumn(except
theaveragecolumn)illustratestheresultsobtainedbytestingthemodelforthecorrespondingsubjectwhile
havingtrainedonthedatafromallsubjects.
themodeltogeneralizebetterinlongerunseensequenceswhenthesubject-independentapproach
isused.
Sofar,wehavedemonstratedthatdespitecausingminordegradationsincertainmetricsfor
specificsubjects,theapplicationofensembling,onaverage,improvestheoverallperformance.
Now,wewillexaminetheextentofthisimpact.Table4indicatesthatensemblingboostsboth
WAccandSLAcc,resultingin1.19%and1.46%improvementinSAccofğ‘€1andğ‘€2,respectively.
Table5revealsthatensemblingeffectivelyaddressesğ‘€ â€™sweaknessinrecognizingsequenceswith
1
4to8words,bringingitclosertoğ‘€ â€™sperformancewitha2.76%and0.51%increaseinWAccforğ‘€
2 1
andğ‘€ ,respectively.Thistranslatestoaremarkable9.00%and4.00%enhancementinrecognizing
2
completesequencesforeachmodel.Moreover,themodelsachievedslightlyhigherresultsinterms
of WWAcc, indicating that they are capable of maintaining their accuracy while dealing with
longersentences.TheresultsofTable6showthattheimpactofensemblingisevenhigherwhile
usingthesubject-dependentapproach.Inthatexperiment,ğ‘€ andğ‘€ witnesseda2.77%and1.32%
1 2
increaseinWAcc,resultinginan11.00%and7.20%improvementinrecognizingcompletesequences,
respectively. Moreover, our method significantly improved the ability of models to predict the
lengthofoutputsequence,resultingin7.20%and5.40%improvement,respectively.
Towrapup,ourexperimentsinthissectionshowtwomainpoints.First,abettergeneralization
inlongersequencesistheunderlyingcauseforusingbatchnormalizationbetweenalllayersin
theclassifier.Second,usingourensemblingapproachyieldsconsiderableimprovementsinboth
models,makingitasuitablechoiceforourSLRtask.
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.18 Salmankhahetal.
Model Table2 Table3 Table4
1 1.96/2.83 1.21/2.33 1.13/3.21
Averageranks
2 2.08/3.13 2.75/3.71 1.95/3.71
Table7. Theaveragerankingofeachmodelbasedontheresultsofexperiments.Theranksrangefrom1to4
correspondingtomodelsâ€™performanceinascendingorder.
6 LIMITATIONSANDFUTUREWORK
6.1 NeglectingNon-manualMarkers
AlthoughPenSLRiscapableofcapturingdiversehandmovementsandfingerpositions,itlacks
the ability to detect non-manual markers, such as facial expressions and head movements. As
previouslymentioned,non-manualmarkersplayacrucialroleinallsignlanguagevariations.In
fact,somegesturesmaysharesimilarhandmovementsandfingerconfigurations,yetdifferin
subtlefacialexpressions.Therefore,incorporatingnon-manualmarkersnotonlyexpandstherange
ofglossesbutalsoenhancesthesystemâ€™sabilitytodifferentiatebetweengestureswithsimilar
manualmarkers.Inthefuture,wecouldmanipulateandimproveourglove-baseddesignsothat
wecantakeintoaccountthesenon-manualmarkers.Toachievethisgoal,onepromisingapproach
involvesemployingstretchablesensorsattachedtotheface,assuggestedin[28],orharnessing
earbudsignals,asexploredinSmartASL[8].
6.2 LimitedDataset
AsexplainedinSection3,wecollectedadatasetofover3000samplesfrom16PSLglosses.Although
ourdatasetstandsasthelargestwithinthePSLdomain,thePSLlexiconextendsbeyondthislimited
scope,andforeffectivecommunicationamongsignlanguageusers,abroadervocabularyisessential.
Therefore,itiscrucialtoprioritizetheexpansionofourdatasettoincludeamoreextensivearray
ofPSLsigns.ThiswillfacilitatemorecomprehensivecommunicationwithinthePSLcommunity.
Additionally,collaboratingwiththePersianDeafCommunityAssociation,particularlyinthedata
gatheringprocess,couldhelpustoimprovethequalityofourdatasetandtailorittoreal-world
applications.
6.3 EnsemblingLimitations
Our ensembling algorithm does not take into account any linguistic relationship between the
predictedsigns.Althoughthiscountsasabenefitinlanguage-independenttasks,suchasgesture
recognition,thesituationisdifferentwhenlinguisticfeaturesaredecisive.Forinstance,insign
languagetranslation,wherethegoalistoconvertsignlanguageglossesintonaturallanguagetext,
ouralgorithmmayfallshortinpreservinglexicalandgrammaticalcorrectness.Thislimitation
arisesbecausetheuseofsequencealignmentcandisruptthecoherenceofsentencestructures.
However,toovercomethisissue,alanguagemodelcanbeusedtorevisetheoutputofensembling
topreservethesentencestructure.
7 CONCLUSION
Inthispaper,weproposePenSLR,thefirstPersiansignlanguagerecognitionsystemcapableof
detectingsignlanguagesentencesinanend-to-endmanner.Toachievethis,wedesignacost-
effective glove-based system that can capture a wide range of manual markers. Moreover, we
constructandpublishthelargestPSLdatasettodate,comprisingmorethan3000samplesfrom
16commonlyusedsigns.Totackletherecognitiontask,wedeployaCRNNarchitecturecoupled
withtheCTClossfunction,facilitatingthegenerationofvariable-lengthoutputsbasedoninput
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.PenSLR:Persianend-to-endSignLanguageRecognitionUsingEnsembling 19
signals.Furthermore,weintroduceanovelensemblingtechniquebasedonsequencealignmentand
utilizemultipleinstancesofourmodeltogenerateanimprovedoutputsequence.PenSLRachieves
an impressive 94.07% word-level accuracy while testing on longer unseen sentences using the
subject-independentapproach.Notably,whenemployingourensemblingscheme,thisrepresents
a0.51%enhancementovertheperformanceachievedsolelywiththeCRNNmodel,leadingtoa
94.58%word-levelaccuracy.Thiseffectoftheensemblingisevenhigherwhenasubject-dependent
approachisused,wherethetestdatabelongstothesamesubjectsasthetrainingdata.
ACKNOWLEDGMENTS
Wewouldliketoextendaspecialthankstothefivevolunteerswhogenerouslydonatedtheirtime
andefforttohelpusrecordandcollectthenecessarydata.Theirunwaveringcommitmentwas
crucialtothesuccessofourproject.
REFERENCES
[1] SalarBasiri,AlirezaTaheri,AliF.Meghdari,MehrdadBoroushaki,andMinooAlemi.2023. DynamicIranianSign
LanguageRecognitionUsinganOptimizedDeepNeuralNetwork:AnImplementationviaaRobotic-BasedArchitecture.
InternationalJournalofSocialRobotics15,4(April2023),599â€“619. https://doi.org/10.1007/s12369-021-00819-0
[2] JiannanChao,FurongTang,andLeiXu.2022. DevelopmentsinAlgorithmsforSequenceAlignment:AReview.
Biomolecules12,4(April2022),546. https://doi.org/10.3390/biom12040546
[3] TusharChouhan,AnkitPanse,AnveshKumarVoona,andS.M.Sameer.2014.Smartglovewithgesturerecognition
abilityforthehearingandspeechimpaired.InProceedingsofthe2014IEEEGlobalHumanitarianTechnologyConference
-SouthAsiaSatellite(GHTC-SAS).IEEE,Trivandrum,India,105â€“110. https://doi.org/10.1109/GHTC-SAS.2014.6967567
[4] JosephDelPreto,JosieHughes,MatteoDâ€™Aria,MarcoDeFazio,andDanielaRus.2022.AWearableSmartGloveand
ItsApplicationofPoseandGestureDetectiontoSignLanguageClassification.IEEERoboticsandAutomationLetters7,
4(Oct.2022),10589â€“10596. https://doi.org/10.1109/LRA.2022.3191232
[5] AlexGraves,SantiagoFernÃ¡ndez,FaustinoGomez,andJÃ¼rgenSchmidhuber.2006.Connectionisttemporalclassification:
labellingunsegmentedsequencedatawithrecurrentneuralnetworks.InProceedingsofthe23rdinternationalconference
onMachinelearning(ICML).ACMPress,Pittsburgh,Pennsylvania,369â€“376. https://doi.org/10.1145/1143844.1143891
[6] HezhenHu,WengangZhou,JunfuPu,andHouqiangLi.2021.Global-LocalEnhancementNetworkforNMF-Aware
SignLanguageRecognition. ACMTransactionsonMultimediaComputing,Communications,andApplications17,3
(Aug.2021),1â€“19. https://doi.org/10.1145/3436754
[7] YinchengJin,YangGao,YanjunZhu,WeiWang,JiyangLi,SeokminChoi,ZhangyuLi,JagmohanChauhan,AnindK.
Dey,andZhanpengJin.2021.SonicASL:AnAcoustic-basedSignLanguageGestureRecognizerUsingEarphones.In
ProceedingsoftheACMonInteractive,Mobile,WearableandUbiquitousTechnologies(IMWUT),Vol.5.ACM,NewYork,
NY,USA,1â€“30. https://doi.org/10.1145/3463519
[8] YinchengJin,ShiboZhang,YangGao,XuhaiXu,SeokminChoi,ZhengxiongLi,HenryJ.Adler,andZhanpeng
Jin.2023. SmartASL:"Point-of-Care"ComprehensiveASLInterpreterUsingWearables.InProceedingsoftheACM
onInteractive,Mobile,WearableandUbiquitousTechnologies(IMWUT),Vol.7.ACM,NewYork,NY,USA,1â€“21.
https://doi.org/10.1145/3596255
[9] AliKarami,BahmanZanj,andAzadehKianiSarkaleh.2011.Persiansignlanguage(PSL)recognitionusingwavelet
transformandneuralnetworks.ExpertSystemswithApplications38,3(March2011),2661â€“2667. https://doi.org/10.
1016/j.eswa.2010.08.056
[10] SaraAskariKhomamiandSinaShamekhi.2021. PersiansignlanguagerecognitionusingIMUandsurfaceEMG
sensors.Measurement168(Jan.2021),108471. https://doi.org/10.1016/j.measurement.2020.108471
[11] WenguoLi,ZhizengLuo,andXugangXi.2020. MovementTrajectoryRecognitionofSignLanguageBasedon
OptimizedDynamicTimeWarping.Electronics9,9(Aug.2020),1400. https://doi.org/10.3390/electronics9091400
[12] YuxuanLiu,XijunJiang,XinggeYu,HuaidongYe,ChaoMa,WanyiWang,andYoufanHu.2023.Awearablesystem
forsignlanguagerecognitionenabledbyaconvolutionalneuralnetwork. NanoEnergy116(Nov.2023),108767.
https://doi.org/10.1016/j.nanoen.2023.108767
[13] ChenghongLu,ShingoAmino,andLeiJing.2023. DataGlovewithBendingSensorandInertialSensorBasedon
WeightedDTWFusionforSignLanguageRecognition. Electronics12,3(Jan.2023),613. https://doi.org/10.3390/
electronics12030613
[14] AnshulMittal,PradeepKumar,ParthaPratimRoy,RamanBalasubramanian,andBidyutB.Chaudhuri.2019. A
ModifiedLSTMModelforContinuousSignLanguageRecognitionUsingLeapMotion.IEEESensorsJournal19,16
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.20 Salmankhahetal.
(Aug.2019),7056â€“7063. https://doi.org/10.1109/JSEN.2019.2909837
[15] NitinThoppeyMuralidharan,RahulRamS.,RohidhM.R.,SenthilNathanM.,andHarikumarM.E.2022.Modelling
ofSignLanguageSmartGloveBasedonBitEquivalentImplementationUsingFlexSensor.In2022International
ConferenceonWirelessCommunicationsSignalProcessingandNetworking(WiSPNET).IEEE,Chennai,India,99â€“104.
https://doi.org/10.1109/WiSPNET54241.2022.9767137
[16] SaulB.NeedlemanandChristianD.Wunsch.1970. Ageneralmethodapplicabletothesearchforsimilarities
intheaminoacidsequenceoftwoproteins. JournalofMolecularBiology 48,3(March1970),443â€“453. https:
//doi.org/10.1016/0022-2836(70)90057-4
[17] AliSanjabi,AbbasAliBehmanesh,ArdavanGuity,SaraSiyavoshi,MartinWatkins,andJulieA.Hochgesang.2016.
ZabanEsharehIrani(ZEI)andItsFingerspellingSystem. SignLanguageStudies 16,4(2016),500â€“534. https:
//doi.org/10.1353/sls.2016.0010
[18] PanneerSelvamSanthalingam,AlAminHosain,DingZhang,ParthPathak,HuzefaRangwala,andRajaKushalnagar.
2020. mmASL:Environment-IndependentASLGestureRecognitionUsing60GHzMillimeter-waveSignals.In
ProceedingsoftheACMonInteractive,Mobile,WearableandUbiquitousTechnologies(IMWUT),Vol.4.ACM,NewYork,
NY,USA,1â€“30. https://doi.org/10.1145/3381010
[19] JiachengShangandJieWu.2017. ARobustSignLanguageRecognitionSystemwithMultipleWi-FiDevices.In
ProceedingsoftheWorkshoponMobilityintheEvolvingInternetArchitecture(MobiArch).ACM,LosAngelesCAUSA,
19â€“24. https://doi.org/10.1145/3097620.3097624
[20] S.Sharma,R.Gupta,andA.Kumar.2023. Continuoussignlanguagerecognitionusingisolatedsignsdataand
deeptransferlearning. JournalofAmbientIntelligenceandHumanizedComputing14,3(March2023),1531â€“1542.
https://doi.org/10.1007/s12652-021-03418-z
[21] JulieD.Thompson,DesmondG.Higgins,andTobyJ.Gibson.1994. CLUSTALW:improvingthesensitivityof
progressivemultiplesequencealignmentthroughsequenceweighting,position-specificgappenaltiesandweight
matrixchoice.NucleicAcidsResearch22,22(1994),4673â€“4680. https://doi.org/10.1093/nar/22.22.4673
[22] ZhiboWang,TengdaZhao,JinxinMa,HongkaiChen,KaixinLiu,HuajieShao,QianWang,andJuRen.2020.Hear
SignLanguage:AReal-timeEnd-to-EndSignLanguageRecognitionSystem.IEEETransactionsonMobileComputing
21,7(2020),2398â€“2410. https://doi.org/10.1109/TMC.2020.3038303
[23] FengWen,ZixuanZhang,TianyiyiHe,andChengkuoLee.2021. AIenabledsignlanguagerecognitionandVR
spacebidirectionalcommunicationusingtriboelectricsmartglove.NatureCommunications12,1(Sept.2021),5378.
https://doi.org/10.1038/s41467-021-25637-w
[24] JianWu,LuSun,andRoozbehJafari.2016.AWearableSystemforRecognizingAmericanSignLanguageinReal-Time
UsingIMUandSurfaceEMGSensors.IEEEJournalofBiomedicalandHealthInformatics20,5(Sept.2016),1281â€“1290.
https://doi.org/10.1109/JBHI.2016.2598302
[25] HuaiwenZhang,ZihangGuo,YangYang,XinLiu,andDeHu.2023. C2ST:Cross-modalContextualizedSequence
TransductionforContinuousSignLanguageRecognition.InProceedingsofthe2023IEEE/CVFInternationalConference
onComputerVision(ICCV).IEEE,Paris,France,20996â€“21005. https://doi.org/10.1109/ICCV51070.2023.01925
[26] QianZhang,JiaZhenJing,DongWang,andRunZhao.2022.WearSign:PushingtheLimitofSignLanguageTranslation
UsingInertialandEMGWearables.InProceedingsoftheACMonInteractive,Mobile,WearableandUbiquitousTechnologies
(IMWUT),Vol.6.ACM,NewYork,NY,USA,1â€“27. https://doi.org/10.1145/3517257
[27] QianZhang,DongWang,RunZhao,andYinggangYu.2019.MyoSign:enablingend-to-endsignlanguagerecognition
withwearables.InProceedingsofthe24thInternationalConferenceonIntelligentUserInterfaces(IUI).ACM,Marinadel
RayCalifornia,650â€“660. https://doi.org/10.1145/3301275.3302296
[28] ZhihaoZhou,KyleChen,XiaoshiLi,SonglinZhang,YufenWu,YihaoZhou,KeyuMeng,ChenchenSun,Qiang
He,WenjingFan,EndongFan,ZhiweiLin,XulongTan,WeiliDeng,JinYang,andJunChen.2020. Sign-to-speech
translationusingmachine-learning-assistedstretchablesensorarrays.NatureElectronics3,9(June2020),571â€“578.
https://doi.org/10.1038/s41928-020-0428-6
[29] RonglaiZuoandBrianMak.2024.ImprovingContinuousSignLanguageRecognitionwithConsistencyConstraints
andSignerRemoval.ACMTransactionsonMultimediaComputing,Communications,andApplications20,6(June2024),
1â€“25. https://doi.org/10.1145/3640815
ACMTrans.MultimediaComput.Commun.Appl.,Vol.1,No.1,Article.Publicationdate:June2024.