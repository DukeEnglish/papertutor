StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal
CHONGJIEYEâˆ— andLINGTENGQIUâˆ—,TheChineseUniversityofHongkong,Shenzhen,China
XIAODONGGU,AlibabaGroup,China
QIZUO,AlibabaGroup,China
YUSHUANGWU,TheChineseUniversityofHongkong,Shenzhen,China
ZILONGDONG,AlibabaGroup,China
LIEFENGBO,AlibabaGroup,China
YULIANGXIUâ€ ,MaxPlanckInstituteforIntelligentSystems,Germany
XIAOGUANGHANâ€ ,TheChineseUniversityofHongkong,Shenzhen,China
I. Monocular Surface Recon
II. Multi-view Surface Recon
III. Normal Enhancement
Stable & Sharp Normal Estimation Real-World Applications
Fig.1. WeproposeStableNormal,whichtailorsthediffusionpriorsformonocularnormalestimation.Unlikepriordiffusion-basedworks,wefocus
onenhancingestimationstabilitybyreducingtheinherentstochasticityofdiffusionmodels(i.e.,StableDiffusion[Rombachetal.2021]).Thisenables
â€œStable-and-Sharpâ€normalestimation,whichoutperformsmultiplebaselines(tryCompare),andimprovesvariousreal-worldapplications(tryDemo).
Thisworkaddressesthechallengeofhigh-qualitysurfacenormalestima- previousattemptsstillstrugglewithstochasticinference,conflictingwith
tionfrommonocularcoloredinputs(i.e.,imagesandvideos),afieldwhich thedeterministicnatureoftheImage2Normaltask,andcostlyensembling
hasrecentlybeenrevolutionizedbyrepurposingdiffusionpriors.However, step,whichslowsdowntheestimationprocess.Ourmethod,StableNormal,
mitigatesthestochasticityofthediffusionprocessbyreducinginference
âˆ—EqualContribution
variance,thusproducingâ€œStable-and-Sharpâ€normalestimateswithoutany
â€ CorrespondingAuthor
additionalensemblingprocess.StableNormalworksrobustlyunderchal-
Authorsâ€™ addresses: Chongjie Ye, chongjieye@link.cuhk.edu.cn; Lingteng Qiu, lengingimagingconditions,suchasextremelighting,blurring,andlow
220019047@link.cuhk.edu.cn,TheChineseUniversityofHongkong,Shenzhen,China; quality.Itisalsorobustagainsttransparentandreflectivesurfaces,aswellas
XiaodongGu,dadong.gxd@alibaba-inc.com,AlibabaGroup,China;QiZuo,muyuan. clutteredsceneswithnumerousobjects.Specifically,StableNormalemploys
zq@alibaba-inc.com,AlibabaGroup,China;YushuangWu,yushuangwu@link.cuhk.
acoarse-to-finestrategy,whichstartswithaone-stepnormalestimator
edu.cn,TheChineseUniversityofHongkong,Shenzhen,China;ZilongDong,list.dzl@
alibaba-inc.com,AlibabaGroup,China;LiefengBo,liefeng.bo@alibaba-inc.com,Al- (YOSO)toderiveaninitialnormalguess,thatisrelativelycoarsebutre-
ibabaGroup,China;YuliangXiu,yuliang.xiu@tuebingen.mpg.de,MaxPlanckInstitute liable,thenfollowedbyasemantic-guidedrefinementprocess(SG-DRN)
forIntelligentSystems,Germany;XiaoguangHan,hanxiaoguang@cuhk.edu.cn,The thatrefinesthenormalstorecovergeometricdetails.Theeffectivenessof
ChineseUniversityofHongkong,Shenzhen,China.
4202
nuJ
42
]VC.sc[
1v46861.6042:viXra2 â€¢ Ye,etal.
StableNormalisdemonstratedthroughcompetitiveperformanceinstandard
datasetssuchasDIODE-indoor,iBims,ScannetV2andNYUv2,andalso
invariousdownstreamtasks,suchassurfacereconstructionandnormal
enhancement.TheseresultsevidencethatStableNormalretainsboththe
â€œstabilityâ€ andâ€œsharpnessâ€ foraccuratenormalestimation.StableNormal
representsababyattempttorepurposediffusionpriorsfordeterministices-
timation.Todemocratizethis,codeandmodelshavebeenpubliclyavailable Input GenPercept GeoWizard Ours
inhf.co/Stable-X. [Xuetal.2024] [Fuetal.2024b]
CCSConcepts:â€¢Computingmethodologiesâ†’Reconstruction.
Fig.2. ComparativeAnalysisofNormalEstimators:â€œStabilityâ€vs.
AdditionalKeyWordsandPhrases:MonocularNormalEstimation,Diffusion â€œSharpnessâ€.One-stepGenPerceptcompromisesthehigh-frequencyde-
Model,SurfaceReconstruction tailsandproducesoverly-smoothnormalsforobjectsonthetable,while
GeoWizardproducesseeminglysharpnormals,butneithercorrectnorsta-
1 INTRODUCTION ble.Ourmethodwellbalancesstabilityandsharpness.The redboxes
highlightthevisualdifferencementionedabove.
Normalmap,asa2.5Drepresentation,bridges2Dand3Dworlds.In
3Dmodeling,objectsurfacesaretypicallyrepresentedbypolygons.
Normalmapsaddillusorysurfacedetailstothesepolygons,which
enhancestheirrealism.In2Ddomain,ifaccuratelyestimatedfrom
in-the-wildpixels,taskssuchasrelightingorintrinsicdecompo-
sitionbecomefeasible,openingthedoortoabroadspectrumof
applications.StableNormalaimstoestimateaccurate&sharpsurface
normalsfrommonocularcoloredinputs(i.e.,images,videos).
Intheeraofdeeplearning,thisâ€œImage2Normalâ€taskhasbeen
wellexploredinalineofworks[Bansaletal.2016a;Eftekharetal.
2021; Eigen and Fergus 2015a; Fouhey et al. 2013a; Ranftl et al.
2021a;Wangetal.2015a].Recently,advancesindiffusion-based
imagegenerator,oftentrainedonlarge-scaledatasets[Schuhmann
et al. 2022], have shifted the vision communityâ€™s focus towards
repurposingthediffusionpriors[Rombachetal.2022a]toestimate
the geometric or intrinsic cues, such as depth [Ke et al. 2024a],
normal[Fuetal.2024b],andmaterials[Kocsisetal.2024]. Fig.3. High-variancenormalestimations.Weshowmultiplesamplesfor
Theseeffortshaveyieldedâ€œsharp-lookingâ€results(Fig.3).How- asinglesceneandvisualizethemeanandvarianceofthepredictednormals.
ever, human eyes lack the sensitivity to accurately perceive the Foreachsample,whilethenormalmapsexhibitsharpdetails,thereishigh
varianceinareaswithhigh-frequencycontent.Thishighvarianceinsharp
normalmaps.Despiteproducingâ€œsharp-lookingâ€normals,temporal
inconsistencyexists1,andtheresults,evenafterbeingensembled, regionsmakestheinferencelessreliable.
stilldeviatesignificantlyfromground-truthnormals(Fig.3).Simply
put,theseresultsareâ€œsharpâ€ butneitherâ€œcorrectâ€ norâ€œstableâ€.
GenPercept[Xuetal.2024],couldcompromisetherecoveryofhigh-
Weattributethistotwofactors:1)unstableimagingconditions,
frequencydetailsandresultinoverly-smoothnormals(SeeFig.2).
suchasextremelighting,dramaticcameramovement,motionblur,
Thus,findingabalancebetweenâ€œstabilityâ€vs.â€œsharpnessâ€isneeded.
andlow-qualityimages.2)inductivebiasofthediffusionprocess
SowepresentStableNormaltotacklethistrade-off.Itdemon-
â€” stochasticity. Such stochasticity contradicts the nature of the
stratesthat,areliableinitialization,coupledwithastablerefine-
estimationprocess,whichshouldbeasdeterministicaspossible.
ment,isessentialtoproducesharpandstablenormalestimates.
Therefore,acrucialquestionisraised:
Ourapproachfollowsthecoarse-to-finescheme:1)one-stepnormal
How can we mitigate the inherent stochasticity of the diffusion estimation(Section3.3)forreliableinitialization,and2)semantic-
processfordeterministicestimation? guideddiffusionrefinement(Section3.4)toprogressivelysharpen
thenormalmapsinasemantic-awaredirection.
Answeringthisquestioninthenormaldomainismoreurgent
Specifically,aShrinkageRegularizerisintroducedtotrainthe
thanindepthdomain.Sincemonoculardepthestimationtypically
one-step normal estimator, which reduces the training variance
estimatesaffine-invariantdepth(i.e.,depthvaluesuptoaglobal
by splitting the vanilla diffusion loss into generative and recon-
offsetandscale),whilesurfacenormalsarenotsubjecttoscaleand
structionterms.Thisone-stepestimator,namelyYOSO(You-Only-
translationambiguity.Thatistosay,givenasingleimage,thetask
Sample-Once),alreadyperformson-parwithcurrentstate-of-the-art
ofnormalestimation(one-to-onemapping),ismoreâ€œdeterminis-
DSINE[BaeandDavison2024],seeTable3.Additionally,Semantic-
ticâ€thandepthestimation(one-to-manymapping).However,elim-
GuidedDiffusionRefinementNetwork(SG-DRN)ispresentedto
inatingstochasticityfromthediffusionprocess,liketheone-step
enhancethestabilityofthediffusion-basedrefinementprocessby
1huggingface.co/docs/diffusers/main/en/using-diffusers/marigold_usage#frame-by- integratingDINOsemanticpriors.Suchpriorsdecreasesampling
frame-video-processing-with-temporal-consistency variancewhileenhancinglocaldetails,asshowninFig.6.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal â€¢ 3
WeevaluateStableNormalonDIODE-indoor,iBims,ScannetV2, inspiredbyvisualprompting[Baretal.2022],backgroundprompt-
andNYUv2datasets.Also,weshowhowourstrongnormalesti- ing[Baradadetal.2023]wasintroducedtoreducethedomaingap
matorimprovesvariousreconstructionscenarios(i.e.,object-level, betweensyntheticandrealdata,bysimplyplacingthesegmented
indoor-scene,andnormalintegration-based).Thesuperiorityof objectintoalearnedbackgroundâ€œpromptâ€.Despitesteadyadvance-
StableNormalissubstantiatedbothqualitativelyandquantitatively. ments,regression-basednormalestimators,trainedonlimitedand
PleasecheckthevideoandFig.1toseehowrobustStableNormal constraineddata,continuetofacegeneralizationissuesandstruggle
performsinchallengingconditions,suchasextremelighting,blur- tocapturefine-grainedgeometricdetails.
ring,objecttransparency&reflections,orclusteredscenes.
ThemaincontributionsofStableNormalareasfollows: 2.2 Diffusion-basedMonocularNormalEstimation
â€¢ Wepinpointthecriticalissuewhydiffusionpriorscannot
Recently,thecomputervisioncommunityhaswitnessedthebloom
bedirectly(w/obellsandwhistles,e.g.post-ensembling)
ofdiffusion-basedText-to-Image(T2I)modelanditsextensions[Pee-
applied on â€œImage2Normalâ€ task â€” the inherent conflict
blesandXie2022;Rombachetal.2021;Zhangetal.2023a].Several
betweentheâ€œstochasticâ€diffusionprocessandâ€œdeterministicâ€
workshaveexploredhowtoadaptthestrongpretrainedmodel,thus
requirementforgeometriccuesestimation.
repurposeitasgeometriccuesestimator[Fuetal.2024b;Jietal.
â€¢ Toaddressthisconflict,weproposeasimple-yet-effective
2023;Keetal.2024b;Liuetal.2023;Longetal.2023;Qiuetal.2024;
solution,namelyâ€œStableNormalâ€.Itjustifiesthatareliable
Zhaoetal.2023].Wonder3D[Longetal.2023]proposestomodelthe
initialization(YOSO),coupledwithastablerefinement(SG-
jointdistributionofcolorandnormaltoenhancetheirconsistency,
DRN),isessentialtoestimatesharpnormalssteadily.
whichhasbeenshowntoimprovethequalityofthefinal3Doutput.
â€¢ WeconductextensiveexperimentstoevaluateStableNor-
Richdreamer[Qiuetal.2024]concurrentlytrainsadepthandnormal
malâ€™s accuracy. It not only outperforms other baselines
diffusionmodelonthelarge-scaleLAION-2Bdataset[Schuhmann
byalargemargininhigh-qualityindoorbenchmarks(i.e.,
etal.2022],utilizingpredictionsfromtheoff-the-shelfnormaland
DIODE-indoor,iBims,andScannetV2),butalsofaraheadof
depthestimators[Lasingeretal.2019].Moreover,Geowizard[Fu
itspeers(i.e.,GeoWizard,DSINE)intermsofinferencesta-
etal.2024b]extendsWonder3Dbyaddingageometryswitcher
bilityatreal-worldscenarios,evenunderextremeconditions.
(indoor/outdoor/object)tosegregatethemulti-sourceddatadistri-
Thisstabilitybenefitsmanydownstreamtasks,seeFig.1.
butionofvariousscenesintodistinctsub-distributions.
2 RELATEDWORKS Althoughthesediffusion-basedapproachescancaptureâ€œsharp-
lookingâ€ surfacedetails,theseresultsactuallydeviatessignificantly
2.1 Regression-basedMonocularNormalEstimation
fromground-truthinnormalspace,owingtototheinherenthigh-
SurfacenormalestimationfrommonocularRGBinputshasbeen varianceofdiffusionprocess(seeFig.3).Thelargevarianceisfirst
extensivelystudied[Doetal.2020;EigenandFergus2015b;Fouhey introducedbyGaussianinitialization,whichispropagatedandam-
etal.2013b,2014;Huangetal.2019;LadickÃ½etal.2014;Liaoetal. plifiedintheentiremulti-stepdiffusionprocess(i.e.,signal-leak
2019;Qietal.2018,2022;Wangetal.2016,2020,2015b;Zhangetal. issue[Everaertetal.2024]).Infact,somepriorresearchhasex-
2019].Ingeneral,thepriorregression-basedmethodsconsistofa ploredthisissue,eitheremployinganaffine-invariantensembling
featureextractor,followedbyapredictionhead.Hoiemetal.[Hoiem strategyduringthepost-processingstage[Fuetal.2024b;Keetal.
etal.2005,2007]werethepioneersinframingthisclassictaskas 2024a],orcompletelydiscardingtheiterativemulti-stepgeneration
astatisticallearningproblem.Theoutputspacewasdiscretized, process,thusshiftingtowardsaone-stepperceptionproblem[Xu
andhandcraftedfeatureswereextractedtoclassifythenormals. etal.2024].
However,suchfeaturesaregenerallydesignedforspecificscenarios However, both strategies come with their own pitfalls: post-
andcannotgeneralizewelltounseenscenes. ensembling,whichappliestomultipleoutputs,iscomputationallyin-
Thisgeneralizationproblemwaslateraddressedbydeeplearning tensive.Theassumptionofaffineinvarianceoftenfailstogeneralize
techniquesinadata-drivenmanner[Bansaletal.2016b;Wangetal. acrossdifferenttypesofoutputs,likenormals.WhileGeoWizard[Fu
2015b].Morerecently,Omnidata-V2[Eftekharetal.2021],witha etal.2024b]exhibitssharperresultscomparedtoothertraditional
U-Netarchitecture[Ronnebergeretal.2015],istrainedonalarge- approaches,itdoesnotnotablyimprovequantitativeperformance,
scaledata(12M)capturedfromdiversescenesundervariouscamera suggestingthatdiffusion-basednormalestimatorsinducethedirec-
settings.Baeetal.[Baeetal.2021]proposetoestimatetheper-pixel tionaldeviationinnormalspace(seeFig.3).Furthermore,without
surfacenormalprobabilitydistribution,fromwhichtheexpected thepost-ensemblingstep,thediffusion-basedestimatorstendto
angularerrorcanbeinferredtoquantifythealeatoricuncertainty. produceoutputswithlargevariance(seeFig.3),highlightingits
ThetransitionfromCNNstovisiontransformers(ViT)hasfurther inherentstochasticnature.Regardingtheone-stepapproach,it
advancedthisfield,asdemonstratedbyDPT[Ranftletal.2021b]. oversimplifiesthemarkovchainofthediffusionprocess,smoothing
DSINE[BaeandDavison2024]rethinkshowtocorrectlymodel outintrinsiclocalgeometricdetails,leadingtothetypicalover-
theinductivebiasesforsurfacenormalestimation,andproposesto smoothingartifactsseeninotherregression-basedmethods[Bae
leveragetheper-pixelraydirection,andlearntherelativerotation andDavison2024;Eftekharetal.2021].Therefore,whenrepurpos-
betweennearbypixels.Theseeffortsdecreasetheneedforlarge- ingthediffusionmodelfordeterministicestimationtasks,suchas
scaletrainingdata,DSINEtrainedonlyon160Kimagessurpass normalestimation,atrade-offbetweenâ€œstabilityâ€ andâ€œsharpnessâ€
theOmnidata-V2,whichistrainedonover12Mimages.Recently, arises,whichrequirescarefulconsiderationbeforeproceeding.4 â€¢ Ye,etal.
3 METHOD VAE,inwhichğ‘istheadditionaltextpromptembedding(typically
3.1 PreliminariesonDiffusionModel obtainedbyCLIP[Radfordetal.2021]).
Diffusion Probabilistic Models [Ho et al. 2020; Song et al. 2020]
3.2 Diffusion-basedNormalEstimator
aimtomodeladatadistributionğ‘(ğ‘¥)bysequentiallytransforma
Gaussiandistributionviatheso-calledbackwarddiffusionprocess Apart from common multi-modal generation tasks (e.g., text-to-
ğ‘¥ ğ‘¡âˆ’1=ğµ ğ‘¡ğ‘¥ ğ‘¡âˆ’ğœ‡ ğœƒğœ–(ğ‘¥ ğ‘¡,ğ‘¡)+ğœ– ğ‘¡ inwhichğœ– ğ‘¡ âˆ¼N(0,ğœ ğ‘¡ğ¼)andğœ‡ ğœƒğœ– predicts image[Rombachetal.2021],text-to-3D[Pooleetal.2023]),the
theinjectednoise.Thisbackwardprocessisuniquelydetermined pre-traineddiffusionmodelshavealsoproventohavesurprisingly
byapredefinedforwarddiffusionprocessğ‘¥ ğ‘¡+1=ğ´ ğ‘¡ğ‘¥ ğ‘¡ +ğœ– ğ‘¡. goodzero-shotperformanceinseveraldiscriminativetasks,suchas
Asaclassicalexample,DDPM[Hoetal.2020]assumesthatthe classification[Lietal.2023b],andsegmentation[Lietal.2023c;Tian
initialGaussiandistributionN(0,I)canbeobtainedbyrunningthe etal.2024].Andsinceimage-to-imagetranslationcouldbeconsid-
followingforwarddiffusionprocess: eredasasingle-modalgenerationtask,different2Dmodalities(e.g.,
image,normal,depth,cannyedge)couldalsobeinterconverted[Ke
âˆš âˆš etal.2024a;Wangetal.2023;Zhangetal.2023a]withtheadapted
ğ‘(ğ‘¥ ğ‘¡)= ğ›¼ ğ‘¡ğ‘¥ 0+ 1âˆ’ğ›¼ ğ‘¡ğ,ğ‘¥ 0âˆ¼ğ‘(ğ‘¥),ğ‘¡ âˆˆ{0,1,...,ğ‘‡} (1)
orfine-tunedSDmodel.
where ğ âˆ¼ N(0,I),ğ‘‡ denotes the number of the time step, t is
thecurrenttimestep,andğ›¼ ğ‘¡ isthenoiseschedulecontrollinghow NormalEstimationwithSD.Sincenormalestimationcanbeseen
fastthedatadistributionistransformedintoastandardGaussian
astranslatinganRGBimageintoanormalmapimage,thediffusion
distribution.Asaresult,thebackwarddiffusionprocessinDDPM
priorfromSDcanalsobeeffectivelyutilized.Astraightforward
provestobe
approachistotaketheRGBimageastheconditioningsignalto
generatethecorrespondingnormalmaps,asinGeoWizard[Fuetal.
ğ‘¥ ğ‘¡âˆ’1= âˆš1 ğ›¼ ğ‘¡ğ‘¥ ğ‘¡ âˆ’ âˆšï¸ƒ ğ›¼ ğ‘¡(11 âˆ’âˆ’ Î ğ›¼ ğ‘¡ ğœğ‘¡ =0ğ›¼ ğœ)ğœ‡ ğœƒğœ– (ğ‘¥ ğ‘¡,ğ‘¡;)+ğœ ğ‘¡ğœ– (2) i2 d n0 it t2 i oo4 n ab] ls aa i tgn end na tlM ci osa dr ci eog m wol p id tu h[ tK e ade pbe reyt -a tfi rl r. as2 it n0 e e2 n d4 ca Vo] Ad. iM Engo enr te ch oes dp R ee G rc ,i B nfi ac in ma pl el uy ly, tt i ğ¸h m ğ‘›e a ,gc ao e nn dğ‘°-
ThelossfunctionforDDPMisadenosingautoencoderloss: then,similartoControlNet[Zhangetal.2023a],wetransformthis
latentcodeğ¸ğ‘›(ğ‘°)throughanadditionalencoderğ‘“ ğœ™,intothecontrol
ğ¿ ğœƒ =E ğ’™0,ğ’„,ğ‘¡(cid:13) (cid:13)ğ’™0âˆ’ğğœƒğ’™0(ğ’™ğ‘¡,ğ’„,ğ‘¡)(cid:13) (cid:13)2 (3) signalforthedecoderblocksoftheU-NetinSD.Thedecoderblocks
ofU-Net,whichisparameterizedbyğœƒ,andencoderğ‘“ ğœ™ aretrained
Reparameterization.Itisoftenconvenienttoreparameterizedif-
withthefollowingloss(inğ-reparameterization):
fusionmodelsaspredictingtheone-stepdenoisedoutput(called
ğ‘¥ 0-reparameterization) instead of the âˆšinjected noise (the default
ğ-reparameterization).InDDPM,ğ‘¥ ğ‘¡ = ğ›¼ ğ‘¡ğ‘¥ 0+ğœ– ğ‘¡ andthereforeloss ğ¿ ğœƒ,ğœ™ =E ğ,ğ’„,ğ‘°,ğ‘¡(cid:13) (cid:13)ğâˆ’ğğœƒğ(ğ’™ğ‘¡,ğ’„,ğ‘¡,ğ‘“ ğœ™(ğ¸ğ‘›(ğ‘°)))(cid:13) (cid:13)2 (6)
forğ-reparameterizationis(uptoascale)
ğ¿ ğœƒ =E ğ,ğ’„,ğ‘¡(cid:13) (cid:13)ğâˆ’ğğœƒğ(ğ’™ğ‘¡,ğ’„,ğ‘¡)(cid:13) (cid:13)2 (4) w enh ce or de eğ‘° di fs rot mhe thin ep gu rt oi um na dg te r, uğ‘¥ thğ‘¡ n= oğ‘ rm(ğ¸ ağ‘› l( mğ‘ ag pt) ğ‘) i gs tt ah te til mat ee sn tt epfe ğ‘¡a .ture
Duringinference,itisstraightforwardtoestimatethenormal
DiffusionSamplers.Whenthenumberoftimestepsğ‘‡ islarge
mapforagivenRGBimagebyrunninganywaysamplingalgorithm
enough,boththeforwarddiffusionprocessandthebackwardone
forthetrained(conditional)diffusionmodel.Theestimatednormal
canbeseenasapproximationsoftheircontinuouscounterparts
map,thoughlookingsharp,isstochasticallygenerated.Weobserver
thatcanbemodeledbystochasticdifferentialequations(SDEs).It
thatthehighvarianceintheestimatednormalmapsaretypically
isthereforepossibletosamplefromatrainedDDPMmodelwith
misalignedwiththecorrespondinginputimages.Whileensemble-
SDEsolversorsamplersotherthanthedefaultDDPMbackward
likemethodscanbeused(asproposedinMarigold[Keetal.2024a])
diffusionprocessforbetterefficiency(atacostofprecision).Asan
toreducethevariancethroughaveraging,theresultsarestillless
example,DDIMgeneratessampleswith
thansatisfactoryandtheentireensemblingprocessisquitetime-
âˆš consuming(seeFig.5).
ğ‘¥
ğ‘¡âˆ’1=âˆš
ğ›¼
ğ‘¡âˆ’1Â·(cid:18)ğ‘¥ ğ‘¡ âˆ’ 1âˆ’ğ›¼ âˆšğ‘¡ ğ›¼Â·ğğœƒğ(ğ‘¥ ğ‘¡,ğ’„,ğ‘¡)(cid:19)
+direction(ğ‘¥ ğ‘¡)+ğœğ
ğ‘¡ TheVariancefromtheDiffusionModel.Asarguedabove,the
(5)
majorissueofdiffusion-basednormalestimationisthehighvariance
whereğœ isascalartocontroltheamountofinjectednoiseduring
inthediffusioninferenceprocedure.Thesourcesofrandomness
theprocess.Notably,ifğœ issetto0,DDIMbecomesadeterministic
indiffusionsamplingalgorithmsaremostly1)theinitialGaussian
sampler(i.e.,independentofanynoise).
noiseand2)allintermediateinjectedGaussiannoises.Thus,we
Text-to-image(T2I)diffusionmodels..Differentfromuncondi- suggest mitigating the variance through a dual-phase inference
tionaldiffusionmodels,T2Idiffusionmodelsaimtogenerateimages approach.Intheinitialphase,areliable"initialestimate"withhigh
withoptionaltextprompts.AclassicalexampleisStableDiffusion certaintyisgenerated.Subsequently,asecondphaseofrefinement
(SD)[Rombachetal.2021],adiffusionmodelğœ‡ ğœƒ(ğ‘§ ğ‘¡,ğ‘¡,ğ‘)builtwith iscarriedoutwitharestrictednumberofdiffusionsamplingsteps,
aU-Netarchitectureandtrainedonthelatentspaceofapretrained ensuringminimalGaussiannoiseinjection.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal â€¢ 5
Fig.4. OverviewoftheStableNormal.Theoverallpipelineiscomposedoftwostages:1)YOSOaimstoproduceaconfidentinitializationğ‘¥ ğ‘¡+forstagetwo
withanovelShrinkageRegularizer;2)SG-DRNplaystheroleofstabledenoising,byleveragingthestrongersemanticcontrolinformationextractedfrom
DINO[Oquabetal.2024].ThetextualpromptfortheU-Netinbothstagesissettoâ€œThe normal mapâ€.
3.3 You-Only-Sample-OnceNormalInitialization 3.4 Semantic-guidedNormalRefinement
One-stepEstimation.Theone-stepsamplingstrategyfornormal Weobservethatforsubsequentsamplingstepsthatrefinetheinitial
estimationisfirstlyintroducedinGenPercept[Xuetal.2024]:no normalestimate,thedesignedimage-conditioneddiffusionmodel
Gaussiannoiseisintroduced,theestimationprocessisdeterministic, tendstoleveragelocalinsteadglobalinformationintheRGBimage
butatacostofoverly-smoothingoutputs.Weinsteadperformone- input.However,itisintuitiveimportantnottorelysolelyonlocal
stepsamplingwithaGaussiannoiseinputtobalancethesharpness imageinformation:forinstance,todeterminethenormalsforpixels
andstability.Inmathematicalterms,weadoptğ‘¥ ğ‘¡+-parameterization that correspond to a wall, global information is typically much
insteadofğ‘¥ 0-parameterizationandreformualtethelossfunction moreinformative.Wethereforeproposetoincludesemantic(and
showninEq.(6)tothefollowingoneshowninEq.(7): global)featuresfromapre-trainedencoder(forwhichweuseDINO
features[Oquabetal.2024])asanauxiliaryconditionsignal.
ğ¿ ğœƒ,ğœ™ =E ğ’™ğ‘¡+,ğ’„,ğ‘°,ğ‘¡+(cid:13) (cid:13)ğ’™ğ‘¡+âˆ’ğğœƒğ‘¥ ğ‘¡+(ğ’™âˆ,ğ’„,ğ‘¡+,ğ‘“ ğœ™(ğ¸ğ‘›(ğ‘°)))(cid:13) (cid:13)2 (7) A der pc ih cti ete dc it nu Fr ie g.o 4f (bS )G ,- wD hR erN e. tT hehe ime an gti ere coa nrc dh iti it oe nct bu rr ae no cf hS iG s- dD enR oN tei ds
whereğ‘¥ âˆdenotesanoisysamplefromtheGaussiandistribution b exy ceğ‘“ ğœ’ p. tI ft oe rm anpl eo xy trs aa lin ge ht tw wo er igk ha tr sc eh mit ae nct tu icr -e ins ji em cti il oa nrt no ett wha ot rkin
ğ‘”
ğœ“YO thS aO
t
resultedfromrunningtheforwarddiffusionprocess(asinEq.(1))
injectsthesemanticfeaturesintotheencoderlayeroftheU-Netin
withğ‘¡ approachesinfinityandTissetto1000.Notethatweare
SG-DRN(denotedbyğœ‡ ğœ).
interestedinmappingadistributionfroma(standard)Gaussian
onetoonethatcorrespondstotimeğ‘¡+ âˆˆ (0,ğ‘‡),insteadtothatat Semantic-injectionNetwork.Forefficiency,weimplementalight-
timeğ‘¡ =0.Wecallsuchone-stepestimationâ€”You-Only-Sample- weightnetworktofeedsemanticfeaturesintotheU-Net.Specifically,
Once(YOSO).Unfortunately,naÃ¯velyestimatingğ‘¥ ğ‘¡+fromaGaussian thenetworkemploysfourconvlayers(with3Ã—3kernels,1Ã—1strides,
distributionmeanslearningamany-to-onemapping,whichishard. andchannelcountsof16,32,64,128)thatareakintothecondition
Toaddressthisissue,weproposetouseaShrinkageRegularizer. encoderin[Zhangetal.2023a]toalignthespatialresolutionof
DINOfeatureswiththatofnoisylatentfeatures.GiventhatDINO
ShrinkageRegularizer.Wefurtherreducethevarianceinthepre- featurestypicallyhavealowerresolutionthandiffusionlatentfea-
dictednormalmapsbytrainingthediffusionmodelwitharegular- tures,forresolutionalignmentweuseFeatUp[Fuetal.2024a]and
izedloss.Insteadofpenalizingtheentropyofthepredicteddistribu- bi-linearinterpolationtoupsampleDINOfeatures.Thenoisylatent
tionwhichisgenerallyhard,wetakeadifferentpathbyâ€œshrinkingâ€ featuresareaddedbythealignedDINOfeaturesbeforebeingfed
thedistributionofpredictednormalmaps,ğœ‡ ğœƒğ‘¥ ğ‘¡+ (ğ‘¥ âˆ,ğ‘,ğ‘¡,ğ‘“ ğœ™(ğ¸ğ‘›(ğ¼))), intothedenoisingU-Net.Duringtraining,thenetworkweightsare
ğ‘¥+ initializedusingaGaussiandistribution,exceptthefinalprojection
totheDiracdeltafunctionğ›¿(ğ‘¥âˆ’ğœ‡ ğœƒğ‘¡(0,ğ‘,ğ‘¡,ğ‘“ ğœ™(ğ¸ğ‘›(ğ¼)))):
layer,whichisinitializedasazeroconvolution.
Loss function. Following the I2VGen-XL [Zhang et al. 2023b],
ğ¿
ğœƒ,ğœ™
=(cid:40) E Eğ’™ ğ’™ğ‘¡ ğ‘¡+ +, ,ğ’„ ğ’„, ,ğ‘° ğ‘°, ,ğ‘¡ ğ‘¡+ +(cid:13) (cid:13)
(cid:13)
(cid:13)ğ’™ ğ’™ğ‘¡ ğ‘¡+ +âˆ’ âˆ’ğ ğğœƒ ğœƒğ‘¥ ğ‘¥ğ‘¡ ğ‘¡+ +( (ğ’™ 0,âˆ ğ’„, ,ğ‘¡ğ’„ ,, ğ‘“ğ‘¡ ğœ™,ğ‘“ (ğœ™ ğ¸( ğ‘›ğ¸ (ğ‘› ğ‘°( )ğ‘° )))
(cid:13)
(cid:13)) 2)(cid:13) (cid:13) ,2, ifğ‘ifğ‘ <â‰¥
ğœ†
ğœ† w fue ncr te ip oa nra om fğœ‡e ğœte cr aiz ne bt eh de eğœ‡ fiğœ neto dt ah s:eğ‘¥ 0-reparameterization.Theloss
whereğ‘ âˆ¼ğ‘ˆ(0,1),andğœ†=0.4. (8) ğ¿ ğœƒ,ğœ’,ğœ“ =E ğ’™0,ğ’„,ğ‘°,ğ’…,ğ‘¡(cid:13) (cid:13) (cid:13)ğ’™0âˆ’ğğœğ‘¥ 0 (cid:16) ğ’™ğ‘¡,ğ’„,ğ‘¡,ğ‘“ ğœ’(ğ¸ğ‘›(ğ‘°)),ğ‘” ğœ“(ğ’…)(cid:17)(cid:13) (cid:13) (cid:13)2 (9)6 â€¢ Ye,etal.
whereğ’…istheprocessedsemanticfeaturesextractedfromDINO underperformedcomparedtotheoriginalreleasedversion,sowe
andğ‘¡+ âˆˆ (0,ğ‘‡). decidedtousetheoriginalmodelforourevaluation.ForGeoWizard,
sincethetrainingcodeisnotavailable,weutilizedthepre-released
3.5 HeuristicDenoisingSampling model4forourevaluations.Weconsiderthisapproachfairbecause
Duringinference,weapplyDDIMtoobtainourfinalnormalpredic- weusethesametrainingdataset.
tion,asEq.(10).Specifically,theinitialnormallatentğ‘¥ ğ‘¡+,predicted ThetestingdataforevaluationincludesthechallengingDIODE-
fromYOSO,isfedintothesolverwith10-stepDDIM.Empirically, indoor[Vasiljevicetal.2019],iBims[Kochetal.2018],ScanNetV2
wesettheinitialsamplingstepğ‘¡+as401,whichprovidesanoptimal [Daietal.2017],andNYUv2[Silbermanetal.2012]datasets.As
compromisebetweenstabilityandsharpness. presented in Tab. 2, our method achieves superior performance
acrossiBims,ScanNetV2,andDIODE-indoorbyalargemargin.On
ğ‘¥ ğ‘¡âˆ’1=âˆš ğ›¼ ğ‘¡âˆ’1Â·(ğ‘¥Ë†0)+direction(ğ‘¥ ğ‘¡)+ğœğ NYUv2,ourmethodisslightlyinferiortoDSINE.Wearguethat
bothScannetandNYUV2arecapturedusinglow-qualitysensors,
ğ‘¥Ë†0=ğğœğ‘¥ 0 (cid:16) ğ’™ğ‘¡,ğ’„,ğ‘¡,ğ‘“ ğœ’(ğ¸ğ‘›(ğ‘°)),ğ‘” ğœ“(ğ’…)(cid:17) (10) thustheirGTnormalarenotaccurate,whichisalsomentioned
ğ‘¥ ğ‘¡+ =ğğœƒğ‘¥ ğ‘¡+ (cid:16) ğ’™âˆ,ğ’„,ğ‘¡+,ğ‘“ ğœ™(ğ¸ğ‘›(ğ‘°))(cid:17) i cn omG pe ao rW isi oz na srd o[ nFu che at lla el n. g2 i0 n2 g4b sc] e). nF ai rg iou sr ,e w9 hs ih chow ds emth oe nsq tu ra al ti et sat ti hve e
accuracyandsharpnessofStableNormal.
4 EXPERIMENTS
Inthissection,wecompareStableNormalwithotherSOTAs(i.e., (a)OutputVarianceAnalysis (b)InferenceTimeAnalysis
DSINE,Marigold,GenPerceptandGeoWizard)invariousreal-world
datasets.Inaddition,anablationstudyisconductedtodemonstrate
theeffectivenessofdifferentcomponents,i.e.,YOSOandSG-DRN.
4.1 ExperimentalSetup
Datasets. Following GeoWizard [Fu et al. 2024b], our model is
trainedonacomprehensivedatasetofhigh-resolutionimagesand
groundtruthnormalsrenderedfromsyntheticscenesacrossthree
categories:25,463samplesfromHyperSim[Robertsetal.2021]and EnsembleTimes EnsembleTimes
50,884samplesfromReplica[Straubetal.2019]forindoorenvi-
ronments;76,048samplesfrom3DKenBurns[Niklausetal.2019] Fig.5. Thecomparisonofoutputvarianceandinferencetimebetween
and39,630syntheticcityimagesfromMatrixCity[Lietal.2023a]; ourmethod,GeoWizard,andMarigold.Theleftplotshowstheoutput
varianceoverensembletime,whiletherightplotdisplaystheinference
and85,997background-free3DobjectsfromObjaverse[Deitkeetal.
time(includingensembling).Itisimportanttonotethatourmethoddoes
2022].MostofthedataisphotorealisticallyrenderedusingBlender
notemploytheensemblestrategyandonlyrequiresasingleforwardpass.
andUnrealEngine,totalingover250,000image-normalpairs.
Implementation.Wefine-tunetheStableDiffusionV2.12using
theAdamWoptimizer[LoshchilovandHutter2019]withafixed Figure5comparestheinferencevarianceandtimebetweenour
learningrateof3e-5.Pleasecheckoutmoreimplementationdetails methodandGeoWizardontheDIODE-indoordataset.Specifically,
inSupMat.â€™sAppendixA. weestimateeachimage10timesusingdifferentinitializationseeds,
Metrics.Forevaluation,wefollowthemetricsoutlinedinDSINE[Bae allowing us to calculate the variance for each individual image.
andDavison2024]andcalculatetheangularerrorbetweentheesti- Wethencalculatedtheoverallvarianceforeachmodelbyaverag-
matedandgroundtruthnormalmaps.Wereportboththemeanand ingthesevaluesacrosstheentiredataset.AsshowninFig.5(a),
medianangularerrors,withlowervaluesindicatingbetteraccuracy. GeoWizardemploysanensemblestrategytoreducethevariance
Additionally,wemeasurethepercentageofpixelswithanangular oftheoutput.However,ourapproachsignificantlydecreasesthe
errorbelowspecifiedthresholdsof11.25â—¦,22.5â—¦,and30.0â—¦,where outputvariance(0.410vs.1.370)withoutintroducinganyensemble
higherpercentagesreflectsuperiorperformance. strategies.Furthermore,theensemblestrategycompromisesspeed
to achieve a lower variance. Figure 5 (b) shows that GeoWizard
4.2 Comparisontothestate-of-the-art
samplesfivetimes(approximately10seconds)toreachavariance
WechooseDSINE[BaeandDavison2024],Marigold[Keetal.2024a] of1.370,whileourmethodachievesavarianceof0.410within3
(normalversion3,denoteasMarigoldâ€ ),GenPercept[Xuetal.2024] secs.TheinferencespeedwastestedonasingleA100GPU.
andGeoWizard[Fuetal.2024b]forcomparison.DSINEistheSOTA
4.3 Ablationstudy
methodamongallregression-basedmethodsandGeoWizardisthe
SOTAamongallexistingdiffusion-basedones.Duetotheunavail- Weconductablationstudiestoanalyzethecontributionofeach
abilityofDSINEâ€™strainingdata,weretrainedthemodelusingthe componentinourframeworkacrossfourdatasets:NYUv2,Scan-
providedcodeandourdataset.Nonetheless,ourretrainedmodel Net,iBims-1,andDIODE-indoor.Bothquantitativeandqualitative
resultsaresummarizedinTable3andFig.6.
2hf.co/stabilityai/stable-diffusion-2-1
3hf.co/prs-eth/marigold-normals-lcm-v0-1 4hf.co/lemonaddie/GeowizardStableNormal:ReducingDiffusionVarianceforStableandSharpNormal â€¢ 7
Table1. QuantitativecomparisonontheDTUDataset[Jensenetal.2014].WeshowtheChamferdistance(LowerisBetter).Ourmethodachievesthe
highestreconstructionaccuracyamongothernormalestimationmethods.Differentcellcolorsreferstobest,and2nd-best.
24â†“ 37â†“ 40â†“ 55â†“ 63â†“ 65â†“ 69â†“ 83â†“ 97â†“ 105â†“ 106â†“ 110â†“ 114â†“ 118â†“ 122â†“ Meanâ†“
2DGS[Huangetal.2024] 0.48 0.91 0.39 0.39 1.01 0.83 0.81 1.36 1.27 0.76 0.70 1.40 0.40 0.76 0.52 0.80
2DGS+DSINE[BaeandDavison2024] 0.62 0.76 0.49 0.38 1.20 1.04 0.68 1.34 1.35 0.76 0.61 0.83 0.42 0.57 0.44 0.76
2DGS+GeoWizard[Fuetal.2024b] 0.54 0.75 0.43 0.38 1.15 0.80 0.66 1.28 1.47 0.80 0.61 0.81 0.40 0.59 0.50 0.75
2DGS+Ours 0.51 0.72 0.41 0.38 1.18 0.86 0.61 1.29 1.09 0.84 0.59 0.79 0.36 0.54 0.43 0.70
Table2. Quantitativeevaluation.HerewecomparewithDSINE[Baeand Table4. AblationstudyoftheeffectivenessofShrinkageRegularizer.Best
Davison2024],Marigoldâ€ [Keetal.2024a],andGeoWizard[Fuetal.2024b], resultsarehighlighted.
anothertwodiffusion-basednormalestimators,onfourindoorbenchmarks.
Differentcellcolorsreferstobest,and2nd-best. Ablation Meanâ†“ Medâ†“ 11.25â—¦â†‘ 22.5â—¦â†‘ 30â—¦â†‘
DIODE-indoor[Vasiljevicetal.2019]
Method meanâ†“ medâ†“ 11.25â—¦â†‘ 22.5â—¦â†‘ 30â—¦â†‘ w/oShrinkageRegularizer 18.624 14.237 37.504 76.569 87.740
w/ShrinkageRegularizer 17.122 13.787 32.950 83.385 89.884
NYUv2[Silbermanetal.2012]
iBims-1[Kochetal.2018]
GeoWizard 20.363 11.898 46.954 73.787 80.804
Marigoldâ€  20.864 11.134 50.457 73.003 79.332 w/oShrinkageRegularizer 18.552 9.049 61.791 79.077 81.852
w/ShrinkageRegularizer 17.695 8.431 63.635 80.212 84.034
GenPercept 20.896 11.516 50.712 73.037 79.216
DSINE 18.610 9.885 56.132 76.944 82.606
Ours 19.707 10.527 53.042 75.889 81.723
ScanNet[Daietal.2017]
GeoWizard 21.439 13.930 37.080 71.653 79.712
AblationonSG-DRN.Wefirstevaluatedtherefinementstepâ€“
Marigoldâ€  21.284 12.268 45.649 72.666 79.045
GenPercept 20.652 10.502 53.017 74.470 80.364 SG-DRN.Werefertothemethodwithouttherefinementpipelineas
DSINE 18.610 9.885 56.132 76.944 82.606 YOSOOnly.AsshowninTable3,thereisaperformancedegradation
Ours 18.098 10.097 56.007 78.776 84.115
onboththeiBims-1andDIODE-indoordatasets,highlightingthe
iBims-1[Kochetal.2018]
GeoWizard 19.748 9.702 58.427 77.616 81.575 criticalroleoftheSG-DRNrefinementmoduleinimprovingnormal
Marigoldâ€  18.463 8.442 64.727 79.559 83.199 estimationaccuracy.Notably,sinceNYUv2andScanNetfeature
GenPercept 18.600 8.293 64.697 79.329 82.978
smoothGTnormals,andthepredictionnormalsbyYOSOOnlyare
DSINE 18.773 8.258 64.131 78.570 82.160
Ours 17.248 8.057 66.655 81.134 84.632 relativelysmoothaswell,thequantitativeperformanceofYOSO
DIODE-indoor[Vasiljevicetal.2019] Onlyevensurpassesthatofthefullversionwiththerefinementpro-
GeoWizard 19.371 15.408 30.551 75.426 86.357
cess.However,thisisnotthecasewhenexaminingthequalitative
Marigoldâ€  16.671 12.084 45.776 82.076 89.879
GenPercept 18.348 13.367 39.178 79.819 88.551 results(seeSupMat.â€™sFig.R.3).Furthermore,wealsoevaluatethe
DSINE 18.453 13.871 36.274 77.527 86.976 DSINEwithSG-DRNmodule,referedasSG-DRN+DSINE,theresults
Ours 13.701 9.460 63.447 86.309 92.107
onDIODE-indoorandiBIMS-1datasetsalsojustifytheeffectiveness
ofmulti-steprefinement.
Table3. AblationStudies.Differentcellcolorsreferstobestand2nd-best.
YOSONormalInitialization.Next,weinvestigatetheeffectofthe
meanâ†“ medâ†“ 11.25â—¦â†‘ 22.5â—¦â†‘ 30â—¦â†‘
YOSOinitialization.Todothis,wetriedanalternativetousethe
NYUv2[Silbermanetal.2012]
Ours 19.707 10.527 53.042 75.889 81.723 outputoftheDSINEmethodinsteadofourYOSOastheinitialization,
YOSOOnly 18.917 10.509 53.074 76.008 82.524 whichistermedasSG-DRN+DSINE.TheresultsontheDIODE-
Oursw/oDINO 19.739 10.536 52.999 75.833 81.667
indoordatasetrevealthatusingDSINEâ€™sinitializationleadstoan
DSINE 18.610 9.885 56.132 76.944 82.606
SG-DRN+DSINE 19.869 10.548 52.952 75.738 81.575 increaseinmeanangleerrorfrom13.701Â°to18.453Â°.Thisverifies
ScanNet[Daietal.2017] thatthenecessityofourYOSOinitialization.
Ours 18.098 10.097 56.007 78.776 84.115
YOSOOnly 17.679 9.860 57.220 78.823 84.331
Oursw/oDINO 19.326 11.626 48.115 77.438 83.575 AblationonSemanticfeatureextractor.Therearealternatives
DSINE 18.610 9.885 56.132 76.944 82.606 forextractingsemanticfeatures.WedenotetheonereplacingDINO
SG-DRN+DSINE 19.118 10.221 54.789 77.115 82.568
extractorwithastandardResNet-50backboneasOursw/oDINO,
iBims-1[Kochetal.2018]
Ours 17.248 8.057 66.655 81.134 84.632 withwhich,theperformancedecreasesacrossalldatasets,validat-
YOSOOnly 17.695 8.431 63.635 80.212 84.034 ingthatthesuperiorityofDINOvisualrepresentationtobethe
Oursw/oDINO 18.234 8.875 62.172 80.417 84.347
semanticguidancefornormalestimation.Themostsignificantdrop
DSINE 18.773 8.258 64.131 78.570 82.160
SG-DRN+DSINE 17.877 8.069 66.589 80.630 83.957 isobservedontheDIODE-Indoordataset,wherethemeanangle
DIODE-indoor[Vasiljevicetal.2019] errorrisesfrom13.701Â°to15.611Â°.QualitativecomparisonsinFig.6
Ours 13.701 9.460 63.447 88.223 92.107
furtherverifiestheusefulnessofDINOfeatures.
YOSOOnly 17.122 13.787 32.950 83.385 89.884
Oursw/oDINO 15.611 11.912 45.801 86.563 91.843
DSINE 18.453 13.871 36.274 77.527 86.976 EffectsofShrinkageRegularizer.Table4illustratesthatourpro-
SG-DRN+DSINE 14.752 10.139 58.221 86.455 90.888
posedShrinkageRegularizercaneffectivelymitigatethedifficulty
oflearningmany-to-onemapping,improvingoverallmetricson
bothDIODE-indoorandiBims-1benchmark.
ticilpxE8 â€¢ Ye,etal.
Fig.6. QualitativeAblationStudy.YOSOcanproducerelativelysharpsurfacenormalestimationswithonlyasingle-stepsampling;however,itsresultsstill
lacksufficientdetails.AfterrefinementbySG-DRN,thepredictedsurfacenormalsbecomesignificantlysharper,asillustratedbythecomparisonbetweenthe
thirdandfourthcolumnsinthefigure.ThiscomparisonhighlightstheimpactofsemanticfeaturesonSG-DRNâ€™sperformance.Specifically,thefirstrow
demonstrateshowusingDINOfeaturesassiststhenetworkinmitigatingtheeffectsoflightingonnormalestimation.ThesecondrowindicatesthatDINO
featuresenableeffectivestructuralmodeling,enhancingtheconsistencyofthenormaloutput.Furthermore,thethirdrowshowsthatDINOfeaturesimprove
thenetworkâ€™sabilitytounderstandmaterials,e.g.,plasticmaterial.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal â€¢ 9
5 APPLICATIONS
5.1 Multi-viewSurfaceReconstruction
Accuratenormalestimationiscrucialforfaithfulsurfacereconstruc-
tions,especiallyfornon-Lambertiansurfaces(Fig.7).Weleverage
ourgeneratednormalmapstoregularizethesurfacereconstruction
pipelinefollowing2DGS[Huangetal.2024].Quantitativeresultson
DTU(Table1)showourmethodachievesthelowestmeanChamfer
distanceamongcomparedtechniques,highlightingthesignificant
impactofouraccuratenormalestimates.
5.2 MonocularSurfaceReconsturction
Ourhigh-fidelitynormalestimationalsobenefitsmonocularsurface
reconstructionvianormalfieldintegration,likeBilateralNormal
Integration(BiNI)[Caoetal.2022].Wecomparemonoculargeomet-
ricregularizationfromdifferentmethodson80DiLiGenTsamples
withground-truthnormals.Table5reportsourmethodsignificantly
improvesNormalRMSE,MeanAngleError(by20%),andDepth
MeanAngleErroroverpreviousmethods,demonstratingrobust
Fig.7. QualitativecomparisononDTU[Jensenetal.2014]dataset.Thefirst
normalestimationacrosslightingconditions.Fig.8visualizesex-
rowdisplaystheinputimagesandestimatednormalmaps.Thesecondrow
tractedmeshcomparisonsagainstGTandGeoWizard,showingour
visualizestherenderedworld-spacenormalmapsafterthereconstruction.
methodfaithfullyrecoversintricategeometricstructures.
Table5. QuantitativeevaluationontheDiLiGenT[Shietal.2019]dataset
formonocularsurfacereconsturctionapplication.Differentcellcolorsrefers
tobest,and2nd-best.
Method N-RMSEâ†“ MAEâ†“ D-RMSEâ†“
DSINE[BaeandDavison2024] 0.50 22.53 0.0053
GeoWizard[Fuetal.2024b] 0.49 24.51 0.0048
Ours 0.41 18.78 0.0044
5.3 NormalEnhancement
RecentgenerativeAIadvancesenable3Dcontentcreationbyfine-
tuningpre-trained2Ddiffusionmodelstopredictmulti-viewnormal
maps[Longetal.2023;Luetal.2024;Qiuetal.2024;Zhengetal.
2024],whicharethenfusedinto3Dmodels.However,existingmeth-
odsproducelow-resolutionandover-smoothoutputslackingfine
details.Toimproveit,weapplyourmethodtoWonder3D[Long
etal.2023]toimprovethedetailofthegeneratedmulti-viewnor-
malmapsandtheresulting3Dshapes.Weupsamplethemulti-view
Fig.8. QualitativecomparisononDiLiGenT[Shietal.2019]dataset.
imagesusingbilinearupsamplingandthelow-resnormalmapsto
initializeğ‘¥ ğ‘¡,leveragingtheirmulti-viewconsistency.OurSG-DRN
thenrefinestheupsamplednormalmapstorecoverfinerdetails. sharpnessâ€trade-off.Thisisvalidatedbymultipleindoorbench-
FollowingWonder3D[Longetal.2023],wetrainaNeuS[Wangetal. marks,andvariousreal-worldapplications(checkourvideoformore
2021]perobjectusingtherefinednormalmapsandextracthigh-res details).SomefailurecasesareinSupMat.â€™sAppendixC.Whileour
meshes.Figure10showsourmethodsignificantlyimprovesthe focusisonnormalestimation,webelieveourmethodologyandthe
detailofthegenerated3Dobjectscomparedtotheoriginalone. identifiedtrade-offwillalsobenefitotherrelatedfields,includingbut
notlimitedtodepthestimationandvariousperceptiontasks(e.g.,
6 CONCLUSION
detection,segmentation,etc).Todemocratizethis,wewillmakeour
We present StableNormal, which tailors the diffusion priors for codeandmodelspubliclyavailable,onlyforresearchpurpose.
monocularnormalestimation.Unlikepriordiffusion-basedworks,
weprioritizeenhancingestimationstabilitybyreducinginherentdif-
fusionstochasticity.Ourapproach,acoarse-to-finestrategy,hinges Acknowledgments.WethankGuanyingChenandZhenLiufor
onthebeliefthatareliableinitialguesscombinedwithasemantic- proofreading,ZhenLiuandXuCaoforfruitfuldiscussions.
guidedrefinementprocessiscrucialforbalancingtheâ€œstabilityvs.10 â€¢ Ye,etal.
Fig. 9. Qualitative comparison of different methods on NYUv2[Silberman et al. 2012], ScanNet[Dai et al. 2017], iBims-1[Koch et al. 2018], DIODE-
indoor[Vasiljevicetal.2019]datasets.StableNormaloutperformsotherrelatedworksintermsofaccuracyandsharpness.
Fig.10. Comparisonofgeometricsurfacenormalsfordifferentscenes.Thesurfacenormalsarerenderedfromthereconstructed3Dmeshmodels.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal â€¢ 11
REFERENCES
RasmusRamsbÃ¸lJensen,A.Dahl,GeorgeVogiatzis,EngilTola,andHenrikAanÃ¦s.2014.
GwangbinBae,IgnasBudvytis,andRobertoCipolla.2021.EstimatingandExploitingthe LargeScaleMulti-viewStereopsisEvaluation.2014IEEEConferenceonComputer
AleatoricUncertaintyinSurfaceNormalEstimation.In2021IEEE/CVFInternational VisionandPatternRecognition(2014),406â€“413.
ConferenceonComputerVision(ICCV). https://doi.org/10.1109/iccv48922.2021.01289 YuanfengJi,ZheChen,EnzeXie,LanqingHong,XihuiLiu,ZhaoqiangLiu,TongLu,
GwangbinBaeandAndrewJ.Davison.2024. RethinkingInductiveBiasesforSur- ZhenguoLi,andPingLuo.2023.Ddp:Diffusionmodelfordensevisualprediction.
faceNormalEstimation.InIEEE/CVFConferenceonComputerVisionandPattern InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.21741â€“
Recognition(CVPR). 21752.
AayushBansal,BryanRussell,andAbhinavGupta.2016a. Marrrevisited:2d-3d BingxinKe,AntonObukhov,ShengyuHuang,NandoMetzger,RodrigoCayeDaudt,
alignmentviasurfacenormalprediction.InProceedingsoftheIEEEconferenceon andKonradSchindler.2024a.RepurposingDiffusion-BasedImageGeneratorsfor
computervisionandpatternrecognition.5965â€“5974. MonocularDepthEstimation.InComputerVisionandPatternRecognition(CVPR).
AayushBansal,BryanRussell,andAbhinavGupta.2016b. MarrRevisited:2D-3D BingxinKe,AntonObukhov,ShengyuHuang,NandoMetzger,RodrigoCayeDaudt,
AlignmentviaSurfaceNormalPrediction.In2016IEEEConferenceonComputer andKonradSchindler.2024b.RepurposingDiffusion-BasedImageGeneratorsfor
VisionandPatternRecognition(CVPR). https://doi.org/10.1109/cvpr.2016.642 MonocularDepthEstimation.InProceedingsoftheIEEE/CVFConferenceonComputer
AmirBar,YossiGandelsman,TrevorDarrell,AmirGloberson,andAlexeiEfros.2022. VisionandPatternRecognition(CVPR).
Visualpromptingviaimageinpainting.ConferenceonNeuralInformationProcessing TobiasKoch,LukasLiebel,FriedrichFraundorfer,andMarcoKÃ¶rner.2018.Evaluation
Systems(NeurIPS)35(2022),25005â€“25017. ofCNN-basedSingle-ImageDepthEstimationMethods. arXiv:1805.01328[cs.CV]
ManelBaradad,YuanzhenLi,ForresterCole,MichaelRubinstein,AntonioTorralba, PeterKocsis,VincentSitzmann,andMatthiasNieÃŸner.2024.IntrinsicImageDiffusion
WilliamT.Freeman,andVarunJampani.2023.BackgroundPromptingforImproved forSingle-viewMaterialEstimation.InComputerVisionandPatternRecognition
ObjectDepth. arXiv:2306.05428[cs.CV] (CVPR).
XuCao,HiroakiSanto,BoxinShi,FumioOkura,andYasuyukiMatsushita.2022.Bi- Lâ€™uborLadickÃ½,BernhardZeisl,andMarcPollefeys.2014.DiscriminativelyTrainedDense
lateralnormalintegration.InEuropeanConferenceonComputerVision.Springer, SurfaceNormalEstimation.468â€“484. https://doi.org/10.1007/978-3-319-10602-1_31
552â€“567. KatrinLasinger,RenÃ©Ranftl,KonradSchindler,andVladlenKoltun.2019. Towards
AngelaDai,AngelX.Chang,ManolisSavva,MaciejHalber,ThomasFunkhouser,and robustmonoculardepthestimation:Mixingdatasetsforzero-shotcross-dataset
MatthiasNieÃŸner.2017.ScanNet:Richly-annotated3DReconstructionsofIndoor transfer.arXivpreprintarXiv:1907.01341(2019).
Scenes. arXiv:1702.04405[cs.CV] AlexanderCLi,MihirPrabhudesai,ShivamDuggal,EllisBrown,andDeepakPathak.
MattDeitke,DustinSchwenk,JordiSalvador,LucaWeihs,OscarMichel,EliVander- 2023b.Yourdiffusionmodelissecretlyazero-shotclassifier.InInternationalConfer-
Bilt,LudwigSchmidt,KianaEhsani,AniruddhaKembhavi,andAliFarhadi.2022. enceonComputerVision(ICCV).2206â€“2217.
Objaverse:AUniverseofAnnotated3DObjects.arXivpreprintarXiv:2212.08051 YixuanLi,LihanJiang,LinningXu,YuanboXiangli,ZhenzhiWang,DahuaLin,andBo
(2022). Dai.2023a.Matrixcity:Alarge-scalecitydatasetforcity-scaleneuralrenderingand
TienVanDo,KhiemVuong,StergiosI.Roumeliotis,andHyunSooPark.2020. Sur- beyond.InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.
faceNormalEstimationofTiltedImagesviaSpatialRectifier.CornellUniversity- 3205â€“3215.
arXiv,CornellUniversity-arXiv(Jul2020). ZiyiLi,QinyeZhou,XiaoyunZhang,YaZhang,YanfengWang,andWeidiXie.2023c.
AinazEftekhar,AlexanderSax,JitendraMalik,andAmirZamir.2021.Omnidata:A Open-vocabularyobjectsegmentationwithdiffusionmodels.InInternationalCon-
scalablepipelineformakingmulti-taskmid-levelvisiondatasetsfrom3dscans.In ferenceonComputerVision(ICCV).7667â€“7676.
ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.10786â€“ ShuaiLiao,EfstratiosGavves,andCeesG.M.Snoek.2019.SphericalRegression:Learning
10796. Viewpoints,SurfaceNormalsand3DRotationsonn-Spheres.CornellUniversity-
DavidEigenandRobFergus.2015a.Predictingdepth,surfacenormalsandsemantic arXiv,CornellUniversity-arXiv(Apr2019).
labelswithacommonmulti-scaleconvolutionalarchitecture.InProceedingsofthe XianLiu,JianRen,AliaksandrSiarohin,IvanSkorokhodov,YanyuLi,DahuaLin,Xihui
IEEEinternationalconferenceoncomputervision.2650â€“2658. Liu,ZiweiLiu,andSergeyTulyakov.2023.Hyperhuman:Hyper-realistichuman
DavidEigenandRobFergus.2015b.PredictingDepth,SurfaceNormalsandSemantic generationwithlatentstructuraldiffusion.arXivpreprintarXiv:2310.08579(2023).
LabelswithaCommonMulti-ScaleConvolutionalArchitecture.In2015IEEEInterna- XiaoxiaoLong,Yuan-ChenGuo,ChengLin,YuanLiu,ZhiyangDou,LingjieLiu,Yuexin
tionalConferenceonComputerVision(ICCV). https://doi.org/10.1109/iccv.2015.304 Ma,Song-HaiZhang,MarcHabermann,ChristianTheobalt,etal.2023.Wonder3d:
Martin Nicolas Everaert, Athanasios Fitsios, Marco Bocchio, Sami Arpa, Sabine Singleimageto3dusingcross-domaindiffusion.(2023).
SÃ¼sstrunk,andRadhakrishnaAchanta.2024. Exploitingthesignal-leakbiasin IlyaLoshchilovandFrankHutter.2019. DecoupledWeightDecayRegularization.
diffusionmodels.InProceedingsoftheIEEE/CVFWinterConferenceonApplications arXiv:1711.05101[cs.LG]
ofComputerVision.4025â€“4034. YuanxunLu,JingyangZhang,ShiweiLi,TianFang,DavidMcKinnon,YanghaiTsin,
DavidFFouhey,AbhinavGupta,andMartialHebert.2013a.Data-driven3Dprimitives LongQuan,XunCao,andYaoYao.2024.Direct2.5:DiverseText-to-3DGeneration
forsingleimageunderstanding.InProceedingsoftheIEEEInternationalConference viaMulti-view2.5DDiffusion. arXiv:2311.15980[cs.CV]
onComputerVision.3392â€“3399. SimonNiklaus,LongMai,JimeiYang,andFengLiu.2019.3DKenBurnsEffectfroma
DavidF.Fouhey,AbhinavGupta,andMartialHebert.2013b.Data-Driven3DPrimitives SingleImage.ACMTransactionsonGraphics38,6(2019),184:1â€“184:15.
forSingleImageUnderstanding.In2013IEEEInternationalConferenceonComputer MaximeOquab,TimothÃ©eDarcet,ThÃ©oMoutakanni,HuyVo,MarcSzafraniec,Vasil
Vision. https://doi.org/10.1109/iccv.2013.421 Khalidov,PierreFernandez,DanielHaziza,FranciscoMassa,AlaaeldinEl-Nouby,
DavidFordFouhey,AbhinavGupta,andMartialHebert.2014. UnfoldinganIndoor MahmoudAssran,NicolasBallas,WojciechGaluba,RussellHowes,Po-YaoHuang,
OrigamiWorld.687â€“702. https://doi.org/10.1007/978-3-319-10599-4_44 Shang-WenLi,IshanMisra,MichaelRabbat,VasuSharma,GabrielSynnaeve,Hu
StephanieFu,MarkHamilton,LauraE.Brandt,AxelFeldmann,ZhoutongZhang,and Xu,HervÃ©Jegou,JulienMairal,PatrickLabatut,ArmandJoulin,andPiotrBo-
WilliamT.Freeman.2024a.FeatUp:AModel-AgnosticFrameworkforFeaturesat janowski.2024. DINOv2:LearningRobustVisualFeatureswithoutSupervision.
AnyResolution.InTheTwelfthInternationalConferenceonLearningRepresentations. arXiv:2304.07193[cs.CV]
https://openreview.net/forum?id=GkJiNn2QDF WilliamPeeblesandSainingXie.2022.ScalableDiffusionModelswithTransformers.
XiaoFu,WeiYin,MuHu,KaixuanWang,YuexinMa,PingTan,ShaojieShen,Dahua BenPoole,AjayJain,JonathanTBarron,andBenMildenhall.2023. Dreamfusion:
Lin,andXiaoxiaoLong.2024b.GeoWizard:UnleashingtheDiffusionPriorsfor3D Text-to-3dusing2ddiffusion.InternationalConferenceonLearningRepresentations
GeometryEstimationfromaSingleImage.arxiv(2024). (ICLR)(2023).
JonathanHo,AjayJain,andPieterAbbeel.2020. Denoisingdiffusionprobabilistic XiaojuanQi,RenjieLiao,ZhengzheLiu,RaquelUrtasun,andJiayaJia.2018.GeoNet:
models.Advancesinneuralinformationprocessingsystems33(2020),6840â€“6851. GeometricNeuralNetworkforJointDepthandSurfaceNormalEstimation.In
DerekHoiem,AlexeiA.Efros,andMartialHebert.2005. Automaticphotopop-up. 2018IEEE/CVFConferenceonComputerVisionandPatternRecognition. https:
ACMTransactionsonGraphics(Jul2005),577â€“584. https://doi.org/10.1145/1073204. //doi.org/10.1109/cvpr.2018.00037
1073232 XiaojuanQi,ZhengzheLiu,RenjieLiao,PhilipH.S.Torr,RaquelUrtasun,andJiayaJia.
DerekHoiem,AlexeiA.Efros,andMartialHebert.2007.RecoveringSurfaceLayout 2022.GeoNet++:IterativeGeometricNeuralNetworkwithEdge-AwareRefinement
fromanImage.InternationalJournalofComputerVision(Jul2007),151â€“172. https: forJointDepthandSurfaceNormalEstimation.IEEETransactionsonPatternAnalysis
//doi.org/10.1007/s11263-006-0031-y andMachineIntelligence(Feb2022),969â€“984. https://doi.org/10.1109/tpami.2020.
BinbinHuang,ZehaoYu,AnpeiChen,AndreasGeiger,andShenghuaGao.2024.2D 3020800
GaussianSplattingforGeometricallyAccurateRadianceFields.InSIGGRAPH2024 LingtengQiu,GuanyingChen,XiaodongGu,QiZuo,MutianXu,YushuangWu,Wei-
ConferencePapers.AssociationforComputingMachinery. https://doi.org/10.1145/ haoYuan,ZilongDong,LiefengBo,andXiaoguangHan.2024. Richdreamer:A
3641519.3657428 generalizablenormal-depthdiffusionmodelfordetailrichnessintext-to-3d.In
Jingwei Huang, Yichao Zhou, Thomas Funkhouser, and LeonidasJ. Guibas. 2019. ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.
FrameNet:LearningLocalCanonicalFramesof3DSurfacesfromaSingleRGB 9914â€“9925.
Image.CornellUniversity-arXiv,CornellUniversity-arXiv(Mar2019).12 â€¢ Ye,etal.
AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,Sandhini LvminZhang,AnyiRao,andManeeshAgrawala.2023a.AddingConditionalControl
Agarwal,GirishSastry,AmandaAskell,PamelaMishkin,JackClark,etal.2021. toText-to-ImageDiffusionModels.InIEEEInternationalConferenceonComputer
Learningtransferablevisualmodelsfromnaturallanguagesupervision.InInterna- Vision(ICCV).
tionalconferenceonmachinelearning. ShiweiZhang,JiayuWang,YingyaZhang,KangZhao,HangjieYuan,ZhiwuQin,Xiang
RenÃ©Ranftl,AlexeyBochkovskiy,andVladlenKoltun.2021a.Visiontransformersfor Wang,DeliZhao,andJingrenZhou.2023b.I2vgen-xl:High-qualityimage-to-video
denseprediction.InProceedingsoftheIEEE/CVFinternationalconferenceoncomputer synthesisviacascadeddiffusionmodels.arXivpreprintarXiv:2311.04145(2023).
vision.12179â€“12188. ZhenyuZhang,ZhenCui,ChunyanXu,YanYan,NicuSebe,andJianYang.2019.Pattern-
ReneRanftl,AlexeyBochkovskiy,andVladlenKoltun.2021b. VisionTransformers AffinitivePropagationacrossDepth,SurfaceNormalandSemanticSegmentation.
forDensePrediction. InternationalConferenceonComputerVision,International In2019IEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR).
ConferenceonComputerVision(Jan2021). https://doi.org/10.1109/cvpr.2019.00423
Mike Roberts, Jason Ramapuram, Anurag Ranjan, Atulit Kumar, Miguel Angel WenliangZhao,YongmingRao,ZuyanLiu,BenlinLiu,JieZhou,andJiwenLu.2023.
Bautista,NathanPaczan,RussWebb,andJoshuaM.Susskind.2021. Hyper- Unleashingtext-to-imagediffusionmodelsforvisualperception.InProceedingsof
sim:APhotorealisticSyntheticDatasetforHolisticIndoorSceneUnderstanding. theIEEE/CVFInternationalConferenceonComputerVision.5729â€“5739.
arXiv:2011.02523[cs.CV] Xin-YangZheng,HaoPan,Yu-XiaoGuo,XinTong,andYangLiu.2024.MVD2:Efficient
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and BjÃ¶rn Multiview3DReconstructionforMultiviewDiffusion. arXiv:2402.14253[cs.CV]
Ommer.2021. High-ResolutionImageSynthesiswithLatentDiffusionModels.
arXiv:2112.10752[cs.CV]
RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBjÃ¶rnOmmer.
2022a.High-resolutionimagesynthesiswithlatentdiffusionmodels.InComputer
VisionandPatternRecognition(CVPR).10684â€“10695.
RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBjÃ¶rnOmmer.
2022b.High-ResolutionImageSynthesisWithLatentDiffusionModels.InProceed-
ingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR).
10684â€“10695.
OlafRonneberger,PhilippFischer,andThomasBrox.2015.U-Net:ConvolutionalNet-
worksforBiomedicalImageSegmentation.LectureNotesinComputerScience,Lecture
NotesinComputerScience(Jan2015).
ChristophSchuhmann,RomainBeaumont,RichardVencu,CadeGordon,RossWight-
man,MehdiCherti,TheoCoombes,AarushKatta,ClaytonMullis,MitchellWorts-
man,etal.2022.Laion-5b:Anopenlarge-scaledatasetfortrainingnextgeneration
image-textmodels. AdvancesinNeuralInformationProcessingSystems35(2022),
25278â€“25294.
BoxinShi,ZhipengMo,ZheWu,DinglongDuan,Sai-KitYeung,andPingTan.2019.
ABenchmarkDatasetandEvaluationforNon-LambertianandUncalibratedPho-
tometricStereo.IEEETransactionsonPatternAnalysisandMachineIntelligence41
(2019),271â€“284. https://api.semanticscholar.org/CorpusID:156683
NathanSilberman,DerekHoiem,PushmeetKohli,andRobFergus.2012. Indoor
SegmentationandSupportInferencefromRGBDImages.InEuropeanConference
onComputerVision.
JiamingSong,ChenlinMeng,andStefanoErmon.2020.Denoisingdiffusionimplicit
models.arXivpreprintarXiv:2010.02502(2020).
JulianStraub,ThomasWhelan,LingniMa,YufanChen,ErikWijmans,SimonGreen,
JakobJEngel,RaulMur-Artal,CarlRen,ShobhitVerma,etal.2019.TheReplica
dataset:Adigitalreplicaofindoorspaces.arXivpreprintarXiv:1906.05797(2019).
JunjiaoTian,LavishaAggarwal,AndreaColaco,ZsoltKira,andMarGonzalez-Franco.
2024.Diffuse,Attend,andSegment:UnsupervisedZero-ShotSegmentationusing
StableDiffusion.ComputerVisionandPatternRecognition(CVPR)(2024).
IgorVasiljevic,NickKolkin,ShanyiZhang,RuotianLuo,HaochenWang,FalconZ.Dai,
AndreaF.Daniele,MohammadrezaMostajabi,StevenBasart,MatthewR.Walter,
andGregoryShakhnarovich.2019.DIODE:ADenseIndoorandOutdoorDEpth
Dataset. arXiv:1908.00463[cs.CV]
PengWang,LingjieLiu,YuanLiu,ChristianTheobalt,TakuKomura,andWenping
Wang.2021. NeuS:LearningNeuralImplicitSurfacesbyVolumeRenderingfor
Multi-viewReconstruction.ConferenceonNeuralInformationProcessingSystems
(NeurIPS)(2021).
PengWang,XiaohuiShen,BryanRussell,ScottCohen,BrianPrice,andAlanL.Yuille.
2016.SURGE:surfaceregularizedgeometryestimationfromasingleimage.Neural
InformationProcessingSystems,NeuralInformationProcessingSystems(Dec2016).
RuiWang,DavidGeraghty,KevinMatzen,RichardSzeliski,andJan-MichaelFrahm.
2020.VPLNet:DeepSingleViewNormalEstimationWithVanishingPointsand
Lines.In2020IEEE/CVFConferenceonComputerVisionandPatternRecognition
(CVPR). https://doi.org/10.1109/cvpr42600.2020.00077
XiaolongWang,DavidFouhey,andAbhinavGupta.2015a.Designingdeepnetworks
forsurfacenormalestimation.InProceedingsoftheIEEEconferenceoncomputer
visionandpatternrecognition.539â€“547.
XiaolongWang,DavidF.Fouhey,andAbhinavGupta.2015b.DesigningDeepNetworks
forSurfaceNormalEstimation.In2015IEEEConferenceonComputerVisionand
PatternRecognition(CVPR). https://doi.org/10.1109/cvpr.2015.7298652
ZhendongWang,YifanJiang,YadongLu,PengchengHe,WeizhuChen,Zhangyang
Wang,MingyuanZhou,etal.2023. In-contextlearningunlockedfordiffusion
models.ConferenceonNeuralInformationProcessingSystems(NeurIPS)36(2023),
8542â€“8562.
GuangkaiXu,YongtaoGe,MingyuLiu,ChengxiangFan,KangyangXie,ZhiyueZhao,
HaoChen,andChunhuaShen.2024.DiffusionModelsTrainedwithLargeData
AreTransferableVisualModels.arXivpreprintarXiv:2403.06090(2024).StableNormal:ReducingDiffusionVarianceforStableandSharpNormal â€¢ 13
A MOREDETAILSABOUTIMPLEMENTATION C FAILURECASE
Wefine-tunethepre-trainedStableDiffusionV2.1[Rombachetal. WhileStableNormalcanproducesharpandstablenormalestimation
2022b]usingtheAdamWoptimizer[LoshchilovandHutter2019] undermostcircumstances,itmayalsofailinsomeextremecaseslike
withafixedlearningrateof3e-5.Toenhancetherobustnessof alldata-drivenmethods.AsdepictedinFigure.R.2,StableNormal
ourmethodagainstexposure,weincorporateexposureaugmen- couldpartiallyoutputthenormalofthingsbehindthetranspar-
tation.Furthermore,wetransformallinputmapstotherange[-1, ent objects(Left) and output a similar color(green) for plants in
1]toalignwiththeVAEâ€™sexpectedinputrange.Duringtraining, images(Right)regardlessofthecomplexnormaldirectionsonthe
weemployrandomcropswithvaryingaspectratiosandpadthe surfaceofplants.Thisisduetotheinductivebiasintroducedbyour
imagestoafixedboxresolutionusingblackpadding.Ourtraining trainingdataset(Lackofdataincludingoutdoorscenesandplants),
processinvolvestwostages:first,wepre-trainournetworkwith which could be solved in the future by adding more simulating
aresolutionof512x512usingabatchsizeof64foraround20,000 renderings.
steps.Subsequently,wefine-tunethemodelona768x768resolution
D MOREQUALITATIVEANALYSISOFYOSO
withabatchsizeof32for10,000steps.Theentiretrainingprocess
takesapproximatelyonedayonfourA100GPUs.Notably,both Althoughourmethodpredictssharperandmoreaccuratenormals
YOSOandSG-DRNemploythesametrainingstrategy. comparedtoYOSOOnly,thequalitativeresultsappearworsethan
thoseofYOSOOnlybecausethegroundtruthnormalmapsofboth
NYUv2andScanNetaresmootherandlessdetailed(seeFig.R.3).
Fig.R.1. ThedetailsofthearchitectureofourU-Net.
B THEARCHITECTUREOFU-NETINBOTHSTAGES
OurstructuremaintainsmostbuildingblocksofControlNet[Zhang
etal.2023a]withseveralmodificationsfornormalestimation(we
showthesecondstagehere).AsdepictedinFigure.R.1,weuse
afixedtextpromptâ€œTheNormalMap"inboththetrainingand
testingphasesandaddasemantic-guidernetworktoencodeDINO
features.Theencodedfeatureisfurtheraddedwiththeoutputofthe
YOSOstagetoactasinputtotheSG-DRN.Thesemanticguiderisa
simplestackingof2Dconvolutionsforobtainfeatures,following
byFeatup[Fuetal.2024a]andbi-linearinterpolationtoupsample Fig.R.3. ThequalitativecomparisonresultsbetweenYOSOOnlyandOurs
theirresolutiontothesameshapeastheYOSOoutput. onbothNYUv2andScanNetdataset.
E MOREQUALITATIVECOMPARISONS
WepresentmorequalitativecomparisonresultsbetweenGeoWiz-
ard[Fuetal.2024b],DSINE[BaeandDavison2024],Marigold[Ke
etal.2024a],GenPercept[Xuetal.2024]andStableNormalfrom
Fig.R.4toFig.R.7.
Fig.R.2. TypicalbadcasesgeneratedbyStabelNormal.14 â€¢ Ye,etal.
Fig.R.4. Morequalitativeresults(PartI).FromthelefttotherightareresultsfromDSINE[BaeandDavison2024],GenPercept[Xuetal.2024],GeoWizard[Fu
etal.2024b],Marigold[Keetal.2024b]andStableNormalrespectively.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal â€¢ 15
Fig.R.5. Morequalitativeresults(PartII).FromthelefttotherightareresultsfromDSINE[BaeandDavison2024],GenPercept[Xuetal.2024],GeoWizard[Fu
etal.2024b],Marigold[Keetal.2024b]andStableNormalrespectively.16 â€¢ Ye,etal.
Fig.R.6. Morequalitativeresults(PartIII).Fromthelefttotheright(theuptothebottom)areresultsfromGeoWizard[Fuetal.2024b],DSINE[Baeand
Davison2024],andStableNormalrespectively.StableNormal:ReducingDiffusionVarianceforStableandSharpNormal â€¢ 17
Fig.R.7. Morequalitativeresults(PartIV).FromthelefttotherightareresultsfromGeoWizard[Fuetal.2024b],DSINE[BaeandDavison2024],and
StableNormalrespectively.