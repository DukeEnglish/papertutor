Pre-training Cross-lingual Open Domain Question Answering
with Large-scale Synthetic Supervision
FanJiang and TomDrummond and TrevorCohn*
SchoolofComputingandInformationSystems
TheUniversityofMelbourne,Victoria,Australia
fan.jiang1@student.unimelb.edu.au
{tom.drummond, trevor.cohn}@unimelb.edu.au
Abstract uments or the questions require knowledge from
diversecultures(Asaietal.,2021b).
Cross-lingual question answering (CLQA) is
Several attempts have been made to enhance
acomplexproblem,comprisingcross-lingual
the performance of multilingual open-domain
retrievalfromamultilingualknowledgebase,
QA(Asaietal.,2021b;Abulkhanovetal.,2023).
followed by answer generation either in En-
These approaches typically require passage la-
glish or the query language. Both steps are
usuallytackledbyseparatemodels,requiring belsforretrievertrainingthroughsupervisedcon-
substantial annotated datasets, and typically trastive learning. This requirement complicates
auxiliary resources, like machine translation cross-lingualretrievaltrainingsignificantlydueto
systemstobridgebetweenlanguages. Inthis thechallengeofconstructingalarge-scaledataset
paper,weshowthatCLQAcanbeaddressed
containing query-passage labels. This challenge
usingasingleencoder-decodermodel. Toef-
emergesfromtheunavailabilityofpriorknowledge
fectively train this model, we propose a self-
regardingwhichlanguagecontainstherelevantev-
supervised method based on exploiting the
idence. Furthermore, these efforts often involve
cross-linguallinkstructurewithinWikipedia.
WedemonstratehowlinkedWikipediapages separatetrainingoftheretrieverandreader,leading
canbeusedtosynthesisesupervisorysignals toerrorpropagationwithintheresultingpipeline.
for cross-lingual retrieval, through a form of EvidenceinthecontextofEnglishopen-domain
clozequery,andgeneratemorenaturalqueries
QA reveals that integrating retriever and reader
tosuperviseanswergeneration. Together,we
trainingtypicallyleadstoimprovedperformance
showourapproach,CLASS,outperformscompa-
on both components. This achievement is often
rablemethodsonbothsupervisedandzero-shot
realised by training both components (Guu et al.,
languageadaptationsettings, includingthose
usingmachinetranslation. 2020; Lewis et al., 2020) or a unified model that
performsbothtasks(Leeetal.,2022;Jiangetal.,
1 Introduction 2022)throughfullyend-to-endtraining. Nonethe-
less, such a joint training paradigm has not been
OpenDomainQuestionAnswering(QA)isthetask
extensivelyexploredinmultilingualopen-domain
ofgeneratingananswerforagivenquestionbased
QA,andhowtoadaptittosuitthecomplexitiesof
ontheevidencegatheredfromalargecollectionof
multilingualsettingsremainsanopenquestion.
documents. A widely adopted pipeline "retrieve-
In this paper, we introduce the first unified
then-read" is employed for this task (Chen et al.,
model capable of performing both cross-lingual
2017; Karpukhin et al., 2020), which begins by
retrievalandmultilingualopen-domainQAtasks.
retrieving a small set of passages using a dense
Toachievethis,weproposeCLASS(Cross-Lingual
retrieval model and subsequently processes re-
QAPre-trainingwithSyntheticSupervision),aself-
trievedpassagestogeneratetheanswerwithaded-
supervisedmethodtopre-trainthemodelwithmul-
icated reader. Unlike English open-domain QA,
tilingualtextsatscale. CLASScomprisestwocore
wherebothquestionsandknowledgesourcesshare
components: cross-lingualretrievalpre-training
thesamelanguage,multilingualopen-domainQA
thatequipsthemodelwithrobustcross-lingualre-
presentsnewchallenges,asitinvolvesretrievingev-
trievalability,andmultilingualQApre-training
idencefrommultilingualcorpora,consideringthat
that further enhances retrieval and QA abilities
manylanguageslackcomprehensivesupportdoc-
jointly. Concretely,asdepictedinFigure1,thepre-
*NowatGoogleDeepMind trainingdataiscreatedbyminingparallelqueries
1
4202
beF
62
]LC.sc[
1v80561.2042:viXraAEn: 2011 AL: 2011å¹´
A: India
MMMuuullltttiiillliiinnnggguuuaaalll MMMooodddeeelll EEnngglliisshh MMooddeell MMMuuullltttiiillliiinnnggguuuaaalll MMMooodddeeelll & En
qL: æ¨å®šå£²ä¸Šæšæ•°ã¯7.3ä¸‡æšã‚’è¨˜éŒ²ã—ã€æ°´æ¨¹ã®ã‚·ãƒ³ã‚°
A: India ãƒ«å…¨3ä½œå“ãŒå¹´é–“ãƒãƒ£ãƒ¼ãƒˆTOP200å…¥ã‚Šã‚’æœãŸã—ãŸã®
qEn : m O an nc ye d i in f f[ eM rea ns tk d] e, sh ti ip np ai te ios n w s.e ..nt to qL : ã‚¤ãƒ³ãƒ‰ã§ã¯ã€ ç›®ãƒ’ çš„ãƒƒãƒ” åœ°ãƒ¼ ...ã¯å¤šãã®ç•°ãªã‚‹ ã¯ r se aa lã„ ec sh ã¤
o
t fh ã§ 7e
3
tã™ ,o 0p 0ã‹ 02 ?0ï¼Ÿ )0 ( o W f h the en ad nid n ua all l t ch hr ae re t so , f wM iti hz u ek si' ts i msin ag tl ee ds
Once in India, hippies went to ã‚¤ãƒ³ãƒ‰ã§ã¯ã€ãƒ’ãƒƒãƒ”ãƒ¼ã¯å¤šãã®ç•°ãª Query Transformation
many different destinations, on ã‚‹ç›®çš„åœ°ã¸ã„ã£ãŸãŒã€ãƒˆãƒªãƒ´ã‚¡ãƒ³ãƒ‰
the beaches of Goa and Kovalam ãƒ©ãƒ ï¼ˆã‚±ãƒ¼ãƒ©ãƒ©å·ï¼‰ã®ã‚´ã‚¢ã¨ã‚³ãƒãƒ©
in Trivandrum (Kerala), or ãƒ ã®ãƒ“ãƒ¼ãƒã«å¤§é‡ã«é›†ã¾ã£ãŸã‚Šã€ Type: Date
c spro es ns de d
m
oth ne
th
b
s
o inrd Ker
a
ti hn mto
a
nN de up .al to å›½ ã‚ºã§å¢ƒ æ•°ã‚’ ãƒ¶è¶Š æœˆãˆ éãŸ ã”ãƒ ã—ãƒ‘ ãŸãƒ¼ ã‚Šãƒ« ã—ãŸã® ã€‚ã‚«ãƒˆãƒãƒ³ æ¨ 20å®š 11å£² å¹´ä¸Š ã«ãƒªæš ãƒªæ•° ãƒ¼ã¯ ã‚¹7 ã•.3 ã‚Œä¸‡ ãŸæš æ°´ã‚’ æ¨¹è¨˜ ã®éŒ² ã‚·ã— ãƒ³ã€ NER Tagging
ã‚°ãƒ«å…¨3ä½œå“ãŒå¹´é–“ãƒãƒ£ãƒ¼ãƒˆTOP200 2011 (MMXI) was a common
å…¥ã‚Šã‚’æœãŸã—ãŸã€‚(Estimated sales year starting on Saturday of
were 73,000 copies, and all three of the Gregorian calendar...
Parallel Sentence Mining M eni tz eu rk ei d's ths ein g tole ps 2r 0e 0le a os fe d t hei n an2 n0 u1 a1 l Language Link
charts.)
2011å¹´å¹³å¹´ï¼ˆ2011 ã­ã‚“ï¼‰ã¯ã€è¥¿
æš¦ï¼ˆã‚°ãƒ¬ã‚´ãƒªã‚ªæš¦ï¼‰ã«ã‚ˆã‚‹ã€åœŸæ›œæ—¥
ã‹ã‚‰å§‹ã¾ã‚‹ã€‚å¹³æˆ23å¹´ã€‚
(a). Stage 1: Cross-Lingual Retrieval Pre-training (b). Stage 2: Multilingual Question-Answering Pre-training
Figure1: Theoverviewofourtwo-stageunsupervisedpre-trainingmethodforcross-lingualopendomainquestion
answering. Notethattranslationsinstage2areemployedforillustrativepurposesonlyandarenotusedfortraining.
fromparallelWikipediapages,usingsaliententi- 1. Empirical results on the XOR-TYDI QA
tieswithinEnglishsentencesasanswers. Tofacil- benchmark demonstrate that CLASS outper-
itatecross-lingualretrievals,aknowledgedistilla- forms a wide range of prominent unsuper-
tionprocessisintroduced,requiringthemodelto vised, zero-shot, and supervised models on
match the distributions of a well-trained English bothtasks,whilesolelyrelyingonQApairs
teacherwhengivenqueriesinbothlanguages. The throughoutthewholetrainingprocesses.
follow-upisaself-supervisedlearningtaskforend- 2. On the MKQA dataset, CLASS exhibits re-
to-endpre-trainingbypropagatingtrainingsignals markable generalisation capabilities across
derivedfromtheendQAtask. Thisprocessentails linguisticallydiverselanguageswithoutusing
generatingpre-trainingdatausinganchortextsindi- human-annotateddata.
catedbyhyperlinksandaquestiontransformation 3. To the best of our knowledge, we are the pi-
techniquetoresembletheformatsofnaturalques- oneersinsystematicallyexploringtheadvan-
tions. Notably,ourapproachdoesnotnecessitate tagesofpre-trainingformultilingualretrieval
additionaltoolssuchasmachinetranslationandof- and open-domain QA tasks. This demon-
fersamoreconvenientapplicationtolow-resource stratesthefeasibilityofachievingmultilingual
languages,requiringonlycomparabledocuments open-domainQAwithinaunifiedmodel.
(i.e.,Wikipedialanguagelinks).
2 Preliminaries
Thislarge-scalepre-trainingframeworkempow-
ers the model to demonstrate promising unsuper- 2.1 TaskDefinition
vised performance, and it can even outperform GivenaquestionqL inlanguageL,Cross-lingual
manycompetitivesupervisedcounterparts. Byfine-
PassageRetrievalrequiresretrievingacollection
tuningitwithsupervisedEnglishandmultilingual of passages DEn from English Wikipedia CEn
QAdata, wecanattainfurtherimprovements, ul- thatpotentiallyprovideevidencetoanswerqL. An
timately establishing new state-of-the-art perfor- English answer aEn is then generated by a cross-
mance in both cross-lingual retrieval and multi-
lingualreaderwithretrievedinformation. Incon-
lingual open-domain QA tasks. In summary, our
trast,MultilingualOpen-DomainQuestionAn-
contributionsare:1
swering aims at answering qL in language L by
referringtoamultilingualWikipediaCMulti. In
1Sourcecodewillbereleasedathttps://github.com/
Fantabulous-J/CLASS thissetting,thepriorknowledgeofwhichlanguage
2
ğ¸ ğ‘› ğ¸ ğ‘› ğ‘ƒ ğ‘ğ‘ğ‘’
ğ¸ğ¸ ğ‘›ğ‘›ğœƒğœƒ
ğ¸ğ¸ğ¸ ğ‘›ğ‘›ğ‘›ğ“’ğ“’ğ“’
ğ’Ÿ
â„’ K L
ğ‘ƒ ğ‘€ ğ¿ğ‘ğ‘’ ğ‘ ğ¸ ğ‘›
ğœƒ
â„’
ğ‘€
align
ğ¿
ğ‘ƒ ğ‘€ ğ¿ ğ‘ğ‘ğ‘’
ğ‘€ğ‘€ğ“’ğ“’
ğ¿ â„’ readerğ¸
ğ‘› ğ‘ƒ ğ‘ ğ‘ an s â„’ alignğ¿
ğ‘ƒ ğ‘ ğ‘ an s
â„’ reader
ğ‘¢ğ‘¢ ğ‘™ğ‘™ğ‘¡ğ‘¡ğ‘–ğ‘–
ğ“’ğ“’ ğ¸ğ¸ ğ‘›ğ‘›
ğ‘ƒan ğ‘s ğ¸ â„’ e2eğ‘› ğ¿ ğ‘
ğ‘€ğ‘€ğ“’ğ“’ ğ‘¢ğ‘¢
ğ‘€ ğ¿ğœƒ
ğ‘™ğ‘™ğ‘¡ğ‘¡ğ‘–ğ‘–
ğ‘ƒan ğ‘s â„’ e2eğ¿ ğ¿ ğ‘
ğ“’ ğ‘€ ğ‘¢ ğ‘™ğ‘¡ğ‘– ğ“’ ğ¸ ğ‘›containstheevidenceisunavailable,andtherele- scoreservesasthepassagerelevancemeasurement:
vantpassagescanberetrievedfromanylanguage.
L = KL(P (Â·|q,D)||P (Â·|q,D)),
KL be ca
2.2 ModelArchitecture
exp(s(q,d ))
i
P (Â·|q,D) = |d âˆˆ D,
Weuseasingleencoder-decoderlanguagemodel be (cid:80) exp(s(q,d )) i
djâˆˆD j
toperformbothpassageretrievalandanswergen-
erationtask(Leeetal.,2022;Jiangetal.,2022).
(cid:88)H (cid:88)|di|
SG(CA(0,h,t))
P (Â·|q,D) = |d âˆˆ D,
ca i
H
Retriever Wedividetheencoderintotwoparts, h=0t=0
with the first B layers used as the dual-encoder,
whereP (Â·|q,D)andP (Â·|q,D)arethedistribu-
be ca
wherethequeryandpassageareencodedindepen-
tionsoverD fromtheretrieverandthedecoderâ€™s
dently. Following Jiang et al. (2022), we use the
cross-attention scores, respectively. SG signifies
query Q and key vectors K in B +1-th layer as
the stop-gradient operation, and CA denotes the
queryandpassagerepresentations,respectively:
cross-attentionscoreatthelastdecoderlayer. The
term0referstothefirstoutputtoken,H isthenum-
E = {KB+1,h âˆˆ R|d|Ã—e}H ,
d d h=1 berofcross-attentionheads,and|d |standsforthe
i
E q = {QB q+1,h âˆˆ R|q|Ã—e}H h=1, lengthofpassaged i.
where|q|and|d|arequeryandpassagelength. H 3 Method
is the number of self-attention heads and e is the
dimensionofeachhead. Weproposeanunsupervisedtwo-stagepre-training
The self-attention matrix SAB+1,h from a spe- method for cross-lingual open-retrieval question
q,d
cific head is considered the source of retrieval answering,asdepictedinFigure1. Ourapproach
scores. Asumofmaxcomputations(Khattaband starts with cross-lingual retrieval pre-training,
Zaharia,2020)areperformedtoreduceittoyield where the multilingual model develops excellent
theretrievalscore: cross-lingualdenseretrievalcapabilities. Thispro-
ficiencyisacquiredthroughlearningfromawell-
s(q,d) = (cid:88) maxSAB+1,h, trainedEnglishmodel,employingcloze-styleparal-
i,j
jâˆˆ|d| lelqueriesandretrievedEnglishpassagesasinputs.
iâˆˆ|q|
The subsequent stage involves pre-training for
SAB+1,h = QB+1,hÃ—KB+1,hâŠ¤ âˆˆ R|q|Ã—|d|.
q,d q d multilingual question-answering (QA), where
the model is further pre-trained on multilingual
Reader Aftertheretrieverlayer,bothqueryand
question-answerpairsthatareautomaticallygen-
passage are encoded jointly, wherein the remain-
erated. Thisprocessentailsselectingpotentialan-
ing encoder layers function as the cross-encoder.
swers from anchor texts and applying our novel
Then, the joint encodings of multiple passages
questiontransformationtechniquestoconvertcloze
{E }n areintegratedintothedecodertogen-
q,d i i=0 questions into natural questions by prompting a
eratetheanswerefficientlyfollowingtheFusion-
largelanguagemodel.
in-Decoderapproach(IzacardandGrave,2021).
3.1 Cross-LingualRetrievalPre-training
2.3 TrainingObjectives
Pre-trainingData Weconsiderclozequestions,
Themodelistrainedend-to-endbyemployingthe
whicharestatementswiththeanswermasked,as
trainingsignalsderivedfromtheanswergeneration
pseudoqueries. Theanswersaresalientspansse-
task: L = L +Î±Â·L .
e2e reader KL
lectedfromnamedentities. Weextractallnamed
ReaderLoss Thereaderistrainedwithlanguage entitiesforanEnglishsentenceusingaNERsys-
modelling loss via teacher forcing, by providing tem,generatingqueriesforeach. Formally,letsEn
thequeryqandacollectionofevidenceDasinput: beasentencesampledfromanEnglishWikipedia
page WEn, along with its associated named enti-
L
reader
=P ans(a|q,D)=âˆ’log(cid:81)T t=1P(a t|a <t,q,D) ties{a i}n i=1. Thisallowsustoderiveclozequeries
{qEn}n by masking each entity a . Then, for
i i=1 i
RetrieverLoss Theretrieveristrainedbylearn- each qEn, the objective is to identify its transla-
i
ingfromthedecoder,whereinthecross-attention tionqL inlanguageLbysearchingfromsentences
i
3{qL}n within a Wikipedia page WL, which is impedes the development of advanced question-
j j=0
connectedtoWEnvialanguagelinksinWikipedia. answeringskills. Moreover,theincapacitytopre-
Weuseamargin-basedminingmethod(Artetxe ciselylocateandmasktheanswerawithinqL for
andSchwenk,2019)toidentifyparallelsentences perfectly aligned queries makes the QA task no-
basedontheirsimilarityintheembeddingspace: tably simpler, as a implicitly appears in qL (e.g.,
"ã‚¤ãƒ³ãƒ‰"inqL istheJapaneseanswerinFigure1).
cos(x,y) Meanwhile, since qEn and qL could be roughly
M(x,y) = ,
(cid:80) cos(x,z) +(cid:80) cos(y,z) aligned, the querying of a by qL is not assured,
zâˆˆNx 2k zâˆˆNy 2k
therebyintroducingnoiseintothepre-traineddata
where N x and N y are the top-k neighbours of (e.g.,"In1945,hisfathersenthimtoCollÃ¨gedes
sentence x and y in the other language, respec- FrÃ¨res" and "çˆ¶ã¯ã‚µãƒ–ãƒªãƒ¼ã‚’ãƒ¤ãƒƒãƒ•ã‚¡ã®ã‚«
tively. cos(x,y) denotes the cosine similarity be- ãƒˆãƒªãƒƒã‚¯ç³»ãƒ•ãƒ©ãƒ³ã‚¹èªå­¦æ ¡ã«é€ã£ãŸã€‚" are
tween the embeddings of x and y. We follow aligned but the Japanese query does not mention
mSimCSE(Wangetal.,2022)topre-trainamultilin- the answer 1945). Thus, we design another pre-
gualmodelwithunsupervisedcontrastlearningand trainingtechniquetoaddressthelimitationsabove.
employitforembeddingextraction. Weapplythis
scoring function to qEn and each qL âˆˆ {qL}n . 3.2.1 Pre-trainingData
i j j j=0
Pairs whose scores surpass a pre-defined thresh-
Theconstructionofpre-trainingdatainthisstage
old T are selected as parallel queries, denoted as
involvestwosequentialsteps. Initialdataarefirst
{qEn,qL,a }.2
i j i acquiredfromamultilingualWikipediasourcein
theformatofclozequestions,followedbyaformat
Training A well-trained English model Î¸En is
transformationintonaturalquestions.
employedtoteachamultilingualmodelÎ¸ML using
parallelqueries. Specifically,givenatrainingexam-
InitialData IncontrasttoEnglishtexts,where
ple{qEn,qL,a},weemployÎ¸En toretrieveaset
robust NER systems facilitate the detection of
ofrelevantpassagesDEn fromEnglishWikipedia
namedentitieswithhighprecisionforanswergen-
CEnforqEn. Themultilingualmodelisthencom-
eration, such systems in other languages exhibit
pelledtoalignitsretrievaldistributionswiththose
inherentdeficiencies. Instead,weemployanchor
ofÎ¸En overDEn throughKLdivergenceloss:
textswithhyperlinksasanswercandidates. Specif-
ically, for a given sentence sL in language L, we
L = KL(PML(Â·|qL,DEn)||PEn(Â·|qEn,DEn))
KL be be consider the anchor texts {aL}n within it as
+KL(PML(Â·|qEn,DEn)||PEn(Â·|qEn,DEn)). i i=0
be be potential answers and construct cloze questions
{qL}n accordingly.
Additionally, Î¸ML is trained to predict the an- i i=0
ForeachaL,wefetchtheWikipediapageWL
swerawitheitherqEn orqL asthequestion: i
towhichitlinksandaccessthecorrespondingEn-
L = P (a|qEn,DEn)+P (a|qL,DEn). glishWikipediapageWEn vialanguagelink. Sub-
reader ans ans
sequently,thetitleaEn ofWEn isassumedtobe
i
Moreover,toensurethatthemultilingualmodel thepseudotranslationofaL. Moreover,NERtag-
i
generatesconsistentpredictionsacrosslanguages, gingisperformedonthefirstparagraphofWEn to
weintroduceanalignmentregularisationterm: identifythetypet ofthetitleentityaEn,whichis
i i
thenassignedtoaL. Finally,atrainingexampleis
i
L align=KL(P bM eL(Â·|qL,DEn)||P bM eL(Â·|qEn,DEn)) derivedintheformof(q iL,aL
i
,aE
i
n,t i).3
+KL(P (a|qL,DEn)||P (a|qEn,DEn)).
ans ans
Query Transformation We employ large lan-
Overall,Î¸ML istrainedwiththeweightedcom- guagemodels(LLMs)forquerytransformationvia
binedloss: L = L +Î±Â·(L +L ). In-ContextLearning(ICL)(Brownetal.,2020).
stage1 reader KL align
WefirstpromptChatGPT(gpt-3.5-turbo)to
3.2 MultilingualQAPre-training
generate a few examples as meta-examples (Fan
Theclozequestionsaresubstantiallydifferentfrom et al., 2023) for ICL. Specifically, we randomly
theformatsofnaturalquestions,whichinherently
3Notably,aLischosenfortrainingwhenthedownstream
2Weidentifya iandmaskitinq jLthroughstringmatchif taskinvolvesmi ultilingualquestion-answering.Likewise,aE
i
n
LiswritteninLatinscriptandleaveqLunchangedotherwise. isemployedwhenEnglishanswergenerationisofinterest.
j
4sampleinstancesfromtheinitialdatasetandgener- B
CLASS-US
Stage 2
atetransformedquestionsbasedonthestructureof A D E
thepromptshowninPrompt3.1. Stage 1 NQ FT XOR FT
C
Stage 2
Prompt3.1: Meta-ExampleGeneration w/o QT CLASS-ZS CLASS
Figure2: Thetrainingpipelineofourmethod.
Rewritethissentence{qL}intoanaturalquestionwhose
i
questionwordis{wh_word}andansweris{aL}. Please
respond in the format: "The transformed
qi
uestion is:
7 languages of XOR-TYDI QA and a subset of
{qLT }" MKQAlanguagesasCMulti (Asaietal.,2021a).
i
WetakeR@2ktandR@5ktasevaluationmet-
wherewh_wordischosenaccordingtotheentity ricsforcross-lingualretrieval,whichmeasuresthe
typet i throughheuristics(Lewisetal.,2019). This fraction of queries for which the top-n retrieved
step yields a curated set of ICL examples: K = tokens contain the answer. The average R@2kt
{qL,wh_word,aL,qLT }k . Anexampleisshown andR@5ktscoresacrossalllanguagesareusedfor
i i i i=0
inFigure9intheAppendix. modelcomparison. F1andExactMatch(EM)are
We employ an open-sourced LLM, LLaMA-2- usedforevaluatingquestion-answeringtasks,with
7B(Touvronetal.,2023),fortheefficienttransfor- token-levelBLEUscoressupplementedonXOR-
mationofquestionsatlargescale. Specifically,the FullandMKQA.TheaverageF1scoreacrossall
promptisconstructedasfollows: (1)thefirstpart languagesisusedforperformancecomparisons.
includestheinstructionthatexpressestheintentof
the question transformation task; (2) n instances
4.2 ExperimentalSettings
are randomly sampled from K and organised in
a pre-defined structure; (3) the last part includes Pre-training Corpus In stage-1, for each
thetestinstancetobetransformed. Examplesare WEn âˆˆ CEn,wegatheritsparallelpagesacross
showninAppendixD. various languages. We consider 15 distinct lan-
guages,comprising7fromXOR-TYDI QA,and8
3.2.2 Training arehigh-resourceorcloselyrelatedtothe7evalu-
For each (qLT ,aL), we use the retrieval compo- atedlanguages. Parallelsentencesareminedfrom
nent of the current model Î¸ML to gather a set of eachpairofparallelpages. Astate-of-the-artNER
passagesDMulti fromCMulti,4 andoptimisethe taggerisappliedtoeachEnglishsentence,andwe
model using L as defined in Â§2.3. To ensure retainpairsfeaturingcontainednamedentities.
e2e
efficient training, passages are retrieved for each In stage-2, data generation is limited to 7 lan-
trainingquerybeforehand,withperiodicrefreshing guageson XOR-TYDI QA.WeemployLLaMA-
atspecificintervalsusingthemostrecentmodel. 2-7B to generate one transformed question per
trainingexamplewith3randomlysampledmeta-
4 Experiments
examplesinthesamelanguageastheprompt. We
generate multiple questions for each example in
4.1 Dataset
low-resource languages. More details are in Ap-
We evaluate our approach on the XOR-TYDI pendicesA.1.1andA.1.2.
QA dataset (Asai et al., 2021a), where the
XOR-Retrievetaskinvolvescross-lingualretrieval TrainingRecipe AnEnglishteacherÎ¸En isfirst
and QA and XOR-Full centers on multilingual
trained on NQ (Kwiatkowski et al., 2019) as in
open-retrieval QA. For both tasks, we employ
Jiang et al. (2022). Undertaking stage-1 pre-
MKQA(Longpreetal.,2021),adatasetgenerated
trainingbyenforcingmt5-large(Xueetal.,2021)
by translating questions from Natural Questions tolearnfromÎ¸EnresultsinCLASS-US-Stage1,fol-
(NQ) (Kwiatkowski et al., 2019), to evaluate our
lowed by stage-2 pre-training to obtain the unsu-
modelâ€™szero-shotcross-lingualtransferabilityon
pervised model, CLASS-US. The zero-shot model
unseenlanguages. WeusetheFebruary2019En-
CLASS-ZSisacquiredbytrainingCLASS-USonEn-
glish Wikipedia dump as CEn and use the same
glish data (i.e., NQ), followed by fine-tuning on
Wikipediadumpsof13diverselanguagesfromall
labelled data from XOR-TYDI QA to obtain the
supervisedmodelCLASS.Anoverviewisshownin
4WereplaceaLwithaEnandCMultiwithCEnwhen
i
thedownstreamtaskofinterestisEnglishanswergeneration. Figure2andmoredetailsareinAppendixA.1.3.
5R@2kt R@5kt
Method Size
Ar Bn Fi Ja Ko Ru Te Avg Ar Bn Fi Ja Ko Ru Te Avg
UnsupervisedRetrievers
LAPCAÂ¶Â§ 560M 51.1 50.2 48.6 35.1 57.3 32.2 64.4 48.4 61.0 58.4 52.6 40.5 66.7 40.8 70.1 55.7
CLASS-US 410M 66.0 75.7 63.4 57.7 63.5 68.8 70.6 66.5 71.2 81.6 69.4 66.8 70.5 75.1 77.3 73.1
Zero-shotRetrievers
DPR+MTâ€  220M 43.4 53.9 55.1 40.2 50.5 30.8 20.2 42.0 52.4 62.8 61.8 48.1 58.6 37.8 32.4 50.6
LAPCAÂ¶Â§ 560M 46.2 50.3 56.6 41.4 48.7 52.3 54.6 50.0 53.0 60.5 66.2 49.7 56.1 60.7 63.8 58.6
ReAtt+MT 583M 63.1 67.7 20.7 55.9 60.3 55.3 58.4 54.5 67.3 71.0 29.3 61.8 67.0 61.2 66.4 60.6
CLASS-ZS 410M 65.1 79.3 67.8 60.6 61.1 69.2 74.4 68.2 72.5 83.2 73.9 70.5 69.1 75.1 81.9 75.2
(Semi-)SupervisedRetrievers
CORA 557M 32.0 42.8 39.5 24.9 33.3 31.2 30.7 33.5 42.7 52.0 49.0 32.8 43.5 39.2 41.6 43.0
mDPRâ€  557M 38.8 48.4 52.5 26.6 44.2 33.3 39.9 40.5 48.9 60.2 59.2 34.9 49.8 43.0 55.5 50.2
SentriÂ§ 560M 47.6 48.1 53.1 46.6 49.6 44.3 67.9 51.0 56.8 62.2 65.5 53.2 55.5 52.3 80.3 60.8
QuiCK 557M 52.8 70.1 62.2 54.8 62.8 57.8 70.6 61.3 63.8 78.0 65.3 63.5 69.8 67.1 74.8 68.9
DrDecrâˆ— 278M - - - - - - - 66.0 70.2 85.9 69.4 65.1 68.8 68.8 83.2 73.1
LAPCAÂ¶Â§ 560M 61.1 76.9 72.6 60.9 69.1 69.1 75.6 69.3 70.2 83.8 79.6 69.7 73.6 75.5 83.1 76.5
CLASS 410M 67.3 80.9 67.2 64.7 71.6 69.6 79.8 71.6 74.8 84.5 72.3 73.9 79.3 77.2 85.3 78.2
F1 EM
Method Size
Ar Bn Fi Ja Ko Ru Te Avg Ar Bn Fi Ja Ko Ru Te Avg
mDPRâ€  835M 17.9 19.4 24.5 13.1 14.3 17.2 14.4 17.2 11.7 14.1 18.3 10.7 9.9 11.1 10.2 12.3
MT+DPRâ€  - 28.0 25.6 29.3 19.2 19.4 18.4 3.8 20.5 23.4 20.3 22.1 13.8 14.2 13.6 2.7 15.7
ReAtt+MT 1.19B 26.0 36.6 3.5 18.4 29.3 29.3 27.0 24.3 17.1 30.1 1.7 14.5 22.7 22.8 21.0 18.6
GMT+GSâ€  - 39.5 42.1 28.2 23.5 30.5 34.8 31.6 32.9 28.5 34.4 21.3 17.4 23.8 26.4 25.1 25.3
CLASS 1.23B 44.0 59.4 43.9 40.6 44.8 47.9 50.1 47.2 35.7 52.2 35.3 35.1 37.1 38.8 44.1 39.8
Table1: ResultsonthedevsetofXOR-Retrieve. ResultsreportedbyAsaietal.(2021a)andAbulkhanovetal.
(2023)aredenotedwithâ€ andÂ¶,respectively. âˆ—indicateshuman-translatedsupervisedparallelqueriesreleasedby
XOR-Retrieveareusedfortraining. Â§representsmethodsthatemployMTsystemsfortrainingdataaugmentation.
4.3 MainResults hindLAPCA.5 Themostpronouncedperformance
gaps are in Bengali and Korean, with the fewest
XOR-Retrieve Table1showstheresultsonthe
two training samples available within XOR-Full.
devsetofXOR-Retrieve. CLASS,whichexclusively
We believe it is the translated questions used by
employsquestion-answerpairsfortraining,demon-
Sentri and LAPCA that alleviate such discrepan-
stratesasubstantialperformanceadvantageoverall
cies. WeexpectCLASScanbefurtherimprovedby
baselinesthatrelyonpassagelabelsforcontrastive
introducing such augmented training data during
learning. Thisadvantageisparticularlypronounced
fine-tuning,whichweleaveasfuturework.
underunsupervisedandzero-shotsettings,where
both variants, CLASS-US and CLASS-ZS, achieve MKQA We assess the zero-shot performance
improvementsofmorethan10%comparedtostate- of CLASS in various unseen languages included
of-the-artmethods. IntheEnglishspanextraction in MKQA. Figure 3 shows that in cross-lingual
task,CLASSsurpassesallcompetitivebaselinesby retrieval tasks, all variants of our method exhibit
a significant margin (+15%), which is attributed promisingresults. Notably,CLASS-UScanoutper-
toitssuperiorretrievalabilitiesingatheringmore form the supervised model CORA significantly,
relevantdocuments. and further fine-tuning on English data leads to
substantialimprovements. Interestingly,CLASSun-
XOR-Full Table2reportstheresultsofCLASSon derperformsCLASS-ZS,despitebeingfurtherfine-
XOR-Full. CLASSachievessuperiorperformance tunedonmultilingualdata. Weattributethisphe-
whencomparedtoaseriesofbaselinemodelsand nomenon to two factors: the limited number of
thepriorstate-of-the-artCORAmodelinalltested queriesinXOR-Retrievemayresultinthemodel
languages, showcasing an average improvement overfitting to these specific languages; the query
of 7.8%. Compared to methods that rely on ma- topicsdiffer,asMKQAistheliteraltranslationof
chinetranslationtogenerateasubstantiallylarger
5AdirectcomparisonwithSentriandLAPCAisnotfeasi-
pool of multilingual training data from English
blesincetheWikipediapagestheyemployedasknowledge
datasets,CLASSiscomparabletoSentributfallsbe- sourcesaredifferentfromoursandAsaietal.(2021b).
6F1 MacroAverage
Method Size
Ar Bn Fi Ja Ko Ru Te F1 EM BLEU
BM25â€  - 31.1 21.9 21.4 12.4 12.1 17.7 â€“ â€“ â€“ â€“
MT+DPRâ€  - 7.2 4.3 17.0 7.9 7.1 13.6 0.5 8.2 3.8 6.8
ReAtt+MT 1.19B 15.0 10.5 1.8 13.1 14.9 15.4 8.2 11.3 5.5 9.5
GMT+GSâ€  - 18.0 29.1 13.8 5.7 15.2 14.9 15.6 16.0 9.9 14.9
MT+Monoâ€  - 15.8 9.6 20.5 12.2 11.4 16.0 0.5 17.3 7.5 10.7
CORAâ€  1.14B 42.9 26.9 41.4 36.8 30.4 33.8 30.9 34.7 25.8 23.3
CLASS 1.23B 49.5 32.0 49.6 44.7 37.5 41.4 42.0 42.4 32.7 29.2
IncomparableModels
SentriÂ§ 1.14B 52.5 31.2 45.5 44.9 43.1 41.2 30.7 41.3 34.9 30.7
LAPCAÂ§ 1.14B 53.4 50.2 49.3 44.7 49.5 49.3 38.9 47.8 38.7 35.5
Table2: QuestionAnsweringresultsontheXOR-Fulldevset. ResultsreportedbyAsaietal.(2021b)aredenoted
withâ€ . Â§indicatesmethodsthatusesyntheticandtranslatedqueriesfromEnglishdatasetsasaugmenteddata.
CORA Sentri CLASS-US CLASS CLASS - qL w/ 7 langs w/ MT
BM25+MT QuiCK CLASS-ZS 70 - qEn - align w/ CS
50
60
50
40
(a) Cross-lingual Retrieve
MT+Mono CLASS-US 40
25 ReAtt+MT CLASS-ZS R@2kt R@5kt
MT+DPR CLASS
CORA
70
20
60
15
(b) Multilingual QA 50
Figure3: Zero-shotcross-lingualretrievalresults(Avg.
R@2kt)onunseenlanguagesofMKQA. 40
ar bn fi ja ko ru te da* nl* no*
Figure4: Ablationsonstage-1pre-training,withresults
ontheXOR-Retrievedevsetreported. âˆ— indicatesun-
NQwhileXOR-Retrieveiscreatedindependently.
seenlanguagesfromMKQA.
InthemultilingualQAtask,weobservesimilarpat-
ternswhereCLASS-ZSachievesthebestzero-shot
performanceacrossunseenlanguageswhilefurther
byensuringconsistentpredictions. iii)Pre-training
fine-tuningthismodelonXOR-Fulldataresultsin
solelyonthe7languagesof XOR-TYDI QA (w/
areductioninitsoverallgeneralizability.6 Detailed
7langs)doesnotsignificantlyimpactaverageper-
resultsineachlanguageareinAppendixB.
formance but affects specific low-resource lan-
guages. Inparticular,addingdatafromlanguages
4.4 Analysis
relatedtoTeluguandJapanese(e.g.,Tamil&Chi-
Wepresentdetailedablationstudiesinthissection.
nese) yields improvements. Moreover, including
MoreanalysesareinAppendixC.
a wider range of languages improves generalisa-
Ablations WecompareCLASSwithdifferentvari- tiontounseenlanguages. Forinstance,pre-training
ants to study the impact of different components in German enhances understanding of the West
instage-1pre-training. AsshowninFigure4,we Germaniclanguages(i.e.,Danish,Dutch,andNor-
foundthat: i)RemovingquerieseitherinEnglish wegian). iv) When comparing the approaches of
(-qEn) or in target languages (-qL) leads to per- gatheringparallelqueries,ourmethodoutperforms
formancedegradation. ii)Thecross-lingualalign- code-switching (w/ CS), which creates pseudo-
mentregularisation(-Lalign)enhancestheperfor- translationsthroughlexiconreplacementbasedon
mance of the model trained with parallel queries bilingualdictionaries,andmachinetranslations(w/
MT).Thisinferiorityisprimarilyattributedtothe
6Weleavetheexplorationofimprovedfine-tuningtech-
limitedcoverageofbilingualdictionariesandpoor
niquesthatstrikeabalancebetweenenhancingsupervisedand
zero-shotcross-lingualresultsasfuturework. translationqualityinlow-resourcelanguages.
7
tk2@R
1F
tk2@RXOR-Retrieve XOR-Full taband Zaharia,2020), anddistilling fromcross-
Method
R@2ktR@5kt F1 EM F1 EM BLEU encoderrerankers(Renetal.,2021). Withthead-
ventofmultilingualpre-trainedmodels,thesetech-
Unsupervised
CLASS-US(AB) 66.5 73.1 21.717.0 18.412.0 14.6 niqueswereadaptedtoimprovecross-lingualdense
-Stage-2(A) 59.1 67.4 6.0 4.1 5.7 3.9 4.0 retrievals (Asai et al., 2021b; Ren et al., 2022).
-QueryTF(AC) 66.1 73.1 7.4 5.5 7.2 4.8 4.9
However,allthesemethodsrelyonpassagelabels
Zero-shot
CLASS-ZS(ABD) 68.2 75.2 34.528.0 23.915.8 19.4 for contrastive learning, which is challenging to
-Stage-2(AD) 62.9 71.1 32.826.9 13.7 8.1 8.3 obtain in cross-lingual settings. In contrast, our
-Pre-train(D) 27.6 36.3 17.013.0 15.4 9.6 11.0
method explores a semi-supervised method and
Supervised
CLASS(ABDE) 71.6 78.2 47.239.8 42.432.7 29.2 showsthatacompetitivecross-lingualretrievercan
-Stage-2(ADE) 69.6 75.7 46.038.7 42.533.1 29.1 beachievedusingonlyquery-answerpairs.
-Pre-train(DE) 62.8 69.3 41.635.2 41.932.6 28.7
Multilingual Retrieval Pre-training Large-
Table3: Effectsoftwo-stagepre-training. Resultson scaleunsupervisedretrievalpre-traininghasbeen
thedevsetsarereported. Symbolswithinbracketsare shown to significantly enhance dense retriev-
describedinFigure2.
ers(GaoandCallan,2021;Izacardetal.,2022)in
processingEnglishtexts. Pre-traininghasalsobeen
Effects of Two-stage Pre-training We evalu- explored in cross-lingual and multilingual dense
atetheeffectivenessofourproposedpre-training retrieval,withaparticularemphasisonaugmenting
framework by excluding either the stage-2 or the the cross-lingual alignment capabilities of mod-
entirepre-trainingprocedures. Table3showcases els. LAPCA (Abulkhanov et al., 2023) is trained
theperformanceonbothXOR-RetrieveandXOR- through extensive cross-lingual contrastive learn-
Fullacrossunsupervised,zero-shot,andsupervised ing,employingtextsfromparallelWikipediapages
settings. The inclusion of stage-2 pre-training andparalleltextsgeneratedbymachinetranslation
dramatically boosts the performance in both un- systems. DrDecr(Lietal.,2022)learnsfromEn-
supervised and zero-shot scenarios. Removing glish models but operates on a smaller scale and
Query Transformation in stage-2 by solely em- reliesonsupervisedparallelqueries. Inthiswork,
ploying cloze-style questions has no discernible wedelveintothepotentialoflarge-scaleunsuper-
impact on retrieval performance but yields sub- visedpre-trainingforcross-lingualdenseretrieval
optimal QA results. This highlights the impor- and show that the resulting model exhibits high
tance of generating queries that resemble the for- efficacy,outperformingmanysupervisedones.
matsofnaturalquestionstodownstreamQAtasks.
Pre-trainingforRetrieval-AugmentedMultilin-
When discarding the entire pre-training process,
gualQA InthecontextofEnglish,jointlytrain-
wherein the model only uses the initial retrievals
ing a retriever and reader on supervised query-
from DPR (Karpukhin et al., 2020) for warm-up
answer pairs (Sachan et al., 2021; Lewis et al.,
training, we observe a notable decline in perfor-
2020) or large-scale unsupervised data derived
manceonbothdatasets. Insupervisedsettings,the
from masked salient span masking (Guu et al.,
advantagesconferredbyourproposedpre-training
2020;Leeetal.,2022)havebeenshowntoenhance
diminish in the presence of labelled data. These
theperformanceofbothretrievalandquestionan-
benefitsbecomeprogressivelyinconsequentialas
swering tasks. However, the application of such
thenumberofsuperviseddataincreases(i.e.,15K
a joint training paradigm, whether in supervised
inXOR-Retrievev.s. 61KinXOR-Full).
trainingorunsupervisedpre-training,hasnotbeen
exploredincross-lingualandmultilingualsettings.
5 RelatedWork
Ourstudyrepresentsthefirstinvestigationintothis
MultilingualDenseRetrieval Denseretrievers issue and proposes a curated pre-training frame-
adopt pre-trained language models and follow a work within a unified model to address both re-
dual-encoderarchitecture(Karpukhinetal.,2020) trievalandquestion-answeringtasks. Weintroduce
toencodequeriesandpassagesintodensevectors atwo-stagepre-trainingproceduretoinitiallyequip
andcalculatethesimilarityscores. Effectivetech- amultilingualmodelwithrobustcross-lingualre-
niques were proposed to advance English dense trieval abilities by learning from English experts
retrievals,includinghardnegativemining(Xiong andthengraduallyevolvingitthroughexposureto
et al., 2021), multi-vector representations (Khat- large-scalemultilingualQApairs. Thisapproach
8yieldsremarkableunsupervisedresultsandsignifi- aconcern. Nevertheless,itremainsimperativeto
cantperformanceimprovementsacrossunseenlan- exploremethodsforreducingtherelianceonpar-
guageswithoutannotatedtrainingdata. allel Wikipedia texts, as this is essential to scale
ourmethodtomorediverseanduniquelanguages,
6 Conclusion whichisworthexploringasafuturework.
Thisworkdoesnotexaminethebenefitsofpre-
Inthispaper,weexplorethepotentialofaunified
training in a broader range of languages and the
model for both cross-lingual retrieval and multi-
scaling effects of both model size and data size
lingualQAtasks. Byincorporatingourproposed
formultilingualQAtasks,whichisaninteresting
pre-trainingparadigm,CLASS,themodelâ€™sperfor-
researchtopicthatshouldbeaddressedrigorously
mance can be significantly improved, achieving
inthefuture.
bothboostedretrievalandQAperformance,while
As this work uses large language models for
exhibiting impressive zero-shot transfer abilities
query transformation, it is possible that undesir-
tonumerousunseenlanguages. Detailedablations
ablebiases(e.g., genderandcultural)inherentin
andthoroughanalysesareconductedtoassessthe
theselanguagemodelsmaybepropagatedtodown-
efficacy of each component within our approach.
streamsystems. Furthermore,theextensivecorpus
OurfutureworkaimsatscalingCLASStoabroader
ofWikipediatexts,drawnfromamultitudeoflan-
rangeoflanguagestofurtherenhancethemodelâ€™s
guages,couldpotentiallyintroduceadiversearray
cross-lingualtransferperformance.
of biases related to races and cultures to the pre-
trained model. Assessing the magnitude of bias
Limitations
withinthepre-trainingdataanditssubsequentim-
Theproposedpre-trainingframeworkincursaddi- pactonthemodelisaninherentlyintricateproblem,
tionaltrainingcostswhencomparedtostandardsu- whichremainsanopenquestionforfutureresearch.
pervisedtraining,suchasvariouspre-trainingdata Theoretically,ourmodelcanincorporateinforma-
generationpipelines. Theentiretrainingpipeline tionextractedfromanyexternalcorpustogenerate
requiresapproximatelytwoweekstocompletewith answerstoaskedquestions. Thiscapabilitycarries
amaximumof32A100GPUs. Thiscouldbeless the potential for significant information leakage
practicalforresearcherswhodonothaveaccessto or the exposure of potentially toxic content from
sufficient GPU resources. Nonetheless, common thecorpus,whichunderscorestheneedforexercis-
techniquessuchasgradientaccumulationcanbe ingcautionwhenapplyingourmethodinsensitive
appliedtoadaptourapproachfortraininginamore domains.
academic setting, although more training time is
requiredtoachievecomparableresults.
References
Bothstagesinourpre-trainingparadigmdepend
ontheavailabilityofparallelWikipediapages. This DmitryAbulkhanov,NikitaSorokin,SergeyNikolenko,
canposeachallengewhendealingwithlanguages and Valentin Malykh. 2023. Lapca: Language-
thathavelimitedresourcesevenintermsofmono- agnosticpretrainingwithcross-lingualalignment. In
Proceedings of the 46th International ACM SIGIR
lingual texts. Our approach may fail when no
ConferenceonResearchandDevelopmentinInfor-
language links exist between English and a spe-
mationRetrieval,SIGIRâ€™23,page2098â€“2102,New
cific low-resource language. One may resort to York,NY,USA.AssociationforComputingMachin-
employingamulti-hopapproachtodiscoverparal- ery.
lelWikipediapages,byfirstsearchingforthelan-
Mikel Artetxe and Holger Schwenk. 2019. Margin-
guagelinkedtothelow-resourcelanguagewithin
basedparallelcorpusminingwithmultilingualsen-
Wikipedia and then repeating this process itera- tence embeddings. In Proceedings of the 57th An-
tively until reaching the corresponding English nualMeetingoftheAssociationforComputational
Linguistics,pages3197â€“3203,Florence,Italy.Asso-
page. Anotheroptioncouldberelyingonthegen-
ciationforComputationalLinguistics.
eralisationofthemultilingualmodelbytrainingit
inclosely-relatedlanguages. Ouranalysishasre- AkariAsai,JungoKasai,JonathanClark,KentonLee,
vealedthatincorporatingahigh-resourcelanguage EunsolChoi,andHannanehHajishirzi.2021a. XOR
QA:Cross-lingualopen-retrievalquestionanswering.
inthepre-trainingphaseconsistentlyresultsinim-
InProceedingsofthe2021ConferenceoftheNorth
provements for other languages within the same
AmericanChapteroftheAssociationforComputa-
language family, which makes this issue less of tionalLinguistics: HumanLanguageTechnologies,
9pages 547â€“564, Online. Association for Computa- pages 874â€“880, Online. Association for Computa-
tionalLinguistics. tionalLinguistics.
Akari Asai, Xinyan Yu, Jungo Kasai, and Hannaneh ZhengbaoJiang,LuyuGao,ZhiruoWang,JunAraki,
Hajishirzi. 2021b. One question answering model Haibo Ding, Jamie Callan, and Graham Neubig.
formanylanguageswithcross-lingualdensepassage 2022. Retrieval as attention: End-to-end learning
retrieval. In Advances in Neural Information Pro- ofretrievalandreadingwithinasingletransformer.
cessingSystems. In Proceedings of the 2022 Conference on Empiri-
calMethodsinNaturalLanguageProcessing,pages
Tom Brown, Benjamin Mann, Nick Ryder, Melanie 2336â€“2349,AbuDhabi,UnitedArabEmirates.As-
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind sociationforComputationalLinguistics.
Neelakantan,PranavShyam,GirishSastry,Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss, VladimirKarpukhin,BarlasOguz,SewonMin,Patrick
Gretchen Krueger, Tom Henighan, Rewon Child, Lewis,LedellWu,SergeyEdunov,DanqiChen,and
AdityaRamesh,DanielZiegler,JeffreyWu,Clemens Wen-tauYih.2020. Densepassageretrievalforopen-
Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma- domainquestionanswering. InProceedingsofthe
teusz Litwin, Scott Gray, Benjamin Chess, Jack 2020ConferenceonEmpiricalMethodsinNatural
Clark, ChristopherBerner, SamMcCandlish, Alec LanguageProcessing(EMNLP),pages6769â€“6781,
Radford, Ilya Sutskever, and Dario Amodei. 2020. Online.AssociationforComputationalLinguistics.
Language models are few-shot learners. In Ad-
OmarKhattabandMateiZaharia.2020. Colbert: Effi-
vances in Neural Information Processing Systems,
cientandeffectivepassagesearchviacontextualized
volume 33, pages 1877â€“1901. Curran Associates,
lateinteractionoverbert. InProceedingsofthe43rd
Inc.
InternationalACMSIGIRConferenceonResearch
DanqiChen,AdamFisch,JasonWeston,andAntoine and Development in Information Retrieval, SIGIR
Bordes.2017. ReadingWikipediatoansweropen- â€™20,page39â€“48,NewYork,NY,USA.Association
domainquestions. InProceedingsofthe55thAnnual forComputingMachinery.
Meeting of the Association for Computational Lin-
TomKwiatkowski, JennimariaPalomaki, OliviaRed-
guistics(Volume1: LongPapers),pages1870â€“1879,
field,MichaelCollins,AnkurParikh,ChrisAlberti,
Vancouver,Canada.AssociationforComputational
DanielleEpstein,IlliaPolosukhin,JacobDevlin,Ken-
Linguistics.
tonLee,KristinaToutanova,LlionJones,Matthew
Alexis CONNEAU and Guillaume Lample. 2019. Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob
Cross-lingual language model pretraining. In Ad- Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-
vances in Neural Information Processing Systems, ralquestions: Abenchmarkforquestionanswering
volume32.CurranAssociates,Inc. research. TransactionsoftheAssociationforCompu-
tationalLinguistics,7:452â€“466.
Lijie Fan, Dilip Krishnan, Phillip Isola, Dina Katabi,
andYonglongTian.2023. ImprovingCLIPtraining HaejunLee,AkhilKedia,JongwonLee,AshwinParan-
withlanguagerewrites. InThirty-seventhConference jape, Christopher Manning, and Kyoung-Gu Woo.
onNeuralInformationProcessingSystems. 2022. You only need one model for open-domain
questionanswering. InProceedingsofthe2022Con-
LuyuGaoandJamieCallan.2021. Condenser: apre- ferenceonEmpiricalMethodsinNaturalLanguage
trainingarchitecturefordenseretrieval. InProceed- Processing, pages 3047â€“3060, Abu Dhabi, United
ingsofthe2021ConferenceonEmpiricalMethods ArabEmirates.AssociationforComputationalLin-
in Natural Language Processing, pages 981â€“993, guistics.
OnlineandPuntaCana,DominicanRepublic.Asso-
ciationforComputationalLinguistics. PatrickLewis,LudovicDenoyer,andSebastianRiedel.
2019. Unsupervised question answering by cloze
KelvinGuu,KentonLee,ZoraTung,PanupongPasu- translation. InProceedingsofthe57thAnnualMeet-
pat,andMing-WeiChang.2020. Realm: retrieval- ingoftheAssociationforComputationalLinguistics,
augmentedlanguagemodelpre-training. InProceed- pages 4896â€“4910, Florence, Italy. Association for
ingsofthe37thInternationalConferenceonMachine ComputationalLinguistics.
Learning,ICMLâ€™20.JMLR.org.
PatrickLewis,EthanPerez,AleksandraPiktus,Fabio
GautierIzacard,MathildeCaron,LucasHosseini,Sebas- Petroni,VladimirKarpukhin,NamanGoyal,Hein-
tianRiedel,PiotrBojanowski,ArmandJoulin,and richKÃ¼ttler, MikeLewis, Wen-tauYih, TimRock-
EdouardGrave.2022. Unsuperviseddenseinforma- tÃ¤schel, Sebastian Riedel, and Douwe Kiela. 2020.
tionretrievalwithcontrastivelearning. Transactions Retrieval-augmented generation for knowledge-
onMachineLearningResearch. intensive nlp tasks. In Advances in Neural Infor-
mationProcessingSystems,volume33,pages9459â€“
GautierIzacardandEdouardGrave.2021. Leveraging 9474.CurranAssociates,Inc.
passageretrievalwithgenerativemodelsforopendo-
mainquestionanswering. InProceedingsofthe16th Yulong Li, Martin Franz, Md Arafat Sultan, Bhavani
ConferenceoftheEuropeanChapteroftheAssoci- Iyer,Young-SukLee,andAvirupSil.2022. Learn-
ationforComputationalLinguistics: MainVolume, ing cross-lingual IR from an English retriever. In
10Proceedings of the 2022 Conference of the North YaushianWang,AshleyWu,andGrahamNeubig.2022.
AmericanChapteroftheAssociationforComputa- Englishcontrastivelearningcanlearnuniversalcross-
tionalLinguistics: HumanLanguageTechnologies, lingual sentence embeddings. In Proceedings of
pages4428â€“4436,Seattle,UnitedStates.Association the2022ConferenceonEmpiricalMethodsinNat-
forComputationalLinguistics. uralLanguageProcessing,pages9122â€“9133,Abu
Dhabi,UnitedArabEmirates.AssociationforCom-
Shayne Longpre, Yi Lu, and Joachim Daiber. 2021.
putationalLinguistics.
MKQA:Alinguisticallydiversebenchmarkformul-
tilingualopendomainquestionanswering. Transac- LeeXiong,ChenyanXiong,YeLi,Kwok-FungTang,
tionsoftheAssociationforComputationalLinguis- Jialin Liu, Paul N. Bennett, Junaid Ahmed, and
tics,9:1389â€“1406. ArnoldOverwijk.2021. Approximatenearestneigh-
bor negative contrastive learning for dense text re-
PengQi,YuhaoZhang,YuhuiZhang,JasonBolton,and
trieval. In International Conference on Learning
Christopher D. Manning. 2020. Stanza: A python
Representations.
naturallanguageprocessingtoolkitformanyhuman
languages. InProceedingsofthe58thAnnualMeet-
LintingXue,NoahConstant,AdamRoberts,MihirKale,
ingoftheAssociationforComputationalLinguistics:
RamiAl-Rfou,AdityaSiddhant,AdityaBarua,and
SystemDemonstrations,pages101â€“108,Online.As-
ColinRaffel.2021. mT5: Amassivelymultilingual
sociationforComputationalLinguistics. pre-trainedtext-to-texttransformer. InProceedings
ofthe2021ConferenceoftheNorthAmericanChap-
Houxing Ren, Linjun Shou, Ning Wu, Ming Gong,
teroftheAssociationforComputationalLinguistics:
andDaxinJiang.2022. Empoweringdual-encoder
HumanLanguageTechnologies,pages483â€“498,On-
withquerygeneratorforcross-lingualdenseretrieval.
line.AssociationforComputationalLinguistics.
In Proceedings of the 2022 Conference on Empiri-
calMethodsinNaturalLanguageProcessing,pages
XinyuZhang,XueguangMa,PengShi,andJimmyLin.
3107â€“3121,AbuDhabi,UnitedArabEmirates.As-
2021. Mr. TyDi: A multi-lingual benchmark for
sociationforComputationalLinguistics.
denseretrieval. InProceedingsofthe1stWorkshop
RuiyangRen,YingqiQu,JingLiu,WayneXinZhao, onMultilingualRepresentationLearning,pages127â€“
QiaoQiaoShe,HuaWu,HaifengWang,andJi-Rong 137,PuntaCana,DominicanRepublic.Association
Wen.2021. RocketQAv2: Ajointtrainingmethod forComputationalLinguistics.
fordense passageretrievaland passagere-ranking.
In Proceedings of the 2021 Conference on Empiri-
calMethodsinNaturalLanguageProcessing,pages
2825â€“2835,OnlineandPuntaCana,DominicanRe-
public.AssociationforComputationalLinguistics.
DevendraSinghSachan,SivaReddy,WilliamL.Hamil-
ton,ChrisDyer,andDaniYogatama.2021. End-to-
endtrainingofmulti-documentreaderandretriever
foropen-domainquestionanswering. InAdvancesin
NeuralInformationProcessingSystems.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Bhosale,DanBikel,LukasBlecher,CristianCanton
Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu,
JudeFernandes,JeremyFu,WenyinFu,BrianFuller,
CynthiaGao,VedanujGoswami,NamanGoyal,An-
thonyHartshorn,SagharHosseini,RuiHou,Hakan
Inan,MarcinKardas,ViktorKerkez,MadianKhabsa,
IsabelKloumann,ArtemKorenev,PunitSinghKoura,
Marie-AnneLachaux,ThibautLavril,JenyaLee,Di-
anaLiskovich,YinghaiLu,YuningMao,XavierMar-
tinet,TodorMihaylov,PushkarMishra,IgorMoly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein,RashiRungta,KalyanSaladi,AlanSchelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,
Melanie Kambadur, Sharan Narang, Aurelien Ro-
driguez,RobertStojnic,SergeyEdunov,andThomas
Scialom.2023. Llama2: Openfoundationandfine-
tunedchatmodels.
11A ExperimentalSettings A.1.2 QueryTransformation
We use ChatGPT to generate 32 meta-examples.
A.1 ImplementationDetails
We then employ LLaMA-2-7B9 for query trans-
A.1.1 ParallelQueriesMining formationbyrandomlysampling3meta-examples
to construct prompts for each test instance, with
Ourimplementationencompasses15distinctlan-
theformatasshowninPromptsD.1,D.2,D.3,D.4,
guages,namelyArabic,Bengali,German,Span-
D.5,D.6,andD.7. WeuseBloomz-7B10forTelugu
ish, Finnish, French, Italian, Japanese, Korean,
aswefindLLaMA-2-7Bdoesnotworkwellinthis
Russian, Telugu, Tamil, Malayalam, Kannada,
language. TheQuestionwordwh_wordischosen
Chinese. Parallelqueriesarecollectedfromparal-
lelWikipediapagesforeachen-x. Usingunsuper- based on the entity type of the answer according
totheheuristicrulesinTable7. Ultimately,146K
visedcontrastivelearning,weadopttheapproach
examplesaregeneratedperlanguage,resultingin
in Wang et al. (2022) to first pre-train a multilin-
gualmodelXLM-R7 onEnglishWikipediatextsby atotalof1Mtraininginstances.
taking the dropout as a form of data augmenta-
A.1.3 TrainingDetails
tion. Theresultingmodelisproficientingenerat-
We use mt5-large11 to initialise the model. In
ing universal cross-lingual sentence embeddings
stage-1, we train the model for 64k steps on 32
without the need for parallel data, demonstrating
A100GPUs,whichtakesaboutoneweektocom-
robustzero-shotcross-lingualtransfercapabilities.
plete. The passages for all training queries are
Subsequently,wedeploythepre-trainedmodelfor
retrieved by the English teacher at once before
extractingmultilingualsentenceembeddingsand
training. In stage-2, we further train the model
miningparallelqueriesforeachen-xlanguagepair.
for 16k steps on 16 A100 GPUs with roughly 4
Empirically,wesetthemargin-scorethresholdto
days. Weperiodicallyupdatetheretrievedpassages
1.5formostlanguages;however,forJapaneseand
foreachtraininginstanceevery1kstepsusingthe
Chinese,weobserveimprovedperformancewith
mostrecentmodel. Forfine-tuning,wefirsttrain
alargerthresholdof1.65. Thisprocessyields5.4
the model on NQ with 8k steps and fine-tune the
million examples for the training, with the num-
modelonXOR-Retrievefor6kstepsand12ksteps
berofparallelqueriesforeachlanguagepairen-x
onXOR-Full,whichtakesabout19hoursand156
showninFigure5.
hourstocomplete,respectively. Likewise,wealso
We employ a balanced sampling strategy to
dopassagerefreshingperiodicallyevery1ksteps.
avoidthetrainingbiastowardshigh-resourcelan-
For all training stages, we use the same batch
guages. For N number of languages {D }N
i i=1 size of 64 queries with each paired with 100 re-
withprobabilities,{p }N ,wedefinethefollowing
i i=1 trieved passages and learning rate 5Ã—10âˆ’5. We
multinomialdistributiontosamplefrom:
setÎ±to8inalltraininglossfunctions. Wesetthe
fÎ± n maximumqueryandpassagelengthsto50and200
p i = (cid:80)Ni fÎ±,wheref i = (cid:80)N i
n
, forbothtrainingandevaluation.
j=1 j j=1 j
A.2 Datasets
where Î± is the sampling factor, which is set to
Weusedthefollowingdatasetsformodelevalua-
0.5byfollowingCONNEAUandLample(2019)
tioninourexperiments:
and n is the total number of parallel queries in
i â€¢ XOR-Retrieve. This dataset is under the
thei-thlanguage. Duringtraining,weusethisto
MIT License for non-commercial research
determinenâ€²,thenumberofparallelqueriesineach
i purposes. Itcontains15250QApairsfortrain-
language;andtop-nâ€² queriesareusedfortraining
i ingandtakesthe20190201EnglishWikipedia
according to the margin-based scores. For every
dumpwhichcontains18Mpassagesasthere-
pairofminedquery,weemployastate-of-the-art
trievaldatabase.
NamedEntityTaggerfromStanza(Qietal.,2020)8
â€¢ XOR-Full. It is under the MIT License for
tofindsaliententitieswithintheEnglishqueryand
non-commercial research purposes. It con-
takeallidentifiedentitiesasanswercandidatesto
tains61360QApairsfortrainingandacollec-
constructcloze-stylequeries.
9https://huggingface.co/meta-llama/Llama-2-7b
7https://huggingface.co/xlm-roberta-large 10https://huggingface.co/bigscience/bloomz-7b1
8https://github.com/stanfordnlp/stanza 11https://huggingface.co/google/mt5-large
121e6
Original
1.4 Resample
1.2
1.0
0.8
0.6
0.4
0.2
0.0
ar bn de es fi fr it ja ko ru te ta ml kn zh
Languages
Figure5: Thenumberofminedparallelqueriesforeachlanguagepairen-x.
tionof43Mpassagesastheretrievaldatabase, 111,744,1254,829,720,421,995,670,646,
whichiscollectedfrom20190201Wikipedia and1190ineachlanguage,respectively. The
dumpsacross13languages,namelyEnglish, corpussizesforretrievalare2M,300K,33M,
Arabic, Finnish, Japanese, Korean, Russian, 1.9M, 1.5M, 7M, 1.5M, 9.6M, 137K, 548K,
Bengali, Telugu, Indonesian, Thai, Hebrew, and569Kineachlanguage,respectively.
Swedish,andSpanish.
â€¢ Natural Questions. It is under the Apache A.3 Baselines
Licenseandcontains79168QApairs. A.3.1 Cross-lingualPassageRetrieval
â€¢ MKQA. It is under the Apache License.
Wecompareourproposedmodelwitharangeof
This dataset covers 26 linguistically diverse
strongbaselines:
languages,namelyArabic,Danish,German,
â€¢ mDPR. This is the multilingual version of
English, Spanish, Finnish, French, Hebrew,
Dense Passage Retrieval (DPR) (Karpukhin
Hungarian,Italian,Japanese,Korean,Khmer,
etal.,2020)encoder,whichundergoesinitial
Malay,Dutch,Norwegian,Polish,Portuguese,
training on English NQ queries followed by
Russian,Swedish,Thai,Turkish,Vietnamese,
fine-tuningonXOR-Retrieve.
Chinese(Simplified),Chinese(HongKong),
â€¢ DPR+MT. This is a translate-test baseline
and Chinese (Traditional). For the cross-
that involves the translation of queries into
lingualretrievaltask,eachlanguagecontains
Englishduringtesttime,followedbymonolin-
6620questionsandtheretrievaldatabasecon-
gualpassageretrievalusingtheEnglishDPR
sistsof18MEnglishWikipediapassages. For
encoder.
themultilingualQAtask,eachlanguagecon-
â€¢ CORA. This method trains a multilingual
tains6758questionsanditusesthesamere-
DPR encoder iteratively, with positive and
trievaldatabaseasXOR-Full.
negativepassagesidentifiedbyamultilingual
â€¢ Mr.TyDi. It is under the Apache License.
QAmodel.
This dataset contains 11 languages, namely
â€¢ Sentri. Aniterativeself-trainingmethodthat
Arabic,Bengali,English,Finnish,Indonesian,
uses the latest retriever to identify positive
Japanese, Korean, Russian, Swahili, Telugu,
andnegativepassagesthroughanswerstring
and Thai. The queries for testing are 1081,
matchingforupdatingthetrainingdataset. It
13
seireuQ
lellaraP
fo
rebmuNalso employs data augmentation techniques â€¢ MT+Mono. This is a combination of the
bytranslatingEnglishdatasets. BM25 and MT+DPR baselines, which first
â€¢ QuiCK. A knowledge distillation method doesmonolingualQAforthetargetlanguage
thattrainsamultilingualbi-encoderretriever, using the BM25 method and resorts to the
learningfromaquerygeneratorastheteacher. MT+DPRbaselineifnoanswerisfound.
Thequerygeneratorisalsousedforgenerat- â€¢ Fusion-in-Decoder. Thisencompassesafam-
ingsyntheticmultilingualqueriestoenhance ily of multilingual retrieval-augmented gen-
theknowledgedistillationprocess. eration models, which take the passages re-
â€¢ DrDecr. AmultilingualColBERTmodelthat turned by a multilingual retriever as inputs
learnsfromanEnglishColBERTonparallel togeneratetheanswerinthetargetlanguage.
queries, sourced from both parallel corpora CORA,SentriandLAPCAareincludedin
and human-translated gold queries released thisfamilybyusingthepassagesreturnedby
byXOR-Retrieve. theirrespectiveretrievers.
â€¢ LAPCA. Apre-trainingmethodthattakesthe
first paragraphs of parallel Wikipedia pages B DetailedZero-shotEvaluation
as the parallel corpus for cross-lingual pre-
Cross-lingual Retrieval Table 4 presents the
training. Additionally,machinetranslationis
detailed result comparisons in each of the 20
employedfordataexpansion.
unseen languages covered by MKQA. Notably,
CLASS-ZSoutperformsotherbaselinessignificantly
A.3.2 MultilingualOpenDomainQuestion
onaverageandachievesthebestresultsinnearly
Answering
all languages except for Vietnamese. Compar-
â€¢ mDPR. Thismodelusesamultilingualreader
ing the three variants of our method, fine-tuning
toidentifytheanswerspanfromthepassages
onsupervisedEnglishdatasignificantlyenhances
retrievedbythemDPRretrieverasdescribed
cross-lingualtransferabilitiestoeveryunseenlan-
above.
guage (i.e., CLASS-US vs CLASS-ZS). However,
â€¢ MT+DPR. Thisrepresentsthetranslate-test
fine-tuningCLASS-ZSonalimitednumberofsuper-
baseline,inwhichqueriesaretranslatedinto
visedmultilingualdatawitharestrictedlanguage
Englishandtheanswersareidentifiedwithin
set does not lead to improved generalization per-
English passages retrieved by the DPR+MT
formance, as indicated by the result comparison
retriever. The English answer is then trans-
in every language between CLASS-ZS and CLASS.
latedbacktothetargetlanguageifnecessary.
Furthermore,adecreaseinperformanceisalsoob-
â€¢ ReAtt+MT. ThisistheEnglishteacherem-
served in both supervised and zero-shot settings
ployedinourstage-1pre-training. Weusea
wheneitherstage-2pre-trainingortheentirepre-
state-of-the-art machine translation model12
training procedures are omitted, highlighting the
to translate the queries into English at test
effectiveness of our pre-training approach in en-
time. It always retrieves passages from En-
hancingcross-lingualability.
glishWikipediaandgeneratesanswersinEn-
glish. Thegeneratedansweristranslatedback Multilingual QA Table 5 presents the detailed
tothetargetlanguageifnecessary. multilingualQAresultsforeachofthe20unseen
â€¢ GMT+GS. This pipeline follows the same languages covered by MKQA. We observe simi-
procedure as MT+DPR except that we em- larpatternswhereCLASS-USsurpassesarangeof
ploy Google Search for passage retrieval machine-translation-basedmethodsandCLASS-ZS
andGoogleMachineTranslationservicesfor outperformsthesupervisedCORAwithasignifi-
queryandanswertranslation. cant margin. Further fine-tuning CLASS-ZS on a
â€¢ Monolingual baseline (BM25). Instead of limited number of supervised multilingual data
usingamultilingualDPRoranEnglishDPR with a restricted language set hampers its gener-
model with query translation, this baseline alizability,withadeclineinperformanceacrossall
always retrieves the passage from the target examinedlanguages.
languageandextractstheanswerusingamul-
tilingualreader. MonolingualRetrieval Weevaluatethemodel
on the monolingual retrieval setting, with the re-
12https://huggingface.co/facebook/m2m100_418M sultsontheMr. TyDidataset(Zhangetal.,2021)
1460
42
50 40
38
40
w/ CS 36 CLASS
w/ MT
CORA
CLASS
30 34
0 20 40 60 80 100 5 15 25 50 100
Billion of Tokens Number of Passages
Figure6:Performanceevolutioninstage-1pre-training. Figure 8: Effects of employing different numbers of
retrievedpassagesforQAduringinferencetime.
70
morelabelleddatabecomesavailable. Notably,as
60 illustrated in Figure 7, the introduction of stage-
2 pre-training results in a 75% reduction in the
50
required amount of labelled data. Furthermore,
40 CLASS employing pre-training of both stages eliminates
CLASS w/o stage-2
CLASS w/o pre-train the need for any labelled data, in contrast to the
30
1% 5% 25% 50% 75% 100% approachthatsolelyreliesonsuperviseddatafor
Figure7:Scalingtrainingdataoncross-lingualretrieval. training(i.e.,CLASSw/opre-train).
EffectsofNumberofRetrievedPassages Fig-
reported in Table 6. We compare CLASS-ZS with
ure8reportstheperformanceconcerningthenum-
a series of zero-shot multilingual retrievers that
ber of retrieved passages for QA during infer-
havebeenfine-tunedonEnglishdatasets. Notably,
ence. Weobservetheperformanceimprovescon-
eventhoughCLASS-ZShavenotundergoneexplicit
sistently as the number of retrieved passages in-
training for monolingual retrieval, it consistently
creases. CLASS significantly outperforms CORA
outperformstheothermodelsineverylanguageex-
whenusingonlytop-5retrievedpassages,showcas-
amined,withtheperformancegainsbeingparticu-
ingsuperiorinferenceefficiency.
larlypronouncedinlanguageswritteninNon-Latin
scripts(e.g.,Japanese,Korean,andThai).
D QueryTransformationExamples
C MoreAnalysis Table9showcasesexamplesillustratingthegener-
ation of meta-examples through prompting Chat-
Performance Evolution during Pre-training
GPT. Prompts D.1, D.2, D.3, D.4, D.5, D.6, and
Figure 6 illustrates the trajectory of the perfor-
D.7 provide detailed illustrations of prompting a
manceontheXOR-Retrievecross-lingualretrieval
muchsmallerlargelanguagemodel,LLaMA-2-7B,
task. As shown in the Figure, the use of code-
toperformquerytransformationusingIn-Context
switchingconsistentlyyieldsinferiorresultscom-
Learning,whichincorporatesmeta-examplesinto
paredtoCLASSandthevariantusingmachinetrans-
the prompt to guide the modelâ€™s behaviour. The
lation. Aftertrainingonaround45billiontokens,
choice of the question word is determined based
CLASSconsistentlyoutperformsMT,matchingthe
on the detected entity type of the answer and the
performance of CS and MT with only 30% and
heuristicrulesoutlinedinTable7.
50%computationcosts. Thisdemonstratesgreater
trainingefficiency. Theperformancecontinuesto
improveoverthenext50%ofthetrainingtokens,
implying that the scalability of pre-training data
remainsbeneficialastrainingprogresses.
Few-ShotCross-lingualRetrieval Weconsider
afew-shotlearningtaskwithvaryingnumbersof
labelled training examples. Figure 7 shows that
CLASSisconsistentlybetterthantheothertwovari-
ants,althoughtheperformancegapdiminishesas
15
tk2@R
tk2@R
1FMethod Da De Es Fr He Hu It Km Ms Nl No Pl Pt Sv Th Tr Vi cn hk tw Avg
Unsupervised
CLASS-US 50.5 53.4 53.8 53.9 44.1 49.1 52.6 39.8 55.3 53.3 49.5 52.6 50.4 52.5 54.9 50.9 48.0 48.0 46.3 46.4 50.3
Zero-shot
BM25+MT 44.1 43.3 44.9 42.5 36.9 39.3 40.1 31.3 42.5 46.5 43.3 46.5 45.7 49.7 46.5 42.5 43.5 37.5 37.5 36.1 42.0
CLASS-ZS 59.3 58.9 59.4 59.2 50.1 54.0 58.7 46.2 59.6 60.4 58.5 57.5 58.0 59.4 58.0 55.1 54.1 52.1 51.5 51.4 56.1
-Stage-2 58.0 57.6 57.7 58.0 47.3 51.8 57.2 44.4 58.0 59.3 57.1 56.1 56.2 57.7 56.4 53.6 52.3 50.6 49.8 49.1 54.4
-Pre-train 50.9 50.5 49.9 50.0 32.5 41.9 49.6 32.9 49.9 52.3 50.2 46.6 49.3 51.5 44.2 44.7 41.3 37.8 37.7 37.1 45.0
Supervised
CORA 44.5 44.6 45.3 44.8 27.3 39.1 44.2 22.2 44.3 47.3 48.3 44.8 40.8 43.6 45.0 34.8 33.9 33.5 41.5 41.0 41.1
Sentri 57.6 56.5 55.9 55.1 47.9 51.8 54.3 43.9 56.0 56.3 56.5 55.8 54.8 56.9 55.3 53.0 54.4 50.2 50.7 49.4 53.3
QuiCK 58.3 56.4 55.2 55.5 44.7 52.4 52.3 42.0 56.9 57.5 57.0 54.9 54.7 58.0 55.7 53.9 54.9 50.4 49.3 48.9 53.4
CLASS 57.4 57.5 58.0 57.8 48.5 52.5 57.1 43.4 58.2 58.4 56.7 56.0 56.4 57.6 57.2 54.2 52.5 51.3 49.9 50.2 54.6
-Stage-2 56.9 57.3 57.2 57.0 47.3 51.8 56.2 42.9 57.6 58.7 56.0 55.3 55.5 56.8 56.1 53.3 51.5 51.4 49.9 49.4 53.9
-Pre-train 56.5 55.3 55.9 55.1 44.8 50.8 55.0 41.3 56.4 57.4 55.8 53.3 54.8 56.5 53.7 51.9 49.6 47.3 46.4 45.8 52.2
Table4:Zero-shotcross-lingualretrievalresults(R@2kt)ontheMKQAdataset."cn":"Zh-cn"(Chinese,simplified).
"hk": "Zh-hk"(Chinese,HongKong). "tw": "Zh-tw"(Chinese,traditional).
Method Da De Es Fr He Hu It Km Ms Nl No Pl Pt Sv Th Tr Vi cn hk tw Avg
Unsupervised
CLASS-US 24.9 27.4 29.1 27.1 12.9 21.7 25.2 9.3 26.3 27.0 25.0 23.7 22.4 26.0 13.2 22.8 17.5 7.3 8.9 6.3 20.2
Zero-shot
ReAtt+MT 22.4 23.9 21.6 23.5 24.2 6.3 13.7 3.2 12.7 22.1 21.5 11.2 18.6 17.3 7.2 6.3 24.0 10.8 4.7 4.0 15.0
MT+DPR 26.2 25.9 28.4 21.9 8.9 15.7 25.1 1.2 12.6 28.3 18.3 24.6 24.7 19.7 6.9 18.2 15.1 3.3 3.8 3.8 16.5
CLASS-ZS 37.6 38.5 40.2 37.6 17.0 29.1 36.2 16.2 36.9 38.6 37.4 34.4 33.6 38.6 18.9 30.9 29.6 8.7 13.8 8.5 29.1
Supervised
MT+Mono 19.3 21.6 21.3 21.9 8.9 16.5 20.9 1.2 12.6 21.5 17.4 24.6 19.9 20.0 8.3 16.6 15.1 4.9 3.8 5.1 14.8
CORA 30.4 30.2 32.0 30.8 15.8 18.4 29.0 5.8 27.8 32.1 29.2 25.6 28.4 30.9 8.5 22.2 20.9 5.2 6.7 5.4 21.8
CLASS 33.4 35.4 37.5 35.7 12.3 27.7 35.3 10.2 34.6 36.1 34.3 31.9 32.8 33.3 17.6 29.3 25.1 8.6 10.2 7.4 26.4
Table5: Zero-shotmultilingualquestionansweringresults(F1)ontheMKQAdataset. "cn": "Zh-cn"(Chinese,
simplified). "hk": "Zh-hk"(Chinese,HongKong). "tw": "Zh-tw"(Chinese,traditional).
Method Ar Bn Fi Id Ja Ko Ru Sw Te Th Avg
mDPR 62.0 67.1 37.5 46.6 53.5 49.0 49.8 26.4 35.2 45.5 47.3
LAPCA 89.4 95.0 83.6 90.6 78.1 76.0 80.2 74.4 93.0 92.8 85.3
mContriever 88.7 91.4 88.1 89.8 81.7 78.2 83.8 91.4 96.6 90.5 88.0
CLASS-ZS 93.8 96.4 92.6 94.8 91.3 86.8 92.5 93.1 98.8 97.1 93.7
Table6: Zero-shotmonolingualretrievalwithresults(R@100)onthetestsetofMr. TyDidataset.
HighLevelAnswerCategory NamedEntityTypes Mostappropriatewh_word
PERSON/NORP/ORG PERSON,NORP,ORG Who
PLACE GPE,LOC,FAC Where
THING PRODUCT,EVENT,WORKOFART,LAW,LANGUAGE What
TEMPORAL TIME,DATE When
NUMERIC PERCENT,MONEY,QUANTITY,ORDINAL,CARDINAL Howmuch/Howmany
Table7: Theheuristicsrulesforchoosingthemostappropriatequestionwordbasedonnamedentitytypes(taken
fromLewisetal.(2019)).
16FinnishPrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence"StrappingYoungLad(lyh.SYL)oliDevinTownsendinvuonna1994perustamakanadalainenmetal-
liyhtye."intoanaturalquestionwhosequestionwordis"Milloin"andansweris"1994".Pleaserespondintheformat:"The
transformedquestionis: MilloinDevinTownsendperustikanadalaisenmetalliyhtyeenStrappingYoungLad(lyh.SYL)?"
RussianPrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence" Ğ’215Ğ³Ğ¾Ğ´ÑƒĞ¦Ğ°Ğ¾Ğ¦Ğ°Ğ¾Ğ°Ñ‚Ğ°ĞºĞ¾Ğ²Ğ°Ğ»Ğ§Ğ¶Ğ°Ğ½Ğ›ÑƒĞ¸Ñ€Ğ°Ğ·Ğ³Ñ€Ğ¾Ğ¼Ğ¸Ğ»ĞµĞ³Ğ¾Ğ²Ğ±Ğ¸Ñ‚Ğ²ĞµĞ²Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ĞµĞ¯Ğ½Ğ¿Ğ¸Ğ½Ğ³ÑƒĞ°Ğ½ÑŒ.
"intoanaturalquestionwhosequestionwordis" ĞšÑ‚Ğ¾"andansweris" Ğ§Ğ¶Ğ°Ğ½Ğ›Ñƒ".Pleaserespondintheformat:"Thetrans-
formedquestionis: ĞšÑ‚Ğ¾ Ğ±Ñ‹Ğ» Ğ°Ñ‚Ğ°ĞºĞ¾Ğ²Ğ°Ğ½ Ğ¦Ğ°Ğ¾ Ğ¦Ğ°Ğ¾ Ğ¸ Ñ€Ğ°Ğ·Ğ³Ñ€Ğ¾Ğ¼Ğ»ĞµĞ½ Ğ² Ğ±Ğ¸Ñ‚Ğ²Ğµ Ğ² Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğµ Ğ¯Ğ½Ğ¿Ğ¸Ğ½Ğ³ÑƒĞ°Ğ½ÑŒ Ğ² 215 Ğ³Ğ¾Ğ´Ñƒ? "
JapanesePrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence"ç†Šé‡é‚£æ™ºç¥ç¤¾ï¼ˆãã¾ã®ãªã¡ã˜ã‚“ã˜ã‚ƒï¼‰ã¯ã€å®®åŸçœŒåå–å¸‚ã«ã‚ã‚‹ç¥ç¤¾ã§ã‚ã‚‹ã€‚"intoanatural
questionwhosequestionwordis"ã©ã“"andansweris"å®®åŸçœŒ".Pleaserespondintheformat:"Thetransformedquestionis:
ç†Šé‡é‚£æ™ºç¥ç¤¾ã¯ã©ã“ã«ã‚ã‚‹ç¥ç¤¾ã§ã™ã‹ï¼Ÿ"
KoreanPrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence"19á„‰á…¦á„€á…µá„’á…®á„‡á…¡á†«á„‹á…¦á„‹á…¡á„‹á…µá†¯á„…á…¢á†«á„ƒá…³á„‹á…¦á„‚á…³á†«á„ƒá…©á†¨á„…á…µá†¸á„€á…ªá„á…©á„Œá…µá„€á…¢á„’á…§á†¨á„‹á…³á†¯á„‹á…­á„€á…®á„’á…¡á„‚á…³á†«á„‹á…®á†«á„ƒá…©á†¼á„‹á…µá„á…³á„€á…¦á„’á…ªá†¨á„‰á…¡á†«á„ƒá…¬á„‹á…¥á†»á„ƒá…¡."intoa
naturalquestionwhosequestionwordis"á„‹á…¥á„ƒá…µ"andansweris"á„‹á…¡á„‹á…µá†¯á„…á…¢á†«á„ƒá…³".Pleaserespondintheformat:"Thetransformed
questionis: 19á„‰á…¦á„€á…µá„’á…®á„‡á…¡á†«á„‹á…¦á„ƒá…©á†¨á„…á…µá†¸á„€á…ªá„á…©á„Œá…µá„€á…¢á„’á…§á†¨á„‹á…³á†¯á„‹á…­á„€á…®á„’á…¡á„‚á…³á†«á„‹á…®á†«á„ƒá…©á†¼á„‹á…µá…³á„á„€á…¦á„’á…ªá†¨á„‰á…¡á†«á„ƒá…¬á†«á„‚á…¡á„…á…¡á„‚á…³á†«á„‹á…¥á„ƒá…µá„‹á…µá†¸á„‚á…µá„á…¡?"
ArabicPrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence" â„(cid:152)k(cid:159) (cid:143)Â¤ (cid:155)(cid:20)A(cid:154) (cid:0)(cid:152)tâ€˜ly(cid:156) (cid:0)(cid:152)â€˜A(cid:152)Â¤ (cid:11)ftqr (cid:0)(cid:152)mslmy(cid:159), â„(cid:158)\r(cid:0) â€“(cid:143)r(cid:0) (cid:1)FrÂ¡(cid:156) â„(cid:1)(cid:146)AC(cid:7)h(cid:156) (cid:1)(cid:27)@Â¡A (cid:136)(cid:159)
â„ZAÂ¶(cid:144)(cid:143)Â¤ â„(cid:154)(cid:0)(cid:152)(cid:28)ly(cid:21)â„(cid:19)nw(cid:10)Jr(cid:148)(cid:5)FyA)(cid:1)FAFAâ„Fn(cid:140)A(cid:143)wCâ€º,â„(cid:1)(cid:152)mA(cid:158)yA(cid:155)A(cid:152)yzÂ§Aâ„(cid:7)râ„(cid:158)A'(cid:143)Â¤(cid:19)nw(cid:10)(cid:5)FyA((cid:158)fshA(cid:143)Â¤
F(cid:159)(cid:155)bkrâ€º."intoanaturalquestionwhosequestionwordis" (cid:1)Â§(cid:159)"andansweris" (cid:19)nw(cid:10)Jr(cid:148)(cid:5)FyA".Pleaserespondin
theformat:"Thetransformedquestionis:
(cid:1)Â§(cid:159)Â§(cid:2)(cid:27)@(cid:1)(cid:143)r(cid:0) (cid:1)Fr(cid:0)(cid:152)mslmy(cid:159)â„(cid:1)(cid:146)AC(cid:7)h(cid:156)â„ZAÂ¶(cid:144)(cid:139)A(cid:152)bA(cid:190)A,(cid:155)mAÂ§Â¥ '(cid:3)(cid:152)Y(cid:143)qd(cid:0)(cid:160)(cid:0)flÂ¡tmA(cid:157)(cid:7)A(cid:152)tâ€˜ly(cid:156)(cid:0)(cid:152)â€˜A(cid:152)Â¤? "
BengaliPrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence"varte Hajar Hajar manuP AnaHaer mara JaJ, ik(cid:218)u zflm(cid:23)carkra taedr (cid:23)it Udas(cid:140)n."intoanatural
questionwhosequestionwordis"ekaQaJ"andansweris"vart".Pleaserespondintheformat:"Thetransformedquestionis:
ekaQaJ Hajar Hajar manuP AnaHaer mara JaJ EbK zflm(cid:23)carkra taedr (cid:23)it Udas(cid:140)n Qaek?"
TeluguPrompt
You are an AI model that rewrites sentences into questions, using a given question word and answer.
Rewrite this sentence "
!à°Ÿ#à°²%à°ª(â€™ à°¿*,+-à±†à°‚*+à°¨123à°¾à°¸6à°•à°¨89à°¾à°ªà°°;<à°¶>?@*à±‡6à°†à°²à°¯à°‚à°†à°‚à°§â€™à°ª*â€™ à±‡E?à°¾à°·Gà°‚H à°²%à°ªIJà°®LM*Nà°µ?PQà°²SRà°²%
." into a natural question whose question word is " " and answer is " ". Please
TUà°¨à±LWà°‚à°¡à°…Z[à°ªà°ŸGà°£à°‚à°²%à°‰à°‚*+ à°à°µà°°_ TUà°¨à±LWà°‚à°¡
respond in the format: "The transformed question is:
à°†à°‚à°§â€™à°ª*â€™ à±‡E?à°¾à°·Gà°‚H à°ªIJà°®LM*Nà°µ?PQà°²SRà°²%â€˜à°ª(â€™ à°¿*,+-à±†à°‚*+à°¨123à°¾à°¸6à°•à°¨89à°¾
? "
à°ªà°°;<à°¶>?@*à±‡6à°†à°²à°¯à°‚à°‰à°¨aà°ªà°ŸGà°£à°‚à°à°µà°°_
Figure9: Meta-examplesobtainedbypromptingChatGPTareshownforeachlanguagecoverdbyXOR-TYDIQA.
Lightbluetexts indicatethetransformedquestions.
17PromptD.1: FinnishExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: ToisaaltahÃ¤nolitaiteidensuosijajahÃ¤nenvaltakaudellaanPreussisaihaltuunsasuurenosanPuola-Liettuasta
Puolanjaoissavuosina1793ja1795.
Questionword:MissÃ¤
Answer:Preussi
TransformedQuestion: MissÃ¤maassataiteidensuosijahallitsijamissÃ¤valtakunnassasaatiinhaltuunsasuuriosaPuola-
LiettuastaPuolanjaoissavuosina1793ja1795?
Sentence:HÃ¤npelasiurallaanmyÃ¶sRuotsissajaSlovakiassa.
Questionword:MissÃ¤
Answer:Slovakia
TransformedQuestion:MissÃ¤maassahÃ¤npelasiurallaanRuotsinlisÃ¤ksi?
Sentence:BarokinjÃ¤lkeenconcertogrossojaovatsÃ¤veltÃ¤neetmuunmuassaHeitorVilla-Lobos,BohuslavMartinuËš,Alfred
SchnittkejaPhilipGlass.
Questionword:Kuka
Answer:BohuslavMartinuËš
TransformedQuestion: KukasÃ¤veltÃ¤jistÃ¤HeitorVilla-Lobosin,AlfredSchnittkenjaPhilipGlassinohellaonsÃ¤veltÃ¤nyt
concertogrossojabarokinjÃ¤lkeen?
Sentence:HÃ¤nenajatteluunsavaikuttivatmuunmuassabuddhalaisetjataolaisetideat,joihinhÃ¤ntutustuiAasianmatkoillaan,
MahatmaGandhinvÃ¤kivallattomuusliike,sekÃ¤hÃ¤nenkatolinenuskontonsa.
Questionword:Kuka
Answer:MahatmaGandhi
TransformedQuestion: KukavaikuttihÃ¤nenajatteluunsa,mahtimaailmaanjakatoliseenuskontonsa?
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: On the other hand, he/she was a fan of the arts and during his/her reign, Prussia took over a large part of
Poland-LithuaniainthepartitionsofPolandin1793and1795.
Questionword:Where
Answer:Prussia
TransformedQuestion: InwhichcountrydidtheloveroftheartsruleandinwhichkingdomwasalargepartofPoland-
LithuaniatakenoverduringthepartitionsofPolandin1793and1795?
Sentence:He/ShealsoplayedinSwedenandSlovakiaduringhercareer.
Questionword:Where
Answer:Slovakia
TransformedQuestion:Inwhichcountrydidhe/sheplayinhis/hercareerbesidesSweden?
Sentence:AftertheBaroque,concertogrossoshavebeencomposedby,amongothers,HeitorVilla-Lobos,BohuslavMartinuËš,
AlfredSchnittkeandPhilipGlass.
Questionword:Kuka
Answer:BohuslavMartinuËš
TransformedQuestion:BesidesHeitorVilla-Lobos,AlfredSchnittkeandPhilipGlass,whichofthecomposershascomposed
concertogrossosaftertheBaroque?
Sentence: His/Herthinkingwasinfluenced,amongotherthings,byBuddhistandTaoistideas,whichhe/shegottoknow
duringhis/hertravelsinAsia,MahatmaGandhiâ€™snon-violencemovement,andhis/herCatholicreligion.
Questionword:Who
Answer:MahatmaGandhi
TransformedQuestion: Whoinfluencedhis/herthinking,theworldofpowerandhis/herCatholicreligion?
18PromptD.2: RussianExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: ĞšĞ¾Ñ€Ğ°Ğ±Ğ»Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞ»Ğ¸ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ğ·Ğ° ÑƒÑ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ’ĞœĞ¡ ÑÑ‚Ñ€Ğ°Ğ½ ĞĞĞ¢Ğ Ğ² ĞĞ¾Ñ€Ğ²ĞµĞ¶ÑĞºĞ¾Ğ¼ Ğ¸ Ğ¡Ñ€Ğµ-
Ğ´Ğ¸Ğ·ĞµĞ¼Ğ½Ğ¾Ğ¼ Ğ¼Ğ¾Ñ€ÑÑ…, ÑĞ»ĞµĞ´Ğ¸Ğ»Ğ¸ Ğ·Ğ° ĞºĞ¾Ñ€Ğ°Ğ±ĞµĞ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¸ Ğ°Ğ²Ğ¸Ğ°Ğ½Ğ¾ÑĞ½Ñ‹Ğ¼Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ğ¼Ğ¸ Ñ„Ğ»Ğ¾Ñ‚Ğ¾Ğ² Ğ¡Ğ¨Ğ Ğ¸ Ğ’ĞµĞ»Ğ¸ĞºĞ¾Ğ±Ñ€Ğ¸Ñ‚Ğ°Ğ½Ğ¸Ğ¸.
Questionword: ĞšÑ‚Ğ¾
Answer: ĞĞĞ¢Ğ
TransformedQuestion: ĞšÑ‚Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞ» ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ğ·Ğ° ÑƒÑ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ’ĞœĞ¡ Ğ² ĞĞ¾Ñ€Ğ²ĞµĞ¶ÑĞºĞ¾Ğ¼ Ğ¸ Ğ¡Ñ€ĞµĞ´Ğ¸Ğ·ĞµĞ¼Ğ½Ğ¾Ğ¼ Ğ¼Ğ¾Ñ€ÑÑ… Ğ¸
ÑĞ»ĞµĞ´Ğ¸Ğ» Ğ·Ğ° ĞºĞ¾Ñ€Ğ°Ğ±ĞµĞ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¸ Ğ°Ğ²Ğ¸Ğ°Ğ½Ğ¾ÑĞ½Ñ‹Ğ¼Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ğ¼Ğ¸ Ñ„Ğ»Ğ¾Ñ‚Ğ¾Ğ² Ğ¡Ğ¨Ğ Ğ¸ Ğ’ĞµĞ»Ğ¸ĞºĞ¾Ğ±Ñ€Ğ¸Ñ‚Ğ°Ğ½Ğ¸Ğ¸?
Sentence: 1Ğ°Ğ¿Ñ€ĞµĞ»Ñ1768Ğ³Ğ¾Ğ´Ğ°Ğ”Ğ¾Ğ²ĞµÑ€Ğ½ÑĞ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ°ÑÑ‚Ğ¿ĞµĞ½ÑĞ¸ÑĞšĞ¾Ñ€Ğ¾Ğ»ĞµĞ²ÑĞºĞ¾Ğ¹Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ğ¸Ğ¼ÑƒĞ·Ñ‹ĞºĞ¸Ğ²Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğµ1000
Ğ»Ğ¸Ğ²Ñ€Ğ¾Ğ² ĞºĞ°Ğº Ğ°Ğ²Ñ‚Ğ¾Ñ€Ñƒ Ğ¼ÑƒĞ·Ñ‹ĞºĞ¸.
Questionword: ĞšÑ‚Ğ¾
Answer: ĞšĞ¾Ñ€Ğ¾Ğ»ĞµĞ²ÑĞºĞ¾Ğ¹ Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ğ¸ Ğ¼ÑƒĞ·Ñ‹ĞºĞ¸
TransformedQuestion: ĞšÑ‚Ğ¾1Ğ°Ğ¿Ñ€ĞµĞ»Ñ1768Ğ³Ğ¾Ğ´Ğ°Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ»Ğ¿ĞµĞ½ÑĞ¸ÑĞ²Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğµ1000Ğ»Ğ¸Ğ²Ñ€Ğ¾Ğ²Ğ”Ğ¾Ğ²ĞµÑ€Ğ½ÑĞºĞ°ĞºĞ°Ğ²Ñ‚Ğ¾Ñ€Ñƒ
Ğ¼ÑƒĞ·Ñ‹ĞºĞ¸?
Sentence: Ğ¡Ğ¾Ñ„Ğ¸Â´Ñ Ğ¨Ğ°Ñ€Ğ»Ğ¾Â´Ñ‚Ñ‚Ğ° ĞĞ²Ğ³ÑƒÂ´ÑÑ‚Ğ° (22 Ñ„ĞµĞ²Ñ€Ğ°Ğ»Ñ 1847, ĞœÑĞ½Ñ…ĞµĞ½ â€” 4 Ğ¼Ğ°Ñ 1897, ĞŸĞ°Ñ€Ğ¸Ğ¶) â€” Ğ¿Ñ€Ğ¸Ğ½Ñ†ĞµÑÑĞ°
Ğ‘Ğ°Ğ²Ğ°Ñ€ÑĞºĞ°Ñ, Ğ³ĞµÑ€Ñ†Ğ¾Ğ³Ğ¸Ğ½Ñ Ğ‘Ğ°Ğ²Ğ°Ñ€ÑĞºĞ°Ñ, Ğ¿Ğ¾Ğ·Ğ´Ğ½ĞµĞµ Ğ³ĞµÑ€Ñ†Ğ¾Ğ³Ğ¸Ğ½Ñ ĞĞ»Ğ°Ğ½ÑĞ¾Ğ½ÑĞºĞ°Ñ Ğ¸ ĞÑ€Ğ»ĞµĞ°Ğ½ÑĞºĞ°Ñ.
Questionword: Ğ“Ğ´Ğµ
Answer: ĞœÑĞ½Ñ…ĞµĞ½
TransformedQuestion: Ğ“Ğ´Ğµ Ñ€Ğ¾Ğ´Ğ¸Ğ»Ğ°ÑÑŒ Ğ¡Ğ¾Ñ„Ğ¸Ñ Ğ¨Ğ°Ñ€Ğ»Ğ¾Ñ‚Ñ‚Ğ° ĞĞ²Ğ³ÑƒÑÑ‚Ğ°, Ğ¿Ñ€Ğ¸Ğ½Ñ†ĞµÑÑĞ° Ğ‘Ğ°Ğ²Ğ°Ñ€ÑĞºĞ°Ñ?
Sentence: Ğ’ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¹ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğµ XIX Ğ²ĞµĞºĞ° Ğ¿Ğ°Ñ€Ğ¾Ğ²Ğ¾Ğ·Ñ‹ Ğ² Ğ Ğ¾ÑÑĞ¸Ñ, Ğ² Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¼, Ğ²Ğ²Ğ¾Ğ·Ğ¸Ğ»Ğ¸ÑÑŒ Ğ¸Ğ·-Ğ·Ğ° Ñ€ÑƒĞ±ĞµĞ¶Ğ°.
Questionword: ĞšĞ¾Ğ³Ğ´Ğ°
Answer: XIX Ğ²ĞµĞº
TransformedQuestion: ĞšĞ¾Ğ³Ğ´Ğ° Ğ¿Ğ°Ñ€Ğ¾Ğ²Ğ¾Ğ·Ñ‹ Ğ² Ğ Ğ¾ÑÑĞ¸Ñ, Ğ² Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¼, Ğ²Ğ²Ğ¾Ğ·Ğ¸Ğ»Ğ¸ÑÑŒ Ğ¸Ğ·-Ğ·Ğ° Ñ€ÑƒĞ±ĞµĞ¶Ğ°?
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:Theprojectâ€™sshipsmonitoredNATOnavalexercisesintheNorwegianandMediterraneanSeasandmonitoredship
andaircraftcarriergroupsoftheUSandBritishnavies.
Questionword:Who
Answer:NATO
TransformedQuestion:WhomonitorednavalexercisesintheNorwegianandMediterraneanseasandmonitoredshipand
aircraftcarriergroupsoftheUSandBritishfleets?
Sentence:OnApril1,1768,DauvergnewasawardedapensionfromtheRoyalAcademyofMusicintheamountof1000
livresastheauthorofmusic.
Questionword:Who
Answer:RoyalAcademyofMusic
TransformedQuestion:Who,onApril1,1768,awardedapensionof1000livrestoDovergneastheauthorofmusic?
Sentence: SophiaCharlotteAuguste(22February1847,Munich-4May1897,Paris)-PrincessofBavaria,Duchessof
Bavaria,laterDuchessofAlenÃ§onandOrlÃ©ans.
Questionword:Where
Answer:Munich
TransformedQuestion:WherewasSophiaCharlotteAugusta,PrincessofBavariaborn?
Sentence:Inthefirsthalfofthe19thcentury,steamlocomotivesweremainlyimportedtoRussiafromabroad.
Questionword:When
Answer:19thcentury
TransformedQuestion: WhenweresteamlocomotivesmainlyimportedintoRussiafromabroad?
19PromptD.3: JapaneseExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: 2æœˆã€ç«‡æ†²ã¯å·¦æ ¡å°‰ã®è€¿å¤”ã‚’é£ã‚ã—ã€é‡‘å¾®å±±ã«ãŠã„ã¦åŒ—åŒˆå¥´ã®å˜äºã‚’åŒ…å›²ã—ã“ã‚Œã‚’å¤§ã„ã«ç ´ã‚Šã€å˜äº
ã®æ¯ã®é–¼æ°ã‚’æ•è™œã¨ã—ãŸã€‚
Questionword:èª°
Answer:åŒˆå¥´
TransformedQuestion:2æœˆã«é‡‘å¾®å±±ã§ç«‡æ†²ã®é£ã‚ã—ãŸå·¦æ ¡å°‰ã®è€¿å¤”ãŒåŒ…å›²ã—å¤§ã„ã«ç ´ã£ãŸã®ã¯èª°ã®å˜äºã§ã™ã‹ï¼Ÿ
Sentence:ã“ã®ç”ºã‚’æ³•äººåŒ–ã™ã‚‹æ³•ã¯ãƒªãƒãƒ£ãƒ¼ãƒ‰ãƒ»ã‚­ãƒ£ã‚ºã‚¦ã‚§ãƒ«ãŒæå‡ºã—ã€ã‚­ãƒ£ã‚ºã‚¦ã‚§ãƒ«ã¯ã“ã“ã‚’æœ¬æ‹ åœ°ã¨ã—ã€å¾Œ
ã®1776å¹´ã‹ã‚‰1780å¹´ã¾ã§ãƒãƒ¼ã‚¹ã‚«ãƒ­ãƒ©ã‚¤ãƒŠå·ã®åˆä»£çŸ¥äº‹ã¨ãªã£ãŸã€‚
Questionword:ã©ã“
Answer:ãƒãƒ¼ã‚¹ã‚«ãƒ­ãƒ©ã‚¤ãƒŠå·
TransformedQuestion:ãƒªãƒãƒ£ãƒ¼ãƒ‰ãƒ»ã‚­ãƒ£ã‚ºã‚¦ã‚§ãƒ«ãŒåˆä»£çŸ¥äº‹ã¨ãªã£ãŸã®ã¯ã©ã“ã§ã™ã‹ï¼Ÿ
Sentence:ã“ã‚Œã‚ˆã‚Šä»¥å‰ã€å¸ç©ºå¼µè¯ã¯å¸é¦¬å€«ã«ç–ã¾ã‚Œã¦èª…æ®ºã•ã‚Œã¦ã„ãŸã€‚
Questionword:èª°
Answer:å¼µè¯
TransformedQuestion:èª°ãŒã“ã‚Œã‚ˆã‚Šä»¥å‰ã«å¸é¦¬å€«ã«ç–ã¾ã‚Œã¦èª…æ®ºã•ã‚Œã¦ã„ãŸã®ã§ã™ã‹ï¼Ÿ
Sentence:é­¯è¿…ã¯ã“ã®ç„¡æ”¯ç¥ãŒå­«æ‚Ÿç©ºã®å…ˆç¥–ãƒ»æºæµã§ã¯ãªã„ã‹ã¨æ¨æ¸¬ã—ãŸã€‚
Questionword:èª°
Answer:é­¯è¿…
TransformedQuestion: èª°ã¯ã“ã®ç„¡æ”¯ç¥ãŒå­«æ‚Ÿç©ºã®å…ˆç¥–ãƒ»æºæµã§ã¯ãªã„ã‹ã¨æ¨æ¸¬ã—ãŸã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: InFebruary,DouXiansentZuoâ€™slieutenant,GengKui,tobesiegeanddefeattheNorthernXiongnuDanyuat
Jinweishan,andtookDanyuâ€™smother,theYanfamily,prisoner.
Questionword:Who
Answer:Xiongnu
TransformedQuestion:InFebruary,inJinweishan,whichwasthelandofDanyuthatwasbesiegedandseverelydefeatedby
GengKu,thecommanderoftheleftschoolsentbyDouXian?
Sentence:TheacttoincorporatethetownwasintroducedbyRichardCaswell,whomadeithishomeandlaterbecameNorth
Carolinaâ€™sfirstgovernorfrom1776to1780.
Questionword:Where
Answer:NorthCarolina
TransformedQuestion:WheredidRichardCaswellbecomethefirstgovernor?
Sentence:Beforethis,ZhangHuawasshunnedbySimaLunandkilled.
Questionword:Who
Answer:ZhangHua
TransformedQuestion:WhohadbeenshunnedandkilledbySimaLunbeforethis?
Sentence:LuXunsurmisedthatthisMujiqiwastheancestorandoriginofSunWukong.
Questionword:Who
Answer:LuXun
TransformedQuestion: WhocouldhaveguessedthatMujiqiwastheancestor/originofSonGoku?
20PromptD.4: KoreanExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:á„Œá…¥á†«á„á…®á„‹á…¦á„‰á…¥á„‰á…³á†¼á„…á…µá„’á…¡á†«á„ƒá…±,á„‹á…©á„‡á…¥á„‹á…¯á„á…µá„‚á…³á†«10á„‚á…§á†«á„€á…¡á†«á„€á…¨á„‰á…©á†¨á„’á…¢á„‰á…¥á„‘á…§á†¼á„’á…ªá„…á…³á†¯á„Œá…µá„á…§á†»á„‹á…³á„‚á…¡á„‚á…¢á„‡á…®á†«á„‹á…³á„…á…©á„‹á…µá†«á„’á…¢á„’á…¢á„‰á…¡á†«á„ƒá…¬á„‹á…¥á†»á„ƒá…¡.
Questionword:á„‚á…®á„€á…®
Answer:á„‹á…©á„‡á…¥á„‹á…¯á„á…µ
TransformedQuestion:á„‚á…®á„€á…®á„€á…¡á„Œá…¥á†«á„á…®á„‹á…¦á„‰á…¥á„‰á…³á†¼á„…á…µá„’á…¡á†«á„ƒá…±10á„‚á…§á†«á„ƒá…©á†¼á„‹á…¡á†«á„‘á…§á†¼á„’á…ªá„…á…³á†¯á„Œá…µá„á…µá„ƒá…¡á„€á…¡á„‚á…¢á„‡á…®á†«á„‹á…³á„…á…©á„‹á…µá†«á„’á…¢á…¢á„’á„‰á…¡á†«á„ƒá…¬á„‹á…¥á†»á„‚á…¡á„‹á…­?
Sentence:á„€á…³á„€á…¡á„€á…®á„ƒá…¡á†«á„‹á…³á†¯á„„á…¥á„‚á…¡á†«á„Œá…µ10á„‚á…§á†«á„‹á…µá…¬á„ƒá„‚á…³á†«2013á„‚á…§á†«4á„‹á…¯á†¯,á„‰á…³á„‘á…©á„…á…³á„á…µá†¼á„…á…µá„‰á…³á„‡á…©á†«á„‹á…³á†«á„’á…©á„‚á…¡á†¯á„ƒá…®á„…á…³á†¯100,000á„‡á…¥á†«á„á…¢á„’á…¬á„‹á…¯á†«á„‹á…³á„…á…©á„ƒá…³á†¼á†¨á„…á…©á„’á…¢
á„€á…§á†¼á„‹á…´á„…á…³á†¯á„‘á…­á„’á…¢á†»á„ƒá…¡.
Questionword:á„‚á…®á„€á…®
Answer:á„‰á…³á„‘á…©á„…á…³á„á…µá†¼á„…á…µá„‰á…³á„‡á…©á†«
TransformedQuestion:á„‚á…®á„€á…¡2013á„‚á…§á†«4á„‹á…¯á†¯á„€á…³á„€á…¡á„€á…®á„ƒá…¡á†«á„‹á…³á†¯á„„á…¥á„‚á…¡á†«á„Œá…µ10á„‚á…§á†«á„‹á…µá„ƒá…¬á„‚á…³á†«á„’á…¢á„‹á…¦á„’á…©á„‚á…¡á†¯á„ƒá…®á„…á…³á†¯100,000á„‡á…¥á†«á„á…¢á„’á…¬á„‹á…¯á†«á„‹á…³á„…á…©á„ƒá…³á†¼á†¨á„…á…©
á„’á…¢á„€á…§á†¼á„‹á…´á„…á…³á†¯á„‘á…­á„’á…¢á†»á„‚á…¡á„‹á…­?
Sentence:19á„‰á…¦á„€á…µá„’á…®á„‡á…¡á†«á„‹á…¦á„‹á…¡á„‹á…µá†¯á„…á…¢á†«á„ƒá…³á„‹á…¦á„‚á…³á†«á„ƒá…©á†¨á„…á…µá†¸á„€á…ªá„á…©á„Œá…µá„€á…¢á„’á…§á†¨á„‹á…³á†¯á„‹á…­á„€á…®á„’á…¡á„‚á…³á†«á„‹á…®á†«á„ƒá…©á†¼á„‹á…µá„á…³á„€á…¦á„’á…ªá†¨á„‰á…¡á†«á„ƒá…¬á„‹á…¥á†»á„ƒá…¡.
Questionword:á„‹á…¥á„ƒá…µ
Answer:á„‹á…¡á„‹á…µá†¯á„…á…¢á†«á„ƒá…³
TransformedQuestion:19á„‰á…¦á„€á…µá„’á…®á„‡á…¡á†«á„‹á…¦á„ƒá…©á†¨á„…á…µá†¸á„€á…ªá„á…©á„Œá…µá„€á…¢á„’á…§á†¨á„‹á…³á†¯á„‹á…­á„€á…®á„’á…¡á„‚á…³á†«á…®á†«á„‹á„ƒá…©á†¼á„‹á…µá…³á„á„€á…¦á„’á…ªá†¨á„‰á…¡á†«á„ƒá…¬á†«á„‚á…¡á„…á…¡á„‚á…³á†«á„‹á…¥á„ƒá…µá„‹á…µá†¸á„‚á…µá„á…¡?
Sentence:á„‰á…¡á†«á…¡á†«á„á„Œá…¦á†¯á„…á…©á„ƒá…¡á„…á…µ()á„„á…©á„‚á…³á†«á„’á…¡á„ƒá…³á„…á…µá„‹á…¡á„‚á…®á„‰á…³á„‹á…´á„ƒá…¡á„…á…µá„‚á…³á†«á„…á…©á„†á…¡á„‹á…¦á„‹á…µá†»á„‚á…³á†«á„ƒá…¡á„…á…µá„€á…¡á„‹á…®á†«á„ƒá…¦á…¡á„’á„‚á…¡á„‹á…µá„ƒá…¡.
Questionword:á„‹á…¥á„ƒá…µ
Answer:á„…á…©á„†á…¡
TransformedQuestion: á„‰á…¡á†«á…¡á†«á„á„Œá…¦á†¯á„…á…©á„ƒá…¡á„…á…µá„€á…¡á„‹á…µá†»á„‚á…³á†«á„€á…©á†ºá„‹á…³á†«á„‹á…¥á„ƒá…µá„‹á…µá†«á„€á…¡?
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:Afterwinningthebattle,Overwatchcontinuedtomaintainpeacefor10years,butwasdisbandedduetointernal
strife.
Questionword:Who
Answer:Overwatch
TransformedQuestion:Whowonthebattle,keptthepeacefortenyears,andthendisbandedduetoinfighting?
Sentence:InApril2013,10yearsafterhelefttheclub,SportingLisbonpaidtributetoRonaldobyregisteringhimastheir
100,000thmember.
Questionword:Who
Answer:SportingLisbon
TransformedQuestion:WhopaidtributetoRonaldobyregisteringhimastheir100,000thmemberinApril2013,marking10
yearssincehelefttheclub?
Sentence:Inthelate19thcentury,movementscallingforindependenceandlandreformspreadwidelyinIreland.
Questionword:Where
Answer:Ireland
TransformedQuestion:Inwhichcountrydidthemovementcallingforindependenceandlandreformspreadsignificantlyin
thelate19thcentury?
Sentence:PonteSantâ€™Angelo()orHadrianâ€™sBridgeisoneofthebridgesinRome.
Questionword:Where
Answer:Rome
TransformedQuestion: WhereisthePonteSantâ€™Angelo?
21PromptD.5: ArabicExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: â„(cid:152)d(cid:149)fi'(cid:143)Â¤(cid:155)qAVâ€˜TÂ¡A(cid:158)w(cid:143)r(cid:7)wflÂ§T(cid:143)r(cid:19)ynyA(cid:143)Â¤(cid:136)A(cid:157)1777,â„(cid:152)knÂ¢(cid:0)(cid:158)tq(cid:153)(cid:3)(cid:152)Y(cid:152)yksyn(cid:140)tw(cid:160),(cid:149)ntA(cid:149)Â¤(cid:143)Â¤
(cid:136)A(cid:157)1797.
Questionword: (cid:1)Â§(cid:159)
Answer: (cid:149)ntA(cid:149)Â¤
TransformedQuestion: (cid:1)Â§(cid:159)(cid:0)(cid:158)tq(cid:153)â„(cid:152)d(cid:149)fi'(cid:7)â€˜d(cid:155)yfi Â£(cid:143)Â¤(cid:155)qAVâ€˜TÂ¡A(cid:158)w(cid:143)r,â„flÂ§T(cid:143)r(cid:19)ynyA(cid:143)Â¤(cid:136)A(cid:157)1797?
Sentence: â„(cid:149)A(cid:160)(cid:158)\A(cid:157)Jr(cid:149)TFÂ¤(cid:7)Â¤(cid:3)xÂ¡w(cid:0)â€“(cid:149)(cid:16)r(cid:11)qd(cid:155)Aâ„(cid:143)AE(cid:7)A(cid:152)mnA(cid:143)sT(cid:143)Â¤(cid:149)(cid:153)(cid:155)râ€º.
Questionword: (cid:155)(cid:159)
Answer: Jr(cid:149)TFÂ¤(cid:7)Â¤(cid:3)x
TransformedQuestion: (cid:155)(cid:159)(cid:149)A(cid:160)(cid:152)dÂ§Â¢(cid:0)(cid:152)n\A(cid:157)(cid:0)â€“(cid:149)(cid:16)r(cid:11)qd(cid:155)Aâ„(cid:143)AE(cid:7)A(cid:152)mnA(cid:143)sT(cid:143)Â¤(cid:149)(cid:153)(cid:155)râ€º?
Sentence: (cid:149)mA(cid:0)(cid:152)(cid:28)Wwâ€œ(cid:0)(cid:152)(cid:20)wÂ§T(cid:0)(cid:152)brÂ§WA(cid:158)yT(cid:11)K(cid:140)(cid:153)(cid:1)Â§SA}A(cid:152)T(cid:158)A '(cid:0)(cid:152)tnfy@'(cid:7)y(cid:159)(cid:0)(cid:152)bw(cid:0)(cid:7)A(cid:14)21â„23.
Questionword: (cid:155)(cid:159)
Answer: (cid:0)(cid:152)(cid:28)Wwâ€œ(cid:0)(cid:152)(cid:20)wÂ§T(cid:0)(cid:152)brÂ§WA(cid:158)yT
TransformedQuestion: (cid:155)(cid:159)Â§K(cid:140)(cid:153)}A(cid:152)T(cid:158)A '(cid:0)(cid:152)tnfy@'(cid:7)y(cid:159)(cid:0)(cid:152)bw(cid:0)(cid:7)A(cid:14)21â„23?
Sentence: â„(cid:146)d (cid:0)(cid:143)tt(cid:25) (cid:23)dÂ§(cid:16)A(cid:190) (cid:143)Â¤ (cid:146)Or (cid:0)(cid:152)â€˜\(cid:156) (cid:146)A(cid:136)ty(cid:159) (cid:11)SmA(cid:160) (cid:7)A(cid:158)wC(cid:0)(cid:155)A (cid:152)(cid:24)r(cid:10) (cid:11)KrÂ§(cid:159) (cid:152)t(cid:24)rÂ§rÂ§T (cid:136)A(cid:157) 1973, â„(cid:7)A(cid:158)wC(cid:0)(cid:155)A
(cid:152)(cid:24)r(cid:10)(cid:11)mwE2006.
Questionword: (cid:1)Â§(cid:159)
Answer: (cid:146)Or(cid:0)(cid:152)â€˜\(cid:156)
TransformedQuestion: (cid:1)Â§(cid:159)(cid:7)A(cid:158)wC(cid:0)(cid:155)A(cid:152)(cid:24)r(cid:10)(cid:11)KrÂ§(cid:159)(cid:152)t(cid:24)rÂ§rÂ§T(cid:136)A(cid:157)1973?
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:ClaywasborninHanoverCounty,Virginiain1777,butmovedtoLexington,Kentuckyin1797.
Questionword:Where
Answer:Kentucky
TransformedQuestion:WheredidClaymoveafterhisbirthinHanoverCounty,Virginiain1797?
Sentence:TheCPSsystemwasthemostadvancedandwonthecompetition.
Questionword:Who
Answer:CPSsystem
TransformedQuestion:Whohadthemostadvancedsystemandwonthecompetition?
Sentence:BritishAirwaysalsooperatestheTeenClubloungebetweengatesB21andB23.
Questionword:Who
Answer:BritishAirways
TransformedQuestion:WhooperatestheExecutiveClubloungebetweengatesB21andB23?
Sentence:TwohallswererecentlyopenedinAl-AzmPalacecontainingapanoramaoftheOctoberLiberationWarof1973,
andapanoramaoftheJulyWarof2006.
Questionword:Where
Answer:Al-AzmPalace
TransformedQuestion: WhereisthepanoramaoftheOctoberLiberationWarof1973?
22PromptD.6: BengaliExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:Ja(cid:213)apeQ sbar Aaeg e(cid:22)(cid:150)pd(cid:140) (cid:23)aN Haran.
Questionword:ek
Answer:e(cid:22)(cid:150)pd(cid:140)
TransformedQuestion:Ja(cid:213)apeQ sbar Aaeg ek (cid:23)aN Haran?
Sentence:Apridek katarer rajzan(cid:140) edaHaet raiSJar EkiT â€¡QaJ(cid:140) d(cid:142)tabas rJeeq.
Questionword:ekaQaJ
Answer:katar
TransformedQuestion:raiSJar â€¡QaJ(cid:140) d(cid:142)tabasiT ekaQaJ Abiâ€¡Qt?
Sentence:varte Hajar Hajar manuP AnaHaer mara JaJ, ik(cid:218)u zflm(cid:23)carkra taedr (cid:23)it Udas(cid:140)n.
Questionword:ekaQaJ
Answer:vart
TransformedQuestion:ekaQaJ Hajar Hajar manuP AnaHaer mara JaJ EbK zflm(cid:23)carkra taedr (cid:23)it Udas(cid:140)n Qaek?
Sentence:EiT OJaiSKTn -Er isJaTl-E Abiâ€¡Qt exala jaJgaJ EkiT maeqr bajar.
Questionword:ekaQaJ
Answer:isJaTl
TransformedQuestion: EiT OJaiSKTn ekaQaJ exala jaJgaJ EkiT maeqr bajar?
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:Draupadiwasthefirsttodieonthejourney.
Questionword:Who
Answer:Draupadi
TransformedQuestion:Whodiedfirstonthejourney?
Sentence:Inaddition,RussiahasapermanentembassyinDoha,thecapitalofQatar.
Questionword:Where
Answer:Qatar
TransformedQuestion:WhereisthepermanentembassyofRussialocated?
Sentence:ThousandsofpeopledieofstarvationinIndia,butmissionariesareindifferenttothem.
Questionword:Where
Answer:India
TransformedQuestion:Wherearethousandsofpeopledyingofstarvationandthemissionariesareindifferenttothem?
Sentence:Itisanopen-airfishmarketlocatedinSeattle,Washington.
Questionword:Where
Answer:Seattle
TransformedQuestion: WhereisanopenairfishmarketinWashington?
23PromptD.7: TeluguExample&Translation
Rewrite sentences into short and precise questions, using given question words and answers:
Sentence: , , , , .
à°ˆ"$à°¾à°®à°®&à°²(à°µ*+ ,à±†à°°à°•0 à°®1234 56à°°7à°¶à°¨à°— à°•;à°°"à°¾à°¯à°²0=à°¦à°²à°—&à°¨?à°ªBA Cà°¨à°ªà°‚à°Ÿà°²0
Question word:
à°à°µà°°7
Answer:
à°®1234
Transformed Question: ?
à°ˆ"$à°¾à°®à°®&à°²(à°ªBA Cà°¨à°ªà°‚à°Ÿà°²à°²(à°à°µà°°7à°’à°•à°ŸI
Sentence: .
à°ˆà°¸à°®à°¯à°‚à°²(à°ªà°ªA à°‚à°šà°‚à°²(Là°‰NOC*à°¾à°²à°—à°£Qà°¯RSTà°¨UVà°°7à°—&à°¦à°²à°•0,à±†à±–XCYà°¾à°°à°£RSTà°‚NZ
Question word:
à°à°•[à°¡
Answer:
,à±†à±–XC
Transformed Question: ?
à°ˆà°¸à°®à°¯à°‚à°²(à°ªà°ªA à°‚à°šà°‚à°²(à°‰NOC*à°¾à°²à°—à°£Qà°¯RSTà°¨UVà°°7à°—&à°¦à°²à°•0à°à°•[à°¡Yà°¾à°°à°£RSTà°‚NZ
Sentence:
]à°ŸIà°²(à°ª^A à°¿Nâ€˜Z,à±†à°‚NZà°¨a$5à°¾à°¸?à°•à°¨bYà°¾à°ªà°°Rcà°¶d*eNà±‡?à°†à°²à°¯à°‚à°†à°‚à°§Aà°ªNA à±‡i*à°¾à°·kà°‚l à°²(à°ªmnà°®"oNCà°µ*+pà°²q1à°²(UVà°¨à±"sà°‚à°¡à°…X6
.
à°ªà°Ÿkà°£à°‚à°²(à°‰à°‚NZ
Question word:
à°à°µà°°7
Answer:
UVà°¨à±"sà°‚à°¡
Transformed Question:
à°†à°‚à°§Aà°ªNA à±‡i*à°¾à°·kà°‚l à°ªmnà°®"oNCà°µ*+pà°²q1à°²(Là°ª^A à°¿Nâ€˜Z,à±†à°‚NZà°¨a$5à°¾à°¸?à°•à°¨bYà°¾à°ªà°°Rcà°¶d*eNà±‡?à°†à°²à°¯à°‚à°‰à°¨u
?
à°ªà°Ÿkà°£à°‚à°à°µà°°7
Sentence: .
và°¾à°¤bYxLà°•à±ƒà°¤à°µà°°zà°…à°¡|{Y}à°¨à°¡à°‚à°šà±‚^à°¿à°¨Nà±‹Aà°£&à°¡{à°§à°°z*à°¾(cid:128)5(cid:129)à±–à°ª(cid:130)5(cid:129)(cid:131)(cid:132)(cid:133)à°¡{
Question word:
à°à°µà°°7
Answer:
à°§à°°z*à°¾(cid:128)
Transformed Question: ?
và°¾à°¤bYxLà°•à±ƒà°¤à°µà°°zà°…à°¡|{Y}à°¨à°¡à°‚à°šà±‚^à°¿à°¨Nà±‹Aà°£&à°¡{à°à°µà°°75(cid:129)à±–à°ª(cid:130)5(cid:129)(cid:131)(cid:132)(cid:133)à°¡{
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:Themaincropsinthisvillagearerice,sugarcane,mango,groundnut,vegetablesetc.
Questionword:Who
Answer:mango
TransformedQuestion:Whichisoneofthemaincropsinthisvillage?
Sentence:Chinaaccountedforasignificantincreaseinworldemissionsduringthisperiod.
Questionword:Where
Answer:China
TransformedQuestion:Whereintheworldhascausedthesignificantincreaseinemissionsduringthistime?
Sentence:Amongthese,thefamousSriVasaviKanyakaParameshwariDeviTempleislocatedinthetownofPenugondain
theWestGodavaridistrictofthestateofAndhraPradesh.
Questionword:Who
Answer:Penugonda
TransformedQuestion:WhichtowninWestGodavaridistrictofAndhraPradeshstatehasthefamousSriVasaviKanyaka
ParameshwariDevitemple?
Sentence:SeeingSatyakibeingstoppedbyKritavarma,DronawenttowardsDharmaraja.
Questionword:Who
Answer:Dharmaraja
TransformedQuestion: TowhomdidDronagowhenhesawKritavarmastoppingSatyaki?
24