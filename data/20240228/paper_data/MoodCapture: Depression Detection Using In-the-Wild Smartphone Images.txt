MoodCapture: Depression Detection Using In-the-Wild
Smartphone Images
SubigyaNepalâˆ— WeichenWang TessGriffin
ArvindPillaiâˆ— DartmouthCollege DartmouthCollege
DartmouthCollege Hanover,NewHampshire,USA Hanover,NewHampshire,USA
Hanover,NewHampshire,USA
AmandaC.Collins MichaelHeinz DamienLekkas
DartmouthCollege DartmouthCollege DartmouthCollege
Hanover,NewHampshire,USA Hanover,NewHampshire,USA Hanover,NewHampshire,USA
ShayanMirjafari MatthewNemesure GeorgePrice
DartmouthCollege DartmouthCollege DartmouthCollege
Hanover,NewHampshire,USA Hanover,NewHampshire,USA Hanover,NewHampshire,USA
NicholasC.Jacobson AndrewT.Campbell
DartmouthCollege DartmouthCollege
Hanover,NewHampshire,USA Hanover,NewHampshire,USA
ABSTRACT KEYWORDS
MoodCapturepresentsanovelapproachthatassessesdepression Depression,In-the-wild,Smartphones,MentalHealth,PHQ,Ma-
basedonimagesautomaticallycapturedfromthefront-facingcam- chineLearning,Face,FacialExpressions,Mood,PassiveSensing
eraofsmartphonesaspeoplegoabouttheirdailylives.Wecollect
ACMReferenceFormat:
over125,000photosinthewildfromN=177participantsdiagnosed
Subigya Nepal, Arvind Pillai, Weichen Wang, Tess Griffin, Amanda C.
withmajordepressivedisorderfor90days.Imagesarecaptured
Collins,MichaelHeinz,DamienLekkas,ShayanMirjafari,MatthewNemesure,
naturalisticallywhileparticipantsrespondtothePHQ-8depression GeorgePrice,NicholasC.Jacobson,andAndrewT.Campbell.2024.Mood-
surveyquestion:â€œIhavefeltdown,depressed,orhopelessâ€.Ouranal- Capture:DepressionDetectionUsingIn-the-WildSmartphoneImages.In
ysisexploresimportantimageattributes,suchasangle,dominant ProceedingsoftheCHIConferenceonHumanFactorsinComputingSystems
colors,location,objects,andlighting.Weshowthatarandomforest (CHIâ€™24),May11â€“16,2024,Honolulu,HI,USA.ACM,NewYork,NY,USA,
trainedwithfacelandmarkscanclassifysamplesasdepressedor 18pages.https://doi.org/10.1145/3613904.3642680
non-depressedandpredictrawPHQ-8scoreseffectively.Ourpost-
hocanalysisprovidesseveralinsightsthroughanablationstudy, 1 INTRODUCTION
featureimportanceanalysis,andbiasassessment.Importantly,we
Today,mostpeopleautomaticallyunlocktheirphonesusingcamera
evaluateuserconcernsaboutusingMoodCapturetodetectdepres-
biometricsandfacerecognition.Thefront-facingcameraquietly
sionbasedonsharingphotos,providingcriticalinsightsintoprivacy
capturesglimpsesofusersâ€™facestenstohundredsoftimesdaily,
concernsthatinformthefuturedesignofin-the-wildimage-based
weekinandweekout.Unlikeselfies,thesein-the-momentimages
mentalhealthassessmenttools.
captureauthentic,unguardedfacialexpressions,freefrombiases
such as social desirability and self-presentation. We envision a
CCSCONCEPTS futurewhereAIprocessestheseunguardedfacialimagesonthe
â€¢Human-centeredcomputingâ†’Ubiquitousandmobilecom- phoneinreal-timeusingdeeplearning,assessingtheuserâ€™smood
puting;â€¢Appliedcomputingâ†’Healthinformatics. withoutneedingtheimagestoleavethedevice,thussafeguarding
privacy.Thislow-burden,continuousapproachtodepressionas-
sessmentanddetectionwillsignificantlyalterhowmentalhealth
âˆ—Bothauthorscontributedequallytothisresearch. ispassivelyassessed,enablingearlydetectionofdepression,timely
intervention,andconstantevaluationofindividualsatrisk.This
paperdiscussesthefirststepstowardrealizingthisvision.
Permissiontomakedigitalorhardcopiesofpartorallofthisworkforpersonalor Depressionisacomplexandpervasivementalhealthissueaffect-
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed ingmillionsofpeopleworldwide.AccordingtotheWorldHealth
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
Organization(WHO),over264millionpeoplesufferfromdepres-
onthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored.
Forallotheruses,contacttheowner/author(s). sion[56],makingitaleadingcauseofdisabilityandamajorcon-
CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA tributortotheoverallglobalburdenofdisease.Theconsequences
Â©2024Copyrightheldbytheowner/author(s).
ofdepressionextendbeyondemotionaldistress[62],significantly
ACMISBN979-8-4007-0330-0/24/05.
https://doi.org/10.1145/3613904.3642680 impactingphysicalhealth[23,55],socialrelationships[67],and
4202
beF
52
]CH.sc[
1v28161.2042:viXraCHIâ€™24,May11â€“16,2024,Honolulu,HI,USA NepalandPillaietal.
occupationalfunctioning[19].Inseverecases,depressioncanlead userprivacy.Comparedtopriorstudies,ourapplicationcap-
tosuicide,accountingfornearly800,000deathseachyear[1,9].The turesfront-facingphotosin-the-moment,resultinginnatu-
needforearlydetectionandinterventionindepressioniscritical, ralisticimageswithauthenticemotions.Ourappprovides
astimelyidentificationoftheconditionallowsindividualstoac- valuableinsightsforfuturein-the-wildstudies.
cessappropriatetreatmentandsupport,therebyimprovingclinical â€¢ Weanalyzedifferentimagecharacteristicssuchasillumina-
outcomesandreducingtheriskoflong-termcomplications[21,63]. tion,location,phoneangle,backgroundcolor,andobjects,
Smartphones offer an opportunity to explore alternative ap- providinginsightsintothevisualpropertiesofsmartphone
proachesfordepressiondetectionthataremoreobjective,unobtru- images.Forexample,majorityoftheimagesweretakenin-
sive,andcontinuous.Thevastamountsofdatageneratedthrough doorsinwelllitenvironments.Thesepropertiesarecrucial
dailysmartphoneusage,includingimages,textmessages,andsocial formodeltrainingandinformsHCIpractitionersaboutthe
mediainteractions,providearichandecologicallyvalidsourceof environmentalconditionsinuserinteractions.
informationthatcanbeutilizedtogaininsightsintoanindividu- â€¢ Weevaluatetheperformanceofseveralmachinelearning
alsâ€™mentalstate.Consequently,severalstudieshavemadeuseof anddeeplearningmodelsfordepressiondetectionandPHQ-
smartphonesensingdatatoassessdepression[14,75]. 8scoreprediction.Arandomforesttrainedwith3Dfaceland-
Mostofthepriorresearchutilizingfacialimagestodetectde- marksdemonstratesthefeasibilityofanalyzingdepression
pressionfocusoncapturingtheseimagesincontrolledsettings, fromin-the-wildsmartphoneimages,resultinginabalanced
whereindividualsmaybeinstructedtoperformspecificactions accuracyof0.60,Matthewâ€™sCorrelationCoefficient(MCC)
[22,38,43,46].Thesefacefeaturesarenotauthenticastheyare of0.14andMeanAbsoluteError(MAE)of130.31(a6%im-
performativeandareinfluencedbybiasessuchassocialdesirability provementoverbaselineona0-800scale).Furthermore,we
andself-presentation.Furthermore,traditionalmethodssuchas identifyimportantfeaturesprovidingusefulinsightsforHCI
clinicalassessmentsandsubjectiveself-reportsaretime-consuming design.
andaffectedbyrecallbias.Advancesinsmartphonecamerasoffer â€¢ Wereportonuseracceptancewithrespecttothecomfort
asolutiontoaddressthesedisadvantages.Tothisend,wepresent levelsoftheparticipantsinsharingtheirphotosformental
MoodCapture,anovelapproachtocollectin-the-wildfaceimages healthassessment,providingvaluableinsightsintoprivacy
andself-reporteddepressionsymptomsinnatural,everydayenvi- concernsthatinformthefuturedesignofin-the-wildimage-
ronmentsusingsmartphones.Theresultingfaceimagescapture basedmentalhealthassessmenttools.
authenticandunguardedfacialexpressions.Thus,minimizingthe
InadditiontoitsrelevancetotheHCIcommunity,ourMood-
influenceofself-awarenessonemotionsandenhancingthecred-
Capturestudycontributestoaffectivecomputing,whichdealswith
ibilityofourdata.Byusingsuchnaturalisticimagesforanalysis
recognizing,interpreting,andsimulatinghumanemotions.Bylever-
andtrainingmachineanddeeplearningmodels,wecanbetterun-
agingcomputationalmethodsandmachinelearningmodelstoin-
derstandintricatepatternsassociatedwithdepression.Ultimately,
terpretemotionalcuesfromimages,ourresearchcontributestothe
insightsfromourworkcanbeusedtocreateaccurate,efficient,and
understandinganddevelopmentofaffectivecomputingwithinthe
personalizedtoolsfordepressiondetection.
HCIfield.Furthermore,ourstudyhastangible,real-worldimplica-
OurpapercontributestothegrowingintersectionofHuman-
tions,suchasthepotentialbenefitsofearlydepressiondetection,
ComputerInteraction(HCI)researchandmentalhealthassessment
timelyinterventions,improvedclinicaloutcomes,andoverallwell-
byinvestigatingthepotentialofmachinelearninganddeeplearning
beingforindividuals.
modelstrainedusingin-the-wildsmartphoneimagesforidentify-
Thispaperisstructuredasfollows:Section2,presentsrelated
ingdepressivesymptoms.Wecollectedover125,000imagesfrom
works in depression detection and work that uses smartphone
N=177participantsdiagnosedwithmajordepressivedisorderover
images.Section3detailstheMoodCapturestudy,participantdemo-
threemonths,utilizing87distincttypesofAndroiddevicesowned
graphics,andtheanalysisweperformtoidentifyimagecharacteris-
byusersinthestudy.Onaverage,eachparticipantprovidedsix
ticsandtodetectdepression.Section4,discussesourresults,while
photosperday,creatingavariedandextensivedataset.Wecom-
Section5describestheethicalconsiderationsanduseracceptance
prehensivelyanalyzevariousimagecharacteristicsobtainedfrom
study.Section6discussesthestudyfindingsanditsimplications.
theseimagescapturedin-the-wild.Weevaluatetheperformance
Finally,Section7andSection8,discussthelimitationsofthestudy
ofmachinelearninganddeeplearningmodelstrainedtopredict
andprovidesomeconcludingremarks,respectively.
depressionbasedontheseimages,asshowninFigure1.Atthe
endofthestudyperiod,weassessuseracceptancebyinquiring
aboutparticipantsâ€™comfortlevelsandprivacyconcernsinsharing 2 RELATEDWORK
theirphotosformentalhealthassessmentpurposes.Therefore,our
Inthissection,wedelveintothepertinentliterature,examiningthe
researchaimstofosterthedevelopmentofmoreethicallysound
keystudiesanddevelopmentsinthefieldthatinformthefoundation
mentalhealthassessmentandinterventiontools.Thecontributions
ofourMoodCaptureresearch.
ofourworkareasfollows:
2.1 SmartphonesandMentalHealth
â€¢ Wedevelopapassive-sensingimage-basedmobileappcalled
MoodCapturethatautomaticallycollectsin-the-wildsmart- Depressionhasbeentraditionallydiagnosedthroughclinicalinter-
phoneimagesfromparticipantsâ€™front-facingcameras,ensur- viewsorself-reportingquestionnariessuchastheBeckDepression
inganunobtrusivedatacollectionprocessandmaintaining Inventory (BDI) [7] and the Hamilton Depression Rating ScaleMoodCapture:DepressionDetectionUsingIn-the-WildSmartphoneImages CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA
Figure1:MoodCaptureFramework:UsersanswerthePHQ-8depressionsurveyquestionsusingtheMoodCaptureAndroidApp
whiletheapptakesburstsofphotosusingthefront-facingcameraonthesmartphone(top-left).Imagecharacteristicsare
analysedusingfactors,suchas,illumination,indoorvs.outdoors,phoneangle,dominantimagecolor,andbackgroundobjects
(top-right).Giventhatrawimagescompromiseprivacy,thesecharacteristicsprovideinsightsintothetypesoffeaturesour
machinelearninganddeeplearningmodelinfer.Finally,OpenFacefeaturesareextractedtotrainmachinelearningmodels,
whilerawimagesareusedtotraindeeplearningmodels(bottom).Depressionclassificationisabinarypredictorthatclassifies
animageasdepressedornotdepressed,whereasPHQ-8scorepredictionisaregressionmodelthatpredictsrawPHQ-8scores.
(HDRS) [37]. However, these tools are affected by the individu- FacebookandInstagram.Forinstance,thelinguisticattributesof
alsâ€™subjectiverecollections,socialdesirabilitybias,mentalhealth postscanshedlightonauserâ€™semotionalstate,sentiment,and
stigmas, or the personâ€™s diminished self-awareness [18, 33, 69]. overallmentalwell-being[12,17].Moreover,machinelearningal-
Therefore,thepervasive,objective,andcontinuousnatureofmulti- gorithmshavebeenemployedtodecipherpatternsandindicators
facetedsmartphonedatamakesitanidealcandidateforunobtrusive ofdepressionfromvisualcontentsharedontheseplatforms.Such
depressiondetection.Manystudiesevaluatepatternsincalllogs, analysesoftenencompassaspectslikecolors,objects,scenes,and
textmessages,GPScoordinates,andoverallsmartphoneactivity,to overallaesthetics[26,30,61].
gaininsightsintobehavioralshifts,socialengagementfrequencies,
andalterationsindailyroutines,allofwhichcanserveasindicators
2.2 ContextualImageFactorsinHuman
ofdeterioratingmentalhealth[14,53,75,77].Othermodalitiessuch
ComputerInteraction
asspeechhavealsogainedtractioninevaluatingmentalhealth
symptomssuchassuicidalideation[8,59].Thegrowthofsocial Understandingthecontentandintrinsiccharacteristicsofsponta-
mediaplatformsprovideswaystoharnessuser-generatedcontent neousimagescouldbeessentialfromaHCIstandpoint.Contextual
fordepressiondetection.Inparticular,analyticalapproachesusing elementslikeenvironment,angle,color,andlightingplayasignifi-
textandimageshavebeenappliedtocontentfromplatformslike cantroleinhowusersinteractwiththeirsmartphones.Forexample,CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA NepalandPillaietal.
researchbyIkematsuetal.[34]indicatesthatpeopleoftenprefer 2.4 â€œIn-the-wild"SmartphoneImagesfor
positionsthatrequireminimalmovementwhenusingtheirdevices. MentalHealth
Thismakesitvaluabletoexaminefactorssuchasthesmartphoneâ€™s
Ourstudyemphasizestheanalysisof"in-the-wild"smartphoneim-
angleandthebackgroundobjectspresentduringuse.Inaddition,
ages,particularlythosecapturedviafront-facingcamerasofsmart-
theambientlightduringdeviceinteractioncanactasasituational
phones.Theseimagesofferadirectwindowintoanindividualâ€™s
impairment,asnotedbyTigwelletal.[71]andSarsenbayevaetal.
emotions,expressions,andenvironment,thusenhancingtheaccu-
[68]. For instance, the facial expressions and illumination on a
racyofmentalhealthassessments.Incontrasttosocialmediacon-
userâ€™sfacecanvarygreatlybetweenbrightoutdoorsunlightand
tent,theseimagesremainrelativelyfreefrombiaseslikesocialde-
controlledindoorlightingconditions.Theenvironment,whether
sirabilityandself-presentation,whichoftenaffecttraditionaltools.
indoororoutdoor,alsoaffectscolor,whichinturncaninfluence
Alimitednumberofpastresearchhaveused"in-the-wild"smart-
userpsychology.ValdezandMehrabian[72]conductedstudiesas-
phoneimagesformentalhealthevaluation.Forinstance,Wang
sessingtheimpactofcoloronemotionslikepleasure,dominance,
etal.[73]collected5811opportunisticphotosin-the-wildfrom37
andarousal.Theirfindingssuggestthatcolorslikeblueandpurple
studentsovertenweeksusingtheirphoneâ€™sfront-facingcamera.
aretypicallyperceivedaspleasant,whilegreenishhuestendtobe
Thestudyreportedthatdepressionscoressignificantlycorrelate
morearousing.Thisraisesthepossibilitythatthedominantcolor
withthestudentsâ€™facialexpressionsandactivity.WhileWangetal.
inauserâ€™ssurroundingsmighthaveacorrelationwiththeirfacial
[73]wasthefirsttousein-the-wildimagesfromfront-facingphone
featuresduringsmartphoneinteraction.
camerastostudymentalhealthonanon-clinicalpopulationofcol-
legestudents,theauthorsstatethattherewasinsignificantsignal
intheimagestopredictself-reporteddepression.MoodCaptureis
inspiredbythisoriginalwork,whichwaspartoftheStudentLife
2.3 SmartphoneImagesinControlledSettings study[74]in2013.OurprogressisthatadecadeonfromtheStu-
forMentalHealth dentLifestudy,phonecamerashaveseensignificantadvancements,
leadingtosubstantialdifferencesintheircapabilitiescompared
Extractingfacialfeaturestoassessmentalhealthandemotionshas
to those from ten years ago. For example, new phone cameras
receivedsignificantattentionincomputervision,withapplications
typicallyoffermuchhigherresolutionandmoremegapixelsthan
spanningfromeducationtohealthcare[51].Here,manystudies
thosefromadecadeago,resultinginsharperandmoredetailed
have explored facial expressions, gaze patterns, and the overall
facephotos;advancesinsensortechnologyandimageprocessing
compositionofimagestoextractvisualmarkerssymptomaticofde-
havegreatlyimprovedlow-lightperformance,resultingintodayâ€™s
pression[38,43,46].However,mostofthesestudiesareconducted
phonecamerascapturingbetterqualityfacephotosinlow-light
incontrolledenvironmentsorrelyonparticipantsdeliberatelycap-
conditions;opticalimagestabilizationhasbecomemorecommon
turingtheirimages,whichcouldinadvertentlyinfluencetheiremo-
insmartphonecamerastoday,reducingtheimpactofshakyhands
tionalportrayal.Forinstance,Kongetal.[38]capturedphotographs
andresultinginsmoothersharperphotos,especiallyinlowlight;
usingatabletinastandardizedclinicalsetting.Participantswere
andfinallyfront-facingcamerasprimarilydesignedforselfieshots
askedtositbeforeawhitebackground,removehatsorglasses,
haveimprovedsignificantlyintermsofresolution,imagequality,
andtieuplonghairtoexposetheirears;theuserslookedstraight
auto-focusontheface.OtherdifferencesbetweenWangetal.[73]
aheadwithrelaxedexpressionsasinstructed.Similarly,Liuetal.
andourworkarethatwetakeadvantageofmassiveadvancespre-
[46]employedamulti-modaldeepConvolutionalNeuralNetwork
sentedbydeeplearningmodelsandfocusnotonanon-clinical
(CNN),consideringbothfacialexpressionsandbodymovements.
groupbutaclinicalpopulation.
Duringpsychotherapysessions,theycapturedvideousinga4K
Otherstudieshavealsoleveragedfrontfacingcamerasinone
high-resolutioncamerainacontrolledlaboratorysetting.Conse-
way or another. Khamis et al. [36] studied the visibility of the
quently,theparticipantsâ€™expressionsandbodymovementswere
face and eye in 25,726 in-the-wild images of smartphone users
analyzedinahighlyregulatedcontext.Numerousotherstudies
andfoundthatthefullfaceisvisibleabout29%ofthetime.The
havesimilarlyreliedonadvanceddevicesforimagecapture,used
authorsstatedthattheirstate-of-the-artfacedetectionalgorithm
videorecordings,orincorporatedadditionalsignals(suchasmove-
performedpoorlyagainstphotostakenfromfront-facingcameras.
ment,audio)withincontrolledenvironments[22,31,35,57,60,78].
Similarly,BÃ¢ceetal.[3]usedin-the-wildimagestostudythevisual
Ourworkaimstoaddresstheselimitationsbyexaminingthe
attentionandgazeofusers.Darvariuetal.[16],ontheotherhand,
feasibilityofusingspontaneouslycapturedimagesfrompartici-
usedin-the-wildimagesfromrear-facingcameras.Theauthorsde-
pantsâ€™smartphones,whichoffersamorenaturalandlessintrusive
velopedasmartphoneapplicationthatallowsuserstoperiodically
methodforpredictingdepression.Assmartphoneshavebecomean
logtheiremotionalstatetogetherwithpicturesfromtheireveryday
integralpartofmodernlife,theyareanidealtoolforunobtrusive
lives.Theycollected3,305moodreportswithphotosfrom22par-
andwidespreaddatacollection.Byutilizingsmartphonecameras
ticipants.Authorsreportfindingcontext-dependentassociations
tocaptureparticipantsâ€™images,ourapproacheliminatestheneed
betweenobjectssurroundingindividualsandtheirself-reported
forcontrolledenvironmentsordeliberateimage-taking,therebyre-
emotionalstate.However,thegenuinespontaneityofthesecaptures
ducingthepotentialforbiasedemotionalportrayals.Furthermore,
andtheirpotentialforunbiasedmentalhealthevaluationremain
thewidespreadavailabilityofsmartphonesenablesourmethodto
relativelyunexplored.Ourcontributiontothisgrowingfieldpivots
reachalargerandmorediversepopulation,ultimatelypromoting
ontheinnovativeuseofgenuinelyspontaneous,in-the-wildfacial
greateraccessibilityandinclusivityinmentalhealthassessments.MoodCapture:DepressionDetectionUsingIn-the-WildSmartphoneImages CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA
imagesfordepressiondetection.Byemployingapassive-sensing Participantswerecompensated$1foreachcompletedEMA,with
mobileapplicationthatseamlesslycapturesimageswithoutthe anadditional$50bonusforachievingacompletionrateof90%or
subjectâ€™s acute awareness, we negate the potential influence of higherduringthestudyperiod.Compensationwasnotdependent
self-awarenessonemotionalrepresentation.Thisstrategybolsters onsharingphotos;participantswerecompensatedregardlessof
theecologicalvalidityofourdatasource,makingitarobusttool theirphotoconsent.ThestudywasapprovedbyDartmouthCol-
fordepressiondetection. legeâ€™sInternalReviewBoard(IRB).Ouranalysisandpredictive
modelingfocuseson177outofthe181participantswhoprovided
consentfortheirphotostobecaptured.Wecollected125,335im-
3 METHODOLOGY
agesfromtheseparticipants,excluding15,063photosthatwere
Inwhatfollows,wediscussthedesignofourMoodCapturestudy, eithertooblurry,containednofaces,featuredchildren,orcontained
demographicinformationoftheindividualsthatparticipatedinthe nudity.
studyandtheground-truthusedforanalysis.
3.2 Demographics
Themajorityofparticipantsinourstudyidentifiedasfemale(86.4%,
3.1 StudyDesign
N=153)followedbymale(9.6%,N=17)andnon-binary(2.8%,N=5).
We recruited 181 participants from across the United States us- Intermsofrace,83.6%(N=148)areWhite,2.8%(N=5)areAsians,
ingtargetedonlineadvertisementsonGoogleandFacebook.Each 4.5%(N=8)areBlackorAfricanAmerican,0.5%(N=1)areAmerican
participantunderwentaclinician-administeredStructuredClinical Indian/AlaskaNativeand6.7%(N=12)belongtomorethanone
InterviewforDSM-5(SCID),andonlythosediagnosedwithMa- race.SeeTable1forthedetailedbreakdown.
jorDepressiveDisorder(MDD),withoutbipolardisorder,active
suicidality,orpsychosis,wereeligibleforthestudy.Uponquali- Table1:Demographics,smartphones,andimagecomposition
fication,participantsinstalledourAndroid-basedmobilesensing inourstudy.
appontheirdevices,whichgatheredEcologicalMomentaryAssess-
ments(EMA)duringthe90-daystudyperiod.Theappprompted Category Count Percentage
participantstocompleteabriefPatient HealthQuestionnaire-8 Sex
(PHQ-8)[41](seeTable6)surveyabouttheirdepressivesymptoms Female 153 86.4%
threetimesdaily(morning,afternoon,andevening).Asparticipants Male 17 9.6%
answeredtheirdailysurveys,theappwasdesignedtodiscreetly Non-binary 5 2.8%
captureaburstofupto5imagesusingthefront-facingcamera. Other(prefertoself-describe) 2 1.1%
Specifically,imagesweretakenwhenparticipantsrespondedto Race
thePHQ-8item:â€œIhavefeltdown,depressed,orhopeless.â€ (seeFig. White 148 83.6%
2).Wechosethisquestionaswebelieveditwouldbestcapture Asian 5 2.8%
participantsâ€™genuineemotionsrelatedtodepression.ThePHQ- BlackorAfricanAmerican 8 4.5%
8isavalidatedinventoryformeasuringdepression.Forfurther AmericanIndian/AlaskaNative 1 0.5%
informationaboutthesurvey,pleaserefertotheGroundTruth Morethanonerace 12 6.7%
section. Other(prefertoself-describe) 3 1.6%
Duringtheonboardingprocess,weinformedparticipantsabout Smartphones
theimagecaptureprocedureandemphasizedthatsharingtheirpho- Samsung 107 60.4%
toswasoptional.Uponlaunchingthemobileappforthefirsttime, Google 36 20.3%
participantswereasked,â€œTohelpusbetterunderstandyourdepres- Motorola 19 10.7%
sivesymptoms,wewouldliketotakeafewphotosinthebackground Other 15 8.4%
thatcaptureyourfacialexpressionswhileyoufilloutquestionnaires. ImageResolution
Doyougiveuspermissiontodothis?â€ Participantscouldrespond 3648x2736 57 32.2%
witheither"Yes"or"No."Iftheyagreedtosharetheirphotos,the 3264x2448 52 29.3%
appcapturedimagesastheyansweredtheEMA.Iftheyoptednot 2640x1980 16 9.0%
tosharetheirphotos,noimageswerecaptured.Theimagecap- Other 52 29.3%
tureprocesswasdesignedtobeunobtrusive,withonlyagreen
dotatthetopoftheAndroidstatusbar/screenindicatingcamera
usageâ€“whichusersâ€™mayormaynothaveobserved.Participants
3.3 GroundTruth
didnotseetheirfaceorreceiveanyotherindicationthatphotos
werebeingtaken.Thisdiscreetimagecaptureprocessensureda OurstudyisdesignedtoaccountforthewidevariabilityinMDD
seamlessuserexperiencewithoutinterruptingorobstructingthe symptoms.Inparticular,MDDcanmanifestinover1000distinct
EMAflow.Asstatedearlier;whileparticipantsconsentedtohave symptomcombinationsacrossindividuals,withsignificantwithin-
photostakenusingthefront-facingcameraduringtheoperationof dayvariations[15,20,24,25].However,existingdiagnosticmethods
theMoodCaptureappinthestudytheywerenotinformedexactly faceseverallimitations.Firstly,SCIDsarenoteffectiveincapturing
whenthesephotoswerecaptured,thuspromotingin-the-moment moment-to-momentfluctuationsindepressionsymptoms.Secondly,
naturalisticandauthenticcaptureofusersâ€™facesandsurroundings. theLikertscaleusedindepressionscreeningtoolslikethePHQ-8,CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA NepalandPillaietal.
Figure2:PHQ-8applicationscreensforeachitem:ImagesarealwayscapturedwhileusersrespondtothePHQ-8depression
surveyquestion(highlightedincyan):â€œIhavefeltdown,depressed,orhopelessâ€.Whileusersconsenttohavephotostaken
usingthefront-facingcameraduringtheoperationoftheMoodCaptureapptheyarenotinformedexactlywhenthesephotos
arecapturedtopromoteinthemomentnaturalisticandauthenticimages.
whichtypicallyoffersalimitedresponserangefrom0-3,forces holisticanalysis,wecomplementourbinaryclassificationmodels
respondentstofittheirexperiencesintopre-setcategories.This withregressionmodelsthatpredictrawPHQ-8scores.Notethat
canleadtocentraltendencybiasandalackofdetailedresponses thePHQisversatile,servingbothasascreeningtoolfordepression
forcomplexmentalstates.Toovercomethesechallengesandbetter andasameanstomonitorclinicalsymptomchanges[40].
captureintra-individualvariation,ourclinicalteammodifiedthe ToenhancethereliabilityandaccuracyoftheEMAresponses,
PHQ-8scaletoamorenuancedcontinuousscalerangingfrom0-100 weemployedavalidationtechniquewhereintheapprandomly
(seeFigure2).Thepracticeofre-scalingpsychometricscalesisnot reversedonequestionineachPHQ-8survey(thusaddinganad-
uncommonandhasbeenappliedtothePHQinvariouspaststud- ditionalitem),ensuringthatparticipantsareattentive.Wethen
ies[29,48,50,54].AstandardPHQ-8scoreof10orhigher(outof comparedtheresponsestotheoriginalandreversedquestions;if
24)signifiesmajordepression[44].Inourcontinuousscale,ascore thereisasignificantdiscrepancy,theresponseisexcludedfromour
exceeding334indicatesdepression(i.e.,10/24times800).Toprovide analysis.Afterapplyingthisfilteringprocess,weobtainarefinedMoodCapture:DepressionDetectionUsingIn-the-WildSmartphoneImages CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA
datasetcomprising31,215EMAs.Sincewecapturedaburstofim- 3.4 ImageCharacteristics
ageswitheachEMAresponse,weamassed110,272imagesintotal. Wegatherin-the-wildimagescapturedbyparticipantsusingadi-
AsdepictedinFigure3a,wedividedourdatasetintotwogroups: verserangeofsmartphoneswithvariedconfigurationsandcamera
depressed(74,347images,N=175)andnon-depressed(35,925im- placements.Predominantly,participantsuseSamsung,Google,and
ages,N=156).Onaverage,participantssubmitted176EMAs(stdev Motoroladevices,andtheimagescapturedfromthesedeviceshad
=78)and623images(stddev=278)perparticipantduringthestudy resolutionsrangingfrom1920x1080to4656x3488(seeTable1).Our
period.Itiscrucialtonotethatallparticipantsrecruitedforthis naturalisticapproachatcapturingimageensuresecologicalvalidity
studyhadmajordepressivedisorder.Consequently,theyreported andrepresentsusersâ€™naturalbehaviorwhileengagingwiththeir
beingbelowthecut-offthresholdonsomedaysandaboveiton devicesindifferentenvironments.Toexaminethecharacteristics
others.However,19participantsconsistentlyreporteddepression oftheseimages,weanalyzefactorssuchasphoneangle,dominant
throughoutthestudy. color,lightingcondition,photolocation,andbackgroundelements
presentinthephotos.Thein-the-wildsmartphoneimagesoffer
auniqueglimpseintothemultitudeofwaysusersinteractwith
theirdevicesandsurroundings.However,extractingmeaningful
insightsfromtheseimagesdemandsarefinedapproachthatac-
knowledgesthediversecontextsinwhichtheyarecaptured.To
achievethis,weutilizetheBLIP[45]visualquestionanswering
(VQA)model,anadvancedAItoolspecificallydesignedforimage
analysisandansweringquestionsaboutimagecontentandcontext.
BLIPisrecognizedasastate-of-the-artmethodforvisualquestion
answeringtasks.Furthermore,theVQAanalysiscontextualizesour
predictivemodelinginthefollowingways.First,itcanelucidate
therawimagecontent,whichistheinputforourdeeplearning
models.Second,asourMLmodelsusehandcraftedfeaturesfrom
(a)DistributionofPHQ-8Scores theface,itdifferentiatestheperformanceobtainedbyconsidering
backgroundinadditiontofaceversusonlyface.Insummary,our
motivationistoharnessVQAtointerpretbothexplicitandimplicit
imagecontent.Consequently,enablingamoreholisticapproachto
imageanalysis,whereboththecentralsubjectsandtheirsurround-
ingcontextcontributetothepredictiveinsights.Importantly,as
wecannotdisplayimagestoprotectparticipantprivacy,theVQA
providessomelevelofinterpretation.WiththehelpoftheVQA
model,weexplorethefollowingcharacteristics:
ImageAngle:Byinquiringabouttheimageangle,wegainan
understanding of user interaction dynamics with their devices.
Varyingangles,suchashighorlow,offerinsightsintousersâ€™phys-
icalengagementwiththeirsmartphones.High,low,orlevelangle
(b)Intra-individualvariability referstotheperspectivefromwhichanimageiscapturedortaken
withrespecttothesubjectintheframe.Alowangleshotrefers
Figure3:PHQ-8scorestatistics:Figure(a)depictsthedistri- tothesubjectlookingdownattheirphone,whereasahighangle
butionofthePHQ-8scorereportedbytheparticipantand shotreferstotheuserlookingupattheirphone.Alevelangleshot
thecorrespondinglabel(i.e.,DepressionorNoDepression). istakenfromthesameheightasthesubject,capturingitateye
Figure(b)showsthevariabilityofPHQ-8scoresamongpar- level.WeaskedtheVQA:â€œIstheimagetakenfromahigh,low,or
ticipantsoverthedurationofthestudy(Cronbachâ€™sğ›¼ğ›¼ğ›¼===000...888555). levelangle?â€.
DominantColors:Colorsarecrucialforestablishingthecontextof
Figure3bshowsthevariabilityofPHQ-8scoresamongpartici- animage.Toidentifydominantcolorsintheimagesandunderstand
pantsi.e.,intra-individualvariability.Itprovidesinsightintothe theusersâ€™environments,weaskedtheVQA:â€œWhatisthedominant
fluctuationsinaparticipantâ€™sscoresovertime.Onaverage,par- coloroftheimage?â€.
ticipantsâ€™scoresvariedaroundtheirownmeanbyapproximately
LightingCondition:Lightingconditionsinanimagerevealim-
101.92points,withthevariabilityrangingwidelyfromastandard
portantinformationabouttheuserâ€™sambientenvironment.Using
deviationof27.56pointstoashighas262.24points.Thissuggests
theVQAmodel,weclassifiedimagesbasedontheirlightingas
thatsomeparticipantshadrelativelystablescoresovertime,while
well-lit,dimlylit,orpoorlylit.WeaskedtheVQA:â€œIstheimage
othersexhibitedmorepronouncedfluctuations.Moreover,wemea-
well-lit,dimlylit,orpoorlylit?â€.
sured the internal consistency of the PHQ-8 items, obtaining a
Cronbachâ€™sğ›¼ =0.85.Thisdemonstratesgoodreliabilityandvalid-
ityofourmeasures.CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA NepalandPillaietal.
PhotoLocation:Thelocationcontext(indoorsoroutdoors)can Table2:DescriptionofOpenFacefeatures[6].
significantlyinfluenceuser-deviceinteractions.Wedeterminedthe
location context of images with the help of the VQA model by FeatureSet Features Description
asking:â€œIsthephototakenindoorsoroutdoors?â€.
FAU[4] 35 FAUusesthefacialactioncodingsystemto
Background Objects: Identifying specific objects in the back- describeanatomicallypossibleexpressions
resultingfrommuscleactivations.Itindi-
groundcanprovidevaluableinformationabouttheuserâ€™scontext
catesthepresenceandintensityofanex-
andactivities.WequeriedtheVQAmodelaboutthebackground pression1.
objectstorecognizeandcategorizevariouselementswithinthe
Gaze[76] 8 Directionvectorineyegazedirectionasmea-
images.WeaskedtheVQA:â€œWhatarethebackgroundobjectsinthe suredfromtheeyelocation,consistingof
photo?â€. locationandangle.Thisfeatureiscomputed
afterlandmarkdetection.
NumberofPeopleintheImage:Inordertoevaluatethesocial
EyeLandmarks 280 Contains2Dand3Dlandmarksdescribing
contextoftheimages,weemployedtheVQAmodeltodetermine
variouspositionsoftheeye.
thenumberofpeoplepresentineachimage.Thisinformationpro-
HeadPose 6 Describestranslationinmillimeterswithre-
videsinsightintousersâ€™socialinteractionsandtheirsurroundings
specttocameracentreandrotationinradi-
duringdeviceusage.Weasked:â€œHowmanypeopleareintheimage?â€.
ansaroundx,y,andzaxes.
RigidityParameters 40 Theseparametersaredividedintorigidand
ByleveragingtheBLIPVQAmodel,weareabletoextractstruc-
non-rigid shape parameters. Rigid shape
turedinsightsaboutthecontentandcontextofin-the-wildimages, parametersdescribethefaceâ€™spositioning
enhancingourunderstandingofuserbehaviorandinteractionwith withinanimagethatincludesaspectslike
their devices in diverse settings. Importantly, two expert anno- scale,rotation,andmovement.Conversely,
thenon-rigidshapeparametersfocusonthe
tatorsmanuallyannotated1500uniqueimagescorrespondingto
variationsinfacialappearancecausedbyin-
individualEMAs.Toclarifyanyambiguities,weprovidedthem
dividualcharacteristicsorexpressions,such
withspecificinstructions.Theydeterminedtheimageanglebased asvariationsinfacialwidthorheight,smiles,
oneyelevelwiththephone.â€˜Dominantcolorâ€™referstothemost blinking,andotherfacialexpressions.
prominentcolorintheoverallimage.Forlightingconditions,â€˜well- 2DLandmarks[5] 136 Thesearexandyaxeslocationsofdiffer-
litâ€™representsthebestlightingcondition,whileâ€˜poorlylitâ€™indicates entfacelandmarksintheimage.Theseland-
theworst.Aftercompletingthemanualannotation,wecalculated marksrefertospecificlocationsintheface.
Forexample,apointintherighteyeisrepre-
theaverageaccuracybetweenthetwoannotatorsandtheinter-
sentedaslandmarknumber38,whilepoints
rateragreementusingCohenâ€™skappa(ğœ…).Theseresults(seeTable
inthelipsarerepresentedusingnumbers
3)indicatesubstantialagreementbetweentheannotatorsandalign- 49-68.Alllandmarknumbersaredescribed
mentwithVQAresponses,indicatinghighreliability,consistency in[65,66].
andaccuracy. 3DLandmarks[5] 204 Thesearex,y,andzaxeslocationsofdiffer-
entfacelandmarksintheimage.Theland-
3.5 DepressionClassificationandRegression marknumbersareidenticalto2Dlandmarks,
however,theyarerepresentedusingthree
In this study, we aim to accurately identify depression from fa- coordinates.
cialimagesbyutilizingbothmachinelearninganddeeplearning
techniques.Inparticular,webuildbinaryclassificationmodelsto
classifyafaceimageasdepressedornotdepressed,andaregression overallmodelperformance.WeuseaLogisticRegression[32]model
modeltopredicttherawPHQ-8score(seeSection3.3). forclassificationandanElasticNet[79]forourregressiontask,
whereasaRandomForest(RF)[11]isusedforbothtasks.Statistical
3.5.1 MachineLearning. Tofacilitatemachinelearningapproaches,
approachessuchasregressionandabagging-baseddecisiontree
weextract711(709trainable)facialfeaturesusingOpenFace[6],
canprovidedifferentmodelinginsights.ThebaselinemodelisaRF
awell-validatedfeaturesetfordepressiondetectionthathasbeen
trainedusingtheparticipantâ€™sgender,age,andtimespentonEMA.
employedinavarietyofstudies[28,58,64].Theextractedfeatures
consistof2Dand3Dfaciallandmarks,headpose,eyegaze,facial 3.5.2 DeepLearning. Deeplearningmodelsarecapableoflearn-
expressionsrepresentedbyfacialactionunits(FAU),andrigidand ingusefulfeaturesdirectlyfromrawimages.Pre-trainedcomputer
non-rigidshapeparameters(seeTable2).Beforetraining,weapply visionmodelstrainedonlarge-scaledatasetscancaptureimagefea-
featureselectionusingonlythetrainingsetintwodistinctways. turesthataretransferabletootherdomains.Asaresult,weexamine
First,wecomputethemutualinformation(MI)metric,selecting theperformanceofvariousEfficientNet[70]andInceptionResNetv3
themostindependentfeaturesindicatedbysmallerMIvalues.In variants,whichwerepreviouslytrainedontheImageNetandVG-
ouranalysis,wechoosethetop25%,50%,or100%ofthefeatures. GFace2datasets,respectively.UponobservingthattheEfficientNet
Second,weconductanablationstudytogainvaluableinsightsinto B0(EffNet)modelprovidedthebestperformancewhileothermod-
theeffectivenessofdifferenthand-craftedfeatures,thusinferring elswereunderfittingourdataset,wedecidedtofurtherfine-tune
thebestperformingfeatureset.Anablationstudyisasystematic EffNetfordepressionprediction.WeimplementEffNetusingthe
experimentalprocedureinwhichcertainfeaturesaresystematically PyTorchframework,freezingalllayersduringthetrainingprocess
removed or â€œablatedâ€ to analyze their individual impact on the exceptforblocks6and7.TheclassificationandregressionmodelsMoodCapture:DepressionDetectionUsingIn-the-WildSmartphoneImages CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA
arefine-tunedusingbinarycross-entropyandmeanabsoluteerror intheimage.Furthermore,ğœ…isgreaterthan0.70forallquestions
lossfunctions,respectively.Foroptimization,weusetheAdamopti- indicatingsubstantialinter-rateragreement.Intermsofcapture
mizer(withalearningrateof0.0001)withabatchsizeof256trained angle,theimagespredominantlyfavoredalowangle,withapprox-
for50epochs.Thisfine-tuningprocessallowsthemodeltolearn imately96.08%fallingintothiscategory.Conversely,amere3.92%
andadapttothespecificcharacteristicsofourdepressiondetection werecapturedfromahighangle,suggestingaspecificuserposture
dataset,potentiallyimprovingitsperformanceandgeneralizability. ordeviceinteractionhabitinthemajorityofinstances.Dissecting
thedominantcolorspresent,wefoundthatâ€˜whiteâ€™emergedas
3.5.3 Evaluation. Toeffectivelyevaluateourmodels,weadopta
theprevailingcolor,characterizingroughly67.51%ofthedataset.
5-foldleave-subject-outcross-validationapproach.Thismethod
Othernoticeablecolorsincludedâ€˜blackâ€™at8.70%,whileacombined
ensures that all images associated with a single participant are
representationofâ€˜brownâ€™,â€˜blueâ€™,â€˜grayâ€™,andâ€˜yellowâ€™accountedfor
exclusivelyusedfortraining,validation,ortestingthemodelbut
approximately18%.Adiversearrayofotherhuesconstitutedthe
notmixedamongthesubsets.Furthermore,weusenestedcross-
remaining5.75%,emphasizingtherichnessofuserenvironments.
validationonourtrainingdataforhyper-parametertuning.The
Closeranalysisduringtheannotationprocessrevealedthattheim-
subject-independentsplitsandcross-validationensureourresults
agesâ€™dominantwhitecolormainlyreflectsenvironmentalelements
aremorerobustthanthoseofasingletrain-teststrategy.Weevalu-
likewhitewallsandceilings,notparticipantsâ€™skintones.Impor-
ateclassificationperformanceusingbalancedaccuracy(Equation1)
tantly,wenoticedmostimagesconsistedofpartialfaceimages,an
andMatthewâ€™sCorrelationCoefficient(MCC)(Equation2),whereas
observationcommonlyfoundinothersimilarstudies[36].Hence,
regressionperformanceisevaluatedusingMAE(Equation3).We
thedominantcolorisinfluencedbybackgroundobjects.Thisis
chosethesemetricsastheyprovideacomprehensiveassessment.
evidencedinFigure4,wherewalls,ceilings,tilesandlightsare
Forexample,MCCsummarizesallfourvaluesintheconfusion
frequentlyidentifiedasbackgroundobjects,ensuringouranalysis
matrix,whereasbalancedaccuracyemphasizesbothtruepositive
focusesonenvironmental,notphysiological,aspects.Thelight-
andtruenegativedetection.Infact,MCCispreferredoverF1score
ingconditionsunderwhichtheseimagesweretakenwerealso
inmanybinaryclassificationproblems[13].
revealing.Avastmajority(80.57%)werecapturedunderwell-lit
ğ‘‡ğ‘ƒ ğ‘‡ğ‘
+
BalancedAccuracy=
ğ‘‡ğ‘ƒ+ğ¹ğ‘ ğ‘‡ğ‘+ğ¹ğ‘ƒ
(1)
2
ğ‘‡ğ‘ƒÃ—ğ‘‡ğ‘ âˆ’ğ¹ğ‘ƒÃ—ğ¹ğ‘
ğ‘€ğ¶ğ¶ = (2)
âˆšï¸ (ğ‘‡ğ‘ƒ+ğ¹ğ‘ƒ)(ğ‘‡ğ‘ƒ+ğ¹ğ‘)(ğ‘‡ğ‘ +ğ¹ğ‘ƒ)(ğ‘‡ğ‘ +ğ¹ğ‘)
whereğ‘‡ğ‘ƒ,ğ‘‡ğ‘,ğ¹ğ‘ƒ,andğ¹ğ‘ aretruepositives,truenegatives,false
positives,andfalsenegatives,respectively.Notethathigherbal-
ancedaccuracyandMCCvaluesindicatebetterperformance.MCC
rangesfrom-1to+1,where+1,0and-1indicateperfectclassifica-
tion,randomcoin-tossclassification,andperfectmis-classification,
respectively.TheregressionmodelsareevaluatedusingMAEde-
finedas:
ğ‘
1 âˆ‘ï¸ Figure4:Backgroundobjects:WordCloudshowingtherange
ğ‘€ğ´ğ¸= ğ‘ |ğ‘¦ ğ‘– âˆ’ğ‘¦Ë†ğ‘–| (3) ofobjectsdetectedinthebackgroundoftheimagescaptured.
ğ‘–=1 (Acc=91.72;ğœ…ğœ…ğœ…=0.70)
whereğ‘ isthenumberofsamples.ğ‘¦ ğ‘–andğ‘¦Ë†ğ‘–aretrueandpredicted
PHQ-8scores,respectively.NotethatlowerMAEvaluesindicate
conditions,indicatingoptimalsettingsforsmartphoneinteraction.
betterperformance.
Thedimlylitandpoorlylitcategoriesfollowedwith10.35%and
9.08%,respectively,showcasingthevariedambientconditionsin
4 RESULTS
whichusersinteractwiththeirdevices.Furthermore,intermsof
Inthissection,wepresenttheoutcomesofouranalysis,which photo location, an impressive 95.08% of the images were taken
includesanexaminationofimagecharacteristics,anevaluationof indoors,signifyingtheprimaryenvironmentforuser-deviceinter-
thepredictivecapabilitiesofourmachinelearningmodels,andan action.Theoutdoorsegment,constituting4.92%,providedinsight
ablationstudy.Inaddition,weidentifycrucialfeaturesintegralto intothemoredynamicandmobileinteractionsusersmightexpe-
ourmodelsâ€™performanceandexplorepotentialbiaseswithinthese rience.Notably,95.81%ofthecapturedimagesfeaturedonlyone
models. person.Regardingbackgroundobjects,wediscoveredthatwalls,
lights,pictures,andwindowswerethemostcommonelements.The
4.1 ImageCharacteristics
presenceoftermssuchas"pillow"couldimplyindividualsreclining,
OuranalysisusingtheVQAmodelrevealmanyinsightsintodiffer- whilewordslike"plant,""moon,""flower,"and"cloud"mightsuggest
entfeaturesofreal-worldsmartphoneimages.Theseimagesserve outdoorsettings.Overall,itappearsthatasignificantnumberof
asglimpsesintouserinteractionsandsurroundings.FromTable3 imageswerecapturedindoorsagainstplainbackdrops,possibly
andFigure4,wenoticethattheVQAobtainedgoodaccuracyrang- withinhomesoroffices.Tovisuallyrepresentthesebackground
ingfrom89%forlightingconditionsto97%fornumberofpeople objects,wehavecreatedawordcloud,whichcanbeseeninFigure4.CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA NepalandPillaietal.
Table3:ImageCharacteristics:Differentcharacteristicsof importanceofconductinganablationstudytodeterminethemost
theimagecaptured,suchasimageangle,dominantcolors, impactfulfeaturesforouranalysis.
lightingconditions,photolocationandnumberofpeople Insummary,anRFtrainedwith3Dlandmarksperformswell
present.TheaccuracyandCohenâ€™skappaarepresentedin acrossbothclassificationandregressiontasksindicatedbywell-
bracesnexttothecategories.Theseresultsindicatesubstan- balancedscoresacrossbalancedaccuracy(0.60),MCC(0.14),and
tialagreementbetweentheannotatorsandalignmentwith MAE(130.31).Moreover,RFoffersbetterexplainabilitycompared
VQAresponses,indicatinghighreliability,consistencyand todeeplearningmethods,makingitanidealchoiceforpost-hoc
accuracy. analysis(Section4.4).Ourinvestigationintodepressiondetection
andPHQ-8predictionusingmachinelearninganddeeplearning
Characteristics Count methodsprovidesimportantinsightsintothepotentialofdiffer-
ImageAngle(Acc=96.67;ğœ…=0.82) enttechniqueswhenappliedtoMoodCapturedatainnaturalistic
conditions.Theresultsemphasizetheimportanceofconsidering
Lowangle 105,949(96.08%)
arangeofmethods,fromdeeplearningmodelscapableoflearn-
Highangle 4,323(3.92%)
ingcomplexfeaturestotraditionalmachinelearningtechniques
DominantColors(Acc=96.81;ğœ…=0.75)
thatofferinterpretabilityandsimplicity.Bycarefullyselectingand
White 744,14(67.51%)
fine-tuningthesemodels,wecanimprovetheoverallperformance
Black 9,586(8.70%)
and applicability of depression detection systems in real-world
Brown 6,053(5.49%)
scenarios.
Blue 5,809(5.27%)
Gray 5,197(4.72%)
Other 9,213(8.31%)
4.3 AblationStudy
LightingConditions(Acc=89.03;ğœ…=0.81)
Welllit 88,843(80.57%) Inthisanalysis,weaimedtodetermineifspecificOpenFacefeature
Dimlylit 11,418(10.35%) setsaremoreusefulfordepressiondetectionbyevaluatingthe
Poorlylit 10,011(9.08%) performanceacrossthesevengroups(Facialactionunits,Gaze,
Eyelandmarks,Pose,RigidityParameters,2Dand3Dlandmarks).
PhotoLocation(Acc=98.27;ğœ…=0.71)
FromTable5,wemakeseveralinterestingobservationsthatprovide
Indoors 104,800(95.08%)
insightsintotheutilityofindividualfeaturesets.
Outdoors 5,472(4.92%)
First,wenoticethatmanyfeaturesetsperformbetterthanthe
No.ofPeopleintheImage(Acc=97.89;ğœ…=0.75)
automaticfeatureselectionusingMI,indicatingthatonlysome
One 105,657(95.81%)
specificfeaturesintheimageareusefulfordepressiondetection.
Two 523(0.47%)
Thisfindingsuggeststhatamorefocusedapproachtofeatureex-
Three+ 8(0.01%)
tractionandselectionmayimproveoverallperformance.Second,
None 4084(3.71%)
weobservethatfacialactionunitsarelessdiscriminativethanother
features.Thisresultmaybeattributedtothepresenceofpartialface
images,whicharecommoninfront-facingcameras,thushindering
4.2 PredictiveAnalysis
theeffectivenessofactionunitsindetectingdepression.Third,we
In our analysis, we leveraged both machine learning and deep findthatgazefeaturesoutperformeyelandmarks,suggestingthat
learningtoassessMoodCaptureâ€™sabilitytodetectdepressionin gazedirectionandangleareuseful.Theseobservationshighlight
naturalsettings.AsshowninTable4,theEffNetmodelshowsbetter theimportanceofcapturingsubtlefacialchangeswhendeveloping
performanceincorrectlyidentifyingclasses,asevidencedbyits depressiondetectionsystems.
0.61balancedaccuracy.However,itisinterestingtonotethatthe Table5alsoindicatesthat3DLandmarksisthebestperforming
RFmodeloutperformsthedeeplearningmodelintermsofoverall featuresetforclassificationandPHQ-8predictionacrossallmetrics
classification (MCC of 0.14) and regression task i.e., predicting (balancedaccuracy=0.60;MCC=0.14;MAE=130.31).Theseresults
PHQ-8 scores (with an MAE of 130.31). Notably, RF achieves a suggestthatanRFtrainedwith3Dlandmarksismoreaccurate,
lowerMAEthanthebaselinemodel(130.31vs.138.18),indicating correlatesbetterwiththegroundtruth,andhaslowerPHQ-8pre-
anapproximately6%improvement.Thismakesitmorerobustfor dictionerrorsthanothermethods.3Dlandmarks(seeTable2)are
handlingmeasurementerrorswhensettinggroundtruththresholds coordinatesofspecificpointsontheface.Forexample,apointin
forclassification. therighteyeisrepresentedaslandmarknumber38.Thislocationis
Furthermore,wegainseveralmodelinginsightsfromTable4. representedusingcoordinates.Alllandmarknumbersaredescribed
First,weobservethatRFoutperformsLRacrossallmetrics,suggest- in[65,66].Intuitively,differentvaluesof3Dlandmarkscorrespond
ingthatdecisiontreeswithbaggingareusefulinmodellingface tochangesinfacialexpressionsovertime.
featuresfordepression.RFâ€™sabilitytomodelnon-lineardependen- Inconclusion,theablationstudyprovidesvaluableinsightsinto
ciesandin-builtfeatureselectionmakesitagoodcandidateforour theutilityofspecificfeaturesetsfordepressiondetection.Byun-
problem.Second,wenoticethatmanualfeatureselection,suchas derstandingthestrengthsandlimitationsofindividualfeatures,
using3Dlandmarksofferbetterperformancethanusingautomatic researchersandpractitionerscanmakeinformeddecisionswhende-
featureselectionmethodswithMI.Thisfindingunderscoresthe signingandimplementingdepressiondetectionsystems,ultimatelyMoodCapture:DepressionDetectionUsingIn-the-WildSmartphoneImages CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA
Table4:Performance:Depressiondetectionusingmachinelearninganddeeplearningmethods.Standarddeviationisgivenin
braces.â€˜LR+ENâ€™referstologisticregressionfordepressionclassificationandelasticnetforregressioni.e.,rawPHQ-8score
prediction.ğ‘…ğ‘…ğ‘…222valuesarepresentedinAppendixB.
Method BalancedAccuracyâ†‘ MCCâ†‘ MAEâ†“
Baseline 0.52(0.05) 0.03(0.11) 138.18(3.71)
LR+EN(MI) 0.52(0.02) 0.04(0.03) 135.40(2.65)
RandomForest(MI) 0.54(0.02) 0.06(0.04) 134.45(2.05)
RandomForest(3DLandmarks) 0.60(0.04) 0.14(0.08) 130.31(3.94)
EffNet 0.61(0.02) 0.03(0.00) 137.19(3.67)
Table5:AblationStudy:Investigatingdepressiondetection
ofOpenFacefeaturesetsusingarandomforest.Thestandard
deviationispresentedinbraces.ğ‘…ğ‘…ğ‘…222valuesarepresentedin
AppendixB.
FeatureSet BalancedAccuracyâ†‘ MCCâ†‘ MAEâ†“
FacialActionUnits 0.54(0.02) 0.06(0.04) 133.34(3.02)
Gaze 0.55(0.02) 0.10(0.05) 132.57(3.11)
EyeLandmarks 0.54(0.02) 0.08(0.04) 132.04(2.90)
HeadPose 0.55(0.03) 0.11(0.05) 131.01(3.68)
RigidityParameters 0.55(0.05) 0.06(0.04) 133.11(3.08)
2DLandmarks 0.53(0.03) 0.05(0.06) 132.62(3.41)
3DLandmarks 0.60(0.04) 0.14(0.08) 130.31(3.94)
improvingoverallperformanceandapplicabilityinreal-worldsce-
(a)Importantfeaturesfordepressionclassification.
narios.
4.4 MachineLearningFeatureImportance
Itiscrucialtounderstandimportantfacefeaturesthatarecorrelated
withdepression.Therefore,weemployapost-hocexplainability
approach,namelySHapleyAdditiveexPlanations(SHAP)[49],to
investigateourbestperforming(Table4)RandomForestmodel.
SHAPexplainsthemodeloutputsusingnotionsfromgamethe-
ory.Itassignseachfeatureanimportancevalueforaparticular
prediction,offeringinsightsintohowandwhyamodelmakesits
decisions.
Thetoptenimportantfeaturesfordepressionclassificationand
regressionareshowninFigure5.Here,weobservethatlipsand
facecontourpositionareusefulforbothdepressionclassification
andscoreprediction.Forinstance,wenoticethatlargervaluesof
facecontourneartheleftcheek(X_14,X_13,X_11)influencethe
modeltowardspredictingdepressionandpushtherawPHQ-8score (b)Importantfeaturesforpredictingrawdepressionscore.
higher.Interestingly,wefindthatimportanteyeandlipfeatures
occurontherightsideoftheface(Y_48,Y_36,Y_17,Y_41);and Figure5:SHAPplotsdescribingthetop10featuresforthe
highervaluesareassociatedwithhigherdepressionscores.This classificationandregressiontasks.Thebestperformingran-
indicatesthattheMLmodelcapturesasymmetryassociatedwith domforesttrainedusing3Dlandmarkfeaturesisevaluated
front-facingcamerapictures,i.e.,therightsideofthefacecouldbe usingSHAP.Thefeaturesarexandyaxiswiththenumbers
morevisible.WediscussthisfurtherinSection6. (0-indexed)correspondingtofaciallandmarks[65,66].
4.5 InvestigatingBiasinMachineLearning
Ourdatasetpredominantlyconsistsofwhitefemales,highlighting groupsforgender:females,andacombinedgroupofmalesandnon-
theneedtoassessbiasesinourmachinelearningmodelsrelated binaryindividuals.Wemadethedecisiontocombinethegroupsdue
togenderandrace.Thus,wecategorizethetestdatasetintotwo tothenotablysmallerrepresentationofnon-binaryindividualsandCHIâ€™24,May11â€“16,2024,Honolulu,HI,USA NepalandPillaietal.
themodelwasmoreeffectiveforwhiteparticipantsinboththe
classificationandregressiontasks.Thesebiaseslikelystemfrom
thepredominanceofwhitefemalesinourdataset,alimitationthat
wediscussinSection7.Ouranalysisofthesebiasesisintended
toenhancetransparencyinmachinelearningmodels,providing
insightsforfutureresearchinthisarea.
5 ETHICALCONSIDERATIONSANDUSER
ACCEPTANCE
(a)Gender-wiseperformancecomparison
Figure7:ComfortLevel:Participantâ€™scomfortwiththeauto-
matedcaptureoftheirphotos.
Instudiesinvolvingsensitivementalhealthdata,itisparamount
toaddresstheethicalimplicationstosafeguardparticipantsâ€™privacy,
confidentiality,andwell-being.Ourprimarygoalwastoprioritize
(b)Race-wiseperformancecomparison thesecurityandconfidentialityofthedata.Wesecurelystoredall
collecteddataandgrantedaccessonlytospecificteammembers.
Figure6:Randomforestperformanceonsub-populations Wetookgreatcareinremovingallpersonallyidentifiableinfor-
dividedbygenderandrace.Notethatbalancedaccuracyand mationbyimplementingathoroughanonymizationprocess.To
MCCaremultipliedby100forbettervisualization. respectprivacy,anyimagethatunintentionallycapturedsubjects
ornuditywasidentifiedduringareviewbytwoteammembersand
subsequentlydeleted.Weunderstandthesensitivenatureofmental
malesinourstudy.Thisdecisionaimedtoaddresstheimbalanceand healthandmadesuretomaintaintransparencywithourpartici-
ensureamoremeaningfulanalysis,acknowledgingtheconstraints pants.Theywereinformedaboutthestudyâ€™spurpose,methodology,
posedbythelimitedsamplesizesofthesespecificdemographic andexpectedoutcomes.Thisapproachnotonlysoughttheirpermis-
groups.Similarly,weclassifythedataintowhiteandnon-white sionbutalsoensuredtheyfeltcomfortableandsafethroughoutthe
categoriesforrace.Again,thisbinarygroupingstrategyisdesigned process.Wefurtherclarifiedthattheircompensationwasunrelated
toincreasegroupsizes,therebyimprovingthestatisticalpower totheirphotos.
ofouranalysis.WeuseourbestperformingRFmodelforthese Attheendofthestudy,weaskedparticipantsabouttheircomfort
evaluations. levelswithautomatedfront-facingphotocaptureduringsurveys.
Figure 6 displays the performance results of our models, re- Thiswasoptional,sowehaveresponsesfromonly172outofthe181
vealingseveralnotableobservations.Firstly,asindicatedbyMCC participantsthatwererecruited.Approximately45%ofparticipants
scores,weobservethattheclassifierpredictionsshowsomecor- werecomfortable,while38%feltitwasintrusiveoruneasy,andthe
relationwiththegroundtruthatvaryinglevelsacrossdifferent remaining17%wereneutral.Ifparticipantswereuncomfortable,
gendersandraces.Secondly,asshowninFigure6a,theresultsfor wefurtheraskthemaboutspecificreasonsfortheirfeelingswhich
depressionclassificationandregressionvariedbygender.Specif- canbesummarizedintoafewkeythemes,asshownbelow.While
ically,wefoundthatdepressionclassificationwasmoreaccurate weacknowledgetheseconcerns,itisimportanttonotethatthe
forfemales,whereasPHQ-8scorepredictionsweremoreprecise studyfollowedstrictprivacyanddataprotectionguidelines.
for non-females, as indicated by their lower MAE. Thirdly, the (1) PrivacyandSurveillance:Participantsfeltuncomfortable
race-basedperformanceanalysisinFigure6bdemonstratedthat withtheideaofbeingwatchedormonitored,asitevokedaMoodCapture:DepressionDetectionUsingIn-the-WildSmartphoneImages CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA
senseofintrusionintotheirpersonalspace.Oneparticipant 6 DISCUSSION
mentioned,â€œIdonâ€™tlikebeingwatched.Iâ€™malreadyparanoid Inthissection,weprovideasummaryofourfindingsandengagein
whenitcomestocameras.â€ athoroughdiscussion,exploringtheimplicationsanduncovering
(2) AppearanceandSelf-Esteem:Severalparticipantsmen- thepotentialopportunitieshighlightedbyourresults.
tionedtheirdiscomfortwithhavingtheirphotostakendue
toconcernsabouttheirappearance.Oneparticipantstated,
6.1 Summaryofresults
â€œIdonâ€™twantpeopletoseephotosofmeâ€,whileanothersaid,
â€œIamveryuncomfortablewithmyappearancewhenIâ€™mde- Ourstudyinvestigatedthepotentialofusingin-the-wildsmart-
pressed.â€ phoneimagesanddeeplearningmodelsfordetectingdepression
(3) InappropriateSituations:Participantsworriedaboutthe andpredictingPHQ-8scores,aimingtocontributetothedevelop-
possibilityofphotoburstsbeingtakenduringinconvenient mentofuser-centeredandunobtrusivementalhealthassessment
orinappropriatemoments.Oneparticipantshared,â€œIfIwas tools.Theresultsofouranalysisprovidedvaluableinsightsintothe
comfortableandathome,duringsomeofthemImaynothave characteristicsofin-the-wildimages,theperformanceofmachine
beencompletelycovered.â€ learninganddeeplearningmodels,anduseracceptanceofsuch
(4) DataSecurity:Althoughparticipantswereawareofthe approaches.Theimagecharacteristicsanalysisrevealedthatmost
studyâ€™sdataprotectionmeasures,somestillexpressedcon- imageswerecapturedfromalowangle,indoors,andunderwell-lit
cernsaboutthesafetyandstorageoftheirimages.Onepar- conditions. These findings highlighted the participantsâ€™ natural
ticipantexpressed,â€œTheideaofmypicturebeingoutthere behaviorwiththeirsmartphones,emphasizingtheimportanceof
...althoughIknowitwastobeanalyzedwithAI.â€ consideringreal-worldHCIdynamicsindesigningmentalhealth
(5) LackofControl:Participantsfeltuneasyaboutnotbeing assessmenttools.
abletoreview,approve,ordeletethephotostakenduring Ourpredictiveanalysisdemonstratesthatarandomforestmodel
thebursts,aswellasnotknowingwhenthecamerawas trainedbymanuallyselecting3Dlandmarkfeaturesobtainsthe
active.Aparticipantshared,â€œHavingpicturestakenandnot bestoverallclassification(balancedaccuracyof0.60,MCCof0.14)
knowingwhattheylookedlikeoriftheywereembarrassingis and regression performance (MAE of 130.31). Interestingly, the
anuncomfortablethingtothinkabout.â€ EffNetdeeplearningmodelbarelybeatthisscoreforclassification
taskby0.01.Itcorrectlyidentifieddepressedandnon-depressed
participantswithabalancedaccuracyof0.61.Givenadditionalhigh
qualitydata,thedeeplearningmodelscouldimproveoverexisting
methods.Tosummarize,thesescoresarepromising.Theyareeven
Insummary,participantsâ€™concernsmainlyrevolvedaroundpri- morenoteworthyconsideringthatthefacialimageswerecaptured
vacy,self-esteem,potentialinappropriatesituations,datasecurity, usingadiverserangeofsmartphonedevicesâ€“87differentmodels
andcontrolovertheimages.Itisessentialtoconsiderthesecon- from9distinctbrands.Asthecameraqualityofthesedevicesvaries
cernswhendesigningandimplementingstudiesinvolvingphoto significantly,itisimportanttonotethattheresultsmaybeinflu-
burstsorsimilardatacollectionmethodstoensureparticipantsâ€™ encedbyfactorssuchasimageclarityandauto-focuscapabilities.
comfortandtrustintheresearchprocess.Acknowledgingthesen- Despitethesepotentiallimitations,ourfindingssupporttheecolog-
sitivenatureofourresearch,weofferedparticipantstheoptionto icalvalidityofthestudyandemphasizethepotentialofmachine
deletetheirphotosattheendofthestudyiftheyfeltuncomfort- learninganddeeplearningmethodsinanalyzingdepressionfrom
able.Interestingly,noparticipantschosethisoption,highlighting facialimages,evenwhencapturedinless-than-idealconditions.
the trust they placed in our research process and commitment Duringpost-hocanalysis,wegainedseveralinterestinginsights.
toethicalconduct.Weremainkeenlyawareofthepotentialfor Firstly,ourablationstudyindicatesthatsmallerdomain-specific
technologymisuse,especiallyinunauthorizedsurveillanceordata featuresetsperformbetterinbothourtasks.Specifically,wenotice
miningscenarios.Wehavetakenmeasurestominimizesuchrisks, that3Dlandmarks,gaze,andposeoffergoodperformanceacrossall
emphasizingthatourtechnologicaldevelopmentsareprimarily metrics.Byfocusingonthesefeatures,researcherscanpotentially
intendedashealthaids,nottoolsforunwarrantedmonitoring.Fur- improvetheoverallperformanceofmentalhealthassessmenttools.
ther,toaddressparticipantsâ€™concernsregardingprivacyanddata Secondly,ourexplainabilityanalysisrevealedthatlargervalueson
security,onepossiblesolutioncouldbeleveragingthecapabilities therightsideofthefacehaveanimpactonbothdepressiondetec-
ofAIchipsonsmartphones.Byconductingallimageclassification tionandPHQ-8scoreprediction.Thisfindingsuggeststhatpeople
andprocessingonthedeviceitself,noimageswouldneedtobe hold phones in a way that emphasizes the asymmetry of front-
transmittedorstoredexternally.Thisapproachcouldsignificantly facingfaceimages.Thirdly,ourinvestigationintobiaseswithin
alleviateusersâ€™concernsabouttheirimagesbeingstoredoraccessed machinelearningmodelsofferscrucialinsightsforfutureresearch,
byunauthorizedparties.AsAItechnologycontinuestoadvance, particularlyintermsofimprovinggeneralizationandguidingdata
incorporatingon-deviceprocessingcapabilitiesintoourresearch collectionstrategies.Intermsofuseracceptance,wefounddiverse
methodologymaynotonlyincreaseusertrustandcomfortbutalso responsesregardingparticipantsâ€™comfortlevelswithautomated
pavethewayforanewgenerationofprivacy-focusedhealthaids. front-facingphotocapture.Whilesomeparticipantswerecomfort-
Inlinewithourcommitmenttoethicalconduct,wewillcontinueto ablewiththeprocess,othersfeltuneasyduetoconcernsrelated
exploreandimplementsuchtechnologicaladvancementstoensure toprivacy,self-esteem,inappropriatesituations,datasecurity,and
theprotectionofparticipantsâ€™dataandprivacyinourresearch. controlovertheimages.TheseconcernshighlighttheneedforCHIâ€™24,May11â€“16,2024,Honolulu,HI,USA NepalandPillaietal.
carefulconsiderationofethicalimplicationsindesigningandim- disorderscontinuetoimpactindividualsandcommunitiesworld-
plementingstudiesinvolvingphotoburstsorsimilardatacollection wide,adoptingnovelapproachesliketheonepresentedinourstudy
methods. cancontributetomoreeffectivepreventionstrategies,earlyinter-
Inconclusion,ourresearchhighlightsthepotentialofusingin- vention,andresourceallocation.Thiscouldultimatelyleadtobet-
the-wildsmartphoneimages,machinelearninganddeeplearning termentalhealthoutcomesandoverallwell-beingforindividuals
modelsfordepressionanalysis,offeringamoreobjective,unob- acrossvariousdemographicandculturalcontexts.Insummary,the
trusive,andcontinuousapproachtomentalhealthassessment.By implicationsofourstudyextendwellbeyondtheimmediatefind-
carefullyconsideringtheinsightsgainedfromouranalysisand ings,offeringvaluableinsightsforarangeofstakeholdersworking
addressingtheethicalimplications,researchersandpractitioners at the intersection of mental health, digital health, and human-
canworktowardsdevelopinguser-centered,effective,andethically computerinteraction.Byconsideringuseracceptance,exploring
soundtoolsformentalhealthassessmentandintervention. thepotentialofsmartphoneimagesformentalhealthassessment,
andrecognizingthebroaderpublichealthcontext,ourstudycon-
tributestothedevelopmentofmoreeffective,user-friendly,and
6.2 Implications
contextuallyappropriatementalhealthassessmenttoolswiththe
Thefindingsfromourstudyholdsignificantimplicationsforvar- potentialtoimprovethelivesofindividualsaffectedbydepression.
ious stakeholders, including researchers, practitioners, and pol-
icymakers in the fields of mental health, digital health, human-
7 LIMITATIONS
computerinteraction(HCI),andpublichealth.
Ourresearchhighlightsthepotentialofutilizingsmartphone Ourstudywhileprovidingvaluableinsightsintotheuseofin-the-
imagesandmachinelearningmodelsasasupplementarymethod wildsmartphoneimagesanddeeplearningmodelsfordepression
formentalhealthassessment.Thisinnovativeapproachencourages detection,hassomelimitationsthatshouldbeacknowledged.First,
theexplorationofalternativewaystoassessmentalhealththatcan ourstudyâ€™sdatasetmaybelimitedinsizeanddiversity,asitcon-
complementtraditionaltoolssuchasself-reportquestionnairesand sistsofarelativelysmallnumberofparticipants.Additionally,it
clinicalinterviews.Whileourdatawascollectedfromparticipants isimportanttorememberthatourdatasetisprimarilycomposed
whohadmajordepressivedisorder,theresultspavethewayfor ofwhitefemales.Althoughourmodelscurrentlyshowbetterper-
future researchto investigatethe broaderapplicabilityof these formanceforfemalesinclassificationtasksandfornon-females
methods,potentiallyleadingtoabetterunderstandingofdepres- inregressiontasks,expandingourdatasettoincludemorediverse
sionandimprovedmentalhealthsupportovertime.Consequently, samplesisnecessary.Byincorporatingadditionaldatathatrepre-
promotingtimelyaccesstoappropriateinterventionsandsupport sentsabroaderspectrumofthepopulation,wecanensureamore
systems. comprehensiverepresentation.Thisexpansionwillnotonlyen-
FromanHCIperspective,ourstudyunderscorestheimportance hancetherobustnessofourfindingsbutalsosignificantlyimprove
ofconsideringuseracceptancewhendevelopingmentalhealthas- the generalizability of our results across different demographic
sessmenttoolsthatutilizesmartphoneimagesandmachinelearn- groups.Furthermore,thestudyreliesonself-reporteddata,such
ing.Recently,therehasbeenagrowinginterestamongresearchers asdepressionscores,whichmaybesubjecttobiases,including
tointegrateuseracceptanceintothetrainingphaseofmachine socialdesirabilityandrecallbias.Futureresearchcouldbesignifi-
learningmodels,asproposedinstudieslike[10,47].Inarelated cantlyenhancedbyincludingmoreobjectivemeasuresofmental
observation, our feature importance analysis indicated that the health,suchasclinicalevaluationsorphysiologicalindicators.In
rightsideofthefaceismoreusefulindepressiondetection.This ourstudy,weadjustedeachitemâ€™sscoreonthePHQ-8fromits
phenomenoncouldbelinkedtothedominanceofright-handed original0-3rangetoabroader0-100scale.Asmentionedearlier,
individuals,oftenresultinginpartialfaceimagesthatcapturemore thepracticeofre-scalingpsychometricscalesisnotuncommonand
oftherightside.Variousstudiessupporttheideathathandedness hasbeenappliedtothePHQinvariouspaststudies[29,48,50,54].
influencesuserinteractionwithsmartphonesanduserexperience However,onelimitationofadaptingthePHQ-8toa0-100scale
(UX)[2,27,42,52].Therefore,futureresearchinHCIcouldbenefit isthepotentialforinconsistencieswhencorrelatingthesescores
fromfocusingondevelopingtoolsthatfacilitatethecaptureofthe withestablishedlevelsofdepressionseverity.Tomitigatethis,we
entirefacemoreeffectively.Forinstance,theworkbyNelavelliand proportionallyscaledtheoriginalscorestoderiveourdepression
Ploetz[52]exploresadaptiveappdesigntailoredtotheuserâ€™shand- categorization,strivingtopreservetheoriginalscoringsystemâ€™s
edness,whichcouldbeapromisingdirectionforenhancingface integrity.Additionally,ourpredictionmodelsconsiderboththeraw
imagecaptureinsmartphoneapplications.Insummary,understand- PHQscoresandtheadjustedclassscales,anapproachthataimsto
ingusersâ€™concernsandpreferencesiscrucialforcreatingtoolsthat balancedetailedgranularitywithtraditionalscoringvalidity.Itis
aremorelikelytobeadoptedandusedbythoseinneedofsupport. alsoimportanttohighlightthatallparticipantsinourstudyhad
ThisfocusonuseracceptancecaninspiretheHCIcommunityto receivedclinicaldiagnosesforMDD.However,wereliedonself-
designmentalhealthassessmenttoolsthatbalanceeffectiveness, reporteddatafortrackingdailydepressionlevels,whichfacilitated
privacy,anduserengagement,leadingtothedevelopmentofmore moreconsistentmonitoring.Ourstudyalsofocusedexclusivelyon
accessibleandinclusivedigitalmentalhealthsolutions. aclinicallydepressedcohort.Includinghealthyindividualsinthe
Inthebroadercontextofpublichealth,thestudyâ€™sfindingsem- datasetwouldhavebeenbeneficialfordevelopingamorecompre-
phasizetheimportanceofleveragingtechnologyandinnovative hensiveandaccuratepredictionmodel.Arandomizedcontrolled
methodstoaddressmentalhealthchallenges.Asmentalhealth trial(RCT)withhealthycontrolsorincorporatingadiversecohortMoodCapture:DepressionDetectionUsingIn-the-WildSmartphoneImages CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA
ofindividualsnotexperiencingdepressioncouldprovidevaluable weintendtoexplorethecombinationofthison-deviceprediction
insightsintothedifferencesbetweendepressedandnon-depressed approachwithfederateddeeplearning,wheremodelsaretrained
individualsandimprovethemodelâ€™sabilitytodistinguishbetween withoutsharingrawdataacrossanetworkinacentralentitysuch
them.Futureresearchshouldconsiderexpandingthedatasettoin- asaserverorcloud.Thisapproachcouldeffectivelyaddresssecu-
cludebothdepressedandhealthyindividuals,whichcancontribute rityconcernsassociatedwithcentralizeddatacollectionandthe
tothedevelopmentofmoreeffectiveandprecisementalhealth privacyissuesourparticipantsraisedduringtheacceptancestudy.
assessmenttools. Finally,werecognizethattheperformanceofthemodelsweconsid-
Anotherlimitationisthatthestudyprimarilyfocusesontheanal- eredforface-baseddepressiondetection,particularlydeeplearning
ysisofin-the-wildsmartphoneimagesandtheirrelationshipwith models,wouldbenefitsignificantlyfromalargerfacedataset.In
depression.However,theremaybeotherfactors,suchassocialin- theMoodCapturestudy,wecollectedover125,000imagesfrom
teractions,physicalactivity,andenvironmentalcontext,thatcould 177individualslivingwithdepressionoveraperiodof90days,
provideadditionalinsightsintodepressiondetection.Integrating representingawell-sizeddatasettodemonstratethepotentialof
thesefactorsintofutureresearchmayhelptodevelopmoreholistic thisidea.Iffutureface-baseddepressionstudieshaveaccessto
andaccuratepredictionmodels.Deeplearningmodels,whilepow- largerpoolsofnaturalisticimages(e.g.,VGGFace2,whichcontains
erfulandeffective,canoftenbeconsideredas"black-box"models over3millionfaceimages)collectedinthewild,weanticipatethat
withlimitedinterpretability.Thismaymakeitdifficulttounder- theaccuracyandcapabilitiesofthemodelswouldseesignificant
standthespecificfeaturesorpatternsthatthemodelhasidentified improvement.
asbeingrelatedtodepression.Futureresearchcouldexplorethe
useofmoreinterpretablemodelsortechniquestoprovideinsights ACKNOWLEDGMENTS
intotheunderlyingmechanismslinkingvisualcuesanddepression.
Wesincerelythanktheparticipantswhokindlyconsentedtoshare
Lastly,theuseofin-the-wildsmartphoneimagesformentalhealth
theirphotosforthisstudy.TheCHIreviewershelpedliftthispaper
assessmentraisesethicalandprivacyconcerns,whichneedtobe
considerably.Theirinsight,detailedcomments,andsuggestions
carefullyconsideredwhendesigningandimplementingsuchtools.
wereinvaluable.Wethankthemfortheirdiligenceandforcaring
Ensuringuserconsent,datasecurity,andtransparencyintheuseof
aboutthesubjectmatterandourpaper.Theresearchdiscussedin
personaldataiscrucialformaintainingtrustandfosteringtheadop-
thispaperwassupportedbytheNationalInstituteofMentalHealth
tionofthesetools.Addressingtheselimitationsinfutureresearch
(NIMH)underawardnumberR01MH123482-01.Weacknowledge
canhelptofurtheradvanceourunderstandingoftherelationship
thatthecontentofthismanuscriptissolelyourresponsibilityand
betweensmartphoneimages,deeplearningmodels,anddepres-
doesnotnecessarilyreflecttheviewsoftheNIMH.Wealsoclarify
siondetection,contributingtothedevelopmentofmoreeffective,
thatthefundingbodyhadnoinvolvementinthestudyâ€™sdesign,
user-centered,andethicallysoundmentalhealthassessmenttools.
datacollection,analysis,interpretation,ormanuscriptpreparation.
8 CONCLUSIONANDFUTUREWORK REFERENCES
Throughthisstudy,wehavedemonstratedthepotentialofusing [1] AwuniProsperMandelaAmaltingaandJamesFenibeMbinta.2020. Factors
associatedwithdepressionamongyoungpeopleglobally:anarrativereview.
in-the-wild smartphoneimages and machine learning to detect
InternationalJournalOfCommunityMedicineAndPublicHealth7,9(Aug.2020),
depression,offeringvaluableinsightsformentalhealthassessment, 3711. https://doi.org/10.18203/2394-6040.ijcmph20203949
HCIanddigitalhealth.Withthis,weaimtopavethewayformore [2] SinanAÅŸÃ§Ä±andKeremRÄ±zvanoÄŸlu.2014.Leftvs.right-handedUX:Acomparative
userstudyonamobileapplicationwithleftandright-handedusers.InDesign,
effectiveanduser-centeredmentalhealthassessmenttools.Ad- UserExperience,andUsability.UserExperienceDesignforDiverseInteractionPlat-
dressingthelimitationsofourstudyandbuildinguponitsfindings, formsandEnvironments:ThirdInternationalConference,DUXU2014,HeldasPart
ofHCIInternational2014,Heraklion,Crete,Greece,June22-27,2014,Proceedings,
futureresearchcancontributetothedevelopmentofmorerobust,
PartII3.Springer,173â€“183.
accurate,andethicallysoundmentalhealthassessmenttoolsthat [3] MihaiBÃ¢ce,SanderStaal,andAndreasBulling.2020. Quantificationofusersâ€™
havethepotentialtoimprovethelivesofindividualsaffectedby visualattentionduringeverydaymobiledeviceinteractions.InProceedingsofthe
2020CHIConferenceonHumanFactorsinComputingSystems.1â€“14.
depression.
[4] TadasBaltruÅ¡aitis,MarwaMahmoud,andPeterRobinson.2015.Cross-dataset
WhenweembarkedondesigningourMoodCapturestudytoin- learningandperson-specificnormalisationforautomaticactionunitdetection.
vestigatewhetherhigh-resolutionfacecapturefromphonescould In201511thIEEEInternationalConferenceandWorkshopsonAutomaticFaceand
GestureRecognition(FG),Vol.6.IEEE,1â€“6.
assessmood,wewereacutelyawareoftheethicalissuessurround- [5] TadasBaltrusaitis,PeterRobinson,andLouis-PhilippeMorency.2013. Con-
ingourresearchandthepotentialprivacyconcernsofapopulation strainedlocalneuralfieldsforrobustfaciallandmarkdetectioninthewild.In
ProceedingsoftheIEEEinternationalconferenceoncomputervisionworkshops.
thatincludedindividualsdiagnosedwithdepression.Asdiscussed
354â€“361.
inthesectiononEthicalConsiderationsandUserAcceptance,our [6] TadasBaltrusaitis,AmirZadeh,YaoChongLim,andLouis-PhilippeMorency.
studywasmeticulouslydesignedtosafeguarduserprivacythrough- 2018.Openface2.0:Facialbehavioranalysistoolkit.In201813thIEEEinternational
conferenceonautomaticface&gesturerecognition(FG2018).IEEE,59â€“66.
out,andwesoughttheirevaluationsoftheMoodCaptureapppost-
[7] AaronTBeck,RobertASteer,GregoryKBrown,etal.1987. Beckdepression
study.Thisinvaluablefeedbackformsthefoundationforfuture inventory.HarcourtBraceJovanovichNewYork:.
workinimage-basedmooddetectionwhichwebelieveisapromis- [8] AnasBelouali,SamirGupta,VaibhavSourirajan,JiaweiYu,NathanielAllen,Adil
Alaoui,MaryAnnDutton,andMatthewJReinhard.2021.Acousticandlanguage
ingtechnology.Onedirectionweplantopursueasournextstep analysisofspeechforsuicidalideationamongUSveterans.BioDatamining14,1
involves utilizing on-phone AI chips that are now available on (2021),1â€“17.
[9] JosÃ©ManoelBertolote,AlexandraFleischmann,DiegoDeLeo,andDanutaWasser-
top-endsmartphonestorundeeplearningmodelsdirectlyonthe
man.2003.Suicideandmentaldisorders:doweknowenough?BritishJournalof
device,ensuringthatimagesneverleavethephone.Additionally, Psychiatry183,5(Nov.2003),382â€“383. https://doi.org/10.1192/bjp.183.5.382CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA NepalandPillaietal.
[10] DjallelBouneffouf.2013.Applyingmachinelearningtechniquestoimproveuser Assessment80,1(Feb.2003),26â€“30. https://doi.org/10.1207/s15327752jpa8001_10
acceptanceonubiquitousenvironement.arXivpreprintarXiv:1301.4351(2013). [34] KaoriIkematsu,HarunaOshima,RachelEardley,andItiroSiio.2020. Investi-
[11] LeoBreiman.2001.Randomforests.Machinelearning45(2001),5â€“32. gatingHowSmartphoneMovementisAffectedbyLyingDownBodyPosture.
[12] StevieChancellorandMunmunDeChoudhury.2020. Methodsinpredictive ProceedingsoftheACMonHuman-ComputerInteraction4,ISS(2020),1â€“17.
techniquesformentalhealthstatusonsocialmedia:acriticalreview.NPJdigital [35] ManjuLataJoshiandNehalKanoongo.2022.Depressiondetectionusingemo-
medicine3,1(2020),43. tionalartificialintelligenceandmachinelearning:Acloserreview. Materials
[13] DavideChiccoandGiuseppeJurman.2020. TheadvantagesoftheMatthews Today:Proceedings58(2022),217â€“226.
correlationcoefficient(MCC)overF1scoreandaccuracyinbinaryclassification [36] MohamedKhamis,AnitaBaier,NielsHenze,FlorianAlt,andAndreasBulling.
evaluation.BMCgenomics21,1(2020),1â€“13. 2018.UnderstandingFaceandEyeVisibilityinFront-FacingCamerasofSmart-
[14] PrernaChikersal,AfsanehDoryab,MichaelTumminia,DaniellaKVillalba,Ja- phonesusedintheWild.InProceedingsofthe2018CHIConferenceonHuman
nineMDutcher,XinwenLiu,SheldonCohen,KaseyGCreswell,JenniferMankoff, FactorsinComputingSystems.ACM. https://doi.org/10.1145/3173574.3173854
JDavidCreswell,etal.2021.Detectingdepressionandpredictingitsonsetusing [37] KennethA.Kobak.2010.HamiltonDepressionRatingScale.,1pages. https:
longitudinalsymptomscapturedbypassivesensing:amachinelearningapproach //doi.org/10.1002/9780470479216.corpsy0402
withrobustfeatureselection.ACMTransactionsonComputer-HumanInteraction [38] XinruKong,YanYao,CuiyingWang,YuangengWang,JingTeng,andXianghua
(TOCHI)28,1(2021),1â€“41. Qi.2022. AutomaticIdentificationofDepressionUsingFacialImageswith
[15] AngÃ©liqueOJCramer,ClaudiaDVanBorkulo,ErikJGiltay,HanLJVanDerMaas, DeepConvolutionalNeuralNetwork. MedicalScienceMonitor28(June2022).
KennethSKendler,MartenScheffer,andDennyBorsboom.2016.Majordepres- https://doi.org/10.12659/msm.936409
sionasacomplexdynamicsystem.PloSone11,12(2016),e0167490. [39] KurtKroenke,RobertLSpitzer,andJanetBWWilliams.2001.ThePHQ-9:validity
[16] Victor-AlexandruDarvariu,LauraConvertino,AbhinavMehrotra,andMirco ofabriefdepressionseveritymeasure.Journalofgeneralinternalmedicine16,9
Musolesi.2020. Quantifyingtherelationshipsbetweeneverydayobjectsand (2001),606â€“613.
emotionalstatesthroughdeeplearningbasedimageanalysisusingsmartphones. [40] KurtKroenke,RobertLSpitzer,JanetBWWilliams,andBerndLÃ¶we.2010.The
ProceedingsoftheACMonInteractive,Mobile,WearableandUbiquitousTechnolo- PatientHealthQuestionnaireSomatic,Anxiety,andDepressiveSymptomScales:
gies4,1(2020),1â€“21. asystematicreview.Gen.Hosp.Psychiatry32,4(July2010),345â€“359.
[17] MunmunDeChoudhury,MichaelGamon,ScottCounts,andEricHorvitz.2013. [41] KurtKroenke,TaraWStrine,RobertLSpitzer,JanetBWWilliams,JoyceTBerry,
Predictingdepressionviasocialmedia.InProceedingsoftheinternationalAAAI andAliHMokdad.2009.ThePHQ-8asameasureofcurrentdepressioninthe
conferenceonwebandsocialmedia,Vol.7.128â€“137. generalpopulation.Journalofaffectivedisorders114,1-3(2009),163â€“173.
[18] JorgeAriasdelaTorre,GemmaVilagut,AntoniSerrano-Blanco,VicenteMartÃ­n, [42] AndreasKurniawan,NunnunBonafix,HendriHartono,etal.2020.DesignUI/UX
AntonioJosÃ©Molina,JoseMValderas,andJordiAlonso.2020. Accuracyof MobileGamesforLeftHandDominantPeople.JournalofGames,GameArt,and
Self-ReportedItemsfortheScreeningofDepressionintheGeneralPopulation. Gamification5,2(2020),48â€“53.
InternationalJournalofEnvironmentalResearchandPublicHealth17,21(Oct. [43] Young-ShinLeeandWon-HyungPark.2022.DiagnosisofDepressiveDisorder
2020),7955. https://doi.org/10.3390/ijerph17217955 ModelonFacialExpressionBasedonFastR-CNN.Diagnostics12,2(Jan.2022),
[19] MDeady,DAJCollins,DAJohnston,NGlozier,RACalvo,HChristensen, 317. https://doi.org/10.3390/diagnostics12020317
andSBHarvey.2021. Theimpactofdepression,anxietyandcomorbidityon [44] BrookeLevis,AndreaBenedetti,andBrettDThombs.2019. AccuracyofPa-
occupationaloutcomes.OccupationalMedicine72,1(Oct.2021),17â€“24. https: tientHealthQuestionnaire-9(PHQ-9)forscreeningtodetectmajordepression:
//doi.org/10.1093/occmed/kqab142 individualparticipantdatameta-analysis. BMJ (April2019),l1476. https:
[20] OmidVEbrahimi,JulianBurger,AsleHoffart,andSverreUrnesJohnson.2021. //doi.org/10.1136/bmj.l1476
Within-andacross-daypatternsofinterplaybetweendepressivesymptomsand [45] JunnanLi,DongxuLi,CaimingXiong,andStevenHoi.2022.Blip:Bootstrapping
relatedpsychopathologicalprocesses:adynamicnetworkapproachduringthe language-imagepre-trainingforunifiedvision-languageunderstandingand
COVID-19pandemic.BMCmedicine19,1(2021),1â€“17. generation.InInternationalConferenceonMachineLearning.PMLR,12888â€“12900.
[21] DavidMFergussonandLianneJWoodward.2002.Mentalhealth,educational, [46] DongdongLiu,BowenLiu,TaoLin,GuangyaLiu,GuoyuYang,DezhenQi,YeQiu,
andsocialroleoutcomesofadolescentswithdepression.Arch.Gen.Psychiatry YuerLu,QinmeiYuan,StellaC.Shuai,XiangLi,OuLiu,XiangdongTang,Jianwei
59,3(March2002),225â€“231. Shuai,YupingCao,andHaiLin.2022.Measuringdepressionseveritybasedon
[22] RitaFranceseandPasqualeAttanasio.2022. Emotiondetectionforsupport- facialexpressionandbodymovementusingdeepconvolutionalneuralnetwork.
ingdepressionscreening.MultimediaToolsandApplications82,9(Dec.2022), FrontiersinPsychiatry13(Dec.2022). https://doi.org/10.3389/fpsyt.2022.1017064
12771â€“12795. https://doi.org/10.1007/s11042-022-14290-0 [47] SaschaLÃ¶bner,SebastianPape,andVanessaBracamonte.2023.UserAcceptance
[23] RalphR.Frerichs,CarolS.Aneshensel,PatriciaA.Yokopenic,andVirginiaA. CriteriaforPrivacyPreservingMachineLearningTechniques.InProceedingsof
Clark.1982.Physicalhealthanddepression:Anepidemiologicsurvey.Preventive the18thInternationalConferenceonAvailability,ReliabilityandSecurity.1â€“8.
Medicine11,6(Nov.1982),639â€“646.https://doi.org/10.1016/0091-7435(82)90026-3 [48] HillaryD.Lum,EvanP.Carey,DianeFairclough,MaryE.Plomondon,Evelyn
[24] EikoIFried,JessicaKFlake,andDonaldJRobinaugh.2022. Revisitingthe Hutt,JohnS.Rumsfeld,andDavidB.Bekelman.2016. BurdensomePhysical
theoreticalandmethodologicalfoundationsofdepressionmeasurement.Nature andDepressiveSymptomsPredictHeartFailureâ€“SpecificHealthStatusOver
ReviewsPsychology1,6(2022),358â€“368. OneYear.JournalofPainandSymptomManagement51,6(June2016),963â€“970.
[25] EikoIFriedandRandolphMNesse.2015.Depressionisnotaconsistentsyndrome: https://doi.org/10.1016/j.jpainsymman.2015.12.328
AninvestigationofuniquesymptompatternsintheSTAR*Dstudy.Journalof [49] ScottMLundbergandSu-InLee.2017.Aunifiedapproachtointerpretingmodel
affectivedisorders172(2015),96â€“102. predictions.Advancesinneuralinformationprocessingsystems30(2017).
[26] VenkataRamaKiranGarimella,AbdulrahmanAlfayad,andIngmarWeber.2016. [50] RahulMajethia,VadlamudiPratikshaSharma,andRishikaDwaraghanath.2022.
Socialmediaimageanalysisforpublichealth.InProceedingsofthe2016CHI MentalHealthIndicesasBiomarkersforAssistiveMentalHealthcareinUniver-
ConferenceonHumanFactorsinComputingSystems.5543â€“5547. sityStudents.In202210thInternationalConferenceonAffectiveComputingand
[27] FilipNormanGolles.2017. Usabilityofmobileinterfaceswithregardstoleft- IntelligentInteraction(ACII).IEEE.https://doi.org/10.1109/acii55700.2022.9953847
handeduse.USCCS2017(2017),65. [51] WafaMelloukandWahidaHandouzi.2020. Facialemotionrecognitionusing
[28] YuanGongandChristianPoellabauer.2017.Topicmodelingbasedmulti-modal deeplearning:reviewandinsights.ProcediaComputerScience175(2020),689â€“694.
depressiondetection.InProceedingsofthe7thannualworkshoponAudio/Visual https://doi.org/10.1016/j.procs.2020.07.101
emotionchallenge.69â€“76. [52] KritiNelavelliandThomasPloetz.2018. AdaptiveAppDesignbyDetecting
[29] MelisaGumus,DanielleDDeSouza,MengdanXu,CeliaFidalgo,WilliamSimpson, Handedness.arXivpreprintarXiv:1805.08367(2018).
andJessicaRobin.2023.Evaluatingtheutilityofdailyspeechassessmentsfor [53] SubigyaNepal,WeichenWang,VladoVojdanovski,JeremyFHuckins,Alex
monitoringdepressionsymptoms. DIGITALHEALTH 9(Jan.2023). https: daSilva,MeghanMeyer,andAndrewCampbell.2022.COVIDStudentStudy:A
//doi.org/10.1177/20552076231180523 YearintheLifeofCollegeStudentsduringtheCOVID-19PandemicThrough
[30] SharathChandraGuntuku,DanielPreotiuc-Pietro,JohannesCEichstaedt,and theLensofMobilePhoneSensing.InProceedingsofthe2022CHIConference
LyleHUngar.2019.Whattwitterprofileandpostedimagesrevealaboutdepres- onHumanFactorsinComputingSystems(NewOrleans,LA,USA)(CHIâ€™22).
sionandanxiety.InProceedingsoftheinternationalAAAIconferenceonweband AssociationforComputingMachinery,NewYork,NY,USA,Article42,19pages.
socialmedia,Vol.13.236â€“246. https://doi.org/10.1145/3491102.3502043
[31] WeitongGuo,HongwuYang,ZhenyuLiu,YapingXu,andBinHu.2021.Deep [54] MinhXNguyen,H.LuzMcNaughtonReyes,BrianWPence,KateMuessig,
NeuralNetworksforDepressionRecognitionBasedon2Dand3DFacialExpres- HeidiEHutton,CarlALatkin,DavidDowdy,GeetanjaliChander,KathrynE
sionsUnderEmotionalStimulusTasks.FrontiersinNeuroscience15(April2021). Lancaster,ConstantineFrangakis,TeeradaSripaipan,VietHaTran,andVivianF
https://doi.org/10.3389/fnins.2021.609760 Go.2021.Thelongitudinalassociationbetweendepression,anxietysymptoms
[32] DavidWHosmerJr,StanleyLemeshow,andRodneyXSturdivant.2013.Applied andHIVoutcomes,andthemodifyingeffectofalcoholdependenceamongART
logisticregression.Vol.398.JohnWiley&Sons. clientswithhazardousalcoholuseinVietnam.JournaloftheInternationalAIDS
[33] MelissaHunt,JosephAuriemma,andAsharaC.A.Cashaw.2003.Self-Report Society24,S2(June2021). https://doi.org/10.1002/jia2.25746
BiasandUnderreportingofDepressionontheBDI-II. JournalofPersonalityMoodCapture:DepressionDetectionUsingIn-the-WildSmartphoneImages CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA
[55] JamesSOlverandMalcolmJHopwood.2013.Depressionandphysicalillness. [75] RuiWang,WeichenWang,AlexDaSilva,JeremyFHuckins,WilliamMKelley,
MedicalJournalofAustralia199,S6(Oct.2013). https://doi.org/10.5694/mja12. ToddFHeatherton,andAndrewTCampbell.2018.Trackingdepressiondynamics
10597 incollegestudentsusingmobilephoneandwearablesensing. Proceedingsof
[56] WorldHealthOrganization.2023.Mentaldisorders. https://www.who.int/news- theACMonInteractive,Mobile,WearableandUbiquitousTechnologies2,1(2018),
room/fact-sheets/detail/mental-disordersAccessed:[2023]. 1â€“26.
[57] A.Pampouchidou,K.Marias,M.Tsiknakis,P.Simos,F.Yang,andF.Meriaudeau. [76] ErrollWood,TadasBaltrusaitis,XucongZhang,YusukeSugano,PeterRobinson,
2015.Designingaframeworkforassistingdepressionseverityassessmentfrom andAndreasBulling.2015. Renderingofeyesforeye-shaperegistrationand
facialimageanalysis.In2015IEEEInternationalConferenceonSignalandImage gazeestimation.InProceedingsoftheIEEEinternationalconferenceoncomputer
ProcessingApplications(ICSIPA).578â€“583. https://doi.org/10.1109/ICSIPA.2015. vision.3756â€“3764.
7412257 [77] XuhaiXu,PrernaChikersal,AfsanehDoryab,DaniellaKVillalba,JanineM
[58] AnastasiaPampouchidou,OlympiaSimantiraki,C-MVazakopoulou,Charikleia Dutcher,MichaelJTumminia,TimAlthoff,SheldonCohen,KaseyGCreswell,
Chatzaki,MatthewPediaditis,AnnaMaridaki,KostasMarias,PanagiotisSimos, JDavidCreswell,etal.2019. Leveragingroutinebehaviorandcontextually-
FanYang,FabriceMeriaudeau,etal.2017.Facialgeometryandspeechanalysis filteredfeaturesfordepressiondetectionamongcollegestudents.Proceedingsof
fordepressiondetection.In201739thAnnualInternationalConferenceoftheIEEE theACMonInteractive,Mobile,WearableandUbiquitousTechnologies3,3(2019),
EngineeringinMedicineandBiologySociety(EMBC).IEEE,1433â€“1436. 1â€“33.
[59] ArvindPillai,SubigyaKumarNepal,WeichenWang,MatthewNemesure,Michael [78] XiuzhuangZhou,KaiJin,YuanyuanShang,andGuodongGuo.2018.Visuallyin-
Heinz,GeorgePrice,DamienLekkas,AmandaCCollins,TessGriffin,Benjamin terpretablerepresentationlearningfordepressionrecognitionfromfacialimages.
Buck,etal.2024.InvestigatingGeneralizabilityofSpeech-basedSuicidalIdeation IEEEtransactionsonaffectivecomputing11,3(2018),542â€“552.
DetectionUsingMobilePhones.ProceedingsoftheACMonInteractive,Mobile, [79] HuiZouandTrevorHastie.2005.Regularizationandvariableselectionviathe
WearableandUbiquitousTechnologies7,4(2024),1â€“38. elasticnet.JournaloftheRoyalStatisticalSocietySeriesB:StatisticalMethodology
[60] AlexanderRamos-Cuadros,LuisPalominoSantillan,andWillyUgarte.2021. 67,2(2005),301â€“320.
EvaluatingtheDepressionLevelBasedonFacialImageAnalyzingandPatient
Voice.InInternationalConferenceonInformationandCommunicationTechnologies
forAgeingWellande-Health.Springer,35â€“55.
[61] AndrewGReeceandChristopherMDanforth.2017.Instagramphotosreveal
predictivemarkersofdepression. EPJDataScience6,1(Aug.2017). https:
//doi.org/10.1140/epjds/s13688-017-0110-z
[62] JonathanRottenberg,JamesJ.Gross,andIanH.Gotlib.2005.EmotionContext
InsensitivityinMajorDepressiveDisorder.JournalofAbnormalPsychology114,
4(Nov.2005),627â€“639. https://doi.org/10.1037/0021-843x.114.4.627
[63] SamuliISaarni,JaanaSuvisaari,HarriSintonen,SamiPirkola,SeppoKoskinen,
ArpoAromaa,andJoukoLÃ¶nnqvist.2007. Impactofpsychiatricdisorderson
health-relatedqualityoflife:generalpopulationsurvey. Br.J.Psychiatry190
(April2007),326â€“332.
[64] GuramritpalSinghSaggu,KeshavGupta,KVArya,andCiroRodriguezRodriguez.
2022.DepressNet:AMultimodalHierarchicalAttentionMechanismapproach
forDepressionDetection.Int.J.Eng.Sci.15,1(2022),24â€“32.
[65] ChristosSagonas,EpameinondasAntonakos,GeorgiosTzimiropoulos,Stefanos
Zafeiriou,andMajaPantic.2016.300facesin-the-wildchallenge:Databaseand
results.Imageandvisioncomputing47(2016),3â€“18.
[66] ChristosSagonas,GeorgiosTzimiropoulos,StefanosZafeiriou,andMajaPantic.
2013. 300facesin-the-wildchallenge:Thefirstfaciallandmarklocalization
challenge.InProceedingsoftheIEEEinternationalconferenceoncomputervision
workshops.397â€“403.
[67] ZiggiIvanSantini,AiKoyanagi,StefanosTyrovolas,CatherineMason,and
JosepMariaHaro.2015.Theassociationbetweensocialrelationshipsanddepres-
sion:Asystematicreview.JournalofAffectiveDisorders175(April2015),53â€“65.
https://doi.org/10.1016/j.jad.2014.12.049
[68] ZhannaSarsenbayeva,NielsvanBerkel,ChuLuo,VassilisKostakos,andJorge
Goncalves.2017.Challengesofsituationalimpairmentsduringinteractionwith
mobiledevices.InProceedingsofthe29thaustralianconferenceoncomputer-human
interaction.477â€“481.
[69] GeorgSchomerus,CharlotteAuer,DieterRhode,MelanieLuppa,HaraldJ.Frey-
berger,andSilkeSchmidt.2012.Personalstigma,problemappraisalandperceived
needforprofessionalhelpincurrentlyuntreateddepressedpersons.Journalof
AffectiveDisorders139,1(June2012),94â€“97. https://doi.org/10.1016/j.jad.2012.
02.022
[70] MingxingTanandQuocLe.2019. Efficientnet:Rethinkingmodelscalingfor
convolutionalneuralnetworks.InInternationalconferenceonmachinelearning.
PMLR,6105â€“6114.
[71] GarrethWTigwell,DavidRFlatla,andRachelMenzies.2018.Itâ€™snotjustthelight:
understandingthefactorscausingsituationalvisualimpairmentsduringmobile
interaction.InProceedingsofthe10thNordicConferenceonHuman-Computer
Interaction.338â€“351.
[72] PatriciaValdezandAlbertMehrabian.1994.Effectsofcoloronemotions.Journal
ofexperimentalpsychology:General123,4(1994),394.
[73] RuiWang,AndrewT.Campbell,andXiaZhou.2015.UsingOpportunisticFace
LoggingfromSmartphonetoInferMentalHealth:ChallengesandFutureDi-
rections.InAdjunctProceedingsofthe2015ACMInternationalJointConference
onPervasiveandUbiquitousComputingandProceedingsofthe2015ACMInter-
nationalSymposiumonWearableComputers(Osaka,Japan)(UbiComp/ISWCâ€™15
Adjunct).AssociationforComputingMachinery,NewYork,NY,USA,683â€“692.
https://doi.org/10.1145/2800835.2804391
[74] RuiWang,FanglinChen,ZhenyuChen,TianxingLi,GabriellaHarari,Stefanie
Tignor,XiaZhou,DrorBen-Zeev,andAndrewTCampbell.2014.StudentLife:
assessingmentalhealth,academicperformanceandbehavioraltrendsofcollege
studentsusingsmartphones.InProceedingsofthe2014ACMinternationaljoint
conferenceonpervasiveandubiquitouscomputing.3â€“14.CHIâ€™24,May11â€“16,2024,Honolulu,HI,USA NepalandPillaietal.
A SURVEYS B ADDITIONALMETRICSFORMODELS
Table6:PHQ-8Questionnaire[39] Table8:Performance:R-squared(ğ‘…ğ‘…ğ‘…222)valuesforPHQ-8regres-
sionscoreprediction.â€˜LR+ENâ€™referstologisticregression
fordepressionclassificationandelasticnetforregression.
No. Question
Inthepast4hours...
1 Ihavehadlittleinterestorpleasureindoingthings Method ğ‘…ğ‘…ğ‘…222
2 Ihavefeltdown,depressed,orhopeless
Baseline 0.05
3 LastnightIhadtroublewithsleep
4 Ihavefelttiredorhavehadlittleenergy LR+EN(MI) 0.12
5 Ihavehadapoorappetiteorhavebeenovereating RandomForest(MI) 0.14
6 Ihavefeltbadaboutmyself RandomForest(3DLandmarks) 0.20
7 Ihavehadtroubleconcentrating EffNet 0.13
8 Ihavebeenmovingorspeakingslowly,orfidgetingmore.
Table9:AblationStudy:InvestigatingR-squared(ğ‘…ğ‘…ğ‘…222)values
Table7:UserComfortQuestionnaire
forPHQ-8regressionscorepredictionofOpenFacefeature
setsusingarandomforest.
No. Question
1 Asyouknow,participatinginthisstudyisconfidentialandwe Method ğ‘…ğ‘…ğ‘…222
havemultiplemeasuresinplacetoprotectthedatayouâ€™veshared.
Giventhat,wewouldliketoknowhowcomfortableyouwere FacialActionUnits 0.13
withsharingthefront-facingphotoburstswhiletakingsurveys Gaze 0.11
2 Pleasetelluswhythephotoburstsmadeyouuncomfortable. EyeLandmarks 0.17
HeadPose 0.16
RigidityParameters 0.13
2DLandmarks 0.16
3DLandmarks 0.20