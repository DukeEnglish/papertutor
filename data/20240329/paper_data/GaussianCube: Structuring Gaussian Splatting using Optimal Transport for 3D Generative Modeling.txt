GaussianCube: Structuring Gaussian Splatting
using Optimal Transport for 3D Generative Modeling
BowenZhang1‚àó YijiCheng2‚àó JiaolongYang3 ChunyuWang3
FengZhao1 YansongTang2 DongChen3 BainingGuo3
1UniversityofScienceandTechnologyofChina 2TsinghuaUniversity 3MicrosoftResearchAsia
Abstract
3DGaussianSplatting(GS)haveachievedconsiderableimprovementoverNeural
RadianceFieldsintermsof3Dfittingfidelityandrenderingspeed. However,this
unstructuredrepresentationwithscatteredGaussiansposesasignificantchallenge
for generative modeling. To address the problem, we introduce GaussianCube,
astructuredGSrepresentationthatisbothpowerfulandefficientforgenerative
modeling. Weachievethisbyfirstproposingamodifieddensification-constrained
GSfittingalgorithmwhichcanyieldhigh-qualityfittingresultsusingafixednum-
beroffreeGaussians,andthenre-arrangingtheGaussiansintoapredefinedvoxel
gridviaOptimalTransport. Thestructuredgridrepresentationallowsustouse
standard3DU-Netasourbackboneindiffusiongenerativemodelingwithoutelab-
oratedesigns. ExtensiveexperimentsconductedonShapeNetandOmniObject3D
showthatourmodelachievesstate-of-the-artgenerationresultsbothqualitatively
andquantitatively,underscoringthepotentialofGaussianCubeasapowerfuland
versatile3Drepresentation. Projectpage: https://gaussiancube.github.io/.
1 Introduction
Recentadvancementsingenerativemodeling[23,17,35,14,64,27]haveledtosignificantprogress
in3Dcontentcreation[53,33,4,49,41,6,16]. Mostofthepriorworksinthisdomainleverage
variantsofNeuralRadianceField(NeRF)[32]astheirunderlying3Drepresentations[6,49],which
typicallyconsistofanexplicitandstructuredproxyrepresentationandanimplicitfeaturedecoder.
However,suchhybridNeRFvariantshavedegradedrepresentationpower,particularlywhenusedfor
generativemodelingwhereasingleimplicitfeaturedecoderissharedacrossallobjects. Furthermore,
thehighcomputationalcomplexityofvolumetricrenderingleadstobothslowrenderingspeedand
extensivememorycosts. Recently,theemergenceof3DGaussianSplatting(GS)[28]hasenabled
high-quality reconstruction [61, 31, 55] along with real-time rendering speed. The fully explicit
characteristicof3DGSalsoeliminatestheneedforasharedimplicitdecoder. Although3DGShas
beenwidelystudiedinscenereconstructiontasks,itsspatiallyunstructurednaturepresentssignificant
challengewhenapplyingittogenerativemodeling.
Inthiswork,weintroduceGaussianCube,anovelrepresentationcraftedtoaddresstheunstructured
natureof3DGSandunleashitspotentialfor3Dgenerativemodeling(seeTable1forcomparisons
with prior works). Converting 3D Gaussians into a structured format without sacrificing their
expressivenessisnotatrivialtask. Weproposetofirstperformhigh-qualityfittingusingafixed
numberofGaussiansandthenorganizetheminaspatiallystructuredmanner. Tokeepthenumber
ofGaussiansfixedduringfitting,anaivesolutionmightomitthedensificationandpruningsteps
inGS,which, however, wouldsignificantlydegradethefittingquality. Incontrast, weproposea
densification-constrainedfittingstrategy,whichretainstheoriginalpruningprocessyetconstrains
*InternsatMicrosoftResearchAsia.
Preprint.Workinprogress.
4202
raM
82
]VC.sc[
1v55691.3042:viXraRepresentation Spatially-structured Fully-explicit High-qualityReconstruction EfficientRendering
VanillaNeRF[32] ‚úó ‚úó ‚úó ‚úó
NeuralVoxels[49] ‚úì ‚úó ‚úó ‚úó
Triplane[6] ‚úì ‚úó ‚úó ‚úó
GaussianSplatting[28] ‚úó ‚úì ‚úì ‚úì
OurGaussianCube ‚úì ‚úì ‚úì ‚úì
Table1: Comparisonwithprior3Drepresentations.
thenumberofGaussiansthatperformdensification,ensuringthetotaldoesnotexceedapredefined
maximumN3(32,768inthispaper). Forthesubsequentstructuralization,weallocatetheGaussians
acrossanN √óN √óN voxelgridusingOptimalTransport(OT).Consequently,ourfittedGaussians
aresystematicallyarrangedwithinthevoxelgrid,witheachgridcontainingaGaussianfeature. The
proposedOT-basedstructuralizationprocessachievesmaximalspatialcoherence,characterizedby
minimaltotaltransportdistances,whilepreservingthehighexpressivenessofthe3DGS.
Weperform3DgenerativemodelingwiththeproposedGaussianCubeusingdiffusionmodels[23].
ThespatiallycoherentstructureoftheGaussiansinourrepresentationfacilitatesefficientfeature
extraction and permits the use of standard 3D convolutions to capture the correlations among
neighboring Gaussians effectively. Therefore, we construct our diffusion model with standard
3DU-Netarchitecturewithoutelaboratedesigns. Itisworthnotingthatourdiffusionmodeland
theGaussianCuberepresentationaregeneric,whichfacilitatesbothunconditionalandconditional
generationtasks.
Weconductcomprehensiveexperimentstoverifytheefficacyofourproposedapproach. Themodel‚Äôs
capabilityforunconditionalgenerationisevaluatedontheShapeNetdataset[7]. Boththequantitative
andqualitativecomparisonsindicatethatourmodelsurpassesallpreviousmethods. Additionally,
weperformclass-conditionedgenerationontheOmniObject3Ddataset[56],whichisaextensive
collectionofreal-worldscannedobjectswithabroadvocabulary. Ourmodelexcelsinproducing
semanticallyaccurate3Dobjectswithcomplexgeometriesandrealistictextures,outperformingthe
state-of-the-artmethods. Theseexperimentscollectivelydemonstratethestrongcapabilitiesofour
GaussianCubeandsuggestitspotentialasapowerfulandversatile3Drepresentationforavarietyof
applications. SomegeneratedsamplesofourmethodispresentedinFigure1.
2 RelatedWork
Radiancefieldrepresentation.Radiancefieldsmodelrayinteractionswithscenesurfacesandcanbe
ineitherimplicitorexplicitforms. Earlyworksofneuralradiancefields(NeRFs)[32,65,37,1,39]
are often in an implicit form, which represents scenes without defining geometry. These works
optimizeacontinuousscenerepresentationusingvolumetricray-marchingthatleadstoextremely
highcomputationalcosts. Recentworksintroducetheuseofexplicitproxyrepresentationfollowed
byanimplicitfeaturedecodertoenablefasterrendering. Theexplicitproxyrepresentationsdirectly
represent continuous neural features in a discrete data structure, such as triplane [6, 25], voxel
grid[15,43],hashtable[34],orpointsets[60]. Recently,the3DGaussianSplattingmethods[28,61,
55,12,30]utilize3DGaussiansastheirunderlyingrepresentationandadaptivelydensifyandprune
themduringfitting,whichoffersimpressivereconstructionquality. Thefullyexplicitrepresentation
alsoprovidesreal-timerenderingspeed. However,the3DGaussiansareunstructuredrepresentation,
andrequireper-sceneoptimizationtoachievephoto-realisticquality. Incontrast,ourworkproposesa
structuredrepresentationtermedGaussianCubefor3Dgenerativetasks.
Image-based3Dreconstruction. Comparedtoper-sceneoptimization,image-based3Dreconstruc-
tionmethods[50,29,51,63]candirectlyreconstruct3Dassetsgivenimageswithoutoptimization.
PixelNeRF[63]leveragesanimagefeatureencodertoempowerthegeneralizabilityofNeRF.Simi-
larly,pixel-alignedGaussianapproaches[8,45,47]followthisideatodesignfeed-forwardGaussian
reconstruction networks. LRM [24, 21] shows that transformers can also be scaled up for 3D
reconstructionwithlarge-scaletrainingdata,whichisfollowedbyhybridGaussian-triplanemeth-
ods[67,58]withintheLRMframeworks. However,thelimitednumberofGaussiansandspatially
unstructuredpropertyhindersthesemethodsfromachievinghigh-qualityreconstruction,whichalso
makesithardtoextendthemto3Dgenerativemodeling.
3Dgeneration. PreviousworksofSDS-basedoptimization[38,48,59,54,44,11,10]distill2D
diffusionpriors[40]toa3Drepresentationwiththescorefunctions. Despitetheacceleration[46,62]
2Figure1: Samplesofourgenerated3Dobjects. Ourmodelisabletocreatediverseobjectswith
complexgeometryandrichtexturedetails.
achievedbyreplacingNeRFwith3DGaussians,generatinghigh-fidelity3DGaussiansusingthese
optimization-basedmethodsstillrequirescostlytest-timeoptimization. 3D-awareGANs[6,16,5,18,
36,13,57]cangenerateview-dependentimagesbytrainingonsingleimagecollections.Nevertheless,
theyfallshortinmodelingdiverseobjectswithcomplexgeometryvariations. Manyrecentworks[53,
33,19,49,41]applydiffusionmodelsfor3Dgenerationusingstructuredproxy3Drepresentations
suchashybridtriplane[53,41]orvoxels[33,49]. However,theytypicallyneedasharedimplicit
featuredecoderacrossdifferentassets,whichgreatlylimitstherepresentationexpressiveness. Also,
theinherentcomputationalcostfromNeRFleadstoslowrenderingspeed,makingitunsuitablefor
efficient training and rendering. Building upon the strong capability and rendering efficiency of
GaussianSplatting[28],weproposeaspatiallystructuredGaussianrepresentation,makingitsuitable
for3Dgenerativemodeling. Aconcurrentworkof[20]alsoinvestigatedtransforming3DGSinto
avolumetricrepresentation. TheirmethodconfinestheGaussianstovoxelgridsduringfittingand
incorporatesaspecializeddesificationstrategy. Incontrast,ourmethodonlyrestrictsthetotalnumber
ofGaussians,adheringtotheoriginalsplittingstrategyandallowingunrestrictedspatialdistribution.
Thispreservestherepresentationpowerduringfitting. ThesubsequentOT-basedvoxelizationyields
spatially coherent arrangement with minimal global offset cost and hence effectively eases the
difficultyofgenerativemodeling.
3Representation Construction 3D Diffusion
Densification-constrained Fitting Gaussian Voxelization Timesteps ‚àΩ
via Optimal Transport
Class label ‚àΩ ‚®Å Rasterization
3D U-Net
Multi-view 3DGS Optimal GaussianCube Noise Generated GaussianCube
Images Transport
Figure2: Overallframework. Ourframeworkcomprisestwomainstagesofrepresentationcon-
structionand3Ddiffusion. Intherepresentationconstructionstage,givenmulti-viewrenderingsofa
3Dasset,weperformdensification-constrainedfittingtoobtain3DGaussianswithconstantnumbers.
Subsequently, the Gaussians are voxelized into GaussianCube via Optimal Transport. In the 3D
diffusionstage,our3DdiffusionmodelistrainedtogenerateGaussianCubefromGaussiannoise.
3 Method
Followingpriorworks,ourframeworkcomprisestwoprimarystages: representationconstructionand
diffusionmodeling. Inrepresentationconstructionphase,wefirstapplyadensification-constrained
3DGSfittingalgorithmforeachobjecttoobtainaconstantnumberofGaussians.TheseGaussiansare
thenorganizedintoaspatiallystructuredrepresentationviaOptimalTransportbetweenthepositions
ofGaussiansandcentersofapredefinedvoxelgrid. Fordiffusionmodeling,wetraina3Ddiffusion
modeltolearnthedistributionofGaussianCubes. TheoverallframeworkisillustratedinFigure2.
Wewilldetailourdesignsforeachstagesubsequently.
3.1 RepresentationConstruction
Weexpectthe3Drepresentationtobebothstructured,expressiveandefficient. DespiteGaussian
Splatting(GS)offerssuperiorexpressivenessandefficiencyagainstNeRFs,itfailstoyieldfixed-
lengthrepresentationsacrossdifferent3Dassets;nordoesitorganizethedatainaspatiallystructured
format. Toaddresstheselimitations,weintroduceGaussianCube,whicheffectivelyovercomesthe
unstructurednatureofGaussianSplatting,whileretainingbothexpressivenessandefficiency.
Formally, a 3D asset is represented by a collection of 3D Gaussians as introduced in Gaussian
Splatting[28]. Thegeometryofthei-th3DGaussiang isgivenby
i
(cid:18) (cid:19)
1
g (x)=exp ‚àí (x‚àí¬µ )‚ä§Œ£‚àí1(x‚àí¬µ ) , (1)
i 2 i i i
where ¬µ ‚àà R3 is the center of the Gaussian and Œ£ ‚àà R3√ó3 is the covariance matrix defining
i i
the shape and size, which can be decomposed into a quaternion q ‚àà R4 and a vector s ‚àà R3
i i
forrotationandscaling,respectively. Moreover,eachGaussiang haveanopacityvalueŒ± ‚àà R
i i
andacolorfeaturec ‚ààR3forrendering. Combiningthemtogether,theC-channelfeaturevector
i
Œ∏ ={¬µ ,s ,q ,Œ± ,c }‚ààRC fullycharacterizestheGaussiang .
i i i i i i i
Notably,theadaptivecontrolisoneofthemostessentialstepsduringthefittingprocessinGS[28]. It
dynamicallyclonesGaussiansinunder-reconstructedregions,splitsGaussiansinover-reconstructed
regions,andeliminatesthosewithirregulardimensions. Althoughtheadaptivecontrolsubstantially
improves the fitting quality, it can lead to a varying number of Gaussians for different objects.
Furthermore,theGaussiansarestoredwithoutapredeterminedspatialorder,resultinginanabsence
ofanorganizedspatialstructure.Theseaspectsposesignificantchallengesto3Dgenerativemodeling.
To overcome these obstacles, we first introduce our densification-constrained fitting strategy to
obtainafixednumberoffreeGaussians. Then,wesystematicallyarrangetheresultingGaussians
withinapredefinedvoxelgridviaOptimalTransport,therebyachievingaspatiallystructuredGS
representation.
Densification-constrained fitting. Our approach begins with the aim of maintaining a constant
number of Gaussians g ‚àà RNmax√óC across different objects during the fitting. A naive approach
4Nùëê
Nùëë
Densification ùê∑
detection 11 Optimal Transport
Candidate
sampling ùê∑ 21 ùê∑
12 ùëá =
Densification
DP er tu en ci tn iog n ùê∑ 22 ùëá‚àó=argmin‡∑çT ùëñùëó‚ãÖùê∑ ùëñùëó
ùëá
ùëñ,ùëó
Pruning
Nùëöùëéùë•
(a) (b)
Figure3: Illustrationofrepresentationconstruction. First,weperformdensification-constrained
fittingtoyieldafixednumberofGaussians,asshownin(a). WethenemployOptimalTransportto
organizetheresultantGaussiansintoavoxelgrid. A2Dillustrationofthisprocessispresentedin(b).
mightinvolveomittingthedensificationandpruningstepsintheoriginalGS.However,wearguethat
suchsimplificationssignificantlyharmthefittingquality,withempiricalevidenceshowninTable4.
Instead,weproposetoretainthepruningprocesswhileimposinganewconstraintonthedensification
phase. Specifically,ifthecurrentiterationcomprisesN GaussiansandN Gaussiansneedtobe
c d
densified,weintroduceameasuretopreventexceedingthepredefinedmaximumofN Gaussians
max
(withN setto32,768inthiswork). ThisisachievedbyselectingN ‚àíN Gaussianswith
max max c
thelargestview-spacepositionalgradientsfromtheN candidatesfordensificationincaseswhere
d
N >N ‚àíN . Otherwise,allN GaussiansaresubjectedtodensificationasintheoriginalGS.
d max c d
Additionally,insteadofperformingthecloningandsplittinginthesamedensificationsteps,weoptto
performeachalternatelywithoutinfluencingeachother. Uponcompletionoftheentirefittingprocess,
wepadGaussianswithŒ±=0toreachthetargetcountofN withoutaffectingtherenderingresults.
max
ThedetailedfittingprocedureisshowninFigure3(a).
GaussianvoxelizationviaOptimalTransport. TofurtherorganizetheobtainedGaussiansintoa
spatiallystructuredrepresentationfor3Dgenerativemodeling,weproposetomaptheGaussianstoa
‚àö
predefinedstructuredvoxelgridv ‚àà RNv√óNv√óNv√óC whereN
v
= 3N max. Intuitively,weaimto
‚Äúmove‚ÄùeachGaussianintoavoxelgridwhilepreservingtheirgeometricrelationsasmuchaspossible.
Tothisend,weformulatethisasanOptimalTransport(OT)problem[52,3]betweentheGaussians‚Äô
spatialpositions{¬µ ,i=1,...,N }andthevoxelgridcenters{x ,j =1,...,N }. LetDbe
i max j max
adistancematrixwithD beingthemovingdistancebetween¬µ andx ,i.e.,D =‚à•¬µ ‚àíx ‚à•2.
ij i j ij i j
ThetransportplanisrepresentedbyabinarymatrixT‚ààRNmax√óNmax,andtheoptimaltransportplan
isgivenby:
minimize
(cid:80)Nmax(cid:80)NmaxT
D
i=1 j=1 ij ij
T
subjectto
(cid:80)NmaxT
=N ‚àÄi‚àà{1,...,N }
j=1 ij max max (2)
(cid:80)NmaxT
=N ‚àÄj ‚àà{1,...,N }
i=1 ij max max
T ‚àà{0,1} ‚àÄ(i,j)‚àà{1,...,N }√ó{1,...,N }.
ij max max
ThesolutionisabijectivetransportplanT‚àóthatminimizesthetotaltransportdistances. Weemploy
theJonker-Volgenantalgorithm[26]tosolvetheOTproblem.WeorganizetheGaussiansaccordingto
thesolutions,withthej-thvoxelgridencapsulatingthefeaturevectorofthecorrespondingGaussian
Œ∏ = {¬µ ‚àíx ,s ,q ,Œ± ,c } ‚àà RC,wherek isdeterminedbytheoptimaltransportplan(i.e.,
k k j k k k k
T‚àó =1). NotethatwesubstitutetheoriginalGaussianpositionswithoffsetsofthecurrentvoxel
kj
center to reduce the solution space for diffusion modeling. As a result, our fitted Gaussians are
systematicallyarrangedwithinavoxelgridvandmaintainthespatialcoherence.
3.2 3DDiffusiononGaussianCube
Wenowintroduceour3Ddiffusionmodelincorporatedwiththeproposedexpressive,efficientand
spatiallystructuredrepresentation. AfterorganizingthefittedGaussiansgintoGaussianCubeyfor
eachobject,weaimtomodelthedistributionofGaussianCube,i.e.,p(y).
5Formally,thegenerationprocedurecanbeformulatedintotheinversionofadiscrete-timeMarkov
forward process. During the forward phase, we gradually add noise to y ‚àº p(y) and obtain a
0
sequenceofincreasinglynoisysamples{y |t‚àà[0,T]}accordingto
t
y :=Œ± y +œÉ œµ, (3)
t t 0 t
whereœµ ‚àà N(0,I)representstheaddedGaussiannoise,andŒ± ,œÉ constitutethenoiseschedule
t t
which determines the level of noise added to destruct the original data sample. As a result, y
T
willfinallyreachisotropicGuassiannoiseaftersufficientdestructionsteps. Byreversingtheabove
process,weareabletoperformthegenerationprocessbygraduallydenoisethesamplestartingfrom
pureGaussiannoisey ‚àºN(0,I)untilreachingy . Ourdiffusionmodelistrainedtodenoisey
T 0 t
intoy foreachtimestept,facilitatingbothunconditionalandclass-conditionedgeneration.
0
Modelarchitecture. ThankstothespatiallystructuredorganizationoftheproposedGaussianCube,
standard3Dconvolutionissufficienttoeffectivelyextractandaggregatethefeaturesofneighboring
Gaussianswithoutelaboratedesigns. WeleveragethepopularU-Netnetworkfordiffusion[35,14]
and simply replace the original 2D convolution layer to their 3D counterparts. The upsampling,
downsamplingandattentionoperationsarealsoreplacedwithcorresponding3Dimplementations.
Conditioningmechanism. Whenperformingclass-conditionaldiffusiontraining,weuseadaptive
groupnormalization(AdaGN)[14]toinjectconditionsofclasslabelsc intoourmodel,whichcan
cls
bedefinedas:
AdaGN(f )=GroupNorm(f )¬∑(1+Œ≥)+Œ≤, (4)
i i
wherethegroup-wisescaleandshiftparametersŒ≥ andŒ≤areestimatedtomodulatetheactivations
{f }ineachresidualblockfromtheembeddingsofbothtimestepstandconditionc .
i cls
Training objective. In our 3D diffusion training, we parameterize our model yÀÜ to predict the
Œ∏
noise-freeinputy using:
0
(cid:104) (cid:105)
L =E ‚à•yÀÜ (Œ± y +œÉ œµ,t,c )‚àíy ‚à•2 , (5)
simple t,y0,œµ Œ∏ t 0 t cls 0 2
where the condition signal c is only needed when training class-conditioned diffusion models.
cls
Weadditionallyaddsupervisionontheimageleveltoensurebetterrenderingqualityofgenerated
GaussianCube,whichhasbeenshowntoeffectivelyenhancethevisualqualityinpreviousworks[53,
33]. Specifically,wepenalizethediscrepancybetweentherasterizedimagesI ofthepredicted
pred
GaussianCubesandtheground-truthimagesI :
gt
L =L +L
image pixel perc
(cid:32) (cid:33)
=E
t,Ipred
(cid:88)(cid:13) (cid:13)Œ®l(I pred)‚àíŒ®l(I gt)(cid:13) (cid:13)2
2 (6)
l
(cid:16) (cid:17)
+E ‚à•I ‚àíI ‚à•2 ,
t,Ipred pred gt 2
whereŒ®l isthemulti-resolutionfeatureextractedusingthepre-trainedVGG[42]. Benefitingfrom
theefficiencyofbothrenderingspeedandmemorycostsfromGaussianSplatting[28],weareableto
renderthefullimageratherthanonlyasmallpatchasinpreviousNeRF-basedmethods[53,9],which
facilitatesfasttrainingwithhigh-resolutionrenderings. Ouroveralltraininglosscanbeformulated
as:
L=L +ŒªL , (7)
simple image
whereŒªisabalancingweight.
4 Experiments
4.1 DatasetandMetrics
Tomeasuretheexpressivenessandefficiencyofvarious3Drepresentations,wefit100objectsin
ShapeNetCar[7]usingeachrepresentationandreportthePSNR,LPIPS[66]andStructuralSimilarity
IndexMeasure(SSIM)metricswhensynthesizingnovelviews.Furthermore,weconductexperiments
ofsingle-categoryunconditionalgenerationonShapeNet[7]CarandChair. Werandomlyrender
150viewsandfit32√ó32√ó32√ó14GaussianCubeforeachobject. Tofurthervalidatethestrong
6Representation Spatially-structured PSNR‚Üë LPIPS‚Üì SSIM‚Üë Rel.Speed‚Üë Params(M)‚Üì
Instant-NGP ‚úó 33.98 0.0386 0.9809 1√ó 12.25
GaussianSplatting ‚úó 35.32 0.0303 0.9874 2.58√ó 1.84
Voxels ‚úì 28.95 0.0959 0.9470 1.73√ó 0.47
Voxels‚àó ‚úì 25.80 0.1407 0.9111 1.73√ó 0.47
Triplane ‚úì 32.61 0.0611 0.9709 1.05√ó 6.30
Triplane‚àó ‚úì 31.39 0.0759 0.9635 1.05√ó 6.30
OurGaussianCube ‚úì 34.94 0.0347 0.9863 3.33√ó 0.46
Table2: QuantitativeresultsofrepresentationfittingonShapeNetCar. ‚àó denotesthattheimplicit
featuredecoderissharedacrossdifferentobjects.
Ground-truth Instant-NGP GaussianSplatting Voxel‚àó Triplane‚àó OurGaussianCube
Figure4: Qualitativeresultsofobjectfitting.
capabilityoftheproposedframework,wealsoconductexperimentsonOmniobject3D[56],whichisa
challengingdatasetcontaininglarge-vocabularyreal-worldscanned3Dobjects. WefitGaussianCube
ofthesamedimensionsasShapeNetusing100multi-viewrenderingsforeachobject. Tonumerically
measurethegenerationquality,wereporttheFID[22]andKID[2]scoresbetween50Krenderings
ofgeneratedsamplesand50Kground-truthrenderingsatthe512√ó512resolution.
4.2 ImplementationDetails
ToconstructGaussianCubeforeachobject,weperformtheproposeddensification-constrainedfitting
for30Kiterations. SincethetimecomplexityofJonker-Volgenantalgorithm[26]isO(cid:0) N3 (cid:1) ,we
max
opt for an approximate solution to the Optimal Transport problem. This is achieved by dividing
thepositionsoftheGaussiansandthevoxelgridintofoursortedsegmentsandthenapplyingthe
Jonker-Volgenant solver to each segment individually. We empirically found this approximation
successfullystrikesabalancebetweencomputationalefficiencyandspatialstructurepreservation.
Forthe3Ddiffusionmodel,weadopttheADMU-Netnetwork[35,14]. Weperformfullattentionat
theresolutionof83and43withinthenetwork. Thetimestepsofdiffusionmodelsaresetto1,000
andwetrainthemodelsusingthecosinenoiseschedule[35]withlossweightŒªsetto10. Allmodels
aretrainedon16TeslaV100GPUswithatotalbatchsizeof128.
4.3 MainResults
3Dfitting.WefirstevaluatetherepresentationpowerofourGaussianCubeusing3Dobjectfittingand
compareitagainstpreviousNeRF-basedrepresentationsincludingTriplaneandVoxels,whichare
widelyadoptedin3Dgenerativemodeling[6,53,4,33,49]. WealsoincludeInstant-NGP[34]and
originalGaussianSplatting[28]forreference,althoughtheycannotbedirectlyappliedingenerative
modeling due to their spatially unstructured nature. As shown in Table 2, our GaussianCube
outperforms all NeRF-based representations among all metrics. The visualizations in Figure 3
illustratethatGaussianCubecanfaithfullyreconstructgeometrydetailsandintricatetextures,which
demonstratesitsstrongcapability. Moreover, comparedwithover131,000Gaussiansutilizedin
the original GS for each object, our GaussianCube only employs 4√ó less Gaussians due to our
densification-constrainedfitting. Thisleadstothefasterfittingspeedofourmethodandsignificantly
fewerparameters(over10√ólessthanTriplane),whichdemonstrateitsefficiencyandcompactness.
7ShapeNetCar ShapeNetChair OmniObject3D
Method
FID-50K‚Üì KID-50K(‚Ä∞)‚Üì FID-50K‚Üì KID-50K(‚Ä∞)‚Üì FID-50K‚Üì KID-50K(‚Ä∞)‚Üì
EG3D 30.48 20.42 27.98 16.01 - -
GET3D 17.15 9.58 19.24 10.95 - -
DiffTF 51.88 41.10 47.08 31.29 46.06 22.86
Ours 13.01 8.46 15.99 9.95 11.62 2.78
Table3: QuantitativeresultsofunconditionalgenerationonShapeNetCarandChair[7]andclass-
conditionedgenerationonOmniObject3D[56].
EG3D[6] GET3D[16] DiffTF[4] Ours
Figure5:Qualitativecomparisonofunconditional3DgenerationonShapeNetCarandChairdatasets.
Ourmodeliscapableofgeneratingresultsofcomplexgeometrywithrichdetails.
DiffTF[4] Ours
Figure6: Qualitativecomparisonofclass-conditioned3Dgenerationonlarge-vocabularyOmniOb-
ject3D[56]. Ourmodelisabletohandlediversedistributionwithhigh-fidelitygeneratedsamples.
Notably,for3Dgenerationtasks,NeRF-basedmethodstypicallynecessitateasharedimplicitfeature
decoderfordifferentobjects, whichleadstosignificantdecreasessinfittingqualitycomparedto
single-objectfitting,asshowninTable2. Incontrast,theexplicitcharacteristicofGSallowsour
GaussianCubetobypasssuchasharedfeaturedecoder,resultinginnoqualitygapbetweensingle
andmultipleobjectfitting.
Single-categoryunconditionalgeneration. Forunconditionalgeneration,wecompareourmethod
withthestate-of-the-art3Dgenerationworksincluding3D-awareGANs[6,16]andTriplanediffusion
models[4]. AsshowninTable3,ourmethodsurpassesallpriorworksintermsofbothFIDand
KIDscoresandsetsnewrecords. WealsoprovidevisualcomparisonsinFigure5,whereEG3Dand
DiffTFtendtogenerateblurryresultswithpoorgeometry,andGET3Dfailstoprovidesatisfactory
textures.Incontrast,ourmethodyieldshigh-fidelityresultswithauthenticgeometryandsharptexture
details.
Large-vocabularyclass-conditionedgeneration. Wealsocompareclass-conditionedgeneration
withDiffTF[4]onmorediverseandchallengingOmniObject3D[56]dataset.Weachievesignificantly
8RepresentationFitting Generation
Method Densify&Prune
PSNR‚Üë LPIPS‚Üì SSIM‚Üë FID-50K‚Üì KID-50K(‚Ä∞)‚Üì
A.Voxelgridw/ooffset ‚úó 25.87 0.1228 0.9217 - -
B.Voxelgridw/offset ‚úó 30.18 0.0780 0.9628 40.52 24.35
C.Oursw/oOT ‚úì 34.94 0.0346 0.9863 21.41 14.37
D.Ours ‚úì 34.94 0.0346 0.9863 13.01 8.46
Table4: QuantitativeablationofbothrepresentationfittingandgenerationqualityonShapeNetCar.
Ground-truth Table4A. Table4B. Table4D.(Ours)
Figure7: Qualitativeablationofrepresentationfitting. OurGaussianCubeachievessuperiorfitting
resultswhilemaintainingaspatialstructure.
OptimalTransport(Ours) NearestNeighborTransport Table4B. Table4C. Table4D.(Ours)
(a) (b)
Figure8: AblationstudyoftheGaussianstructuralizationmethodsand3Dgeneration. Forvisualiza-
tionofGaussianstructuralizationin(a),wemapthecoordinatesofthecorrespondingvoxelgridof
eachGaussianstoRGBvaluestovisualizetheorganization. OurOptimalTransportsolutionyields
smoothtransitamongGaussians,indicatingacoherentglobalstructure,whereasNearestNeighbor
Transportleadstoobviousdiscontinuities. OurOT-basedsolutionalsoresultsinthebestgeneration
qualityshownin(b).
betterFIDandKIDscoresthanDiffTFasshowninTable3,demonstratingthestrongercapacityofour
method.VisualcomparisonsinFigure6revealthatDiffTFoftenstrugglestocreateintricategeometry
anddetailedtextures,whereasourmethodisabletogenerateobjectswithcomplexgeometryand
realistictextures.
4.4 AblationStudy
Wefirstexaminethekeyfactorsinrepresentationconstruction. TospatiallystructuretheGaussians,
asimplestapproachwouldbeanchoringthepositionsofGaussianstoapredefinedvoxelgridwhile
omittingdensificationandpruning,whichleadstoseverefailurewhenfittingtheobjectsasshown
in Figure 7. Even by introducing learnable offsets to the voxel grid, the complex geometry and
detailedtexturesstillcannotbewellcaptured,asshowninFigure7. Weobservethattheoffsetsare
typicallytoosmalltoeffectivelyleadtheGaussiansclosetotheobjectsurfaces,whichdemonstrates
thenecessityofperformingdensificationandpruningduringobjectfitting. Basedontheseinsights,
9we do not organize the Gaussians during the fitting stage. Instead, we only maintain a constant
number of Gaussians using densification-constrained fitting and post-process the Gaussians into
aspatiallystructuredrepresentation. OurGaussianCubecancapturebothcomplexgeometryand
intricatedetailsasillustratedinFigure7. ThenumericalcomparisoninTable4alsodemonstratesthe
superiorfittingqualityofourGaussianCube.
Wealsoevaluatehowtherepresentationaffects3DgenerativemodelinginTable4andFigure8.
Limitedbythepoorfittingquality,performingdiffusionmodelingonvoxelgridwithlearnableoffsets
leadstoblurrygenerationresultsasshowninFigure8. Tovalidatetheimportanceoforganizing
GaussiansviaOT,wecomparewiththeorganizationbasedonnearestneighbortransportbetween
positionsofGaussiansandcentersofvoxelgrid. WelinearlymapeachGaussian‚Äôscorresponding
coordinatesofvoxelgridtoRGBcolortovisualizethedifferentorganizations. AsshowninFigure8
(a), our proposed OT approach results in smooth color transitions, indicating that our method
successfullypreservesthespatialcorrespondence. However, nearestneighbortransportdoesnot
consider global structure, which leads to abrupt color transitions. Notably, since our OT-based
organizationconsiderstheglobalspatialcoherence,boththequantitativeresultsinTable4andvisual
comparisonsFigure8indicatethatourstructuredarrangementfacilitatesgenerativemodelingby
alleviatingitscomplexity,successfullyleadingtosuperiorgenerationquality.
5 Conclusion
We have presented GaussianCube, a novel representation crafted for 3D generative models. We
addresstheunstructurednatureofGaussianSplattingandunleashitspotentialfor3Dgenerative
modeling. Firstly, we fit each 3D object with a constant number of Gaussians by our proposed
densification-constrainedfittingalgorithm. Furthermore,weorganizetheobtainedGaussiansintoa
spatiallystructuredrepresentationbysolvingtheOptimalTransportproblembetweenthepositions
ofGaussiansandthepredefinedvoxelgrid. TheproposedGaussianCubeisexpressive,efficientand
withspatiallycoherentstructure,providingastrong3Drepresentationalternativefor3Dgeneration.
We train 3D diffusion models to perform generative modeling using GaussianCube, and achieve
state-of-the-artgenerationqualityontheevaluateddatasetswithoutelaboratenetworkortraining
algorithmdesign. ThisdemonstratesthepromiseofGaussianCubetobeaversatileandpowerful3D
representationfor3Dgeneration.
References
[1] JonathanTBarron,BenMildenhall,DorVerbin,PratulPSrinivasan,andPeterHedman. Mip-
nerf 360: Unbounded anti-aliased neural radiance fields. In Proceedings of the IEEE/CVF
ConferenceonComputerVisionandPatternRecognition,pages5470‚Äì5479,2022.
[2] Miko≈ÇajBin¬¥kowski,DanicaJSutherland,MichaelArbel,andArthurGretton. Demystifying
mmdgans. arXivpreprintarXiv:1801.01401,2018.
[3] RainerEBurkardandErandaCela. Linearassignmentproblemsandextensions. InHandbook
ofcombinatorialoptimization: SupplementvolumeA,pages75‚Äì149.Springer,1999.
[4] ZiangCao,FangzhouHong,TongWu,LiangPan,andZiweiLiu.Large-vocabulary3ddiffusion
modelwithtransformer. arXivpreprintarXiv:2309.07920,2023.
[5] Eric R Chan, Marco Monteiro, Petr Kellnhofer, Jiajun Wu, and Gordon Wetzstein. pi-gan:
Periodicimplicitgenerativeadversarialnetworksfor3d-awareimagesynthesis. InProceedings
oftheIEEE/CVFconferenceoncomputervisionandpatternrecognition,pages5799‚Äì5809,
2021.
[6] EricRChan,ConnorZLin,MatthewAChan,KokiNagano,BoxiaoPan,ShaliniDeMello,
OrazioGallo,LeonidasJGuibas,JonathanTremblay,SamehKhamis,etal. Efficientgeometry-
aware3dgenerativeadversarialnetworks. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages16123‚Äì16133,2022.
[7] AngelXChang,ThomasFunkhouser,LeonidasGuibas,PatHanrahan,QixingHuang,ZimoLi,
SilvioSavarese,ManolisSavva,ShuranSong,HaoSu,etal. Shapenet: Aninformation-rich3d
modelrepository. arXivpreprintarXiv:1512.03012,2015.
10[8] DavidCharatan,SizheLi,AndreaTagliasacchi,andVincentSitzmann. pixelsplat: 3dgaus-
sian splats from image pairs for scalable generalizable 3d reconstruction. arXiv preprint
arXiv:2312.12337,2023.
[9] XingyuChen,YuDeng,andBaoyuanWang. Mimic3d: Thriving3d-awaregansvia3d-to-2d
imitation. In2023IEEE/CVFInternationalConferenceonComputerVision(ICCV),pages
2338‚Äì2348.IEEEComputerSociety,2023.
[10] YongweiChen,TengfeiWang,TongWu,XingangPan,KuiJia,andZiweiLiu. Comboverse:
Compositional 3d assets creation using spatially-aware diffusion guidance. arXiv preprint
arXiv:2403.12409,2024.
[11] Yiji Cheng, Fei Yin, Xiaoke Huang, Xintong Yu, Jiaxiang Liu, Shikun Feng, Yujiu Yang,
andYansongTang. Efficienttext-guided3d-awareportraitgenerationwithscoredistillation
samplingondistribution. arXivpreprintarXiv:2306.02083,2023.
[12] R James Cotton and Colleen Peyton. Dynamic gaussian splatting from markerless motion
capturereconstructinfantsmovements. InProceedingsoftheIEEE/CVFWinterConferenceon
ApplicationsofComputerVision,pages60‚Äì68,2024.
[13] YuDeng,JiaolongYang,JianfengXiang,andXinTong. Gram: Generativeradiancemanifolds
for3d-awareimagegeneration. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages10673‚Äì10683,2022.
[14] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis.
AdvancesinNeuralInformationProcessingSystems,34:8780‚Äì8794,2021.
[15] SaraFridovich-Keil,AlexYu,MatthewTancik,QinhongChen,BenjaminRecht,andAngjoo
Kanazawa.Plenoxels:Radiancefieldswithoutneuralnetworks.InProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecognition,pages5501‚Äì5510,2022.
[16] JunGao,TianchangShen,ZianWang,WenzhengChen,KangxueYin,DaiqingLi,OrLitany,
ZanGojcic,andSanjaFidler. Get3d: Agenerativemodelofhighquality3dtexturedshapes
learnedfromimages. arXivpreprintarXiv:2209.11163,2022.
[17] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil
Ozair,AaronCourville,andYoshuaBengio. Generativeadversarialnetworks. Communications
oftheACM,63(11):139‚Äì144,2020.
[18] JiataoGu,LingjieLiu,PengWang,andChristianTheobalt. Stylenerf: Astyle-based3d-aware
generatorforhigh-resolutionimagesynthesis. arXivpreprintarXiv:2110.08985,2021.
[19] AnchitGupta,WenhanXiong,YixinNie,IanJones,andBarlasOgÀòuz. 3dgen: Triplanelatent
diffusionfortexturedmeshgeneration. arXivpreprintarXiv:2303.05371,2023.
[20] XianglongHe,JunyiChen,SidaPeng,DiHuang,YangguangLi,XiaoshuiHuang,ChunYuan,
WanliOuyang,andTongHe. Gvgen: Text-to-3dgenerationwithvolumetricrepresentation.
arXivpreprintarXiv:2403.12957,2024.
[21] ZexinHeandTengfeiWang. Openlrm: Open-sourcelargereconstructionmodels,2023.
[22] MartinHeusel,HubertRamsauer,ThomasUnterthiner,BernhardNessler,andSeppHochreiter.
Ganstrainedbyatwotime-scaleupdateruleconvergetoalocalnashequilibrium. Advancesin
neuralinformationprocessingsystems,30,2017.
[23] JonathanHo,AjayJain,andPieterAbbeel. Denoisingdiffusionprobabilisticmodels. Advances
inNeuralInformationProcessingSystems,33:6840‚Äì6851,2020.
[24] Yicong Hong, Kai Zhang, Jiuxiang Gu, Sai Bi, Yang Zhou, Difan Liu, Feng Liu, Kalyan
Sunkavalli,TrungBui,andHaoTan. Lrm: Largereconstructionmodelforsingleimageto3d.
arXivpreprintarXiv:2311.04400,2023.
[25] WenboHu,YulingWang,LinMa,BangbangYang,LinGao,XiaoLiu,andYuewenMa. Tri-
miprf: Tri-miprepresentationforefficientanti-aliasingneuralradiancefields. InProceedingsof
theIEEE/CVFInternationalConferenceonComputerVision,pages19774‚Äì19783,2023.
11[26] RoyJonkerandTonVolgenant. Ashortestaugmentingpathalgorithmfordenseandsparse
linearassignmentproblems. InDGOR/NSOR:Papersofthe16thAnnualMeetingofDGORin
CooperationwithNSOR/Vortr√§geder16.JahrestagungderDGORzusammenmitderNSOR,
pages622‚Äì622.Springer,1988.
[27] TeroKarras,SamuliLaine,andTimoAila. Astyle-basedgeneratorarchitectureforgenerative
adversarialnetworks. InProceedingsoftheIEEE/CVFconferenceoncomputervisionand
patternrecognition,pages4401‚Äì4410,2019.
[28] BernhardKerbl,GeorgiosKopanas,ThomasLeimk√ºhler,andGeorgeDrettakis. 3dgaussian
splattingforreal-timeradiancefieldrendering. ACMTransactionsonGraphics,42(4),2023.
[29] HaoLi,BartAdams,LeonidasJGuibas,andMarkPauly. Robustsingle-viewgeometryand
motionreconstruction. ACMTransactionsonGraphics(ToG),28(5):1‚Äì10,2009.
[30] MengtianLi,ShengxiangYao,ZhifengXie,KeyuChen,andYu-GangJiang. Gaussianbody:
Clothed human reconstruction via 3d gaussian splatting. arXiv preprint arXiv:2401.09720,
2024.
[31] JonathonLuiten,GeorgiosKopanas,BastianLeibe,andDevaRamanan. Dynamic3dgaussians:
Trackingbypersistentdynamicviewsynthesis. arXivpreprintarXiv:2308.09713,2023.
[32] BenMildenhall,PratulPSrinivasan,MatthewTancik,JonathanTBarron,RaviRamamoor-
thi, and Ren Ng. Nerf: Representing scenes as neural radiance fields for view synthesis.
CommunicationsoftheACM,65(1):99‚Äì106,2021.
[33] NormanM√ºller,YawarSiddiqui,LorenzoPorzi,SamuelRotaBulo,PeterKontschieder,and
MatthiasNie√üner. Diffrf: Rendering-guided3dradiancefielddiffusion. InProceedingsofthe
IEEE/CVFConferenceonComputerVisionandPatternRecognition,pages4328‚Äì4338,2023.
[34] ThomasM√ºller,AlexEvans,ChristophSchied,andAlexanderKeller. Instantneuralgraphics
primitiveswithamultiresolutionhashencoding. ACMTransactionsonGraphics(ToG),41(4):
1‚Äì15,2022.
[35] AlexanderQuinnNicholandPrafullaDhariwal. Improveddenoisingdiffusionprobabilistic
models. InInternationalConferenceonMachineLearning,pages8162‚Äì8171.PMLR,2021.
[36] MichaelNiemeyerandAndreasGeiger. Giraffe: Representingscenesascompositionalgenera-
tiveneuralfeaturefields. InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition,pages11453‚Äì11464,2021.
[37] KeunhongPark,UtkarshSinha,JonathanTBarron,SofienBouaziz,DanBGoldman,StevenM
Seitz,andRicardoMartin-Brualla. Nerfies: Deformableneuralradiancefields. InProceedings
oftheIEEE/CVFInternationalConferenceonComputerVision,pages5865‚Äì5874,2021.
[38] BenPoole,AjayJain,JonathanTBarron,andBenMildenhall. Dreamfusion: Text-to-3dusing
2ddiffusion. arXivpreprintarXiv:2209.14988,2022.
[39] Albert Pumarola, Enric Corona, Gerard Pons-Moll, and Francesc Moreno-Noguer. D-nerf:
Neuralradiancefieldsfordynamicscenes. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages10318‚Äì10327,2021.
[40] RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBj√∂rnOmmer. High-
resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF
ConferenceonComputerVisionandPatternRecognition,pages10684‚Äì10695,2022.
[41] JRyanShue,EricRyanChan,RyanPo,ZacharyAnkner,JiajunWu,andGordonWetzstein. 3d
neuralfieldgenerationusingtriplanediffusion. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages20875‚Äì20886,2023.
[42] KarenSimonyanandAndrewZisserman. Verydeepconvolutionalnetworksforlarge-scale
imagerecognition. arXivpreprintarXiv:1409.1556,2014.
12[43] Cheng Sun, Min Sun, and Hwann-Tzong Chen. Direct voxel grid optimization: Super-fast
convergenceforradiancefieldsreconstruction. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages5459‚Äì5469,2022.
[44] JingxiangSun,BoZhang,RuizhiShao,LizhenWang,WenLiu,ZhendaXie,andYebinLiu.
Dreamcraft3d: Hierarchical3dgenerationwithbootstrappeddiffusionprior. arXivpreprint
arXiv:2310.16818,2023.
[45] StanislawSzymanowicz,ChristianRupprecht,andAndreaVedaldi. Splatterimage: Ultra-fast
single-view3dreconstruction. arXivpreprintarXiv:2312.13150,2023.
[46] JiaxiangTang,JiaweiRen,HangZhou,ZiweiLiu,andGangZeng. Dreamgaussian: Generative
gaussiansplattingforefficient3dcontentcreation. arXivpreprintarXiv:2309.16653,2023.
[47] Jiaxiang Tang, Zhaoxi Chen, Xiaokang Chen, Tengfei Wang, Gang Zeng, and Ziwei Liu.
Lgm: Largemulti-viewgaussianmodelforhigh-resolution3dcontentcreation. arXivpreprint
arXiv:2402.05054,2024.
[48] JunshuTang,TengfeiWang,BoZhang,TingZhang,RanYi,LizhuangMa,andDongChen.
Make-it-3d: High-fidelity3dcreationfromasingleimagewithdiffusionprior. arXivpreprint
arXiv:2303.14184,2023.
[49] ZhicongTang,ShuyangGu,ChunyuWang,TingZhang,JianminBao,DongChen,andBaining
Guo. Volumediffusion: Flexibletext-to-3dgenerationwithefficientvolumetricencoder. arXiv
preprintarXiv:2312.11459,2023.
[50] MaximTatarchenko,StephanRRichter,Ren√©Ranftl,ZhuwenLi,VladlenKoltun,andThomas
Brox. Whatdosingle-view3dreconstructionnetworkslearn? InProceedingsoftheIEEE/CVF
conferenceoncomputervisionandpatternrecognition,pages3405‚Äì3414,2019.
[51] ShubhamTulsiani,TinghuiZhou,AlexeiAEfros,andJitendraMalik. Multi-viewsupervision
forsingle-viewreconstructionviadifferentiablerayconsistency. InProceedingsoftheIEEE
conferenceoncomputervisionandpatternrecognition,pages2626‚Äì2634,2017.
[52] C√©dricVillanietal. Optimaltransport: oldandnew,volume338. Springer,2009.
[53] TengfeiWang,BoZhang,TingZhang,ShuyangGu,JianminBao,TadasBaltrusaitis,Jingjing
Shen,DongChen,FangWen,QifengChen,etal. Rodin: Agenerativemodelforsculpting
3ddigitalavatarsusingdiffusion. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages4563‚Äì4573,2023.
[54] ZhenweiWang,TengfeiWang,GerhardHancke,ZiweiLiu,andRynsonW.H.Lau. Themesta-
tion: Generatingtheme-aware3dassetsfromfewexemplars. ArXiv,2024.
[55] Guanjun Wu, Taoran Yi, Jiemin Fang, Lingxi Xie, Xiaopeng Zhang, Wei Wei, Wenyu Liu,
QiTian,andXinggangWang. 4dgaussiansplattingforreal-timedynamicscenerendering.
arXivpreprintarXiv:2310.08528,2023.
[56] TongWu,JiaruiZhang,XiaoFu,YuxinWang,JiaweiRen,LiangPan,WayneWu,LeiYang,
JiaqiWang,ChenQian,etal. Omniobject3d: Large-vocabulary3dobjectdatasetforrealistic
perception,reconstructionandgeneration. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages803‚Äì814,2023.
[57] JianfengXiang,JiaolongYang,YuDeng,andXinTong. Gram-hd: 3d-consistentimagegenera-
tionathighresolutionwithgenerativeradiancemanifolds. arXivpreprintarXiv:2206.07255,
2022.
[58] DejiaXu,YeYuan,MortezaMardani,SifeiLiu,JiamingSong,ZhangyangWang,andArash
Vahdat. Agg: Amortized generative 3d gaussians for single image to 3d. arXiv preprint
arXiv:2401.04099,2024.
[59] JialeXu,XintaoWang,WeihaoCheng,Yan-PeiCao,YingShan,XiaohuQie,andShenghua
Gao. Dream3d: Zero-shottext-to-3dsynthesisusing3dshapepriorandtext-to-imagediffusion
models. arXivpreprintarXiv:2212.14704,2022.
13[60] QiangengXu,ZexiangXu,JulienPhilip,SaiBi,ZhixinShu,KalyanSunkavalli,andUlrich
Neumann. Point-nerf: Point-basedneuralradiancefields. InProceedingsoftheIEEE/CVF
conferenceoncomputervisionandpatternrecognition,pages5438‚Äì5448,2022.
[61] YuelangXu,BenwangChen,ZheLi,HongwenZhang,LizhenWang,ZerongZheng,andYebin
Liu. Gaussianheadavatar:Ultrahigh-fidelityheadavatarviadynamicgaussians. arXivpreprint
arXiv:2312.03029,2023.
[62] TaoranYi,JieminFang,GuanjunWu,LingxiXie,XiaopengZhang,WenyuLiu,QiTian,and
XinggangWang. Gaussiandreamer: Fastgenerationfromtextto3dgaussiansplattingwith
pointcloudpriors. arXivpreprintarXiv:2310.08529,2023.
[63] AlexYu,VickieYe,MatthewTancik,andAngjooKanazawa. pixelnerf: Neuralradiancefields
fromoneorfewimages. InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition,pages4578‚Äì4587,2021.
[64] Bowen Zhang, Shuyang Gu, Bo Zhang, Jianmin Bao, Dong Chen, Fang Wen, Yong Wang,
andBainingGuo. Styleswin: Transformer-basedganforhigh-resolutionimagegeneration. In
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,pages
11304‚Äì11314,2022.
[65] Kai Zhang, Gernot Riegler, Noah Snavely, and Vladlen Koltun. Nerf++: Analyzing and
improvingneuralradiancefields. arXivpreprintarXiv:2010.07492,2020.
[66] RichardZhang,PhillipIsola,AlexeiAEfros,EliShechtman,andOliverWang. Theunrea-
sonable effectiveness of deep features as a perceptual metric. In Proceedings of the IEEE
conferenceoncomputervisionandpatternrecognition,pages586‚Äì595,2018.
[67] Zi-Xin Zou, Zhipeng Yu, Yuan-Chen Guo, Yangguang Li, Ding Liang, Yan-Pei Cao, and
Song-Hai Zhang. Triplane meets gaussian splatting: Fast and generalizable single-view 3d
reconstructionwithtransformers. arXivpreprintarXiv:2312.09147,2023.
14