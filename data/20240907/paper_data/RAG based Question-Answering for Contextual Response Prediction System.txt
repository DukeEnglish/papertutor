RAG based Question-Answering for Contextual Response
Prediction System
SriramVeturi‚àó NafisIrtizaTripto‚Ä†
SaurabhVaichal‚àó ThePennsylvaniaStateUniversity
sriram_veturi@homedepot.com USA
saurabh_s_vaichal@homedepot.com nit5154@psu.edu
TheHomeDepot
Atlanta,Georgia,USA
ReshmaLalJagadheesh‚Ä° NianYan
TheHomeDepot TheHomeDepot
Atlanta,Georgia,USA Atlanta,Georgia,USA
reshma_lal_jagadheesh@homedepot.com nian_yan@homedepot.com
Abstract Keywords
LargeLanguageModels(LLMs)haveshownversatilityinvarious Retrieval Augmented Generation, Response Prediction System,
NaturalLanguageProcessing(NLP)tasks,includingtheirpoten- QuestionAnsweringSystem,ContactCenterAgents,Automated
tialaseffectivequestion-answeringsystems.However,toprovide Hallucination Measurement,Hallucination Reduction, Retrieval
preciseandrelevantinformationinresponsetospecificcustomer Strategies,OptimalRetrieverThreshold,ScaNN,EmbeddingStrate-
queriesinindustrysettings,LLMsrequireaccesstoacomprehen- gies,ContextualRelevance,Specificity,Completeness,Hallucina-
siveknowledgebasetoavoidhallucinations.RetrievalAugmented tionRate,MissingRate,HumanEvaluationofRAGVersusTradi-
Generation(RAG)emergesasapromisingtechniquetoaddress tionalSeq-2-Seqmodels,RAGDeployment.
this challenge. Yet, developing an accurate question-answering
ACMReferenceFormat:
frameworkforreal-worldapplicationsusingRAGentailsseveral
SriramVeturi,SaurabhVaichal,NafisIrtizaTripto,ReshmaLalJagadheesh,
challenges:1)dataavailabilityissues,2)evaluatingthequalityof
andNianYan.2024.RAGbasedQuestion-AnsweringforContextualRe-
generatedcontent,and3)thecostlynatureofhumanevaluation. sponsePredictionSystem.InProceedingsofCIKM2024(1stWorkshopon
Inthispaper,weintroduceanend-to-endframeworkthatemploys GenAIandRAGSystemsforEnterprise).ACM,NewYork,NY,USA,10pages.
LLMswithRAGcapabilitiesforindustryusecases.Givenacus- https://doi.org/10.1145/nnnnnnn.nnnnnnn
tomerquery,theproposedsystemretrievesrelevantknowledge
documentsandleveragesthem,alongwithpreviouschathistory, 1 Introduction
togenerateresponsesuggestionsforcustomerserviceagentsin
WiththeadventofChatGPTandsimilartoolsinmainstreamme-
thecontactcentersofamajorretailcompany.Throughcomprehen-
dia,LargeLanguageModels(LLMs)haveemergedasthestandard
siveautomatedandhumanevaluations,weshowthatthissolution
solutionforaddressingawiderangeoflanguageunderstanding
outperformsthecurrentBERT-basedalgorithmsinaccuracyand
tasks.However,theycangenerateincorrectorbiasedinformation
relevance.OurfindingssuggestthatRAG-basedLLMscanbean
[34],astheirresponsesarebasedonpatternslearnedfromdatathat
excellentsupporttohumancustomerservicerepresentativesby
maynotalwayscontainnecessaryknowledgeinaclosedomain.To
lighteningtheirworkload.
addressthisissue,RetrievalAugmentedGeneration(RAG)[20]is
commonlyusedtogroundLLMsinfactualinformation.TheRAG
CCSConcepts
architectureprocessesuserinputbyfirstretrievingasetofdocu-
‚Ä¢Computingmethodologies‚ÜíMachinelearning. mentssimilartothequery,whichthelanguagemodelthenusesto
generateafinalprediction.WhileRAG-basedarchitectureshave
‚àóBothfirstauthorscontributedequallytothisresearch.
beensuccessfulinvariousopen-domainquestionanswering(Q/A)
‚Ä†WorkcompletedduringinternshipatTheHomeDepot
‚Ä°WorkcompletedduringemploymentattheHomeDepot tasks[15,30,49],limitedresearchhasexploredtheirscalingdy-
namicsinrealconversationalscenarios.Therefore,ourresearchis
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor oneofthepioneeringeffortsinexploringthefeasibilityofanRAG-
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
basedapproachfordevelopingaknowledge-groundedresponse
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe predictionsystemspecificallytailoredforthecontactcenterofa
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or majorretailcompany.
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
LLMshaverecentlybeenwidelyadoptedacrossvariousindus-
and/orafee.Requestpermissionsfrompermissions@acm.org.
1stWorkshoponGenAIandRAGSystemsforEnterprise,October24,2024,Boise,Idaho, tries,particularlyincontactcenters,toenhancechatbotdevelop-
USA mentandagent-facingautomation[8,12,37].Aprimeexample
¬©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
istheResponsePredictionSystem(RPS),anagent-assistsolution
ACMISBN978-x-xxxx-xxxx-x/YY/MM
https://doi.org/10.1145/nnnnnnn.nnnnnnn thatgeneratescontextuallyrelevantresponses,enablingagents
4202
peS
5
]LC.sc[
1v80730.9042:viXra1stWorkshoponGenAIandRAGSystemsforEnterprise,October24,2024,Boise,Idaho,USA Veturi&Vaichaletal,2024
(A) highlightingthepotentialofRAGLLMasanexcellentchoicefor
Retrieved customercareautomation.
document
x
(B) 2 RelatedWork
We offer a x% military discount I am here to help with [company name] RAGarchitecture: RAGhasemergedasapromisingsolutionby
Thank you for your service, you get x% I am help you with [company name] incorporatingknowledgefromexternaldatabasestoovercomethe
off! needs
We appreciate your service; you can get What can I do for you at [company hallucination,outdatedknowledge,transparencyissuesforLLMs
your x% off today name] ? [5,17,19,20,43].TraditionalRAG,popularizedaftertheadoption
ofChatGPT,followsasimpleprocessofindexing,retrieval,and
generation[14].DespiteadvancementsinAdvancedandModular
RAG,TraditionalRAGremainspopularintheindustryduetoits
ease of development, integration, and quicker speed to market
Figure1:ExampleoftheResponsePredictionSystem.(A):For [21].ThecorecomponentsofTraditionalRAGincludeRetriever,
avalidquery,thesystemretrievestherelevantdocumentand Generator,andAugmentationMethod,withresearchfocusingon
proposestheappropriateresponsesfromwheretheagent improvingsemanticrepresentation[9,48],queryalignment[35],
choose.(B):Foranout-of-domainquery,itguidestheuserto andintegrationwithLLMs[16,28,45],whichmotivateourRQ1
askarelevantquestion. tofindtheoptimumsetupinthisspecificusecaseofRPSinthe
contactcenter.
RAGLLMforquestionanswering: Severalopen-domainquestion-
toefficientlyaddresscustomerquerieswithasingleclick.This answering(Q/A)taskshavebeencompletedbyRAG-basedarchi-
boostsproductivity,improvescustomerexperience,andstream- tecturesefficiently[15,30,49].WiththeadventofLLMsinrecent
linescommunicationprocesses.Inindustrysettings,thefocusis periods,multiplestudiesalsofocusonutilizingLLMsforcustomer
ongeneratingaccurate,contextuallyappropriateresponseswith assistance,specificallyinrecommendations[13,41]anddialogue
minimal latency. Therefore, RAG-based responses, grounded in generation[29,47].Recentworkby[2]proposesaugmentingLLMs
companypolicies,deliverswiftandaccurateresolutionstocus- withuser-specificcontextfromsearchengineinteractionhisto-
tomerissues.Figure1demonstratesapossibleexampleofRPSin riestopersonalizeoutputs,leveragingentity-centricknowledge
realsettings,wheretheagentcandirectlyutilizethegenerated storesderivedfromusers‚Äôwebactivities.Similarly,[40]introduces
responsewithasingleclick. acustomerservicequestion-answeringapproachintegratingRAG
However,implementingRAGforindustry-specificusecasesto with a knowledge graph (KG) constructed from historical issue
assisthumanagentsingeneratingvalidresponsesinvolvesseveral data.Therefore,ourstudyismotivatedbythesepriorresearches
architecturaldecisionsthatcanaffectperformanceandviability. tointegrateRAGasaretrievaltoolandutilizeLLMtogenerate
Theretrievalstylecanbeintegratedintobothencoder-decoder responsestoanswercustomerqueries.
[16,44])anddecoder-onlymodels[5,19,26,27],withvariousem-
beddingandpromptingtechniquesinfluencingthefinalLLMoutput. 3 Methodology
Incontactcenters,wheretheriskofhallucinationsishighandcan Toimplementanend-to-endRAGframeworkwithLLM,first,it
criticallyimpactbusinessperformance,ReAct(Reason+Act)[42] isessentialtocreateacomprehensivedatasetcomprisingrelevant
promptscanhelpmitigateissues.Therefore,ourresearchfocuses question-answerpairsalongwithcorrespondingknowledgedoc-
ondevelopinganoptimalRAGbasedknowledge-groundedRPS uments.Next,designchoicesforspecificcomponentsoftheRAG
foramajorretailcompany‚Äôscontactcenter.Toensureresponse andLLMarchitecturemustbefinalized.Finally,themodelshould
accuracy,wealsoconductthoroughevaluationswithhumanevalu- bethoroughlyevaluatedandrefinedbeforebeingdeployedinto
atorsandautomatedmeasures,comparingRAG-basedresponsesto production.
humangroundtruthandtheexistingBERT-basedsystem(Figure
2showsanoverviewoftraditionalcustomercarescenariowith 3.1 PhaseI:DataPreparation
existingandproposedsystem).Inshort,weanswerthefollowing
AnidealgoldendatasetforevaluatingRAGarchitecture(Figure3)
researchquestions.
shouldinclude:
(1) RQ1:Whataretheeffectsofdifferentembeddingtechniques, (1) Domain-specificquestions(previousqueries)withtheircor-
retrievalstrategies,andpromptingmethodsonRAGperfor- respondinggroundedresponses.
mance? (2) Relevantknowledgebase(KB)articles(companydocuments)
(2) RQ2:DoRAG-basedresponsesprovidegreaterassistanceto containingthepoliciesthatdetermineanswerstospecific
humanagentscomparedtotheexistingBERT-basedsystem? queries.
(3) RQ3:CantheReAct(Reason+Act)promptingimprovefac- (3) Out-of-domain questions to ensure the LLM can handle
tualaccuracyandreducehallucinationsinLLMinreal-time generic queries without hallucinating and can guide cus-
settings? tomerstoproviderelevantqueries.
Ourfindingsdemonstrateanoverallimprovementovertheex- Tocreatearobusttestset(Table1fordetails),weutilizeLLMto
istingsystembysuggestingmoreaccurateandrelevantresponses, generatebothrelevantquestion-answerpairsfromthecompany‚ÄôsRAGbasedQuestion-AnsweringforContextualResponsePredictionSystem 1stWorkshoponGenAIandRAGSystemsforEnterprise,October24,2024,Boise,Idaho,USA
2 LLM retrieves relevant
2 Agent searches for
KB articles (if required) 2 BERT gets KB (if necessary)
the relevant 3 BERT provides
question answer from database 3 LLM generates answer
from
dataset
1 Customer 3 Agent provides
1 Customer
asks a query answer to query 1 Customer 4 Agent gives asks a query 4 Agent gives
asks a query answer to query answer to query
(A) (B) (C)
Figure2:Overviewofthesystems:(A)Agentsrespondtoqueriesbymanuallysearchingforrelevantdocuments,(B)The
existingBERT-basedsystem,whichextractsrelevantQ/Apairsfromthegivenqueryandprovidessuggestedanswerstothe
agents,(C)TheproposedRAGLLMsystem,wheretheLLMretrievesrelevantKBarticles(ifnecessary)andgeneratesanswers
basedonthequeryandtheretrievedarticles.
Phase 1: Data Updated Phase 2: RAG implementation Phase 3: Deployment & Evaluation
preparation Golden Test set
Modeloutput:
Internal KB LLM generated Q/A Best Best Response1,Response2,Response3
embedding retrieval
Input: customer
utterance
LLM
API endpoint
Stratified Threshold calculation for deployment on cloud
sampling maximizing accuracy Selecting
Out of domain Bestmodel
datasets
Prompengineering Best Model
Human Automated
Previous query & responses from history F pi rn od min pg t st h fore r s ah no sl wd ea rn gd e e nx ep rae tr ii om nent with evaluation evaluation
Figure3:EndtoendRAGLLMframework
Source Total# length(query) length(response) previousqueries&responsesinthecontactcenterwithout-of-
KBarticles 1205 Avg.documentlength:134.25 domainquestionsbysamplingfromopen-sourcedatasetssuchas
IndomainQ/A(generated MS-MARCO[3].
4785 10.7 33.59
byLLMfromKBarticles)
IndomainQ/A(sampled
3000 9.58 28.81
fromprevioushistory)
3.2 PhaseII:RAG
OutdomainQ/A(sampled
3660 5.73 5
fromMS-MARCO) ThemaincomponentsoftheRAGarchitecturearetheRetriever
Table1:Totalnumberandaveragelength(intermsofword andtheGeneratorLLM.Weevaluatevariousstrategiesforeach
count)fortheKBarticlesandvariousQ/ApairsfortheRAG componentandfinalizeourchoicesforproduction.Ourfindingsare
implementation validatedthroughexperimentswithseveralopen-domainquestion-
answerdatasets,includingMARCO[3],SQuAD[23],andTrivi-
aQA[18](detailsinAppendix).Theypresentacomparablelevelof
question-answeringchallengeswhereanswerscanbederivedfrom
theretrievedknowledgebase.
EmbeddingStrategy:Thebestembeddingstrategyensures
KBarticles(refertoSectionAintheAppendixforprompts).Ad- highperformanceoftheretrieverandaffectsdownstreamtaskslike
ditionally,wesupplementtheserelevantpairswithsamplesfrom responsegeneration.WecomparetheUniversalSentenceEncoder1stWorkshoponGenAIandRAGSystemsforEnterprise,October24,2024,Boise,Idaho,USA Veturi&Vaichaletal,2024
(USE)embeddings[6],Google‚ÄôsVertexAIembeddingmodeltext- Embedding Embeddingsize R@1 R@3 R@5
embedding-gecko@001 [? ], and SBERT-all-mpnet-base-v2 [24]
USE 512 - - -
fromthesentence-transformerscollection.
SBERT 768 +15.36 +9.42 +8.22
Retrievalstrategies: Byretrievingrelevantpassagesfroma
VertexAI 768 +21.55 +13.87 +11.85
largecorpusofKBarticles,themodelgainscrucialcontextualin-
formation,enhancingresponseaccuracyandcoherence.Wespecif- Table2:Performanceofdifferentembeddingtechniquein
icallyconsiderScaNN[25]foritsefficiencyinhandlinglarge-scale thecompanydataforScaNN.Performanceisshownasthe
datasetsandKNNHNSW[22]foritsefficientmemoryusageas (%)ofimprovementwrtthelowestperformingembedding
retrievalstrategiesinourstudy.Additionally,wetesteddifferent (USEinthisscenario)
retrievalthresholdstoensureincorrectdocumentsarenotretrieved
andpassedtotheLLMforresponsegeneration.
LLMforgeneration: Oncethebestembeddingstrategy,re-
trievaltechnique,andretrievalthresholdsareidentified,wetestdif-
ferentpromptingtechniquestoensurethatLLMsgenerategrounded
factualresponses.WeutilizePaLM2foundationmodels(text-bison,
text-unicorn)[1]fortextgenerationacrossalltasks,astheyoffera
clearpathtoproductionintermsofenterpriselicensesandsecurity
requirementswithGoogle‚Äôsmodels,comparedtootheravailable
LLMsatthetimeofourresearch.
ThebestmodelfromPhase2,incorporatingtheoptimalembed-
ding,retrieval,andpromptingtechniques,ispackagedwithrelevant
KBarticlesanddeployedonacloudVirtualMachine.Forreal-time
usage,anendpointiscreatedthattakesacustomerqueryandthe
Figure4:CosinesimilarityscorebetweenqueryandScaNN
conversationcontextasinput,generatingresponsesuggestionsas
retrievedDocument;retrievalthreshold(0.7)
output.
Metric Improvement
4 ResultsandFindings Accuracy +10.15
Hallucination -4.76
First,weoptimizeRAGsetupforourusecases,thenevaluateLLM Missingrate -5.43
responsesusingautomatedmetricsandhumanevaluations.Finally, AlignScore +5.6
Semanticsimilarity +20.01
weassessifpromptingorReActstrategiescanimprovereal-world
AI-generated -40.17
performancetoanacceptablelevel.
Table3:ComparisionbetweenRAGbasedresponsesandex-
istingBERT-basedonesforautomatedevaluations.Values
indicate the difference in percentage (%) as average of all
4.1 Retrievalevaluation
samples
BestsettingforRAG. :
Weassessedretrieverefficiencyusingthe"RecallatK"(ùëÖ@ùëò)
metric, whereùêæ represents the top 1, 3, 5, or 10 documents re-
trieved,measuringhowwelltheretrieverretrievesrelevantdocu- 4.2 ResponsePredictionSystemEvaluation
ments.TheVertexAI-textembedding-gecko@001(768)embedding,
To develop an effective Response Generation System (RPS), we
pairedwithScaNNretrieval,yieldedthebestoutcomes.Overall,
conductedacomprehensiveevaluationcomparingRAGLLM-based
ScaNNgenerallyoutperformedKNNHNSWinmostcasesdueto
responseswithacurrentBERT-basedalgorithm.Using1,000real
itsefficienthandlingoflarge-scaledatasetsandsuperiorretrieval
contactcenterchattranscripts(PIIandPCIcompliant),comprising
accuracythroughquantizationandre-rankingtechniques[7],so
over5,000messages,weanalyzedcustomerqueries,humanagent
weincludeonlytheScaNNresultsinTable2.Similarly,VertexAI
responses,RAGLLMsuggestions,BERT-basedsuggestions,and
embeddingssurpassedSentenceBERTandUSEduetoitssupe-
retrievedknowledgebasedocumentstoassessquality,consistency,
riorabilitytocapturecomplexsemanticrelationshipstailoredfor
andfactualitythroughautomatedmeasuresandhumanevaluations.
large-scaleindustryapplications.
4.2.1 Automatedevaluations. Weutilizethefollowingevaluation
techniques, with Table 3 illustrating our RAG LLM-based tech-
RetrievalThreshold: Forout-of-domainortrivialcustomerqueries
nique‚ÄôsperformanceagainstthecurrentBERT-basedsystem.
like"Hello"or"Bye,"documentretrievalisunnecessary,asshown
by98.59%ofretrievedarticleshavingacosinesimilarityscorebelow Accuracy,HallucinationandMissingrateevaluation. Inaquestion-
0.7.Incontrast,88.96%ofarticlesretrievedforrelevantcompany answersystem,aresponsetoeachquerycangenerateoneofthree
dataquestionsscoredabove0.7(Figure4).Thissuggeststhatsetting typesofresponses:accurate(correctlyanswersthequestion),hallu-
theretrievalthresholdat0.7effectivelydetermineswhenretrieval cinate(incorrectanswer),ormissing(noanswergenerated).There-
isneeded,therebyenhancingresponsegenerationefficiency. fore,ourapproach,inspiredby[32]whichprovides98%agreementRAGbasedQuestion-AnsweringforContextualResponsePredictionSystem 1stWorkshoponGenAIandRAGSystemsforEnterprise,October24,2024,Boise,Idaho,USA
withhumanjudgments,utilizesanLLM-basedmethod.Weemploy Metric Improvement
ChatGPT-3.5-turboasourevaluatorLLM.WepromptedtheLLM
ContextualRelevance +48.14
withaquery,generatedresponse,andoriginalhumanresponse,cat-
Specificity +97.97
egorizingtheLLM‚Äôsresponsesas"correct"forfactualandsemantic Completeness +70.15
alignment,"incorrect"formismatches,and"unsure"forsemantic Accuracy +45.69
challenges.EvaluationincludesAccuracy(correctresponses),Hal- HallucinationRate -27.49
lucinationRate(incorrectresponses),andMissingRate(unsure MissingRate -70.02
responses)metricsastheproportionofcorrespondingresponses. Preference +200.61
Overall,RAGLLMimprovesaccuracybyreducinghallucinations Table4:Humanevaluationcomparison(%diff.)betweenRAG
andmissingratescomparedtoBERTresponses. andexistingBERT-basedones.
AlignScore: ToensureresponsealignmentwithKBarticles,we
useAlignScore[46]tomeasureinformationconsistency.Evaluat-
ingRAGLLMandBERT-basedmodelsonutteranceswithrelevant K Strategy Accuracy HallucinationRate MissingRate
1 ReAct -2.13 +51.40 -34.38
KBarticleretrievalbyRAG,RAGLLMshowsastatisticallysig- 3 ReAct +7.08 -13.48 -19.38
nificant5.6%improvementviaStudent‚Äôst-test.Thisenhancement 3 CoVe -43.65 +27.43 +11.35
3 CoTP -3.45 +1.33 +1.98
derivesfromintegratingretrieveddocumentsaspromptsforLLM Table5:Comparison(%diff.)ofReActRAG(withdifferent
responses,whereasBERTreliesonquery-answerpairsinitstrain- valuesofk),CoVeandCoTPperformancewithrespectto
ingdataset. baselineoncompanydata.
Semanticsimilarity: Toensureusabilitybyhumanagents,coher-
encebetweengeneratedandoriginalhumanresponsesiscrucial.
WemeasuresemanticsimilarityusingLongFormerembeddings
(2) Completeness:Checkedifthepredictedresponseswere
[4],calculatingcosinesimilaritybetweengeneratedandoriginal
fully-formedandcouldbeusedascompleteanswersbythe
humanresponsesforbothmodels.RAGLLMexhibitsanaverage
agentsinspecificpartsoftheconversation.
20%highersimilarity,astatisticallysignificantimprovement.
(3) Specificity:Determinedwhetherthepredictedresponses
Humantouch: Customerservicearetypicallypreferredtobe weretailoredtothespecificconversationorweretoogen-
handledbyhumans[11,38],emphasizingtheimportanceofgener- eral.Humanannotatorsscoredthesemetricsonascaleof0
atinghuman-likeresponses.WeusetheAItextdetectorGPTZero (lowest)to2(highest).
[33],witha99.05%truepositiverateforhumanresponsesinour Theresults,asdetailedintheTable4,Responsesgeneratedbythe
dataset,toevaluateresponsenaturalness.AssessingAIpercentage RAGmodeldemonstrateda45%improvementinfactualaccuracy
(utterances identified as AI-generated), the BERT-based system, anda27%decreaseintherateofhallucinationscomparedtothe
whichselectsresponsesfromhuman-generatedoptions,sounds existingmodel.Moreover,thehumanevaluatorsfavoredresponses
morehuman. fromtheRAGmodeloverthecurrentproductionmodel75%ofthe
times.
4.2.2 Humanevaluations. Ourmethodaimstosupportratherthan
TheResponsePredictionSystemwasdeployedusingFlask,a
replacehumansthroughahuman-in-the-loopapproach.Wethor-
standardmicrowebframework,andGunicorn,chosenforitsper-
oughlyevaluatethequalityofRAGLLMandBERTresponsesusing
formance,flexibility,andsimplicityinproductionsystemconfig-
humanannotators.Eachresponseisassessedagainstseveralcrite-
uration.TheAPIreceivescustomerqueriesasinputandprovides
ria,andtheaveragescoreiscomputedfromallannotators‚Äôevalua-
answersasoutput.TheAPIwasthoroughlyloadtestedusingLo-
tions.Evaluationmetricsweregroupedintothreemaincategories:
cust,anopen-sourceperformance/loadtestingtoolforHTTPand
otherprotocols,toensureitmeetsreal-timelatencyrequirements
Human Preference Score: Following the classical approach of
inaproductionsetting.Finally,theAPIwasintegratedwiththe
whichversionhumansprefermost[31,39],weevaluatedwhich
AgentWorkspaceUItodeliverpredictionstoContactCenteragents,
model‚Äôsresponses‚Äî"BERT"or"RAG"‚Äîwerepreferredbyhuman
assistingcustomersinreal-time.
evaluators.
4.3 EvaluationforReActandprompting
QuantitativeMetrics: Similarto[32],weevaluatedfactualaccu-
racy(basedonhumanjudgmentof‚Äôcorrect,‚Äô‚Äôincorrect,‚Äôor‚Äôunsure‚Äô). techniques
Accuracy,Hallucination,andMissingrateswerecalculatedasthe ExperimentswithReAct. ToanswerourthirdRQ,weutilized
numberofcorrect,incorrect,andunsureresponsesdividedbythe ReActToolstodeterminewhentoactivatetheinformationretrieval
totalnumberofresponsesevaluated,respectively. componentwithintheRAGframework,whilemaintainingthesame
retrieval,embeddings,andgenerationstrategies.Weevaluatedtwo
QualitativeMetrics:
scenarios:"RAGwithReAct"and"RAGwithoutReAct,"withK=3.
(1) ContextualRelevance:Assessedwhetherthepredicted AsshowninTable5.WhileReActimprovedtheaccuracyby7%and
responseswereappropriateandinlinewiththecontextof reducedhallucinationby13.5%,itresultedinslowerperformance
theconversation. 6,makingitinconvenientinreal-timeconversation.1stWorkshoponGenAIandRAGSystemsforEnterprise,October24,2024,Boise,Idaho,USA Veturi&Vaichaletal,2024
RAGStrategy 95thPercentile 99thPercentile References
reAct 4.0942 6.2084
non-reAct 0.8850 1.1678 [1] RohanAnil,AndrewM.Dai,OrhanFirat,MelvinJohnson,DmitryLepikhin,
Table6:LatencyComparison(seconds)betweenReActRAG AlexandrePassos,SiamakShakeri,EmanuelTaropa,PaigeBailey,ZhifengChen,
EricChu,JonathanH.Clark,LaurentElShafey,YanpingHuang,KathyMeier-
andnon-ReActRAGbasedon10000queries
Hellstern,GauravMishra,EricaMoreira,MarkOmernick,KevinRobinson,Sebas-
tianRuder,YiTay,KefanXiao,YuanzhongXu,YujingZhang,GustavoHernandez
Abrego,JunwhanAhn,JacobAustin,PaulBarham,JanBotha,JamesBradbury,
SiddharthaBrahma,KevinBrooks,MicheleCatasta,YongCheng,ColinCherry,
ChristopherA.Choquette-Choo,AakankshaChowdhery,Cl√©mentCrepy,Shachi
PromptingTechniquesExperiments. WeevaluatedChainofVerifi- Dave,MostafaDehghani,SunipaDev,JacobDevlin,MarkD√≠az,NanDu,Ethan
Dyer,VladFeinberg,FangxiaoyuFeng,VladFienber,MarkusFreitag,Xavier
cation(CoVe)[10]andChainofThoughtPrompting(CoTP)[36]to
Garcia,SebastianGehrmann,LucasGonzalez,GuyGur-Ari,StevenHand,Hadi
improvefactualaccuracyandreducehallucinations.However,both Hashemi,LeHou,JoshuaHowland,AndreaHu,JeffreyHui,JeremyHurwitz,
techniquesaretime-consuming,requiringmultipleLLMcallsper MichaelIsard,AbeIttycheriah,MatthewJagielski,WenhaoJia,KathleenKenealy,
MaximKrikun,SnehaKudugunta,ChangLan,KatherineLee,BenjaminLee,Eric
query,anddidnotshowsignificantimprovementsfortheCompany Li,MusicLi,WeiLi,YaGuangLi,JianLi,HyeontaekLim,HanzhaoLin,Zhong-
data.CoVewas43%lessaccurateandCoTPwas3%lessaccurate taoLiu,FrederickLiu,MarcelloMaggioni,AromaMahendru,JoshuaMaynez,
VedantMisra,MaysamMoussalem,ZacharyNado,JohnNham,EricNi,Andrew
(seeTable5).Therefore,wedecidedagainstusingtheseprompting
Nystrom,AliciaParrish,MariePellat,MartinPolacek,AlexPolozov,ReinerPope,
techniques. SiyuanQiao,EmilyReif,BryanRichter,ParkerRiley,AlexCastroRos,AurkoRoy,
BrennanSaeta,RajkumarSamuel,ReneeShelby,AmbroseSlone,DanielSmilkov,
DavidR.So,DanielSohn,SimonTokumine,DashaValter,VijayVasudevan,Kiran
5 Conclusion
Vodrahalli,XuezhiWang,PidongWang,ZiruiWang,TaoWang,JohnWieting,
Inthisstudy,wedemonstratethepracticalchallengesofimplement- YuhuaiWu,KelvinXu,YunhanXu,LintingXue,PengchengYin,JiahuiYu,Qiao
Zhang,StevenZheng,CeZheng,WeikangZhou,DennyZhou,SlavPetrov,and
ingaRAG-basedResponsePredictionSysteminanindustrysetting. YonghuiWu.2023.PaLM2TechnicalReport. arXiv:2305.10403[cs.CL]
Weevaluatedvariousretrievalandembeddingstrategiescombined [2] JinheonBaek,NirupamaChandrasekaran,SilviuCucerzan,AllenHerring,and
SujayKumarJauhar.2024. Knowledge-augmentedlargelanguagemodelsfor
withdifferentpromptingtechniquestoidentifythebestcombina-
personalizedcontextualquerysuggestion.InProceedingsoftheACMonWeb
tionsfordifferentusecases.Ourevaluationsshowthatretrieving Conference2024.3355‚Äì3366.
relevantknowledgebasearticlesandgeneratingresponsesfrom [3] PayalBajaj,DanielCampos,NickCraswell,LiDeng,JianfengGao,Xiaodong
Liu,RanganMajumder,AndrewMcNamara,BhaskarMitra,TriNguyen,Mir
LLMscanbemorecontextuallyrelevantandaccuratethanBERTre-
Rosenberg,XiaSong,AlinaStoica,SaurabhTiwary,andTongWang.2018.
sponses,whichchoosefromthemostrelevantquery-answerpairs. MSMARCO:AHumanGeneratedMAchineReadingCOmprehensionDataset.
WealsohighlightthatReActandadvancedpromptingtechniques arXiv:1611.09268[cs.CL]
[4] IzBeltagy,MatthewEPeters,andArmanCohan.2020.Longformer:Thelong-
maynotbepracticalforindustrysettingsduetolatencyissues. documenttransformer.arXivpreprintarXiv:2004.05150(2020).
Overall,ourapproachindicatesthatimplementingRAG-basedLLM [5] SebastianBorgeaud,ArthurMensch,JordanHoffmann,TrevorCai,ElizaRuther-
ford,KatieMillican,GeorgevandenDriessche,Jean-BaptisteLespiau,Bogdan
responsegenerationforcontactcentersisfeasibleandcaneffec-
Damoc,AidanClark,DiegodeLasCasas,AureliaGuy,JacobMenick,Roman
tivelyaidhumans,reducingtheirworkload.Inthefuture,weplan Ring,TomHennigan,SaffronHuang,LorenMaggiore,ChrisJones,AlbinCassirer,
toadvanceourworkinthreedirections.Firstly,weaimtoevaluate AndyBrock,MichelaPaganini,GeoffreyIrving,OriolVinyals,SimonOsindero,
KarenSimonyan,JackW.Rae,ErichElsen,andLaurentSifre.2022.Improving
otherLLMs.Secondly,wewilltestifqueryrewritingandrefor-
languagemodelsbyretrievingfromtrillionsoftokens. arXiv:2112.04426[cs.CL]
mulationcanimproveretrievalperformance.Lastly,weintendto [6] DanielCer,YinfeiYang,ShengyiKong,NanHua,NicoleLimtiaco,RhomniSt.
exploreadvancedRAGapproachestointegrateknowledgebases John,NoahConstant,MarioGuajardo-Cespedes,SteveYuan,ChrisTar,Yun-
HsuanSung,BrianStrope,andRayKurzweil.2018.UniversalSentenceEncoder.
fromvarioussources. arXiv:1803.11175[cs.CL]
[7] Wei-Cheng Chang, Jyun-Yu Jiang, Jiong Zhang, Mutasem Al-Darabsah,
ChoonHuiTeo,Cho-JuiHsieh,Hsiang-FuYu,andSVNVishwanathan.2024.
Limitations
PEFA:ParamEter-FreeAdaptersforlarge-scaleembedding-basedretrievalmod-
Despiteongoingsignificantresearch,LLMsremainunpredictable. els.InProceedingsofthe17thACMInternationalConferenceonWebSearchand
DataMining.77‚Äì86.
Thoughthispapershowcasesworkongroundingthegenerated [8] Wei-LinChiang,LianminZheng,YingSheng,AnastasiosNikolasAngelopoulos,
responses,LLMstoacertaindegreearestillcapableofgenerating TianleLi,DachengLi,HaoZhang,BanghuaZhu,MichaelJordan,JosephE
Gonzalez,etal.2024.Chatbotarena:Anopenplatformforevaluatingllmsby
inaccurateinformationbasedontheirlearntparametricmemory.
humanpreference.arXivpreprintarXiv:2403.04132(2024).
ThisworkalsodoesnotfocusonotherLLMissuessuchascontext [9] ZhuyunDai,VincentY.Zhao,JiMa,YiLuan,JianmoNi,JingLu,AntonBakalov,
lengthconstraints,promptinjectionsandqualityofKnowledge KelvinGuu,KeithB.Hall,andMing-WeiChang.2022.Promptagator:Few-shot
DenseRetrievalFrom8Examples. arXiv:2209.11755[cs.CL]
basedata.Addressingotheropenchallengesuchasbiasesalong
[10] ShehzaadDhuliawala,MojtabaKomeili,JingXu,RobertaRaileanu,XianLi,Asli
withtheirethicalconsiderationarealsonotconsideredinthescope Celikyilmaz,andJasonWeston.2023.Chain-of-VerificationReducesHallucina-
ofthispaper.ThepaperalsodoesnotaddressorevaluateRAGfor tioninLargeLanguageModels. arXiv:2309.11495[cs.CL]
[11] TeresaFernandesandElisabeteOliveira.2021.Understandingconsumers‚Äôaccep-
multilingualdatasources. tanceofautomatedtechnologiesinserviceencounters:Driversofdigitalvoice
assistantsadoption.JournalofBusinessResearch122(2021),180‚Äì191.
EthicsStatement [12] SamuelKernanFreire,ChaofanWang,andEvangelosNiforatos.2024.Chatbots
inknowledge-intensivecontexts:Comparingintentandllm-basedsystems.arXiv
ThedatasetusedfortrainingandvalidationofLLMsinthispaper preprintarXiv:2402.04955(2024).
[13] LukeFriedman,SameerAhuja,DavidAllen,ZhenningTan,HakimSidahmed,
donothaveanyunbalancedviewsoropinionsofindividualsthat
ChangboLong,JunXie,GabrielSchubiner,AjayPatel,HarshLara,etal.2023.
mightbiasthegeneratedresponse.TheLLMsarestillcapableof Leveraginglargelanguagemodelsinconversationalrecommendersystems.arXiv
generatinginaccurateresponsesbasedtheirparametricmemory preprintarXiv:2305.07961(2023).
[14] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi,
evenwhenrelevantcontextualinformationmightbeprovided.Fil- Yi Dai, Jiawei Sun, Qianyu Guo, Meng Wang, and Haofen Wang. 2024.
teringtoxicresponsesandpromptinjectionsarealsonotconsidered Retrieval-Augmented Generation for Large Language Models: A Survey.
arXiv:2312.10997[cs.CL]
inthisevaluation.RAGbasedQuestion-AnsweringforContextualResponsePredictionSystem 1stWorkshoponGenAIandRAGSystemsforEnterprise,October24,2024,Boise,Idaho,USA
[15] GautierIzacardandEdouardGrave.2020. Leveragingpassageretrievalwith [38] LaurieWu,AleiFan,YangYang,andZeyaHe.2022.Tech-touchbalanceinthe
generative models for open domain question answering. arXiv preprint serviceencounter:Theimpactofsupplementaryhumanserviceonconsumer
arXiv:2007.01282(2020). responses.InternationalJournalofHospitalityManagement101(2022),103122.
[16] GautierIzacard,PatrickLewis,MariaLomeli,LucasHosseini,FabioPetroni,Timo [39] XiaoshiWu,KeqiangSun,FengZhu,RuiZhao,andHongshengLi.2023.Human
Schick,JaneDwivedi-Yu,ArmandJoulin,SebastianRiedel,andEdouardGrave. preferencescore:Betteraligningtext-to-imagemodelswithhumanpreference.
2022. Atlas:Few-shotLearningwithRetrievalAugmentedLanguageModels. InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.2096‚Äì
arXiv:2208.03299[cs.CL] 2105.
[17] GautierIzacard,PatrickLewis,MariaLomeli,LucasHosseini,FabioPetroni,Timo [40] ZhentaoXu,MarkJeromeCruz,MatthewGuevara,TieWang,ManasiDeshpande,
Schick,JaneDwivedi-Yu,ArmandJoulin,SebastianRiedel,andEdouardGrave. XiaofengWang,andZhengLi.2024. Retrieval-AugmentedGenerationwith
2023. Atlas:Few-shotLearningwithRetrievalAugmentedLanguageModels. KnowledgeGraphsforCustomerServiceQuestionAnswering.arXivpreprint
JournalofMachineLearningResearch24,251(2023),1‚Äì43. http://jmlr.org/papers/ arXiv:2404.17723(2024).
v24/23-0037.html [41] FanYang,ZhengChen,ZiyanJiang,EunahCho,XiaojiangHuang,andYanbin
[18] MandarJoshi,EunsolChoi,DanielWeld,andLukeZettlemoyer.2017.TriviaQA:A Lu.2023.Palr:Personalizationawarellmsforrecommendation.arXivpreprint
LargeScaleDistantlySupervisedChallengeDatasetforReadingComprehension. arXiv:2305.07622(2023).
InProceedingsofthe55thAnnualMeetingoftheAssociationforComputational [42] ShunyuYao,JeffreyZhao,DianYu,NanDu,IzhakShafran,KarthikNarasimhan,
Linguistics(Volume1:LongPapers),ReginaBarzilayandMin-YenKan(Eds.). andYuanCao.2023. ReAct:SynergizingReasoningandActinginLanguage
AssociationforComputationalLinguistics,Vancouver,Canada,1601‚Äì1611. https: Models. arXiv:2210.03629[cs.CL]
//doi.org/10.18653/v1/P17-1147 [43] MichihiroYasunaga,ArmenAghajanyan,WeijiaShi,RichJames,JureLeskovec,
[19] UrvashiKhandelwal,OmerLevy,DanJurafsky,LukeZettlemoyer,andMike PercyLiang,MikeLewis,LukeZettlemoyer,andWentauYih.2023.Retrieval-
Lewis.2020.GeneralizationthroughMemorization:NearestNeighborLanguage AugmentedMultimodalLanguageModeling. arXiv:2211.12561[cs.CV]
Models. arXiv:1911.00172[cs.CL] [44] WenhaoYu.2022.Retrieval-augmentedGenerationacrossHeterogeneousKnowl-
[20] PatrickLewis,EthanPerez,AleksandraPiktus,FabioPetroni,VladimirKarpukhin, edge.InProceedingsofthe2022ConferenceoftheNorthAmericanChapterofthe
NamanGoyal,HeinrichK√ºttler,MikeLewis,WentauYih,TimRockt√§schel, AssociationforComputationalLinguistics:HumanLanguageTechnologies:Student
SebastianRiedel,andDouweKiela.2021.Retrieval-AugmentedGenerationfor ResearchWorkshop,DaphneIppolito,LiunianHaroldLi,MariaLeonorPacheco,
Knowledge-IntensiveNLPTasks. arXiv:2005.11401[cs.CL] DanqiChen,andNianwenXue(Eds.).AssociationforComputationalLinguistics,
[21] NelsonF.Liu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua, Hybrid:Seattle,Washington+Online,52‚Äì58. https://doi.org/10.18653/v1/2022.
FabioPetroni,andPercyLiang.2023.LostintheMiddle:HowLanguageModels naacl-srw.7
UseLongContexts. arXiv:2307.03172[cs.CL] [45] ZichunYu,ChenyanXiong,ShiYu,andZhiyuanLiu.2023. Augmentation-
[22] Yu.A.MalkovandD.A.Yashunin.2018. Efficientandrobustapproximate AdaptedRetrieverImprovesGeneralizationofLanguageModelsasGeneric
nearest neighbor searchusingHierarchicalNavigableSmallWorldgraphs. Plug-In. arXiv:2305.17331[cs.CL]
arXiv:1603.09320[cs.DS] [46] YuhengZha,YichiYang,RuichenLi,andZhitingHu.2023.AlignScore:Evaluating
[23] PranavRajpurkar,JianZhang,KonstantinLopyrev,andPercyLiang.2016. FactualConsistencywithAUnifiedAlignmentFunction.InProceedingsofthe
SQuAD:100,000+QuestionsforMachineComprehensionofText.InProceed- 61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:
ingsofthe2016ConferenceonEmpiricalMethodsinNaturalLanguageProcessing, LongPapers).11328‚Äì11348.
JianSu,KevinDuh,andXavierCarreras(Eds.).AssociationforComputational [47] KaiZhang,FubangZhao,YangyangKang,andXiaozhongLiu.2023.Memory-
Linguistics,Austin,Texas,2383‚Äì2392. https://doi.org/10.18653/v1/D16-1264 augmentedllmpersonalizationwithshort-andlong-termmemorycoordination.
[24] NilsReimersandIrynaGurevych.2019.Sentence-BERT:SentenceEmbeddings arXivpreprintarXiv:2309.11696(2023).
usingSiameseBERT-Networks. arXiv:1908.10084[cs.CL] [48] PeitianZhang,ShitaoXiao,ZhengLiu,ZhichengDou,andJian-YunNie.2023.
[25] GoogleResearch.2020.ScaNN:EfficientVectorSimilaritySearch.https://github. RetrieveAnythingToAugmentLargeLanguageModels.arXiv:2310.07554[cs.IR]
com/google-research/google-research/tree/master/scann. [49] PenghaoZhao,HailinZhang,QinhanYu,ZhengrenWang,YuntengGeng,
[26] OhadRubin,JonathanHerzig,andJonathanBerant.2022.LearningToRetrieve FangchengFu,LingYang,WentaoZhang,andBinCui.2024.Retrieval-augmented
PromptsforIn-ContextLearning. arXiv:2112.08633[cs.CL] generationforai-generatedcontent:Asurvey.arXivpreprintarXiv:2402.19473
[27] WeijiaShi,JulianMichael,SuchinGururangan,andLukeZettlemoyer.2022. (2024).
kNN-Prompt:NearestNeighborZero-ShotInference. arXiv:2205.13792[cs.CL]
[28] WeijiaShi,SewonMin,MichihiroYasunaga,MinjoonSeo,RichJames,Mike
A EvaluationofRAGApproachforOpen
Lewis,LukeZettlemoyer,andWentauYih.2023.REPLUG:Retrieval-Augmented
Black-BoxLanguageModels. arXiv:2301.12652[cs.CL] SourceDatasets
[29] KurtShuster,JingXu,MojtabaKomeili,DaJu,EricMichaelSmith,StephenRoller,
MeganUng,MoyaChen,KushalArora,JoshuaLane,etal.2022.Blenderbot3: ToevaluatetheeffectivenessoftheRAG-basedapproach,wealso
adeployedconversationalagentthatcontinuallylearnstoresponsiblyengage. conductedasamplestudyusingthreeopen-domaindatasetsfol-
arXivpreprintarXiv:2208.03188(2022).
[30] Shamane Siriwardhana, Rivindu Weerasekera, Elliott Wen, Tharindu Kalu- lowingasimilarmethodology.
arachchi,RajibRana,andSurangaNanayakkara.2023.Improvingthedomain
adaptationofretrievalaugmentedgeneration(RAG)modelsforopendomain A.1 DatasetStatistics
questionanswering.TransactionsoftheAssociationforComputationalLinguistics
11(2023),1‚Äì17. Weconsiderthreepopularopensourcequestionansweringdatasets
[31] NisanStiennon,LongOuyang,JeffreyWu,DanielZiegler,RyanLowe,Chelsea
focusingonavariteyoftopics.ArandomsubsetofMSMARCO[3],
Voss,AlecRadford,DarioAmodei,andPaulFChristiano.2020. Learningto
summarizewithhumanfeedback. AdvancesinNeuralInformationProcessing SQuAD[23],TriviaQA[18]wereconsideredfortheevaluation.
Systems33(2020),3008‚Äì3021. Table7showsthebriefoverviewoftheconsidereddatasets.
[32] KaiSun,YifanEthanXu,HanwenZha,YueLiu,andXinLunaDong.2023.Head-
to-Tail:HowKnowledgeableareLargeLanguageModels(LLM)?A.K.A.Will
LLMsReplaceKnowledgeGraphs? arXiv:2308.10168[cs.CL] Dataset Unique Ave. Unique Ave. Unique Ave.
[33] EdwardTian.2023.GPTZero.Online;accessed23-Mar-2023. https://gptzero.me/ Docs Doc. Quest- Question Answers Answer
Tokens ions Tokens Tokens
[34] SMTonmoy,SMZaman,VinijaJain,AnkuRani,VipulaRawte,AmanChadha,
MS-MARCO 4997 58.80 5000 5.67 4999 14.37
andAmitavaDas.2024. Acomprehensivesurveyofhallucinationmitigation
SQUAD 5000 94.21 4994 10.33 4413 2.59
techniquesinlargelanguagemodels.arXivpreprintarXiv:2401.01313(2024).
TRIVIA 3530 4321.4 4087 12.95 3471 1.67
[35] XintaoWang,QianwenYang,YongtingQiu,JiaqingLiang,QianyuHe,Zhouhong
Gu,YanghuaXiao,andWeiWang.2023. KnowledGPT:EnhancingLarge Table7:Opensourcedatasetrandomsamplestatistics
Language Models with Retrieval and Storage Access on Knowledge Bases.
arXiv:2308.11761[cs.CL]
[36] JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,BrianIchter,FeiXia,
EdChi,QuocLe,andDennyZhou.2023.Chain-of-ThoughtPromptingElicits
ReasoninginLargeLanguageModels. arXiv:2201.11903[cs.CL]
A.2 RetrievalandEmbeddingPerformance
[37] AndreasWortmann,OlivierBarais,BenoitCombemale,andManuelWimmer.
2020.ModelinglanguagesinIndustry4.0:anextendedsystematicmappingstudy.
WeobservedaspecifictrendinRecallvaluesinlowerkvalues(1,3)
SoftwareandSystemsModeling19(2020),67‚Äì94.
versushigherkvalues(5,10)forSQuADandTRIVIA.ForSQuAD,1stWorkshoponGenAIandRAGSystemsforEnterprise,October24,2024,Boise,Idaho,USA Veturi&Vaichaletal,2024
VertexAItextembedding-gecko@001(768)embeddingwithScaNN GroundTruth:Thecustomerregistrationprocessisawayfor
retrievalperformedthebestatlowerkbutathigherk,SBERT-all- customerstocreateanaccountwiththem.Thisallowsthemto
mpnet-base-v2(768)withScaNNperformedbetter.ForTRIVIA, tracktheirpurchases,receivepersonalizedoffers,andmore.The
SBERTall-mpnet-base-v2(768)embeddingwithHNSWKNNre- processissimpleandcanbecompletedinafewminutes.
trievalperformedthebestatlowerkbutathigherk,SBERT-all- Prediction:Thecustomerregistrationprocessisaprocessthat
mpnet-base-v2(768)withScaNNperformedbetter.ForMSMARCO, allows customers to register their information with them. This
VertexAI-textembedding-gecko@001(768)embeddingwithScaNN process allows customers to receive benefits such as discounts,
retrievalcombinationwasaclearwinner.ReferTable8formore specialoffers,andpersonalizedshoppingexperiences.
details. Correctness:correct
Question:Whathappensifmyrefundispending?
A.3 EvaluationofGeneratedResponses GroundTruth:Sorry,Idon‚Äôtknow.
Prediction:Sorry,Idon‚Äôtknow.
Table9showstheaccuracy,hallucination,andmissingrateforthe
Correctness:correct
opensourcesdatasets(throughautomatedevaluationasdescribed
2)Exampleswhereyoushouldreturn"incorrect".
inSubsection4.2.1.AsobservedintheRetrievalevaluationsection,
Question:WhatdoIneedtodotogetthemilitarydiscount?
wenoticeasimilarrelationshipintheaccuracyandhallucination
GroundTruth:Youneedtohaveasmartphoneandberegistered
asdocumentsizeincreases.FromTable7,weobservethatthetoken
for the discount. If you don‚Äôt have a smartphone, you can use
lengthoftheTriviaQAdocumentsismuchlargerthanMS-MARCO
discountcodeRC5.Ifyouareinthepilot425storesarea,youcan
and SQuAD. Similarlt, we observed lower accuracy and higher
keyinyourphonenumber.
hallucinationrateswithTriviaQAwhencomparedtoMS-MARCO
Prediction:Themilitarydiscountisavailabletoactivedutymil-
andSQuAD.Table10and11showperformanceofChainofThought
itary members, veterans, and their families. The discount is 10
PromptingandChainofVerificationperformanceonopen-source
percentoffeligiblepurchases.
datasets.Accuracyandhallucinationrateimprovementvarybased
Correctness:incorrect
ontheopensourcedataset.
Question:HowdoIapplyfortheconsumercard?
GroundTruth:Sorry,Idon‚Äôtknow.
B PromptExamples
Prediction:Youcanapplyfortheconsumercardin-store,online
WeutilizeLLMsforvarioustasksinourmethodology,including
orbymail.
question-answer pair generation from knowledge base articles,
Correctness:incorrect
responsegeneration,factualaccuracyevaluation,andadvanced
3)Exampleswhereyoushouldreturn"unsure".
CoTP&CoVprompts.Therefore,weincludethespecificprompts
Question:WhatistheReturnPolicy?
usedforthesedifferenttasks.
GroundTruth:TheReturnPolicyisavailableonthewebsite.You
canfinditbysearchingfor"ReturnPolicy"orbyclickingonthe
Promptforanswergeneration. Youareareadingcomprehension
linkinthearticle.
andanswergenerationexpert.Pleaseanswerthequestionfromthe
Prediction:Sorry,Idon‚Äôtknow.
documentprovided.Ifthedocumentisnotrelatedtothequestion,
Correctness:unsure
simplyreply:"Sorry,Icannotanswerthisquestion".Followingare
Providecorrectnessforthebelowquestion,groundtruthand
theguidelinesyouneedtofollowforgeneratingtheresponses:
prediction:
1)Theyshouldalwaysbeprofessional,positive,friendly,and
Question:<question>
empathetic.2)Theyshouldnotcontainwordsthathaveanegative
GroundTruth:<groundtruth>
connotation (Example: "unfortunately"). 3) They should always
Prediction:<prediction>
betruthfulandhonest.4)TheyshouldalwaysbeSTRICTLYless
Correctness:
than30words.Ifthegeneratedresponseifgreaterthan30words,
PromptforChainofPrompting:Promptforquoteextrac-
rephraseandmakeitlessthan30words.
tion:Youareareadingcomprehensionandquoteextractionexpert.
document:<retrieved_document>,
Pleaseextract,word-for-word,anyquotesrelevanttothequestion.
question:<question>,
Iftherearenoquotesinthisdocumentthatseemrelevanttothe
output:
providedquestion,pleasesay"Ican‚Äôtfindanyrelevantquotes".
PromptforHallucinationJudgement. : Fordocument:<document>,
Youneedtocheckwhetherthepredictionofaquestion-answering question:<question>,
systemstoaquestioniscorrect.Youshouldmakethejudgement output:
basedonalistofgroundtruthanswersprovidedtoyou.Youre-
sponseshouldbe"correct"ifthepredictioniscorrector"incorrect" PromptforGeneratingBaselineResponseandPlanVerification
ifthepredictioniswrong.Yourresponseshouldbe"unsure"where (ChainofVerification). :
thereisavalidgroundtruthandpredictionis"Sorry,Idon‚Äôtknow." Belowisaquestion:<question>
orifyouarenotconfidentifthepredictioniscorrect. Belowisthedocumentfromwhichtheanswershouldbegener-
Belowarethedifferentcasespossible: ated:<document>
1)Exampleswhereyoushouldreturn"correct". YouareansubjectmatterexpertworkingatContactCenters.
Question:Whatisthecustomerregistrationprocess? Yourexpertiseincludesquoteextraction,answergeneration,andRAGbasedQuestion-AnsweringforContextualResponsePredictionSystem 1stWorkshoponGenAIandRAGSystemsforEnterprise,October24,2024,Boise,Idaho,USA
Dataset EmbeddingStrategy RetrievalStrategy Recall@1 Recall@3 Recall@5 Recall@10
SQUAD USE(512) HNSWKNN 0.4188 0.5946 0.6634 0.7424
SQUAD SBERT-all-mpnet-base-v2(768) HNSWKNN 0.6708 0.8444 0.8902 0.9336
SQUAD VertexAI-textembedding-gecko@001(768) HNSWKNN 0.6958 0.8486 0.8804 0.911
SQUAD USE(512) ScaNN 0.4282 0.6116 0.6834 0.7666
SQUAD SBERT-all-mpnet-base-v2(768) ScaNN 0.685 0.8636 0.913 0.9584
SQUAD VertexAI-textembedding-gecko@001(768) ScaNN 0.7156 0.874 0.908 0.9414
TRIVIA USE(512) HNSWKNN 0.459 0.6004 0.6604 0.7333
TRIVIA SBERT-all-mpnet-base-v2(768) HNSWKNN 0.793 0.8691 0.8921 0.9171
TRIVIA VertexAI-textembedding-gecko@001(768) HNSWKNN 0.6423 0.7487 0.782 0.8233
TRIVIA USE(512) ScaNN 0.4101 0.6039 0.6687 0.7548
TRIVIA SBERT-all-mpnet-base-v2(768) ScaNN 0.7086 0.8654 0.8992 0.9288
TRIVIA VertexAI-textembedding-gecko@001(768) ScaNN 0.5936 0.759 0.8038 0.8537
MS-MARCO USE(512) HNSWKNN 0.5263 0.6856 0.7347 0.784
MS-MARCO SBERT-all-mpnet-base-v2(768) HNSWKNN 0.9128 0.9798 0.9878 0.9925
MS-MARCO VertexAI-textembedding-gecko@001(768) HNSWKNN 0.8194 0.9241 0.9425 0.9577
MS-MARCO USE(512) ScaNN 0.5347 0.6996 0.7518 0.8035
MS-MARCO SBERT-all-mpnet-base-v2(768) ScaNN 0.9132 0.9816 0.9896 0.9944
MS-MARCO VertexAI-textembedding-gecko@001(768) ScaNN 0.8296 0.9376 0.9581 0.9738
Table8:Recall@Kforretrievalandembeddingstrategiesfordifferentdatasets.
k Data Accuracy Hallucination Missing shouldalwaysbeprofessional,positive,friendly,andempathetic.
rate rate
1 SQUAD 84.74 8.36 6.9 2)Theyshouldnotcontainwordsthathaveanegativeconnotation
1 TriviaQA 58.48 28.68 12.8 (Example:"unfortunately").3)Theyshouldalwaysbetruthfuland
1 MS-MARCO 89.06 7.06 3.86
3 SQUAD 91.32 5.48 3.2 honest.4)TheyshouldalwaysbeSTRICTLYlessthan30words.
3 TriviaQA 25.08 67.41 7.46
3 MS-MARCO 89.9 6.93 3.16 Ifthegeneratedresponseifgreaterthan30words,rephraseand
Table9:Generationqualitymetrics(%)usingtext-bison@001 makeitlessthan30words.
andScaNN Yourthirdgoalistogeneratealistofpotentialareasthatmight
requireverificationbasedonthecontentofthedocumenttoin-
creasefactualaccuracyoftheanswer.Yourresponseshouldbein
thebelowformat:
dataset basela incc euracy CoTP h baa sll eu lic nin eation C_ or Tat Pe basm eli is ns eing_ra Ct oe TP ‚Äú‚ÄòQuotes:<YourExtractedQuotes>
SQUAD 98.14 94.58 1 4.16 0.86 1.9
TRIVIA 63.95 86.27 22.85 6.45 13.18 6.38 Answer:<YourAnswer>
MS-MARCO 92.1 90.94 4.64 4.32 3.26 4.74
PotentialAreasforVerification:1)YourSpecificpointorsegment
Table10:BaselinevsCoTPevaluationmetrics(%)without
fromyouranswer.2)YourAnotherpointorsegmentfromyour
retrieval(question-doc.pairusedasitis)
answer.N)YourNthpointorsegmentfromyouranswer.‚Äú‚Äò
PromptforExecutingVerificationQuestionsandGeneratingVeri-
dataset basela ic nc euracy CoVe h baa sll eu lic nin eation C_ ora Vt ee basm eli is nsi eng_ra Ct oe Ve fiedResponse(ChainofVerification). :
SQUAD 98.14 95.96 1 3.24 0.86 0.8
TRIVIA 63.95 63.76 22.85 23.83 13.18 12.4 Belowisaquestion:<question>
MS-MARCO 92.1 92.6 4.64 5.54 3.26 1.86
Table11:BaselinevsCoVeevaluationmetrics(%)without Belowistheanswer:<answer>
retrieval(question-doc.pairusedasitis) Belowisthedocumentfromwhichtheanswerwasgenerated:
<document>
Basedonthepotentialareasforverification:<areasofverifica-
tion>
askingverificationquestionstoimprovetheoverallfactualaccuracy YouareansubjectmatterexpertworkingatContactCenters.
oftheanswersyouprovide. Yourexpertiseincludesimprovisinganswerstoquestionsaboutthe
Yourfirstgoalistoextract,word-for-word,anyquotesrelevant companytoincreasefactualcorrectnessusingthefactualaccuracy
tothequestionthatcouldbeusedtoanswerthequestion.Ifthere verificationquestionsprovidedtoyou.
arenoquotesinthisdocumentthatseemrelevanttotheprovided Yourgoalistocheckeachverificationpointagainstthedocu-
question,simplyreturn:"Ican‚Äôtfindanyrelevantquotes". ment,providefeedbackonanyinconsistencies,andthengenerate
Yoursecondgoalistouse*solely*thequotesextractedfrom afinalverified(usingthebelowlistedguidelines),conciseandaccu-
thefirstgoalandgenerateaconciseandaccurateanswer(using rateanswerinstrictlylessthan30wordsthataddressesthefactual
the below listed guideline) by rephrasing the quotes to answer inconsistencies.1)Theyshouldalwaysbeprofessional,positive,
thequestion.Ifthequotescouldnotbeusedtoanswertheques- friendly,andempathetic.2)Theyshouldnotcontainwordsthat
tion,simplyreturn:"Sorry,Icannotanswerthisquestion".1)They haveanegativeconnotation(Example:"unfortunately").3)They1stWorkshoponGenAIandRAGSystemsforEnterprise,October24,2024,Boise,Idaho,USA Veturi&Vaichaletal,2024
shouldalwaysbetruthfulandhonest.4)Theyshouldalwaysbe ishomeoftheGeorgiaAquariumandtheMartinLutherKingJr.
STRICTLYlessthan30words.Ifthegeneratedresponseifgreater NationalHistoricSite,dedicatedtotheAfrican-Americanleader‚Äôs
than30words,rephraseandmakeitlessthan30words. lifeandtimes.
Yourresponseshouldbeinthebelowformat: ReturnText:NOANSWERFOUND
‚Äú‚ÄòFeedback:1)YourVerificationforpoint1.2)YourVerification Examplewhereanswercouldbefoundinthearticles:
forpoint2.N)YourVerificationforpointN. Question:WhichcountyisSmyrnacityin?
FinalVerifiedResponse:[YourRevisedResponse]‚Äú‚Äò Document:SmyrnaisacityinCobbCounty,Georgia,United
States.CobbCountyisacountyintheU.S.stateofGeorgia,located
Promptforgeneratinganswerfromadocumentandquestion(open
intheAtlantametropolitanareainthenorthcentralportionofthe
sourcedatasets). Youareaquestionansweringbot.Yourjobisto
state.
generateanswertothequestionusingtheprovidedarticles.The
ReturnText:CobbCountyofthestateofGeorgia
answersshouldbederivedonlyfromthearticles.Iftheansweris
ProvideanswertothebelowQuestion/Queryusingthebelow
notpresentinthearticles,returnthetext-NOANSWERFOUND.
Document.
Theanswershouldbelessthan10wordsandinasentenceformat.
Question:<question>
Examplewhereanswercouldnotbefoundinthearticles:
Document:<document>
Question:WhichcountyisSmyrnacityin?
ReturnText:
Document:GeorgiaisasoutheasternU.S.statewhoseterrain
spanscoastalbeaches,farmlandandmountains.CapitalcityAtlanta