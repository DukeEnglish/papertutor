Gaussian Opacity Fields: Efficient and Compact Surface Reconstruction
in Unbounded Scenes
ZEHAOYU,UniversityofTÃ¼bingen,TÃ¼bingenAICenter,Germany
TORSTENSATTLER,CzechTechnicalUniversityinPrague,CzechRepublic
ANDREASGEIGER,UniversityofTÃ¼bingen,TÃ¼bingenAICenter,Germany
https://niujinshuchong.github.io/gaussian-opacity-fields
Fig.1. ApplyingTSDFfusionwithrendereddepthmapsfromthestate-of-the-artMip-Splatting[Yuetal.2024a]modelsresultsinnoisyandincomplete
meshes,whilemeshesextractedwithourmethodarecomplete,smoothanddetailed.ThisisachievedbyestablishingaGaussianopacityfieldfrom3D
Gaussians,whichenablesgeometryextractionbydirectlyidentifyingitslevel-set.Moreover,wegeneratetetrahedralmeshesfrom3DGaussiansandutilize
marchingtetrahedratoextractcompactandadaptivemeshes.
Recently,3DGaussianSplatting(3DGS)hasdemonstratedimpressivenovel 2021;Yarivetal.2021].Whilerecentadvancements[Lietal.2023;
viewsynthesisresults,whileallowingtherenderingofhigh-resolutionim- Yarivetal.2023;Yuetal.2022a,b]haveshownimpressiverecon-
agesinreal-time.However,leveraging3DGaussiansforsurfacereconstruc- structionresults,thesemethodsaremostlylimitedtoreconstructing
tionposessignificantchallengesduetotheexplicitanddisconnectednature foregroundobjects[RosuandBehnke2023]andcomputationalex-
of3DGaussians.Inthiswork,wepresentGaussianOpacityFields(GOF), pensivetooptimize[Lietal.2023;Yarivetal.2023].Forinstance,
anovelapproachforefficient,high-quality,andcompactsurfacerecon-
Neuralangelo[Lietal.2023]modelsthebackgroundseparatelywith
structioninunboundedscenes.OurGOFisderivedfromray-tracing-based
NeRFsandnecessitatesapproximately128GPUhourstoreconstruct
volumerenderingof3DGaussians,enablingdirectgeometryextraction
asinglescene.
from3DGaussiansbyidentifyingitslevelset,withoutresortingtoPoisson
reconstructionorTSDFfusionasinpreviouswork.Weapproximatethe Anotherresearchavenuefocusesondirectlyextractingsurfaces
surfacenormalofGaussiansasthenormaloftheray-Gaussianintersection fromNeRFâ€™sopacityfieldforreal-timerendering[Chenetal.2023a;
plane,enablingtheapplicationofregularizationthatsignificantlyenhances Rakotosaonaetal.2024;Reiseretal.2024;Tangetal.2022].These
geometry.Furthermore,wedevelopanefficientgeometryextractionmethod methodsemployamodularworkflowincludingopacityfieldtrain-
utilizingmarchingtetrahedra,wherethetetrahedralgridsareinducedfrom ing,meshextraction,simplification,andrefinement.Particularly
3DGaussiansandthusadapttothesceneâ€™scomplexity.Ourevaluations noteworthyistheBinaryOpacityGrids(BOG)[Reiseretal.2024],
revealthatGOFsurpassesexisting3DGS-basedmethodsinsurfacerecon- which excels at capturing intricate details in unbounded scenes
structionandnovelviewsynthesis.Further,itcomparesfavorablyto,or
through the use of super-sampling. To extract detailed surfaces,
evenoutperforms,neuralimplicitmethodsinbothqualityandspeed.
itrendersdepthmapstogenerateasparsehigh-resolutionvoxel
CCSConcepts:â€¢Computingmethodologiesâ†’Reconstruction;Render- gridandappliesaheuristicfusiontechniquetolabelthevoxelsas
ing;Machinelearningapproaches. insideoroutside.TheMarchingcubealgorithm[LorensenandCline
1998]isappliedtoextractahigh-resolutionmeshwithhundredsof
AdditionalKeyWordsandPhrases:NovelViewSynthesis,Differentiable
millionsofpointsandthousandsofmillionsoftriangles,whichis
Rendering,GaussianSplatting,SurfaceReconstruction,Multi-view-to-3D
thenthensimplifiedusingslowpost-processingtechniques[Gar-
landandHeckbert1997].Notably,asitfocusesonNVSratherthan
1 INTRODUCTION
surfacereconstruction,theextractedmeshesarenoisyandcontain
3DReconstructionfrommulti-viewimageshasbeenalong-standing fewer details in the background region, probably due to lack of
goalincomputervision,withvariousapplicationsinrobotics,graph- regularizationandcontractedspace[Barronetal.2022a]fusion.
ics,animation,virtualreality,andmore.SinceNeuralRadianceField Morerecently,3DGaussianSplatting(3DGS)[Kerbletal.2023]
(NeRF)[Mildenhalletal.2020]demonstratedimpressivenovelview representscomplexscenesasasetof3DGaussians,demonstrating
synthesis(NVS)resultswithimplicitrepresentations[Mescheder photorealisticNVSresultswhiletrainedefficientlyandrendered
etal.2019;Parketal.2019]andvolumerendering[Drebinetal.1988; atreal-time.Ithasbeenquicklyextendedtosurfacereconstruc-
KajiyaandVonHerzen1984;Levoy1990;Max1995],ithasbeen tion[Chenetal.2023b;GuÃ©donandLepetit2023;Huangetal.2024;
extendedtosurfacereconstructionwithoccupancynetworks[Oech-
sleetal.2021]andSignedDistanceFunctions(SDF)[Wangetal.
4202
rpA
61
]VC.sc[
1v27701.4042:viXra2 â€¢ ZehaoYu,TorstenSattler,andAndreasGeiger
Yuetal.2024b].Notably,Sugar[GuÃ©donandLepetit2023]regular- 2 RELATEDWORK
izesthe3DGaussianstoalignwithsurfacesandemploysPoisson 2.1 Novelviewsynthesis
surfacereconstruction[KazhdanandHoppe2013]toextractamesh
NeRF[Mildenhalletal.2020]utilizesamulti-layerperception(MLP)
fromrendereddepthmaps.2DGaussianSplatting(2DGS)[Huang
forscenerepresentation,includinggeometryandview-dependent
etal.2024]uses2DGaussiansinsteadof3DGaussiansasascene
appearances.TheMLPisoptimizedviaaphotometriclossthrough
representationforbettersurfacesrepresentationandutilizesTSDF
volumerendering[Drebinetal.1988;KajiyaandVonHerzen1984;
fusiontoreconstructamesh.Whilethesemethodshaveshown
Levoy1990;Max1995].Subsequentenhancementshavefocusedon
improvedreconstruction,theystrugglewithextractingfine-grained
optimizingNeRFâ€™strainingusingfeature-gridrepresentations[Chen
geometry[GuÃ©donandLepetit2023]andreconstructingbackground
etal.2022;Fridovich-Keiletal.2022;KulhanekandSattler2023;
regions[Huangetal.2024].Aprimarychallengeistheinconsistency
MÃ¼lleretal.2022;Sunetal.2022]andimprovingrenderingspeed
betweenmeshextractionandvolumerenderingduringtraining.
viabaking[Hedmanetal.2021;Reiseretal.2021,2023;Yarivetal.
Specifically,Poissonreconstructionignorestheopacityandscaleof
2023].Moreover,NeRFhasbeenadaptedtoaddresschallengesin
Gaussianprimitivesandrendereddepthmapsarenotsufficiently
anti-aliasing[Barronetal.2022b,2023]andunboundedscenemod-
reliable.Moreover,TSDFfusionstrugglestoaccuratelymodelthin
eling[Barronetal.2022a;Zhangetal.2020].Morerecently,3D
structuresandtoreconstructunboundedscenes.Resortingtohigh-
Gaussiansplatting[Kerbletal.2023]representscomplexscenes
resolutionvoxelgridsforTSDFleadstothecreationoflargemeshes,
with3DGaussians.ItdemonstratedimpressiveNVSresultswhile
similartoBOG[Reiseretal.2024],duetothelackofadaptivityin
beingoptimizedefficientlyandrenderinghigh-resolutionimages
thegridresolutionrelativetothesceneâ€™sgeometriccomplexity.
inreal-time.Subsequentworksimproveditsrenderingqualityvia
Contributions:Inthispaper,weproposeGaussianOpacityFields
anti-aliasing [Yu et al. 2024a] or extended it to dynamic scenes
(GOF),anovelapproachtoachieveefficient,high-quality,andcom-
modeling[Zhouetal.2024],andmore[ChenandWang2024].In
pactsurfacereconstructionfrom3DGaussiansdirectly.Ourkey
thiswork,weextend3DGSforhigh-qualitysurfacereconstruction
insightsarethreefold:First,weestablishaGaussianopacityfield
throughthedevelopmentofGaussianOpacityFields.Wefurther
fromasetof3DGaussians.Specifically,unlikeprojection-based
introduceanefficienttetrahedrongrid-basedmeshextractionalgo-
volumerendering,ourmethodleveragesanexplicitray-Gaussian
rithmtoextractcompactandsceneadaptivemeshes.
intersectiontodetermineaGaussianâ€™scontributionduringvolume
rendering.Ourray-tracing-inspiredformulafacilitatestheevalu- 2.2 3Dreconstruction
ationofopacityvaluesforanypointalongaray.Wethendefine
3DReconstructionfrommulti-viewimagesisafundamentalprob-
theopacityofany3Dpointastheminimalopacityoveralltraining
lemincomputervision.Multi-viewstereomethods[SchÃ¶nberger
viewsthatobservedthepoint.OurGOFisconsistentwithvolume
etal.2016;Yaoetal.2018;YuandGao2020]oftenemploycomplex
renderingduringtrainingandenablessurfaceextractionfrom3D
multi-stagepipelinesthatincludefeaturematching,depthestima-
Gaussiansbydirectlyidentifyingalevelset,withoutresortingto
tion,pointcloudfusion,andultimately,surfacereconstructionfrom
PoissonreconstructionorTSDFfusion.Second,weapproximate
aggregatedpointclouds[KazhdanandHoppe2013].Incontrast,neu-
thesurfacenormalsof3DGaussiansasthenormalsofintersec-
ralimplicitmethods[Oechsleetal.2021;Wangetal.2021;Yarivetal.
tionplanesbetweentherayandGaussians.Thistechniqueallows
2021]significantlysimplifythepipelinebyoptimizinganimplicit
fortheincorporationofregularizations[Huangetal.2024]during
surfacerepresentationviavolumerendering.Afteroptimization,tri-
training,thusenhancingthefidelityofgeometryreconstruction.
anglemeshescanbeextractedeasilywithMarchingcubes[Lorensen
Third,weproposeanefficientsurfaceextractiontechniquebased
andCline1998]atanyresolution.Notableadvancementshavebeen
ontetrahedra-grids.Recognizingthat3DGaussianseffectivelyin-
madethroughtheadoptionofmoreexpressivescenerepresenta-
dicate potential surface locations, we focus opacity evaluations
tions[Lietal.2023],advancedtrainingstrategies[Lietal.2023],
ontheseareas.Inparticular,weusethecenterandcornersof3D
andtheintegrationofmonocularpriors[Yuetal.2022b].Despite
boundingboxesaroundthe3DGaussianprimitivesasvertexset
theseadvances,thesemethodsaremostlylimitedinreconstructing
forthetetrahedralmesh.Uponassessingtheopacityattetrahedral
foregroundobjects[RosuandBehnke2023]andarecomputationally
points,weutilizethemarchingtetrahedraalgorithmfortriangle
expensivetooptimize[Lietal.2023;Yarivetal.2023].Furthermore,
meshextraction.Giventhatouropacityfieldschallengetheassump-
theuseofhigh-resolutiongridsforcapturingfinedetailsoftenre-
tionthatopacitychangeslinearly,wefurtherimplementanbinary
sultsinexcessivelylargemeshes.Bycontrast,weestablishGaussian
searchalgorithmtoaccuratelyidentifytheopacityfieldâ€™slevelset,
OpacityFieldsusing3DGS[Kerbletal.2023],whichfacilitatesfast
substantiallyenhancingthequalityoftheresultingsurfaces.
training.Weutilizemarchingtetrahedra[DoiandKoide1991;Shen
TodemonstratetheeffectivenessandefficiencyofourGaussian
etal.2021]toextractcompact,adaptive,anddetailedmeshesin
OpacityFields(GOF),wecarryoutextensiveexperimentsacross
unboundedscenes.
threechallengingdatasets[Barronetal.2022a;Jensenetal.2014;
Knapitschetal.2017].OurresultsindicatethatGOFnotonlymatches
2.3 SurfaceReconstructionwithGaussians
but,insomecases,surpassestheperformanceofexistingSDF-based
methods,whilebeingmuchfaster.Moreover,GOFoutperformsall InspiredbytheimpressiveNVSperformanceof3DGaussianSplat-
other3DGS-basedmethodsinbothsurfacereconstructionandnovel ting(3DGS)[Kerbletal.2023],researchershaveproposedtoutilize
viewsynthesis. 3DGaussiansforsurfacereconstruction.Recentefforts[Chenetal.
2023b;Yuetal.2024b]haveintegrated3DGaussianswithneuralGaussianOpacityFields:EfficientandCompactSurfaceReconstructioninUnboundedScenes â€¢ 3
implicitsurfaces,optimizingaSignedDistanceFunction(SDF)net-
workand3DGaussiansjointly.Whiletheseapproachesmarksome
advancements,theyalsoinherittheshortcomingsassociatedwith
implicitsurfacesaspreviouslydiscussed.Otherstudieshavefocused
onsurfaceextractionfromoptimizedGaussianprimitivesthrough
post-processingtechniques[GuÃ©donandLepetit2023;Huangetal.
2024;Turkulainenetal.2024].Notably,Sugar[GuÃ©donandLepetit
2023]adoptsPoissonsurfacereconstruction[KazhdanandHoppe
2013]toextractmeshesfromrendereddepthmaps.Meanwhile,2D Fig.2. Illustrationofraytracingvolumerendering.Evaluatinga3D
GaussianSplatting(2DGS)[Huangetal.2024]employsTSDFfusion Gaussianalongarayresultsina1DGaussian,whichhasaclosed-form
forthispurpose.Thoughthesemethodsachieveimprovedrecon- solutionforwhenitreachesmaximalvalue.Theopacityalongtherayis
structions,theyfacechallengesincapturingfine-grainedgeometry monotonouslyincreasinguntilitreachesthemaximalvalueandremains
andadequatelyreconstructingbackgroundareas.Inthiswork,we thesameafterwards.
deriveGaussianOpacityFieldsdirectlyfrom3DGaussians.OurGOF
isconsistentwiththevolumerenderingprocessforrenderingRGB systemofthe3DGaussianandnormalizethepointbyitsscale:
i sm eta ,g we is t. hI ot ue tn ra eb sl oe rs tid ni gre tc ot Psu or isf sa oc nee rex ctr oa nc st ti ro un ctb iy onid ae nn dti Tfy Si Dng Fa ful se iv oe nl
.
oğ‘” =(Rğ‘˜(oâˆ’pğ‘˜))âŠ™s ğ‘˜âˆ’1 (2)
Additionally,weproposeatetrahedrongrid-basedtechniquefor rğ‘” =Rğ‘˜râŠ™s ğ‘˜âˆ’1 (3)
meshextraction,resultingindetailedandcompactmeshes. xğ‘” =oğ‘”+ğ‘¡rğ‘” (4)
whereâŠ™denoteselement-wisemultiplication.Inthislocalcoordi-
3 METHOD natesystem,theGaussianvalueatanypointalongtheraybecomes
a1DGaussian,whichisdescribedby:
Givenmultipleposedandcalibratedimages,ourgoalistorecon-
structthe3Dsceneefficientlywhileallowingdetailedandcompact G ğ‘˜1ğ· (ğ‘¡)=Gğ‘˜(xğ‘”)=ğ‘’âˆ’1 2xğ‘‡ ğ‘”xğ‘” (5)
surfaceextractionandphotorealisticnovelviewsynthesis.Tothis
ThemaximumofEq.5hasaclosedformsolutionat
end,wefirstconstructaGaussianOpacityField(GOF)from3D
Gaussians,enablinggeometryextractiondirectlybyidentifyinga ğµ
ğ‘¡âˆ—=âˆ’ (6)
levelset,eliminatingtheneedfortraditionalPoissonreconstruc- ğ´
tion or TSDF fusion. Next, we extend two effective regularizers whereğ´=rğ‘‡ ğ‘”rğ‘”andğµ=oğ‘‡ ğ‘”rğ‘”.Now,wedefinethecontributionE
from2DGS[Huangetal.2024]toour3DGaussians,improving ofaGaussianGğ‘˜ foragivencameracenteroandraydirectionras:
reconstructionquality.Finally,weproposeanoveltetrahedra-based
methodtoextractdetailedandcompactmeshesfromGOFswith
E(Gğ‘˜,o,r)=G ğ‘˜1ğ· (ğ‘¡âˆ—) (7)
marchingtetrahedra.
VolumeRendering:Similarto3DGS[Kerbletal.2023],thecolor
ofacamerarayisrenderedviaalphablendingaccordingtothe
3.1 Modeling primitiveâ€™sdepthorder1,...,ğ¾:
Similartopriorworks[Kerbletal.2023;Zwickeretal.2001],we ğ¾ ğ‘˜âˆ’1
âˆ‘ï¸ (cid:214)
representthescenewithasetof3DGaussianprimitives{Gğ‘˜|ğ‘˜ =
c(o,r)= cğ‘˜ğ›¼ ğ‘˜E(Gğ‘˜,o,r) (1âˆ’ğ›¼ ğ‘—E(Gğ‘˜,o,r)) (8)
1,Â·Â·Â·,ğ¾}.Thegeometryofeach3DGaussianGğ‘˜ isparameterized ğ‘˜=1 ğ‘—=1
byanopacityğ›¼ ğ‘˜ âˆˆ [0,1],centerpğ‘˜ âˆˆ R3Ã—1,scales âˆˆ R3Ã—1,and wherecğ‘˜ istheview-dependentcolor,modeledwithsphericalhar-
rotationRâˆˆR3Ã—3parameterizedbyaquaternion: monics.Toefficientlyrenderanimage,weutilizethesametile-based
renderingprocessasin3DGS[Kerbletal.2023].
Gğ‘˜(x)=ğ›¼ ğ‘˜ğ‘’âˆ’1 2(xâˆ’pğ‘˜)ğ‘‡ğšº ğ‘˜âˆ’1(xâˆ’pğ‘˜) (1) 3.2 GaussianOpacityFields
OnesignificantbenefitofusingexplicitRay-Gaussianintersection
insteadofprojectionisthatitallowsevaluatingtheopacityvalue
whereğšº
ğ‘˜
âˆˆR3Ã—3isacovariancematrixdefinedasğšº
ğ‘˜
=Rğ‘˜sğ‘˜sğ‘‡ ğ‘˜Rğ‘‡ ğ‘˜. ortransmittanceofanypointalongtheray.Letâ€™sfirstconsiderthe
RayGaussianIntersection:Insteadofprojecting3DGaussians casewhenthereisonlyasingleGaussianGğ‘˜ alongtheray.Inthis
to2DscreenspaceandevaluatingtheGaussianin2D,weevaluate case,theopacityofanypointalongtherayis:
thecontributionofaGaussiantoaraywithexplicitray-Gaussian (cid:40) G1ğ·(ğ‘¡) ifğ‘¡ â‰¤ğ‘¡âˆ—
intersection[Gaoetal.2023;KeselmanandHebert2022].Theray- Oğ‘˜(Gğ‘˜,o,r,ğ‘¡)= Gğ‘˜
1ğ·(ğ‘¡âˆ—) ifğ‘¡ >ğ‘¡âˆ—
GaussianintersectionisdefinedasthepointwheretheGaussian ğ‘˜
reachesitsmaximumvaluealongtheray.Specifically,givenacam- wherex=o+ğ‘¡r.Intuitively,theopacityincreasesuntilitreaches
eracenterato âˆˆ R3Ã—1 andaraydirectionr âˆˆ R3Ã—1,anypoint its maximal value, and after that it remains the same since the
xâˆˆR3Ã—1alongtheraycanbewrittenasx=o+ğ‘¡r,whereğ‘¡isdepth transmittance,e.g.1âˆ’O,ismonotonouslydecreasingalongaview
oftheray.Wefirsttransformthepointxtothelocalcoordinate ray,asillustratedinFigure2.Therefore,theopacityatanypoint4 â€¢ ZehaoYu,TorstenSattler,andAndreasGeiger
alongaraygivenasetofGaussianscanbedefinedsimilartothe To mitigate this issue,
volumerenderingprocessinEq.8as: wedefinethenormalofa
3DGaussianasthenormal
ğ¾ ğ‘˜âˆ’1
âˆ‘ï¸ (cid:214) of the intersection plane
O(o,r,ğ‘¡)= ğ›¼ ğ‘˜Oğ‘˜(Gğ‘˜,o,r,ğ‘¡) (1âˆ’ğ›¼ ğ‘—Oğ‘˜(Gğ‘˜,o,r,ğ‘¡)) (9)
given a ray direction. An
ğ‘˜=1 ğ‘—=1
illustrationisshowninthe
Now, we can define the opacity of a 3D point x as the minimal inset. Therefore, the nor-
opacityvalueamongalltrainingviewsorviewingdirections: mal is approximated as nğ‘– = âˆ’Rğ‘‡(rğ‘” âŠ™ sâˆ’1) and we apply the
depth-normalconsistencyregularisation:
O(x)=minO(o,r,ğ‘¡) (10)
(r,ğ‘¡) Lğ‘› =âˆ‘ï¸ ğœ” ğ‘–(1âˆ’nğ‘–âŠ¤N) (12)
WecallthisGaussianOpacityField(GOF)sinceitisanopacityfield
ğ‘–
derivedfrom3DGaussians.OurGOFsharessimilaritiestothevisual
whereğ‘–indexesoverintersectedGaussiansalongtheray,ğœ”denotes
hull[Laurentini1994]orspacecarving[KutulakosandSeitz2000].
theblendingweight,andNisthenormalestimatedbythegradient
Butinsteadofusingasilhouettewheretheopacityvalueofaray
ofthedepthmap[Huangetal.2024].
(allpointsontheray)iseither1or0,GOFusesvolumerendering
foreachpointbasedon3DGaussians.
FinalLoss:Finally,weoptimizeourmodelfromaninitialsparse
pointcloudusingmultipleposedimagesbyminimizingthefollow-
OurGOFisconsistentwiththevolumerenderingprocessfor
ingloss:
RGBrenderingduringtraining.WithGOF,wecanextractsurfaces
directlybyidentifyingtheirlevelsets,similartoUNISURF[Oechsle L=Lğ‘ +ğ›¼Lğ‘‘ +ğ›½Lğ‘› (13)
etal.2021],withoutresortingtoPoissonreconstruction[GuÃ©don whereLğ‘ isanRGBreconstructionlosscombiningL1 withthe
andLepetit2023]orTSDFfusion[Huangetal.2024].Wewilldiscuss D-SSIMtermfrom[Kerbletal.2023],whileLğ‘‘ andLğ‘› areregu-
ourmethodforefficientandcompactmeshextractioninSection3.4. larizationterms.Notethat,weutilizethedecoupledappearance
WealsonotethatGOFsareageneralformulaaslongasthescene modelingproposedinVastGaussian[Linetal.2024]tomodelthe
representationisasetof3DGaussians.Forexample,wecanuseit unevenilluminationfortheTanksandTemplesdataset[Knapitsch
toextractameshfromapretrained3DGS[Kerbletal.2023]orMip- etal.2017],whereasmallconvolutionalneuralnetworkisusedto
Splatting[Yuetal.2024a]model,whereprojection-basedvolume predictimage-dependentcolorssuchthatthemodelwillnotfake
renderingisusedfortraining,aswewillshownintheexperiments. inconsistentilluminationwithgeometry.
3.3 Optimization 3.4 SurfaceExtraction
Optimizing3DGaussianswithpurephotometriclossleadstonoisy Post-training, the conventional step towards surface or triangle
resultsas3Dreconstructionfrommulti-viewsisanunderconstrained mesh extraction involves densely evaluating the opacity values
problem[Barronetal.2022a;Zhangetal.2020].Therefore,weex- withinregionsofinterest,atechniquewell-suitedtosimplescenar-
tendtheregularizationtermsin2DGS[Huangetal.2024]toop- iosliketheDTUDataset[Jensenetal.2014],asdoneinprevious
timizeour3DGaussians,includingadepthdistortionlossanda work[Oechsleetal.2021;Wangetal.2021;Yarivetal.2021]Fora
normalconsistencyloss. largescaleunboundedscene,somehaveadopteddenseevaluation
DepthDistortion:Weapplythedepthdistortionloss[Huangetal. inacontractedspace[Yarivetal.2023].However,denseevaluation
2024]totheray-GaussianintersectiontoconcentrateGaussians forgridsincurssubstantialcomputationalcostsduetothecubic
alongtheray: growthofcomplexitywithgridresolution.Unfortunately,capturing
âˆ‘ï¸ finedetailsnecessitateshigh-resolutiongrids,leadingtosignificant
Lğ‘‘ = ğœ” ğ‘–ğœ” ğ‘—|ğ‘¡ ğ‘– âˆ’ğ‘¡ ğ‘—| (11) overhead.Alternativesparsegridsmayreducedenseevaluation
ğ‘–,ğ‘—
needsbutstillresultinhugemeshes,oftencomprisinghundredsof
whereğ‘–,ğ‘— indexoverGaussianscontributedtotherayandğœ” ğ‘– = millionsofpointsandbillionsoffaces.Simplifyingsuchlargeand
ğ›¼ ğ‘˜E(Gğ‘˜,o,r)(cid:206)ğ‘˜ ğ‘—=âˆ’ 11 (1âˆ’ğ›¼ ğ‘—E(Gğ‘˜,o,r)) istheblendingweightof complexmeshestypicallyrequiresaslowpost-processingstep.For
theğ‘–âˆ’thGaussianandğ‘¡ ğ‘–isthedepthoftheintersectionpointinEq.6. instance,meshsimplificationinBOG[Reiseretal.2024]requires
However,thedistortionlossminimizesboththedistancebetween approximately4hours.Tocircumventthesechallenges,weintro-
GaussiansandtheweightsofeachGaussianwhereasminimizingthe duceanovelmethodforextractingcompactandadaptivemeshes
weightsoftheGaussianscouldleadtoanincreaseinalphavalues usingtetrahedralgrids.
forGaussiansthatareblendedfirst,whichresultsinexaggerated
TetrahedralGridsGeneration:Ourprimaryinsightisthatthe
Gaussians,resultinginfloaters.Therefore,wedetachthegradient
positionandscaleof3DGaussianprimitivesserveasreliableindica-
ofweightsğ‘¤ andonlyminimizethedistancebetweenGaussians.
ğ‘– torsforthepresenceofsurfaces.Tocapitalizeonthis,wegeneratea
NormalConsistency:Akeychallengeofapplying2DGSâ€™snormal 3Dboundingboxat3-sigmaaroundeachGaussianprimitive,where
consistencyregularization[Huangetal.2024]to3DGaussiansis itscenterhashighestopacityanditscornershavesmallestopacity.
thatthegradientof3DGaussiansalwayspointsoutwardsfromthe Wethenestablishtetrahedralgridswiththecenterandcornersof
centers.Thisleadstodiscontinuitywhentheraypassesthecenter 3Dboundingboxes.DrawinginspirationfromTetra-NeRF[Kul-
ofGaussians,makingthetheoptimizationdifficulty. hanekandSattler2023],weemploytheCGALLibrary[Jaminetal.GaussianOpacityFields:EfficientandCompactSurfaceReconstructioninUnboundedScenes â€¢ 5
Table 1. Quantitative results on the Tanks and Temples
Dataset [Knapitsch et al. 2017]. Reconstructions are evaluated
withtheofficialevaluationscriptsandwereportF1-scoreandaverage
optimizationtime.GOFoutperformsall3DGS-basedsurfacereconstruction
methodsbyalargemarginandperformscomparablywiththeSOTAneural
implicitmethodswhileoptimizingsignificantlyfaster.
Implicit Explicit
NeuS Geo-Neus Neurlangelo SuGaR 3DGS 2DGS Ours
Barn 0.29 0.33 0.70 0.14 0.13 0.36 0.51
(a)MarchingCubes (b)MarchingCubeswithbinarysearch Caterpillar 0.29 0.26 0.36 0.16 0.08 0.23 0.41
Fig.3. QualitycomparisonofapplyingbinarysearchtotheMarching Courthouse 0.17 0.12 0.28 0.08 0.09 0.13 0.28
cubesalgorithmonourGaussianOpacityField.Strongstepartifacts Ignatius 0.83 0.72 0.89 0.33 0.04 0.44 0.68
Meetingroom 0.24 0.20 0.32 0.15 0.01 0.16 0.28
canbeobservedinMarchingcubesresultssincethelinearassumptiondoes
Truck 0.45 0.45 0.48 0.26 0.19 0.26 0.59
notholdinourGOF.Applyingourbinarysearchalgorithmeliminatesthis Mean 0.38 0.35 0.50 0.19 0.09 0.30 0.46
artifact. Time >24h >24h >24h >1h 14.3m 34.2m 1h
2024]forDelaunaytriangulationtoconstructtetrahedralcells.The
4.1 ImplementationDetails
generatedtetrahedralgridmightconnectpointsacrosssignificant
distances. Therefore, we employ an additional filtering step for WebuildGOFupontheopen-source3DGScodebase[Kerbletal.
thetetrahedralcells,removinganycellwhoseedgesconnectnon- 2023]andimplementcustomCUDAkernelsforray-tracing-based
overlappingGaussians.Gaussiansareconsiderednon-overlapping volume rendering, regularizations, and opacity evaluation. Reg-
whenthelengthoftheedgeconnectingthemexceedsthesumof ularization parameters are set toğ›¼ = 1000 for bounded scenes,
theirmaximumscales. ğ›¼ =100forunboundedscenes,andğ›½ =0.05forallscenes,following
2DGS[Huangetal.2024].Wemakeaslightchangeto3DGSâ€™sadap-
EfficientOpacityEvaluation:Toefficientlyevaluatetheopacityof
tivedensificationstrategy,whichincreasesthenumberofprimitives,
theverticesofthetetrahedralgrid,wedesignatile-basedevaluation
toenhanceuniformityofGaussiansandmitigateover-reconstructed
algorithm,inspiredby3DGS[Kerbletal.2023].Specifically,wefirst
regions.Moredetailsofourchangesareprovidedinthesupplemen-
projecttheverticestoimagespaceandidentifythecorresponding
tarymaterial.Similarto3DGS,westopdensificationat15kitera-
tilesfortheseprojections.Thesepointsarethenorganizedaccording
tionsandoptimizeallofourmodelsfor30kiterations.Formesh
totheirtileID.Foreachtile,weretrievethelistofpointsthatare
extraction,weadapttheMarchingTetrahedraalgorithm[Shenetal.
projectedwithinit,projectthesepointsagaintoidentifythepixel
2021]fromtheKaolinlibrary[FujiTsangetal.2022]withourbi-
thatitfallsinside,andidentifytheGaussiansthatcontributetothis
narysearchalgorithmandextractthemeshforthe0.5level-set.All
pixel.Finally,weenumerateallpointstoevaluatetheiropacitybased
experimentsareconductedonanNVIDIAA100GPU.
onthepre-filteredlistofGaussians.Anoverviewofthealgorithm
isprovidedinthesupplementarymaterial.
4.2 GeometryEvaluation
BinarySearchofLevelSet:Upondeterminingtheopacityval-
WefirstcompareagainstbothSOTAimplicitandexplicitsurface
uesforthetetrahedralgrid,weproceedtoextracttrianglemeshes
reconstructionmethodsontheTanksandTemplesDataset.Recon-
usingtheMarchingTetrahedramethod[Shenetal.2021].Tradi-
structionsareevaluatedonlyfortheforegroundobjectssincethe
tionalmarchingalgorithms,includingMarchingCubes[Lorensen
groundtruthpointclouddonotcontainbackgroundregions.As
andCline1998]andMarchingTetrahedra,typicallyrelyonlinear
showninTable1,ourmethodiscompetitivewithleadingimplicit
interpolationtoapproximatethelevelset,presumingtheunderly-
approach[Lietal.2023]whilebeingmuchmoreefficienttoopti-
ingfieldâ€™slinearity.Thisassumption,however,misalignswiththe
mize.Notethatmostimplicitapproaches[Lietal.2023;Wangetal.
characteristicsofourGaussianOpacityField,leadingtoartifacts
2021]onlyreconstructtheforegroundobjects,ourmethodisableto
duetolinearinterpolation,asshowninFigure3(a).Toovercome
reconstructdetailedmeshesalsoforthebackgroundregions,which
thisdiscrepancyandaccuratelyidentifythelevelsetwithinour
isofgreatimportanceformesh-basedreal-timerendering[Reiser
non-linearopacityfield,werelaxthelinearassumptiontoamono-
etal.2024].Furthermore,whileourmethodisslightlyslowerthan
tonically increasing assumption. This adjustment allows for the
3DGS[Kerbletal.2023]and2DGS[Huangetal.2024]duetothe
implementationofabinarysearchalgorithmtopreciselyidentify
ray-Gaussianintersectioncomputation,itsignificantlyoutperforms
thelevelset.Inpractice,wefoundthatconducting8iterationsof
allSOTA3DGS-basedmethodsintermsofreconstructionquality.A
binarysearchâ€”effectivelysimulating256denseevaluationsâ€”yields
qualitativecomparisonisshowninFigure4.GOFreconstructsfine-
consistentandreliableoutcomes.Acomparisonhighlightingthe
detailedsurfacesforbothforegroundobjectsandthebackground
improvementsofbinarysearchisshowninFigure3.
regions.Bycontrast,meshesextractedfromSuGaR[GuÃ©donand
Lepetit 2023] are noisy, while 2DGS [Huang et al. 2024] fails to
4 EXPERIMENTS
extractgeometryforthebackgroundregions.
WeconductathoroughevaluationofourGaussianOpacityField WefurthercompareagainstSOTAsurfacereconstructionmeth-
(GOF),comparingitssurfacereconstructionandnovelviewsysnthe- odsontheDTUdataset[Jensenetal.2014].AsshowninTable2,
sisagainstleadingmethods.Wefurthervalidatetheeffectiveness ourmethodoutperformsall3DGS-basedmethods.Despiteaper-
ofitskeycomponentsthroughablationstudies. formancegapwiththeleadingimplicitreconstructionmethod[Li6 â€¢ ZehaoYu,TorstenSattler,andAndreasGeiger
SuGar[GuÃ©donandLepetit2023] 2DGS[Huangetal.2024] Ours GT
Fig.4. SurfaceReconstructionontheTanksandTemplesDataset[Knapitschetal.2017].Weshowtherenderednormalmapsfromextractmeshes
togetherwithGTimagesforreference.SuGaRâ€™smeshisnoisy[GuÃ©donandLepetit2023]and2DGSfailsatreconstructingbackgroundregions[Huangetal.
2024].Incontrast,ourmethodcanreconstructdetailedsurfacesforbothforegroundobjectsandbackgroundregions.
Table2. QuantitativecomparisonontheDTUDataset[Jensenetal.2014].WeshowtheChamferdistanceandaverageoptimizationtime.Ourmethod
achievesthehighestreconstructionaccuracyamongotherexplicitmethods.
24 37 40 55 63 65 69 83 97 105 106 110 114 118 122 Mean Time
NeRF[Mildenhalletal.2021] 1.90 1.60 1.85 0.58 2.28 1.27 1.47 1.67 2.05 1.07 0.88 2.53 1.06 1.15 0.96 1.49 >12h
VolSDF[Yarivetal.2021] 1.14 1.26 0.81 0.49 1.25 0.70 0.72 1.29 1.18 0.70 0.66 1.08 0.42 0.61 0.55 0.86 >12h
NeuS[Wangetal.2021] 1.00 1.37 0.93 0.43 1.10 0.65 0.57 1.48 1.09 0.83 0.52 1.20 0.35 0.49 0.54 0.84 >12h
Neuralangelo[Lietal.2023] 0.37 0.72 0.35 0.35 0.87 0.54 0.53 1.29 0.97 0.73 0.47 0.74 0.32 0.41 0.43 0.61 >12h
3DGS[Kerbletal.2023] 2.14 1.53 2.08 1.68 3.49 2.21 1.43 2.07 2.22 1.75 1.79 2.55 1.53 1.52 1.50 1.96 11.2m
SuGaR[GuÃ©donandLepetit2023] 1.47 1.33 1.13 0.61 2.25 1.71 1.15 1.63 1.62 1.07 0.79 2.45 0.98 0.88 0.79 1.33 âˆ¼1h
2DGS[Huangetal.2024] 0.48 0.91 0.39 0.39 1.01 0.83 0.81 1.36 1.27 0.76 0.70 1.40 0.40 0.76 0.52 0.80 18.8m
Ours 0.50 0.82 0.37 0.37 1.12 0.74 0.73 1.18 1.29 0.68 0.77 0.90 0.42 0.66 0.49 0.74 30m
etal.2023],GOFâ€™soptimizationismuchfaster.Thisperformance Table3. QuantitativeresultsonMip-NeRF360[Barronetal.2022b]
disparityisattributedtotheDTUdatasetâ€™sstrongview-dependent
dataset.OurmethodachievedSOTANVSresults,especiallyintheoutdoor
scenesintermsofLPIPS.
appearance.Utilizingabetterview-dependentappearancemodel-
ing[Verbinetal.2022]oracoarse-to-finetrainingstrategy[Lietal.
OutdoorScene Indoorscene
2023]couldpotentiallyimprovethereconstructions.
PSNRâ†‘ SSIMâ†‘ LPIPSâ†“ PSNRâ†‘ SSIMâ†‘ LIPPSâ†“
NeRF 21.46 0.458 0.515 26.84 0.790 0.370
DeepBlending 21.54 0.524 0.364 26.40 0.844 0.261
4.3 NovelviewSynthesis
InstantNGP 22.90 0.566 0.371 29.15 0.880 0.216
ToevaluatetheNVSresultsofGOF,wefurthercompareagainst MERF 23.19 0.616 0.343 27.80 0.855 0.271
SOTANVSmethodsontheMip-NeRFdataset[Barronetal.2022a]. MipNeRF360 24.47 0.691 0.283 31.72 0.917 0.180
ThequantitativeresultsareshowninTable3.GOFnotonlyper- Mobile-NeRF 21.95 0.470 0.470 - - -
formsslightlybetterthanallother3DGS-basedmethodsinterms BakedSDF 22.47 0.585 0.349 27.06 0.836 0.258
SuGaR 22.93 0.629 0.356 29.43 0.906 0.225
ofPSNR,itoutperformsallothermethodssignificantlyinterms
BOG 23.94 0.680 0.263 27.71 0873 0.227
ofLPIPS[Zhangetal.2018]intheoutdoorscenes.Themainim-
3DGS 24.64 0.731 0.234 30.41 0.920 0.189
provementscomefromourimproveddensificationstrategy.Inthe
Mip-Splatting 24.65 0.729 0.245 30.90 0.921 0.194
supplementarymaterial,weshowthataddingourdensificationstrat- 2DGS 24.21 0.709 0.276 30.10 0.913 0.211
egyto3DGS[Kerbletal.2023]andMip-Splatting[Yuetal.2024a] Ours 24.82 0.750 0.202 30.79 0.924 0.184
improvestheNVSresultsbyalargemargin.Fortheindoorscenes,
ourresultsaresimilartoMip-Splatting[Yuetal.2024a],withless
than0.1PSNRdifference,whichweattributetoourregularization, outperformsSugar[GuÃ©donandLepetit2023]and2DGS[Huang
whichtradesoffNVSandsurfacereconstruction.Ourmethodalso et al. 2024] in all metrics. We show a qualitative comparison of
ticilpmi
ticilpxeGaussianOpacityFields:EfficientandCompactSurfaceReconstructioninUnboundedScenes â€¢ 7
SuGar[GuÃ©donandLepetit2023] 2DGS[Huangetal.2024] Ours GT
Fig.5. ReconstructionsontheMip-NeRF360Dataset[Barronetal.2022a].WeshowtherenderednormalmapsfromextractmeshestogetherwithGT
imagesforreference.Ourmethodcanreconstructdetailedsurfacesforbothforegroundobjectsandbackgroundregionswhilemeshesfrompreviousworkare
noisy[GuÃ©donandLepetit2023]orfailtoreconstructbackgroundregionsandthinstructures,suchasthespokesinthebicyclescene[Huangetal.2024].
SOTA3DGS-basedmodel,Mip-Splatting[Yuetal.2024a]andcom-
pareitwithTSDFfusion.Acomparisonoftheextractedmeshesis
showninFigure6.ThemeshextractedfromTSDFfusionisnoisyand
hasalotofholesontheground,duetotheinconsistencyofdepth.
Mip-Splatting+TSDFFusion Mip-Splatting+GOF GTImage Bycontrast,ourextractedmeshismorecomplete.Ourmethodalso
Fig.6. Comparisonofmeshextractionmethods.ApplyingGOFtoSOTA extractsdetailedsurfacesforthebackgroundregions.Resultsin
Mip-Splatting[Yuetal.2024a]yieldssignificantimprovementsoverTSDF, Table4(Avs.BandCvs.F)furtherindicatetheeffectivenessofour
enablingcompletemeshextractionforbackgroundregions. method.
RegularizationandAppearanceModeling:AsshowninTable4
Table4. AblationonTNTDataset.GOFsignificantlyimprovessurface
(Dvs.F),usingthenormalregularizationduringtrainingsignifi-
extractionqualityandourregularizationanddecoupledappearancemodel-
cantlyimprovesreconstructionquality,whichisconsistentwiththe
ingfurtherimprovetheresults.
observationin2DGS[Huangetal.2024].Includingthedecoupled
Precisionâ†‘ Recallâ†‘ F-scoreâ†‘ appearancemodeling[Linetal.2024]furtherimprovestherecon-
A.Mip-Splattingw/TSDF 0.15 0.25 0.16 structionresultsasshowninTable4(Evs.F),sincethemodelis
B.Mip-Splattingw/GOF 0.40 0.33 0.36
lesslikelytomodelview-dependentappearancewithgeometry.
C.Oursw/oGOF 0.37 0.45 0.39
D.Oursw/onormalconsistency 0.41 0.35 0.37
E.Oursw/odecoupledappearance 0.49 0.39 0.43
F.Ours 0.54 0.42 0.46 5 CONCLUSION
WehavepresentedGaussianOpacityFields(GOF),anovelmethod
forefficient,high-quality,andcompactsurfacereconstructionin
extractedmeshesinFigure5.Similartoourobservationsonthe
unboundedscenes.OurGOFisderivedfromray-tracing-basedvol-
TanksandTemplesdataset[Knapitschetal.2017],GOFisableto
umerenderingof3DGaussians,maintainingconsistencywithRGB
reconstructdetailedsurfacesforbothforegroundobjectsandback-
rendering.OurGOFenablesgeometryextractiondirectlyfrom3D
groundregions,whileSuGaRâ€™s[GuÃ©donandLepetit2023]meshis
Gaussiansbyidentifyingitslevelset,withoutPoissonreconstruc-
noisyandhasfewerdetailsand2DGSâ€™sfailstoextractmeshesfor
tion or TSDF. We approximate the surface normal of Gaussians
thebackgroundregions.
as the normal of the ray-Gaussian intersection plane and apply
depth-normalconsistencyregularizationtoenhancegeometryre-
4.4 AblationStudy
constructions.Furthermore,weproposeanefficientandcompact
MeshExtraction:OurGOFenablesmeshextractionfrom3DGaus- meshextractionmethodutilizingmarchingtetrahedra,wherethe
siansdirectlybyidentifyingalevelsetwithoutresortingtoPoisson tetrahedralgridsareinducedfrom3DGaussians.Ourevaluations
reconstructionorTSDFfusion.Todemonstratetheeffectiveness revealthatGOFsurpassesexistingmethodsinbothsurfacerecon-
andgeneralizabilityofourmeshextractionstrategy,weapplyittoa structionandnovelviewsynthesisinunboundedscenes.8 â€¢ ZehaoYu,TorstenSattler,andAndreasGeiger
Acknowledgement:WethankChristianReiserforinsightfuldis- Graphics36,4(2017).
cussionsandvaluablefeedbackthroughouttheproject.Wealso JonasKulhanekandTorstenSattler.2023.Tetra-NeRF:RepresentingNeuralRadiance
thankBinbinHuangforproofreading.ZYandAGaresupportedby
FieldsUsingTetrahedra.arXivpreprintarXiv:2304.09987(2023).
KiriakosNKutulakosandStevenMSeitz.2000.Atheoryofshapebyspacecarving.
theERCStartingGrantLEGO-3D(850533)andDFGEXCnumber Internationaljournalofcomputervision38(2000),199â€“218.
2064/1-projectnumber390727645.TSissupportedbyaCzech AldoLaurentini.1994.Thevisualhullconceptforsilhouette-basedimageunderstanding.
IEEETransactionsonpatternanalysisandmachineintelligence16,2(1994),150â€“162.
ScienceFoundation(GACR)EXPROgrant(UNI-3D,grantno.23- MarcLevoy.1990.Efficientraytracingofvolumedata.ACMTransactionsonGraphics
07973X). (TOG)9,3(1990),245â€“261.
ZhaoshuoLi,ThomasMÃ¼ller,AlexEvans,RussellHTaylor,MathiasUnberath,Ming-
YuLiu,andChen-HsuanLin.2023. Neuralangelo:High-FidelityNeuralSurface
REFERENCES Reconstruction.InIEEEConferenceonComputerVisionandPatternRecognition
(CVPR).
JonathanT.Barron,BenMildenhall,DorVerbin,PratulP.Srinivasan,andPeterHedman. JiaqiLin,ZhihaoLi,XiaoTang,JianzhuangLiu,ShiyongLiu,JiayueLiu,YangdiLu,
2022a.Mip-NeRF360:UnboundedAnti-AliasedNeuralRadianceFields.CVPR(2022). XiaofeiWu,SongcenXu,YouliangYan,andWenmingYang.2024.VastGaussian:
JonathanTBarron,BenMildenhall,DorVerbin,PratulPSrinivasan,andPeterHedman. Vast3DGaussiansforLargeSceneReconstruction.InConferenceonComputerVision
2022b.Mip-nerf360:Unboundedanti-aliasedneuralradiancefields.InProceedings andPatternRecognition(CVPR).
oftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.5470â€“5479. WilliamELorensenandHarveyECline.1998.Marchingcubes:Ahighresolution3D
JonathanT.Barron,BenMildenhall,DorVerbin,PratulP.Srinivasan,andPeterHedman. surfaceconstructionalgorithm.InSeminalgraphics:pioneeringeffortsthatshaped
2023.Zip-NeRF:Anti-AliasedGrid-BasedNeuralRadianceFields.(2023). thefield.347â€“353.
AnpeiChen,ZexiangXu,AndreasGeiger,JingyiYu,andHaoSu.2022. TensoRF: NelsonMax.1995.Opticalmodelsfordirectvolumerendering.IEEETransactionson
TensorialRadianceFields.InEuropeanConferenceonComputerVision(ECCV). VisualizationandComputerGraphics1,2(1995),99â€“108.
GuikunChenandWenguanWang.2024. Asurveyon3dgaussiansplatting. arXiv LarsMescheder,MichaelOechsle,MichaelNiemeyer,SebastianNowozin,andAndreas
preprintarXiv:2401.03890(2024). Geiger.2019.OccupancyNetworks:Learning3DReconstructioninFunctionSpace.
HanlinChen,ChenLi,andGimHeeLee.2023b.NeuSG:NeuralImplicitSurfaceRe- InConferenceonComputerVisionandPatternRecognition(CVPR).
constructionwith3DGaussianSplattingGuidance.arXivpreprintarXiv:2312.00846 BenMildenhall,PratulP.Srinivasan,MatthewTancik,JonathanT.Barron,RaviRa-
(2023). mamoorthi,andRenNg.2020.NeRF:RepresentingScenesasNeuralRadianceFields
ZhiqinChen,ThomasFunkhouser,PeterHedman,andAndreaTagliasacchi.2023a. forViewSynthesis.InECCV.
Mobilenerf:Exploitingthepolygonrasterizationpipelineforefficientneuralfield BenMildenhall,PratulPSrinivasan,MatthewTancik,JonathanTBarron,RaviRa-
renderingonmobilearchitectures.InProceedingsoftheIEEE/CVFConferenceon mamoorthi,andRenNg.2021.Nerf:Representingscenesasneuralradiancefields
ComputerVisionandPatternRecognition.16569â€“16578. forviewsynthesis.Commun.ACM65,1(2021),99â€“106.
AkioDoiandAkioKoide.1991. Anefficientmethodoftriangulatingequi-valued ThomasMÃ¼ller,AlexEvans,ChristophSchied,andAlexanderKeller.2022. Instant
surfacesbyusingtetrahedralcells. IEICETRANSACTIONSonInformationand NeuralGraphicsPrimitiveswithaMultiresolutionHashEncoding. ACMTrans.
Systems74,1(1991),214â€“224. Graph.41,4,Article102(July2022),15pages. https://doi.org/10.1145/3528223.
RobertADrebin,LorenCarpenter,andPatHanrahan.1988.Volumerendering.ACM 3530127
SiggraphComputerGraphics22,4(1988),65â€“74. MichaelOechsle,SongyouPeng,andAndreasGeiger.2021.UNISURF:UnifyingNeural
SaraFridovich-Keil,AlexYu,MatthewTancik,QinhongChen,BenjaminRecht,and ImplicitSurfacesandRadianceFieldsforMulti-ViewReconstruction.InInternational
AngjooKanazawa.2022.Plenoxels:RadianceFieldswithoutNeuralNetworks.In ConferenceonComputerVision(ICCV).
CVPR. JeongJoonPark,PeterFlorence,JulianStraub,RichardNewcombe,andStevenLove-
ClementFujiTsang,MariaShugrina,JeanFrancoisLafleche,TowakiTakikawa,Jiehan grove.2019.DeepSDF:LearningContinuousSignedDistanceFunctionsforShape
Wang,CharlesLoop,WenzhengChen,KrishnaMurthyJatavallabhula,Edward Representation.InTheIEEEConferenceonComputerVisionandPatternRecognition
Smith,ArtemRozantsev,OrPerel,TianchangShen,JunGao,SanjaFidler,Gavriel (CVPR).
State,JasonGorski,TommyXiang,JianingLi,MichaelLi,andRevLebaredian. Marie-JulieRakotosaona,FabianManhardt,DiegoMartinArroyo,MichaelNiemeyer,
2022. Kaolin:APytorchLibraryforAccelerating3DDeepLearningResearch. AbhijitKundu,andFedericoTombari.2024.NeRFMeshing:DistillingNeuralRa-
https://github.com/NVIDIAGameWorks/kaolin. dianceFieldsintoGeometrically-Accurate3DMeshes.InProc.oftheInternational
JianGao,ChunGu,YoutianLin,HaoZhu,XunCao,LiZhang,andYaoYao.2023.Re- Conf.on3DVision(3DV).
lightable3DGaussian:Real-timePointCloudRelightingwithBRDFDecomposition ChristianReiser,StephanGarbin,PratulP.Srinivasan,DorVerbin,RichardSzeliski,Ben
andRayTracing.arXiv:2311.16043(2023). Mildenhall,JonathanT.Barron,PeterHedman,andAndreasGeiger.2024.Binary
MichaelGarlandandPaulSHeckbert.1997.Surfacesimplificationusingquadricerror OpacityGrids:CapturingFineGeometricDetailforMesh-BasedViewSynthesis.
metrics.InProceedingsofthe24thannualconferenceonComputergraphicsand arXiv2402.12377(2024).
interactivetechniques.209â€“216. ChristianReiser,SongyouPeng,YiyiLiao,andAndreasGeiger.2021.KiloNeRF:Speed-
AntoineGuÃ©donandVincentLepetit.2023.SuGaR:Surface-AlignedGaussianSplatting ingupNeuralRadianceFieldswithThousandsofTinyMLPs.InInternational
forEfficient3DMeshReconstructionandHigh-QualityMeshRendering. arXiv ConferenceonComputerVision(ICCV).
preprintarXiv:2311.12775(2023). ChristianReiser,RickSzeliski,DorVerbin,PratulSrinivasan,BenMildenhall,Andreas
PeterHedman,PratulPSrinivasan,BenMildenhall,JonathanTBarron,andPaulDe- Geiger,JonBarron,andPeterHedman.2023.Merf:Memory-efficientradiancefields
bevec.2021.Bakingneuralradiancefieldsforreal-timeviewsynthesis.InProceedings forreal-timeviewsynthesisinunboundedscenes.ACMTransactionsonGraphics
oftheIEEE/CVFInternationalConferenceonComputerVision.5875â€“5884. (TOG)42,4(2023),1â€“12.
BinbinHuang,ZehaoYu,AnpeiChen,AndreasGeiger,andShenghuaGao.2024.2D RaduAlexandruRosuandSvenBehnke.2023.PermutoSDF:FastMulti-ViewReconstruc-
GaussianSplattingforGeometricallyAccurateRadianceFields.arXiv2403.17888 tionwithImplicitSurfacesusingPermutohedralLattices.InIEEE/CVFConference
(2024). onComputerVisionandPatternRecognition(CVPR).
ClÃ©mentJamin,SylvainPion,andMoniqueTeillaud.2024. 3DTriangulationData JohannesLutzSchÃ¶nberger,EnliangZheng,MarcPollefeys,andJan-MichaelFrahm.
Structure.InCGALUserandReferenceManual(5.6.1ed.).CGALEditorialBoard. 2016.PixelwiseViewSelectionforUnstructuredMulti-ViewStereo.InEuropean
https://doc.cgal.org/5.6.1/Manual/packages.html#PkgTDS3 ConferenceonComputerVision(ECCV).
RasmusJensen,AndersDahl,GeorgeVogiatzis,EnginTola,andHenrikAanÃ¦s.2014. TianchangShen,JunGao,KangxueYin,Ming-YuLiu,andSanjaFidler.2021. Deep
Largescalemulti-viewstereopsisevaluation.InProceedingsoftheIEEEconference MarchingTetrahedra:aHybridRepresentationforHigh-Resolution3DShapeSyn-
oncomputervisionandpatternrecognition.406â€“413. thesis.InAdvancesinNeuralInformationProcessingSystems(NeurIPS).
JamesTKajiyaandBrianPVonHerzen.1984. Raytracingvolumedensities. ACM ChengSun,MinSun,andHwann-TzongChen.2022.DirectVoxelGridOptimization:
SIGGRAPHcomputergraphics18,3(1984),165â€“174. Super-fastConvergenceforRadianceFieldsReconstruction.
MichaelKazhdanandHuguesHoppe.2013.Screenedpoissonsurfacereconstruction. JiaxiangTang,HangZhou,XiaokangChen,TianshuHu,ErruiDing,JingdongWang,
ACMTransactionsonGraphics(ToG)32,3(2013),1â€“13. andGangZeng.2022.DelicateTexturedMeshRecoveryfromNeRFviaAdaptive
BernhardKerbl,GeorgiosKopanas,ThomasLeimkÃ¼hler,andGeorgeDrettakis.2023. SurfaceRefinement.arXivpreprintarXiv:2303.02091(2022).
3DGaussianSplattingforReal-TimeRadianceFieldRendering.ACMTransactionson MatiasTurkulainen,XuqianRen,IaroslavMelekhov,OttoSeiskari,EsaRahtu,andJuho
Graphics42,4(July2023).https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/ Kannala.2024.DN-Splatter:DepthandNormalPriorsforGaussianSplattingand
LeonidKeselmanandMartialHebert.2022. ApproximateDifferentiableRendering Meshing.arXiv2403.17822(2024).
withAlgebraicSurfaces.InEuropeanConferenceonComputerVision(ECCV). DorVerbin,PeterHedman,BenMildenhall,ToddZickler,JonathanT.Barron,and
ArnoKnapitsch,JaesikPark,Qian-YiZhou,andVladlenKoltun.2017. Tanksand PratulP.Srinivasan.2022.Ref-NeRF:StructuredView-DependentAppearancefor
Temples:BenchmarkingLarge-ScaleSceneReconstruction.ACMTransactionsonGaussianOpacityFields:EfficientandCompactSurfaceReconstructioninUnboundedScenes â€¢ 9
NeuralRadianceFields.CVPR(2022).
PengWang,LingjieLiu,YuanLiu,ChristianTheobalt,TakuKomura,andWenping
Wang.2021. NeuS:LearningNeuralImplicitSurfacesbyVolumeRenderingfor
Multi-viewReconstruction.AdvancesinNeuralInformationProcessingSystems34
(2021),27171â€“27183.
YaoYao,ZixinLuo,ShiweiLi,TianFang,andLongQuan.2018. MVSNet:Depth
InferenceforUnstructuredMulti-viewStereo.EuropeanConferenceonComputer
Vision(ECCV)(2018).
LiorYariv,JiataoGu,YoniKasten,andYaronLipman.2021.Volumerenderingofneural
implicitsurfaces. AdvancesinNeuralInformationProcessingSystems34(2021),
4805â€“4815.
LiorYariv,PeterHedman,ChristianReiser,DorVerbin,PratulP.Srinivasan,Richard
Szeliski,JonathanT.Barron,andBenMildenhall.2023.BakedSDF:MeshingNeural
SDFsforReal-TimeViewSynthesis.arXiv(2023).
MulinYu,TaoLu,LinningXu,LihanJiang,YuanboXiangli,andBoDai.2024b.GSDF:
3DGSMeetsSDFforImprovedRenderingandReconstruction.arXiv2403.16964
(2024).
ZehaoYu,AnpeiChen,BozidarAntic,SongyouPeng,ApratimBhattacharyya,Michael
Niemeyer,SiyuTang,TorstenSattler,andAndreasGeiger.2022a.SDFStudio:AUni-
fiedFrameworkforSurfaceReconstruction. https://github.com/autonomousvision/
sdfstudio
ZehaoYu,AnpeiChen,BinbinHuang,TorstenSattler,andAndreasGeiger.2024a.
Mip-Splatting:Alias-free3DGaussianSplatting.ConferenceonComputerVisionand
PatternRecognition(CVPR)(2024).
ZehaoYuandShenghuaGao.2020.Fast-MVSNet:Sparse-to-DenseMulti-ViewStereo
WithLearnedPropagationandGauss-NewtonRefinement.InConferenceonCom-
puterVisionandPatternRecognition(CVPR).
ZehaoYu,SongyouPeng,MichaelNiemeyer,TorstenSattler,andAndreasGeiger.
2022b.MonoSDF:ExploringMonocularGeometricCuesforNeuralImplicitSurface
Reconstruction.AdvancesinNeuralInformationProcessingSystems(NeurIPS)(2022).
KaiZhang,GernotRiegler,NoahSnavely,andVladlenKoltun.2020.NeRF++:Analyzing
andImprovingNeuralRadianceFields.arXiv:2010.07492(2020).
RichardZhang,PhillipIsola,AlexeiAEfros,EliShechtman,andOliverWang.2018.
TheUnreasonableEffectivenessofDeepFeaturesasaPerceptualMetric.InCVPR.
HongyuZhou,JiahaoShao,LuXu,DongfengBai,WeichaoQiu,BingbingLiu,YueWang,
AndreasGeiger,andYiyiLiao.2024.HUGS:HolisticUrban3DSceneUnderstanding
viaGaussianSplatting.arXivpreprintarXiv:2403.12722(2024).
MatthiasZwicker,HanspeterPfister,JeroenVanBaar,andMarkusGross.2001.EWA
volumesplatting.InProceedingsVisualization,2001.VISâ€™01.IEEE,29â€“538.10 â€¢ ZehaoYu,TorstenSattler,andAndreasGeiger
Table5. QuantitativeresultsonMip-NeRF360[Barronetal.2022b] ourMarchingTetrahedraaugmentedwithbinarysearchisshownin
dataset.OurdensificationstrategyimprovetheNVSresultssignificantly.
Algorithm3,thesameideacouldbeappliedtotheMarchingCubes
algorithm.
OutdoorScene Indoorscene
PSNRâ†‘ SSIMâ†‘ LPIPSâ†“ PSNRâ†‘ SSIMâ†‘ LIPPSâ†“
3DGS[Kerbletal.2023] 24.64 0.731 0.234 30.41 0.920 0.189 Algorithm1GaussianOpacityFieldevaluation
3DGSwithourdensification 24.62 0.743 0.199 31.10 0.928 0.174
Mip-Splatting[Yuetal.2024a] 24.65 0.729 0.245 30.90 0.921 0.194
ğ‘€,ğ‘†,ğ´:Gaussianmeans,covariances,andopacity
Mip-Splattingwithourdensification 24.77 0.745 0.205 31.18 0.926 0.180 ğ‘ƒ:positionofpoints
ğ‘‰:viewconfigurations
6 DENSIFICATION functionEvaluateOpacityField(ğ‘€,ğ‘†,ğ´,ğ‘‰,ğ‘ƒ)
Inthissection,wedescribeourmodificationsto3DGSâ€™sdensification ğ‘‚ â†1 âŠ²InitOpacity
strategy to overcome the over-blur regions in Gaussian density forallViewsğ‘£inğ‘‰ do
controlandclusteredissuesresultingfromcloneoperation. ğ‘¤,â„â†GetImageSize(ğ‘‰)
DensificationMetric:In3DGS[Kerbletal.2023],thedensifica-
ğ‘‚
ğ‘£
â†EvaluateSingleView(ğ‘¤,â„,ğ‘€,ğ‘†,ğ´,ğ‘‰,ğ‘ƒ)
tionofaGaussian(eitherbycloningorsplitting)isguidedbythe
ğ‘‚ â†Min(ğ‘‚,ğ‘‚ ğ‘£) âŠ²TakeMinimalOpacity
magnitudeoftheview-spacepositiongradient ğ‘‘ ğ‘‘ğ¿ x,wherexisthe en red tufo rnr
ğ‘‚
centerofprojectedGaussians.Specifically,ğ‘‘ğ¿ sumsoverpixelsthat
ğ‘‘x endfunction
theGaussiancontributedto:
ğ‘‘ğ¿ âˆ‘ï¸ ğ‘‘ğ¿ ğ‘‘pğ‘–
= (14)
ğ‘‘x
ğ‘–
ğ‘‘pğ‘– ğ‘‘x
Algorithm2GaussianOpacityFieldevaluationforasingleview
Ifthenormofthegradientâˆ¥ğ‘‘ ğ‘‘ğ¿ xâˆ¥2isaboveapredefinedthreshold ğ‘¤ ğ‘€, ,â„ ğ‘†: ,w ğ´i :d Gth aua sn sd iah ne mig eh at no sf ,t cr oa vin arin iag ni cm esa ,g ae
ndopacity
ğœ ,theGaussianischosenasthecandidatefordensification.
x
ğ‘ƒ:positionofpoints
However, we found this metric is not effective in identifying
ğ‘‰:viewconfigurationofcurrentcamera
overly blurred areas, due to its inability to distinguish between
well-reconstructedregionsandthosewherethegradientsignals functionEvaluateSingleView(ğ‘¤,â„,ğ‘€,ğ‘†,ğ´,ğ‘‰,ğ‘ƒ)
fromdifferentpixelsnegateeachother,leadingtominimaloverall CullGaussian(ğ‘€,ğ‘‰) âŠ²FrustumCulling
gradientmagnitudes.Therefore,weproposeasimplemodification ğ‘€â€²,ğ‘†â€²â†ScreenspaceGaussians(ğ‘€,ğ‘†,ğ‘‰) âŠ²Transform
tothemetricthataccumulatesthenormsoftheindividualpixel ğ‘‡ ğ‘”â†CreateTiles(ğ‘¤,â„)
gradientsinstead: ğ¿ ğ‘”,ğ¾ ğ‘”â†DuplicateWithKeys(ğ‘€â€²,ğ‘‡ ğ‘”) âŠ²IndicesandKeys
ğ‘‘ğ¿â€² âˆ‘ï¸ ğ‘‘ğ¿ ğ‘‘pğ‘– SortByKeys(ğ¾ ğ‘”,ğ¿ ğ‘”) âŠ²GloballySort
ğ‘‘x
= âˆ¥
ğ‘‘pğ‘– ğ‘‘x
âˆ¥2 (15) ğ‘… ğ‘”â†IdentifyTileRanges(ğ‘‡ ğ‘”,ğ¾ ğ‘”)
ğ‘– CullPoints(ğ‘ƒ,ğ‘‰) âŠ²FrustumCulling
O stru ur cm tioet nri ec rrâˆ¥ oğ‘‘
ğ‘‘
rğ¿
x
s.â€² âˆ¥2betterindicatesregionswithsignificantrecon- ğ‘‡ğ‘ƒ ğ‘â€²â† â†S Cc rr ee ae tn eTsp ila ec se (ğ‘¤Po ,i â„n )ts(ğ‘ƒ,ğ‘‰) âŠ²Transform
Toevaluatetheeffectivenessofourimproveddensificationmetric, ğ¿ ğ‘,ğ¾ ğ‘ â†CreateWithKeys(ğ‘ƒâ€²,ğ‘‡ ğ‘) âŠ²IndicesandKeys
weapplyitto3DGS[Kerbletal.2023]andMip-Splatting[Yuetal. SortByKeys(ğ¾ ğ‘,ğ¿ ğ‘) âŠ²GloballySort
2024a].ThequantitativeresultsareshowninTable5andqualitative ğ‘… ğ‘ â†IdentifyTileRanges(ğ‘‡ ğ‘,ğ¾ ğ‘)
comparisonsareshowninFigure7.OurstrategyimprovesNVS ğ‘‚ â†1 âŠ²InitOpacity
resultssignificantly,especiallyintermsofLPIPS[Zhangetal.2018]. forallTilesğ‘¡ inğ¼ do âŠ²ğ¼ istheCanvas
forallPixelsğ‘–inğ‘¡ do
ClonewithSampling:WefoundthatthepositionofGaussianis
relativelystable,whichisalsoobservedinMip-Splatting[Yuetal.
ğ‘Ÿ
ğ‘”
â†GetTileRange(ğ‘… ğ‘”,ğ‘¡)
2024a].Therefore,Gaussiansclonedfromthesameparentsremain
ğ¿ ğ‘”â€² â†FilterGaussians(ğ‘–,ğ¿ ğ‘,ğ‘Ÿ ğ‘”,ğ¾ ğ‘”,ğ‘€,ğ‘†,ğ´) âŠ²Select
Gaussiansthatcontributestopixelğ‘–
clustered.Toaddressthisissue,insteadofusingthesameposition
fortheclonedGaussian,wesampleanewGaussianaccordingto
ğ‘Ÿ
ğ‘
â†GetTileRange(ğ‘… ğ‘,ğ‘¡)
theGaussianâ€™sparametersimilartotheproceduresforGaussian
ğ¿ ğ‘â€² â†FilterPoints(ğ‘–,ğ¿ ğ‘,ğ‘Ÿ ğ‘,ğ¾ ğ‘,ğ‘ƒ)âŠ²SelectPointsthat
projectedtopixelğ‘–
split[Kerbletal.2023].Wefoundthissimplestrategyleadstomore
uniformlydistributedGaussians,asshowninFigure8.
forallPointsğ‘inğ¿ ğ‘â€² do
ğ‘‚[ğ‘] â†EvaluateOpacity(ğ‘–,ğ¿ ğ‘”â€²,ğ¾ ğ‘”,ğ‘€,ğ‘†,ğ´)
7 DETAILSFORSURFACEEXTRACTION endfor
endfor
Weprovideapseudo-codeofourtile-basedGaussianOpacityField
endfor
evaluationinAlgorithm1andAlgorithm2.Notethattheevaluation
returnğ‘‚
takes3DGaussians,trainingviews,and3Dpointsasinputandit
endfunction
doesnotrelyonthetetrahedracells.Therefore,thesamealgorithm
alsoappliestotheMarchingCubesAlgorithm.Thepseudo-codeofGaussianOpacityFields:EfficientandCompactSurfaceReconstructioninUnboundedScenes â€¢ 11
3DGS[Kerbletal.2023] 3DGS+OurDensification Mip-Splatting[Yuetal.2024a] Mip-Splatting+OurDensification
Fig.7. ComparisonofdensificationstrategyontheMip-NeRF360Dataset[Barronetal.2022a].Applyingourdensificationto3DGS[Kerbletal.
2023]andMip-Splatting[Yuetal.2024a]significantimprovetheNVSresults.Pleasenotethattheglassregionsareblurinboth3DGSandMip-Splatting,
whileourmethodrendertheimagefaithfully.
3DGS[Kerbletal.2023] Ours 3DGS Ours[Kerbletal.2023]
Fig.8. ComparisonofclonestrategyontheMip-NeRF360Dataset[Barronetal.2022a].Ourclonestrategyleadstomoreuniformlydistributed
Gaussianprimitives.
Algorithm3MarchingTetrahedrawithBinarySearch Thisprocesscouldpotentiallybeoptimizedbyconsideringthespa-
ğ‘€,ğ‘†,ğ´:Gaussianmeans,covariances,andopacity tiallocalitysincethepointsaregeneratedfrom3DGaussians,orby
ğ‘ƒ,ğ¶:TetrahedraPointsandCells employingparallelprocessingtechniquesonGPUs.Additionally,
ğ‘‰:viewconfigurations optimizingtheselectionandnumberofGaussianprimitivesused
ğ¿:Levelsetvalue forconstructingtetrahedralgridscouldfurtherimproveefficiency.
ğ‘:Stepofbinarysearch
OpacityEvaluationOptimization:Duringthebinarysearchof
functionMarchingTetrahedraBinarySearch(ğ‘€,ğ‘†,ğ´,ğ‘ƒ,ğ¶, marchingtetrahedra,ourmethodevaluatestheopacityofpoints
ğ‘‰) usingalltrainingviews,whichmayleadtoredundantcomputations.
ğ‘‚ â†EvaluateOpacityField(ğ‘€,ğ‘†,ğ´,ğ‘‰,ğ‘ƒ) Recognizingthatasingleviewcandetermineapointâ€™sminimal
ğ¹,ğ‘ƒ1,ğ‘ƒ2,ğ‘‚1,ğ‘‚2â†MarchingTetrahedra(ğ‘ƒ,ğ¶,ğ‘‚,ğ‘†) opacityvaluesuggestsamoreefficientapproachcouldbedeveloped
foralliğ‘£in{1,2,...,ğ‘}do byassociatingpointswiththeirrespectiveinfluentialtrainingviews.
ğ‘ƒ ğ‘š â†MidPoint(ğ‘ƒ1,ğ‘ƒ2) ViewDependentAppearanceModeling:Usingsphericalhar-
ğ‘‚ ğ‘š â†EvaluateOpacityField(ğ‘€,ğ‘†,ğ´,ğ‘‰,ğ‘ƒ ğ‘š) monicsforview-dependentappearancemodelinghaslimitations,
ğ‘ƒ1,ğ‘ƒ2,ğ‘‚1,ğ‘‚2â†ChangeEndPointsAndValues(ğ‘ƒ1,ğ‘ƒ2,ğ‘‚1, such as potentially inaccurately representing reflections as geo-
ğ‘‚2,ğ¿,ğ‘ƒ ğ‘š,ğ‘‚ ğ‘š) metricfeatures.Incorporatingabetterview-dependentappearance
endfor model[Verbinetal.2022]couldenhancethequalityofreconstruc-
ğ‘‰ â†LinearInterpolate(ğ‘ƒ1,ğ‘ƒ2,ğ‘‚1,ğ‘‚2,ğ¿) tions.
returnğ¹,ğ‘‰ âŠ²returnfacesandverticesfortrianglemesh
Mesh-basedRendering:WhilethecurrentfocusofGOFison
endfunction
surfacereconstructionandnovelviewsynthesis,leveragingthe
extractedmeshesforreal-timerenderingisaninterestingfuture
direction[Reiseretal.2024].Thiscouldpotentiallyimprovethe
8 LIMITATIONSANDFUTUREDIRECTIONS qualityofmesh-basedrenderinggiventhedetailedandcompact
Wenowdiscusssomelimitationsandpotentialfutureextensionsof meshesextractedwithGOF.
ourmethod.
9 MORERESULTS
DelaunayTriangulationEfficiency:WeemploytheCGALLi-
brary[Jaminetal.2024]forDelaunaytriangulationtoconstruct BinarySearchforMarchingTetrahedra:Todemonstratethe
tetrahedralcells,whichhasğ‘‚(ğ‘logğ‘)complexity.Itbecomesa effectivenessofapplyingbinarysearchtomarchingtetrahedra[Shen
bottleneckparticularlywhenthenumberofpointsincreases.For etal.2021],weapplybinarysearchwithdifferentnumbersofsteps.
example,ittakesaround8minutestoconstructthetetrahedralcells AsshowninFigure9,usingbinarysearchsignificantlyimproves
forthebicyclesceneintheMip-NeRFdataset[Barronetal.2022a]. thequalityofreconstructedmeshesinjustafewiterations.12 â€¢ ZehaoYu,TorstenSattler,andAndreasGeiger
Step0 Step1 Step3 Step7 GTImage
Fig.9. DifferentnumberofbinarysearchstepswithmarchingtetrahedraontheDTUdataset[Jensenetal.2014].Applyingourbinarysearchto
MarchingTetrahedra[Shenetal.2021]significantlyimprovethequalityofextractedmeshesinjustfewsteps.
0.1 0.3 0.5 0.7 0.9
Fig.10. MeshesextractedwithdifferentlevelsetsontheMip-NeRF360dataset[Barronetal.2022a].Ourmethodssupportsmulti-layermeshes
extractionbyusingdifferentlevelsetsformarchingtetrahedra.
Multi-layerMeshes:Whileweextractmeshesforthe0.5level-set levelsets0.1,0.3,0.5,0.7,and0.9andshowtherenderedmeshesin
inthemainpaper,ourmethodalsosupportsextractingmesheswith Figure10.Finerstructurecanbeextractedwithasmallerlevelset,
levelsets.Asaproofofconcept,weextractmesheswithdifferent butitmightresultinexpandedmeshes.