DiFu,FaresAbawi,PhilippAllgeuer,andStefanWermter.2024.HumanImpressionofHumanoidRobotsMirroringSocialCues.InCompanionofthe2024ACM/IEEEInternational
ConferenceonHuman-RobotInteraction(HRIâ€™24Companion),March11-14,2024,Boulder,CO,USA.https://doi.org/10.1145/3610978.3640580.
Human Impression of Humanoid Robots Mirroring Social Cues
DiFuâˆ— FaresAbawiâˆ—
di.fu@uni-hamburg.de fares.abawi@uni-hamburg.de
UniversityofHamburg UniversityofHamburg
Hamburg,Germany Hamburg,Germany
PhilippAllgeuer StefanWermter
philipp.allgeuer@uni-hamburg.de stefan.wermter@uni-hamburg.de
UniversityofHamburg UniversityofHamburg
Hamburg,Germany Hamburg,Germany
A B
C D
Figure1:Aparticipantperformingthefourmirroringtasksinrandomorder:A)TheiCubrobotmirroringfacialexpressions;
B)ThePepperrobotaffectivelysignalingthroughLEDcolorchanges;C)TheiCubrobotmirroringheadmovementbasedon
aninertialmeasurementunit(IMU)readings.TheredcircleshowstheIMU;D)TheiCubrobotmirroringheadmovement
accordingtoavision-basedmodel.Theredcircleshowsthecamera.
ABSTRACT controlledoneinthemovementmirroringtask.Ourfindingssug-
Mirroringnon-verbalsocialcuessuchasaffectormovementcan gestthatdifferentroboticplatformsimpactpeopleâ€™sperceptionof
enhancehuman-humanandhuman-robotinteractionsinthereal robotsâ€™mirroringduringHRI.Thecontrolmethodalsocontributes
world.Theroboticplatformsandcontrolmethodsalsoimpactpeo- totherobotâ€™smirroringperformance.Ourworkshedslightonthe
pleâ€™sperceptionofhuman-robotinteraction.However,limitedstud- designandapplicationofdifferenthumanoidrobotsinthereal
ieshavecomparedrobotimitationacrossdifferentplatformsand world.
controlmethods.Ourresearchaddressesthisgapbyconducting
twoexperimentscomparingpeopleâ€™sperceptionofaffectivemirror- CCSCONCEPTS
ingbetweentheiCubandPepperrobotsandmovementmirroring
â€¢Human-centeredcomputingâ†’Userstudies;Interactionde-
betweenvision-basediCubcontrolandInertialMeasurementUnit
signtheory,conceptsandparadigms.
(IMU)-basediCubcontrol.WediscoveredthattheiCubrobotwas
perceivedasmorehumanlikethanthePepperrobotwhenmirroring
affect.Avision-basedcontrollediCuboutperformedtheIMU-based KEYWORDS
affectivemirroring,movementmirroring,gazeandheadmovement,
âˆ—Bothauthorscontributedequallytothisresearch. human-robotinteraction
ThisworkislicensedunderaCreativeCommonsAttribution ACMReferenceFormat:
International4.0License.
DiFu,FaresAbawi,PhilippAllgeuer,andStefanWermter.2024.Human
ImpressionofHumanoidRobotsMirroringSocialCues.InCompanionof
HRIâ€™24Companion,March11â€“14,2024,Boulder,CO,USA
the2024ACM/IEEEInternationalConferenceonHuman-RobotInteraction
Â©2024Copyrightheldbytheowner/author(s).
ACMISBN979-8-4007-0323-2/24/03 (HRIâ€™24Companion),March11â€“14,2024,Boulder,CO,USA.ACM,NewYork,
https://doi.org/10.1145/3610978.3640580 NY,USA,5pages.https://doi.org/10.1145/3610978.3640580
4202
naJ
22
]OR.sc[
1v67021.1042:viXraHRIâ€™24Companion,March11â€“14,2024,Boulder,CO,USA DiFu,FaresAbawi,PhilippAllgeuer,andStefanWermter
1 INTRODUCTION Inthisstudy,weconductedtwoexperimentswithtwohumanoids,
The mirror neuron system (MNS) in humans facilitates the un- theiCubandPepperrobots,asshowninFigure1.Thefirstexper-
derstandingofothersbysimulatingtheirbehaviorsviasensori- iment compared peopleâ€™s perceptions of affective mirroring on
motorprocesses[5].Mirroring,afundamentalelementofsocial differenthumanoidrobots.Thesecondexperimentassessedthe
interaction,involvessubconsciouslyimitatinganotherindividualâ€™s impactofvariouscontrolmethodsonthesamerobotplatformdo-
nonverbalcues,suchasgestures,expressions,andpostures[10]. ingmovementmirroring.Weevaluatedtherobotsâ€™performance
Itcanreflectanadaptiveintegrationandutilizationofsocialcues bytheirmirroringspeedandaccuracy.Peopleâ€™sperceptionofthe
withinthesocialcontext[22].Thismechanismoftenleadsindi- robotswasmeasuredfromfourdimensionsâ€”SociallyIntelligent,
vidualstocollaboratewiththosewhoexhibitsimilarandfamiliar Mechanical,Responsive,andHumanlike.Throughtheseinvestiga-
behaviors[7].Mirrorsystemdysfunctioncontributestodifficulties tions,ourgoalistoenhancethealignmentofroboticdesignwith
in social communication for individuals with Autism Spectrum humaninteractionpreferences.Weaimtosolvetheseissuesby
Disorders (ASD) [18]. Mirroring also plays a significant role in investigatingthefollowingresearchquestions(RQ):
human-robotsocialinteraction.Bymimickingnon-verbalsocial RQ1 Howdodifferentroboticsplatforms,specificallytheiCub
cues,humansfeelsociallyclosertotherobotandperceiveitas andPepperrobots,compareinaffectivemirroring?
moreawareoftheintentionsbehindtheirsocialbehaviors[14]. RQ2 Howdovariousroboticcontrolmethods,especiallyvision-
For robots, affective mirroring causes people to perceive the basedcontrolledandIMU-basedcontrolledmethods,impact
robotasanagentcapableofconveyinginternalstates,displaying theiCubrobotâ€™sperformanceinmovementmirroringtasks?
socialintelligence,andexpressinghumanlikecharacteristics[3,6].
Gonsioretal.[11]investigatedtheimpactofmirroringfacialex- 2 STUDYDESIGN
pressionsonempathyandperceivedsubjectiveperformancein 2.1 AffectiveMirroringTask
interactionswiththerobotheadEDDIE[21],revealingthatadap-
Inthisexperiment,participantswereaskedtomakeeightfacial
tivemodesofrobotbehavior,wheretherobotmirroredhuman
expressionsâ€”Anger,Fear,Happiness,Disgust,Sadness,Neutral,Sur-
expressions, led to increased levels of human empathy and im-
prise,andContemptâ€”infrontofthePepperoriCubrobots.The
provedperceivedtaskperformancecomparedtoanon-adaptive
expressionsweretobeperformedwithinoneminuteinanyorder.
modeâ€”withoutfacialexpressionmimicry.Althoughmostprevious
Therobotmirroredparticipantsâ€™expressionseitherthroughaffec-
researchshowsconsistentfindings,fewstudiescomparepeopleâ€™s
tivesignalingâ€”bychangingthePepperrobotâ€™seyeandshoulder
perceptionsofaffectivemirroringondifferenthumanoidrobots.
LEDcolors[13,16]â€”orroboticfacialexpressionsâ€”bychangingthe
Robotsconveyemotionalsignalsinvariousways.Forinstance,the
iCubrobotâ€™seyebrowandmouthLEDpatterns[2].Next,partici-
iCubrobotcandisplaysimplifiedfacialexpressionswithLEDlight
pantswereaskedtomatchthecolorsdisplayedonthePepperrobot
patternchanges,andthePepperrobotcanchangethecolorofthe
(depictedinthetoprowofFigure2)andfacialexpressionsonthe
shoulderandeyelidstorepresentemotions.Itmaycausepeopleto
iCubrobot(depictedinthebottomrowofFigure2)toemotioncat-
interpretthemdifferentlyforthesameexpression.
egories.Technicaldetailsforrunningtheexperimentareprovided
Movementmirroringenhancesrobotsâ€™sociabilityduringhuman-
aspartoftheWrapyfi[1]tutorialseries1.
robotinteractions,makingthemmorehumanlike,empathetic,and
Uponcompletionofthetask,participantswereaskedtoscana
sociallyintelligent[4].Twoprimarymethodsofenablingrobots
QRcodeappearingonthePepperâ€™stabletusingtheircellphonesto
tomirrorhumanmovementsincludeIMU-basedcontrolledand
completeathree-itemquestionnaire,evaluatingtheirexperiences
vision-basedcontrolledimitations.IMU-basedcontrolledmirroring
witheitherrobot.Inbothquestionnaires,participantswereasked
usesreadingsfromanIMUattachedtoahead-mountedeyetracker
toratetheirinteractionwiththerobotsusinga5-pointLikertscale:
wornbyanactortodirectlytranslatetheirheadmovementsinto
roboticactions[9].Incontrast,vision-basedcontrolledmirroring Q1 Howprecisewastherobotinmirroringyourfacialexpres-
usesexternalcamerasandposeestimationalgorithmstointerpret sions?(1=veryimprecise,5=veryprecise)
anactorâ€™sheadmovementsandmirrorthemthrougharobot[8]. Q2 Didtherobotmirroryourexpressionswithmajordelay?(1=
Liuetal.[17]showthatthelightweightmodelsurpassestheother nosignificantdelay,5=significantdelay)
state-of-the-artmodelsonthesamerobotdoingtheheadmovement Participantsratedtheirimpressionoftherobotsonfourdimensions
mirroring.Geminianietal.[9]findthattheMicrosoftKinect-based â€”SociallyIntelligent,Mechanical,Responsive,andHumanlikeâ€”using
controlledNAOrobotoutperformstheIMU-basedcontrolledNAO a5-pointLikertscale(1=notatall,5=yes,alot).
robotregardinglimbmovementmirroringintheautismtreatment.
However,comparingdifferentcontrolmethodsofrobotsondoing 2.2 GazeandHeadMovementMirroringTask
headandgazemirroringremainstobestudied. In this experiment, participants interacted with the iCub robot
Socialrobotsaredesignedtoaidpeople,butindividualshave giventwoconditions.Underthevision-basedcontrolledcondition,
beenadaptingtotherobotsinstead.Thisisduetothefactthat theiCubrobotâ€™smovementswereactuatedbyavision-basedhead
robotsarenotalwaysdesignedwithhumanpreferencesandinterac- poseestimationmodel.Undertheinertialmeasurementunit(IMU)
tiveneeds[15,19].Researchersinroboticmirroringareconstantly controlledcondition,theorientationreadingsarrivedinsteadfrom
improvinghumanoidrobotsâ€™accuracyandtimelinessinsimulat- anIMUattachedtoawearableeyetracker.Participantsworethe
ingsocialcues.However,researchaboutsubjectiveevaluationand eyetrackerandwereaskedtolookattheiCubrobot,freelymoving
preferenceoftheroboticplatformandcontrolmethodislimited.
1https://wrapyfi.readthedocs.io/en/latest/tutorials/Multiple%20Robots.htmlHumanImpressionofHumanoidRobotsMirroringSocialCues HRIâ€™24Companion,March11â€“14,2024,Boulder,CO,USA
theireyesandhead.Participantsobservedthemovementsofthe toeachdimensionofthequestionnaires.Resultsshowedthattheir
iCubrobottoevaluatetheinteraction.Technicaldetailsforrunning responseswerenormallydistributed.Inaddition,allPosthoctests
the experiment are provided as part of the Wrapyfi [1] tutorial inthisstudyusedBonferronicorrection.
series2.
ParticipantswereaskedtoratetheirinteractionwiththeiCub 3.1 AffectiveMirroring
robotusinga5-pointLikertscale:
Fortheaffectivemirroringtaskoneitherrobot,therecognition
Q1 Howprecisewastherobotinmirroringyourheadmovements? accuracyislistedinFigure2.ForthePepperrobot,participants
(1=veryimprecise,5=veryprecise) weremostaccurateinrecognizinganger(86.2%)andleastaccurate
Q2 Didtherobotmirroryourheadmovementswithmajordelay? inrecognizingfear(3.4%).FortheiCubrobot,participantswere
(1=nosignificantdelay,5=significantdelay) mostaccurateinrecognizinghappiness(100%)andleastaccurate
Q3 Didtherobotmoveitseyes?(Yes/No) inrecognizingdisgust(16.7%).
Q4 Howprecisewastherobotinmirroringyoureyemovements? Forparticipantsâ€™ratingofinteractionwiththerobots,results
(1=veryimprecise,5=veryprecise) ofpaired-samplesğ‘¡-testsdisplayednosignificantdifferenceinpre-
Q5 Didtherobotmirroryoureyemovementswithmajordelay? cision (Q1) between the Pepper (mean Â± SE = 2.79Â±.18) and
(1=nosignificantdelay,5=significantdelay) iCub(mean Â± SE=2.90Â±.15)robots,(ğ‘¡(28) = .46,ğ‘ = .65).No
ParticipantsratedtheirimpressionoftheiCubrobotonfourdimen- significantdifferenceindelay(Q2)wasfoundbetweenthePepper
sionsâ€”SociallyIntelligent,Mechanical,Responsive,andHumanlikeâ€” (mean Â± SE = 2.38Â±.18) and iCub (mean Â± SE = 2.48Â±.20)
usinga5-pointLikertscale(1=notatall,5=yes,alot).
robots,(ğ‘¡(28)=.52,ğ‘ =.61).Forparticipantsâ€™ratingoftheimpres-
sionoftherobots,resultsofpaired-samplesğ‘¡-testsdisplayedthat
2.3 ExperimentalSetup theiCub(mean Â± SE = 2.86Â±.20)robotwasratedsignificantly
morehumanlikethanthePepper(mean Â± SE=2.10Â±.16)robot,
Theparticipantswereseated80cmawayfromtheiCubrobotâ€™s
(ğ‘¡(28) =3.45,ğ‘ < .01).Nosignificantdifferenceswerefoundfor
head,adjustingitsheighttomatchtheireyelevel.Acircularmarker
theotherthreedimensionsâ€”SociallyIntelligent,Mechanical,and
wasplacedbesidetheiCubrobottocalibratethePupilCoreeye
Responsiveâ€”betweenthetworobots(ğ‘ğ‘  >.05)(SeeTable1).
tracker.SituatedinfrontoftheiCubrobotwasaLogitechC920
webcamfacingtheparticipantstoperformtasksrequiringafixed
3.2 MovementMirroring
viewoftheirfaceswhiletheiCubrobotmoveditsheadandeyes.
ThePepperrobotstoodfacingtheparticipantsatanangleof45 Apaired-samplesğ‘¡-testsshowedthatparticipantsratedthevision-
degreeswithadistanceof1.2m.ThePepperrobotdisplayedan basedcontrolledrobot(mean Â± SE=3.55Â±.24)significantlymore
illustrationoftheongoingtaskonitstabletandcommunicatedthe precise(Q1)thantheIMU-basedcontrolledrobot(mean Â± SE=
instructionsverbally.Theinteractionwasoneminutelongpertask 2.90Â±.19),(ğ‘¡(26) = 2.19,ğ‘ < .05).Thevision-basedcontrolled
conditionandtheconditionorderwasrandomized.Weusedthe robot(mean Â± SE=2.00Â±.17)wasratedsignificantlylessdelayed
Wrapyfi[1]frameworkformanagingthetaskorder,transmitting (Q2)thantheIMU-basedcontrolledrobot(meanÂ±SE=2.66Â±.21),
databetweenmodelsandrobotsusingvariousmiddleware,and (ğ‘¡(26) = âˆ’3.09,ğ‘ < .01).Underthevision-basedcontrolledcon-
orchestratingtheexperimentalpipeline. dition,allparticipantsobservedthattherobotmirroredtheireye
movements,whereastwodidnotundertheIMU-basedcontrolled
2.4 Participants condition(Q3).Therefore,weonlyanalyzeddatafrom27partici-
pantswhoreportedobservingeyemovementunderbothconditions.
30participants(female=7,male=22,preferrednottosay=1)
Thepaired-samplesğ‘¡-testshowednosignificantdifferenceinthe
took part in both studies. Participants were between 24 and 41
precisionratingoftheeyemovementbetweenthevision-basedcon-
yearsofage,withameanageof28.7.Allparticipantsreported
trolledrobot(meanÂ±SE=2.48Â±.19)andtheIMU-basedcontrolled
nohistoryofneurologicalconditionsâ€”seizures,epilepsy,stroke,
robot(meanÂ±SE=2.37Â±.19)(ğ‘ >.05)(Q4).Also,nosignificantdif-
etc.â€”andhadnormalorcorrected-to-normalvisionandhearing.
ferencewasfoundinthedelayratingoftheeyemovementbetween
Oneparticipantâ€™sdatawasexcludedfromthePepperrobotâ€™saffec-
thevision-basedcontrolledrobot(mean Â± SE = 3.07Â±.23)and
tivemirroringexperimentbecauseofself-reportedcolorblindness.
theIMU-basedcontrolledrobot(mean Â± SE=3.48Â±.24)(ğ‘ >.05)
Another participantâ€™s data was excluded from the iCub robotâ€™s
(Q5).Fortheimpressionoftherobot,participantsreportedthat
movementmirroringexperimentduetotechnicalissues.Thisstudy
thevision-basedcontrollediCub(mean Â± SE=3.66Â±.22)robot
adheredtotheprinciplesexpressedintheDeclarationofHelsinki.
wassignificantlymoreresponsivethantheIMU-controlledrobot
ParticipantssignedconsentformsapprovedbytheEthicsCommit-
(mean Â± SE = 3.17Â±.21),(ğ‘¡(26) = 2.39,ğ‘ < .05).However,no
teeattheDepartmentofInformatics,UniversityofHamburg.
significantdifferenceswerefoundintheremainingdimensions
3 RESULTS â€”SociallyIntelligent,Mechanical,andHumanlikeâ€”betweenthetwo
conditions(ğ‘ğ‘  >.05)(resultsareshowninTable1).
We evaluated the results of both mirroring tasks, studying the
perceivedimpressionoftherobotineachseparatecondition,as
4 DISCUSSION
wellascomparingthepairedconditionswithineachrespective
task.Normalitytestswereconductedontheparticipantsâ€™answers ParticipantsassociatedtheiCubrobotâ€™sfacialexpressionswithemo-
tionsmorethanthePepperrobotâ€™saffectivesignalingandfound
2https://wrapyfi.readthedocs.io/en/latest/tutorials/Multiple%20Sensors.html theiCubrobotmorehumanlike.AnotherobservationrelatestoHRIâ€™24Companion,March11â€“14,2024,Boulder,CO,USA DiFu,FaresAbawi,PhilippAllgeuer,andStefanWermter
Anger Fear Happiness Disgust Sadness Neutral Surprise Contempt
86.2% 3.4% 65.5% 24.1% 34.5% 37.9% 10.3% 6.9%
73.3% 46.7% 100% 16.7% 26.7% 80.0% 60.0% 20.0%
Figure2:EightemotioncategoriesmimickedonthePepper(Top)andiCub(Bottom)robotsintheformofaffectivesignaling
androboticfacialexpressions,respectively.Resultsofthehumanstudyarereportedbeloweachimageintermsoftheaverage
accuracyinmatchingeachaffectivesignalorfacialexpressiontoanemotioncategory.
5.0 5.0
Affect iCub Mov(Model) iCub
4.5 4.5
Affect Pepper Mov(IMU) iCub
4.0 4.0 *
3.5 3.5
**
3.0 3.0
2.5 2.5
2.0 2.0
1.5 1.5
1.0 1.0
Soc. Intelligent Mechanical Responsive Humanlike Soc. Intelligent Mechanical Responsive Humanlike
(a)AffectiveMirroring (b)MovementMirroring
Figure3:Participantsâ€™impressions(5-pointLikertscale)ofrobotsunderdifferentaffectiveandmovementmirroringconditions.
âˆ—denotes.01<ğ‘<.05,andâˆ—âˆ—.001<ğ‘<.01
Table1:Impressionoftherobotsunderdifferenttaskcondi- perceivedasequallyhumanlike,implyingthatlessresponsiveness
tions(MeanÂ±SE)
doesnotcontradicthumanlikeness.
Severallimitationscouldbeaddressedandinvestigatedinfuture
Affect Affect Mov.(Model) Mov.(IMU) research.Wecouldnotcomparemovementmirroringonthetwo
iCub Pepper iCub iCub humanoidrobots.ThisisbecausethePepperrobotisnotableto
Soc.Intelligent 2.81Â±.22 2.89Â±.21 2.65Â±.20 2.46Â±.22 roll its head or move its eyes, unlike the iCub robot. Our iCub
Mechanical 3.08Â±.24 2.93Â±.21 3.65Â±.24 3.85Â±.18
robotdoesnâ€™thaveafullbody,hence,wecannotstudythelimb
Responsive 3.31Â±.21 3.19Â±.16 3.65Â±.15 3.23Â±.22
mirroringbetweenthetworobots.Futurestudiescouldaddress
Humanlike 2.81Â±.22 2.15Â±.16 2.46Â±.19 2.39Â±.21
theinteractioneffectbetweenaffectiveandmovementmirroring.
Moreover,researcherscouldinvestigatehowdifferenthumanoid
robotsandcontrolmethodsimpactchildrenwithASD,andwhether
theaccuracyofrecognizingdifferentaffectivesignalsconveyedby
itaffectstheirsocialfunctions[24].
eitherrobot.ParticipantscouldaccuratelyassociateAngerwiththe
colorredandHappinesswithgreenonthePepperrobot.Thisis
5 CONCLUSIONS
complementedbyfindingsassociatingexposuretodifferentcolors
withphysiologicalandpsychologicalresponses[20,23].Partici- Weinvestigatedhumanperceptionsoftwohumanoidrobotsinthe
pantsmoreaccuratelyidentifiedexpressionsofHappiness,Neutral, affectiveandmovementmirroringtasks.Ourfindingsrevealedthat
andSurpriseontheiCubrobotcomparedtothePepperrobot.This arobotdisplayingfacialexpressionslikeaniCubrobotwasper-
canbeattributedtohumansprimarilyrelyingonobservingthe ceivedasmorehumanlikethanarobotconveyingaffectivesignals
mouth and eyebrows to recognize these facial expressions [12], likeaPepperrobot.Forgazeandheadmirroring,avision-based
featuresthatthePepperrobotlacks. controlledrobotperformedbetterthananIMU-basedcontrolled
Wecomparedtwomovementmirroringmethods.Thevision- robot.Thiscouldbeattributedtolatencyinprocessingandtrans-
basedcontrolledmethodproducedsmoother,moreprecise,and mittingthefilteredIMUreadings.Insummary,weshowedthat
moreresponsivemovementsthantheIMU-basedcontrolledmethod. roboticplatformsandrobotcontrolmethodsplayedanessential
TheIMU-basedcontrolledmethodtransferstheIMUreadingsat roleinmirroringtasksduringHRI.Itmayguidefuturehumanoid
afasterrate,butthiscausesjitterymovementsduetohardware robotdesigndecisionstoalignwithhumansâ€™needs.
limitations.ThesefindingsarealsoconsistentwithGeminiaiet
ACKNOWLEDGMENTS
al.[9]thattheIMU-basedNAOrobotismoreintrusiveandrequires
longersetuptimethantheKinect-basedNAOrobotduringthelimb TheauthorsgratefullyacknowledgepartialsupportfromtheGer-
movementmirroring.However,inourstudy,bothmethodswere manResearchFoundationDFGunderprojectCML(TRR169).
reppeP
buCiHumanImpressionofHumanoidRobotsMirroringSocialCues HRIâ€™24Companion,March11â€“14,2024,Boulder,CO,USA
REFERENCES
InternationalWorkshoponRobotandHumanInteractiveCommunication(RO-
[1] FaresAbawi,PhilippAllgeuer,DiFu,andStefanWermter.2024. Wrapyfi:A MAN).IEEE,350â€“356. https://doi.org/10.1109/ROMAN.2011.6005294
PythonWrapperforIntegratingRobots,Sensors,andApplicationsacrossMultiple [12] MariaGuarnera,ZiraHichy,MauraCascio,StefanoCarrubba,andStefaniaL
Middleware.InACM/IEEEInternationalConferenceonHuman-RobotInteraction Buccheri.2017.Facialexpressionsandtheabilitytorecognizeemotionsfromthe
(HRI).ACM. https://doi.org/10.1145/3610977.3637471 eyesormouth:acomparisonbetweenchildrenandadults.TheJournalofGenetic
[2] MotonobuAoki,KarthikeyanKalyanasundaramBalasubramanian,DiegoTorazza, Psychology178,6(2017),309â€“318. https://doi.org/10.1080/00221325.2017.1361377
FrancescoRea,DoreenJirak,GiulioSandini,TakuraYanagi,AtsushiTakamatsu, [13] DavidOJohnson,RaymondHCuijpers,andDavidvanderPol.2013.Imitating
StephaneBouet,andTomohiroYamamura.2022.ANovelWire-driven3DEye- humanemotionswithartificialfacialexpressions.InternationalJournalofSocial
browDesignforCommunicationwithHumanoidRobotiCub.In2022IEEE/RSJ Robotics5(2013),503â€“513.
InternationalConferenceonIntelligentRobotsandSystems(IROS).IEEE,8248â€“ [14] JamyLi,WendyJu,andCliffNass.2015.ObserverPerceptionofDominanceand
8254. MirroringBehaviorinHuman-RobotRelationships.InACM/IEEEInternational
[3] CynthiaBreazeal,KerstinDautenhahn,andTakayukiKanda.2016.Socialrobotics. ConferenceonHuman-RobotInteraction(HRI).ACM,133â€“140. https://doi.org/10.
SpringerHandbookofRobotics(2016),1935â€“1972. https://doi.org/10.1007/978-3- 1145/2696454.2696459
319-32552-1_72 [15] VelvetinaLim,MakiRooksby,andEmilySCross.2021. SocialRobotsona
[4] NicoletaBugnariu,CarolynYoung,KatelynRockenbach,RitaMPatterson,Car- GlobalStage:EstablishingaRoleforCultureDuringHuman-RobotInteraction.
olynGarver,IsuraRanatunga,MonicaBeltran,NahumTorres-Arenas,and InternationalJournalofSocialRobotics13,6(2021),1307â€“1333. https://doi.org/
DanPopa.2013. Human-robotinteractionasatooltoevaluateandquan- 10.1007/s12369-020-00710-4
tifymotorimitationbehaviorinchildrenwithAutismSpectrumDisorders. [16] Pei-Chun Lin, Patrick CK Hung, Ying Jiang, Carolina Padilla Velasco, and
In2013InternationalConferenceonVirtualRehabilitation(ICVR).IEEE,57â€“62. MarcoAntonioMartÃ­nezCano.2023. Anexperimentaldesignforfacialand
https://doi.org/10.1109/ICVR.2013.6662088 coloremotionexpressionofasocialrobot.TheJournalofSupercomputing79,2
[5] EvanWCarrandPiotrWinkielman.2014. Whenmirroringisbothsimple (2023),1980â€“2009.
andâ€œsmartâ€:howmimicrycanbeembodied,adaptive,andnon-representational. [17] XiaofengLiu,YizhouChen,JieLi,andAngeloCangelosi.2022.Real-TimeRobotic
FrontiersinHumanNeuroscience8(2014),505. https://doi.org/10.3389/fnhum. MirroredBehaviorofFacialExpressionsandHeadMotionsBasedonLightweight
2014.00505 Networks.IEEEInternetofThingsJournal10,2(2022),1401â€“1413. https://doi.
[6] LuisaDamiano,PaulDumouchel,andHagenLehmann.2015.Towardshumanâ€“ org/10.1109/JIOT.2022.3205123
robotaffectiveco-evolutionovercomingoppositionsinconstructingemotions [18] JellinaPrinsenandKaatAlaerts.2022.Brokenorsociallymistunedmirroringin
andempathy. InternationalJournalofSocialRobotics7(2015),7â€“18. https: ASD?Aninvestigationviatranscranialmagneticstimulation.AutismResearch
//doi.org/10.1007/s12369-014-0258-7 15,6(2022),1056â€“1067. https://doi.org/10.1002/aur.2720
[19] SelmaÅ abanoviÄ‡.2010.RobotsinSociety,SocietyinRobots:MutualShapingof
[7] HinkeMEndedijk,MMeyer,HBekkering,AHNCillessen,andSabineHunnius.
SocietyandTechnologyasaFrameworkforSocialRobotDesign.International
2017.Neuralmirroringandsocialinteraction:Motorsysteminvolvementduring
JournalofSocialRobotics2,4(2010),439â€“450. https://doi.org/10.1007/s12369-
actionobservationrelatestoearlypeercooperation.DevelopmentalCognitive
010-0066-7
Neuroscience24(2017),33â€“41. https://doi.org/10.1016/j.dcn.2017.01.001
[20] SichaoSongandSeijiYamada.2017.ExpressingEmotionsthroughColor,Sound,
[8] MarcoFerro,AntonioPaolillo,AndreaCherubini,andMarilenaVendittelli.2019.
andVibrationwithanAppearance-ConstrainedSocialRobot.InACM/IEEEIn-
Vision-BasedNavigationofOmnidirectionalMobileRobots.IEEERoboticsand
ternationalConferenceonHuman-RobotInteraction(HRI).ACM,2â€“11. https:
AutomationLetters4,3(2019),2691â€“2698. https://doi.org/10.1109/LRA.2019.
//doi.org/10.1145/2909824.3020239
2913077
[21] StefanSosnowski,AnsgarBittermann,KoljaKÃ¼hnlenz,andMartinBuss.2006.
[9] AliceGeminiani,LauraSantos,ClaudiaCasellato,AndreaFarabbi,NicolaFarella,
DesignandEvaluationofEmotion-DisplayEDDIE.InIEEE/RSJInternational
JosÃ©Santos-Victor,IvanaOlivieri,andAlessandraPedrocchi.2019.Designand
ConferenceonIntelligentRobotsandSystems(IROS).IEEE,3113â€“3118. https:
validationoftwoembodiedmirroringsetupsforinteractivegameswithautis-
//doi.org/10.1109/IROS.2006.282330
ticchildrenusingtheNAOhumanoidrobot.In201941stAnnualInternational
[22] LynMVanSwol.2003. TheEffectsofNonverbalMirroringonPerceivedPer-
ConferenceoftheIEEEEngineeringinMedicineandBiologySociety(EMBC).IEEE,
suasiveness,AgreementwithanImitator,andReciprocityinaGroupDiscus-
1641â€“1644. https://doi.org/10.1109/EMBC.2019.8857576
sion. CommunicationResearch30,4(2003),461â€“480. https://doi.org/10.1177/
[10] GyÃ¶rgyGergely.2018.Thesocialconstructionofthesubjectiveself:Theroleof
0093650203253318
affect-mirroring,markedness,andostensivecommunicationinself-development.
[23] LisaWilmsandDanielOberfeld.2018. Colorandemotion:effectsofhue,sat-
InDevelopmentalscienceandpsychoanalysis.Routledge,45â€“88. https://doi.org/
uration,andbrightness. PsychologicalResearch82,5(2018),896â€“914. https:
10.4324/9780429473654-4
//doi.org/10.1007/s00426-017-0880-8
[11] BarbaraGonsior,StefanSosnowski,ChristophMayer,JÃ¼rgenBlume,BerndRadig,
[24] ZhiZheng,EricMYoung,AmyRSwanson,AmySWeitlauf,ZacharyEWarren,
DirkWollherr,andKoljaKÃ¼hnlenz.2011. Improvingaspectsofempathyand
andNilanjanSarkar.2015.Robot-MediatedImitationSkillTrainingforChildren
subjectiveperformanceforHRIthroughmirroringfacialexpressions.InIEEE
WithAutism.IEEETransactionsonNeuralSystemsandRehabilitationEngineering
24,6(2015),682â€“691. https://doi.org/10.1109/TNSRE.2015.2475724