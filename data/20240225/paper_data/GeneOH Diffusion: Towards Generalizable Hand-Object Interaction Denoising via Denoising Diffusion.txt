PublishedasaconferencepaperatICLR2024
GENEOH DIFFUSION: TOWARDS GENERALIZABLE
HAND-OBJECT INTERACTION DENOISING VIA DE-
NOISING DIFFUSION
XueyiLiu1,3 LiYi1,2,3
1TsinghuaUniversity 2ShanghaiAILaboratory 3ShanghaiQiZhiInstitute
Project website: meowuu7.github.io/GeneOH-Diffusion
ABSTRACT
Inthiswork,wetacklethechallengingproblemofdenoisinghand-objectinterac-
tions(HOI).Givenanerroneousinteractionsequence,theobjectiveistorefinethe
incorrecthandtrajectorytoremoveinteractionartifactsforaperceptuallyrealistic
sequence. Thischallengeinvolvesintricateinteractionnoise,includingunnatural
handposesandincorrecthand-objectrelations,alongsidethenecessityforrobust
generalization to new interactions and diverse noise patterns. We tackle those
challengesthroughanovelapproach,GeneOHDiffusion,incorporatingtwokey
designs: an innovative contact-centric HOI representation named GeneOH and
a new domain-generalizable denoising scheme. The contact-centric representa-
tionGeneOHinformativelyparameterizestheHOIprocess,facilitatingenhanced
generalization across various HOI scenarios. The new denoising scheme con-
sists of a canonical denoising model trained to project noisy data samples from
a whitened noise space to a clean data manifold and a ‚Äúdenoising via diffusion‚Äù
strategy which can handle input trajectories with various noise patterns by first
diffusingthemtoalignwiththewhitenednoisespaceandcleaningviathecanon-
icaldenoiser. Extensiveexperimentsonfourbenchmarkswithsignificantdomain
variationsdemonstratethesuperioreffectivenessofourmethod. GeneOHDiffu-
sionalsoshowspromiseforvariousdownstreamapplications.
Refining estimations from videos
Cleaning motion-retargeted results
Snapshotsfrom Timestamp Timestamp Timestamp
TrainingSet (a) GeneralizableHOIDenoising (b) DiverseResultsfromStochasticDenoising (c) ApplicationsonInteractionDenoising
Figure1: Trainedonlyonlimiteddata,GeneOHDiffusioncancleannovelnoisyinteractionswith
newobjects,handmotions,andunseennoisepatterns(Fig.(a)),producesdiverserefinedtrajectories
withdiscretemanipulationmodes(Fig. (b)),andisapracticaltoolformanyapplications(Fig. (c)).
1 INTRODUCTION
Interactingwithobjectsisanessentialpartofourdailylives,andaccuratelytrackinghandsduring
these interactions has become crucial for various applications, such as gaming, virtual and aug-
mented reality, robotics, and human-machine interaction. Yet, this task is highly complex and ill-
posedduetonumerousfactorslikeintricatedynamicsinvolvedandhand-objectocclusions. Despite
bestefforts,existingtrackingalgorithmsoftenstrugglewithproducingplausibleandrealisticresults.
To better cater to the requirements of downstream tasks, noisy tracking results usually need to be
refined.Givenahand-objectinteraction(HOI)sequencewitherrors,theHOIdenoisingaimstopro-
1
4202
beF
22
]VC.sc[
1v01841.2042:viXra
1tluseR
2tluseRPublishedasaconferencepaperatICLR2024
duceanaturalinteractionsequencefreeofartifactssuchaspenetrations. Inthiswork, weassume
the object poses are tracked accurately and focus on refining the hand trajectory following (Zhou
et al., 2022; Grady et al., 2021; Zhou et al., 2021b; Zhang et al., 2021). This setting is impor-
tantwithmanypracticaldemandsinapplicationssuchascleaningsynthesizedmotions(Tendulkar
et al., 2023; Huang et al., 2023; Ghosh et al., 2023; Wu et al., 2022), refining motion-retargeted
trajectories(Heckeretal.,2008;Tak&Ko,2005;Abermanetal.,2019),andvirtualobjectmanip-
ulations(Ohetal.,2019;Katoetal.,2000;Shaeretal.,2010). Earlyapproachesreliedonmanually
designedpriors(Dewaeleetal.,2004;Hackenbergetal.,2011),which,however,provedinadequate
in handling intricate noise. More recent endeavors have shifted towards learning denoising priors
fromdata(Zhouetal.,2022;2021b;Gradyetal.,2021), yettheexistingdesignsstillfallshortof
providingasatisfactorysolution.
LeveragingdatapriorsforHOIdenoisingischallengedbyseveraldifficulties. First,theinteraction
noise is highly complex, covering unnatural hand poses, erroneous hand-object spatial relations,
and inconsistent hand-object temporal relations. Second, hand movements, hand-object relations,
and the noise pattern may vary dramatically across different HOI tracks. For instance, the noise
patternexhibitedinhandtrajectoriesestimatedfromvideosdiffersmarkedlyfromthatresultedfrom
inaccuratecapturingorannotations.Adenoisingmodelisoftenconfrontedwithsuchout-of-domain
dataandisexpectedtohandlethemadeptly. However,suchadistributionshiftposesasubstantial
challenge for data-driven models. Lacking an effective solution, prior works always cannot clean
suchcomplexinteractionnoiseorcanhardlygeneralizetounseenerroneousinteractions.
WeproposeGeneOHDiffusion,apowerfuldenoisingmethodwithstronggeneralizabilityandprac-
ticalapplicability(seeFigure1),totackletheabovedifficulties.Ourmethodresolvesthechallenges
around two key ideas: 1) designing an effective HOI representation that can both informatively
parameterize the interaction and facilitate the generalization by encoding and canonicalizing vital
HOIinformationinacoordinatesysteminducedbytheinteractionregion; 2)learningacanonical
denoiser that projects noisy data from a whitened noise space to the data manifold for domain-
generalizabledenoising. Asatisfactoryrepresentationthatparameterizesthehigh-dimensionalHOI
processfordenoisingshouldbeabletorepresenttheinteractionprocessfaithfully,highlightnoises,
andaligndifferentHOItrackswelltoenhancegeneralizationcapabilitiesTherefore, weintroduce
GeneOH, Generalized contact-centric Hand-Object spatial and temporal relations. GeneOH en-
codestheinteractioninformatively,encompassingthehandtrajectory,hand-objectspatialrelations,
and hand-object temporal relations. Furthermore, it adopts a contact-centric perspective and in-
corporates an innovative canonicalization strategy. This approach effectively reduces disparities
between different sequences, promoting generalization across diverse HOI scenarios. To enhance
thedenoisingmodel‚Äôsgeneralizationabilitytonovelnoisedistributions,oursecondeffortcenterson
thedenoisingschemeside.Weproposetolearnacanonicaldenoisingmodelthatdescribesthemap-
pingfromawhitenednoisespacetothedatamanifold.Thewhitenednoisespacecontainsnoisydata
diffusedfromcleandatainthetrainingdatasetviaGaussiannoiseatvariousnoisescales. Withthe
canonicaldenoiser,wethenleveragea‚Äúdenoisingviadiffusion‚Äùstrategytohandleinputtrajectories
withvariousnoisepatternsinadomain-generalizablemanner.Itfirstalignstheinputtothewhitened
noisespacebydiffusingitviaGaussiannoise. Subsequently,thediffusedsampleiscleanedbythe
canonical denoising model. To strike a balance between the denoising model‚Äôs generalization ca-
pabilityandthefaithfulnessofthedenoisedtrajectory,weintroduceahyper-parameterthatdecides
thescaleofnoiseaddedduringthediffusionprocess,ensuringthediffusedsampleremainsfaithful
totheoriginalinput. Furthermore,insteadoflearningtocleantheinteractionnoisethroughasingle
stage, we devise a progressive denoising strategy where the input is sequentially refined via three
stages,eachofwhichconcentratesoncleaningonespecificcomponentofGeneOH.
We conduct extensive experiments on three datasets, GRAB (Taheri et al., 2020), a high-quality
MoCapdataset,HOI4D(Liuetal.,2022),areal-worldinteractiondatasetwithnoiseresultingfrom
inaccuratedepthsensingandimprecisevisionestimations,andARCTIC(Fanetal.,2023),adataset
featuringdynamicmotionsandchangingcontacts,showingtheremarkableeffectivenessandgener-
alizabilityofourmethod. WhenonlytrainedonGRAB,ourdenoisercangeneralizetoHOI4Dwith
novelanddifficultnoisepatternsandARCTICwithchallenginginteractions, surpassingpriorarts
byasignificantmargin,asdemonstratedbythecomprehensivequantitativeandqualitativecompar-
isons. Wewillreleaseourcodetosupportfutureresearch. Insummary,ourcontributionsinclude:
‚Ä¢ AnHOIdenoisingframeworkwithpowerfulspatialandtemporaldenoisingcapabilityand
unprecedentedgeneralizabilitytonovelHOIscenarios;
2PublishedasaconferencepaperatICLR2024
‚Ä¢ AnHOIrepresentationnamedGeneOHthatcanfaithfullycapturetheHOIprocess,high-
lightunnaturalartifacts,andalignHOItracksacrossdifferentobjectsandinteractions;
‚Ä¢ An effective and domain-generalizable denoising method that can both generalize across
differentnoisepatternsandcleancomplexnoisethroughaprogressivedenoisingstrategy.
2 RELATED WORKS
Hand-object interaction is an important topic for understanding human behaviors. Prior works to-
wardsthisdirectionmainlyfocusondatacollection(Taherietal.,2020;Hampalietal.,2020;Guzov
etal.,2022;Fanetal.,2023;Kwonetal.,2021),reconstruction(Tiwarietal.,2022;Xieetal.,2022;
Qu et al., 2023; Ye et al., 2023), interaction generation (Wu et al., 2022; Tendulkar et al., 2023;
Zhang&Tang,2022;Ghoshetal.,2023;Lietal.,2023),andmotionrefinement(Zhouetal.,2022;
Grady et al., 2021; Zhou et al., 2021b; Nu¬¥nÀúez, 2022). The HOI denoising task wishes to remove
unnatural phenomena from HOI sequences with interaction noise. In real application scenarios, a
denoisingmodelwouldfrequentlyencounterout-of-domaininteractions,andisexpectedtogener-
alize to them. This problem is then related to domain generalization, a general machine learning
topic(Siciliaetal.,2023;Seguetal.,2023;Wangetal.,2023;Zhangetal.,2023;Jiangetal.,2022;
Wang et al., 2022; Blanchard et al., 2011; Muandet et al., 2013; Dou et al., 2019), where a wide
rangeofsolutionshavebeenproposedintheliterature. Amongthem,leveragingdomaininvariance
tosolvetheproblemisapromisingsolution. Ourworkisrelatedtothiskindofapproach,atahigh
level. However, what is the domain invariant information for the HOI denoising task, and how to
encouragethemodeltoleveragesuchinformationfordenoisingremainsverytricky. Wefocuson
designinginvariantrepresentationsandlearningacanonicaldenoiserfordomain-generalizablede-
noising. Moreover,wearealsorelatedtointriguingworksthatwishtoleveragedatapriorstosolve
the inverse problem (Song et al., 2023; Mardani et al., 2023; Tumanyan et al., 2023; Meng et al.,
2021;Chungetal.,2022). Forourtask,weneedtoanswersomefundamentalquestionsregarding
whataregeneralizabledenoisingpriors,howtolearnthemfromdata,andhowtoleveragetheprior
torefinenoisyinputfromdifferentdistributions. We‚Äôllillustrateoursolutioninthemethodsection.
3 HAND-OBJECT INTERACTION DENOISING VIA DENOISING DIFFUSION
Givenanerroneoushand-objectinteractionsequencewithKframes(HÀÜ,O)={(HÀÜ ,O )}K ,we
k k k=1
assumetheobjectposetrajectory{O }K isaccuratefollowing(Zhouetal.,2022;2021b;Grady
k k=1
etal.,2021;Zhangetal.,2021)andaimatcleaningthenoisyhandtrajectory{HÀÜ }K . Thisset-
k k=1
ting is of considerable importance, given its practical applicability in various domains (Tendulkar
et al., 2023; Ghosh et al., 2023; Li et al., 2023; Wu et al., 2022; Hecker et al., 2008; Oh et al.,
2019;Shaeretal.,2010). Thecleanedhandtrajectoryshouldbefreeofunnaturalhandposes, in-
correct spatial penetrations, and inconsistent temporal hand-object relations. The hand trajectory
shouldpresentvisuallyconsistentmotionsandadequatecontactwiththeobjecttosupportmanip-
ulation. The problem is ill-posed in nature owing to the difficulties posed by complex interaction
noiseandthesubstantialdomaingapacrossdifferentinteractionsresultingfromnewobjects,hand
movements,andunseennoisepatterns.
We resolve the above difficulties by 1) designing a novel HOI representation that parameterizes
the HOI process faithfully and can both simplify the distribution of complex HOI and foster the
model generalization across different interactions (Section 3.1) and 2) devising an effective de-
noising scheme that can both clean complex noises through a progressive denoising strategy and
generalizeacrossdifferentinputnoisepatterns(Section3.2).
3.1 GENEOH:GENERALIZEDCONTACT-CENTRICHAND-OBJECTSPATIALANDTEMPORAL
RELATIONS
DesigninganeffectiveandgeneralizableHOIdenoisingmodelrequiresaseriouseffortintherepre-
sentationdesign. Itinvolvesstrikingabalancebetweenexpressivemodelingoftheinteractionwith
objects and supporting the model‚Äôs generalization to new objects and interactions. The ideal HOI
representationshouldaccuratelycapturetheinteractionprocess,highlightanyunusualphenomena
likespatialpenetrations,andfacilitatealignmentacrossdiverseinteractionsequences.
3PublishedasaconferencepaperatICLR2024
WeintroduceGeneOHtoachievethis.Itintegratesthehandtrajectory,hand-objectspatialrelations,
and hand-object temporal relations to represent the HOI process faithfully. An effective normal-
ization strategy is further introduced to enhance alignment across diverse interactions. The hand
trajectory and the object trajectory are compactly represented as the trajectory of hand keypoints,
denotedasJ = {J }K ,andtheinteractionregionsequence: P = {P }K ,inacontact-aware
k k=1 k k=1
manner. WewillthendetailthedesignofGeneOH.
Generalizedcontactpoints. Theinteractionregion
GeneOH
isestablishedbasedonpointssampledfromtheob- Canonicalized Hand-Object ùêæ
Object RelativeDirection Hand-Object
ject surface close to the hand trajectory, referred to HandPoint ObjectPoint RelativePositions
MovingDirection MovingDirection (ùíâùíå‚àíùíêùíå)ùëπùíåùëª
a (ds e‚Äú ng oe tn ee dra al siz Ped ‚ààco Rnt Na oc √ót 3p )oi sn at ms‚Äù p. leT dhe fy roa mre oN bjo ecp to sin ut rs
-
GeneralizedCo ‚Ä¶ntactPoint Objec N ùíêt ùíåoP ,ro ùíèmi ùíån at lwith
ùëò=1
face points, whose distance to the hand trajectory (a)CanonicalizedHandTrajectory (b H) a G nde -n Oer ba jl ei cz te Sd pC ao tin at la Rct e- lC ate in ot nri sc
doesnotexceedathresholdvalueofr (setto5mm). Frameùëò Frameùëò+1 ùêæ‚àí1
c Hand-ObjectRelativeVelocities
Thesequenceofthesepointsacrossallframesisrep- andRelativeDistances
resentedbyP ={P }K ,whereP denotespoints {ùëë#ùíâùíê,ùíóùíåùíâ‚àíùíóùíåùíê}
k k=1 k ObjectVelocityandNormal
at frame k. Each P
k
is associated with a 6D pose, ùíóùíåùíê,ùíèùíå
ùëò=1
consistingoftheobject‚Äôsorientation(ortheorienta- (c) Generalized Contact-Centric Hand-ObjectTemporalMotion-AwareRelations
tionofthefirstpartforarticulatedobjects),denoted
Figure2: ThreecomponentsofGeneOH.
asR ,andthecenterofP ,denotedast .
k k k
Canonicalizedhandtrajectories. Weincludehandtrajectoriesinourrepresentationtoeffectively
modelhandmovements. Specifically,weleveragehandkeypointstomodelthehand,astheyoffera
compactandexpressiverepresentation. Werepresentthehandtrajectoryasthesequenceof21hand
keypoints,denotedasJ = {J
k
‚àà RNh√ó3}K k=1,whereN
h
= 21. Wefurthercanonicalizethehand
trajectory J using the poses of the generalized contact points to eliminate the influence of object
poses,resultinginthecanonicalizedhandtrajectoryinGeneOH:J¬Ø={J¬Ø =(J ‚àít )RT}K .
k k k k k=1
Generalized contact-centric hand-object spatial relations. We further introduce a hand-object
spatial representation in GeneOH. The representation is based on hand keypoints and general-
ized contact points to inherit their merits. The spatial relation centered at each generalized con-
tact point o ‚àà P comprises the relative offset from o to each hand keypoint h ‚àà J , i.e.,
k k k k k
{h ‚àío |h ‚àà J }, the object point normal n , and the object point position o . These statis-
k k k k k k
ticsaresubsequentlycanonicalizedusingthe6Dposeofthegeneralizedcontactpointstoencour-
age cross-interaction alignment. Formally, the spatial representation centered at o is defined as:
k
so =((o ‚àít )RT,n RT,{(h ‚àío )RT|h ‚ààJ }). ThespatialrelationS iscomposedofsoat
k k k k k k k k k k k k
eachgeneralizedcontactpoint: S = {{so|o ‚àà P }}K . Byencodingobjectnormalsandhand-
k k k k=1
objectrelativeoffsets,S canrevealunnaturalhand-objectspatialrelationssuchaspenetrations.
Generalizedcontact-centrichand-objecttemporalrelations. Consideringthelimitationsofthe
above two representations in revealing temporal errors such as incorrect manipulations resulting
from inconsistent hand-object motions, we further introduce hand-object temporal relations to pa-
rameterize the HOI temporal information explicitly. We again take hand keypoints J to represent
hand shape and generalized contact points P for the object shape to take advantage of their good
ability in supporting generalization. The temporal relations encode the relative velocity between
eachhandpointo andeachhandkeypointh atframek(vho =vh‚àívo),theEuclideandistance
k k k k k
betweeneachpairofpoints(dho =‚à•h ‚àío ‚à• ),andtheobjectvelocityvo intherepresentation,as
k k k 2 k
illustratedinFigure2.Wefurtherintroducetwostatisticsbyusingtheobjectpointnormaltocanon-
icalizevho,resultingintwonormalizedstatistics: vho ,orthogonaltotheobjecttangentplane,and
k k,‚ä•
vho, lying in the object‚Äôs tangent plane, and encoding them with hand-object relative distances:
k,‚à•
eh k,o
‚ä•
= e‚àík¬∑dh kok b‚à•v kh ,o ‚ä•‚à•
2
and eh k,o
‚à•
= e‚àík¬∑dh kok a‚à•v kh ,o ‚à•‚à• 2. Here, k, k a, and k
b
are positive hyper-
parameters,andtheterme‚àík¬∑dh ko isnegativelyrelatedtothedistancebetweenthehandandobject
points. Thiscanonicalizationandencodingstrategyaimstoencouragethemodeltolearndifferent
denoisingstrategiesforthetwotypesofrelativevelocities,enhancecross-interactiongeneralization
byfactoringoutobjectposes,andemphasizetherelativemovementbetweenveryclosehand-object
point pairs. The temporal representation T is defined by combining the above statistics of each
hand-objectpointpairacrossallframestogether:
T ={{vo,{dho,vho,eho,eho |h ‚ààJ }}|o ‚ààP }K‚àí1. (1)
k k k k,‚à• k,‚ä• k k k k k=1
Itrevealstemporalerrorsbyencodingobjectvelocities,hand-objectdistancesandrelativevelocities.
4PublishedasaconferencepaperatICLR2024
ProgressiveHOIDenoising
Input D H isa tn rd ib T utr ia oj nectory M Spo at ti io an lDD ii ff ff D Nen oo isi ysi Sn ag mv pli ea Diffusion Diffuse D Di ef nfu os ise ev via iath ae CD anif ofu ns icio an lDP ero nc oe iss es r SD amat pa le
TemporalDiff Distribution
Whitened
Noisy NoiseSpace
Output Denoised Sample
Trajectory Distribution Diffuse Denoise Denoise Denoised
Denoised Sample Sample
Distribution
Figure3: TheprogressiveHOIdenoosinggraduallycleanstheinputnoisytrajectorythroughthree
stages.EachstageconcentratesonrefiningthetrajectorybydenoisingaspecificpartofGeneOHvia
acanonicaldenoiserthroughthe‚Äúdenoisingviadiffusion‚Äùstrategy.
The GeneOH representation. The overall representation, GeneOH, comprises the above three
components,asdefinedformally:GeneOH={J¬Ø,S,T}.Figure2illustratesthedesign.Itfaithfully
capturestheinteractionprocess,canrevealnoisebyencodingcorrespondingstatistics,andbenefits
thegeneralizationbyemployingcarefullydesignedcanonicalizationstrategies. Inspectingbackinto
previousworks,TOCH(Zhouetal.,2022)doesnotexplicitlyparameterizethehand-objecttemporal
relationsorhandshapesanddoesnotcarefullyconsiderthespatialcanonicalizationtofacilitatethe
generalization, which limits its denoising capability and may lead to the loss of high-frequency
handposedetails. ManipNet(Zhangetal.,2021)doesnotencodetemporalrelationsanddoesnot
incorporate contact-centric canonicalization, rendering it inadequate for capturing the interaction
processandlesseffectiveforgeneralizationpurposes.
3.2 GENEOHDIFFUSION: PROGRESSIVEHOIDENOISINGVIADENOISINGDIFFUSION
WhileGeneOHexcelsinencodingtheinteractionprocessfaithfully,highlightingerrorstofacilitate
denoising,andreducingthedisparitiesamongvariousinteractionsequences,designinganeffective
denoising model is still challenged by complex interaction noise, even from a distribution unseen
during training. Previous methods typically employ pattern-specific denoising models trained to
mapnoisydatarestrictedtocertainpatternstothecleandatamanifold(Zhouetal.,2022;2021b).
However, these methods are susceptible to overfitting, resulting in conceptually incorrect results
whenfacedwithinteractionswithunseennoisepatterns,asevidencedinourexperiments.
To ease the challenge posed by novel in-
Algorithm1DenoisingviaDiffusion
teraction noise, we propose a new denois-
Input: forwarddiffusionfunctionDiffuse(¬∑,t),thede- ing paradigm that learns a canonical de-
noising model denoise(¬∑,t), input noisy point xÀÜ, noising model and leverages it for domain-
diffusionstepst diff. generalizable denoising. It describes the map-
Output: denoiseddatax.
ping from noisy data at various noise scales
1: functionDENOISE(xÀútdiff,t diff)
from a whitened noise space to the data man-
2: fortfromt to1do
3: xÀút‚àí1 ‚àºd dif ef noise(xÀút,t) ifold. The whitened noise space is populated
withnoisydatasamplesdiffusedfromtheclean
4: returnxÀú0
data via a diffusion process which gradually
5: xÀú‚ÜêDiffuse(xÀÜ,t )
diff adds Gaussian noise to the data according to a
6: returnx‚ÜêDENOISE(xÀú,t diff)
variance schedule, a similar flavor to the for-
ward diffusion process in diffusion-based generative models (Song et al., 2020; Ho et al., 2020;
Rombachetal.,2022;Dhariwal&Nichol,2021). Withthecanonicaldenoiser,wethenleveragea
‚Äúdenoisingviadiffusion‚Äùstrategytohandleinputtrajectorieswithvariousnoisepatternsinagen-
eralizablemanner. ItfirstdiffusestheinputtrajectoryxÀÜviathediffusionprocesstoanothersample
xÀú that resides closer to the whitened noise space. Then the model projects the diffused sample xÀú
to the data manifold. To balance the generalization ability of the denoising and the fidelity of the
denoised result to the input, the diffused xÀú needs to be faithful to the input xÀÜ. We then introduce
a diffusiontimestep t that decideshow many diffusion stepsare added. The process isvisually
diff
depictedintherightpartofFigure3. DetailsareoutlinedinAlgorithm1. Wealsoimplementthe
denoisingmodel‚Äôsfunctionandthetrainingasthoseofthescorefunctionsindiffusion-basedgen-
erativemodels. Itisamulti-stepstochasticdenoiserthateliminatesthenoiseoftheinputgradually
tozerostep-by-step. Thiswaythedenoisercandealwithnoiseatdifferentscalesflexiblyandcan
givemultiplesolutionsfortheill-posedambiguousdenoisingproblem.
Basedonthedomain-generalizabledenoisingstrategy,designingasingledata-drivenmodeltoclean
heterogeneous interaction noise in one stage is still not feasible. The interaction noise contains
variouskindsofnoiseatununiformscalesstemmingfromdifferentreasons.Thusthecorresponding
5PublishedasaconferencepaperatICLR2024
noise-to-datamappingisveryhighdimensionalandisverychallengingtolearnfromlimiteddata.
Apromisingsolutiontotacklethecomplexityistakingaprogressiveapproachandlearningmultiple
specialists,eachconcentratingoncleaningaspecifictypeofnoisyinformation. However,themulti-
stageformulationbringsnewdifficulties. Itnecessitatescarefulconsiderationoftheinformationto
becleanedateachstagetopreventthecurrentstagefromcompromisingthenaturalnessachievedin
previousstages. Fortunately,ourdesignoftheGeneOHrepresentationfacilitatesasolutiontothis
issue. HOIinformationcanberepresentedintothreerelativelyhomogeneousparts: J¬Ø, S, andT.
Furthermore,theirrelationsensurethesequentialrefinementofthehandtrajectorybydenoisingits
J¬Ø,S,andT representationsacrossthreestagescanavoidtheunderminingproblem.Aformalproof
ofthispropertyisprovidedintheAppendixA.2.
Progressive HOI denoising. We design a three-stage denoising approach (outlined in Figure 3),
each stage dedicated to cleaning one aspect of the representation: J¬Ø, S, and T, respectively. In
each stage, a canonical denoising model is learned for the corresponding representation, and the
denoisingiscarriedoutusingthe‚Äúdenoisingviadiffusion‚Äùstrategy. GiventheinputGeneOHinput =
{JÀÜ¬Øinput,SÀÜinput,TÀÜinput},
the first denoising stage, named MotionDiff, denoises the noisy canonical
handtrajectoryJÀÜ¬ØinputtoJ¬Østage 1. Onestage-denoisedhandtrajectoryJstage 1 canbeeasilycomputed
byde-canonicalizingJ¬Østage 1 usingobjectposes. GeneOHinput canalsobeupdatedaccordinglyinto
GeneOHstage 1 = {J¬Østage 1,SÀÜstage 1,TÀÜstage 1}. Then the second stage, named SpatialDiff, denoises
thenoisyspatialrelationSÀÜstage 1 toSstage 2. Twostages-denoisedhandtrajectoryJstage 2 canbetrans-
formedfromthehand-objectrelativeoffsetsinSstage 2:Jstage 2 =Average{(h k‚àío k)+o k|o k ‚ààP k}.
Followingthis,GeneOHstage 1 willbeupdatedtoGeneOHstage 2 = {J¬Østage 2,Sstage 2,TÀÜstage 2}. Finally
the last stage, named TemporalDiff, denoises TÀÜstage 2 to Tstage 3. Since temporal information such
asrelativevelocitiesisredundantlyencodedinT,wecomputethethreestages-denoisedhandtra-
jectoryJstage 3 byoptimizingJstage 2 sothatitsinducedtemporalrepresentationalignswithTstage 3.
AndwetakeJstage 3 asthefinaldenoisingoutput,denotedasJ. Eachstagewouldnotundermine
thenaturalnessachievedafterthepreviousstages,asprovedintheAppendixA.2.
Fitting for a hand mesh trajectory. With the denoised trajectory J and the object trajectory, a
parameterizedhandsequencerepresentedviaMANOparameters{r ,t ,Œ≤ ,Œ∏ }K areoptimized
k k k k k=1
tofitJ well. DetailsareillustratedintheAppendixA.3.
4 EXPERIMENTS
We conduct extensive experiments to demonstrate the effectiveness of our method. We train all
modelsonthesametrainingdatasetandintroducefourfourtestsetswithdifferentlevelsofdomain
shift to assess their denoising ability and the generalization ability (see Section 4.2). Moreover,
wedemonstratetheabilityofourdenoisingmethodtoproducemultiplereasonablesolutionsfora
singleinputinSection4.3. Atlast,weshowvariousapplicationsthatwecansupport(Section4.4).
AnotherseriesofexperimentsusingadifferenttrainingsetispresentedintheAppendixB.1.
4.1 EXPERIMENTALSETTINGS
Trainingdatasets. AllmodelsaretrainedontheGRABdataset(Taherietal.,2020). Wefollowthe
cross-objectsplittingstrategyusedinTOCH(Zhouetal.,2022)andtrainmodelsonthetrainingset.
Ourdenoisingmodelonlyrequiresground-truthsequencesfortraining. Forthosewherethenoisy
counterpartsaredemanded,weperturbeachsequencebyaddingGaussiannoiseonthehandMANO
translation,rotation,andposeparameterswithstandarddeviationssetto0.01,0.1,0.5respectively.
Evaluationdatasets. Weevaluateourmodelandbaselinesonfourdistincttestsets,namelyGRAB
test set with Gaussian noise, GRAB (Beta) test set with noise sampled from a Beta distribution
(B(8,2)), HOI4D dataset (Liu et al., 2022) with real noise patterns resulting from depth sensing
errorsandinaccurateposeestimationalgorithms,andARCTICdataset(Fanetal.,2023)withGaus-
sian noise but containing challenging bimanual and dynamic interactions with changing contacts.
Noisy trajectories with synthetic noise are created by adding noise sampled from corresponding
distributionstotheMANOparameters.
Metrics. Weintroducetwosetsofevaluationmetrics. Thefirstsetfocusesonassessingthemodel‚Äôs
ability to recover GT trajectories from noisy inputs following previous works (Zhou et al., 2022),
6PublishedasaconferencepaperatICLR2024
includingMeanPer-Joint/VertexPositionError(MPJPE/MPVPE),measuringtheaveragedistance
betweenthedenoisedhandjointsorverticesandthecorrespondingGTpositionsandContactIoU
(C-IoU)assessingthesimilaritybetweenthecontactmapinducedbydenoisedtrajectoryandtheGT.
The second set quantifies the quality of denoised results, including Solid Intersection Volume (IV)
and Penetration Depth, measuring penetrations, Proximity Error, evaluating the difference of the
hand-objectproximitybetweenthedenoisedtrajectoryandtheGT,andHOMotionConsistency,as-
sessingthehand-objectmotionconsistency.DetailedcalculationsarepresentedintheAppendixC.2.
GRAB(thingeometry) GRAB(Beta)(novelsyntheticnoise) HOI4D(novelrealnoise,thingeometry)
Timestamp Timestamp Timestamp
ARCTIC(novelarticulatedmotions,changingcontacts)
Touchandleavethelid Touchthebase Openandclosethelid
Timestamp
Figure4: Qualitativecomparisons. Pleaserefertoourwebsiteandvideo foranimatedresults.
differentwaystoresolvepenetrations diversegraspingposes differentmanipulationstrategies
Timestamp Timestamp Timestamp
Figure5: Stochasticdenoisingcanproducedivserseresultswithdiscretemodes.
Baselines. WecompareourmodelwiththepriorartontheHOIdenoisingproblem,TOCH(Zhou
etal.,2022). Avariantnamed‚ÄúTOCH(w/MixStyle)‚ÄùisfurthercreatedbycombiningTOCHwith
a general domain generalization method MixStyle (Zhou et al., 2021a). Another variant, ‚ÄúTOCH
(w/Aug.)‚Äù,whereTOCHistrainedonthetrainingsetsoftheGRABandGRAB(Beta),isfurther
introducedtoenhanceitsrobustnesstowardsunseennoisepatterns.
Evaluationsettings. Whenevaluatingourmodel,weselectthetrajectorythatisclosesttotheinput
noisy trajectory from 100 randomly sampled denoised trajectories using seeds from 0 to 99. For
deterministic denoising models, we report the performance on a single run. Since our model can
give multiple solutions for a single input, we additionally report the performance of our model in
the form of average with standard deviations in the Appendix on the second metric set measuring
quality.
4.2 HOIDENOISING
We evaluated our model and compared it with previous works on four test sets: GRAB, GRAB
(Beta), HOI4D, and ARCTIC. In the GRAB test set, all objects were unseen during training, re-
sulting in a shift in the interaction distribution. In the GRAB (Beta) test set, the object shapes,
interaction patterns, and noise patterns differ from those in the training set. The HOI4D dataset
includesinteractionsequenceswithnovelobjectsandunobservedinteractions,alongwithrealnoise
7
y tusi
po
nN
I
HCOT
sruO
y tusi
po
nN
I
sruO
y tusi
po
nN
I
1tluseR
2tluseRPublishedasaconferencepaperatICLR2024
Table 1: Quantitative evaluations and comparisons to baselines. Bold red numbers for best
valuesanditalicbluevaluesforthesecondbest-performedones. ‚ÄúGT‚Äùstandsfor‚ÄúGround-Truth‚Äù.
MPJPE MPVPE C-IoU IV PenetrationDepth ProximityError HOMotionConsistency
Dataset Method (mm,‚Üì) (mm,‚Üì) (%,‚Üë) (cm3,‚Üì) (mm,‚Üì) (mm,‚Üì) (mm2,‚Üì)
GT - - - 0.50 1.33 - 0.51
Input 23.16 22.78 1.01 4.48 5.25 13.29 881.23
GRAB
TOCH 12.38 12.14 23.31 2.09 2.17 3.12 20.37
TOCH(w/MixStyle) 13.36 13.03 23.70 2.28 2.62 3.10 21.29
TOCH(w/Aug.) 12.23 11.89 22.71 1.94 2.04 3.16 22.58
Ours 9.28 9.22 25.27 1.23 1.74 2.53 0.57
Input 17.65 17.40 13.21 2.19 4.77 5.83 27.58
GRAB
TOCH 24.10 22.90 16.32 2.33 2.77 5.60 25.05
(Beta)
TOCH(w/MixStyle) 22.79 21.19 16.28 2.01 2.63 4.65 17.37
TOCH(w/Aug.) 11.65 10.47 24.81 1.52 1.86 3.07 13.09
Ours 9.09 8.98 26.76 1.19 1.69 2.74 0.52
Input - - - 2.26 2.47 - 46.45
TOCH - - - 4.09 4.46 - 35.93
HOI4D
TOCH(w/MixStyle) - - - 4.31 4.96 - 25.67
TOCH(w/Aug.) - - - 4.20 4.51 - 25.85
Ours - - - 1.99 2.15 - 9.81
GT - - - 0.33 0.92 0 0.41
Input 25.51 24.84 1.68 2.28 4.89 15.21 931.69
ARCTIC
TOCH 14.34 14.07 20.32 1.84 2.01 4.31 18.50
TOCH(w/MixStyle) 13.82 13.58 21.70 1.92 2.13 4.25 18.02
TOCH(w/Aug.) 14.18 13.90 20.10 1.75 1.98 5.64 22.57
Ours 11.57 11.09 23.49 1.35 1.93 2.71 0.92
caused by inaccurate sensing and vision estimations. The ARCTIC dataset contains challenging
bimanualdexterousHOIsequenceswithdynamiccontacts. Table1andFigure4,5summarizethe
quantitativeresultsandcandemonstratethesuperiorityofourmethodtorecoverGTsequencesand
produce high-quality results compared to previous baseline methods. We include more results in
theAppendixB.1,ourwebsiteandvideo.
Performanceonchallengingnoisyinteractions. AsshowninFigure4,theperturbednoisytrajec-
toriesexhibitobviousproblemssuchasunnaturalhandposes,largeanddifficultpenetrationssuch
aspenetratingthethinmughandle,andunrealisticmanipulationscausedbyincorrectcontactsand
inconsistenthand-objectmotions.Ourmethodcanproducevisuallyappealinginteractionsequences
fromnoisyinputseffectively. Besides,wedonothavedifficultyinhandlingdifficultshapessuchas
themughandleandscissorringswhichareveryeasytopenetrate. However,TOCHcannotperform
well. Itsresultsstillexhibitobviouspenetrations(thelastframe)andhandmotionsthatareinsuffi-
cienttomanipulatethemug. Furthermore,wearenotchallengedbydifficultanddynamicmotions
withchangingcontacts,asdemonstratedbyresultsontheARCTICdataset.
Results on noisy interactions with unseen noise patterns. In Figure 4, we demonstrate our
method‚Äôs robustness against new noise patterns, including previously unseen synthetic noise and
novel real noise. Our approach effectively cleans such noise, producing visually appealing and
motion-aware results with accurate contacts. In contrast, TOCH fails in these scenarios, as it ex-
hibits obvious penetrations (as seen in the middle example) and results in stiff hand trajectories
withoutpropercontactstomanipulatetheobject(asseenintherightmostexample).
4.3 STOCHASTICHOIDENOISING
Figure5illustratesourabilitytoprovidemultipleplausibledenoisedresultsforasinglenoisyinput.
Notably,weobservediscretemanipulationmodesamongtheseresults. Forinstance,intheleftmost
exampleofFigure5,ourmodelgeneratesdifferenthandposestoaddresstheunnaturalphenomenon
in the second frame, where two fingers penetrate through the camera. Similarly, in the rightmost
example,ourresultsoffertwodistinctwaystorotatethescissorforacertainangle.
4.4 APPLICATIONS
Cleaninghandtrajectoryestimations. Asadenoisingmodel,ourapproachcaneffectivelyrefine
handtrajectoryestimationsderivedfromimagesequenceobservations. Figure6providesexamples
ofapplyingourmodeltoestimationsobtainedfromArcticNet-LSTM(Fanetal.,2023).
8PublishedasaconferencepaperatICLR2024
Refiningnoisyretargetedhandmotions.IntherightpartofFigure6,weshowcasetheapplication
ofourdenoisingmodelincleaningnoisyretargetedhandtrajectories. Ourmodelexcelsatresolving
penetrations present in the sequence resulting from direct retargeting. In contrast, TOCH‚Äôs result
stillsuffersfromnoticeablepenetrations.
CleaningHOIestimations Cleaningretargetedhandtrajectories Cleaningretargetedhandtrajectories (sourcemotionanddirectlyretargetedmotion)
Timestamp Timestamp Timestamp
Figure 6: Applications on refining noisy hand trajectories estimated from videos (left) and
cleaningretargetedhandtrajectories(right).
5 ABLATION STUDY
Generalizedcontact-centricparameterizations. GeneOHleveragesgeneralizedcontactpointsto
normalizethehand-objectrelations. Toassesstheeffectivenessofthisdesign,Wecreateanablated
modelnamed‚ÄúOurs(w/oCanon.)‚Äù,whichusespointssampledfromtheentireobjectsurfaceforpa-
rameterizing.FromTable2,wecanobservethatourdesignonparameterizingaroundtheinteraction
regioncansuccessfullyimprovethemodel‚Äôsgeneralizationabilitytowardsunseeninteractions.
Denoising via diffusion. To further investi- Table2: AblationstudiesontheHOI4Ddataset.
gatetheimpactofthe‚Äúdenoisingviadiffusion‚Äù IV PenetrationDepth HOMotion
Method (cm3,‚Üì) (mm,‚Üì) Consistency(mm2,‚Üì)
strategy on enhancing the model‚Äôs generaliza-
Input 2.26 2.47 46.45
tionability,weablateitbyreplacingthedenois-
Ours(w/oSpatialDiff) 2.94 3.45 31.67
ing model with an autoencoder structure. The Ours(w/oTemporalDiff) 1.72 1.90 34.25
Ours(w/oDiffusion) 3.16 3.83 18.65
resultsaresummarizedinTable2. Besides,the Ours(w/oCanon.) 2.36 3.57 13.26
Ours 1.99 2.15 9.81
comparisons between ‚ÄúOurs (w/o Diffusion)‚Äù
andTOCHhighlightthesuperiorityofourrepresentationGeneOHaswell.
Hand-object spatial and temporal denoising. We propose
a progressive denoising strategy composed of three stages to
clean the complex interaction noise. This multi-stage ap-
proachiscrucial,asasingledenoisingstagewouldfailtopro-
ducereasonableresultsinthepresenceofcomplexinteraction
noise. Tovalidatetheeffectivenessofthestage-wisedenois-
ing, we created two ablated versions: a) ‚ÄúOurs (w/o Tempo-
ralDiff)‚Äùbyremovingthetemporaldenoisingmodule,andb)
‚ÄúOurs(w/oSpatialDiff)‚Äùbyremovingboththetemporaland
spatialdenoisingmodules. Figure7andTable2demonstrate
theireffectivenessinremovingunnaturalhand-objectpenetra- Figure7: EffectivenessoftheSpa-
tionsandenforcingconsistenthand-objectmotions. tialDiffandTemporalDiffstages.
MorequantitativeandqualitativeresultsforablationstudiesareincludedintheAppendixB.2.
6 CONCLUSION AND LIMITATIONS
In this work, we propose GeneOH Diffusion to tackle the generalizable HOI denoising problem.
We resolve the challenge by 1) designing an informative HOI representation that is friendly for
generalization, and 2) learning a canonical denoising model for domain-generalizable denoising.
Experimentsdemonstrateourhighdenoisingcapabilityandgeneralizationability.
Limitations. Themainlimitationliesintheassumptionofaccurateobjectposetrajectories. Itmay
not hold if the HOI sequences are estimated from in-the-wild videos. Refining object poses and
handposesatthesametimeisavaluableandpracticalresearchdirection.
9
-teNcitcrA
-sruO
MTSL
desioneD
ecnorituoMo
eScruoS
gnisioon/ewD
o/w
HCOT
sruO
noitoM
gnisioneD
).o f)f/ .ifw fDiD(
llaass ir tiur atO pu aSO po/Sw(
).)f.ffo
fiiDD/w
lalrs a( or pu rs mO or epu T mO o/we(T
srsuruOO
noitoM
ecruoS
gnisioneD
o/w HCHCOOTT
srsruuOOPublishedasaconferencepaperatICLR2024
REFERENCES
Kfir Aberman, Rundi Wu, Dani Lischinski, Baoquan Chen, and Daniel Cohen-Or. Learning
character-agnosticmotionformotionretargetingin2d. arXivpreprintarXiv:1905.01680,2019.
2
GillesBlanchard,GyeminLee,andClaytonScott. Generalizingfromseveralrelatedclassification
taskstoanewunlabeledsample. Advancesinneuralinformationprocessingsystems,24,2011. 3
HyungjinChung,ByeongsuSim,DohoonRyu,andJongChulYe. Improvingdiffusionmodelsfor
inverseproblemsusingmanifoldconstraints. arXivpreprintarXiv:2206.00941,2022. 3
GuillaumeDewaele,Fre¬¥de¬¥ricDevernay,andRaduHoraud. Handmotionfrom3dpointtrajectories
andasmoothsurfacemodel.InEuropeanConferenceonComputerVision,pp.495‚Äì507.Springer,
2004. 2
PrafullaDhariwalandAlexanderNichol. Diffusionmodelsbeatgansonimagesynthesis. Advances
inNeuralInformationProcessingSystems,34:8780‚Äì8794,2021. 5
QiDou,DanielCoelhodeCastro,KonstantinosKamnitsas,andBenGlocker. Domaingeneraliza-
tionviamodel-agnosticlearningofsemanticfeatures.AdvancesinNeuralInformationProcessing
Systems,32,2019. 3
ZicongFan,OmidTaheri,DimitriosTzionas,MuhammedKocabas,ManuelKaufmann,MichaelJ.
Black,andOtmarHilliges.ARCTIC:Adatasetfordexterousbimanualhand-objectmanipulation.
InProceedingsIEEEConferenceonComputerVisionandPatternRecognition(CVPR),2023. 2,
3,6,8,31
Anindita Ghosh, Rishabh Dabral, Vladislav Golyanik, Christian Theobalt, and Philipp Slusallek.
Imos: Intent-driven full-body motion synthesis for human-object interactions. In Computer
GraphicsForum,volume42,pp.1‚Äì12.WileyOnlineLibrary,2023. 2,3
Patrick Grady, Chengcheng Tang, Christopher D Twigg, Minh Vo, Samarth Brahmbhatt, and
Charles C Kemp. Contactopt: Optimizing contact to improve grasps. In Proceedings of the
IEEE/CVFConferenceonComputerVisionandPatternRecognition,pp.1471‚Äì1481,2021. 2,3
VladimirGuzov,TorstenSattler,andGerardPons-Moll.Visuallyplausiblehuman-objectinteraction
capturefromwearablesensors. arXivpreprintarXiv:2205.02830,2022. 3
Georg Hackenberg, Rod McCall, and Wolfgang Broll. Lightweight palm and finger tracking for
real-time3dgesturecontrol. In2011IEEEVirtualRealityConference,pp.19‚Äì26.IEEE,2011. 2
ShreyasHampali,MahdiRad,MarkusOberweger,andVincentLepetit. Honnotate: Amethodfor
3dannotationofhandandobjectposes. InCVPR,2020. 3
ChrisHecker,BerndRaabe,RyanWEnslow,JohnDeWeese,JordanMaynard,andKeesvanProoi-
jen. Real-timemotionretargetingtohighlyvarieduser-createdmorphologies. ACMTransactions
onGraphics(TOG),27(3):1‚Äì11,2008. 2,3
JonathanHo,AjayJain,andPieterAbbeel. Denoisingdiffusionprobabilisticmodels. Advancesin
NeuralInformationProcessingSystems,33:6840‚Äì6851,2020. 5
SiyuanHuang,ZanWang,PuhaoLi,BaoxiongJia,TengyuLiu,YixinZhu,WeiLiang,andSong-
ChunZhu. Diffusion-basedgeneration,optimization,andplanningin3dscenes. InProceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 16750‚Äì16761,
2023. 2
JunguangJiang,YangShu,JianminWang,andMingshengLong. Transferabilityindeeplearning:
Asurvey. arXivpreprintarXiv:2201.05867,2022. 3
HirokazuKato,MarkBillinghurst,IvanPoupyrev,KenjiImamoto,andKeihachiroTachibana. Vir-
tualobjectmanipulationonatable-toparenvironment. InProceedingsIEEEandACMInterna-
tionalSymposiumonAugmentedReality(ISAR2000),pp.111‚Äì119.Ieee,2000. 2
10PublishedasaconferencepaperatICLR2024
Taein Kwon, Bugra Tekin, Jan Stu¬®hmer, Federica Bogo, and Marc Pollefeys. H2o: Two hands
manipulating objects for first person interaction recognition. In Proceedings of the IEEE/CVF
InternationalConferenceonComputerVision,pp.10138‚Äì10148,2021. 3
QuanzhouLi,JingboWang,ChenChangeLoy,andBoDai.Task-orientedhuman-objectinteractions
generationwithimplicitneuralrepresentations. arXivpreprintarXiv:2303.13129,2023. 3
YunzeLiu,YunLiu,CheJiang,KangboLyu,WeikangWan,HaoShen,BoqiangLiang,ZhoujieFu,
HeWang,andLiYi. Hoi4d: A4degocentricdatasetforcategory-levelhuman-objectinteraction.
In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.
21013‚Äì21022,2022. 2,6,31
MortezaMardani,JiamingSong,JanKautz,andArashVahdat. Avariationalperspectiveonsolving
inverseproblemswithdiffusionmodels. arXivpreprintarXiv:2305.04391,2023. 3
ChenlinMeng,YutongHe,YangSong,JiamingSong,JiajunWu,Jun-YanZhu,andStefanoErmon.
Sdedit:Guidedimagesynthesisandeditingwithstochasticdifferentialequations.InInternational
ConferenceonLearningRepresentations,2021. 3
KrikamolMuandet,DavidBalduzzi,andBernhardScho¬®lkopf. Domaingeneralizationviainvariant
featurerepresentation.InInternationalconferenceonmachinelearning,pp.10‚Äì18.PMLR,2013.
3
JohnnyNu¬¥nÀúez. ComparisonofSpatio-TemporalHandPoseDenoisingModels. PhDthesis,Univer-
sitatDEBarcelona,2022. 3
JuYoungOh,JiHyungPark,andJung-MinPark. Virtualobjectmanipulationbycombiningtouch
andheadinteractionsformobileaugmentedreality. AppliedSciences,9(14):2933,2019. 2,3
WentianQu,ZhaopengCui,YindaZhang,ChenyuMeng,CuixiaMa,XiaomingDeng,andHongan
Wang. Novel-viewsynthesisandposeestimationforhand-objectinteractionfromsparseviews.
arXivpreprintarXiv:2308.11198,2023. 3
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjo¬®rn Ommer. High-
resolutionimagesynthesiswithlatentdiffusionmodels. InProceedingsoftheIEEE/CVFCon-
ferenceonComputerVisionandPatternRecognition,pp.10684‚Äì10695,2022. 5
JavierRomero,DimitriosTzionas,andMichaelJBlack. Embodiedhands: Modelingandcapturing
handsandbodiestogether. arXivpreprintarXiv:2201.02610,2022. 18
Mattia Segu, Alessio Tonioni, and Federico Tombari. Batch normalization embeddings for deep
domaingeneralization. PatternRecognition,135:109115,2023. 3
Orit Shaer, Eva Hornecker, et al. Tangible user interfaces: past, present, and future directions.
FoundationsandTrends¬ÆinHuman‚ÄìComputerInteraction,3(1‚Äì2):4‚Äì137,2010. 2,3
Anthony Sicilia, Xingchen Zhao, and Seong Jae Hwang. Domain adversarial neural networks for
domaingeneralization: Whenitworksandhowtoimprove. MachineLearning,pp.1‚Äì37,2023.
3
Bowen Song, Soo Min Kwon, Zecheng Zhang, Xinyu Hu, Qing Qu, and Liyue Shen. Solv-
ing inverse problems with latent diffusion models via hard data consistency. arXiv preprint
arXiv:2307.08123,2023. 3
YangSong,JaschaSohl-Dickstein,DiederikPKingma,AbhishekKumar,StefanoErmon,andBen
Poole. Score-basedgenerativemodelingthroughstochasticdifferentialequations. arXivpreprint
arXiv:2011.13456,2020. 5
OmidTaheri,NimaGhorbani,MichaelJBlack,andDimitriosTzionas. Grab: Adatasetofwhole-
bodyhumangraspingofobjects. InComputerVision‚ÄìECCV2020: 16thEuropeanConference,
Glasgow,UK,August23‚Äì28,2020,Proceedings,PartIV16,pp.581‚Äì600.Springer,2020. 2,3,
6,30
11PublishedasaconferencepaperatICLR2024
SeyoonTakandHyeong-SeokKo. Aphysically-basedmotionretargetingfilter. ACMTransactions
onGraphics(TOG),24(1):98‚Äì117,2005. 2
Purva Tendulkar, D¬¥ƒ±dac Sur¬¥ƒ±s, and Carl Vondrick. Flex: Full-body grasping without full-body
grasps. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recog-
nition,pp.21179‚Äì21189,2023. 2,3
Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Daniel Cohen-Or, and Amit H Bermano.
Humanmotiondiffusionmodel. arXivpreprintarXiv:2209.14916,2022. 32
Garvita Tiwari, Dimitrije Antic¬¥, Jan Eric Lenssen, Nikolaos Sarafianos, Tony Tung, and Gerard
Pons-Moll. Pose-ndf: Modelinghumanposemanifoldswithneuraldistancefields. InComputer
Vision‚ÄìECCV2022: 17thEuropeanConference,TelAviv,Israel,October23‚Äì27,2022,Proceed-
ings,PartV,pp.572‚Äì589.Springer,2022. 3
NarekTumanyan,MichalGeyer,ShaiBagon,andTaliDekel. Plug-and-playdiffusionfeaturesfor
text-driven image-to-image translation. In Proceedings of the IEEE/CVF Conference on Com-
puterVisionandPatternRecognition,pp.1921‚Äì1930,2023. 3
JindongWang,CuilingLan,ChangLiu,YidongOuyang,TaoQin,WangLu,YiqiangChen,Wenjun
Zeng,andPhilipYu. Generalizingtounseendomains: Asurveyondomaingeneralization. IEEE
TransactionsonKnowledgeandDataEngineering,2022. 3
Pengfei Wang, Zhaoxiang Zhang, Zhen Lei, and Lei Zhang. Sharpness-aware gradient matching
fordomaingeneralization. InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition,pp.3769‚Äì3778,2023. 3
YanWu,JiahaoWang,YanZhang,SiweiZhang,OtmarHilliges,FisherYu,andSiyuTang. Saga:
Stochasticwhole-bodygraspingwithcontact. InComputerVision‚ÄìECCV2022: 17thEuropean
Conference,TelAviv,Israel,October23‚Äì27,2022,Proceedings,PartVI,pp.257‚Äì274.Springer,
2022. 2,3,25,33
Xianghui Xie, Bharat Lal Bhatnagar, and Gerard Pons-Moll. Chore: Contact, human and object
reconstructionfromasinglergbimage. InComputerVision‚ÄìECCV2022: 17thEuropeanCon-
ference,TelAviv,Israel,October23‚Äì27,2022,Proceedings,PartII,pp.125‚Äì145.Springer,2022.
3
Lixin Yang, Xinyu Zhan, Kailin Li, Wenqiang Xu, Jiefeng Li, and Cewu Lu. Cpf: Learning a
contact potential field to model the hand-object interaction. In Proceedings of the IEEE/CVF
InternationalConferenceonComputerVision,pp.11097‚Äì11106,2021. 33
YufeiYe,PoorviHebbar,AbhinavGupta,andShubhamTulsiani.Diffusion-guidedreconstructionof
everydayhand-objectinteractionclips.InProceedingsoftheIEEE/CVFInternationalConference
onComputerVision,pp.19717‚Äì19728,2023. 3
HeZhang,YutingYe,TakaakiShiratori,andTakuKomura. Manipnet: neuralmanipulationsynthe-
siswithahand-objectspatialrepresentation. ACMTransactionsonGraphics(ToG),40(4):1‚Äì14,
2021. 2,3,5,15
RuipengZhang,QinweiXu,JiangchaoYao,YaZhang,QiTian,andYanfengWang. Federateddo-
maingeneralizationwithgeneralizationadjustment. InProceedingsoftheIEEE/CVFConference
onComputerVisionandPatternRecognition,pp.3954‚Äì3963,2023. 3
Yan Zhang and Siyu Tang. The wanderings of odysseus in 3d scenes. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 20481‚Äì20491, 2022.
3
KaiyangZhou,YongxinYang,YuQiao,andTaoXiang. Domaingeneralizationwithmixstyle. In
ICLR,2021a. 7,32
Kanglei Zhou, Zhiyuan Cheng, Hubert PH Shum, Frederick WB Li, and Xiaohui Liang. Stgae:
Spatial-temporal graph auto-encoder for hand motion denoising. In 2021 IEEE International
SymposiumonMixedandAugmentedReality(ISMAR),pp.41‚Äì49.IEEE,2021b. 2,3,5,15
12PublishedasaconferencepaperatICLR2024
Keyang Zhou, Bharat Lal Bhatnagar, Jan Eric Lenssen, and Gerard Pons-Moll. Toch: Spatio-
temporal object correspondence to hand for motion refinement. In European Conference on
ComputerVision(ECCV).Springer,October2022. 2,3,5,6,7,15,30,31,32,33
Qian-YiZhou,JaesikPark,andVladlenKoltun. Open3D:Amodernlibraryfor3Ddataprocessing.
arXiv:1801.09847,2018. 31
13PublishedasaconferencepaperatICLR2024
Overview. TheAppendixprovidesalistofmaterialstosupportthemainpaper.
‚Ä¢ AdditionalTechnicalExplanations(Sec.A).Wegiveadditionalexplanationstocomple-
mentthemainpaper.
‚Äì TheGeneOHrepresentation(Sec.A.1). Wediscussmoreinsightsintotherepresenta-
tiondesign,whyGeneOHcanhighlighterrors,andhowitcomparestorepresentations
designedinpreviousworks.
‚Äì GeneOHDiffusion(Sec.A.2). Wetalkmoreaboutthewhitenednoisespace,thedif-
fusion process, the multi-step stochastic denoising process, the ‚Äúdenoising via dif-
fusion‚Äù strategy, and the progressive denoising, together with a discussion on why
eachdenoisingstagecansuccessfullycleantheinputwithoutbreakingthenaturalness
achievedafterpreviousstages.
‚Äì Fittingforahandmeshtrajectory(Sec.A.3). Weprovidedetailsofthefittingprocess.
‚Ä¢ AdditionalExperimentalResults(Sec.B).Weincludemoreexperimentalresultsinthis
sectiontosupporttheeffectivenessofthemethod,including
‚Äì HOI denoising results (Sec. B.1). We include more denoising results on GRAB,
GRAB (Beta), HOI4D, and the ARCTIC dataset, including long sequences with bi-
manual manipulations. Besides, we discuss the results of another series of experi-
mentswherethetrainingdatasetischangedtothetrainingsetoftheARCTICdataset.
‚Äì Ablation studies (Sec. B.2). We provide more quantitative and qualitative results of
theablationstudies.
‚Äì Applications(Sec.B.3). We providemoreresultsontheapplicationsthatourmodel
cansupport.
‚Äì Failurecases(Sec.B.4). Wediscussthelimitationsandfailurecasesofourmethod.
‚Äì Analyzing the distinction between noise in real hand-object interaction trajectories
andartificialnoise(Sec.B.5). Wediscussthedifferencesbetweentherealnoisepat-
ternsandtheartificialnoise.
‚Äì Userstudy(Sec.B.6).Weadditionallyincludeauserstudytofurtherassessthequality
ofourdenoisedresults.
‚Ä¢ ExperimentalDetails(Sec.C).Weillustratedetailsofdatasets,metrics,baselines,mod-
els, the training and evaluation settings, and the running time as well as the complexity
analysis.
We include a video and an website to introduce our work. The website and the video contain
animateddenoisedresults. Wehighlyrecommendexploringtheseresourcesforanintuitiveunder-
standingofthechallenges,theeffectivenessofourmodel,anditssuperiorityoverpriorapproaches.
A ADDITIONAL TECHNICAL EXPLANATIONS
A.1 THEGENEOHREPRESENTATION
MoreinsightsofthecanonicalizationdesignonT areexplainedasfollows.
CanonicalizationdesignonthetemporalrelationsT. ThetemporalrelationsT leverageshand-
object relative velocity vho at each frame k of each hand-object point pair (h,o) to represent the
k
motionrelations. Wefurthercanonicalizetherelativevelocityviaobjectnormalsbydecomposing
vho into two statistics: vho , vertical to the object tangent plane and parallel to the object point
k k,‚ä•
normal,andvho,lyingintheobject‚Äôstangentplane. Thisdecompositionenablesthemodeltolearn
k,‚à•
different denoising strategies for the two types of relative velocities and enhance cross-interaction
generalization by factoring out object poses. However, relying solely on relative velocities is in-
sufficienttorevealmotionnoiseinhand-objectinteractions. Thesamerelativevelocityparallelto
the normal direction can correspond to a clean state when the hand is far from the object, but a
noisystatewhentheyareincontact. Toaddressthis,wefurtherencodethedistancebetweeneach
hand-objectpairandtheirrelativevelocitiesintotwostatistics, {(eho ,eho )}, usingthefollowing
k,‚ä• k,‚à•
14PublishedasaconferencepaperatICLR2024
formulation:
eh k,o
‚ä•
=e‚àík¬∑dh ko k b‚à•v kh ,o ‚ä•‚à•
2
(2)
eh k,o
‚à•
=e‚àík¬∑dh ko k a‚à•v kh ,o ‚à•‚à• 2. (3)
Here, k, k a, and k
b
are positive hyperparameters, and the term e‚àík¬∑dh ko is inversely related to the
distancebetweenthehandandobjectpoints. Thisformulaallowsthestatisticsforveryclosehand-
objectpointpairstobeemphasizedintherepresentation.
Why GeneOH can highlight errors? For spatial errors, we mainly consider the geometric pen-
etrations between the hand and the object. The hand-object spatial relations S in GeneOH reveal
penetrationsbyparameterizingtheobjectnormalsandhand-objectrelativeoffsets. Inmoredetail,
for each hand-object point pair (h ,o ), the dot product between the object normal n of o and
k k k k
therelativeoffseth ‚àío indicatesthesigneddistancebetweentheobjectpointandthehandpoint.
k k
Foreachhandpointh ,itssigneddistancetotheobjectmeshcanberevealedbyjointlyconsidering
k
itssigneddistancetoallgeneralizedcontactpoints. Sincethehandpointh penetratestheobjectif
k
andonlyifitssigneddistancetotheobjectmeshisnegative,thespatialrelationparameterizationS
canindicatethepenetrationphenomena.
Fortemporalerrors,wemainlyconsiderinconsistenthand-objectmotions. Thereisnounifieddef-
inition or statement regarding what consistent hand-object motions indicate. Intuitively, the hand
should be able to manipulate the object, where sufficient contact and consistent motions between
veryclosehand-objectpointpairsaredemanded. Forveryclosehand-objectpairs,theslidingmo-
tionontheobjectsurfaceispermittedbuttheverticalpenetrationmovingtendencyisnotallowed.
The above expectations and unnatural situations can be revealed from simple statistics like hand-
object relative velocities and hand-object distances. The distance can tell whether they are close
to each other. The relative velocity can reveal their moving discrepancy. The decomposed rela-
tivevelocitylyinginthetangentplaneandverticaltothetangentplaneindicatethesurfacesliding
tendencyandthepenetratingtendencyrespectively. Thedistance-relatedweightterme‚àíkfdh ko can
emphasizehand-objectpairsthatareveryclosetoeachother. Therefore,thetemporalrelationsrep-
resentationT leveragedinGeneOHcansuccessfullyindicatethetemporalnaturalnessandincorrect
phenomena. ThuslearningthedistributionofT canteachthemodelwhatistemporalnaturalness
andhowtocleanthenoisyrepresentation.
TheGeneOHrepresentationcanbeappliedtoparameterizeinteractionsequencesinvolvingrigid
orarticulatedobjects. Itcarefullyintegratesboththehandmotionsandhand-objectspatialandtem-
poralrelations‚Äîmoreexpressiveandcomprehensivecomparedtodesignsinpreviousworks(Zhou
et al., 2022; 2021b; Zhang et al., 2021). Besides, it can highlight spatial and temporal interaction
errors. TheaboveadvantagesmakeGeneOHwell-suitedfortheHOIdenoisingtask.
Inspecting back to previous works, TOCH (Zhou et al., 2022) does not explicitly encode hand-
centricposesorhand-objecttemporalrelationsandonlygroundsthehandsontotheobjectwithout
careful consideration of cross-interaction alignment. ManipNet (Zhang et al., 2021) takes hand-
objectdistancestorepresenttheirrelations. Butthisisnotenoughtorevealtheirspatialrelations.
Canonicalizationsarealsonotcarefullyconsideredinthiswork.
A.2 GENEOHDIFFUSION
Wegiveamoredetailedexplanationofthethreedenoisingstagesinthefollowingtext.
Thewhitenednoisespace.Thisspaceisconstructedbydiffusingthetrainingdatatowardsarandom
Gaussiannoise. Adiffusiontimestep1 ‚â§ t ‚â§ T whereT isthemaximumtimestepcontrolsto
diff
what extent the input is diffused to pure Gaussian noise. It is the space modeled by the diffusion
modelsduringtraining. Thediffusionfunctionweadoptinthisworkisalsoexactlythesameasthe
forwarddiffusionprocessofdiffusionmodels. Tobemorespecifically,givenadatapointx,thet
diff
diffusionwouldtransformtox byalinearcombinationofxandarandomGaussiannoisenwith
t
thesamesizetoxviathefollowingequation:
‚àö ‚àö
x = Œ±¬Ø x+ 1‚àíŒ±¬Ø n, (4)
t t t
whereŒ± = 1‚àíŒ≤ ,Œ±¬Ø = Œ†t Œ± ,{Œ≤ }istheforwardprocessvariances. Thedistributionofx is
t t t s=1‚àös t ‚àö t
anormaldistribution: x ‚àºN( Œ±¬Ø x,(1‚àí Œ±¬Ø )I).
t t t
15PublishedasaconferencepaperatICLR2024
Intuitively, the noise space contains all possible x across all possible timestep 1 ‚â§ t ‚â§ T. x
t t
with smaller t will be more similar to x. In practice, T is set to 1000, Œ≤ = 0.001,Œ≤ = 0.02
1 T
withalinearinterpolationbetweenthemtocreatethevariancesequence{Œ≤ }. Duringtrainingtis
t
uniformlysampledfromthe{t|t‚ààZ,1‚â§t‚â§T}.
Training of the denoising model. Denote the multi-step stochastic denoising model leveraged in
ourmethodasdenoise(¬∑,t)whichtakesthenoisysamplewiththenoisescaletasinputanddenoise
it back to the noise sample with noise scale t ‚àí 1. When t = 1, the denoised result lies in the
cleandatamanifolddepictedbythemodelandistakenasthefinaldenoisedresult.Thedenoise(¬∑,t)
leveragesascorefunctionœµ (¬∑,t)topredictthenoisecomponentoftheinputnoisesamplexÀú . The
Œ∏ t
scorefunctionœµ (¬∑,t)containsoptimizablenetworkweightsŒ∏ andiswhatweneedtolearnduring
Œ∏
training. œµ (¬∑,t) only predicts the noise component nÀÜ. After that, a posterior sampling process is
Œ∏
leveragedtosamplexÀú basedonxÀú andthepredictednÀÜ viathefollowingequation:
t‚àí1 t
1 1‚àíŒ±
xÀú = ‚àö (xÀú ‚àí ‚àö t œµ (xÀú ,t))+œÉ z, (5)
t‚àí1 Œ± t 1‚àíŒ±¬Ø Œ∏ t t
t t
where z ‚àà N(0,I), œÉ2 = Œ≤ . Therefore, the denoising model is a multi-step stochastic denoiser
t t
since at each step it only identifies the mean of the posterior distribution and the denoised result
needstobesampledfromthedistributionwiththepredictedmeanandthepre-definedvariance.
The ‚Äúdenoising via diffusion‚Äù strategy. The input trajectory with noise xÀÜ is diffused to xÀú via
Gaussiannoisewiththediffusiontimestept usingthefollowingequation:
diff
(cid:112) (cid:112)
xÀú=xÀú =xÀÜ = Œ±¬Ø x+ 1‚àíŒ±¬Ø n, (6)
tdiff tdiff tdiff tdiff
wheren‚ààN(0,I)isarandomGaussiannoise.
Given the noisy sample xÀú with noise scale t, the denoising model denoise(¬∑,t) predicts its noise
t
componentviathescorefunction:
nÀÜ =œµ (xÀú ,t). (7)
Œ∏ t
Then xÀú is denoised to xÀú with noise scale t ‚àí 1 by sampling from the posterior distribution
t t‚àí1
followingEq.5withthepredictedmeanxÀú t‚àí ‚àö1 1‚àí ‚àíŒ± Œ±¬Øt tnÀÜ andthepre-definedvarianceœÉ t2.
MotionDiff: canonicalizedhandtrajectorydenoising. Thisdenoisingstageremovesnoisefrom
the canonicalized hand trajectory
JÀÜ¬Øinput
of the input noisy interaction sequence by applying the
diffusion model for one stage-denoised J¬Østage 1, following the ‚Äúdenoising via diffusion‚Äù strategy.
To do this, the noisy representation
JÀÜ¬Øinput
is diffused by adding noise for t steps, followed by
m
denoisingfort stepsusingthediffusionmodel. Theresultingonestage-denoisedhandtrajectory
m
Jstage 1 in the world coordinate space is obtained by de-canonicalizing the denoised canonicalized
handtrajectoryJ¬Østage 1 usingtheposeofthegeneralizedcontactpoints(R k,t k). GeneOHinput can
alsobeupdatedaccordinglyintoGeneOHstage 1 ={J¬Østage 1,SÀÜstage 1,TÀÜstage 1}.
SpatialDiff:hand-objectspatialdenoising. Thehand-objectspatialdenoisingmoduleoperateson
thenoisyhand-objectspatialrelationsSÀÜstage 1 oftheonestage-denoisedinteractionsequenceoutput
by the previous MotionDiff stage. The representation SÀÜstage 1 is diffused by adding noise for t s
diffusionsteps,followedbyanothert stepofdenoising.Onceweobtainthedenoisedrepresentation
s
Sstage 2 which includes the hand-object relative offsets {(h k ‚àí o k)} centered at each generalized
contactpointo ,weadoptasimpleapproachtoconvertitintoatwostages-denoisedhandsequence.
k
Specifically,weaveragethedenoisedhandoffsetsfromeachobjectpointasfollows:
J =Average{(h ‚àío )+o |o ‚ààP }. (8)
k k k k k
Followingthis,GeneOHstage 1 willbeupdatedtoGeneOHstage 2 ={J¬Østage 2,Sstage 2,TÀÜstage 2}.
TemporalDiff: hand-objecttemporaldenoising. Weproceedtocleanthenoisyhand-objecttem-
poralrelationsTÀÜstage 2 ofthetwostages-denoisedsequence.The‚Äúdenoisingviadiffusion‚Äùprocedure
isappliedtothetemporalrelationstoachievethis. Wethenaddanadditionaloptimizationtodis-
till the information contained in the denoised temporal representation to the three stages-denoised
trajectory. Theobjectiveisformulatedas:
minimize‚à•f (J,P)‚ÜíT(Jstage 2,P)‚àíTstage 3‚à•, (9)
Jstage2
16PublishedasaconferencepaperatICLR2024
whereP isthesequenceofgeneralizedcontactpoints,f (¬∑,¬∑)convertsthehandtrajectory
(J,P)‚ÜíT
to the corresponding temporal relations. The distance is calculated on hand-object distances, i.e.,
{dho},relativevelocity{vho}andtworelativevelocity-relatedstatistics({eho,eho }). Weem-
k k k,‚à• k,‚ä•
ployanAdamoptimizertofindtheoptimalhandtrajectory. Theoptimizedtrajectoryistakenasthe
finaldenoisedtrajectoryJ.
Stage-wise denoising strategy. Let I = {(H ,O )}K ‚àà M denote an interaction sequence,
k k k=1
whereMisthemanifoldcontainsallinteractionsequences. LetM J¬Ø,M S,andM
T
representthe
manifolds depicted by the three denoising stages respectively. Let I J¬Ø, I S, and I
T
represent one
stage-denoised trajectory, two stages-denoised trajectory, and the three stages-denoised trajectory
respectively. Further,letRc ,Rc,andRc denotethesetofallnaturalcanonicalizedhandtrajec-
J¬Ø S T
tories,naturalhand-objectspatialrelations,andcorrecthand-objecttemporalrelationsrespectively.
LetR J¬Ø, R S, andR
T
denotethesetofallcanonicalizedhandtrajectories, hand-objectspatialre-
lations, and hand-object temporal relations respectively. Denote the function that transforms the
interactiontrajectoryI tothecanonicalizedhandtrajectoryasf I‚ÜíJ¬Ø, thefunctionthatconvertsI
tothehand-objectspatialrelationsasf , andthefunctionthattransformsI tothehand-object
I‚ÜíS
temporalrelationsasf .
I‚ÜíT
Forallinteractiontrajectoriesconsideredinthework,wemakethefollowingassumption:
Assumption For any trajectory I with the first frame free of spatial noise, we can find a natural
trajectoryI‚Ä≤withthesamefirstframe,thatisI‚Ä≤[1]=I[1].
Thethreefully-traineddenoisingmodelsforJ¬Ø,S,andT shouldbeabletomapthecorresponding
input representation to the set of Rc , Rc, and Rc respectively. Then the relations between the
J¬Ø S T
interactionmanifoldsdepictedbythethreedenoisingstagesandthenaturaldatapriormodeledby
thethreedenoisingmodelshavethefollowingrelations:
‚Ä¢ I ‚ààM J¬Ø ifandonlyiff I‚ÜíJ¬Ø(I)‚ààRc J¬Ø;
‚Ä¢ I ‚ààM ifandonlyiff (I)‚ààRc;
S I‚ÜíS S
‚Ä¢ I ‚ààM ifandonlyiff (I)‚ààRc andthefirstframeI[1]isfreeofspatialnoise.
T I‚ÜíT T
BasedontherelationsbetweenJ¬Ø,S,andT,wecanmakethefollowingclaim:
Claim1 Thereexistingfunctionsf S‚ÜíJ¬Ø : R S ‚Üí R J¬Ø andf T‚ÜíS : (R T,I S[1] ‚Üí R S),sothatfor
anyinteractionIwithcorrespondingGeneOHrepresentationsGeneOH(I)={J¬Ø,S,T},wehave:
J¬Ø=f S‚ÜíJ¬Ø(S)andS =f T‚ÜíS(T,I[1]).
Proof. The canonicalized hand keypoints at each frame k, i.e., J¬Ø is composed of each canoni-
k
calized hand keypoint J¬Ø = {(h ‚àí t )RT|h ‚àà J }, which can be derived from the canon-
k k k k k k
icalized hand-object spatial relation at the frame k. Specifically, for each o ‚àà P , we have
k k
(h ‚àít )RT = (h ‚àío )RT +(o ‚àít )RT. Theuniquecanonicalizedhandtrajectoryatthe
k k k k k k k k k
framek canbedecidedfromthetrajectoryconvertedfromeachobjectpointo ‚àà P . Depending
k k
on the conversion function from such multiple hypotheses of the canonicalized hand trajectory re-
sultingfromdifferento k,thereexistsafunctionf S‚ÜíJ¬Ø : S ‚Üí R J¬Ø thattransformsthehand-object
spatialrelationsS tothecanoncializedhandtrajectoryJ¬Ø.
Similarly, given the hand-object temporal relations at the frame k(1 ‚â§ k ‚â§ K ‚àí1) of the object
pointo ‚àà P andthenaturalhandkeypointsatthestartingframe1,i.e.,J ,therelativevelocity
k k 1
for each hand-object pair (h ,o ) can be derived from the decoded hand-object relative velocity
k k
vho, two velocity-related statistics (eho ,eho), the hand-object distance dho. Given the hand-
k k,‚ä• k,‚à• k
objectrelativepositions{(h ‚àío )|h ‚ààJ },thehand-objectrelativepositionsateachfollowing
1 1 1 1
frame k + 1(1 ‚â§ k ‚â§ K ‚àí 1) can be derived iteratively via the hand-object relative velocity
{vho|o ‚àà P }: h ‚àí o = (h ‚àí o ) + ‚àÜtvho. Therefore, there existing a function
k k k k+1 k+1 k k k
f : R ‚Üí R thatcanconvertthetemporalrelationsT tothehand-objectspatialrelations
T‚ÜíS T S
S.
Basedonthisproperty,wecanmakethefollowingclaimregardingtherelationsbetweenthethree
graduallyconstructedmanifolds:
Claim2 Assumethefirstframeofthetwostages-denoisedtrajectoryI [1]isfreeofspatialnoise,
S
whichalmostalwaysholdstrue,wehaveM
T
‚äÜM
S
‚äÜM J¬Ø.
17PublishedasaconferencepaperatICLR2024
Proof. ForI ‚ààM
S
withtheGeneOHrepresentation{J¬Ø,S,T},assumeI ‚àà/ M J¬Ø.
‚Ä¢ FromI ‚ààM ,wehaveS ‚ààRc;
S S
‚Ä¢ BasedonthedefinitionofRc,thesetofspatialrelationsderivedfromallnaturalinterac-
S
tions,thereexistsanaturalinteractionI‚Ä≤sothatf (I‚Ä≤)=S;
I‚ÜíS
‚Ä¢ SinceI‚Ä≤isanaturalinteraction,wehaveJ¬Ø‚Ä≤ =f I‚ÜíJ¬Ø(I‚Ä≤)‚ààRc J¬Ø;
‚Ä¢ SinceJ¬Ø=f S‚ÜíJ¬Ø(S)=J¬Ø‚Ä≤,wehaveJ¬Ø‚ààRc J¬Ø;
‚Ä¢ Basedontheassumedfully-traineddenoisingmodel,wehaveI ‚ààM J¬Ø.
TheconclusioncontradictswiththeassumptionI ‚àà/ M J¬Ø. ThusM S ‚äÜM J¬Ø holdstrue.
ForaI ‚ààM withtheGeneOHrepresentation{J¬Ø,S,T}whosefirstframeisfreeofspatialnoise,
T
assumeI ‚àà/ M .
S
‚Ä¢ FromI ‚ààM ,wehavethatT ‚ààRc ;
T T
‚Ä¢ BasedonthedefinitionofRc ,thesetoftemporalrelationsderivedfromallnaturalinter-
T
actions,andtheAssumption1,thereexistinganaturalinteractionI‚Ä≤,withthefirstframe
sametoI,sothatf (I‚Ä≤)=T;
I‚ÜíT
‚Ä¢ SinceI‚Ä≤isanaturalinteraction,wehaveS‚Ä≤ =f (I‚Ä≤)‚ààRc;
I‚ÜíS S
‚Ä¢ SinceS =f (T,I[1])=f (T,I‚Ä≤[1])=S‚Ä≤,wehaveS ‚ààRc;
T‚ÜíS T‚ÜíS S
‚Ä¢ Basedontheassumedfully-traineddenoisingmodel,wehaveI ‚ààM .
S
TheconclusioncontradictswiththeassumptionI ‚àà/ M . ThusM ‚äÜM holdstrue.
S T S
The stage-wise GeneOH Diffusion functions as the following steps to clean the input interaction
I ‚ààM:
‚Ä¢ Given the input interaction I, the denoising model for J¬Ø maps J¬Ø to another J¬Ø1 ‚àà Rc .
J¬Ø
ThereexistinganinteractionI1 s.t. J¬Ø1 = f I‚ÜíJ¬Ø(I1), whichisalsoexactlythesameas
thetrajectoryderivedfromJ¬Ø1andtheobjecttrajectory{O }K . Therefore,afterthefirst
k k=1
denoisingstage,wehaveI1 ‚ààM J¬Ø.
‚Ä¢ GivenS1,thedenoisingmodelforS mapsS1 toS2 ‚àà Rc. Thereexistinganinteraction
S
I2s.t. S2 =f (I2). Therefore,aftertheseconddenoisingstage,wehaveI2 ‚ààM .
I‚ÜíS S
‚Ä¢ Afterthat,thedenoisingmodelforT mapsT2 =f (I2)toT3 ‚ààRc . Afterthat,the
I‚ÜíT T
interactionI3constructedasthefollowingsteps:
‚Äì ConstructS3fromT3andI2[1]viaS3 =f (T3,I2[1]);
T‚ÜíS
‚Äì ConstructJ¬Ø3fromS3viaJ¬Ø3 =f S‚ÜíJ¬Ø(S3);
‚Äì ConstructI3fromJ¬Ø3andtheobjecttrajectory{O }K .
k k=1
Since T3 = f (I3) ‚àà Rc and I3[1] = I2[1] is free of spatial noise, we have I3 ‚àà
I‚ÜíT T
M .
T
Therefore, the three denoising stages gradually map the input noisy interaction to a progressively
smallermanifoldcontainedinthepreviouslargemanifold. Formallywehave
GeneOHDiffusion(¬∑):M‚ÜíM J¬Ø ‚ÜíM S ‚ÜíM T. (10)
A.3 FITTINGFORANHOITRAJECTORY
Once the interaction sequence has been denoised, we proceed to fit a sequence of hand
MANO (Romero et al., 2022) parameters to obtain final hand meshes. The objective is optimiz-
ingaseriesofMANOparameters{r ,t ,Œ≤ ,Œ∏ }K sothattheyfitthedenoisedtrajectoryJ well.
k k k k k=1
Notice the hand trajectory J consists of a sequence of hand keypoints so we also need to derive
18PublishedasaconferencepaperatICLR2024
Table 3: HOI4D Dataset. Per-category statistics of the HOI4D dataset used in our experiments,
includingnumberofsequencesandtheindexofthestartframe.
Laptop Pliers Scissors Bottle Bowl Chair Mug ToyCar Kettle
#Seq. 155 187 93 214 217 167 249 257 58
StartingFrame 120 150 50 0 0 0 0 0 0
keypointsfromMANOparameterstoallowtheaboveoptimization.Luckilythisprocessisdifferen-
tiableandweuseJrecon({r ,t ,Œ≤ ,Œ∏ }K )todenoteit.Wecanthereforeoptimizethefollowing
k k k k k=1
reconstructionlossfortheMANOhands
L =‚à•J ‚àíJrecon({r ,t ,Œ≤ ,Œ∏ }K )‚à•, (11)
recon k k k k k=1
where the distance function is a simple mean squared error (MSE) between the hand keypoints
at each frame. To regularize the hand parameters {Œ≤ ,Œ∏ } and enforce temporal smoothness, we
k k
introduceanadditionalregularizationlossdefinedas
K K‚àí1
1 (cid:88) 1 (cid:88)
L = (‚à•Œ≤ ‚à• +‚à•Œ∏ ‚à• )+ ‚à•Œ∏ ‚àíŒ∏ ‚à• . (12)
reg K k 2 k 2 K‚àí1 k+1 k 2
k=1 k=1
Theoveralloptimizationobjectiveisformalizedas
minimize (L +L ), (13)
{rk,tk,Œ≤k,Œ∏k}K
k=1
recon reg
andweemployanAdamoptimizertosolvethefittingproblem.
B ADDITIONAL EXPERIMENTAL RESULTS
We present additional experimental results to further support the denoising effectiveness and the
stronggeneralizationabilityofourmethod.
B.1 HOIDENOISING
For the first set of evaluation metrics, Table 4 presents more evaluations on our method, ablated
versions, and the comparisons to the baseline models than the table in the main text. For the sec-
ond set of evaluation metrics, Table 5 summarizes more results and comparisons. For stochastic
denoisingmethods, including‚ÄúOurs‚Äù, ‚ÄúOursw/oCanon.‚Äù, ‚ÄúOursw/oSpatialDiff‚Äù, and‚ÄúOursw/o
TemporalDiff‚Äù,wereportthemeanandthestandarddeviationofresultsobtainedfromthreeinde-
pendent runs with the random seed set to 11, 22, and 77 respectively. Such statistics offer a more
comprehensive view of the average results quality produced by those methods. Please notice that
theevaluationmethodisdifferentfromtheonepresentinthemaintext,wheretheresultclosestto
theinputtrajectoryamong100independentrunsischosentoreportevaluationmetrics.
MoreresultsontheGRABtestset‚Äìnovelinteractionswithnewobjects. Figure8showsquali-
tativeevaluationsontheGRABtestsettocomparethegeneralizationabilityofdifferentdenoising
modelstowardsnovelinteractionswithunseenobjects.
More results on the GRAB (Beta) test set ‚Äì novel interactions with new objects and unseen
synthetic noise patterns. Figure 9 shows qualitative evaluations on the GRAB (Beta) test set to
comparethegeneralizationabilityofdifferentdenoisingmodelstowardsunseenobjects,unobserved
interactions,andnovelsyntheticnoise.
More results on the HOI4D dataset ‚Äì novel interactions with new objects and unseen real
noise patterns. Figure 10 shows qualitative evaluations on the HOI4D test set to compare the
generalizationabilityofdifferentdenoisingmodelstowardsunseenobjects,unobservedinteractions,
andnovelrealnoise.
WiredhandtrajectoryproducedbyTOCH(w/MixStyle).ThroughourexperimentswithTOCH
on interaction sequences with new noise patterns unseen during training, we frequently observe
strange hand trajectories from its results with stiff hand poses, unsmooth trajectories, and large
19PublishedasaconferencepaperatICLR2024
Table 4: Quantitative evaluations and comparisons. Performance comparisons of our method,
baselines, andablatedversionsondifferenttestsetsusingthefirstsetofevaluationmetrics. Bold
rednumbersforbestvaluesanditalicbluevaluesforthesecondbest-performedones.
MPJPE MPVPE C-IoU
Dataset Method
(mm,‚Üì) (mm,‚Üì) (%,‚Üë)
Input 23.16 22.78 1.01
TOCH 12.38 12.14 23.31
TOCH(w/MixStyle) 13.36 13.03 23.70
GRAB TOCH(w/Aug.) 12.23 11.89 22.71
Ours(w/oSpatialDiff) 7.83 7.67 26.09
Ours(w/oTemporalDiff) 8.27 8.13 26.55
Ours(w/oDiffusion) 8.52 8.38 26.44
Ours(w/oCanon.) 10.15 10.07 24.92
Ours 9.28 9.22 25.27
Input 17.65 17.40 13.21
TOCH 24.10 22.90 16.32
GRAB
TOCH(w/MixStyle) 22.79 21.19 16.28
(Beta)
TOCH(w/Aug.) 11.65 10.47 24.81
Ours(w/oDiffusion) 12.16 11.75 22.96
Ours(w/oCanon.) 10.89 10.61 24.68
Ours 9.09 8.98 26.76
Input 25.51 24.84 1.68
ARCTIC
TOCH 14.34 14.07 20.32
TOCH(w/MixStyle) 13.82 13.58 21.70
TOCH(w/Aug.) 14.18 13.90 20.10
Ours 11.57 11.09 23.49
penetrations as shown in Figure 9 and 4. Such phenomena cannot be mitigated by augmenting it
withgeneraldomaingeneralizationtechniques. Figure12demonstratesthattheimprovedversion,
TOCHwithMixStyle,alsoyieldssimilarunnaturalresults. Thissuggeststhatthenovelnoisedistri-
butionpresentsachallengingobstacleforthedenoisingmodeltogeneralizetonewnoisyinteraction
sequences. Incontrast,ourmethoddoesnothavesuchdifficultyinhandlingtheshiftednoisedistri-
bution.
ResultsofTOCHandTOCH(w/Aug.) ontheHOI4Ddataset. Figure11comparestheresults
of TOCH (w/ Aug.) with our method. In the example of opening a scissor, TOCH produces very
strange‚Äúflyinghands‚Äùtrajectories,forwhichpleaserefertoourvideoforanintuitiveunderstanding.
Thoughtheresultsproducedbytheimprovedversiondonotexhibitthe‚Äúflyinghands‚Äùartifacts,it
is still very strange, stiff, suffering from very unnatural hand poses, and cannot perform correct
manipulations. TheresultsofTOCHandTOCH(w/Aug.) ontheToyCarexampleareverysimilar
sinceourexperimentsindeedgetverysimilarresultsfromsuchtwomodelsinthiscase. Theyboth
aretroubledbystrangehandshapesandveryunnaturaltrajectories.
MoreresultsontheARCTICdataset‚Äìnovelinteractionswithnewobjectsinvolvingdynamic
object motions and changing contacts. Figure 13 shows qualitative evaluations on the ARCTIC
test set to test the ability of our denoising model to clean noisy and dynamic interactions with
changingcontacts.
Besides, we include samples of our results on longer sequences with bimanual manipulations in
Figure14.
Multi-statedenoisingv.s.one-stagedenoising.Weleverageamulti-stagedenoisingstrategyinthis
worktotacklethechallengeposedbycomplexinteractionnoise.InSectionA.2,wedemonstratethe
stage-wise denoising strategy gradually projects the input trajectory from the manifold containing
unnatural interactions, to the manifold of trajectories with natural hand motions, to the manifold
20PublishedasaconferencepaperatICLR2024
Table 5: Quantitative evaluations and comparisons. Performance comparisons of our method,
baselines,andablatedversionsondifferenttestsetsusingthesecondsetofevaluationmetrics.Bold
rednumbersforbestvaluesanditalicbluevaluesforthesecondbest-performedones. ‚ÄúGT‚Äùstands
for‚ÄúGround-Truth‚Äù.
IV PenetrationDepth ProximityError HOMotionConsistency
Dataset Method
(cm3,‚Üì) (mm,‚Üì) (mm,‚Üì) (mm2,‚Üì)
GT 0.50 1.33 0 0.51
Input 4.48 5.25 13.29 881.23
TOCH 2.09 2.17 3.12 20.37
TOCH(w/MixStyle) 2.28 2.62 3.10 21.29
GRAB
TOCH(w/Aug.) 1.94 2.04 3.16 22.58
Ours(w/oSpatialDiff) 2.15¬±0.02 2.29¬±0.03 6.71¬±1.09 12.16¬±0.67
Ours(w/oTemporalDiff) 0.86¬±0.02 1.54¬±0.02 3.93¬±0.31 9.36¬±0.68
Ours(w/oDiffusion) 1.07 1.70 2.63 10.05
Ours(w/oCanon.) 1.57¬±0.02 1.83¬±0.03 2.91¬±0.28 1.30¬±0.03
Ours 1.22¬±0.01 1.72¬±0.01 2.44¬±0.18 0.41¬±0.01
GT 0.50 1.33 0 0.51
Input 2.19 4.77 5.83 27.58
GRAB TOCH 2.33 2.77 5.60 25.05
(Beta) TOCH(w/MixStyle) 2.01 2.63 4.65 17.37
TOCH(w/Aug.) 1.52 1.86 3.07 13.09
Ours(w/oDiffusion) 1.98 2.06 3.00 11.99
Ours(w/oCanon.) 1.79¬±0.02 1.73¬±0.03 3.19¬±0.15 1.28¬±0.03
Ours 1.18¬±0.00 1.69¬±0.01 2.78¬±0.14 0.54¬±0.00
Input 2.26 2.47 - 46.45
TOCH 4.09 4.46 - 35.93
TOCH(w/MixStyle) 4.31 4.96 - 25.67
HOI4D
TOCH(w/Aug.) 4.20 4.51 - 25.85
Ours(w/oDiffusion) 3.16 3.83 - 18.65
Ours(w/oCanon.) 2.37¬±0.02 3.57¬±0.03 - 12.80¬±0.79
Ours 1.99¬±0.02 2.14¬±0.02 - 9.75¬±0.88
GT 0.33 0.92 0 0.41
Input 2.28 4.89 15.21 931.69
ARCTIC
TOCH 1.84 2.01 4.31 18.50
TOCH(w/MixStyle) 1.92 2.13 4.25 18.02
TOCH(w/Aug.) 1.75 1.98 5.64 22.57
Ours 1.35¬±0.01 1.91¬±0.02 2.69¬±0.11 0.85¬±0.00
Table6: QuantitativeevaluationsofthemodeltrainedontheARCTICtrainingset. Boldred
numbersforbestvalues. ‚ÄúGT‚Äùstandsfor‚ÄúGround-Truth‚Äù.
MPJPE MPVPE C-IoU IV PenetrationDepth ProximityError HOMotionConsistency
Dataset Method (mm,‚Üì) (mm,‚Üì) (%,‚Üë) (cm3,‚Üì) (mm,‚Üì) (mm,‚Üì) (mm2,‚Üì)
GT - - - 0.50 1.33 - 0.51
Input 23.16 22.78 1.01 4.48 5.25 13.29 881.23
GRAB
Ours(GRAB) 9.28 9.22 25.27 1.23 1.74 2.53 0.57
Ours(ARCTIC) 11.47 11.29 24.79 1.48 1.80 2.60 0.55
Input - - - 2.26 2.47 - 46.45
HOI4D
Ours(GRAB) - - - 1.99 2.15 - 9.81
Ours(ARCTIC) - - - 1.54 1.96 - 9.33
GT - - - 0.33 0.92 0 0.41
Input 25.51 24.84 1.68 2.28 4.89 15.21 931.69
ARCTIC
Ours(GRAB) 11.57 11.09 23.49 1.35 1.93 2.71 0.92
Ours(ARCTIC) 10.34 10.07 25.08 1.21 1.64 2.62 1.10
withcorrectspatialrelations,andtothemanifoldoftrajectorieswithconsistenttemporalrelations.
One may question whether it is possible to use the last projection step only to project the input to
thenaturalinteractionmanifoldinasinglestep. Ourexperimentalobservationsshowthedifficulty
ofremovingsuchcomplexnoiseinonesinglestage. Aneffectivemappingtocleansuchcomplex
noiseisveryhardtolearnforneuralnetworks.
21PublishedasaconferencepaperatICLR2024
View 1 View 2 View 3
Figure 8: Evaluation and comparisons on the GRAB test set. Input and denoised results are
shownfromthreeviewsviafourkeyframesinthetime-increasingorder. Pleaserefertoourwebsite
andvideoforanimatedresults.
GeneralizefromARCTICtootherdatasets. Tofurtherevaluatethegeneralizationabilityofour
method,weconductanewseriesofexperimentswherewetrainthemodelontheARCTICdataset
(seetheSectionCfordatasplittingandothersettings)andevaluateonGRAB,HOI4D,andARCTIC
(testsplit). Table6containsitsperformance. Wecanobservethatthoughourmodeltrainedonthe
GRAB can generalize to ARCTIC with good performance, the reduced domain gap when using
ARCTICasthetrainingsetcanreallyimprovetheperformance. Forinstance,Figure15showsthat
themodeltrainedontheARCTICtrainingsetcanperformobviouslybetteronexampleswherethe
modeltrainedonGRABwouldstruggle(pleaseseeSectionB.4forthediscussiononfailurecase).
Forthesequencewherethehandneedstoopenwidetoholdthemicrowave, themodeltrainedon
GRABcannotcleanthenoisyveryeffectively,producingresultswithobviouspenetrationsandthe
unnaturalhandtrajectorywithinstantaneousshaking. However,themodeltrainedontheARCTIC
dataset can eliminate such noise and produce a much natural trajectory. Besides, training on this
22
y tusi
po nN I
sruO
HCOT
y tusi
po nN I
sruO
HCOT
y tusi
po nN I
sruO
HCOT
y tusi
po nN I
sruO
HCOTPublishedasaconferencepaperatICLR2024
View 1 View 2 View 3
Figure9: EvaluationandcomparisonsontheGRAB(Beta)testset. Pleaserefertoourwebsite
andvideoforanimatedresults.
dataset can benefit the model‚Äôs performance on the HOI4D dataset with articulated objects and
articulatedmotions.
B.2 ABLATIONSTUDIES
This section includes more ablation study results to complement the selected results in the main
text. Table4and5presentamorecomprehensivequantitativeevaluationofablatedmodelsandthe
comparisonstothefullmodel.
Generalizedcontact-centricparameterizations. ApartfromtheresultspresentinTable4and5,
Figure 16 gives and visual example where the ablated version without such contact-centric design
cannot generalize well to the manipulation sequence with large object movements. We can still
observeobviouspenetrationsfromallthreeframespresenthere.
Denoising capability on recovering ground-truth and modeling high-frequency pose details.
Togetherwiththeabilitytomodelvarioussolutions,thestochasticdenoisingprocessalsoempowers
the model to explore a broad space that is more likely to encompass samples close to the ground-
truth sequences. Figure 17 shows that ours is more faithful to the ground-truth sequence than the
resultofTOCH,regardingbothrecoveredhandposesandthecontactinformation.
Besides,takingadvantageofthepowerofourHOIrepresentationGeneOHandthenoveldenoising
scheme,weareabletomodelhigh-frequencyshapedetailsintheresults. However,TOCH‚Äôsresults
wouldexhibitflathandposesfrequently. Thismayresultfromitshigh-dimensionalrepresentations
23
ysioN
ysioN
ysioN
sruO
HCOT
sruO
HCOT
sruO
HCOT
tupnI
tupnI
tupnIPublishedasaconferencepaperatICLR2024
View 1 View 2 View 3
Figure10: EvaluationontheHOI4Ddataset.Pleaserefertoourwebsiteandvideoforanimated
results.
24
ysioN
ysioN
ysioN
ysioN
sruO
HCOT
sruO
HCOT
sruO
HCOT
sruO
HCOT
tupnI
tupnI
tupnI
tupnIPublishedasaconferencepaperatICLR2024
View 1 View 2 View 3
Figure11: ComparisonsontheHOI4Ddataset.WecompareourmethodwiththebaselineTOCH
anditsimprovedversionTOCH(w/Aug.).
Timestamp
Figure12: WeirdartifactsproducedbyTOCH(w/MixStyle). (Firstline:) Oursresult. (Second
line:) The result of TOCH (w/ MixStyle). The noisy input is perturbed by noise sampled from a
Betadistribution,differentfromthatusedintraining.
andthelimitedabilityofthedenoisingstrategy,whichmodelsthedeterministic,one-stepnoise-to-
datamappingrelation.
B.3 APPLICATIONS
Thissectionpresentsmoreapplicationsofthedenoisingmodel.
Refiningnoisygraspsproducedbythegenerationnetwork. Inadditiontorefiningnoisyinterac-
tionsequences,ourmethodcanserveasaneffectivepost-processingtooltorefineimplausiblestatic
graspsproducedbythegenerationnetworkasshowninFigure6. Examplesshownherearegrasps
takenfrominteractionresultsproducedby(Wuetal.,2022).
25
ysioN
HCOT
ysioN
HCOT
sruO
HCOT
sruO
HCOT
tupnI
).guA
/w(
tupnI
).guA
/w(
sruO
)elytH
SC xiO MT
/w(PublishedasaconferencepaperatICLR2024
Timestamp
Figure 13: Evaluation on the ARCTIC dataset. The model cleans noisy right hand trajectory
here. LefthandsshowninboththenoisyinputandthedenoisedtrajectoryareGTshapes. Please
refertoourwebsiteandvideoforanimatedresults.
Noisy
Input
Denoised
Noisy
Input
Denoised
Figure14: Evaluationonlonginteractionsequenceswithbimanualmanipulations. Themodel
cleans both the noisy right hand trajectory and the noisy left hand trajectory here. Please refer to
ourwebsiteandvideoforanimatedresults.
26
ysioN
ysioN
ysioN
ysioN
ysioN
sruO
sruO
sruO
sruO
sruO
tupnI
tupnI
tupnI
tupnI
tupnIPublishedasaconferencepaperatICLR2024
Trainedon
GRAB
Trainedon
ARCTIC
Holdamicrowave
Figure 15: Comparisons between the model trained on ARCTIC and the one trained on
GRAB. The model trained on ARCTIC training set can generalize to the corresponding test se-
quencesmoreeasilythankstothereduceddomaingap.
Figure16: Effectivenessofthegeneralizedcontact-centricparameterization. (Firstline:) Re-
sultsofOurs(w/oCanon.). (Secondline:) Resultsofourfullmodel.
Apart from the denoising ability, the denoised data with high-quality interaction sequences and
staticgraspscanfurtheraidavarietyofdownstreamtasks. Herewetakethegraspsynthesisandthe
manipulationsynthesistaskasanexample.
Graspsynthesis.WeselectfourobjectsandtheircorrespondinggraspingposesfromtheGRABtest
settotrainthesynthesisnetwork. Thenweusethenetworktogenerategraspsforunseenobjects.
TheresultsshowninFigure18arenaturalandcontact-aware. Incontrast,thegeneratedgraspsare
notplausibleasshownintheleftmostpartofFigure18.
Manipulation synthesis. We further examine the quality of the denoised interaction data via the
manipulation synthesis task. Based on the representations and the network architecture proposed
inarecentmanipulationsynthesiswork1,wetrainamanipulationsynthesisnetworkusingourde-
noiseddata. Thenetworkthentakesanewobjectsequenceasinputtogeneratethecorresponding
manipulationsequence. AsshowninFigure19,thequalityofourdataiswellsuitedforalearning-
basedsynthesismodel. Itcangeneratediverse,high-qualitymanipulationsequencesforanunseen
objecttrajectory.
Theabovetwoapplicationsindicatethepotentialvalueofourdenoisingmodelinaidinghigh-quality
interactiondatasetcreation.
B.4 FAILURECASES
Figure20summarizesthefailurecases. Ourmethodmaysometimesbeunabletoperformverywell
in the following situations: 1) When the hand needs to open wide to hold the object, the canoni-
calizedhand trajectories andthehand-objectspatial relationscanonicalizedaroundthe interaction
regionmaybeextremelynoveltothedenoisingmodel. Themodelthencannotfullycleanpenetra-
tions from the observations. 2) When the noisy input contains very strange hand motions such as
thesuddendetachmentandgraspingpresentedinFigure20,themodelcanremovesuchartifactbut
stillcannotcleanthetrajectoryperfectly,leavingusremainingpenetrationsshowninthedenoised
result. 3) When the hand is opening an unseen object with extremely thin geometry, we may still
observesubtlepenetrationsfromtheresults.
1https://github.com/cams-hoi/CAMS
27
).nonsr
au CO
o/w(
sruOPublishedasaconferencepaperatICLR2024
Ground-Truth TOCH Ours(Sample1) Ours(Sample2)
Figure17: ComparisonsbetweenourmodelandTOCHontheabilitytorecoverground-truth
interactions. We can explore a wide space that encompasses the sample with hand poses (high-
lighted in yellow circles ) and contacts (in green circles) close to the ground truth. We can model
high-frequency poses. However, TOCH‚Äôs result contains plain poses and cannot recover bending
fingersexhibitedintheground-truthshape.
Results of the Network Camera Toothpaste Laptop
Trained on Nosiy Data
Figure18: Graspsynthesis. Synthesizedgraspsforunseenobjects.
B.5 ANALYZINGTHEDISTINCTIONBETWEENNOISEINREALHAND-OBJECT
INTERACTIONTRAJECTORIESANDARTIFICIALNOISE
From the visualization and animated results shown on the website and the video, the distinctions
betweenthenoiseexhibitedinrealnoisyhand-objectinteractiontrajectories(e.g.,handtrajectories
from the noisy HOI4D dataset and hand trajectories estimated from interaction videos) and the
artificialnoisecouldbesummarizedasfollows:
‚Ä¢ ThetrajectoriesinHOI4Dalwayspresentunnaturalhandposes,jitteringmotions,missing
contacts,andlargepenetrations;
‚Ä¢ Retargeedhandmotionsalwayssufferfromlargepenetrations;
‚Ä¢ ThehandtrajectoriesestimatedfromHOIvideosareusuallywithpenetrationsandmissing
contacts;
‚Ä¢ Acommonfeatureisthatrealnoisyhandtrajectoriesalwayspresenttime-consistentarti-
facts.However,noisytrajectorieswithartificialnoiseaddedindependentlyontoeachframe
usuallypresenttime-varyingpenetrationsandunnaturalposes.
Besides,assummarizedinTable1,thedifferencesbetweendifferentkindsofnoisepatternscanbe
revealedbycomparingvariousmetricscalculatedontheirinputnoisytrajectories,includingmetrics
torevealpenetrations(IV,penetrationdepth),hand-objectproximity(C-IoU,ProximityError),and
motionconsistency.
Further analysis. We further visualize the difference (Œ∏ÀÜ‚àí Œ∏gt) between noisy hand mano pose
parameters (Œ∏ÀÜ) and the GT values (Œ∏gt) obtained from the trajectories estimated from videos (the
noisy input of the application on cleaning hand trajectory estimations, Sec. 4.4), the difference
between the mano pose parameters with artificial Gaussian noise (Œ∏ÀÜn) and the GT values, and the
differencesbetweentheparameterswithartificialnoisedrawnfromtheBetadistribution(Œ∏ÀÜb). By
projectingthemintothe2-dimensionalplaneusingthePCAalgorithm(implementedinthescikit-
learn package), we visualize their positions from 256 examples in Figure 21. As we can see, the
realnoisepatternisverydifferentfromartificialnoise. Inthiscase,thenoiseofthehandtrajectory
estimatedfromvideosfurtherexhibitsinstance-specificpatterns.
28PublishedasaconferencepaperatICLR2024
Timestamp
Figure 19: Manipulation synthesis. Synthesized manipulation sequences for the unseen laptop
object. Framesshownherefromlefttorightareinatime-increasingorder.
Denoised
Openwidetoholdtheunseenlargeobject(ARCTIC)
Noisy
Input
Denoised
Extremelyunnaturalandstrangehand-objecttemporalrelations(HOI4D)
Veryunnaturalandstrangehand-objectspatialrelations
Denoised
Unseenobjectwithverythingeometry(ARCTIC)
Figure20: Failurecasescausedbytheunseenandlargeobject,verystrangehand-objecttemporal
relations,andunseenobjectwithextremelythingeometry.
B.6 USERSTUDY
Tobetteraccessandcomparethequalityofourdenoisedresultstothoseofthebaselinemodel,we
conductedatoyuserstudy. WesetupawebsitecontainingourdenoisedresultsandTOCH‚Äôsresults
on18noisytrajectoriesinarandomlypermutatedorder. Twentypeoplewhoarenotfamiliarwith
thetaskorevenhavenobackgroundinCSareaskedtorateeachclipascorefrom1to5,indicat-
ing their preferences. Specifically, ‚Äú1‚Äù indicates a significant difference between the hand motion
demonstrated in the video and the human behavior, with obvious physical unrealistic phenomena
suchaspenetrationsandmotioninconsistency;‚Äú3‚Äùrepresentsthedemonstratedmotionisplausible
andsimilartothehumanbehavior,butstillsufferfromphysicalartifacts;‚Äú5‚Äùmeansahigh-quality
motionwhichisplausiblewithnoflawsandishuman-like. ‚Äú2‚Äùmeansthequalityisbetterthan‚Äú1‚Äù
butworsethan‚Äú3‚Äù. Similarly,‚Äú4‚Äùmeanstheresultisbetterthan‚Äú3‚Äùbutworsethan‚Äú5‚Äù.
Foreachclip,wecalculatetheaveragescoreachievedbyourmethodandTOCH.Theaverageand
medium scores across all clips are summarized in Table 7. Ours is much better than the baseline
model.
29
1
elpmaS
2
elpmaS
3
elpmaSPublishedasaconferencepaperatICLR2024
40 Real Estimation
n ~ Normal(0, 0.5)
n ~ Beta(8, 2) * 0.3
30
20
10
0
10
20 10 0 10 20 30 40 50
Figure21: Visualizationonthedifferencesbetweenthemanoposeparametersofhandtrajectories
estimated from videos and the GT values, the difference between the mano pose parameters with
artificial Gaussian noise (Œ∏ÀÜn) and the GT values, and the differences between the parameters with
artificialnoisedrawnfromtheBetadistribution(Œ∏ÀÜb). Theanalysisisconductedon256trajectories.
Foreachtrajectory,thedifferencevectorsacrossallframesareconcatenatedtogetherandflattened
toasinglevector.
Table7: Userstudy.
GeneOHDiffusion TOCH
AverageScore 3.96 1.98
MediumScore 4.00 1.55
C EXPERIMENTAL DETAILS
C.1 DATASETS
GRABtrainingset. Thisisthetrainingsetusedinallexperimentspresentedinthemaintext. We
followthecross-objectsplittingstrategyusedin(Zhouetal.,2022)tosplittheGRAB(Taherietal.,
2020)dataset. Thetrainingsplit,containing1308manipulationsequences,isusedtoconstructthe
trainingdataset. Wealsofilteroutframeswherethehandwristismorethan15cmawayfromthe
object. Foreachtrainingsequence,wesliceitintoclipswith60framestoconstructthetrainingset.
Sequenceswithalengthoflessthan60arenotincludedfortrainingortesting. Formodelswhere
noisysequencesarerequiredduringtraining,wecreatethenoisysequencefromthecleansequence
byaddingGaussiannoisetotheMANOparameters. Specifically,theGaussiannoiseisaddedtothe
handMANOtranslation, rotation, andposeparameters, withstandarddeviationsof0.01, 0.1, and
0.5,respectively.
ARCTIC training dataset. It is the training set of all models in the experiments where we wish
to generalize the model trained on ARCTIC to other datasets. Based on the publicly available
sequencesfromthesubjectwiththeindex‚Äús01‚Äù, ‚Äús02‚Äù, ‚Äús04‚Äù, ‚Äús05‚Äù, ‚Äús06‚Äù, ‚Äús07‚Äù, ‚Äús08‚Äù, ‚Äús09‚Äù,
‚Äús10‚Äù,wetakethemanipulationsequencesfrom‚Äús01‚Äùforevaluationandthoseofothersubjectsfor
training. Foreachsequence,wesliceitintosmallclipswithawindowsizeequalto60andthestep
sizesetto60. Wefilteroutclipswherethemaximumdistancefromthewristtothenearestobject
pointislargerthan15cm. Thenumberofalltrainingclipsis2524. Onlytherighthandtrajectoryis
usedfortraining.
The following text contains more details about the four distinct test sets for evaluation, namely
GRAB,GRAB(Beta),HOI4D,andARCTIC.
GRAB (Taheri et al., 2020). The test split of the GRAB dataset, containing 246 manipulation se-
quences,isusedtoconstructthetestset.Foreachtestsequence,wesliceitintoclipswith60frames
usingthestepsize30. Foreachtestsequence,thenoisysequenceisalsocreatedbyaddingGaus-
30PublishedasaconferencepaperatICLR2024
siannoisetotheMANOparameters. TheGaussiannoiseisaddedtothehandMANOtranslation,
rotation,andposeparameters,withstandarddeviationsof0.01,0.1,and0.5,respectively.
GRAB (Beta). The GRAB (Beta) test set is constructed from manipulation sequences from the
GRAB test split. For each sequence, the noisy sequence is created by adding noise from the Beta
distribution(B(8,2))totheMANOparameters. Specifically, werandomlysamplenoisefromthe
Betadistribution(B(8,2)).Thenthesamplednoisewasby0.01,0.05,0.3togetnoisevectorsadded
tothetranslation,rotation,andhandposeparametersrespectively.
HOI4D(Liuetal.,2022). FortheHOI4Ddataset,weselectinteractionsequenceswithhumansma-
nipulatingobjectsfrom3articulatedcategories,includingLaptop,Scissors,andPliers,and6rigid
datasets, namely Chair, Bottle, Bowl, Kettle, Mug, and ToyCar, for test. The number of instances
includedineachcategoryisdetailedinTable3. Foreachsequence, wespecifythestartingframe
andtaketheclipwiththelengthof60framesstartingfromitasthetestclip. Thestartingframeset
foreachcategoryislistedinTable3.
ARCTIC (Fan et al., 2023). The ARCTIC test set for evaluation takes the right hand only since
we observe that dexterous manipulation such as articulated manipulations is always conducted by
the right hand. For instance, as shown in the example in Figure 4, the left hand holds the capsule
machinewithnocontactchangeduringthemanipulationwhiletherighthandfirsttouchesthelid,
thentouchesthebase,andthenopensandclosethelid.However,wecanrefinethelefthandmotions
as well, as demonstrated in the second sequence of the ‚Äúrefining estimation from video‚Äù example
showninFigure1.Themanipulationsequencesfrom‚Äús01‚Äù,34intotal,aretakenforevaluation.For
eachtestsequence,thequantitativeresultsareevaluatedfromclipswiththewindowsize60sliced
fromeachsequenceusingthestepsize30.Thefilteringstrategysimilartothatusedforconstructing
the training dataset is applied to the test clips as well. The default length of the clips used in the
qualitative evaluation is 90, which is the composed result of two adjacent clips with a window
size of 60. The noisy sequence is obtained by adding Gaussian noise to the right hand MANO
parameters. Specifically,theGaussiannoiseisaddedtothehandMANOtranslation,rotation,and
poseparameters,withstandarddeviationsof0.01,0.05,and0.3,respectively.
Since the ARCTIC‚Äôs object template meshes do not provide vertex normals, which are demanded
bothinourmethodandsomebaselinemodels,weusethe‚Äúcompute vertex normals‚Äùfunctionim-
plementedinOpen3D(Zhouetal.,2018)forcomputingthevertexnormals.
C.2 METRICS
We include two sets of evaluation metrics. The first set follows the evaluation protocol of previ-
ous works (Zhou et al., 2022) and focuses on assessing the model‚Äôs capability to recover the GT
trajectoriesfromnoisyobservations,asdetailedinthefollowing.
Mean Per-Joint Position Error (MPJPE). It calculates the average Euclidean distance between
thedenoised3Dhandjointsandthecorrespondingground-truthjoints.
MeanPer-VertexPositionError(MPVPE).ItmeasurestheaverageEuclideandistancebetween
thedenoised3Dhandverticesandthecorrespondingground-truthvertices.
ContactIoU(C-IoU).Thismetricassessesthesimilaritybetweentherefinedcontactmapandthe
ground-truth contact map. The binary contact maps are obtained by thresholding the correspon-
dencedistancewithin¬±2mm. Forourmethod,whichdoesnotrelyoncorrespondencesintroduced
in(Zhouetal.,2022),weutilizethecomputingprocessprovidedby(Zhouetal.,2022)tocompute
thecorrespondences.
To measure whether the denoised trajectory exhibits natural hand-object spatial relations and con-
sistenthand-objectmotions,weintroducethesecondsetofevaluationmetrics.
SolidIntersectionVolume(IV).Weevaluatethismetricfollowing(Zhouetal.,2022). Itquantifies
hand-objectinter-penetrations. Byvoxelizingthehandmeshandtheobjectmesh,wecalculatethe
volumeoftheirintersectedregionastheintersectionvolume.
Per-VertexMaximumPenetrationDepth(PenetrationDepth). Foreachframe,wecalculatethe
maximumpenetrationdepthofeachhandvertexintotheobject.Wethenaveragethesevaluesacross
allframestoobtaintheper-vertexmaximumpenetrationdepth.
31PublishedasaconferencepaperatICLR2024
ProximityError. Themetricisonlyevaluatedondatasetswithground-truthreferences,including
GRAB,GRAB(Beta), andARCTIC.Foreachvertexofthedenoisedhandmesh, wecomputethe
difference between its minimum distance to the object points and the corresponding ground-truth
vertex‚Äôsminimumdistancetotheobjectpoints. Theproximityerrorisobtainedbyaveragingthese
differencesoverallvertices. Theoverallmetricisobtainedbyaveragingtheper-framemetricover
all frames. Specifically, let dh denote the minimum distance from the hand keypoint h at
k,min k
the frame k to objects points. Formally, it is defined as dh = min{dho = ‚à•h ‚àío ‚à• |h ‚àà
k,min k k k 2 k
J ,o ‚ààP
}.LetdhÀÜ
representsthequantityofthekeypointhfromthedenoisedtrajectory,and
k k k k,min
dh representsthequantityofthekeypointhfromtheground-truthtrajectory. Thentheoverall
k,min
metriciscalculatedasProximityerror=mean{{‚à•dhÀÜ ‚àídh ‚à• |h ‚ààJ }|1‚â§k ‚â§K}.
k,min k,min 2 k k
Hand-Object Motion Consistency (HO Motion Consistency). This metric assesses the consis-
tency between the hand and object motions. For each frame where the object is not static, we
identifythenearesthand-objectpointpair(h ,o ) = argmin{dho|(h ‚àà J ,o ‚àà P )}. Weuse
k k k k k k k
the expression ‚à•e‚àí100‚à•hk‚àíok‚à•2‚àÜh
k
‚àí‚àÜo k‚à•2
2
to quantify the level of inconsistency between the
hand and object motions. Here, ‚àÜh and ‚àÜo represent the displacements of the hand point and
k k
the object point between adjacent frames, respectively. We obtain the overall metric by averaging
themetricoverallframes.
C.3 BASELINES
Wegiveamoredetailedexplanationofthecomparedbaselinesasfollowstocomplementthebrief
introductioninthemaintext.
TOCH. We compare our model with the prior art on the HOI denoising problem, TOCH (Zhou
et al., 2022). TOCH utilizes an autoencoder structure and learns to map noisy trajectories to their
correspondingcleantrajectories.Byprojectinginputnoisytrajectoriesontothecleandatamanifold,
itcanaccomplishthedenoisingtask.Weutilizetheofficialcodeprovidedbytheauthorsfortraining
andevaluation.
TOCH(w/MixStyle). Further,toimproveTOCH‚Äôsgeneralizationabilitytowardsnewinteractions,
weaugmentitwithageneraldomaingeneralizationmethodMixStyle(Zhouetal.,2021a),resulting
inavariantnamed‚ÄúTOCH(w/MixStyle)‚Äù.
TOCH(w/Aug.). Anothervariant,‚ÄúTOCH(w/Aug.)‚Äù,whereTOCHistrainedonthetrainingsets
of the GRAB and GRAB (Beta) datasets, is further introduced to enhance its robustness towards
unseennoisepatterns.
C.4 MODELS
Denoisingmodelsusedinourmethod. Werealizethedenoisingmodel‚Äôsfunctionandthetraining
asthoseofthescorefunctionsindiffusion-basedgenerativemodels. Weadapttheimplementation
ofHumanMotionDiffusion(Tevetetal.,2022)toimplementourthreedenoisingmodelsforeach
partoftherepresentation2. Insteadoftrainingthedenoisingfunctiontopredictthestartdatapoint
x fromthenoisydatax asimplementedin(Tevetetal.,2022),wepredictthenoise(x ‚àíx ). We
0 t t 0
alsofollowitsdefaulttrainingprotocol.
We mainly adopt MLPs and Transformers as the basic backbones of the denoising model. The
detailedstructuredependsonthetypeofthecorrespondingstatisticsandthedimensions. Thecode
intheSupplementaryMaterialsprovidesallthosedetails. Sowesparetheefforttolistthemin
detailhere.
Whenleveragingthedenoisingmodeltocleantheinputviathe‚Äúdenoisingviadiffusion‚Äùstrategy,
the diffusion steps is set to 400 for MotionDiff, 200 for SpatialDiff, and 100 for TemporalDiff
empirically.
Ours (w/o Diffusion). In this ablated version, we design a denoising autoencoder for cleaning
the spatial and temporal representations. For each representation J¬Ø,S,T, we leverage an autoen-
coder for denoising. After that, we get the final hand meshes by fitting the MANO parameters
2https://guytevet.github.io/mdm-page
32PublishedasaconferencepaperatICLR2024
{r ,t ,Œ≤ ,Œ∏ } to reconstruct the denoised representations. Assuming the reconstructed hand tra-
k k k k
jectoryasJrecon,thereconstructedhand-objectspatialrelativepositionsasSrecon,andthetempo-
ralrepresentationsasTrecon,thereconstructionlossisformulatedasfollows:
Lrep =Œª ‚à•J ‚àíJrecon‚à• +Œª ‚à•S‚àíSrecon‚à•+Œª ‚à•T ‚àíTrecon‚à•, (14)
recon 1 2 2 3
where Œª ,Œª ,Œª are coefficients for the reconstruction losses. We set Œª ,Œª ,Œª = 1. in our ex-
1 2 3 1 2 3
periments. The distance function between the spatial representations is calculated on the relative
positionsbetweeneachpointpair. Thedistancebetweenthetemporalrepresentationsiscalculated
on hand-object distances, i.e., {dho}, and two relative velocity-related statistics ( {eho,eho } ).
k k,‚à• k,‚ä•
Togetherwiththeregularizationloss
K K‚àí1
1 (cid:88) 1 (cid:88)
L = (‚à•Œ≤ ‚à• +‚à•Œ∏ ‚à• )+ ‚à•Œ∏ ‚àíŒ∏ ‚à• , (15)
reg K k 2 k 2 K‚àí1 k+1 k 2
k=1 k=1
thetotaloptimizationtargetisformulatedasfollows,
minimize (Lrep +L ), (16)
{rk,tk,Œ≤k,Œ∏k}K
k=1
recon reg
andweemployanAdamoptimizertosolvetheproblem.
TOCH (w/ MixStyle). We use the official code provided to implement the MixStyle layer. We
add a MixStyle layer between every two encoder layers of the TOCH model (Zhou et al., 2022).
ConfigurationsofMixStylearekeptthesameasthedefaultsetting.
TOCH (w/ Aug.). The model is trained on paired noisy-clean data pair from the GRAB training
set. We perturb each training sequence with two types of noise, that is the noise from a Gaussian
distribution,andthenoisefromaBetaB(8,2)distribution. ThenoisescalefortheGaussianforthe
translation,rotation,andhandposesare0.01,0.1,and0.5respectively. ThescaleoftheBetanoise
addedonthetranslation,rotation,andhandposesare0.01,0.05,and0.3.
Grasp synthesis network. We adapt the WholeGrasp-VAE network proposed in (Wu et al.,
2022) to a HandGrasp-VAE network3. Instead of using whole-body markers, we use hand anchor
points(Yangetal.,2021),composedof32pointsfromthehandpalmintotal. Toidentifycontact
mapsforbothhandanchorsandobjectpoints,wesetadistancethreshold,i.e.,2mm,andmarkthe
statusofpointswiththeminimumdistancetothehand/objectascontact. Duringtraining,wedonot
addthegroundcontactlosssincethewholebodyisnotconsideredinourhand-graspingsetting. To
trainthenetwork,wefurthersplittheGRABtestsetintoasubsetcontainingbinoculars,wineglass,
fryingpan,andmugfortraining. Thenweusethenetworktosynthesizegraspsforunseenobjects.
Weselect100graspsforeachobjecttoconstructthetrainingdataset.
Manipulationsynthesisnetwork. WeutilizethedenoisedmanipulationtrajectoriesfortheLaptop
categorytotrainthemanipulationsynthesisnetwork.Thetrainingdataconsistsof100manipulation
sequences.
C.5 TRAININGANDEVALUATION
ThedenoisingmodelforJ¬Ø.ThedenoisingmodelforthecanonicalizedhandtrajectoryJ¬Øistrained
on canonicalized hand trajectories {J¬Ø} of all interaction sequences in the training set. We apply
per-instance normalization operation to those points at each frame for centralization and scaling
purposes. Specifically, we utilize the mean and the standard deviation statistics calculated for all
pointsacrossallframes. Inmoredetail, wefirstconcatenateallkeypointsoverallframestoform
theconcatenatedkeypointsJconcat:
J¬Ø =Concat{J¬Ø ,dim=0}K , (17)
concat k k=1
whereJ¬Ø
k
‚ààRNh√ó3 foreachframek. Then,theaverageandthestandarddeviationiscalculatedon
J¬Øconcatvia
¬µJ¬Ø =Average(J¬Ø ,dim=0) (18)
concat
œÉJ¬Ø =Std(J¬Ø ,dim=0). (19)
concat
3https://github.com/JiahaoPlus/SAGA
33PublishedasaconferencepaperatICLR2024
The(¬µJ¬Ø,œÉJ¬Ø)areutilizedtonormalizeJ¬Ø ateachframek,i.e.,
k
J¬Ø ‚àí¬µJ¬Ø
J¬Ø ‚Üê k . (20)
k œÉJ¬Ø
The denoising model for S. Similarly, the denoising model for hand-object spatial relations S
is trained using representations {S} from all interaction sequences in the training set. We apply
per-instancenormalizationtothecanonicalizedhand-objectrelativepositions{(h ‚àío )RT}. The
k k k
normalization is conducted in a per-instance per-object point way. For each object point o in the
generalizedcontactpointsP,wecalculatetheaverageandstandarddeviationof{{h ‚àío }}over
k k
allframesk. Wefirstconcatenatetherelativepositionsoverallframesandallhandkeypointsfor
theconcatenatedspatialrelations,denotedas
so =Concat{{h ‚àío },dim=0}K . (21)
concat k k k=1
Then,theaverageandthestandarddeviationiscalculatedonso via
concat
¬µo =Average(so ,dim=0) (22)
concat
œÉo =Std(so ,dim=0). (23)
concat
Suchstatistics(¬µo,œÉo)areutilizedtonormalizetherelativepositions{{h ‚àío }},i.e.,
k k
(h ‚àío )‚àí¬µo
(h ‚àío )‚Üê k k . (24)
k k œÉo
The denoising model for T. When training the denoising model for the hand-object temporal
relations T, we first train an autoencoder, composed of an encode(¬∑) function and a decode(¬∑)
function for T. It takes the T as input and decode the hand-object distances {dho} and the
k
relative velocity-related quantities {eho ,eho}. Then, the denoising model is trained on the en-
k,‚ä• k,‚à•
coded latent {encode(T)}. This approach avoids the need for designing normalization strate-
gies for the temporal representations. We adopt a PointNet structure block with a positional en-
coder followed by a transformer encoder module for encoding the temporal relation representa-
tions. Given the input temporal representation TÀÜ ‚àà RK√óNo√ó69, the PointNet encoder block
passes it through four PointNet blocks each with three encoding layers with latent dimension
(32,32,32),(64,64,64),(128,128,128),(256,256,256) respectively. The transformer encoder
moduleiswithparameters‚Äúnum heads‚Äùas4,feedforwardlatentdimensionas1024,dropoutrate0,
andthelatentdimension256. Thedecodercontainsfullyconnectedlayersfordecodingeachkind
ofstatisticsdho,eho ,eho individually.
k ‚ä•,k ‚à•,k
Train-time rotation augmentation. For the canonicalized hand trajectory representation J¬Ø, the
train-timerandomrotationaugmentationappliesasinglerandomrotationmatrixtothewholecanon-
icalizedhandtrajectories. Thesamerandomrotationmatrix,denotedasR ,isaddedtothehand-
rnd
object spatial representation S as well. It is used to transform the canonicalized object position,
normal,andthehand-objectoffsetvector:
soR =((o ‚àít )RTR ,n RTR ,{(h ‚àío )RTR |h ‚ààJ }). (25)
k rnd k k k rnd k k rnd k k k rnd k k
Similarly,thesamerandomrotationmatrixR isusedtotransformtheobjectvelocityvectorfrom
rnd
vointhetemporalrepresentationT tovoR .
k k rnd
C.6 COMPLEXITYANDRUNNINGTIMEDISCUSSION
Denote the number of hand keypoints as |J|, the number of generalized contact points |P|, the
complexity,theaverageinferencetime,andthenumberofforwarddiffusionstepsforeachdenoising
stageduringinferencearesummarizedinTable8.
34PublishedasaconferencepaperatICLR2024
Table8: Complexityandrunningtimeduringtheinferencetime.
MotionDiff SpatialDiff TemporalDiff
Averageinferencetime(s) 0.52 16.61 7.04
Complexity O(|J|) O(|P||J|) O(|P||J|)
#Forworddiffusionsteps 400 200 100
35