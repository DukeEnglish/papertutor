Hyp-OC: Hyperbolic One Class Classification for Face Anti-Spoofing
Kartik Narayan and Vishal M. Patel
{knaraya4, vpatel36}@jhu.edu
Johns Hopkins University
https://kartik-3004.github.io/hyp-oc/
Abstractâ€”Face recognition technology has become an inte-
gral part of modern security systems and user authentication
processes. However, these systems are vulnerable to spoofing
attacksandcaneasilybecircumvented.Mostpriorresearchin
face anti-spoofing (FAS) approaches it as a two-class classifica-
tiontaskwheremodelsaretrainedonrealsamplesandknown
spoofattacksandtestedfordetectionperformanceonunknown
spoof attacks. However, in practice, FAS should be treated as
aone-classclassificationtaskwhere,whiletraining,onecannot
assume any knowledge regarding the spoof samples a priori.
In this paper, we reformulate the face anti-spoofing task from
a one-class perspective and propose a novel hyperbolic one-
class classification framework. To train our network, we use a
pseudo-negative class sampled from the Gaussian distribution
with a weighted running mean and propose two novel loss
functions: (1) Hyp-PC: Hyperbolic Pairwise Confusion loss,
and(2)Hyp-CE:HyperbolicCrossEntropyloss,whichoperate
in the hyperbolic space. Additionally, we employ Euclidean
feature clipping and gradient clipping to stabilize the training
in the hyperbolic space. To the best of our knowledge, this is
the first work extending hyperbolic embeddings for face anti-
spoofing in a one-class manner. With extensive experiments
onfivebenchmarkdatasets:Rose-Youtu,MSU-MFSD,CASIA-
MFSD,IdiapReplay-Attack,andOULU-NPU,wedemonstrate
EUCLIDEAN SPACE HYPERBOLIC SPACE
that our method significantly outperforms the state-of-the-art,
achieving better spoof detection performance.
I. INTRODUCTION
Fig.1. FeaturerepresentationofrealandspoofsamplesintheEuclidean
We are in an era where facial recognition is extensively and the hyperbolic space. The representation of real samples in the hy-
perbolic space is compact (dotted circle), resulting in a better separating
utilized for authentication and access control. It is used
gyroplane contrary to the Euclidean space in which the representation
in diverse sectors, including mobile device security, finan- is scattered. Hyperbolic embeddings prove to be effective in one-class
cial services, border control, fraud prevention, e-commerce, classificationforfaceanti-spoofing.
healthcare,etc.However,suchwidespreadadoptionoffacial
recognition technology has made it vulnerable to spoofing
attacks. Malicious actors attempt to deceive the system by all mobile devices and is easily accessible. Itâ€™s not only
spoofing the identity of an individual using presentation affordable but also straightforward to integrate at various
attack instruments (PAI). They employ various attacks, such security checkpoints.
as printed photos, replayed videos, or 3D synthetic masks, WhyOneClass?TheFASproblemhasbeenapproached
that jeopardize security and endanger face as a biometric indifferentwaysintheliterature.Binaryclassifiers[5],[31],
modality. Hence, it is crucial to develop robust face anti- [70], [81], [19]associate samples with realand spoof labels.
spoofing (FAS) techniques that can counter this threat. DomainAdaptationmethods[35],[71],[73],[57],[85],[86]
Why Unimodal FAS ? With the advent of sophisticated utilize target domain data to bridge the gap between source
hardware, there was an influx of multimodal FAS tech- and target domains. Domain Generalization techniques [62],
niques [84], [53], [63], [42], [33], [38], [13] that incorporate [72], [28], [41], [65], [66] focus on minimizing the distri-
auxiliarydatalikedepthmap[79],[43],reflectionmap[82], bution discrepancies between multiple source domains that
infraredimages[83],r-PPGsignals[24],[40],andadditional generalize better to unseen domains. However, all these
sensors [61] to boost the performance. However, relying on formulations assume some kind of prior knowledge of spoof
suchadvancedhardwareandsensorsisproblematicastheyâ€™re samples while training. In the real world face anti-spoofing
expensive and not universally available where FAS systems scenario, spoof samples are infinitely variable, which makes
are deployed. In this work, we focus on unimodal FAS, the task of FAS inherently complex. The variations in spoof
which uses the widespread RGB camera found in nearly attacksareboundless.Whetheryouconsiderwebcam,masks,
4202
rpA
22
]VC.sc[
1v60441.4042:viXra
LAER
FOOPSprint,surveillancecamera,orphone-basedattacks,malicious [27],headmovements[74],[6],gazetracking[1],andremote
actorsexploitvariationsinfactorslike-light,camerasensor, physiological signals [80]. Classical handcrafted features
printer,paper,andmasktofoolthefacialrecognitionsystem. such as LBP [8], SIFT [54], and HOG [32] were leveraged
The vast spectrum of possibilities highlights the need to to extract spoofing patterns. Subsequently, deep learning-
address face anti-spoofing as an anomaly detection or one- based models [3], [77], [5] are utilized to detect spoofs.
class classification problem where one only have access to The majority of these methods approach it as a binary
therealsamples,asitfocusesonidentifyinggenuinesamples classification problem. However, in practice, FAS should
while remaining resilient to the ever-expanding range of be considered a one-class classification (OCC) task. [2]
spoofing techniques. Some recent works [2], [16], [49], [7], showed that two-class methods can be biased towards spoof
in agreement with our approach, have formulated FAS as samples in the training set. Following that, several works
a one-class classification task, demonstrating its complexity were proposed for one-class face anti-spoofing (OC-FAS)
and practical relevance for real-world applications. even though the performance was not competitive compared
Why Hyperbolic ? Recently, hyperbolic embeddings are to binary FAS. An observation is the utilization of classical
adopted for vision tasks such as image segmentation [4], one-class classifiers such as OC-SVM, OC-GMM, and MD
instance segmentation [76], few-shot classification [18] and forfinalclassification.[49]usesIQMfeatureswithone-class
image retrieval [14]. [48], [30] established that hyperbolic GMM for detecting spoofs. [15] shows identity information
embeddings can outperform the Euclidean embeddings sig- can be used to improve OC-FAS performance. [16] uses an
nificantly on data with latent hierarchies, both in terms ensemble of one-class classifiers. [56] uses metric learning,
of representation capacity and generalization ability. In the where a triplet focal loss is used as a regularizer. [44] pro-
FAS scenario, the real and spoof classes have subtle visual posed a Deep Tree Network (DTN) for zero-shot FAS. [20]
differences and lie close to each other in the feature space. usescenterlossforacompactrepresentationofthebonafide
Therefore, it is challenging to fit a hyperplane for one-class class while being away from the embeddings of the attacked
classification,especiallyintheabsenceofaspoofclasswhile class.[7]samplespseudo-negativesamplesfromGaussianto
training. Hyperbolic space with a negative curvature allows train the OC-FAS classifier. [20] introduces a multi-channel
forthelearningofdiscriminativefeaturesowingtothenature neural network for learning one-class representations. De-
of exponential growth in volume with respect to its radius. spitetheseefforts,theperformanceofOC-FASmethodsstill
Consequently, hyperbolic space aids in learning a separating lags significantly behind that of binary FAS approaches.
gyroplane (Section III-A) for effective one-class FAS (See
Figure 1). B. Hyperbolic Embeddings
Inthiswork,weextendtheuseofhyperbolicembeddings
Hyperbolic spaces have gained much attention for their
for face anti-spoofing. We formulate the FAS problem as a
representation capability in a wide range of domains [34],
one-class classification due to its practicality for real-world
[59], [78]. It benefits vision applications [10], [39], [45] be-
deployment and propose two novel loss functions to train
causenaturalimagesoftenexhibithierarchicalstructure[30],
our network. The following are the main contributions of
[46]. [17] proposed several models in the hyperbolic space,
our research:
such as Hyperbolic Neural Networks, Multinomial Logis-
â€¢ We propose using hyperbolic embeddings for one-class tic Regression, Fully-Connected and Recurrent Neural Net-
faceanti-spoofing.Weshowthatusinghyperbolicspace work. [64] introduces hyperbolic convolutional layers. [22]
helps learn a better decision boundary than the Eu- performs Euclidean feature clipping to solve the vanishing
clidean counterpart, boosting the FAS performance. gradientproblemofhyperbolicnetworks.Followingprevious
â€¢ We propose a novel Hyperbolic Pairwise Confusion works [48], [30], we employ the PoincareÂ´ Ball model in
Loss (Hyp-PC) that operates in the hyperbolic space. It which our proposed loss functions operate.
induces confusion within the hyperbolic feature space,
effectively stripping away identity information. Such III. PROPOSEDWORK
disruption of features helps to learn better feature rep-
resentations for the FAS task. Weproposetwonovellossfunctions:(1)Hyp-PC:Hyper-
â€¢ We propose a novel Hyperbolic Cross Entropy loss bolic Pairwise Confusion loss, and (2) Hyp-CE: Hyperbolic
(Hyp-CE). It uses hyperbolic softmax logits and penal- Cross Entropy loss, both of which take advantage of hy-
izes the network for every misclassification. perbolic spaceâ€™s capability to efficiently represent data. We
employ a hyperbolic classifier head (Hyp-OC) that performs
II. RELATEDWORK hyperbolic softmax-regression and use the resulting hyper-
In this section, we give an overview of previous works in bolic logits for one-class face anti-spoofing. An overview
FAS, with a focus on one-class FAS. In addition, we briefly of the proposed framework is depicted in Figure 3. The
review the literature on hyperbolic embeddings. following section is structured as follows. Initially, we lay
out the required foundational concepts of hyperbolic spaces
A. Face Anti-spoofing
inSectionIII-A.WethenexplainHyp-PClossinSectionIII-
Earlier works [36], [12], [32], [54] utilized handcrafted B and Hyp-CE loss in Section III-C. Lastly, we provide
featuresforFAS.Someworksarebasedoneyeblinking[51], a comprehensive overview of the training framework andthe strategies we follow to stabilize hyperbolic training in ğ”¹ "$
Gyroplane
Section III-D. Geodesic distance ğ», â€™" !,)!
Hyperbolic features
A. Preliminaries: Hyperbolic Embeddings
ğ‘
Point on gyroplane &
An d-dimensional hyperbolic space Hd is a smooth Rie- Normal to gyroplane ğ‘ &
mannianmanifoldwithaconstantnegativecurvatureâˆ’c(c> ğ‘’ğ‘¥ğ‘ !"(ğ‘¢) ğ‘‘ "(ğ‘¥,ğ», â€™" !,)!)
0). There are several isometric models in the hyperbolic
space,however,weoperateinthePoincareÂ´ model[48]dueto
its widespread usage in computer vision. The PoincareÂ´ ball ğ‘¢âˆˆğ‘‡ !ğ”¹ "# ğ‘† $%
ğ‘¥
model (Bd,gB c) with manifold Bd ={xâˆˆRd :câˆ¥xâˆ¥<1,câ‰¥
c c
0} depicted in Figure 2 is an d-dimensional ball equipped
with Riemannian metric:
2 Fig.2. VisualizationofthePoincare`BallBd.Si denoteshyperbolicfeatures
where Î»c =
gB x 2c =(Î» isxc) t2 hg eE c= on1 foâˆ’ rmc| a|x l|| f2 aI cd t,
or, gE = I
(1 is) e cx op mo pn ue tn eti Lall Hy ypm âˆ’Pa Cpp ae nd df Lro Hm ypâˆ’T Cx EB .d c H. Ëœ acI ,n
p
ro eu pr rc ew seon nr tk s, thw ee gu ys roe pd lac n(x e, oHËœ fac k c, lp ak s) st ko .
x 1âˆ’câˆ¥xâˆ¥2 d
the Euclidean metric tensor and c is the curvature of the
hyperbolic space. In the Euclidean space, the volume of an all geodesics in Bd orthogonal to a and containing p. Given
c
object with diameter r increases polynomially, however, in K classes and kâˆˆ{1,...,K}, p âˆˆBd, a âˆˆT Bd\{0}, the
k c k pk c
the hyperbolic space, these volumes grow at an exponential hyperbolic distance of x to the gyroplane of class k is given
ratebecauseofÎ» xc whichapproachesinfinitynearthebound- as:
(cid:32) âˆš (cid:33)
ary of the ball. This property allows efficient embedding of 1 2 c|âŸ¨âˆ’p âŠ• x,a âŸ©|
d (x,HËœc )= âˆš sinhâˆ’1 k c k .
data in low dimensions. c ak,pk c (1âˆ’câˆ¥âˆ’p âŠ• xâˆ¥2)âˆ¥a âˆ¥
k c k
Euclidean vector operations are not valid in hyperbolic The logit of class k for hyperbolic feature vector x is based
spaces, and operations from gyrovector spaces are adopted on the distance defined in Equation 6 and calculated using
tooperateinhyperbolicspaces.Someofthebasicoperations the Reimannian metric described in Equation 1 as:
in hyperbolic spaces using the gyrovector formalism [69], Î¶ (x)=Î»c âˆ¥a âˆ¥d (x,HËœc ). (6)
[68] are: As a result, the
lp ik kelihoodpk
is
gk ivec
n
as:ak,pk
MoÂ¨bius Addition. Vector addition of two points u,vâˆˆBd c is p(y=k|x)âˆexp(Î¶ pk(x)). (7)
formulated using MoÂ¨bius addition as, Inourwork,weutilizetheabovelikelihood(i.e.Equation7)
(1+2câŸ¨u,vâŸ©+câˆ¥vâˆ¥2)u+(1âˆ’câˆ¥uâˆ¥2)v
uâŠ• v= (2) as target class classification probability to calculate the
c 1+2câŸ¨u,vâŸ©+c2âˆ¥uâˆ¥2âˆ¥vâˆ¥2
performance metrics. Additionally, we use the hyperbolic-
where, âŸ¨Â·âŸ© denotes the Euclidean inner product. lim âŠ•
câ†’0 c softmax logits (Equation 6) to calculate the Hyp-CE loss
converges to standard + in the Euclidean space.
described in Section III-C. The trainable parameters of
Exponential map. The exponential map expc projects vec-
x hyperbolic classifier head are the vectors {p } and {a } for
k k
tors from Euclidean space into the Poincare` Ball. Euclidean
each class k. We refer to this hyperbolic classifier head as
spacecorrespondstothetangentspaceT Bd ofthemanifold
x c Hyp-OC.
Bd at a reference point x. In our work, we treat the starting
c
point x in the PoincareÂ´ Ball as a parameter and optimize it
using Riemannian gradient [48]. For any point xâˆˆBd, the B. Hyp-PC: Hyperbolic Pairwise Confusion loss
c
exponential map expc:T Bd â†’Bd for u is defined as,
x (cid:18)x c (cid:18)âˆšc (cid:19) (cid:19) Inourproposedmethod,weperformoneclasstraining,in
câˆ¥uâˆ¥ u
expc(u)=xâŠ• tanh âˆš (3) which each iteration consists of n positive samples âˆ‹2|n.
x c 2 câˆ¥uâˆ¥ Let S ={Si |0â‰¤i<n} be the set of hyperbolic feature
Aslim expc(u)=x+u,i.e.theexponentialmapconverges n n
câ†’0 x vectors of the positive samples. Using the geodesic distance
to standard translation operation in Euclidean space.
formulation given in Equation 4, we introduce a novel loss
Distance Measure. The distance between two vectors u,vâˆˆ
function: Hyp-PC which is defined as:
Bd in the PoincareÂ´ Ball is the length of the geodesic con-
nec
cting the two vectors, which is the shortest curve between L
=n/ âˆ‘2âˆ’1 âˆš2 arctanh(cid:0)âˆš
câˆ¥âˆ’Si âŠ• Si+n/2
âˆ¥(cid:1)(cid:46)
n. (8)
those points in (Bd c,gB c) and is defined as: Hyp-PC i=0 c n c n
2 (cid:0)âˆš (cid:1) Here, âˆ¥âˆ¥ represents the Euclidean norm, âŠ• c is calculated
D hyp(u,v)= âˆš carctanh câˆ¥âˆ’uâŠ• cvâˆ¥ (4) using Equation 2, and S ni are hyperbolic feature vectors
When c â†’ 0, geodesics becomes straight-lines recovering exponentially mapped from T Bd to Bd using Equation 3.
x c c
Euclidean geometry: lim D (u,v)=2âˆ¥uâˆ’vâˆ¥. The Hyp-PC loss is utilized to refine the features of posi-
câ†’0 hyp
Hyperbolic Softmax. For pâˆˆBd, aâˆˆT Bd\{0}, Ganea et tive samples by removing identity-related information. This
c p c
al. [17] describes the gyroplane, i.e. the hyperplane in the process declusters the positive class feature representation,
PoincareÂ´ Ball, as: enhancing the modelâ€™s ability to generalize. Such an ap-
HËœc :={xâˆˆBd: âŸ¨âˆ’pâŠ• x,aâŸ©=0}, (5) proach is particularly beneficial for the FAS task, where the
a,p c c
where x is a hyperbolic feature vector mapped using Equa- focusissolelyonspoofdetectionratherthanrecognizingthe
tion 3. HËœc can be interpreted as the union of images of individual identities.
a,pâ„’
#$%&â€™(
ğ‘’ğ‘¥ğ‘"(%)
!
ğ¸ !(ğ‘¥) ğ¸ "(ğ‘¥) ğ»(ğ‘¥) â„’
#$%&()
ğ¸ (ğ‘¥): VGG-16 ğ»(ğ‘¥): PoincarÃ¨Ball
,
ğ¸ -(ğ‘¥): FCNN : Hyperbolic SoftmaxLogits
: Mean â„’ %&â€™()*: Hyperbolic Pairwise Confusion Loss
ğœ‡âˆ— : Concat â„’ : Hyperbolic Cross-Entropy Loss
%&â€™(*+
ğ’©(ğœ‡âˆ—,ğœğ¼) ğ‘’ğ‘¥ğ‘ "# + : Exponential map to ğ”¹ #$ : Pseudo-negative Sampling
: Feature Extraction : Dimensionality Reduction
: Mean Estimation : Hyperbolic Classifier Head
Fig.3. OverviewoftheproposedpipelineHyp-OC(SectionIII-D).E 1(x)extractsthefacialfeatures.Thefacialfeaturesareusedtoestimatethemean
of Gaussian distribution utilized to sample pseudo-negative points. The real features and pseudo-negative features are then concatenated and passed to
E 2(x)fordimensionalityreduction.Thelow-dimensionfeaturesaremappedtoPoincareÂ´ Ballusingexponentialmap.Thetrainingobjectiveistominimize
thesummationoftheproposedlossfunctionsL Hypâˆ’PC (SectionIII-B)andL Hypâˆ’CE (SectionIII-C).Theresultisaseparatinggyroplanebeneficialfor
one-classfaceanti-spoofing.[Bestviewedincolor]
C. Hyp-CE: Hyperbolic Cross Entropy loss reduction. The hyperbolic classifier head outputs the final
target class classification probability explained comprehen-
We propose a novel Hyp-CE â€“ Hyperbolic Cross Entropy
sively in Section III-A. In each batch, given a set of n
loss based on logits from the hyperbolic space calculated
training images X ={Xi |0â‰¤i<n}, we employ E (x) to
using Equation 6. Given K classes and kâˆˆ{1,...,K}, p âˆˆ n n 1
Bd, a âˆˆT Bd\{0}, let the mini-batch size be 2n, thek set produce a set of dâ€²-dimensional feature set F n ={F ni |0â‰¤
c k pk c i<n,dim(Fi)=dâ€²}. Inspired from the work of Baweja et
of hyperbolic features obtained after the exponential map n
(Equation3)beS ={Si |0â‰¤i<2n},thetargetlabelsfor al. [7], we define a Gaussian distribution N (Âµ,ÏƒI) with
themini-batchbe2 Yn ={2 Yn i |0â‰¤i<2n,dim(Yi )=K}and a dâ€²-dimensional adaptive mean to sample pseudo-negative
the weightage of ea2 cn h sam2 pn le in the mini-batc2 hn be W = features in proximity of the real samplesâ€™ features. In each
2n
{Wi |0â‰¤i<2n}, the Hyp-CE loss for the minibatch is iteration, we sample n pseudo-negative features from the
2n distributionwithmeanÂµ=Î±Âµ +(1âˆ’Î±)Âµ ,where
defined as: previous current
L
Hyp-CE=2 âˆ‘nâˆ’1 âˆ‘K
âˆ’W 2i nlog
Kexp(Î¶ pk(S 2i n))
Â·Y 2i n. (9)
bÂµ ap tre cv hio ,us
Âµ
cis urrt eh ne
t
m ise ta hn eo mfr ee aa nls oa fm rp el ae lsâ€™ saf mea ptu ler se â€™s fo ef at th ue rep sre ov fio thu es
i=0 k=1 âˆ‘ exp(Î¶ pk(S 2i n)) currentbatchandÎ± isahyper-parameter.Weconcatenatethe
k=1 realsamplesâ€™featuresandpseudo-negativefeaturesandfeed
In our work, we have two classes and give equal weightage
to all samples. The predicted probability of Si belonging to it to E 2(x) for dimensionality reduction. The concatenated
2n
class k (k=0 for real sample and k=1 for spoof sample) batch of size 2n when given as input to E 2(x) outputs a
low-dimensional representation of features G ={Gi |0â‰¤
can be expressed as: 2n 2n
Usiz nk= g0 E,1 q= uatg i0 og n+k 9g 1 an= dEex qp u( aÎ¶ tip o0 n(e Sx 12ip 0n( ) tÎ¶ ) hp + ek( HeS x2i ypn p() -Î¶) Cp E1(S lo2i sn s)) f. unc( t1 io0 n) uBi s< a il nl2 g(n B, ed d c xi , pm g oB( ncG e) ni 2 wn ti) ait= lh mmd a} a p. n .iG fo L2 ln ed ti Bs thd ct eh =e vn { exm ctâˆˆ oap rR sp de id : nct âˆ¥ to hx eâˆ¥th <e hy1P p,o eci rn bâ‰¥c oa l0r i} ceÂ´
can simply be written as: space be represented as a set S 2n := {S 2i n | 0 â‰¤ i < 2n}.
2nâˆ’1 Finally, S is given as input to H(x) that returns Î¶ (Si ),
L = âˆ‘ y Â·log(z)+(1âˆ’y)(1âˆ’z), (11) 2n pk 2n
Hyp-CE i i i i for k=0,1. These hyperbolic-softmax logits are then used
where, y is the groi u= n0 d truth label and z is the predicted for final prediction.
i i
probability for the spoof class. WeusetheVGG-16pretrainedonVGGFace[52]asE (x)
1
and a neural network with four FC layers as E (x). The last
2
D. Training framework for one-class classification
three convolution layers and the last FC layer of E (x) are
1
Our proposed pipeline uses only real samples for train- updated during the training phase to make the feature repre-
ing and can be viewed as a conjunction of an Euclidean sentations suitable for the FAS task. Additionally, E (x), the
2
network: E(x), and a hyperbolic classifier head: H(x). The startingpointxonthePoincareÂ´Ball(describedinSectionIII-
Euclidean network comprises of two parts: (1) E (x) - A) and {a }, {p } vectors of the hyperbolic classifier head
1 k k
which is a facial feature extractor and (2) E (x) which is are trainable parameters of the proposed pipeline which are
2
a fully-connected neural network used for dimensionality updated when the loss is backpropagated. The proposed lossAlgorithm 1 Training Framework trainingparametersinbothEuclideanandhyperbolicspaces.
1: Input:TrainingdataD={(X n,Y n) i}N i=1,facialfeatureextrac- Althoughtheoptimizationprocessforhyperbolicparameters
torE 1(x),FCNNE 2(x)fordimensionalityreduction,PoincareÂ´ typically requires Riemannian gradients, when working in
Ball (Bd c,gB c) with manifold Bd c ={xâˆˆRd:câˆ¥xâˆ¥<1,câ‰¥0}, the conformal PoincareÂ´ Ball model, Riemannian gradients
hyperbolicclassifierH(x)i.e.HËœ ac ,p:={xâˆˆBd c:âŸ¨âˆ’pâŠ•cx,aâŸ©=
are equivalent to the Euclidean gradients with a scaling
0}for pâˆˆBd c,aâˆˆT pBd c\{0},learningrateÎ³,Adamoptimizer
factor [48]. This allows for the utilization of standard back-
momentum parameters - Î²1&Î²2, hyper-parameter Î± for adap-
propagation techniques in our computations. To stabilize the
tive mean, Euclidean feature clipping function feat clip(,r),
Gradientclippingfunctiongrad clip(,p),Gaussiandistribution training of the hyperbolic one-class classifier we perform
N (Âµ,ÏƒI);Âµ,Ïƒ âˆˆRdâ€² to sample pseudo-negative points, total feature clipping [22] in the Euclidean space that addresses
epochs T =N/nâˆ‹2|n. the issue of vanishing gradients found in the hyperbolic
2: Init: c=0.1, Î± =0.8, Î²1 =0.9, Î²2 =0.999, r=2, p=3,
space.Furthermore,duetotheexponentialnatureofgeodesic
Âµ=0, Ïƒ=1, d=4096, d=128
distances near the edges of the PoincareÂ´ Ball, we perform
3: for t in 0, 1, ..., T do
4: âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’E 1(x)âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’ gradientclippingtoavoidexplodinggradientsandregularize
5: Input Data: Xt n={X ni|0â‰¤i<n}. the parameter updates. The complete training framework is
6: Ft n={F ni|0â‰¤i<n,dim(F ni)=dâ€²}=E 1(Xt n). formalized in Algorithm 1.
7: # Estimating mean of N (Âµ,ÏƒI)
8 9:
:
Âµ Âµc tu =rren Î±t Âµ= tâˆ’âˆ‘ 1n i= +0 (X 1ni âˆ’.
Î±)Âµcurrent.
IV. EXPERIMENTS
10: Pt n: Sample n pseudo-negative points from N (Âµ,ÏƒI). This section, describes the datasets and protocols used to
11: Xt 2n:=Xt nconcatPt n evaluateourproposedpipeline.Wegiveabriefaccountofthe
1 12 3: : âˆ’ Inpâˆ’ uâˆ’ t Dâˆ’ atâˆ’ a:âˆ’ Xâˆ’ t âˆ’ =âˆ’ {âˆ’ XiE 2 |( 0x) â‰¤âˆ’ iâˆ’ <âˆ’ 2nâˆ’ }.âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’ evaluationmetricsandthebaselinemethodsforcomparison.
2n 2n
14: Gt ={Gi |0â‰¤i<2n,dim(Gi )=d} Finally,wedetailtheimplementationstepstakentotrainour
2n 2n 2n
15: =E 2(Xt 2n). proposed model.
16: Gt â†feat clip(f,r)âˆ€f âˆˆGt .
2n 2n
17: # Mapping Gt
2n
to (Bd c,gB c) A. Datasets and Protocols
18: Gt 2n= e= xe p=xp = mc x=t aâ‡’ p St 2n;expc xt :T xtBd c â†’Bd c;xtâˆˆBd c. We evaluate our proposed hyperbolic one-class classifica-
19: âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’H(x)âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’ tionframeworkusingthreedifferentprotocols.Theprotocols
20: Input Data: St ={Si |0â‰¤i<2n}. holistically assess the model for intra-domain and inter-
2n 2n
21: # Calculating hyperbolic-softmax logits domain performance and demonstrate the superiority of the
22: Î¶pk(St 2n)=H(St 2n); k=0,1.
proposed approach. In Protocol 1, we evaluate intra-domain
23: âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’
24: Loss calculation: L =L Hyp-PC+L Hyp-CE. performance where the network is trained and tested on
25: # Trainable parameters the same dataset. We employ widely used FAS datasets:
26: Wt = {Wt ,Wt ,Wt}. ROSE-Youtu R [37], MSU-MFSD (M) [75], CASIA-MFSD
27: Model
upE d1ate:E2 H
(C) [84], Idiap Replay Attack (I) [11], and OULU-NPU
28: for wtâˆˆWt do
(O) [9]. Some sample images of the employed datasets are
29: if wtâˆˆ{Wt ,Wt } then
30: gt=grE a1 d cliE p2 (âˆ‡wtL,r) showninFigure4.InProtocol2,weusetheMCIOdatasets
31: else if wtâˆˆ{Wt} then and follow the leave-one-out setting. In particular, a model
H
32: gt=grad clip(âˆ‡wtL,r)Â·(1âˆ’c 4âˆ¥xtâˆ¥)2 is trained on multiple source domains and tested on a single
33: end if target domain. For instance, MCI â†’ O represents that the
34: mt=Î²1Â·mtâˆ’1+(1âˆ’Î²1)Â·gt model is trained on M,C and I and tested on O. In Protocol
35:
vt=Î²2Â·vtâˆ’1+(1âˆ’Î²2)Â·gt2
3,weagainuseM,C,I,andOdatasetsandfollowasingle-
36: mË†t=mt/(1âˆ’Î² 1t) source-single-target setting. In particular, a model is trained
37: vË†t=vt/(1âˆ’Î²t)
2 using a single source domain and tested on a single target
38: wt+1=wtâˆ’Î³Â· âˆšmË†t
( vË†t+Îµ) domain different from the source domain. Protocols 2 and
39: end for
3 evaluate the inter-domain performance of the model in
40: end for
two different settings. We only focus on single-modal FAS
blue: comments
datasets for all experiments, as discussed in Section I.
orange: euclidean parameter updates
red: hyperbolic parameter updates
B. Performance Metrics and Baseline Methods
We evaluate the model performance using the standard
functionsoperateusingthehyperbolicfeatures.TheHyp-PC metrics for FAS: Attack Presentation Classification Error
loss uses S and Hyp-CE loss uses Î¶ (Si ) as described Rate (APCER), Bonafide Presentation Classification Error
n pk=0,1 2n
in Equation 8 and Equation 9, respectively. The overall loss Rate(BPCER),HalfTotalErrorRate(HTER),andAreaun-
function used to train the pipeline is a combination of the dertheROCcurve(AUC).WerunexperimentsforProtocol-
two losses and is defined as: 1 and Protocol-3 five times and Protocol-2 three times and
L =L +L . (12) reportthemean.Wecompareourmodelwithsevenstate-of-
Hyp-PC Hyp-CE
In our approach, we employ a Euclidean optimizer for the-art one-class classifiers: OC-SVM [60], OC-GMM [26],ROSEYoutu MSU-MFSD CASIA-MFSD IdiapReplay Attack OULU-NPU
Fig. 4. Sample images from the datasets used for training: RoseYoutu [37], MSU-MFSD [75], CASIA-MFSD [84], Idiap Replay Attack [11], OULU-
NPU[9].
SVDD [67], MD [47], OC-CNN [50], Anomaly Detection- hyperplane to calculate the performance metrics. We follow
basedunknownfPAD[7]andDROCC[21].Theseclassifiers the standard sklearn implementation of OC-GMM [26] with
have been previously used for FAS and are the closest to n components=1. We take the log-likelihood of a sample
our proposed work. We re-train all the baselines to make belonging to GMM as the score to calculate performance
the dataset protocol consistent with our work. We employ metrics. We use SVDD implementation of [29], and chose
the same feature extractor as Hyp-OC for all the baseline the kernel â€˜rbfâ€™, C =0.9, and Î³ =0.3. The distance from
models. the center is used to calculate the metrics. For implementing
MD [47], we again follow the standard implementation of
C. Implementation Details the sklearn library, using the distance itself to calculate
metrics.ForOC-CNN[50],AD-fPAD[7],andDROCC[21],
The input to all the models are RGB images, resized and
we follow the official GitHub implementation and use the
center cropped to 224Ã—224Ã—3. We normalize the images
probability of a sample belonging to the spoof class as the
withmean[129.186,104.762,93.593]andstandarddeviation
score to calculate performance metrics.
[1,1,1].WeuseVGG-16pre-trainedonVGGFace[52]asour
featureextractorforallmodels.Weemployafullyconnected V. RESULTSANDANALYSIS
neural network for dimensionality reduction. The FCNN
In this section, we compare our proposed approach with
consistsof3hiddenlayerswith8192,1000,and512neurons,
recentworksthatutilizeone-classclassifiersforFAS.TableI
respectively. The input and output layers have dimensions
reports the intra-domain testing performance for Protocol 1.
4096 and 128, respectively. We perform the exponential
Table III and Table II outline the inter-domain performance
map of Euclidean features to PoincareÂ´ Ball model of the
for Protocol 2 and Protocol 3, in leave-one-out setting
Hyperbolic space of dimension 128. For all the baselines
andsingle-source-single-targetsetting,respectively.Ourpro-
and proposed method, we perform gradient updates on all
posed approach significantly outperforms previous methods.
FCNN and PoincareÂ´ Ball parameters. We only update the
Specifically, we improve upon the best baseline by an Avg.
weights and biases of the last 3 convolution layers and the
HTERof7.493inProtocol-1,4.231inProtocol-2,and2.778
last fully connected layer of the VGG-16 feature extractor
in Protocol-3.
for all the models except DROCC. For DROCC [21], we
update all the parameters of the VGG-16 feature extractor, A. Protocol 1
which gives better results than only updating the last layers
Table I presents the results of Protocol 1, illustrating that
but still falls short compared to the proposed Hyp-OC.
Hyp-OCsignificantlyoutperformspreviousbaselinesinfour
Fortrainingofthemodels,weuseAdamoptimizerwitha out of five datasets. In particular, it shows enhancements of
learning rate of 1e-6, momentum parameters as (0.9,0.999), 7.733 on R, 3.333 on M, 14.518 on C, and 9.506 on I in
andweightdecaysetto1e-6.Weusedifferentbatchsizesand terms of HTER. However, it is the second-best performer
trainingepochsforeachdataset.ForR,M,C,I,O,weusea on O, 4.777 behind the top baseline. Overall, Hyp-OC
batch size of8,8,8,32,32 and trainit for 60,100,100,50,60 demonstrates superior performance across all datasets with
epochs, respectively. We train the models on 8 NVIDIA anAvg.HTERof28.339,markinga7.493increaseuponthe
A5000GPUs,eachwith24GBmemory.Thetrainingstepsof best baseline. The AUC scores of Hyp-OC are 0.713, 0.782,
our proposed approach, as shown in Algorithm 1, highlights 0.784, 0.931, and 0.639 on R, M, C, I, and O, respectively.
that gradients of hyperbolic parameters are scaled versions Theintra-domaintestingresultsestablishHyp-OCasthenew
of Euclidean parameters [48] and are dependent on the state-of-the-art one-class face anti-spoofing model.
curvature of the hyperbolic space.
B. Protocol 2
We re-train all the baselines to make the dataset protocol
consistent for a fair comparison. We use the OneClassSVM Protocol 2 highlights the capability of Hyp-OC to gen-
implementation from the sklearn library [55] with â€˜rbfâ€™ eralize over unseen environments. From Table III, it can be
kernel and Î½ =0.1. We use the signed distance from the inferredthatHyp-OCperformsbetterthanotherbaselinesby
LAER
FOOPSROSEYoutu MSU-MFSD CASIA-MFSD ReplayAttack OULU-NPU Avg.
Method
HTERâ†“ AUCâ†‘ HTERâ†“ AUCâ†‘ HTERâ†“ AUCâ†‘ HTERâ†“ AUCâ†‘ HTERâ†“ AUCâ†‘ HTERâ†“
OC-SVM[60] 56.843 0.415 54.375 0.509 47.778 0.582 59.892 0.401 57.323 0.426 55.242
OC-GMM[26] 62.427 0.302 50.000 0.268 62.593 0.324 60.158 0.054 54.948 0.458 58.025
SVDD[67] 41.807 0.625 36.250 0.705 40.648 0.653 24.633 0.838 35.823 0.682 35.832
MD[47] 51.413 0.474 49.583 0.512 57.963 0.362 47.137 0.576 58.010 0.408 52.822
OC-CNN[50] 46.865 0.538 37.292 0.674 44.722 0.584 34.825 0.716 44.302 0.561 41.601
AD-fPAD[7] 43.157 0.569 30.625 0.733 39.537 0.651 24.217 0.824 41.625 0.605 35.832
DROCC[21] 52.865 0.444 48.542 0.499 48.333 0.499 40.592 0.648 41.906 0.608 46.448
Ours 34.074 0.713 27.292 0.782 25.019 0.784 14.711 0.931 40.600 0.639 28.339
TABLEI
RESULTSOFINTRA-DOMAINPERFORMANCEINPROTOCOL1.WERUNEACHEXPERIMENTFIVETIMESANDREPORTTHEMEANHTERANDAUC.
Method Câ†’I Câ†’M Câ†’O Iâ†’C Iâ†’M Iâ†’O Mâ†’C Mâ†’I Mâ†’O Oâ†’C Oâ†’I Oâ†’M Avg.
OC-SVM[60] 36.033 34.167 41.583 51.667 37.500 43.917 45.648 45.696 55.865 55.093 53.354 45.000 45.460
OC-GMM[26] 50.000 50.625 50.000 53.426 61.667 51.792 50.000 50.000 50.000 50.463 50.888 65.000 52.822
SVDD[67] 35.225 33.958 40.729 41.944 37.500 45.031 44.630 50.013 37.469 45.926 46.967 32.292 40.974
MD[47] 47.246 56.042 58.427 58.148 54.792 58.552 58.426 47.175 56.781 58.611 46.929 54.167 54.608
OC-CNN[50] 49.363 49.375 39.344 48.519 48.750 42.552 49.722 56.067 49.469 47.130 44.767 45.833 47.574
AD-fPAD[7] 50.192 47.917 35.208 40.278 44.792 45.667 48.796 48.408 48.531 50.463 54.017 45.625 46.658
DROCC[21] 47.542 70.000 52.958 41.667 53.750 46.177 47.778 50.483 40.875 45.000 35.129 47.292 48.221
Ours 29.672 35.667 45.217 32.278 36.833 46.254 33.093 35.790 41.229 36.000 51.360 34.958 38.196
TABLEII
RESULTSOFINTER-DOMAINPERFORMANCE(SINGLE-SOURCE-SINGLE-TARGETSETTING)INPROTOCOL3.THEDOMAINSUSEDAREMSU-MFSD
(M),CASIA-MFSD(C),IDIAPREPLAYATTACK(I)ANDOULU-NPU(O).WERUNEACHEXPERIMENTFIVETIMESANDREPORTTHEMEAN
HTER.
Method OCIâ†’M OMIâ†’C OCMâ†’I ICMâ†’O Avg. six out of twelve single-domain-single-target experiments.
OC-SVM[60] 43.333 54.352 52.433 42.167 48.071 For target domain C, a huge improvement in HTER is ob-
OC-GMM[26] 67.083 50.185 50.250 56.083 55.900
SVDD[67] 32.292 43.981 48.250 36.125 40.162 served, with gains of 12.555, 9.000, and 8.000, respectively.
MD[47] 54.167 58.611 47.058 58.500 54.584 WeobservethatSVDD[67]performsbetterthanHyp-OCon
OC-CNN[50] 44.375 49.722 38.471 48.365 45.233
AD-fPAD[7] 36.250 38.025 34.650 44.087 38.253 thetargetdomainM.Also,Hyp-OCdoesnâ€™tperformasgood
DROCC[21] 37.917 42.037 43.250 45.656 42.215 on target domain O, and is exceeded by AD-fPAD [7] on C
Ours 31.875 30.278 30.778 43.156 34.022 â†’O,OC-CNN[50]onIâ†’OandSVDD[67]onMâ†’O.
TABLEIII The overall Avg. HTER of Hyp-OC across all experiments
RESULTSOFINTER-DOMAINPERFORMANCE(LEAVE-ONE-OUT is 38.196, which surpasses all baselines.
SETTING)INPROTOCOL2.THEDOMAINSUSEDAREMSU-MFSD(M),
CASIA-MFSD(C),IDIAPREPLAYATTACK(I)ANDOULU-NPU(O). D. Ablation and Analysis
WERUNEACHEXPERIMENTTHRICEANDREPORTTHEMEANHTER.
In the ablation study, we analyze the influence of each
component of the proposed pipeline on the performance.
a huge margin. Hyp-OC exhibits remarkable proficiency in Furthermore, we discuss the effect of different values for
modeling the real class of different domains irrespective of the Euclidean feature clipping and different curvature values
thediversechangesinenvironmentalfactorssuchaslighting, ofthehyperbolicspaceontheFASperformance.Intheend,
camera angles, and backgrounds of each domain. When we analyze the use of Hyp-OC with other feature extractors.
compared to previous baselines in terms of HTER, Hyp- Proposed One-class classifier for FAS: The effect of
OC achieves better results in three out of the four evaluated different components in the proposed pipeline is shown in
target domains. The performance improvement on OCI â†’ TableIV.Therearetwomajorcomponentsthatstandoutand
M, OMI â†’ C and OCM â†’ I are 0.417, 7.747 and 3.872 impact the performance - Adaptive mean (Table IV row-1)
respectively. Hyp-OC achieves an overall performance gain and Hyp-OC (Table IV row-2). The absence of adaptive
of 4.231 upon the best baseline. mean from the pipeline results in a drop of 14.885 in
HTER. Adaptive mean helps to estimate the mean of the
C. Protocol 3
Gaussiandistributionusedtosamplepseudo-negativepoints.
Table II summarizes the findings for Protocol 3, an inter- In FAS, the spoof samples lie close to the real samples in
domain protocol that assesses a modelâ€™s performance across the feature space. The adaptive mean strategy pushes the
multiple domains while being trained on a single domain. mean of Gaussian distribution towards the cluster of real
This protocol serves to highlight the generalizability of the samples, thus helping to accurately sample pseudo-negative
learned features. Hyp-OC outperforms previous baselines in points. This helps improve the overall performance of theAdaptive Euclidean Avg. Method R M C I O Avg.
Hyp-OC Hyp-PC
mean featureclipping HTER
ResNet50[23] 27.898 31.250 32.222 24.313 52.094 33.555
âœ— âœ“ âœ“ âœ“ 43.224 SeNet50[25] 38.049 35.833 36.019 35.904 43.771 37.915
âœ“ âœ— âœ— âœ— 35.832 CLIPViT[58] 40.756 36.042 32.778 51.979 35.969 39.505
âœ“ âœ— âœ“ âœ“ 32.046 VGGFace[52] 34.074 27.292 25.019 14.711 40.600 28.339
âœ“ âœ“ âœ“ âœ— 30.908
âœ“ âœ“ âœ“ âœ“ 28.339 TABLEV
COMPARISONOFAVG.HTERPERFORMANCEUSINGDIFFERENT
TABLEIV
FEATUREEXTRACTORS.WEREPORTTHERESULTSFORPROTOCOL1.
IMPACTOFVARIOUSCOMPONENTSOFTHEPROPOSEDPIPELINEON
PERFORMANCE.WEREPORTAVG.HTERFORPROTOCOL1.
Euclidean feature clipping [22] to regularize our training
in the hyperbolic space. The clipping value directly relates
39 32.0 31.3 to the effective radius of the PoincareÂ´ Ball. We perform
36.5 31.5
37 31.0 experiments for different clipping values and observe that
2333 9135
27.028.330.0
29.333.5 33.5 32.5 222233 889900 ...... 050505 29.8 29.9
28.5 28.3 28.9
29.4 t
a
[h 2se 2]sp ,he
o
wr wfo hnr icm hia nn sc hFe
oi
wgin
u
si rt ei ta hl
5
aly
t(
ti
r
hn
i
ec gr he eta
) f.
fs ee
T
cs
th
ia vin
s
ed
i
rt
s
ah de
i
in
n
ud sae igc nrr cee rea ems ae ses ens stlo fww roil
t
my h,
27 27.5 0â†’â‰ˆ0.8 when we increase the clipping value from 0â†’1
27.0
25 26.5 and lim effective radius=1. In our work, we
0.01 0.1 0.3 0.5 1 3 5 10 0.5 0.8 0.9 1 2 3 5 clippingvalueâ†’âˆ
Curvature of the PoincarÃ¨Ball Euclidean Feature Clipping Value choose the clipping radius to be 2, which gives the best
performance.
Feature extractor: To support our choice of VGGFace [52]
Fig.5. (Left)HTERperformancew.r.tdifferentcurvaturesofthePoincareÂ´ asafeatureextractor,weperformexperimentswithdifferent
Ball. In our work, we fix the curvature of PoincareÂ´ Ball to 0.1 (orange). feature extractors and compare the Avg. HTER. We use
(Right)HTERperformancew.r.tdifferentEuclideanfeatureclippingvalues.
ResNet50 [23] , SeNet50 [25] and CLIP ViT [58] for
Inourwork,wesettheEuclideanfeatureclippingvalueto2(orange).
comparison and achieve Avg. HTER of 33.555, 37.915 and
39.505, respectively. We observe that VGGFace performs
pipeline. The absence of Hyp-OC results in a noticeable
better in three out of five datasets. However, ResNet50 per-
decline in performance, with HTER dropping by 7.493.
forms better on R, and CLIP ViT performs better on O. The
This shows that the Poincare` Ball model effectively embeds
results indicate that VGGFace is a better choice of feature
feature representations for FAS task. Hyp-OC allows for
extractor for one-class FAS using hyperbolic embeddings.
betterfittingofseparatinggyroplaneforone-classclassifica-
tion. The geodesic distance increases exponentially near the VI. CONCLUSIONANDFUTUREWORK
boundary of the Poincare` Ball. Euclidean feature clipping In this research, we redefine FAS as a one-class classi-
helps to cut down the effective radius of the PoincareÂ´ Ball fication task. We discuss our motivation and showcase the
and solves the problem of vanishing gradients persistent in significance of - the â€œWhy One-Class?â€ approach, empha-
Hyperbolic space. The clipping stabilizes the training and sizing its practicality in real-world applications. We show
acts as a regularizer. This is validated by the performance the benefits of employing a hyperbolic classifier head (Hyp-
drop (Table IV row-3) of 3.707 in HTER when Euclidean OC) to develop a one-class classifier and demonstrate its
feature clipping is removed from the pipeline. Lastly, the effectiveness for FAS using three protocols. For training, we
proposedlossfunctionHyp-PCdisruptsthefeaturespaceby introduce two novel loss functions, Hyp-PC and Hyp-CE,
creatingconfusion.Itremovestheidentityinformationbyun- that operate in the hyperbolic space. Our proposed pipeline
clusteringthefeaturerepresentations,makingitbettersuited outperforms previous baselines and sets a new benchmark
for FAS task. Additionally, it improves the mean estimation for one-class FAS.
forthepseudo-negativeGaussiandistribution.Theabsenceof Despite our advancements over previous one-class FAS
Hyp-PC loss results in a performance drop (Table IV row-4) baselines,werecognizethattheperformanceofHyp-OCstill
of 2.569 in HTER, signifying its importance in the pipeline. lags behindthat of binary classifiers.However, in real-world
Curvature of the Hyperbolic space: We perform exper- deployment,thedistributionofspoofsamplesisconsiderably
iments for different curvatures of the PoincareÂ´ Ball and more complex than that of real samples. This complexity
compare the Avg. HTER as shown in Figure 5 (left). We arises from the infinite variability in presentation attack
can see that the performance is better at lower curvature instruments, which motivates our pursuit of OC-FAS. We
values. Moreover, we observe that the difference between advocate for the development of one-class classifiers using
APCER and BPCER is less at low curvature values than onlyrealsamplesasasteptowardscreatingtrulygeneralized
when the curvature is high. It indicates that the training modelsthatcandetectawidevarietyofspoofattacks.Inthe
is more stable at lower curvatures of hyperbolic spaces. future, we plan to explore other ways to leverage hyperbolic
In our implementation, following previous works [14], [4], embeddings to enhance FAS performance.
we choose the curvature of the hyperbolic space to be Acknowledgement: This work was supported by NSF
0.1. Euclidean feature clipping value: We implemented CAREER award 2045489.
RETH RETHREFERENCES Conference on Computer Vision and Pattern Recognition, pages 11â€“
20,2022.
[1] A. Ali, F. Deravi, and S. Hoque. Liveness detection using gaze [23] K.He,X.Zhang,S.Ren,andJ.Sun.Deepresiduallearningforimage
collinearity. In 2012 Third International Conference on Emerging recognition.InProceedingsoftheIEEEconferenceoncomputervision
SecurityTechnologies,pages62â€“65.IEEE,2012. andpatternrecognition,pages770â€“778,2016.
[2] S. R. Arashloo, J. Kittler, and W. Christmas. An anomaly detection [24] J. Hernandez-Ortega, J. Fierrez, A. Morales, and P. Tome. Time
approachtofacespoofingdetection:Anewformulationandevaluation analysis of pulse-based face anti-spoofing in visible and nir. In
protocol. IEEEaccess,5:13868â€“13882,2017. ProceedingsoftheIEEEConferenceonComputerVisionandPattern
[3] M. Asim, Z. Ming, and M. Y. Javed. Cnn based spatio-temporal Recognition(CVPR)Workshops,June2018.
feature extraction for face anti-spoofing. In 2017 2nd International [25] J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks. In
ConferenceonImage,VisionandComputing(ICIVC),pages234â€“238. Proceedings of the IEEE conference on computer vision and pattern
IEEE,2017. recognition,pages7132â€“7141,2018.
[4] M. G. Atigh, J. Schoep, E. Acar, N. Van Noord, and P. Mettes. [26] J.Ilonen,P.Paalanen,J.-K.Kamarainen,andH.Kalviainen.Gaussian
Hyperbolic image segmentation. In Proceedings of the IEEE/CVF mixturepdfinone-classclassification:computingandutilizingconfi-
conferenceoncomputervisionandpatternrecognition,pages4453â€“ dencevalues.In18thInternationalConferenceonPatternRecognition
4462,2022. (ICPRâ€™06),volume2,pages577â€“580.IEEE,2006.
[5] Y. Atoum, Y. Liu, A. Jourabloo, and X. Liu. Face anti-spoofing [27] H.-K.Jee,S.-U.Jung,andJ.-H.Yoo.Livenessdetectionforembedded
usingpatchanddepth-basedcnns. In2017IEEEInternationalJoint face recognition system. International Journal of Biological and
ConferenceonBiometrics(IJCB),pages319â€“328.IEEE,2017. MedicalSciences,1(4):235â€“238,2006.
[6] W. Bao, H. Li, N. Li, and W. Jiang. A liveness detection method [28] Y. Jia, J. Zhang, S. Shan, and X. Chen. Single-side domain gen-
forfacerecognitionbasedonopticalflowfield. In2009International eralization for face anti-spoofing. In Proceedings of the IEEE/CVF
ConferenceonImageAnalysisandSignalProcessing,pages233â€“236. ConferenceonComputerVisionandPatternRecognition,pages8484â€“
IEEE,2009. 8493,2020.
[7] Y. Baweja, P. Oza, P. Perera, and V. M. Patel. Anomaly detection- [29] Kepeng Qiu. SVDD. â€https://github.com/iqiukp/
based unknown face presentation attack detection. In 2020 IEEE SVDD-Pythonâ€,2020.
InternationalJointConferenceonBiometrics(IJCB),pages1â€“9.IEEE, [30] V.Khrulkov,L.Mirvakhabova,E.Ustinova,I.Oseledets,andV.Lem-
2020. pitsky. Hyperbolic image embeddings. In Proceedings of the
[8] Z. Boulkenafet, J. Komulainen, and A. Hadid. Face anti-spoofing IEEE/CVFConferenceonComputerVisionandPatternRecognition,
basedoncolortextureanalysis.In2015IEEEinternationalconference pages6418â€“6428,2020.
onimageprocessing(ICIP),pages2636â€“2640.IEEE,2015. [31] T. Kim, Y. Kim, I. Kim, and D. Kim. Basn: Enriching feature
[9] Z.Boulkenafet,J.Komulainen,L.Li,X.Feng,andA.Hadid. Oulu- representation using bipartite auxiliary supervisions for face anti-
npu: A mobile face presentation attack database with real-world spoofing. InProceedingsoftheIEEE/CVFInternationalConference
variations. In201712thIEEEinternationalconferenceonautomatic onComputerVisionWorkshops,pages0â€“0,2019.
face&gesturerecognition(FG2017),pages612â€“618.IEEE,2017. [32] J.Komulainen,A.Hadid,andM.PietikaÂ¨inen.Contextbasedfaceanti-
[10] I.Chami,Z.Ying,C.ReÂ´,andJ.Leskovec. Hyperbolicgraphconvo- spoofing.In2013IEEESixthInternationalConferenceonBiometrics:
lutionalneuralnetworks. Advancesinneuralinformationprocessing Theory,ApplicationsandSystems(BTAS),pages1â€“8.IEEE,2013.
systems,32,2019. [33] H.Kuang,R.Ji,H.Liu,S.Zhang,X.Sun,F.Huang,andB.Zhang.
[11] I.Chingovska,A.Anjos,andS.Marcel. Ontheeffectivenessoflocal Multi-modal multi-layer fusion network with average binary center
binary patterns in face anti-spoofing. In 2012 BIOSIG-proceedings lossforfaceanti-spoofing. InProceedingsofthe27thACMInterna-
of the international conference of biometrics special interest group tionalConferenceonMultimedia,pages48â€“56,2019.
(BIOSIG),pages1â€“7.IEEE,2012. [34] M. Law, R. Liao, J. Snell, and R. Zemel. Lorentzian distance
[12] T.deFreitasPereira,A.Anjos,J.M.DeMartino,andS.Marcel.Lbp- learning for hyperbolic representations. In International Conference
topbasedcountermeasureagainstfacespoofingattacks. InComputer onMachineLearning,pages3672â€“3681.PMLR,2019.
Vision-ACCV2012Workshops:ACCV2012InternationalWorkshops, [35] H.Li,W.Li,H.Cao,S.Wang,F.Huang,andA.C.Kot.Unsupervised
Daejeon, Korea, November 5-6, 2012, Revised Selected Papers, Part domain adaptation for face anti-spoofing. IEEE Transactions on
I11,pages121â€“132.Springer,2013. InformationForensicsandSecurity,13(7):1794â€“1809,2018.
[13] P.Deng,C.Ge,H.Wei,Y.Sun,andX.Qiao. Attention-awaredual- [36] X. Li, J. Komulainen, G. Zhao, P.-C. Yuen, and M. PietikaÂ¨inen.
streamnetworkformultimodalfaceanti-spoofing. IEEETransactions Generalizedfaceanti-spoofingbydetectingpulsefromfacevideos.In
onInformationForensicsandSecurity,2023. 2016 23rd International Conference on Pattern Recognition (ICPR),
[14] A.Ermolov,L.Mirvakhabova,V.Khrulkov,N.Sebe,andI.Oseledets. pages4244â€“4249.IEEE,2016.
Hyperbolic vision transformers: Combining improvements in metric [37] Z. Li, R. Cai, H. Li, K.-Y. Lam, Y. Hu, and A. C. Kot. One-class
learning. In Proceedings of the IEEE/CVF Conference on Computer knowledge distillation for face presentation attack detection. IEEE
VisionandPatternRecognition,pages7409â€“7419,2022. Transactions on Information Forensics and Security, 17:2137â€“2150,
[15] S. Fatemifar, S. R. Arashloo, M. Awais, and J. Kittler. Spoofing 2022.
attack detection by anomaly detection. In ICASSP 2019-2019 IEEE [38] A. Liu, Z. Tan, J. Wan, Y. Liang, Z. Lei, G. Guo, and S. Z. Li.
InternationalConferenceonAcoustics,SpeechandSignalProcessing Face anti-spoofing via adversarial cross-modality translation. IEEE
(ICASSP),pages8464â€“8468.IEEE,2019. Transactions on Information Forensics and Security, 16:2759â€“2772,
[16] S. Fatemifar, M. Awais, S. R. Arashloo, and J. Kittler. Combining 2021.
multiple one-class classifiers for anomaly based face spoofing attack [39] S. Liu, J. Chen, L. Pan, C.-W. Ngo, T.-S. Chua, and Y.-G. Jiang.
detection. In 2019 International Conference on Biometrics (ICB), Hyperbolic visual embedding learning for zero-shot recognition. In
pages1â€“7.IEEE,2019. Proceedings of the IEEE/CVF conference on computer vision and
[17] O.Ganea,G.BeÂ´cigneul,andT.Hofmann.Hyperbolicneuralnetworks. patternrecognition,pages9273â€“9281,2020.
Advancesinneuralinformationprocessingsystems,31,2018. [40] S.Liu,P.C.Yuen,S.Zhang,andG.Zhao.3dmaskfaceanti-spoofing
[18] Z. Gao, Y. Wu, Y. Jia, and M. Harandi. Curvature generation in withremotephotoplethysmography.InComputerVisionâ€“ECCV2016:
curvedspacesforfew-shotlearning. InProceedingsoftheIEEE/CVF 14thEuropeanConference,Amsterdam,TheNetherlands,October11â€“
internationalconferenceoncomputervision,pages8691â€“8700,2021. 14,2016,Proceedings,PartVII14,pages85â€“100.Springer,2016.
[19] A. George and S. Marcel. Deep pixel-wise binary supervision for [41] S. Liu, K.-Y. Zhang, T. Yao, M. Bi, S. Ding, J. Li, F. Huang, and
face presentation attack detection. In 2019 International Conference L.Ma. Adaptivenormalizedrepresentationlearningforgeneralizable
onBiometrics(ICB),pages1â€“8.IEEE,2019. face anti-spoofing. In Proceedings of the 29th ACM international
[20] A.GeorgeandS.Marcel. Learningoneclassrepresentationsforface conferenceonmultimedia,pages1469â€“1477,2021.
presentationattackdetectionusingmulti-channelconvolutionalneural [42] W.Liu,X.Wei,T.Lei,X.Wang,H.Meng,andA.K.Nandi. Data-
networks. IEEETransactionsonInformationForensicsandSecurity, fusion-based two-stage cascade framework for multimodality face
16:361â€“375,2020. anti-spoofing. IEEE Transactions on Cognitive and Developmental
[21] S.Goyal,A.Raghunathan,M.Jain,H.V.Simhadri,andP.Jain.Drocc: Systems,14(2):672â€“683,2021.
Deep robust one-class classification. In International conference on [43] Y. Liu, A. Jourabloo, and X. Liu. Learning deep models for face
machinelearning,pages3711â€“3721.PMLR,2020. anti-spoofing:Binaryorauxiliarysupervision. InProceedingsofthe
[22] Y.Guo,X.Wang,Y.Chen,andS.X.Yu.Clippedhyperbolicclassifiers IEEE conference on computer vision and pattern recognition, pages
are super-hyperbolic classifiers. In Proceedings of the IEEE/CVF 389â€“398,2018.[44] Y. Liu, J. Stehouwer, A. Jourabloo, and X. Liu. Deep tree learning PatternRecognition,pages24563â€“24574,2023.
for zero-shot face anti-spoofing. In Proceedings of the IEEE/CVF [67] D.M.TaxandR.P.Duin. Supportvectordatadescription. Machine
ConferenceonComputerVisionandPatternRecognition,pages4680â€“ learning,54:45â€“66,2004.
4689,2019. [68] A. Ungar. A gyrovector space approach to hyperbolic geometry.
[45] T.Long,P.Mettes,H.T.Shen,andC.G.Snoek.Searchingforactions SpringerNature,2022.
on the hyperbole. In Proceedings of the IEEE/CVF Conference on [69] A.A.Ungar.Analytichyperbolicgeometry:Mathematicalfoundations
ComputerVisionandPatternRecognition,pages1141â€“1150,2020. andapplications. WorldScientific,2005.
[46] E.Mathieu,C.LeLan,C.J.Maddison,R.Tomioka,andY.W.Teh. [70] C.-Y.Wang,Y.-D.Lu,S.-T.Yang,andS.-H.Lai. Patchnet:Asimple
ContinuoushierarchicalrepresentationswithpoincareÂ´variationalauto- face anti-spoofing framework via fine-grained patch recognition. In
encoders. Advances in neural information processing systems, 32, Proceedings of the IEEE/CVF Conference on Computer Vision and
2019. PatternRecognition,pages20281â€“20290,2022.
[47] P. Nader, P. Honeine, and P. Beauseroy. Mahalanobis-based one- [71] G. Wang, H. Han, S. Shan, and X. Chen. Improving cross-database
classclassification.In2014IEEEInternationalWorkshoponMachine face presentation attack detection via adversarial domain adaptation.
LearningforSignalProcessing(MLSP),pages1â€“6.IEEE,2014. In 2019 International Conference on Biometrics (ICB), pages 1â€“8.
[48] M.NickelandD.Kiela.PoincareÂ´embeddingsforlearninghierarchical IEEE,2019.
representations. Advances in neural information processing systems, [72] G.Wang,H.Han,S.Shan,andX.Chen. Cross-domainfacepresen-
30,2017. tation attack detection via multi-domain disentangled representation
[49] O. Nikisins, A. Mohammadi, A. Anjos, and S. Marcel. On effec- learning. In Proceedings of the IEEE/CVF conference on computer
tivenessofanomalydetectionapproachesagainstunseenpresentation visionandpatternrecognition,pages6678â€“6687,2020.
attacks in face anti-spoofing. In 2018 International Conference on [73] G. Wang, H. Han, S. Shan, and X. Chen. Unsupervised adversarial
Biometrics(ICB),pages75â€“81.IEEE,2018. domainadaptationforcross-domainfacepresentationattackdetection.
[50] P.OzaandV.M.Patel.One-classconvolutionalneuralnetwork.IEEE IEEETransactionsonInformationForensicsandSecurity,16:56â€“69,
SignalProcessingLetters,26(2):277â€“281,2018. 2020.
[51] G. Pan, L. Sun, Z. Wu, and S. Lao. Eyeblink-based anti-spoofing [74] L. Wang, X. Ding, and C. Fang. Face live detection method based
in face recognition from a generic webcamera. In 2007 IEEE 11th on physiological motion analysis. Tsinghua Science & Technology,
internationalconferenceoncomputervision,pages1â€“8.IEEE,2007. 14(6):685â€“690,2009.
[52] O.Parkhi,A.Vedaldi,andA.Zisserman. Deepfacerecognition. In [75] D. Wen, H. Han, and A. K. Jain. Face spoof detection with image
BMVC 2015-Proceedings of the British Machine Vision Conference distortionanalysis. IEEETransactionsonInformationForensicsand
2015.BritishMachineVisionAssociation,2015. Security,10(4):746â€“761,2015.
[53] A. Parkin and O. Grinchuk. Recognizing multi-modal face spoofing [76] Z. Weng, M. G. Ogut, S. Limonchik, and S. Yeung. Unsupervised
with face recognition networks. In Proceedings of the IEEE/CVF discoveryofthelong-tailininstancesegmentationusinghierarchical
conference on computer vision and pattern recognition workshops, self-supervision. In Proceedings of the IEEE/CVF conference on
pages0â€“0,2019. computervisionandpatternrecognition,pages2603â€“2612,2021.
[54] K.Patel,H.Han,andA.K.Jain. Securefaceunlock:Spoofdetection [77] X. Yang, W. Luo, L. Bao, Y. Gao, D. Gong, S. Zheng, Z. Li,
on smartphones. IEEE transactions on information forensics and and W. Liu. Face anti-spoofing: Model matters, so does data. In
security,11(10):2268â€“2283,2016. Proceedings of the IEEE/CVF Conference on Computer Vision and
[55] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, PatternRecognition,pages3507â€“3516,2019.
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, et al. [78] T.YuandC.M.DeSa. Numericallyaccuratehyperbolicembeddings
Scikit-learn: Machine learning in python. the Journal of machine usingtiling-basedmodels.AdvancesinNeuralInformationProcessing
Learningresearch,12:2825â€“2830,2011. Systems,32,2019.
[56] D.PeÂ´rez-Cabo,D.JimeÂ´nez-Cabello,A.Costa-Pazo,andR.J.LoÂ´pez- [79] Z. Yu, X. Li, J. Shi, Z. Xia, and G. Zhao. Revisiting pixel-wise
Sastre. Deepanomalydetectionforgeneralizedfaceanti-spoofing. In supervisionforfaceanti-spoofing. IEEETransactionsonBiometrics,
Proceedings of the IEEE/CVF Conference on Computer Vision and Behavior,andIdentityScience,3(3):285â€“295,2021.
PatternRecognitionWorkshops,pages0â€“0,2019. [80] Z. Yu, W. Peng, X. Li, X. Hong, and G. Zhao. Remote heart rate
[57] R.Quan,Y.Wu,X.Yu,andY.Yang.Progressivetransferlearningfor measurement from highly compressed facial videos: an end-to-end
faceanti-spoofing.IEEETransactionsonImageProcessing,30:3946â€“ deep learning solution with video enhancement. In Proceedings of
3955,2021. the IEEE/CVF International Conference on Computer Vision, pages
[58] A.Radford,J.W.Kim,C.Hallacy,A.Ramesh,G.Goh,S.Agarwal, 151â€“160,2019.
G.Sastry,A.Askell,P.Mishkin,J.Clark,etal. Learningtransferable [81] Z.Yu,C.Zhao,Z.Wang,Y.Qin,Z.Su,X.Li,F.Zhou,andG.Zhao.
visual models from natural language supervision. In International Searching central difference convolutional networks for face anti-
conferenceonmachinelearning,pages8748â€“8763.PMLR,2021. spoofing. InProceedingsoftheIEEE/CVFConferenceonComputer
[59] R.Sarkar. Lowdistortiondelaunayembeddingoftreesinhyperbolic VisionandPatternRecognition,pages5295â€“5305,2020.
plane. InInternationalsymposiumongraphdrawing,pages355â€“366. [82] K.-Y. Zhang, T. Yao, J. Zhang, S. Liu, B. Yin, S. Ding, and J. Li.
Springer,2011. Structuredestructionandcontentcombinationforfaceanti-spoofing.
[60] B. SchoÂ¨lkopf, J. C. Platt, J. Shawe-Taylor, A. J. Smola, and R. C. In 2021 IEEE International Joint Conference on Biometrics (IJCB),
Williamson.Estimatingthesupportofahigh-dimensionaldistribution. pages1â€“6.IEEE,2021.
Neuralcomputation,13(7):1443â€“1471,2001. [83] P. Zhang, F. Zou, Z. Wu, N. Dai, S. Mark, M. Fu, J. Zhao, and
[61] A.Sepas-Moghaddam,F.Pereira,andP.L.Correia. Lightfield-based K.Li. Feathernets:Convolutionalneuralnetworksaslightasfeather
face presentation attack detection: reviewing, benchmarking and one for face anti-spoofing. In Proceedings of the IEEE/CVF Conference
stepfurther.IEEETransactionsonInformationForensicsandSecurity, on Computer Vision and Pattern Recognition Workshops, pages 0â€“0,
13(7):1696â€“1709,2018. 2019.
[62] R.Shao,X.Lan,J.Li,andP.C.Yuen.Multi-adversarialdiscriminative [84] Z. Zhang, J. Yan, S. Liu, Z. Lei, D. Yi, and S. Z. Li. A face anti-
deepdomaingeneralizationforfacepresentationattackdetection. In spoofingdatabasewithdiverseattacks.In20125thIAPRinternational
Proceedings of the IEEE/CVF conference on computer vision and conferenceonBiometrics(ICB),pages26â€“31.IEEE,2012.
patternrecognition,pages10023â€“10031,2019. [85] F.Zhou,C.Gao,F.Chen,C.Li,X.Li,F.Yang,andY.Zhao. Face
[63] T. Shen, Y. Huang, and Z. Tong. Facebagnet: Bag-of-local-features anti-spoofingbasedonmulti-layerdomainadaptation. In2019IEEE
model for multi-modal face anti-spoofing. In Proceedings of the internationalconferenceonmultimedia&expoworkshops(ICMEW),
IEEE/CVF conference on computer vision and pattern recognition pages192â€“197.IEEE,2019.
workshops,pages0â€“0,2019. [86] Q.Zhou,K.-Y.Zhang,T.Yao,R.Yi,K.Sheng,S.Ding,andL.Ma.
[64] R.Shimizu,Y.Mukuta,andT.Harada.Hyperbolicneuralnetworks++. Generative domain adaptation for face anti-spoofing. In European
arXivpreprintarXiv:2006.08210,2020. ConferenceonComputerVision,pages335â€“356.Springer,2022.
[65] K. Srivatsan, M. Naseer, and K. Nandakumar. Flip: Cross-domain
face anti-spoofing with language guidance. In Proceedings of
the IEEE/CVF International Conference on Computer Vision, pages
19685â€“19696,2023.
[66] Y. Sun, Y. Liu, X. Liu, Y. Li, and W.-S. Chu. Rethinking domain
generalization for face anti-spoofing: Separability and alignment. In
Proceedings of the IEEE/CVF Conference on Computer Vision and