3D Gaussian Ray Tracing: Fast Tracing of Particle Scenes
NICOLASMOENNE-LOCCOZâˆ—,NVIDIA,Canada
ASHKANMIRZAEIâˆ—,NVIDIA,Canada
ORPEREL,NVIDIA,Israel
RICCARDODELUTIO,NVIDIA,USA
JANICKMARTINEZESTURO,NVIDIA,Germany
GAVRIELSTATE,NVIDIA,Canada
SANJAFIDLER,NVIDIA,UniversityofToronto,VectorInstitute,Canada
NICHOLASSHARPâ€ ,NVIDIA,USA
ZANGOJCICâ€ ,NVIDIA,Switzerland
depth of field
mirrors
encapsulating acceleration
refraction primitives structure
inserted objects
Fig.1. Weproposeamethodforfastforwardandinverseraytracingofparticle-basedscenerepresentationssuchasGaussians.Themainideaistoconstruct
encapsulatingprimitivesaroundeachparticle,andinsertthemintoaBVHtoberenderedbyaraytracerspeciallyadaptedtothehighdensityofoverlapping
particles.Efficientraytracingopensthedoortomanyadvancedtechniquesincomputergraphicsandvision,includingsecondaryrayeffectslikemirrors,
refractionsandshadows,aswellashighly-distortedcameraswithrollingshuttereffectsandevenstochasticsamplingofrays.
Projectpage:GaussianTracer.github.io
Particle-basedrepresentationsofradiancefieldssuchas3DGaussianSplat- CCSConcepts:â€¢Computingmethodologiesâ†’Rendering;Reconstruc-
ting,havefoundgreatsuccessforreconstructingandre-renderingofcomplex tion.
scenes.Mostexistingmethodsrenderparticlesviarasterization,projecting
AdditionalKeyWordsandPhrases:RadianceFields,GaussianSplats,Ray
themtoscreenspacetilesforprocessinginasortedorder.Thisworkinstead
Tracing
considersraytracingtheparticles,buildingaboundingvolumehierarchy
andcastingarayforeachpixelusinghigh-performanceGPUraytracing
hardware.Toefficientlyhandlelargenumbersofsemi-transparentparticles, 1 INTRODUCTION
wedescribeaspecializedrenderingalgorithmwhichencapsulatesparti-
Multiview3Dreconstructionandnovel-viewsynthesisareaclassic
cleswithboundingmeshestoleveragefastray-triangleintersections,and
challengeinvisualcomputing,keytoapplicationsacrossrobotics,
shadesbatchesofintersectionsindepth-order.Thebenefitsofraytracing
arewell-knownincomputergraphics:processingincoherentraysforsec- telepresence, AR/VR, and beyond. Many approaches have been
ondarylightingeffectssuchasshadowsandreflections,renderingfrom proposed,butmostrecentlyparticle-basedrepresentationshave
highly-distortedcamerascommoninrobotics,stochasticallysamplingrays, shownincrediblesuccess,ignitedby3DGaussianSplatting[Kerbl
andmore.Withourrenderer,thisflexibilitycomesatlittlecostcompared etal.2023](3DGS)â€”thebasicideaistorepresentasceneasalarge
torasterization.Experimentsdemonstratethespeedandaccuracyofour unstructuredcollectionoffuzzyparticleswhichcanbedifferentiably
approach,aswellasseveralapplicationsincomputergraphicsandvision. renderedbysplattingtoacameraviewwithatile-basedrasterizer.
WefurtherproposerelatedimprovementstobasicGaussianrepresentation,
Thelocation,shape,andappearanceoftheparticlesareoptimized
includingasimpleuseofgeneralizedkernelfunctionswhichsignificantly
usingare-renderingloss.
reducesparticlehitcounts.
Meanwhile,morebroadlyincomputergraphics,renderinghas
longbeenadualitybetweenrasterizationandraytracing.Tradition-
âˆ—Authorscontributedequally.
â€ Authorscontributedequally. ally,rasterizationsupportedreal-timeperformanceattheexpense
4202
luJ
9
]RG.sc[
1v09070.7042:viXra2 â€¢ Moenne-Loccoz,Mirzaeietal.
ofapproximatingimageformation,whileraytracingenabledfully Insummary,thecontributionsofthisworkare:
generalhigh-fidelityrenderingintheexpensiveofflinesetting.How-
â€¢ AGPU-acceleratedraytracingalgorithmforsemi-transparent
ever,theintroductionofspecializedGPUraytracinghardwareand
particles.
real-timerenderershasmovedraytracingintotherealmofreal-time
â€¢ Animprovedoptimizationpipelineforray-traced,particle-
performance.
basedradiancefields.
Thisworkismotivatedbytheobservationthat3DGSislimited
â€¢ GeneralizedGaussianparticleformulationsthatreducethe
bytheclassictradeoffsofrasterization.Thetile-basedrasterizeris
numberofintersectionsandleadtoimprovedrenderingeffi-
ill-suitedtorenderingfromhighly-distortedcameraswithrolling
ciency.
shuttereffects,whichareimportantinroboticsandsimulation.It
â€¢ Applicationsdemonstratingtheutilityofraytracing,includ-
alsocannotefficientlysimulatesecondaryraysneededtohandle
ing:depthoffield,shadows,mirrors,highly-distortedcameras,
phenomenalikereflection,refraction,andshadows.Likewise,ras-
rollingshutter,incoherentrays,andinstancing.
terizationcannotsampleraysstochastically,acommonpracticefor
trainingincomputervision.Indeed,priorworkhasalreadyencoun- 2 RELATEDWORK
teredtheneedforthesecapabilities,butwaslimitedtorendering
2.1 Novel-ViewSynthesisandNeuralRadianceFields
withrestrictivetricksorworkarounds[Niemeyeretal.2024;Seiskari
Classicalapproachestonovel-viewsynthesiscanberoughlycat-
etal.2024].Weinsteadaimtoaddresstheselimitationsbymaking
egorizedbasedonthesparsityoftheinputviews.Inthecaseof
theraytracedGaussianparticlesefficient,withatailoredimple-
sparseviews,mostmethodsfirstconstructaproxygeometryus-
mentationforspecializedGPUraytracing.Tobeclear,goalofthis
ingmulti-viewstereo[SchÃ¶nbergerandFrahm2016;SchÃ¶nberger
workisnottoofferanend-to-endsolutiontounsolvedproblems
etal.2016]andpointcloudreconstructionmethods[Kazhdanetal.
likeglobalilluminationorinverselightingonparticlescenes,but
2006; Kazhdan and Hoppe 2013] and then unproject the images
rathertoprovideakeyalgorithmicingredienttofutureresearchon
ontothisgeometryeitherdirectlyintermsofRGBcolors[Buehler
theseproblems:afastdifferentiableraytracer.
etal.2001;Debevecetal.1996;Woodetal.2000]orextractedla-
EfficientlyraytracingGaussianscenes(andmoregenerallysemi-
tentfeatures[RieglerandKoltun2020,2021].Thenovelviewsare
transparentsurfaces)isnotasolvedproblem[â€œTankiâ€Zhang2021].
renderedbyprojectingthecolororfeaturesfromthegeometryto
Wefindthatevenpastalgorithmsthatwerespeciallydesignedfor
thecameraplane.Inthecaseofdenselysampledinputviews,the
raytracingsemi-transparentparticles[BrÃ¼llandGrosch2020;Knoll
novel-viewsynthesiscaninsteadbeformulateddirectlyaslight
etal.2019;MÃ¼nstermannetal.2018]areineffectiveonthesescene
fieldinterpolationproblem[Davisetal.2012;Gortleretal.1996;
reconstructions,duetothehugenumbersofnon-uniformlydis-
LevoyandHanrahan1996].
tributedanddensely-overlappingparticles.Accordingly,wedesign
Neural Radiance Fields (NeRFs) [Mildenhall et al. 2020] have
acustomizedGPU-acceleratedraytracerforGaussianparticleswith
revolutionizedthefieldofnovel-viewsynthesisbyrepresenting
ağ‘˜-buffer[Bavoiletal.2007]hits-basedmarchingtogatherordered
the scenes in terms of a volumetric radiance field encoded in a
intersections,boundingmeshproxiestoleveragefastray-triangle
coordinate-basedneuralnetwork.Thisnetworkcanbequeriedat
intersections,andabackwardpasstoenableoptimization.Each
anylocationtoreturnthevolumetricdensityandview-dependent
ofthesecomponentsiscarefullytestedforspeedandqualityona
color.Thephoto-realisticqualityofNeRFshasmadethemthestan-
varietyofbenchmarks.Wefounditcrucialtotunethedetailsof
dardrepresentationfornovel-viewsynthesis.Follow-upworkshave
thealgorithmtothetaskathand.Ourfinalproposedalgorithm
focusedonimprovingthespeed[MÃ¼lleretal.2022;Reiseretal.
isalmost25xfasterthanourfirstnaiveimplementation,duetoa
2021],quality[Barronetal.2021,2022,2023],andsurfacerepresen-
widerangeofalgorithmicandnumericalfactors.Wehopethatthese
tation[Lietal.2023;Wangetal.2021,2023a;Yarivetal.2021].NeRF
learningswillbeofvaluetothecommunityleveragingraytracing
hasalsobeenextendedtolarge-scalescenes[Lietal.2024a;Turki
onparticlerepresentations.
etal.2022],sparseinputsviews[Niemeyeretal.2022]andin-the-
Thefundamentalapproachofrepresentingascenewithparti-
wildimagecollections[Martin-Bruallaetal.2021].Finally,several
cles is not limited to the Gaussian kernel; and recent work has
worksinvestigatedwaystospeeduptheinferencebybakingthe
alreadyshownseveralnaturalgeneralizations[Huangetal.2024].
neuralfieldstomoreperformantrepresentations[Duckworthetal.
Ourraytracingscheme,aswellasthebenefitsandapplications
2023;Reiseretal.2024,2023;Wangetal.2023b].Whileachieving
above,likewisegeneralizesmorebroadlytoparticle-basedscene
highqualityandfastrenderingspeeds,thesemethodsoftenemploy
representations,asweshowinsectionSection4.5.
compute-expensivemulti-stagetrainingprocedures.
Weevaluatethisapproachonawidevarietyofbenchmarksand
applications.Onstandardmultiviewbenchmarks,raytracingnearly
2.2 Point-BasedandParticleRasterization
matchesorexceedsthequalityofthe3DGSrasterizerofKerbletal.
[2023],whilestillachievingreal-timerenderingframerates.More GrossmanandDally[1998]definedpoint-basedrenderingasasim-
importantly, we demonstrate a variety of new techniques made plerasterizationofobjectsurfacepointsalongwiththeircolorand
easyandefficientbyraytracing,includingsecondaryrayeffects normals.However,duetotheinfinitesimalsizeofthepoints,such
likeshadowsandreflections,renderingfromcameraswithhigh simplerasterizationinevitablyledtoholesandaliasing.Toaddress
distortionandrollingshutter,trainingwithstochasticallysampled theselimitations,laterworkconvertedpointstoparticleswitha
raysandmore. spatialextent,suchassurfels,circulardiscs,orellipsoids[Pfister
etal.2000;Renetal.2002;Zwickeretal.2001].Morerecently,points3DGaussianRayTracing:FastTracingofParticleScenes â€¢ 3
Fig.2. RayTracingEffects:Theraybasednatureofourpipelinemakesiteasilycompatiblewithconventionalraybasedvisualeffectsattest-time,including
reflections(topleft),depthoffield(topmiddle),refractions(bottomleft),hard-shadowscastbymeshes(bottommiddle)andcombinationsthereof(right).
orparticleshavealsobeenaugmentedwithneuralfeaturesandren- 2.3 DifferentiableRayTracingofVolumetricParticles
deredusingrasterizationincombinationwithCNNnetworks[Aliev Raytracingbecamethegoldstandardforofflinerenderingofhigh-
etal.2020;Kopanasetal.2021;RÃ¼ckertetal.2022]orNeRF-like qualityphoto-realisticimages[Whitted1979].Theadventofdedi-
volumetricrendering[Ostetal.2022;Xuetal.2022]. catedhardwaretoefficientlycomputetheintersectionofcamera
Differentiable rendering through alpha blending was also ex- rayswiththescenegeometryhasalsoenableditsuseforreal-time
tendedtovolumetricparticles.Pulsar[LassnerandZollhÃ¶fer2021] renderingapplicationssuchasgamingandthesimulationindustry.
proposedanefficientsphere-baseddifferentiablerasterizationap- ModernGPUsareexposingraytracingrenderingpipelines,from
proach, which allows for real-time optimization of scenes with thecomputationofdedicatedaccelerationstructurestoaspecific
millionsofparticles.Theseminal3DGSworkofKerbletal.[2023] programmableinterface[Joshietal.2007].
insteadrepresentedthescenesusingfuzzy,anisotropic3DGaussian However,theseworksarehighlyoptimizedforrenderingopaque
particles.Byoptimizingtheshape,position,andappearanceofthese surfacesandefficientlyhandlingorderindependentsemi-transparent
Gaussianparticlesthroughanefficienttile-basedrasterizer,3DGS surfacesorparticlesremainschallenging[â€œTankiâ€Zhang2021].
achievesSoTAresultsintermsofperceptualqualityandefficiency. Afirstclassofworks[Aizenshteinetal.2022;MÃ¼nstermannetal.
3DGSinspiredmanyfollow-upworksthataimtoreducetherender 2018]proposestofirstestimatethetransmittancefunctionalong
timeormemoryfootprint[Fanetal.2023;Niedermayretal.2023; therayandsubsequentlytointegratetheparticlesâ€™radiancebased
Papantonakis et al. 2024], improve surface representation [GuÃ©- onthisestimate.Itassumesthetraversalofthefullscenetobefast
donandLepetit2023;Huangetal.2024],andsupportlarge-scale enough;anassumptionthatdoesnotholdinGaussianparticlesfor
scenes[Kerbletal.2024;Renetal.2024],andmore. scenereconstruction.
Jointly, these works have made significant progress, but they Asecondclassofworksconsistsinre-orderingtheparticlesalong
stillinheritlimitationsofrasterization.Indeed,theyarenotable theray.Knolletal.[2019]proposeaslab-tracingmethodtotrace
torepresenthighlydistortedcameras,modelsecondarylighting semi-transparentvolumetricRBF(radialbasisfunction)particles,
effects,orsensorpropertiessuchasrollingshutterormotionblur. whichenablesreal-timeraytracingofscenesconsistingofseveral
Severalworkshavetriedtoworkaroundtheselimitations.Niemeyer millionsofsuchparticles.However,itsefficiencyislargelybased
et al. [2024] first train a Zip-NeRF [Barron et al. 2023] that can ontheassumptionoftheisotropicshapeoftheparticlesandahigh
modeldistortedandrollingshuttercamerasandthenrenderperfect levelofuniformityintheirspatialdistribution.In[BrÃ¼llandGrosch
pinholecamerasfromtheneuralfieldanddistillthemintoa3DGS 2020], the multi-layer alpha blending approach from [Salvi and
representation.Thisallowsforfastinference,butisstilllimitedto Vaidyanathan2014]isextendedtoraytracing.Theirmulti-layer
perfectpinholecameras.TomodelsecondarylightingeffectsGao alphatracingsupportsefficientrenderingofanysemi-transparent
etal.[2023]combinesrasterizationwithparticle-basedraytracing surfacebutitsapproximationoftheparticleâ€™sorderingmayproduce
forthevisibilitypass.Finally,Seiskarietal.[2024]modelthemotion renderingartifacts.
blurandrollingshutterofthecamerabyapproximatingthemin Ourformulationtakesrootintheseprecursoryworks.However
screenspacethroughrasterizationwithpixelvelocities.Unlikethese asopposedto[Knolletal.2019],itisguaranteedtoprocessevery
works,weformulateaprincipledmethodforefficientraytracing particleintersectingtheray.Andcontraryto[BrÃ¼llandGrosch
ofvolumetricparticles,whichnativelyalleviatesallthelimitations 2020]thehitprocessingorderisconsistent,whichensuresthedif-
mentionedaboveandfurtherallowsustosimulateeffectssuchas ferentiabilityofourtracingalgorithm.
depthoffieldandperfectmirrors.4 â€¢ Moenne-Loccoz,Mirzaeietal.
Compared to rasterization, differentiable ray tracing of semi- Consideringğ›¼
ğ‘–
=ğœ ğ‘–ğœŒ ğ‘–(xğ‘–),Equation4canbeapproximatedusing
transparentparticleshasseenmuchlessprogressinrecentyears. numericalintegrationas
Perhapsthemostsimilarrenderingformulationtoourswaspro-
ğ‘ ğ‘–âˆ’1
posedinFuzzyMetaballs[KeselmanandHebert2022,2023],butit âˆ‘ï¸ (cid:214)
ğ‘³(ğ’,ğ’…)= ğ’„ğ‘–(ğ’…)ğ›¼
ğ‘–
1âˆ’ğ›¼ ğ‘—, (6)
islimitedtosceneswithasmallsetof3DGaussianparticles(several
ğ‘–=1 ğ‘—=1
tens)andimageswithverylowresolution.DifferenttoFuzzyMeta-
balls,ourmethodcaneasilyhandlesceneswithseveralmillionsof
whereinthislinearapproximation,xğ‘– isdefinedasthepointalong
particlesfromwhichitcanrenderfullHDimagesinreal-time. therayğ’“withthehighestresponseğœŒ ğ‘–oftheğ‘–thGaussian(see4.3for
moredetails).Forderivationsofthehigherorderapproximationsof
3 BACKGROUND ğœŒ ğ‘– pleasereferto[KeselmanandHebert2022].
Webeginwithashortreviewof3DGaussianscenerepresentation,
3.3 Hardware-AcceleratedRayTracing
volumetricparticlerendering,andhardware-acceleratedraytracing.
InthisworkweuseNVIDIARTXhardwarethroughtheNVIDIA
3.1 3DGaussianParameterization OptiXprogramminginterface[Parkeretal.2010].Throughthisin-
terface,geometricprimitivessuchastrianglemeshesareprocessed
ExtendingKerbletal.[2023],ourscenescanberepresentedasaset
ofdifferentiablesemi-transparentparticlesdefinedbytheirkernel
toconstructaBoundingVolumeHierarchy(BVH1).Thisacceleration
structureisoptimizedforthecomputationofray-primitiveinter-
function.Forexample,thekernelfunctionofa3DGaussianparticle
ğœŒ :R3â†’Ratagivenpointğ’™ âˆˆR3canbeexpressedas sectionsbydedicatedhardware,theRTcores.Theprogrammable
pipelinesendstraversalqueriestothishardware,freeingtheGPU
ğœŒ(ğ’™)=ğ‘’âˆ’(ğ’™âˆ’ğ)ğ‘‡ğšºâˆ’1(ğ’™âˆ’ğ), (1) streaming-multiprocessors(SMs)forthemaincomputationalload,
whereğ âˆˆR3representstheparticleâ€™spositionandğšºâˆˆR3Ã—3the e.gmaterialshading.TheinteractionsoftheSMswiththeRTcores
aredonethroughthefollowingprogrammableentrypoints:
covariancematrix.Toensurethepositivesemi-definitenessofthe
covariancematrixğšºwhenoptimizingitusinggradientdescent,we â€¢ ray-genprogram(raygeneration)iswheretheSMsmayiniti-
representitas ateascenetraversalforagivenray.
ğšº=ğ‘¹ğ‘‡ ğ‘ºğ‘‡ ğ‘ºğ‘¹ (2) â€¢ intersectionprogramiscalledduringthetraversaltocompute
withğ‘¹ âˆˆ SO(3) arotationmatrixandğ‘º âˆˆ R3Ã—3 ascalingmatrix. thepreciseintersectionwithpotentiallyhitprimitivesthatare
notdirectlysupportedbythehardware.
Thesearebothstoredastheirequivalentvectorrepresentations,
aquaternionğ’’ âˆˆ R4 fortherotationandavectorğ’” âˆˆ R3 forthe â€¢ any-hit programiscalledduringthetraversalforeveryhit
andmayfurtherprocessorrejectthehit.
scale.Forotherparticlevariantsexploredinthiswork,pleaserefer
toSection4.5. â€¢ closest-hit programiscalledattheendofthetraversal,for
furtherprocessingoftheclosestacceptedhit.
Eachparticleis furtherassociatedwithanopacitycoefficient
ğœ âˆˆ R, and a parametric radiance functionğœ™ (ğ’…) : R3 â†’ R3, â€¢ missprogramiscalledattheendofthetraversalforfurther
ğœ· processingwhennohithasbeenaccepted.
dependent on the view direction ğ’… âˆˆ R3. In practice, following
Kerbletal.[2023],weuseasphericalharmonicsfunctionsğ‘Œ â„“ğ‘š(ğ’…) Suchapipelineishighlyoptimizedtorenderopaqueprimitives,
oforderğ‘š = 3definedbythecoefficientsğœ· âˆˆ R48.Notethatwe i.e.thenumberofexpectedhitsduringatraversalislow,witha
areusingtheraydirectionwhileKerbletal.[2023]uses ğâˆ’ğ’ for minimalamountofinteractionsbetweentheSMsandtheRTcores.
âˆ¥ğâˆ’ğ’âˆ¥ Renderingvolumes,wheretheprimitivesaresemi-transparent,re-
performancereason.
quirestraversingandprocessingmanyhitsperray.Toefficiently
Thereforetheparametricradiancefunctioncanbewrittenas
traceavolume,specificapproachesmustbedesigned,tailoredto
(cid:32)â„“max â„“ (cid:33) thetypeofprimitives(orparticles),theirexpectedsize,anddistri-
ğœ™ ğœ·(ğ’…)=ğ‘“ âˆ‘ï¸ âˆ‘ï¸ ğ›½ğ‘š â„“ ğ‘Œ â„“ğ‘š (ğ’…) (3) butionacrossthevolume(seeforexample[Knolletal.2019]).In
â„“=0ğ‘š=âˆ’â„“ thisworkweproposeanefficientanddifferentiablealgorithmto
whereğ‘“ isthesigmoidfunctiontonormalizethecolors. raytraceavolumemadeofoptimizedsemi-transparentparticles
forhigh-fidelitynovelviewrendering.
3.2 DifferentiableRenderingofParticleRepresentations
Giventhisparametrization,thescenecanberenderedalongaray 4 METHOD
ğ’“(ğœ)=ğ’+ğœğ’…withoriginğ’ âˆˆR3anddirectionğ’… âˆˆR3viaclassical The proposed volumetric particle tracer requires two core com-
volumerendering ponents:astrategytorepresentparticlesinanaccelerationstruc-
ğ‘³(ğ’,ğ’…) =âˆ« ğœğœ ğ‘“ ğ‘‡(ğ’,ğ’…)(cid:16) (cid:205)
ğ‘–
(1âˆ’ğ‘’âˆ’ğœ ğ‘–ğœŒ ğ‘–(ğ’+ğœğ’…))ğ’„ğ‘–(ğ’…)(cid:17) ğ‘‘ğœ, (4) t au dr ae p( tB ivV eH b) ot uo ne dffi inc gie mn etl sy ht pe rs it mfo itr ivin et se (r Ss ee cc tt ii oo nns 4a .1g )a ,i an ns dtt ah re em n, du es rii nn gg
ğ‘›
whereğ’„ğ‘–(ğ’…) =ğœ™ ğœ·ğ‘–(ğ’…)isthecoloroftheğ‘–thGaussianobtainedby algorithmwhichcastsraysandgathersbatchesofintersections,
evaluatingitsview-dependantradiancefunction.Thetransmittance
1Forclarity,throughoutthisworkwereferenceBVHasthede-factohardwareaccel-
functionğ‘‡(ğ’,ğ’…)isdefinedas
erationstructure.However,sinceinpracticeNVIDIAOptiXâ€™sspecificationinterfaces
ğ‘‡(ğ’,ğ’…)=ğ‘’âˆ’âˆ« ğœğœ ğ‘›(cid:205) ğ‘–ğœğ‘–ğœŒğ‘–(ğ’+ğ‘¡ğ’…)ğ‘‘ğ‘¡
. (5)
t dh oe esim np ol te dm ee pn et na dtio on no af pb ao rt tt io cm ulal rev imel pa lc ec mel ee nra tati to ion ns .tructures,weemphasizeourpipeline3DGaussianRayTracing:FastTracingofParticleScenes â€¢ 5
Trace Against BVH and Get k-Closest Proxy Hits (Â§4.1) Evaluate Particle Response (Â§4.3) Update Radiance Integral
3D Particles Proxy Geometries and BVH (Â§4.1) Rendering
Repeat Until All Particles Evaluated or Transmiî€¼ance Theshold
Fig.3. OverviewoftheAcceleratedTracingAlgorithm:Givenasetof3Dparticles,wefirstbuildthecorrespondingboundingprimitivesandinsertthem
intoaBVH.Tocomputetheincomingradiancealongeachray,wetraceraysagainsttheBVHtogetthenextkparticles.Wethencomputetheintersected
particlesâ€™responseandaccumulatetheradianceaccordingtoEquation6.Theprocessrepeatsuntilallparticleshavebeenevaluatedorthetransmittance
meetsapredefinedthresholdandthefinalrenderingisreturned.
stretched +adaptive theboundingmeshtriggersprocessingofthecorrespondingpar-
axis-aligned icosahedron
icosahedron clamping
bounding box mesh ticle,asdescribedlaterinSection4.3.Wefittheboundingproxy
mesh (ours)
byspecifyingaminimumresponseğ›¼ whichmustbecaptured
min
(typicallyğ›¼ min = 0.01),andanalyticallycomputeananisotropic
rescalingoftheicosahedrontocoverthewholespacewithatleast
ğ›¼ response.Precisely,foreachparticleweconstructanicosahe-
min
dronwithaunitinner-sphere,andtransformeachcanonicalvertex
ğ’—accordingto:
false-positive
intersections ğ’— â†ğ’—âˆšï¸2log(ğœ/ğ›¼ min)ğ‘ºğ‘¹ğ‘‡ +ğ. (7)
Fig.4. ProxyGeometries:ExamplesofBVHprimitivesconsidered.
Importantly,thisscalingincorporatestheopacityoftheparticles,so
thatlargenearly-transparentparticlesmayhavesmallerbounding
efficientlyscheduledontotheNVIDIAOptiXtracingmodel(Sec- primitives,resultinginadaptiveclampingoftheparticles.
tion4.2).
4.2 RayTracingRenderer
4.1 BoundingPrimitives
Motivation. Giventheabilitytocastraysagainstparticles,volu-
Anyray-tracermustsomehowinserttheprimitiveparticlesinto metricrenderingasinEquation6requiresaccumulatingthecon-
a BVH and query the primitives intersected by a ray. The first tributionofparticlesalongtherayinasortedorder.Onenaiveap-
challengeisthentodecidehowtoinsertparticlesintoaBVHand proachwithintheNVIDIAOptiXprogrammingmodel(Section3.3)
conservativelytestintersectionagainstthem. istorepeatedlycasttheray,processthenearestparticlewitha
TheNVIDIAOptiXprogrammingmodelsupportsthreeprimi- closest-hit program,thenre-casttheraytofindthenextparticle.
tivetypeswhichcanbeinsertedintotheBVH:triangles,spheres, Anotheristotraversethesceneonlytwice,oncetoestimatethe
andcustomprimitivesgivenbytheiraxis-alignedboundingboxes transmittancefunction,andoncetothecomputetheintegralasin
(AABBs).Theseoptionsadmitmanypossiblestrategiestobuilda [MÃ¼nstermannetal.2018].Bothofthesestrategiesareprohibitively
BVHoverparticles,suchasconstructingnaiveaxis-alignedbounds expensive,duetothecostoftraversingthescene.
asAABBsorspheres,orbuildingboundingtrianglemeshes.These Ourrendererbuildsonpastapproachesfortracingsemi-transparent
strategieshaveatradeoffbetweenthecosttotestintersectionvs.the surfacesorparticles:Knolletal.[2019]repeatedgatherslabsof
tightnessofthebound.Forinstance,simplyintersectingaraywith particlesandsortwithineachslab,whileBrÃ¼llandGrosch[2020]
theAABBaroundeachparticleisfast,butadiagonally-stretched processallsemi-transparentsurfacesintoağ‘˜-buffer,mergingadja-
Gaussianparticleswillcausethetraversaltohavetoevaluatemany centparticleswhenthelistoverflows.Asdiscussedin2.3,becauseof
false-positiveintersectionswhichactuallycontributealmostnoth- theirapproximations,thesealgorithmsdonotproduceaconsistent
ingtotherendering.Noneofthesestrategiesnecessarilyaffectthe rendering,whichpreventsdifferentiationandgeneratesartifacts.
appearanceoftherenderedimage,butratherthecomputationspeed
andnumberoflow-contributionparticlesneedlesslyprocessed.Bill- Algorithm. Figure5,Figure3,Procedure1,andProcedure2sum-
marizeourapproach.Tocomputeincomingradiancealongeachray,
boardmeshproxiesareusedelsewhere[Niedermayretal.2023],
butdonotapplyinourgeneralsettingwhereraysmaycomefrom
aray-genprogramtracesarayagainsttheBVHtogatherthenext
anydirection.
ğ‘˜particles,usinganany-hitprogramtomaintainasortedbufferof
theirindices.Forefficiency,atthisstagetheparticleresponseisnot
StretchedPolyhedronProxyGeometry. Afterexperimentingwith yetevaluated;allprimitivehitsaretreatedasintersectedparticles.
manyvariants(Section5.2.1),wefinditmosteffectivetoencapsulate Theray-genprogramtheniteratesthroughthesortedarrayofprim-
particlesinastretchedregularicosahedronmesh(Figure4),which itivehits,retrievesthecorrespondingparticleforeach,andrenders
tightlyboundstheparticleandbenefitsfromhardware-optimized themaccordingtoEquation6.Theprocessthenrepeats,tracinga
ray-triangleintersections.Ahitagainstanyfront-facingtriangleof newrayfromthelastrenderedparticletogatherthenextğ‘˜particles.6 â€¢ Moenne-Loccoz,Mirzaeietal.
Ray
Ray Chunk Boundaries
Gaussian Center Procedure1Ray-Gen(ğ’,ğ’…,ğ‘‡ min,ğ›¼ min,ğ‘˜,ğœ SceneMin,ğœ SceneMax)
Max Response Along Ray
Input: rayoriginğ’,raydirectionğ’…,mintransmittanceğ‘‡ min,min
particleopacityğ›¼ ,hitbuffersizeğ‘˜,rayscenebounds
min
ğœ andğœ
SceneMin SceneMax
Output: rayincomingradianceğ‘³,raytransmittanceğ‘‡
1: ğ‘³â†(0.,0.,0.) âŠ²radiance
2: ğ‘‡ â†1. âŠ²transmittance
3: ğœcurrâ†ğœ SceneMin âŠ²Minimumdistancealongtheray
4: whileğœcurr <ğœ SceneMaxandğ‘‡ >ğ‘‡ mindo
âŠ²CastaraytotheBVHforthenextğ‘˜hits,sorted
5: H â†TraceRay(ğ’+ğœcurrğ’…,ğ’…,ğ‘˜)
6:
7: for(ğœ hit,ğ‘– prim)inH do âŠ²Renderthisbatchofhits
Fig.5. Rendering:oneachroundoftracing,thenextğ‘˜closesthitparticles 8: ğ‘– particleâ†GetParticleIndex(ğ‘– prim)
arecollectedandsortedintodepthorderalongtheray,theradianceis 9: ğ›¼ hitâ†ComputeResponse(ğ’,ğ’…,ğ‘– particle) âŠ²ğœğœŒ(ğ’+ğœğ’…)
computedin-order,andtherayiscastagaintoprocessthenextchunk.
10: ifğ›¼ hit >ğ›¼ minthen
11: ğ‘³hitâ†ComputeRadiance(ğ’,ğ’…,ğ‘– particle) âŠ²Referto
Theprocessterminatesonceallparticlesintersectingtherayare Equation3forSHevaluation
processed,orearly-terminatesassoonasenoughparticledensity 12: ğ‘³â†ğ‘³+ğ‘‡ âˆ—ğ›¼ hitâˆ—ğ‘³hit
isintersectedtoreachapredefinedminimumtransmittanceğ‘‡ min. 13: ğ‘‡ â†ğ‘‡ âˆ—(1âˆ’ğ›¼ hit)
Comparedtopastapproachesthisrendererallowsforprocessing 14: ğœcurrâ†ğœ hit âŠ²Resumetracingfromlasthit
theintersectioninaconsistentorder,withoutmissinganyparticle
15: endwhile
norapproximatingthetransmittance. 16: returnğ‘³,ğ‘‡
Nonetheless,thisproposedalgorithmisjustoneofmanypossible
variants, chosen for performance after extensive benchmarking.
See Section 5.2 for timings and ablations against a selection of Procedure2Any-Hit(ğœ hit,ğ‘– prim,H,ğ‘˜)
alternativesconsidered;wefindthatsubtlechangestothealgorithm
haveadramaticeffectofspeedandqualityondensely-clustered
Input: hitlocationğœ hit,primitiveindexğ‘– prim,hitarrayH,hitbuffer
sizeğ‘˜
multi-viewscenes.
Output: thehitarrayH maybeupdatedin-placewithanewentry
4.3 EvaluatingParticleResponse 1: hâ†(ğœ hit,ğ‘– prim)
After identifying ray-particle inter- 2: forğ‘–in0...ğ‘˜-1do âŠ²insertionsortintohitarray
sections,wemustchoosehowtocom- maximum orthogonal 3: ifH[ğ‘–].ğœ hit <â„.ğœ hitthen
putethecontributionofeachparticle response projection 4: swap(H[ğ‘–],â„)
to the ray. As with prior work, we 5: âŠ²ignoreğ‘˜-closesthitstopreventthetraversalfromstopping
takeasinglesampleperparticle,but 6: ifğœ hit <H[ğ‘˜âˆ’1].ğœ hitthen
westillmustchooseatwhatdistance bounding primitive 7: IgnoreHit()
ğœ alongtheraytoevaluatethatsam- intersection
ple.Knolletal.[2019]orthogonallyprojectthecenteroftheparticle
on to the ray; this strategy is reasonable for isotropic particles,
but can lead to significant error for stretched anisotropic parti- 4.4 DifferentiableRayTracingandOptimization
cles.Instead, weanalyticallycomputeasamplelocationğœmax =
DifferentiableRendering. Beyondforward-renderingofparticle
argmax ğœğœŒ(ğ’+ğœğ’…),thepointofmaximumresponsefromtheparti-
scenes,ourraytracingrendererisalsodifferentiable,tosupport
clealongtheray.ForGaussianparticles,thisbecomes
optimizingparticlescenesfromobserveddata.Tobackpropagate
(ğâˆ’ğ’)ğ‘‡ğšºâˆ’1 ğ’… âˆ’ğ’ğ‘‡ ğ‘”ğ’…ğ‘” (i.e.,reverse-modedifferentiate)throughtherendererwithrespect
ğœmax= ğ’…ğ‘‡ğšºâˆ’1
ğ’…
= ğ’…ğ‘”ğ‘‡
ğ’…ğ‘”
(8) t ro enp da er rti ac nle dp ca or mam pe ut te ers th,w ede efi sr irs et dpe or bf jo er cm tiva en fo ur nd ci tn ia or ny s.fo Tr hw enar ,d in-p ta hs es
whereğ’ğ‘” =ğ‘ºâˆ’1 ğ‘¹ğ‘‡(ğ’âˆ’ğ)andğ’…ğ‘” =ğ‘ºâˆ’1 ğ‘¹ğ‘‡ ğ’…. backwardpasswere-castthesameraystosamplethesamesetof
Notethatthisstrategyincursaslightapproximationintheor- particlesinorder,computinggradientswithrespecttoeachshading
dering:theparticlehitsareintegratedintheorderofthebounding expressionandaccumulatinggradientsinsharedbufferswithatomic
primitiveintersectionsinsteadoftheorderofthesamplelocations. scatter-addoperations.Weimplementedallderivativeexpressions
However,weempiricallyconfirmedthatthisapproximationdoes byhandinanNVIDIAOptiXray-genprogramwhichisstructurally
notleadtoanysubstantiallossinthequalityoftheendresult. similartoProcedure1.3DGaussianRayTracing:FastTracingofParticleScenes â€¢ 7
Optimization. Tofitparticlescenesusingourraytracer,weadopt
theoptimizationschemeofKerbletal.[2023],includingpruning,
cloningandsplittingoperations.Onesignificantchangeisneeded:
Kerbletal.[2023]trackscreen-spacegradientsofparticlepositions
3D Gaussian Generalized Gaussian (GG2)
asacriteriaforcloningandsplitting,butinourmore-generalsetting,
screenspacegradientsareneitheravailablenormeaningfulâ€”instead,
weusegradientsin3Dworld-spaceforthesamepurpose.Recent
Kernelized Surface (SGG2) Cosine Wave Modulation (CSGG2)
workhasproposedmanypromisingextensionstotheoptimization
(a) Particle Kernel Functions (b) Kernelized Surface Particles Reconstruction
scheme of Kerbl et al. [2023]. While our ray tracer is generally
compatiblewithanyoftheseextensions,westayfaithfultothe Fig.6. ParticleKernelFunctions:(a)Inadditionto3DGaussians,inthis
originalapproachforthesakeofconsistentcomparisons.Itshould workweinvestigatedthreeotherparticletypes:thegeneralizedGaussian
alsobenotedthatasparticlesareupdatedduringoptimization,the (GG2),kernelizedsurface(SGG2)andcosinewavemodulation(CSGG2)
raytracingBVHmustberegularlyrebuilt(seeFigure8,bottomleft particles.(b)Showsradianceandnormalreconstructionsobtainedwiththe
forBVHbuildtime). kernelizedsurfaceparticlesfortwoscenes.
TrainingwithIncoherentRays. Optimizationincomputervision
oftenbenefitsfromstochasticdescent,fittingtorandomly-sampled 5 EXPERIMENTSANDABLATIONS
subsetsofaproblemoneachiteration.However,differentiableras- Inthissectionweevaluatetheproposedapproachonseveralstan-
terizationcanonlyefficientlyrenderwholeimagesortiles,andthus dardbenchmarkdatasetsforqualityandspeed,andperformablation
efficientstochasticoptimizationoverthesetofpixelsinasceneis studiesonkeydesignchoicesinSection5.2.Additionaldetailson
notpossible.Inourraytracer,wearefreetotrainwithstochastically- experimentsandimplementationcanbefoundintheappendix.
sampledrays,drawnatrandomoraccordingtosomeimportance
samplingduringtraining,seeSection5.1.Notethatwhenstochastic MethodVariants. Intheexperimentsthatfollow,wewillrefer
sampling is used, window-based image objectives such as SSIM totwovariantsofourmethod.TheOurs(reference)variantcorre-
cannotbeused. spondsto[Kerbletal.2023]ascloselyaspossible.Itemploysregular
3DGaussianparticles,andleavestheoptimizationhyperparameters
4.5 ParticleKernelFunctions unchanged.Wetreatthisasahigh-qualityconfiguration.TheOurs
variantisadaptedbasedontheexperimentsthatfollow,improving
OurformulationdoesnotrequiretheparticlestohaveaGauss-
runtimespeedataslightexpenseofquality.Itusesdegree-2gen-
iankernel,enablingtheexplorationofotherparticlevariants.We
eralizedGaussianparticles,adensitylearningrateto0.09during
considerageneralparticledefinedbyitskernelfunctionğœŒË†(ğ’™).Inad-
optimizing,aswellasoptimizingwithincoherentraysinabatch
ditiontothestandardGaussian,weinvestigatethreeothervariants,
sizeof219startingafter15,000trainingiterations.
visualizedinFigure6:
â€¢ Thestandard3DGaussiankernelgiveninEquation1as 5.1 NovelViewSynthesisBenchmarks
ğœŒË†(ğ’™)=ğœğ‘’âˆ’(ğ’™âˆ’ğ)ğ‘‡ğšºâˆ’1(ğ’™âˆ’ğ), resB ea ars cel hin oe ns. scT eh ne er re epis rea ses nig tn ati ifi oc na .n Wt eam ino clu un dt eo cf omre pc ae rn it soa nn sd toon seg vo ei rn ag
l
representativewell-knownmethods,including3DGS[Kerbletal.
â€¢ GeneralizedGaussiansofdegreeğ‘›(weuseğ‘›=2):
2023],INGP[MÃ¼lleretal.2022],andMipNeRF360[Barronetal.
ğœŒË† ğ‘›(ğ’™)=ğœğ‘’âˆ’((ğ’™âˆ’ğ)ğ‘‡ğšºâˆ’1(ğ’™âˆ’ğ))ğ‘›. (9) 2022], as a standard for comparison. The latter two are widely-
usedray-marchingmethodsthat,likethiswork,donothavethe
â€¢ Kernelizedsurfaces:3DGaussianswithanullğ’›scaleasin[Huang limitationsofrasterization.Weadditionallycomparewiththenon-
etal.2024]. neuralmethodofPlenoxels[SaraFridovich-KeilandAlexYuetal.
â€¢ Cosinewavemodulations: 2022].
ğœŒË† ğ‘(ğ’™)=ğœŒË†(ğ’™)(0.5+0.5ğ‘ğ‘œğ‘ (ğœ“ğ‘¹ğ‘‡ ğ‘ºâˆ’1 (ğ’™âˆ’ğ))) (10) Evaluation Metrics. We evaluate the perceptual quality of the
novel-viewsintermsofpeaksignal-to-noiseratio(PSNR),learned
withğœ“ anoptimizableparameter. perceptualimagepatchsimilarity(LPIPS),andstructuralsimilarity
(SSIM)metrics.Toevaluatetheefficiency,wemeasureGPUtimere-
ComparativeevaluationswiththeseparticlesarepresentedinTa-
quiredforrenderingasingleimagewithouttheoverheadofstoring
ble3.ThegeneralizedGaussiankernelfunctiondefinesdenserpar-
thedatatoaharddriveorvisualizingtheminaGUI.Specifically,
ticles,reducingthenumberofintersectionsandincreasingtheper-
wereporttheperformancenumbersintermsofframes-per-second
formance by a factor of 2 compared to standard Gaussians, see
measuredonasingleNVIDIARTX6000Ada.Forallevaluations,
Section5.2.3formorediscussion.Thekernelizedsurfacevariant
weusethedataset-recommendedresolutionforevaluation.
definesflatparticleswithwell-definednormals,whichcanbeen-
capsulatedbyatwotriangleprimitive(Section4.1)well-adaptedto 5.1.1 MipNeRF360. MipNeRF360[Barronetal.2022]isachalleng-
ourtracingmodel.Finally,themodulationbyacosinewaveaimsto ingdatasetconsistingoflargescaleoutdoorandindoorscenes.In
modelaparticlewithspatiallyvaryingradiance. ourevaluation,weusethefourindoor(room,counter,kitchen,8 â€¢ Moenne-Loccoz,Mirzaeietal.
Ground Truth INGP 3DGS Ours (reference) Ours
Fig.7. Novel-ViewSynthesis:Qualitativecomparisonofournovel-viewsynthesisresultsrelativetobaselines(insets(â€¢)showper-resultcloseups).For
fairness,thiscomparisonusesthesametestviewspickedby[Kerbletal.2023].Additionalcomparisonswith[Barronetal.2022]areincludedintheappendix.3DGaussianRayTracing:FastTracingofParticleScenes â€¢ 9
Table1. Resultsforourapproachandbaselinesonavarietyofnovelviewsynthesisbenchmarks.
MipNeRF360 Tanks & Temples Deep Blending
Method\Metric PSNRâ†‘ SSIMâ†‘ LPIPSâ†“ Mem.â†“ PSNRâ†‘ SSIMâ†‘ LPIPSâ†“ Mem.â†‘ PSNRâ†‘ SSIMâ†‘ LPIPSâ†“ Mem.â†“
Plenoxels 23.63 0.670 0.443 2.1GB 21.08 0.719 0.379 2.3GB 23.06 0.795 0.510 2.7GB
INGP-Base 26.43 0.725 0.339 13MB 21.72 0.723 0.330 13MB 23.62 0.797 0.423 13MB
INGP-Big 26.75 0.751 0.299 48MB 21.92 0.745 0.305 48MB 24.96 0.817 0.390 48MB
MipNeRF360 29.23 0.844 0.207 8.6MB 22.22 0.759 0.257 8.6MB 29.40 0.901 0.245 8.6MB
3DGS(paper) 28.69 0.870 0.182 734MB 23.14 0.841 0.183 411MB 29.41 0.903 0.243 676MB
3DGS(checkpoint) 28.83 0.867 0.228 763MB 23.35 0.837 0.222 422MB 29.43 0.898 0.314 704MB
Ours(reference) 28.88 0.871 0.179 387MB 23.03 0.853 0.158 519MB 29.89 0.908 0.234 329MB
Ours 28.71 0.854 0.202 383MB 23.20 0.830 0.186 489MB 29.23 0.900 0.242 287MB
bonsai)andthreeoutdoor(bicycle,garden,stump)sceneswith- Table2. Renderingperformance:rasterizationv.s.raytracing.
outlicensingissues.Inlinewithpriorwork,weusedimagesdown-
FPSâ†‘
sampledbyafactortwofortheindoorandafactorfourforthe Method MipNeRF360 Tanks & Temples Deep Blending
outdoorscenesinallourevaluations.
3DGS(checkpoint) 238 319 267
Table1showsquantitativeresults,whilenovel-viewsarequal-
Ours(reference) 55 143 77
itatively compared in Figure 7. In terms of quality, our method Ours 78 190 119
performsonparorslightlybetterthan3DGS[Kerbletal.2023]and
otherstate-of-the-artmethods.
Forthisdataset,wealsocompareourmethodagainsttherecent Bothversionsofourmethodoutperformallthebaselinesinterms
top-tiermethodofZip-NeRF[Barronetal.2023]whichachieves ofPSNR.Infact,OursoutperformsOurs(reference)onsevenoutof
30.38PSNR.Intermsofruntime(Table2),at78FPSourefficient eightscenes.Weconjecturethisisduetothesimplicityofscenes
raytracingimplementationisapproximatelythreetimesslower whicharewellrepresentedwithlesshits,andthepositivecontribu-
thanrasterization(238FPS),whilemaintaininginteractivespeeds tionoftrainingwithincoherentrays.Onthesesimplersceneswith
comparedtohigh-qualityray-marchingbasedworksMipNeRF360 lowerresolutionimages,ourmethodiscapableofrenderingnovel
andZip-NeRF(<1FPS). viewsat450FPSandisonly50%slowerthan3DGS.
5.1.2 Tanks&Temples. Tanks & Templesdatasetcontainstwo 5.2 RayTracingAnalysisandAblations
largeoutdoorscenes(TruckandTrain)withaprominentobjectin
Weevaluatetheperformanceoftheproposedraytracerandcom-
thecenter,aroundwhichthecameraisrotating.Thesescenesare
paretoalternatives.Experimentsareevaluatedontheunionofall
particularlychallengingduetotheilluminationdifferencesbetween
validationdatasetsfromSection5.1.Wemeasureforwardrendering
individualframesaswellasthepresenceofdynamicobjects.
time,whichweobservedtocorrelatecloselywiththeper-iteration
SimilartotheresultsonMipNeRF360dataset,ourmethodagain
timeforthebackwardpass.
performsonparwiththestate-of-the-artmethodsintermsofquality,
whilethespeedisapproximately1.7timesslowerthan3DGSat190 5.2.1 ParticlePrimitives. Wefirstconsiderdifferentboundingprim-
FPS.QualitativeresultsaredepictedinFigure7.Onthisdataset, itivestrategiesasdiscussedinSection4.1.Theprimitivesevaluated
Ours achieves better PSNR than our Ours (reference), but is still are:
worseintermsofLPIPSandSSIM.Wehypothesizethatthisisdue
â€¢ CustomprimitiveAABBs:boundingboxprimitive,seeFig-
tothelackofSSIMlosssupervisionwhentrainingthemodelwith
ure4left.
incoherentrays.
â€¢ Octahedron:aneight-facedregularpolyhedronmesh.
5.1.3 Deep Blending. Following Kerbl et al. [2023], we use two
â€¢ Icosahedron:atwenty-facedregularpolyhedronmesh.
indoorscenesPlayroomandDrJohnsonfromtheDeep Blending
â€¢ Icosahedron+unclamped:icosahedronwithoutadaptive
clamping.
dataset. Table 1 shows that our reference implementation Ours
(reference)outperformsallbaselinesacrossallqualitativemetrics. ScalesaredeterminedasinEquation7,excepttheunclampedvariant
Differenttootherdatasets,weobservealargerqualitydropofOurs. whichomitstheopacityterminthatexpression.
ThisisaresultofaqualitydroponPlayroomwhereweobservedin- Figure8(bottom-left)showsthetimetobuildaBVHrelative
stabilityofthetrainingwithincoherentrays.Weleavemoredetailed tothenumberofparticlesforthedifferentprimitives.Forsimple
investigationandparametertuningofincoherentraystrainingfor AABBs, the build time is almost constant whereas for the more
futurework. complexicosahedronbasedprimitives,thebuildtimeiscloseto
linearwithmorethan30mspermillionsofparticles.Thesamefigure
5.1.4 NeRFSynthetic. NeRF Syntheticisacommonlyusedsyn- alsogivestheframeratevs.thenumberofparticlesfordifferent
theticobject-centringdatasetintroducedbyMildenhalletal.[2020]. primitives.First,thenumberofparticlesdoesnotstrictlydetermine
TheeightsceneswithsyntheticobjectswererenderedinBlender the performance. Second, more complex primitives with tighter
anddisplaystrongview-dependenteffectsandintricategeometry boundingenvelopesyieldhigherframerates,andadaptiveclamping
structures.SeeTable4intheappendixforaper-scenebreakdown. basedonopacityhasalargepositiveeffect.10 â€¢ Moenne-Loccoz,Mirzaeietal.
Table3. Qualityandspeedtradeoffsforvariousparticlekernelfunctions. 300 300 10
250 250 8
Tanks & Temples Deep Blending 200 200 Particle\Metric PSNRâ†‘ FPSâ†‘ PSNRâ†‘ FPSâ†‘ 6 150 150
Gaussian(reference) 23.03 143 29.89 77 100 100 4
GeneralizedGaussian(ğ‘›=2) 22.68 277 29.74 141 50 50 2
2DGaussians 22.70 241 29.74 122
Cosinewavemodulation 22.77 268 29.79 126 0 0 0
24 25 26 27 28 29 30 31 0 5 10 15 20 25 30
PSNR Hits array size
Baseline SLAB MLAT Performance False-rejected hits
Ours 2x2 Tiles Ours Stoch. Ours False-accepted hits
125 600
100
5.2.2 TracingAlgorithms. Weconsiderseveralalternativesofthe 57 05 500
proposedraytracerfromSection4.2,bothcomparisonstoprior 25 400
600 300
workandvariantsofourmethod.Theevaluatedapproachesare:
450 200
300
â€¢ Naiveclosest-hittracing:repeatedclosest-hitray-tracingto 150 100
traverseeveryparticlehittingtherayindepthorder. 0 1e6 0
0.0 0.5 1.0 1.5 2.0 2.5 3.0 0 5 10 15 20 25 30 35
â€¢ Slabtracing[Knolletal.2019](SLAB):tracingoneray Number of particles Mean hits per ray
per slab, order independent collection of theğ‘˜-first hits in C Ou cs tato hm edron I Ic co os sa ah he ed dr ro on n Unclamped Gaussian Generalized Gaussian
theany-hitprogram,sortingandintegratingthehitsinthe Fig.8. QuantitativeAblation.Topleft:comparisonofthedifferenttracing
ray-genprogram. algorithmsonthecombinationofourdatasets.Topright:Impactofthehit
â€¢ Multi-layeralphatracing[BrÃ¼llandGrosch2020](MLAT): payloadbuffersizeonourproposedtracingalgorithm.Bottomleft:Impact
tracingasingleraywithindepthordercollectionofthehits ofthedifferentprimitivesonboththeBVHbuildingtimeandtheFPS.
Bottomright:Meannumberofhitsvs.meanFPSforeverysequenceofour
andmergingtheclosesthitswhentheğ‘˜ bufferisfullinthe
dataset.
any-hitprogram.
â€¢ Ourproposedmethod:tracingadynamicnumberofrays
within-ordercollectionofthehits,stoppingtoevaluatecon-
tributionswhentheğ‘˜bufferisfullintheany-hitprogram. Figure8(bottom-right)showsthemean-hitsnumberversusthe
â€¢ Ours+tiledtracing:tracingonerayperğ‘ Ã—ğ‘ tile,butstill performancefortheGaussiankernelandthegeneralizedGaussian
evaluatingappearanceperpixel,akintotile-basedrasteriza- kernelofdegree2.Itreaffirmsthattheperformancedependsonthe
tion. numberofhitsratherthanthenumberofparticles,asnotedprevi-
â€¢ Ours + stochastic depth sampling: tracing a single ray ously.Thisexplainsthesourceofthespeedupforthegeneralized
with in depth order collection of theğ‘˜ first accepted sam- Gaussiankernel,asthesharperextentreducesthenumberofhits.
ples.Samplesareacceptedbasedontheimportancesampling SeeFigure9foravisualplot.
ğ‘(ğ’™)=ğœŒË†(ğ’™).
5.2.4 HitBufferSize. Figure8(top-right)measurestheeffectof
Foreachalgorithmswithachoiceofparameters(sizeofthearray, theparticlebuffersizeğ‘˜,whichdetermineshowmanyparticlehits
numberofslabs,ornumberofsamples),weperformaparameter aregatheredduringeachraycastbeforestoppingtoevaluatetheir
sweepandpresentthebest-performingsetting. response.Falserejectedhitsarehitswhicharetraversed,butnot
Theperformancerelativetotheaccuracyoftheseimplementa- collectedintothebufferbecauseitisfullwithcloserhits;thesehits
tionsareshowninthetop-leftofFigure8.Naiveclosest-hittracing oftenmustbere-traversedlater.Falseacceptedhitsarehitswhichare
isalmosttwiceasslowasourmethod,duetoover-traversalofthe gatheredintothebuffer,butultimatelydonotcontributetoradiance
BVH.Slabtracingandmulti-layeralphatracingaredesignedto becausethetransmittancethresholdisalreadymet.Bothofthese
minimizeover-traversalandhenceachievemuchbetterruntime falsehitsharmperformance,andchoosingtheparticlebatchsizeis
performance,butthisspeedcomesfromapproximateimageforma-
tion(orderingapproximationforMLAT,under-samplingparticles
forSLAB),andtheaccuracyofthesemethodsissubstantiallylower.
Inthedifferentiablesetting,wefindthatthesetheseapproxima-
tionsmakethosemethodsunusableforoptimizingscenes.Adding
tile-basedrenderingtoourapproachyieldsapromisingspeedup,at
thecostofasmallapproximation.Wedonotseeimmediatebenefit
fromstochasticdepthsampling,becausemostofthecomputation
hastobedoneintheany-hitprogram,preventingagoodbalance
ofthetracingworkload.
0 10 20 30 40 50
5.2.3 ParticleKernelFunction. InSection4.5weconsiderparticle ray hit counts
kernelfunctionsbeyondGaussians.Table3givesresults;notably Fig.9. RayHitsforKernelFunctions:Visualizationofthenumberof
generalizedGaussianswithğ‘›=2significantlyincreaseraytracing per-rayparticleshitsfortheGaussian(left)andforthegeneralizedGaussian
speedatonlyasmallcostofquality. kernelfunctionofdegree2(right)(â€¢representsnohits).
SPF
]sm[
dliub
HVB
SPF
SPF
SPF
stih
desrevart-revO3DGaussianRayTracing:FastTracingofParticleScenes â€¢ 11
Ground Truth Ours - 0 Iterations (0%) Ours - 600 Iterations (2%) Ours - 2000 Iterations (6.7%) 3DGS
PSNR: 18.67 PSNR: 26.15 PSNR: 26.80 PSNR: 27.41
PSNR: 23.37 PSNR: 30.52 PSNR: 31.19 PSNR: 30.32
PSNR: 18.43 PSNR: 24.54 PSNR: 25.15 PSNR: 25.19
Fig.10. 3DGSFinetuning:Qualitativeresultsoffinetunedmodelsfrompretrained3DGS[Kerbletal.2023]checkpointsafterdifferentnumbersofiterations.
0.5 particles.Precisely,wemaintainanextraaccelerationstructurecon-
0.0 sistingonlyofmeshfacesforadditionalinsertedgeometry.When
0.5 castingeachrayinProcedure1,wefirstcastraysagainstinserted
1.0 meshes;ifameshishit,werenderallparticlesonlyuptothehit,and
1.5 thencomputearesponsebasedonthematerial.Forrefractionsand
2.0 reflections,thismeanscontinuingtracingalonganewredirected
2.5 rayaccordingtothelawsofoptics.Fornon-transparentdiffused
3.0 meshes,wecomputethecolorandblenditwiththecurrentray
0 250 500 750 1000 1250 1500 1750 2000 radiance,thenterminatetheray.
Number of iterations
MipNeRF360 Tanks & Temples Deep Blending
DepthofField. Following[MÃ¼lleretal.2022],wesimulatedepth
Fig.11. FinetuningPretrained3DGSModels:Afteronly500iterations offieldbyprogressivelytracingmultipleindependentraysamples
offinetuning,wecanrecovermostoftheperceptualqualityof3DGS[Kerbl
perpixel(spp),weightedtogetherwithamovingaveragetodenoise
etal.2023].After2kiterationswematchoroutperform3DGSacrossall
the output image. The examples in Figures 2 and 12 use 64-256
datasets.
spp,althoughconvergenceisoftenreachedwithfewersamplesby
selectingsubsampleswithlowdiscrepancysequences[Burley2020].
atradeoffbetweenthem.Wefindğ‘˜ =16toofferagoodcompromise
ArtificialShadows. Eveninradiancefieldsceneswithbaked-in
anduseitinallotherexperiments.
lighting,simpleshadoweffectscanbeemulatedbycastingaray
towards a point or mesh emitter, and artificially darkening the
6 APPLICATIONS
contributionfromthatpointifthelightisnotvisible.Weadopt
Mostimportantly,efficientdifferentiableraytracingenablesnew
thisapproach,castingshadowraysaftercomputingthedirectional
applicationsandtechniquestobeappliedtoparticlescenerepresen-
contributionfromeachparticle.
tations.
6.2 Instancing
6.1 Ray-BasedEffects
First,wetheradiancefieldrenderingpipelinewithavarietyofvisual In rendering, instancing is a technique to render multiple trans-
formed copies of an object with greatly reduced cost. Although
effectswhicharenaturallycompatiblewithraytracing(Figure2
renderinglibrariesmaysupportsomeformofinstancinginthe
and 12). Here we demonstrate only manually-specified forward
contextofrasterization,thetechniqueisparticularlyeffectivefor
rendering,althoughinverserenderinginconcertwiththeseeffects
ray tracing. This is because repeated copies of an object can be
isindeedsupportedbyourapproach,andisapromisingareafor
storedaslinkedreferencesinsubtreesoftheBVH,withoutactually
ongoingwork.
duplicatingthegeometry.Thisallowsforscalingto100sor1000sof
Reflections,RefractionsandInsertedMeshes. Opticalrayeffectsare instancedobjectsatlittleadditionalcostâ€”thesameisnotpossible
supportedbyinterleavedtracingoftriangularfacesandGaussian withrasterization.Ourefficientraytracerenablesparticlescene
)SGD3
-
sruo(
RNSP
âˆ†12 â€¢ Moenne-Loccoz,Mirzaeietal.
Fig.12. RenderingEffects:Theraytracednatureofourreconstructionsallowsseamlessintegrationwithtraditionalraytracedoperationsforreflectingand
refractingrays,aswellascastingshadowsonnearbyparticles,aswellasapplyingcameraeffects.
datatobeinstanced,asshowninFigure13wherewecropanobject
fromafittedsceneandrender1024copiesofitat25FPS.
6.3 DenoisingandStochasticSampling
Inraytracingmorebroadly,researchonstochasticintegrationtech-
niquesiskeytohighlysample-efficientyetperceptuallycompelling
renders.Asasmalldemonstration,weshowhowourapproachcan
becombinedwithstochasticsamplinganddenoising.
AsdiscussedinSection5.2.2,ourapproachmaybeextendedto
stochastic-samplingbyrejectingthehitsreceivedintheany-hit
programbasedontheimportancesamplingdistributionğ‘=ğœŒË†(ğ’™).
Sincetraversalstopsassoonastheğ‘˜-closestacceptedsamplesare
collected,thismodificationnoticeablyimprovesperformance(see
Fig.13. Instancing:1024instancesoftheTank & TemplesTruck,rendered
Figure8top-left).Thisperformancecomesataqualitycost,but
atmorethan25FPS.
as shown in Figure 14, the resulting noise has statistics that an
off-the-shelfdenoisercaneasilyremove.3DGaussianRayTracing:FastTracingofParticleScenes â€¢ 13
correctlyreconstructingimportantgeometries,suchasthesignpost
inFigure16.
7 DISCUSSION
7.1 DifferencesBetweenRayTracingandRasterization
Here, we recap key differences between our ray tracer and the
GaussiansplattingrasterizerproposedbyKerbletal.[2023].
Generality. Splatrasterizationacceleratesrenderingbyprocess-
ingascreengridofpixelraysemanatingfromasingleviewpointin
16ğ‘¥16tiles,whereasraytracingusesaBVHandcanrenderalong
arbitrarydistributionsofraysfromanydirection.
Primaryvs.GeneralRays. Asingraphicsmorebroadly,raytracing
Fig.14. StochasticSampling:Left,scenerenderedwithourproposed hassignificantbenefitsoverrasterizationtomodelgenerallighting
algorithm.Center,renderedwithstochasticsampling(4samples).Right,
andimageformation.Inthiswork,wedemonstrateavarietyof
denoisedwiththeNVIDIAOptiXdenoiser.
effectssuchasreflection,refraction,depthoffield,andartificial
shadowsenabledbyraytracing(Section6.1).Inaddition,wenote
thatdifferentiableraytracingopensthedoortofurtherresearchon
globalillumination,inverselighting,andphysicalBSDFs.
6.4 ComplexCamerasandAutonomousVehicleScenes
Raytracingmakesiteasy,efficient,andaccuratetorenderfrom ComplexCameras. Usingper-pixelrays,raytracingcaneasily
exoticcameraswhicharefarfromidealpinholes,suchashighly- modelmoregeneralimageformationprocessesthatexhibitnon-
distorted fisheye cameras and those with rolling shutter effects linearopticalmodelssuchashighly-distortedandhigh-FOVfisheye
(Figure15).Whileopticaldistortionsforlow-FOVlensescanbe lenses,aswellastime-dependenteffectslikerollingshutterdis-
tackledtosomeextentbyimagerectification,androllingshutter tortions,whichoriginatefromrows/columnsexposedatdifferent
distortions can be approached by associating rasterized tiles to timestamps(cf.[Lietal.2024b]).Theseareimportantforrobotics
row/columnswithconsistenttimestamps,bothworkaroundscanâ€™t (Section6.4),yetdifficultorimpossibletomodelwithtile-based
beappliedsimultaneously,asimagerectificationdistortsthesetsof rasterization.
concurrentlymeasuredpixelsinanon-linearway.Inraytracing,
Speed. Althoughourraytracingrenderachievesrealtimeperfor-
handlingcomplexcamerassimplymeansgeneratingeachraywith
mance,rasterizationremainsfasterthanraytracingforthebasic
sourceanddirectionwhichactuallycorrespondtotheunderlying
caseofrenderingprimaryraysfrompinholecameras(seeTable2).
camera,evenifthoseraysmaybeincoherentandlackashared
origin. Sub-PixelBehavior. Splatrasterizationimplicitlyappliesapixel-
scaleconvolutiontoGaussians[Zwickeretal.2001],whereasour
AutonomousVehicles. Theimagingsystemsusedonautonomous raytracertrulypoint-samplestherenderingfunctionandhasno
vehicle(AV)platformsandotherrobotsystemsoftenincorporate suchautomaticantialiasing.Thismayleadtodifferencesofren-
suchcameras,anditisveryimportanttoreconstructandrender deredappearanceforsubpixel-skinnyGaussianparticles.However,
themaccuratelyinthoseapplications.Figure16,givesanexample point-sampledrenderingiswell-suitedtomoderndenoisers(seeSec-
ofanautonomousdrivingscenereconstructedfromaside-mounted tion6.3).
camera,whichexhibitsbothapparentintrinsiccameraandrolling
Interoperability. Itispossibletodirectlyrenderscenestrained
shutterdistortioneffects.
withtherasterizerundertheraytracingrenderer,howeverdueto
Tofurtherhighlighttheimportanceofaccuratelyhandlingthese
subtledifferencesnotedabove,therewillbeanoticeabledropin
effects,weperformaquantitativeevaluationofourmethodagainst
qualitywhendirectlyswitchingbetweenrenderers.Thiscanbe
itsrasterizationequivalent3DGS[Kerbletal.2023]onautonomous
quicklyremediedwithfine-tuning(seeFigure11).
drivingscenes.Weselect9scenesfromtheWaymo Open Perception
dataset[Sunetal.2020]withnodynamicobjectstoensureaccurate Approximations. Rasterizationmakesanapproximationbyeval-
reconstructions.Bothmethodsaretrainedwiththeimagescaptured uatingdirectionalappearancethroughthesphericalharmonicsğœ·
bythecameramountedonthefrontofthevehicletoreconstruct fromasingleraydirection,meaningeachparticlehasconstantap-
the scene. We make several changes to the training protocol to pearancedirectioninallpixelsofanimage.Tosupportarbitrary
adaptittothisdata,includingincorporatinglidardepth,seethe distributionsofraysinourraytracer,eachparticleisevaluated
appendixfordetails.Forthecaseof3DGS,werectifytheimagesand exactlywiththeappropriateincomingraydirection.Additionally,
ignoretherollingshuttereffects,whilewithourtracingalgorithm rasterizationapproximatesdepthorderingin16x16tiles.
we can make use of the full camera model and compensate for
7.2 LimitationsandFutureWork
the rolling shutter effect (see Figure 16). Ray tracing achieves a
rectifiedPSNRof29.99onthisbenchmark,comparedto29.83for Ourraytraceriscarefullydesignedtomakeuseofhardwareacceler-
ordinary3DGSâ€”theimprovementismodest,butitcorrespondsto ationandofferssignificantspeedupoverbaselineimplementations14 â€¢ Moenne-Loccoz,Mirzaeietal.
ğ‘“4 ğ‘“3 ğ‘“2 ğ‘“1 ğ‘“0
PerspectiveGT(Unseen) CameraMotionDirections
Reconstructions(NovelViews)
PSNR:40.53
FisheyeInputs RReeccoonnsstrtruucctitoionn(P(PeresrpsepcetcivtieveV)iew) OursPSNR:25.47 ğ‘“ğ‘›+1 ğ‘“ğ‘›+2 ğ‘“ğ‘›+3 ğ‘“ğ‘›+4 ğ‘“ğ‘›+5
(a)NonlinearCameraModels (b)RollingShutterMotionCompensation
Fig.15. ComplexCameras:(a)Comparedtorasterization-basedapproaches,ourraytracing-basedformulationnaturallysupportscomplexcameramodels
asinputslikedistortedfisheyelenses(left),whichcanbere-renderedusingdifferentcameramodelslikeregularperspectivecameras(right),achievinghigh
reconstructionqualityrelativetounseenreferences(seeinsets(â€¢)-thissyntheticcozyroomsceneisby[Maetal.2021]).(b)Raytracingalsonaturallyenables
compensatingfortime-dependenteffectslikerollingshutterimaginesensors,whichinducedistortionsduetosensormotion.Thiseffectisillustratedonthe
leftbymultipledifferentframetilesğ‘“ğ‘–ofasinglesolidboxrenderedbyaleft-andright-panningrollingshuttercamerawithatop-to-bottomshutterdirection.
Byincorporatingtime-dependentper-pixelposesinthereconstruction,ourmethodfaithfullyrecuperatesthetrueundistortedgeometry(right).
reconstructionfromcomputervisionwiththeformulationsforpho-
torealisticrenderingfromcomputergraphics.
DistortedInputs
REFERENCES
Reconstruction(Perspective)
MaksimAizenshtein,NiklasSmal,andMorganMcGuire.2022.WaveletTransparency.
CoRRabs/2201.00094(2022).arXiv:2201.00094 https://arxiv.org/abs/2201.00094
Kara-AliAliev,ArtemSevastopolsky,MariaKolos,DmitryUlyanov,andVictorLem-
pitsky.2020. Neuralpoint-basedgraphics.InComputerVisionâ€“ECCV2020:16th
EuropeanConference,Glasgow,UK,August23â€“28,2020,Proceedings,PartXXII16.
Springer,696â€“712.
JonathanT.Barron,BenMildenhall,MatthewTancik,PeterHedman,RicardoMartin-
Brualla,andPratulP.Srinivasan.2021.Mip-NeRF:AMultiscaleRepresentationfor
Reconstruction(Fisheye,StaticPose,PSNR:28.05) Reconstruction Input Anti-AliasingNeuralRadianceFields.ICCV(2021).
JonathanT.Barron,BenMildenhall,DorVerbin,PratulP.Srinivasan,andPeterHedman.
Fig.16. AVSceneReconstruction:Real-worldAVandroboticsapplica-
2022.Mip-NeRF360:UnboundedAnti-AliasedNeuralRadianceFields.CVPR(2022).
tionsoftenhavetorespectbothdistortedintrinsiccameramodelsandare, JonathanT.Barron,BenMildenhall,DorVerbin,PratulP.Srinivasan,andPeterHedman.
atthesametime,affectedbytime-dependenteffectslikerollingshutter 2023.Zip-NeRF:Anti-AliasedGrid-BasedNeuralRadianceFields.arXiv(2023).
distortionsasframesareexposedathighsensorspeeds.Ourraytracing- LouisBavoil,StevenP.Callahan,AaronLefohn,JoÃ£oL.D.Comba,andClÃ¡udioT.Silva.
basedreconstructioniswell-suitedtohandlebothchallengessimultaneously, 2 fo0 r07 C. oM mu pl uti t- if nr gag Mm ae cn ht ine eff re yc ,t Nso ewnt Yh oe rG k,P NU Yu ,s Uin SAg ,th 9e 7â€“k 1- 0b 4u .ffe hr t( tI p3 sD ://â€™ d07 o) i. .oA rgss /o 10ci .1a 1ti 4o 5n
/
whichweillustratedbyanexampleofaside-facingtop-to-bottomrolling 1230100.1230117
shuttercameraonanAVvehicle:thetopinset(â€¢)depictsfaithfulremoval FelixBrÃ¼llandThorstenGrosch.2020.Multi-LayerAlphaTracing.InVision,Modeling,
oftheintrinsiccameramodeldistortionbyrenderingwithanundistorted andVisualization,JensKrÃ¼ger,MatthiasNiessner,andJÃ¶rgStÃ¼ckler(Eds.).The
EurographicsAssociation. https://doi.org/10.2312/vmv.20201183
camera,whilethebottominset(â€¢)showsourabilitytoremovetheapparent
ChrisBuehler,MichaelBosse,LeonardMcMillan,StevenGortler,andMichaelCohen.
rolling-shutterdistortionsoftheinputsbyrenderingfromastaticcamera 2001.UnstructuredLumigraphRendering.InProceedingsofthe28thAnnualConfer-
pose(linearindicators(â€¢)exemplifythecomplexdistortionoftheinputs). enceonComputerGraphicsandInteractiveTechniques(SIGGRAPHâ€™01).Association
forComputingMachinery,NewYork,NY,USA,425â€“432.
BrentBurley.2020.PracticalHash-basedOwenScrambling.JournalofComputerGraph-
(Figure 8), however ray tracing is still slower than rasterization
icsTechniques(JCGT)10,4(29December2020),1â€“20. http://jcgt.org/published/
0009/04/01/
whenrenderingfromapinholecamera.Additionally,theneedto AbeDavis,MarcLevoy,andFredoDurand.2012.UnstructuredLightFields.Comput.
regularlyrebuildtheBVHduringtrainingincursadditionalcostand Graph.Forum31,2pt1(2012),305â€“314.
PaulE.Debevec,CamilloJ.Taylor,andJitendraMalik.1996.ModelingandRendering
addsoverheadtodynamicscenes.Nonetheless,ourimplementation ArchitecturefromPhotographs:AHybridGeometry-andImage-BasedApproach.
isstillfastenoughfortrainingandinteractiverendering,andmore InProceedingsofthe23rdAnnualConferenceonComputerGraphicsandInteractive
importantlyitopensthedoortomanynewcapabilitiessuchas Techniques(SIGGRAPHâ€™96).AssociationforComputingMachinery,11â€“20.
DanielDuckworth,PeterHedman,ChristianReiser,PeterZhizhin,Jean-FranÃ§oisThib-
distortedcamerasandray-basedvisualeffects(Section6).SeeSec- ert,MarioLuÄiÄ‡,RichardSzeliski,andJonathanT.Barron.2023.SMERF:Stream-
tion7.1foranin-depthdiscussionofthetrade-offsofrasterization ableMemoryEfficientRadianceFieldsforReal-TimeLarge-SceneExploration.
arXiv:2312.07541[cs.CV]
vs.raytracinginthissetting.
ZhiwenFan,KevinWang,KairunWen,ZehaoZhu,DejiaXu,andZhangyangWang.
Lookingforward,thisworkcreatesgreatpotentialforfurther 2023.LightGaussian:Unbounded3DGaussianCompressionwith15xReduction
researchoninverserendering,relighting,andmaterialdecomposi- and200+FPS. arXiv:2311.17245[cs.CV]
JianGao,ChunGu,YoutianLin,HaoZhu,XunCao,LiZhang,andYaoYao.2023.Re-
tiononparticlerepresentations.Indeed,recentworkinthisdirec- lightable3DGaussian:Real-timePointCloudRelightingwithBRDFDecomposition
tion[Gaoetal.2023;Liangetal.2023],hasreliedonapproximations andRayTracing.arXiv:2311.16043(2023).
due to the lack of an efficient ray tracer. More broadly, there is StevenJ.Gortler,RadekGrzeszczuk,RichardSzeliski,andMichaelF.Cohen.1996.The
Lumigraph.InProceedingsofthe23rdAnnualConferenceonComputerGraphics
muchpromisingresearchtobedoneunifyingadvancesinscene andInteractiveTechniques(SIGGRAPHâ€™96).AssociationforComputingMachinery,3DGaussianRayTracing:FastTracingofParticleScenes â€¢ 15
43â€“54. Tombari.2024.RadSplat:RadianceField-InformedGaussianSplattingforRobust
JeffreyPGrossmanandWilliamJDally.1998.Pointsamplerendering.InRendering Real-TimeRenderingwith900+FPS.arXivpreprintarXiv:2403.13806(2024).
Techniquesâ€™98:ProceedingsoftheEurographicsWorkshopinVienna,Austria,June JulianOst,IssamLaradji,AlejandroNewell,YuvalBahat,andFelixHeide.2022.Neural
29â€”July1,19989.Springer,181â€“192. pointlightfields.InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
AntoineGuÃ©donandVincentLepetit.2023.SuGaR:Surface-AlignedGaussianSplatting PatternRecognition.18419â€“18429.
forEfficient3DMeshReconstructionandHigh-QualityMeshRendering. arXiv PanagiotisPapantonakis,GeorgiosKopanas,BernhardKerbl,AlexandreLanvin,and
preprintarXiv:2311.12775(2023). GeorgeDrettakis.2024.ReducingtheMemoryFootprintof3DGaussianSplatting.
BinbinHuang,ZehaoYu,AnpeiChen,AndreasGeiger,andShenghuaGao.2024.2D InProceedingsoftheACMonComputerGraphicsandInteractiveTechniques,Vol.7.
GaussianSplattingforGeometricallyAccurateRadianceFields.SIGGRAPH(2024). StevenG.Parker,JamesBigler,AndreasDietrich,HeikoFriedrich,JaredHoberock,
PushkarJoshi,MarkMeyer,TonyDeRose,BrianGreen,andTomSanocki.2007.Har- DavidLuebke,DavidMcAllister,MorganMcGuire,KeithMorley,AustinRobison,
monicCoordinatesforCharacterArticulation.ACMTrans.Graph.26,3(jul2007), andMartinStich.2010.OptiX:AGeneralPurposeRayTracingEngine.ACMTrans.
71â€“es. https://doi.org/10.1145/1276377.1276466 Graph.29,4,Article66(jul2010),13pages. https://doi.org/10.1145/1778765.1778803
MichaelM.Kazhdan,MatthewBolitho,andHuguesHoppe.2006. PoissonSurface HanspeterPfister,MatthiasZwicker,JeroenVanBaar,andMarkusGross.2000.Surfels:
Reconstruction.InProceedingsoftheFourthEurographicsSymposiumonGeometry Surfaceelementsasrenderingprimitives.InProceedingsofthe27thannualconference
Processing(SGPâ€™06,Vol.256).EurographicsAssociation,61â€“70. onComputergraphicsandinteractivetechniques.335â€“342.
MichaelM.KazhdanandHuguesHoppe.2013.Screenedpoissonsurfacereconstruction. ChristianReiser,StephanGarbin,PratulP.Srinivasan,DorVerbin,RichardSzeliski,Ben
ACMTrans.Graph.32,3(2013),29:1â€“29:13. Mildenhall,JonathanT.Barron,PeterHedman,andAndreasGeiger.2024.Binary
BernhardKerbl,GeorgiosKopanas,ThomasLeimkÃ¼hler,andGeorgeDrettakis.2023. OpacityGrids:CapturingFineGeometricDetailforMesh-BasedViewSynthesis.
3DGaussianSplattingforReal-TimeRadianceFieldRendering.ACMTransactionson SIGGRAPH(2024).
Graphics42,4(July2023).https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/ ChristianReiser,SongyouPeng,YiyiLiao,andAndreasGeiger.2021.KiloNeRF:Speed-
BernhardKerbl,AndreasMeuleman,GeorgiosKopanas,MichaelWimmer,Alexandre ingupNeuralRadianceFieldswithThousandsofTinyMLPs.InInternational
Lanvin,andGeorgeDrettakis.2024.AHierarchical3DGaussianRepresentationfor ConferenceonComputerVision(ICCV).
Real-TimeRenderingofVeryLargeDatasets.ACMTransactionsonGraphics43,4 ChristianReiser,RichardSzeliski,DorVerbin,PratulPSrinivasan,BenMildenhall,
(July2024). https://repo-sam.inria.fr/fungraph/hierarchical-3d-gaussians/ AndreasGeiger,JonathanTBarron,andPeterHedman.2023.Merf:Memory-efficient
LeonidKeselmanandMartialHebert.2022. ApproximateDifferentiableRendering radiancefieldsforreal-timeviewsynthesisinunboundedscenes.arXivpreprint
withAlgebraicSurfaces.InEuropeanConferenceonComputerVision(ECCV). arXiv:2302.12249(2023).
LeonidKeselmanandMartialHebert.2023. Flexibletechniquesfordifferentiable KonstantinosRematas,AndrewLiu,PratulP.Srinivasan,JonathanT.Barron,Andrea
renderingwith3dgaussians.arXivpreprintarXiv:2308.14737(2023). Tagliasacchi,ThomasFunkhouser,andVittorioFerrari.2022.UrbanRadianceFields.
AaronKnoll,R.KeithMorley,IngoWald,NickLeaf,andPeterMessmer.2019.Efficient InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition
ParticleVolumeSplattinginaRayTracer. Apress,Berkeley,CA,533â€“541. https: (CVPR).12932â€“12942.
//doi.org/10.1007/978-1-4842-4427-2_29 KeruiRen,LihanJiang,TaoLu,MulinYu,LinningXu,ZhangkaiNi,andBoDai.
GeorgiosKopanas,JulienPhilip,ThomasLeimkÃ¼hler,andGeorgeDrettakis.2021. 2024.Octree-GS:TowardsConsistentReal-timeRenderingwithLOD-Structured
Point-BasedNeuralRenderingwithPer-ViewOptimization. ComputerGraphics 3DGaussians.arXivpreprintarXiv:2403.17898(2024).
Forum(ProceedingsoftheEurographicsSymposiumonRendering)40,4(June2021). LiuRen,HanspeterPfister,andMatthiasZwicker.2002. ObjectspaceEWAsurface
http://www-sop.inria.fr/reves/Basilic/2021/KPLD21 splatting:Ahardwareacceleratedapproachtohighqualitypointrendering.In
ChristophLassnerandMichaelZollhÃ¶fer.2021.Pulsar:EfficientSphere-basedNeural ComputerGraphicsForum,Vol.21.WileyOnlineLibrary,461â€“470.
Rendering.2021IEEE/CVFConferenceonComputerVisionandPatternRecognition GernotRieglerandVladlenKoltun.2020.FreeViewSynthesis.InEuropeanConference
(CVPR)(2021),1440â€“1449. onComputerVision.
MarcLevoyandPatHanrahan.1996.LightFieldRendering.InProceedingsofthe23rd GernotRieglerandVladlenKoltun.2021.StableViewSynthesis.InProceedingsofthe
AnnualConferenceonComputerGraphicsandInteractiveTechniques(SIGGRAPH IEEEConferenceonComputerVisionandPatternRecognition.
â€™96).AssociationforComputingMachinery,31â€“42. DariusRÃ¼ckert,LinusFranke,andMarcStamminger.2022.Adop:Approximatedif-
Moyang Li, Peng Wang, Lingzhe Zhao, Bangyan Liao, and Peidong Liu. ferentiableone-pixelpointrendering. ACMTransactionsonGraphics(ToG)41,4
2024b. USB-NeRF:UnrollingShutterBundleAdjustedNeuralRadianceFields. (2022),1â€“14.
arXiv:2310.02687[cs.CV] MarcoSalviandKarthikeyanVaidyanathan.2014. Multi-layeralphablending. Pro-
MaxZhaoshuoLi,ThomasMÃ¼ller,AlexEvans,RussellH.Taylor,MathiasUnberath, ceedingsofthe18thmeetingoftheACMSIGGRAPHSymposiumonInteractive3D
Ming-YuLiu,andChen-HsuanLin.2023.Neuralangelo:High-FidelityNeuralSurface GraphicsandGames(2014). https://api.semanticscholar.org/CorpusID:18595625
Reconstruction.InConferenceonComputerVisionandPatternRecognition(CVPR). SaraFridovich-KeilandAlexYu,MatthewTancik,QinhongChen,BenjaminRecht,and
RuilongLi,SanjaFidler,AngjooKanazawa,andFrancisWilliams.2024a. NeRF-XL: AngjooKanazawa.2022.Plenoxels:RadianceFieldswithoutNeuralNetworks.In
ScalingNeRFswithMultipleGPUs. arXiv:2404.16221[cs.CV] CVPR.
ZhihaoLiang,QiZhang,YingFeng,YingShan,andKuiJia.2023.Gs-ir:3dgaussian JohannesLutzSchÃ¶nbergerandJan-MichaelFrahm.2016. Structure-from-Motion
splattingforinverserendering.arXivpreprintarXiv:2311.16473(2023). Revisited.InConferenceonComputerVisionandPatternRecognition(CVPR).
LiMa,XiaoyuLi,JingLiao,QiZhang,XuanWang,JueWang,andPedroV.Sander. JohannesLutzSchÃ¶nberger,EnliangZheng,MarcPollefeys,andJan-MichaelFrahm.
2021. Deblur-NeRF:NeuralRadianceFieldsfromBlurryImages. arXivpreprint 2016.PixelwiseViewSelectionforUnstructuredMulti-ViewStereo.InEuropean
arXiv:2111.14292(2021). ConferenceonComputerVision(ECCV).
RicardoMartin-Brualla,NohaRadwan,MehdiS.M.Sajjadi,JonathanT.Barron,Alexey OttoSeiskari,JerryYlilammi,ValtteriKaatrasalo,PekkaRantalankila,MatiasTurku-
Dosovitskiy,andDanielDuckworth.2021.NeRFintheWild:NeuralRadianceFields lainen,JuhoKannala,EsaRahtu,andArnoSolin.2024.GaussianSplattingonthe
forUnconstrainedPhotoCollections.InCVPR. Move:BlurandRollingShutterCompensationforNaturalCameraMotion.arXiv
BenMildenhall,PratulP.Srinivasan,MatthewTancik,JonathanT.Barron,RaviRa- preprintarXiv:2403.13327(2024).
mamoorthi,andRenNg.2020.NeRF:RepresentingScenesasNeuralRadianceFields PeiSun,HenrikKretzschmar,XerxesDotiwalla,AurelienChouard,VijaysaiPatnaik,
forViewSynthesis.InECCV. PaulTsui,JamesGuo,YinZhou,YuningChai,BenjaminCaine,VijayVasudevan,Wei
ThomasMÃ¼ller,AlexEvans,ChristophSchied,andAlexanderKeller.2022. Instant Han,JiquanNgiam,HangZhao,AlekseiTimofeev,ScottEttinger,MaximKrivokon,
NeuralGraphicsPrimitiveswithaMultiresolutionHashEncoding. ACMTrans. AmyGao,AdityaJoshi,YuZhang,JonathonShlens,ZhifengChen,andDragomir
Graph.41,4,Article102(July2022),15pages. https://doi.org/10.1145/3528223. Anguelov.2020.ScalabilityinPerceptionforAutonomousDriving:WaymoOpen
3530127 Dataset.InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPattern
CedrickMÃ¼nstermann,StefanKrumpen,ReinhardKlein,andChristophPeters.2018. Recognition(CVPR).
Moment-BasedOrder-IndependentTransparency.Proc.ACMComput.Graph.Inter- Tianyiâ€œTankiâ€Zhang.2021.HandlingTranslucencywithReal-TimeRayTracing.Apress,
act.Tech.1,1,Article7(jul2018),20pages. https://doi.org/10.1145/3203206 Berkeley,CA,127â€“138. https://doi.org/10.1007/978-1-4842-7185-8_11
Simon Niedermayr, Josef Stumpfegger, and RÃ¼diger Westermann. 2023. Com- HaithemTurki,DevaRamanan,andMahadevSatyanarayanan.2022. Mega-NERF:
pressed3dgaussiansplattingforacceleratednovelviewsynthesis.arXivpreprint ScalableConstructionofLarge-ScaleNeRFsforVirtualFly-Throughs.InProceedings
arXiv:2401.02436(2023). oftheIEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR).
MichaelNiemeyer,JonathanT.Barron,BenMildenhall,MehdiS.M.Sajjadi,Andreas 12922â€“12931.
Geiger,andNohaRadwan.2022. RegNeRF:RegularizingNeuralRadianceFields PengWang,LingjieLiu,YuanLiu,ChristianTheobalt,TakuKomura,andWenping
forViewSynthesisfromSparseInputs.InProc.IEEEConf.onComputerVisionand Wang.2021. NeuS:LearningNeuralImplicitSurfacesbyVolumeRenderingfor
PatternRecognition(CVPR). Multi-viewReconstruction.NeurIPS(2021).
MichaelNiemeyer,FabianManhardt,Marie-JulieRakotosaona,MichaelOechsle,Daniel ZianWang,TianchangShen,JunGao,ShengyuHuang,JacobMunkberg,JonHasselgren,
Duckworth,RamaGosula,KeisukeTateno,JohnBates,DominikKaeser,andFederico ZanGojcic,WenzhengChen,andSanjaFidler.2023a.NeuralFieldsmeetExplicit16 â€¢ Moenne-Loccoz,Mirzaeietal.
GeometricRepresentationsforInverseRenderingofUrbanScenes.InTheIEEE
ConferenceonComputerVisionandPatternRecognition(CVPR).
ZianWang,TianchangShen,MerlinNimier-David,NicholasSharp,JunGao,Alexander
Keller,SanjaFidler,ThomasMÃ¼ller,andZanGojcic.2023b. AdaptiveShellsfor
EfficientNeuralRadianceFieldRendering. ACMTrans.Graph.42,6,Article259
(2023),15pages. https://doi.org/10.1145/3618390
TurnerWhitted.1979.Animprovedilluminationmodelforshadeddisplay.Seminal
graphics:pioneeringeffortsthatshapedthefield(1979). https://api.semanticscholar.
org/CorpusID:9524504
DanielN.Wood,DanielI.Azuma,KenAldinger,BrianCurless,TomDuchamp,DavidH.
Salesin,andWernerStuetzle.2000. SurfaceLightFieldsfor3DPhotography.In
Proceedingsofthe27thAnnualConferenceonComputerGraphicsandInteractive
Techniques(SIGGRAPHâ€™00).ACMPress/Addison-WesleyPublishingCo.,287â€“296.
QiangengXu,ZexiangXu,JulienPhilip,SaiBi,ZhixinShu,KalyanSunkavalli,and
UlrichNeumann.2022.Point-nerf:Point-basedneuralradiancefields.InProceedings
oftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.5438â€“5448.
LiorYariv,JiataoGu,YoniKasten,andYaronLipman.2021. Volumerenderingof
neuralimplicitsurfaces.InThirty-FifthConferenceonNeuralInformationProcessing
Systems.
MatthiasZwicker,HanspeterPfister,JeroenVanBaar,andMarkusGross.2001.Surface
splatting.InProceedingsofthe28thannualconferenceonComputergraphicsand
interactivetechniques.371â€“378.3DGaussianRayTracing:FastTracingofParticleScenes â€¢ 17
A IMPLEMENTATIONANDTRAININGDETAILS Table4. QuantitativeevaluationontheNeRF Syntheticdataset[Milden-
halletal.2020]
We wrap the NVIDIA OptiX tracer as a Pytorch extension and
trainourrepresentationusingAdamoptimizerfor30,000iterations.
Wesetthelearningratesforrotations,scales,andalbedoto0.001, NeRFSynthetic
Method Chair Drum Ficus Hotdog Lego Materials Mic Ship Mean
0.005,and0.0025,respectively.Thelearningratefortheremaining
NeRF 33.00 25.01 30.13 36.18 32.54 29.62 32.91 28.65 31.10
sphericalharmonicscoefficientsis20timessmallerthanthatfor MipNeRF 35.14 25.48 33.29 37.48 35.70 30.71 36.51 30.41 33.09
INGP 35.00 26.02 33.51 37.40 36.39 29.78 36.22 31.10 33.18
albedo.Finally,wesetthedensitylearningratetoeither0.05for
AdaptiveShells 34.94 25.19 33.63 36.21 33.49 27.82 33.91 29.54 31.84
high-qualitysettingsor0.09forfast-inferencesettings. 3DGS(paper) 35.83 26.15 34.87 37.72 35.78 30.00 35.36 30.80 33.32
Afterinitial500iterations,westartthedensificationandpruning Ours(reference) 35.90 25.77 35.94 37.51 36.01 29.95 35.66 30.71 33.48
Ours 36.02 25.89 36.08 37.63 36.20 30.17 34.27 30.77 33.38
process,whichweperformuntil15,000iterationsarereached.To
densifytheparticles,weaccumulate3Dpositionalgradients,scaled
Table5. QuantitativePSNRablationonthemaximumnumberofallowed
byhalfthedistanceofeachparticletothecamera,topreventunder-
densificationindistantregions.Inlinewith3DGS[Kerbletal.2023],
particlesusingours.
wesplittheparticlesiftheirmaximumscaleisabove1%ofthescene
extentandclonethemotherwise.Pruningdirectlyremovesparticles
MaximumAllowedParticles
whose opacity is below 0.01. Additionally, we employ a simple Dataset 1Ã—106 2Ã—106 3Ã—106 4Ã—106 5Ã—106 6Ã—106
heuristictocapthemaximumnumberofparticlesto3,000,000.We Tanks & Temples 23.21 23.19 23.20 23.14 23.15 23.20
denotethispruningstrategyasvisibilitypruning.Specifically,ifthe Deep Blending 29.24 29.17 29.23 29.14 29.24 29.15
densificationstepresultsinmoreparticles,wereducetheirnumber
to2,700,000bypruningparticleswithminimumaccumulatedweight
thatbothofoursettingsachievecomparableorbetterrenderings
contributiononthetrainingviews.Moreover,whiledensification
withsharpfeatures.Thefirstthreerowscontainscenesfromthe
andpruningareineffectandsimilarto3DGS,weresettheparticle
densitiesto0.01every3000iterations.Duringtraining,weperform
MipNeRF360dataset,whilethelasttworowsfeaturescenesfrom
earlystoppingtoterminatethetracingofrayswhoseaccumulated Tanks & Temples.
AsmentionedinSectionA,weproposeasimplevisibilityprun-
transmittancefallsbelow0.001.Duringinference,weincreasethis
ingstrategytopreventthenumberofparticlesfromexceedinga
thresholdto0.03forimprovedefficiency.Webeginbysolelytraining
certainthreshold.Table5presentsanablationstudyonthemaxi-
albedocolorsandprogressivelyincreasethesphericalharmonicsâ€™
degreeevery1000iterations,uptoamaximumof3.Weupdate
mumnumberofallowedparticlesforscenesintwodatasets:Tanks
theBVHeveryiterationandreconstructitaftereachpruningand & Temples and Deep Blending. When densification causes the
numberofparticlesinthescenetoexceedthethreshold,weprune
densification.
theleastvisibleparticlesbasedontheiraccumulatedcontribution
Forexperimentswithrandom-rays,duringthelast15,000itera-
tothetrainingviews,reducingthenumberofparticlesto90%of
tions,wesamplerandomraysacrossalltrainingviewswithabatch
size of 219 = 524,288, and only use theğ¿1 loss to supervise the thethreshold.Theresultsshowthatourvisibilitypruningstrategy,
whichfiltersoutparticlesthatcontributetheleasttotherendered
particles.
views,maintainsqualityevenwithasfewasonemillionparticles.
A.1 AutonomousVehicles
Tofitautonomousvehiclescenes,wemodifyourtrainingprotocol,
includingincorporatinglidaranddepthsupervision.Toinitialize,
werandomlysample1millionlidarpointsvisibleinatleastone
trainingimage.Thesepointsareassignedaninitialcolorvialookup
projectedintoatrainingimage,andassignedaninitialscalebased
onthedistancetotheclosestrecordedcamerapose.Duringtraining,
weuselidartosupervisedepth;inourraytracerdepthiscomputed
byintegratingthedistancealongtheraytoeachsampleasifitwere
radiance.Notethatin3DGS,lidardepthmustbeapproximatedby
projectinglidarraysontocameraimages,yetinraytracinglidar
rayscanbedirectlycastintothescene.Additionally,wereconstruct
theskyfollowing[Rematasetal.2022]andemployadirectional
MLPwhichpredictsthecoloroftheskybasedontheraydirection.
Askysegmentationisincludedasinput,andusedtosuperviseray
opacitiescomputedfromtheparticlescene.
B ADDITIONALEXPERIMENTSANDABLATIONS
Figure 17 shows qualitative comparisons of our method against
MIPNeRF360[Barronetal.2022].Thezoomed-ininsetsdemonstrate18 â€¢ Moenne-Loccoz,Mirzaeietal.
Ground Truth MIPNeRF360 Ours (reference) Ours
Fig.17. AdditionalQualitativeComparisons:novel-viewsynthesisresultsrelativetotheMIPNeRF360baseline(insets(â€¢)showper-resultcloseups).