Cash or Non-Cash? Unveiling Ideators' Incentive
Preferences in Crowdsourcing Contests
Forthcoming in Journal of Management Information Systems, 2024
Christoph Riedl
D'Amore-McKim School of Business, Northeastern University, Boston MA, USA
c.riedl@northeastern.edu
Johann F√ºller
Faculty of Business and Management, University of Innsbruck, Innsbruck, Austria
johann.fueller@uibk.ac.at
Katja Hutter
Faculty of Business and Management, University of Innsbruck, Innsbruck, Austria
katja.hutter@uibk.ac.at
Gerard J. Tellis
Marshall School of Business, University of Southern California, Los Angeles, CA
tellis@usc.edu
Abstract
Even though research has repeatedly shown that non-cash incentives can be effective,
cash incentives are the de facto standard in crowdsourcing contests. In this multi-study
research, we quantify ideators‚Äô preferences for non-cash incentives and investigate how
allowing ideators to self-select their preferred incentive‚Äîoffering ideators a choice
between cash and non-cash incentives‚Äîaffects their creative performance. We further
explore whether the market context of the organization hosting the contest‚Äîsocial (non-
profit) or monetary (for-profit)‚Äîmoderates incentive preferences and their effectiveness.
We find that individuals exhibit heterogeneous incentive preferences and often prefer
non-cash incentives, even in for-profit contexts. Offering ideators a choice of incentives
can enhance creative performance. Market context moderates the effect of incentives,
such that ideators who receive non-cash incentives in for-profit contexts tend to exert less
effort. We show that heterogeneity of ideators‚Äô preferences (and the ability to satisfy
diverse preferences with suitably diverse incentive options) is a critical boundary
condition to realizing benefits from offering ideators a choice of incentives. We provide
managers with guidance to design effective incentives by improving incentive-preference
fit for ideators.
Keywords: Crowdsourcing; contests; innovation; ideation; incentives; non-monetary rewards; pro-
social incentives.
1Introduction
Crowdsourcing innovation contests broadcast an open call to the public (‚Äúcrowd‚Äù)
inviting them to submit ideas and problem solutions. Successful crowdsourcing contests
typically draw on a wide pool of ideators, including employees, users, non-users,
suppliers, distributors, and professional ideators, tapping into diverse nationalities,
backgrounds, and socioeconomic groups [25,69]. The use of crowdsourcing enables both
for-profit organizations such as BMW, Danone, Fujitsu, Intel, Procter & Gamble or
Volkswagen, and non-profit organizations such as foundations, governments, federal
agencies or NGOs to access a wide variety of high-quality ideas and solutions [2].
Despite the widespread use of crowdsourcing contests, success depends on
participants‚Äô effort and creativity in contributing high-quality solutions, with earlier
studies exploring factors such as prize structures [46,54,64], the number of contestants [11],
or entry barriers [26]. While incentives are a key contest design element in crowdsourcing,
as they are theorized to affect ideators‚Äô effort and creative performance [65], it is not
clear which incentives are most effective. Previous studies show that ideators engage in
crowdsourcing for a variety of reasons [1,8,11,23,45] and a mismatch between incentives
and participants‚Äô motives can backfire and lead to reduced effort [29].
Although we know that ideators are motivated to participate in crowdsourcing
contests for a variety of reasons, why are contests run by diverse organizations from for-
profit to non-profit all using cash prizes? Given the diverse motives of the heterogeneous
crowd that crowdsroucing contests aspire to attract, offering everyone the same incentive
hardly seems effective [29,37]. Could crowdsourcing contest designs be improved by
offering ideators a choice of different incentives?
In this paper we introduce incentive choice‚Äîwhich we contrast from a single, fixed
incentive that is ‚Äúassigned‚Äù to all ideators‚Äîas a new incentive design aspect in
crowdsourcing contests. Incentive choice allows ideators to self-select between cash and
non-cash prizes the incentive they prefer. We theorize that incentive choice can alleviate
a central challenge in incentive design and that improving the incentive-preference fit
increases effort and performance (i.e., idea quality) in crowdsourcing contests [44,56].
We further theorize that market context‚Äîthe for-profit or non-profit orientation of
the contest organizer‚Äîmay be an important moderator for the effectivness of incentives.
In a non-profit context, participants may be happy to volunteer their time to solve societal
problems for mere recognition or praise. In a for-profit context, however, they may
expect cash in return for their efforts to help organizations remain financially successful
and gain competitive advantage. Market context may thus affect the effectiveness of non-
cash incentives. It may also affect preference for non-cash incentives in the first place.
Both of these aspects in turn may inform our understanding of boundary conditions under
which offering a choice of incentives can be effective.
We address the following research questions:
1. Do ideators prefer incentives other than cash when given the choice? While it
is plausible to assume heterogeneous preferences among crowdsourcing
participants, we seek to quantify what the most popular incentives are.
(Quantified in Study 1)
22. Does offering a choice of incentives improve quality and effort? (Main effect
examined in Study 2)
3. Does market context moderate the effect of incentives on quality and effort?
That is, are cash and non-cash incentives equally effective across for-profit and
non-profit contexts? (Moderator examined in Study 3)
4. What boundary conditions may constrain the main effect of incentive choice?
Specifically, if the mechanism behind the effect of offering a choice is increased
preference-incentive fit, the effect may depend on the degree to which ideators
actually prefer different incentives. (Boundary condition examined in Study 4)
In order to address our research questions, we offer evidence from four consecutive
empirical studies. We start by quantifying incentive preferences in a realistic field
experiment with over 1,000 participants (Study 1). Drawing on a broad population we
offer six different incentives in a non-profit context to assess ideators‚Äô interest in
choosing their own incentive and measure popularity of different cash and non-cash
prizes. We establish that both cash and non-cash incentives are highly desirable. While
cash is the most popular individual choice (28%), when aggregating the different non-
cash options together, they account over 49%, and 23% prefer to make no choice at all.
Using an econometric technique to account for self-selection in incentive choice, we
establish preliminary evidence for the main effect of incentive choice: offering a choice
per se improves idea quality in the observational field experiment. We provide additional
evidence for the main effect of offering a choice from a randomized lab experiment
(Study 2) using the two most popular incentive choices from the field experiment (cash
and a donation). We find that offering a choice improves idea quality (but not effort).
Further, we show that ideators who choose the cash incentive produce lower quality ideas
and that ideators who choose the non-cash incentive exert less effort. This study also
offers insights into the specific form in which the incentive choice is delivered. It reveals
that ideators are not merely indifferent to incentive options and some may even choose to
forego incentives entirely.
As theory suggests that the effectiveness of incentive options may depend on the
market context‚Äîfor-profit or non-profit‚Äîoffering a choice of incentives may not be
equally effective in different market contexts. Indeed, we find that market context is an
important moderator of incentive effectivness in another randomized experiment
(Study 3). We show that effort is generally lower in for-profit settings and even lower
when combined with non-cash prizes. Finally, we test an important boundary condition in
our last experiment (Study 4): despite attracting diverse populations in terms of gender,
home country, or economic background, some online platforms may, over time, evolve
an environment in which individuals have homogeneous incentive preferences. Using a
sample of ideators drawn from a population of gig workers narrowly focused on earning
income, we find no interest in non-cash incentives and consequently no benefit to
offering a choice of incentives. Exploring this boundary condition suggests that
incentive-preference fit (and hence improved sorting) is the driving mechanism behind
the positive main effect of offering a choice (as opposed to the act of choosing itself).
This suggests an important practical implication for contest designers: Offering a choice
may not be effective in homogeneous ideator pools without diverse preferences.
3Our paper makes three contributions to the literature on crowdsourcing design and
incentive theory across different market contexts. First, we establish incentive choice as
an important contest design element and explain why it works by shedding light on the
underlying mechanism. This expands past work on crowdsourcing design which has
focused on contest design aspects like prize structures [46,54,64], number of contestants
[11], and entry barriers [26]. Second, we contribute to a better understanding of incentives
in crowdsourcing by showing how for-profit and non-profit market contexts moderate the
effect of incentives. Our study reveals how incentives can sometimes backfire when they
are misaligned with the market context in which they are used [29,65]. Third, we extend
previous research that has identified a range of reasons why individuals participate in
crowdsourcing [1,8,11,23,45] by quantifying the considerable degree to which this occurs
and that diverse motives result in diverse incentive choices. This guides subsequent
theorizing and highlights the advantages of providing alternative incentives in contest
design [58].
Our findings have practical implications as they enable managers to design more
effective incentives for crowdsourcing contests. Our work suggests that in addition to
cash incentives, crowdsourcing organizers should offer a choice of non-cash alternatives
for participants to voluntarily choose from, with cash as a clearly marked default option
to cater to ideators who are indifferent.
Theoretical Background
Incentives, Choice, and Market Context
Incentives refer to rewards that motivate or encourage someone to act. They are external
to the individual and embedded in a situation. Research is increasingly clear that rewards
play a complementary role to intrinsic motivation and spur desired behaviors but can also
be detrimental to intrinsic motivation and reduce desired outcomes [39]. The type and
level of a person‚Äôs motivation together with extrinsic incentives determine a person‚Äôs
likelihood to become active, as well as their level of activity in terms of frequency,
intensity, persistence, and performance [51,67]. Personal motives determine which
incentives are perceived as attractive and how they affect an individual‚Äôs behavior [52].
These reasons range from intrinsic motives (such as curiosity, interest in, and enjoyment
of the task) to internalized extrinsic motives (such as skill development, making friends,
or supporting others), to purely extrinsic motives associated with the outcome of their
engagement (such as monetary rewards) [1,8,11,23,45]. Individuals derive more
satisfaction from an activity and show higher levels of engagement the more the activity
fulfills their motives [61]. Therefore, it is crucial to offer incentives that align with
individuals‚Äô motivations.
Incentives are generally thought to have three kinds of effects which can be captured
by a utility function with three components [9]: they value extrinsic rewards (the extrinsic
motivation component), enjoy doing an activity (the intrinsic motivation component), and
care about their image vis-√†-vis themselves or others (the reputational motivation
component). This model implies that intrinsic, extrinsic, and reputational motivations are
not mutually exclusive but jointly predict behavior. However, how strongly each
4component factors into the utility function is specific to the individual and the context in
which these incentives are employed. Individuals have been shown to differ in both their
preferences for the enjoyment of a task and the image component of their utility [32]. This
has resulted in a robust literature on the limits of monetary incentives [28].
There are four reasons why non-cash incentives may be especially attractive
compared to cash incentives [36]. First, non-cash incentives avoid the need to justify
spending money. Second, they are visible to the social environment and thus may help to
build an individual‚Äôs image and reputation. Third, non-cash incentives may represent an
independent earning class. Because this earning class is mentally kept separate from other
earnings, it may be considered especially rewarding. Fourth, individuals may mentally
adjust the value of non-cash incentives depending on their personal perception and
emotional reaction.
Choice may allow a better incentive-preference match. As individuals‚Äô utility
functions are heterogeneous, for some a cash prize may be considered the most rewarding
and appropriate incentive while for others the same prize may be considered
inappropriate and detrimental. For example, someone may have been looking for a
personal gift but received money instead. As organizers of crowdsourcing contests do not
know individuals‚Äô incentive preferences upfront [48,56] it may be beneficial to allow
participants to choose their incentive and thus avoid the risk of an incentive-preference
mismatch. Research is scarce on how offering ideators a choice of incentives‚Äîas
opposed to a single, fixed incentive that is assigned equally to all ideators‚Äîinfluences the
effect of incentive on effort and performance. So far, some early studies have explored
the effect of choice between different pay schemes such as between fixed and
performance-based pay [14,57] and using observational data between monetary and
symbolic awards [53]. Yet no study has investigated choice between cash and non-cash
prizes more broadly nor have they investigated the underlying mechanism why such
incentive choices may be effective.
Market context may further affect the perceived utility of an incentive and thus influence
effort and quality [9,67]. For example, if you help a friend to fix a computer problem or a
stranger to jump-starting a car you may expect no monetary compensation and a warm
thank may be perceived as appropriate gesture. However, as IT administrator or a car
mechanic you may expect monetary compensation for the same activity instead of a mere
thank you. Hyman and Ariely [33] demonstrated that people categorize interactions based
on whether they occur in a social or monetary market context. Depending on this
classification, individuals may anticipate different incentives for the same activity.
Through a series of laboratory experiments, they found that the direct impact of cash,
non-cash rewards, or no incentives depends on whether the context is for-profit or non-
profit (referred to as the 'market relationship'). In monetary market contexts, individuals
adjust their effort and time according to the compensation offered, whereas they do not
necessarily expect monetary incentives for their involvement in a social market context.
Another study revealed that cash had a negative effect on the willingness to donate blood,
whereas a non-cash incentive, such as a voucher of equal value, did not produce the same
negative effects [40]. Thus, while previous research mainly focused on the direct effects
of cash and non-cash incentives on performance, there remain open questions about how
5market context moderates the impact of incentives on innovation performance in
crowdsourcing.
Related Work on Incentives and Creative Performance
Incentives represent a prominent research topic in crowdsourcing. This section provides
an overview of existing studies that examine how different cash and non-cash incentives
affect creative performance. Appendix 1 offers a review of existing empirical studies
investigating creative or innovation performance as a dependent variable. While the
review highlights the strong interest in exploring incentives and their effect on innovation
performance, especially lately in the crowdsourcing context [1,11,35,65] it mainly focuses
on the effect of cash rewards.
Further, existing research in psychology, education, and organizations examining the
effect of extrinsic incentives on creativity remains ambiguous and sometimes show
contradictory results (i.e., [3,17]). While some studies have suggested that rewards
undermine intrinsic motivation and thus creative performance (e.g., [4,27]), others show
that rewards lead to goal-directed behavior and thus increase creative performance [17].
More recent research has indicated that both intrinsic and extrinsic rewards may boost
creative outcomes once properly adjusted to participants and context [31]. Only two
studies [12,16] have explored the effects of cash and non-cash incentives on creative and
innovation performance. Researchers analyzed the impact of various types of rewards,
i.e., money and social cause on the contribution behavior in crowdsourcing campaigns
[12] and examined intrinsic and extrinsic rewards on creative performance through five
different studies [16].
While we know that participants in crowdsourcing contests have diverse incentive
preferences, there is only one study that investigates the offering of choice between
monetary and symbolic awards which uses observational data [53]. While the study did
not find a direct effect of choice on quality, it did reveal a mediation effect of choice
through effort: participants in the choice option allocated more time compared to those in
the no-choice option. This study shows initial evidence that choice matters, however it
does not disentangle the difference between cash and non-cash choice, the distribution of
preferences, use random assignment, nor does it shed light on the underlying mechanism.
Giving ideators the choice to select their preferred incentive among various options
rather than assigning a specific incentive remains an unexplored research avenue to
maximize the effectiveness of incentives.1
Our overview further shows that most empirical studies are set either in a for-profit
or non-profit context but do not compare effects across market contexts within the same
study, for example by considering market context as a moderator. In summary, although
we have knowledge of the direct effects of incentives, limited research exists about how
choice of incentives affects performance in crowdsourcing and how for-profit vs. non-
profit market contexts moderate the effect of incentives.
1 Examples of existing studies investigated self-selected goal-reward levels for sales employees [10]; a lab experiment allowing individuals to
choose between a fixed and performance-based pay [14]; and several studies that investigated self-selection of pay schemes allowing
individuals to select a competitive (tournament) scheme or piece-rates [19,57]. In all cases, the self-selected incentive choice affected the
overall expected compensation (mostly depending on the individual‚Äôs skill), not the type of compensation (i.e., cash vs. non-cash).
6Research Framework
This section introduces our research framework. We start from the assumption that
individuals have heterogeneous incentive preferences. We derive two hypotheses about
how incentive choice and market context moderate the effect of incentives on idea quality
and effort in crowdsourcing contests (Figure 1).
Choice
H1(main effect)
Assignment/choice
Performance
‚Ä¶ of ‚Ä¶
Quality/effort
Incentive
Cash/non-cash H2(moderator)
Offering a choice and having
Context
different incentive options are
inherently linked. For-profit/non-profit
Figure 1. Research framework.
Main Effect of Incentive Choice. Giving ideators a choice of incentives may lead to
increased effort and performance. We theorize two different pathways for a main effect
of incentive choice. First, when individuals choose their preferred incentives this may
lead to a better incentive-preference fit, which amplifies the effect of the incentive itself,
which then spurs effort and idea quality. That is, giving ideators a choice can alleviate
poor incentive-preference fit. The mechanism behind the incentive-perference fit is
similar to mass customization, where customers self-configure products that meet their
needs better than standardized products because they provide a better match with their
preferences [22]. As incentive preferences of heterogeneous participants are not known
upfront, it may make sense to let them choose their incentive [13,37,47,53]. For this
mechanism to be effecitve, several conditions need to be met. Understanding these
conditions will lead to a better understanding of boundary conditions under which a main
effect of incentive choice may no longer materialize. First, the success of improving
incentive-preference fit relies heavily on offering ‚Äúappealing‚Äù choice options, which may
not be an easy task. When participating in crowdsourcing contests, individuals must
perceive the available options as valuable and in line with their preferences [68]. Second,
in order to make choices that enhance incentive-perference fit, ideators must be aware of
their own preferences, as benefits may not materialize if ideators are merely indifferent.
In case of unclear incentive preference, choice could backfire by causing unnecessary
effort and confusion instead of a better incentive-preference fit [50]. Finally, ideators
have to have heterogeneous incentive preferences. Incentive choice will be unable to
generate improved incentive-preference fit if incentive preferences are homogeneous and
individuals (largely) make the same choice. Taking these boundary conditions into
account, choice of incentives should lead to a better incentive-preference fit and thus
increase the effectivness of incentives.
Second, an alternative reason for increased performance given a choice of incentives
rests on self-determination. Giving ideators a choice of incentives could grow their sense
of control over their actions, which in turn can raise intrinsic motivation [15] which
7increases ideators‚Äô effort and idea quality. That is, the act of choosing an incentive may in
itself increase motivation by making ideators feel more self-determined and enhancing
their sense of autonomy and control. We hypothesize:
H1 (main effect): Incentive choice has a positive effect on a) quality, and b) effort.
Market Context as Moderator. Research shows that the effect of incentives on effort
and quality may depend on the market context and its perception as a monetary market or
a social market of the crowdsourcing contest [33]. That is, market context may moderate
the effect of different incentives because, depending on the context, individuals may have
different incentive expectations for the same activity. Consider getting help for a painting
job or preparing tax returns. In such situations, one may ask either a friend or a
professional [33]. While a friend may help without expecting a return [7], a professional
expects money for their time and effort [20]. Here, the relationship the person seeking
help has with the person providing the help, moderates the effect of the (non-)cash
incentive. It will work well in one context but can backfire in another.
According to relational incentive theory [21,29] people categorize the context in
which an interaction takes place into one of four relationship categories: common
sharing, authority ranking, equality matching, and market pricing. They adjust their
participation behavior and reward expectations according to the classified context. In
common sharing (CS), individuals consider their engagement as contributing to a
common goal and supporting the group to solve a pressing problem without asking for
returns because of shared beliefs, solidarity, and altruistic reasons. In authority ranking
(AR), individuals accept a hierarchical order. They engage in relationships to learn from
superiors, fulfill their duties as good citizens, or conform to the authorities. Equality
matching (EM) is characterized by reciprocity, balance, and tit-for-tat. Individuals engage
in, e.g., carpooling or dinner party invitations because they trust that others will
reciprocate at a later time. Market pricing (MP) refers to situations dominated by cost-
benefit calculations, where personal gain determines if one engages in an activity or not.
While the first three relationship patterns (CS, AR, EM) are social in nature, the MP
schemata is based on economic exchange. Thus, previous research suggests simplifying
the model and subsuming the four categories into two categories, social markets‚Äî
consisting of the CS, AR, and EM relationships, and monetary markets ‚Äì referring to MP
[33]. They investigate the main effect of different market contexts and find that students
show higher intentions to help moving a sofa, spend more time in an online experiment,
and show higher efforts in solving a serious of puzzles depending on the cash or non-cash
incentives offered [33]. They conclude, while monetary markets are sensitive to
compensation, social ones are not. In monetary markets, effort is directly related to the
amount of compensation. In social markets, effort is shaped by altruism.
Based on this insight, we theorize that the same incentive will be perceived
differently depending on the market context and that market context will thus moderate
the effect of the incentive [29]. Specifically, we expect the effect of non-cash incentives
to weaken in monetary market contexts.
While for-profit organizations develop new solutions to stay competitive and
generate profits for their shareholders, non-profit organizations innovate to solve pressing
problems and create common goods that benefit everyone. We therefore suggest that for-
8profit contests be perceived as monetary markets, while non-profit contests be perceived
as social markets. When the incentive is in line with the market context (such as a cash
incentive in a for-profit setting) this should strengthen the effect of the incentive.
Conversely, when the incentive is misaligned with the market context (such as a non-cash
incentive in a for-profit setting), the effect of the incentive should weaken. Further, as
participants adjust their incentive preferences and behaviors according to the market
context, the for-profit status of the contest organizer may activate ideators‚Äô extrinsic
motives and lead to expectations of cash. Alternatively, those engaging in non-profit
settings may not expect to get paid but may appreciate a non-cash reward like a gift or
praise. Non-cash prizes may in fact constitute a mismatch in a for-profit contest setting,
where organizers benefit economically from the crowd‚Äôs contribution while the ideators
receive only a non-cash prize. Ideators may expect a fair monetary compensation when
organizers generate successful returns [30]. Thus, we theorize:
H2 (moderator): Market context moderates the effect of cash and non-cash incentives on
a) quality and b) effort.
Multi-Study Overview
We conducted four studies (see Figure 2) to quantify incentive preferences in a non-profit
field study (Study 1), test the main effect of incentive choice (Study 2), investigate
whether market context moderates the effect of incentives on quality and effort (Study 3),
and finally explore preference heterogeneity as a boundary condition (Study 4). Together,
these four studies paint a more complete picture of how incentive choice and market
context collectively affect effort and idea quality in crowdsourcing contests.
How Choice and Context Affect Incentives Performance in Crowdsourcing Contests
S Me oq tu ive an tc ioe n & iE nx cp el no tr ie v ea n pd re q feu ra en nt cif ey s Study 1 Main effect of choice Study 2 Context as moderator Study 3 Boundary condition Study 4
Quantify incentive Validate main effect of choice Test whether market context Establish heterogeneous
Main Goal preferences in realistic in randomized experiment with moderates the effect of populations as important
crowdsourcing field setting control condition incentives? boundary condition
Treatment Observationalstudy w/o treatment Randomlyassigned choice vs. 2x2 design: incentive delivery Six incentive and choice
Manipulation manipulation. Choice between assigned incentive treatment (choice vs. assigned) crossed with conditions including opt-out
cash and four non-cash options manipulation context (for-profit/non-profit) and indifference condition
Context Single context (non-profit) Single context (non-profit) Randomlyassigned for-profit and Single context (non-profit)
non-profit
S Pa om pup ll ae t ion Heterogeneous -broadcasting Heterogeneous -broadcasting Heterogeneous -broadcasting H MoSm eco hStg ae nutn iceu ado l u Tds uy- rkAy (m3 A Ma4z To )n
Prize Value 1000‚Ç¨ 1st; 600‚Ç¨ 2nd; 400‚Ç¨ 3rd $0 (control) or $50 $500 1st; $300 2nd, $200 3rd $0 (control) or $50
Show-up Fee No No No $1
Method Field study (n=1,205) Experiment with random Experiment with random Experiment with random
assignment (n=208) assignment (n=120) assignment (n=160)
Figure 2. Summary of sequential study design.
9Study 1: Quantify Non-Cash Incentive Preferences in a Field
Experiment
Design and Empirical Setting
To quantify ideators‚Äô incentive preferences and offer preliminary evidence for a main
effect of incentive choice, we set up the ‚ÄúScraplab‚Äù crowdsourcing contest. It was hosted
on a leading contest platform (www.hyvecrowd.com). The contest dealt with up-cycling
and the goal was to create products out of recyclable materials instead of producing
waste. Since the contest contributes to the Sustainable Development Goals of the United
Nations and aims to create impact rather than increasing corporate profits, the context can
be classified as non-profit. This topic seemed to be appropriate as it does not require
specialized knowledge, skills, or familiarity with existing brands. Further, because
resource shortage affects everyone, anyone can have ideas on how to solve it.
The submission of an idea consisted of a visual design in the form of photographs, a
textual description, and a list of materials used (see Appendix 2 for sample designs). As
is common in crowdsourcing contests, ideators could make multiple idea submissions,
create a profile page to share personal information, interact with each other by
commenting on design submissions, provide feedback through ratings, and promote
designs by sharing them on Facebook.
The contest was designed as a rank-order tournament [43] in which the three highest-
rated ideas would receive prizes valued at 1,000‚Ç¨ (1st), 600‚Ç¨ (2nd), and 400‚Ç¨ (3rd).
During registration, participants were offered the option to choose among a cash prize
and five non-cash prizes of the same value. The non-cash prizes included, a donation to a
charity of choice (altruistic motives [34]); a short internship (same renumeration as the
cash prize); career advancement motive [41]; participation in a workshop to improve their
own design innovations (need for a solution [34] or a funded party with friends (hedonic
motives [5,9]). As the incentive question was optional, participants who didn‚Äôt select one
of the five options were assigned to the default cash incentive.
Recruiting and participants. To reach a large and global audience, we advertised the
design contest globally in various design and sustainability communities, including
design schools. The competition was open for submissions for ten weeks. During the
contest period, the website had 16,686 unique visitors (unique IP addresses). 1,205
participants registered and were exposed to the incentive-choice question during their
upfront registration. 924 participants (77%) answered the question and chose their
preferred incentive. 281 participants (23%) did not make a choice. 259 participants
submitted one or more ideas/designs (587 ideas in total) and thus are labeled as ideators.
Among the 259 ideators, 118 answered the optional incentive preference question while
141 did not and were automatically assigned to the default cash option. At the end of the
contest, three ideators were awarded prizes for their designs. Ideators from 64 different
countries participated in the contest. The highest concentration of ideators was from the
United States of America (48%) and most were female (75%).
Data Sources and Measures
10We used three main sources of data in our study: (1) registration data on ideators‚Äô
demographics, occupation, and preferred incentive; (2) log-file data from the online
platform running the contest to explore participants‚Äô behavior; and (3) data from an
independent external consumer panel using experienced workers on Amazon Mechanical
Turk to assess the quality of design submissions. Appendix 3 shows descriptive statistics
and correlations of our individual-level measures.
Independent variables and controls. The key variable of interest is the ideators‚Äô
Incentive Preference, which was an optional question on the registration survey. The
question was not forced so that ideators could choose whether to select an incentive or
not. We focused our analysis on contrasting ideators who chose the cash prize from those
who chose any of the other non-cash prizes. Data on ideators‚Äô gender was from the
registration survey, as well as imputed from the first names and profile pictures of
ideators where necessary.2 Gross Domestic Product (GDP) data from each ideators‚Äô
current country of residence was collected using 2011 numbers from the World Bank. For
ideators with missing values for country of origin (50 instances), we substituted the GDP
sample mean [62].
Because the key outcome measure of interest in this study is the quality of ideas, it is
critical to control for ideators‚Äô ability, which may affect the quality of their designs [42].
Ability is generally unobserved and difficult to capture reliably. As an imperfect measure,
we included a measure indicating whether an ideator is a professional designer.
Professional designers are expected to have relevant experience in design tasks like that
of our contest, by having previously engaged in design work full-time for an extended
period. Experience is probably the most widely used proxy for expertise [18]. Thus, based
on information that ideators provided during the registration procedure, we included an
ideator‚Äôs status as a professional designer as a proxy for expertise (1=professional
designer; 0=not professional designer).
Data from the online platform includes information on the time an ideator first
registered, and the number of designs, comments, and ratings he/she submitted. We
included controls for the number of Submitted Ideas, Submitted Comments, and
Submitted Ratings, as these provide ideators with the ability to learn from both their own
direct experience and from observing the work of others [60]. Lastly, we included a
control for the number of ideas that were already submitted to the contest just prior to the
signup of an ideator. The number of prior ideas is an easily observable signal to potential
contributors of how competitive a contest is. As such, it may affect ideators‚Äô choice of
incentive.
Dependent variable. This is the quality of each ideator‚Äôs best idea. We followed
standard practice in ideation studies [38,66] and measured the dependent variable, Design
Quality, for all designs submitted to the contest. We used an outside panel that followed a
relative assessment technique [4]. We recruited an independent jury who were blind to
the research propositions. They were experienced workers on Amazon Mechanical Turk.
We collected five evaluations for each design, resulting in 2,927 ratings of each of the six
assessment items (17,562 ratings in total) from a total of 77 different raters (Appendix 2
2 Two researchers independently coded gender; discrepancies were discussed and resolved; 12 out of 125 instances of missing gender
information could not be coded and were subsequently excluded from the analysis.
11provides details on the method, the assessment items, and some design examples). We
analyzed how incentive choice affects ideators‚Äô probability to become active
(Appendix 4).
Results
Quantifying incentive preferences. We find that when given the choice, 77% of ideators
1 Study 1 - Scrablab Field Experiment
(N=924) chose an incentive and revealed their preference (Table 1). Almost half of
ideators (49%, N=591) preferred a non-cash incentive over cash. Only 28% (N=333)
Mean SD Min Max (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11)
actively chose the cash incentive. The most popular non-cash incentive was a donation
DesignQuality(1) 3.33 0.66 1.00 4.78
DesignsSubmitted(2) 2.26 2.65 1.00 24.00 0.29
with 1In4c%ent iv(eN: N=o1A7ns1w)e,r (f3o)llo0w.55ed b0y.50 th0e.0 0inte1r.0n0sh0i.p08 w0i.t2h2 14% (N=170), the workshop
Incentive: Cash(4) 0.27 0.44 0.00 1.00 -0.06 -0.14 -0.66
incentivCeom 1m1en%ts W(Nritt=en1(25)7), 4a.4n6d t1h0.e32 pa0.r0t0y 1i1n5c.0e0nt0i.v14e 10.030% 0(.N21=-10.2163). Personal characteristics
RatingsSubmitted(6) 7.11 18.82 0.00 165.00 0.00 0.10 0.11 -0.08 0.57
such as gender Taennudre e(7c)on3o1.m14ic 2b2.a06ck0g.1r4ou7n0d.44 are0. 0w0 e0a.2k1 pr0o.11xie-0s.0 7for0 .n27on0-.c22ash incentive
log(GDP)(8) 10.28 0.61 8.44 11.25 0.02 -0.02 -0.07 0.03 -0.09 0.00 -0.06
preferences (AWpepsteernnd(9i)x 5)0..4 7Thi0s. 5s0ug0.g00ests1 .0t0ha-t0 .w07h-i0l.e06 ov0e.0r4al-l0 .0n4on0-.0c2as-h0. 0i7nc0e.0n1tiv0e.4s0 are very
Female(10) 0.61 0.49 0.00 1.00 -0.08 0.09 -0.04 0.03 0.12 -0.01 0.04 0.02 -0.03
DesignsPriortoRegistration(11) 290.89 171.55 0.00 577.00 -0.02 -0.22 -0.11 0.07 -0.28 -0.21 -0.99 0.08 -0.01 -0.04
popular, there are many different forms such incentives could take.
Professional(12) 0.36 0.48 0.00 1.00 -0.04 -0.03 -0.06 0.04 -0.01 -0.01 0.07 -0.12 0.10 -0.10 -0.08
TTaabbllee 11.: StSutduyd 1y ‚Äì1 D-esDcreipstcirviep sttiavteistsictsa toifs itniccesnatinved pcroefrerreelnacteiso nfosr opafrmticaipinantsst uwdhyo mvaadriea abtl leesasot fonide edaetsoigrns who
msuabdmeisastiolne.a st one design submission (N = 259).
N Percent Percent
Female > 0 E‚Üµort
No Choice 281 (23%) 56% 50%
Cash 333 (28%) 72% 21%
Donation 171 (14%) 82% 6%
Internship 170 (14%) 80% 18%
Workshop 127 (11%) 97% 5%
Party 123 (10%) 90% 1%
Total 1,205 75% 21%
T able 2: Study 1 - Incentive choices and activity. We provide the number of participants who
choosMe eaaicnh eofffethcet opfr iiznesc.enWteivgei vcehtohiecep eornc eqnutaagleitoyf. iSdienacteo rSst(uadmyo 1n gist haen toobtaselrovfa1t,i2o0n5a)l wsthuodcyh ose
athgaivt ednidp rniozet pinerpmariet nththee rsaesn.domized assignment of incentives, the analysis of the main
effect of choice is complicated as the analysis needs to account for self-selection of the
assignments. We analyze our data using a Tobit-5 switching regression (this is also
known as the Roy model [59] to distinguish the cash vs. non-cash incentive effect from
the influence of choice (see Appendix 2 for details on the Tobit-5 model). To establish
whether there is main effect of offering a choice we need to establish two findings. First,
we need to determine whether there is a performance difference among ideators who
chose the cash vs. the non-cash incentive. Second, we need to examine whether the
correlation of the error terms of the self-selection component in the model are positively
correlated. A positive correlation would signify that ideators who chose the incentive
performed better than they would have in a hypothetical scenario in which they were
randomly assigned to that incentive. Regarding the first condition, we find systematic
performance differences between ideators who chose cash and those who chose a non-
cash prize. Specifically, we observe a significantly higher effect of the non-cash incentive
on idea quality compared to the cash incentive (direct incentive effects in Table 2; testing
for equal coefficients comparing ùõΩ = 3.6 to ùõΩ = 3.0; ùúí((12) = 10.29; p <
!"!#$%&‚Äô $%&‚Äô
12
10.001). Regarding the second condition, we find that the estimated correlation
coefficients between the error term of the selection equation and the outcome equations
(the r and r estimates in the table), are both large and significantly different from zero
1 2
(p < 0.001). Since r is positive and significantly different from zero, the model suggests
1
that individuals who chose the non-cash prize produced designs of higher quality (than a
random individual from the sample). Conversely, since r is negative and significantly
2
different from zero, the model suggests that ideators who chose a cash prize produced
designs of lower quality (than a random individual from the sample would have).
Table 2. Study 1 ‚Äì Selection and outcome equations comparing the choice of the cash prize over any of the non-
cash prizes. Standard error in parentheses. Sample: 118 ideators who answered the incentive question and
submitted at least one design.
SelectionEquation Pr(ChooseCash)
Intercept 0.63
(2.03)
log(GDP) 0.07
 
(0.20)
Western 0.62
‚á§‚á§‚á§
 
(0.20)
Female 0.30
 
(0.20)
DesignsPriortoRegistration 0.00
‚á§‚á§‚á§
(0.00)
OutcomeEquation DesignQuality
Non-Cash Cash
DirectIncentiveE‚Üµect(Intercept) 3.55 3.03
‚á§‚á§‚á§ ‚á§‚á§‚á§
(0.11) (0.10)
Professionalexperience 0.30 0.11
 
(0.12) (0.10)
SubmittedDesigns 0.10 0.13
‚á§‚á§‚á§
(0.06) (0.05)
SubmittedComments 0.00 0.05
‚á§‚á§
 
(0.02) (0.02)
SubmittedRatings 0.008 0.005
‚á§‚á§
 
(0.01) (0.00)
ChoiceE‚Üµect
‚á¢ 0.78
1 ‚á§‚á§‚á§
(0.05)
‚á¢ 0.73
2 ‚á§‚á§‚á§
 
(0.06)
Num. obs. selectioneq. 118
Num. obs. outcomeeq. 49 69
AIC 530.72
LogLikelihood -246.36
‚á§‚á§‚á§p<0.01;‚á§‚á§p<0.05;‚á§p<0.1
Table 5: Study 1 - Selection and outcome equations comparing the choice of the cash prize over
any of the non- cash prizes. Standard error in parentheses. Sample: 118 ideators who answered
Based on these estimates, we can predict a counterfactual of how ideators who chose
incentivequestionandsubmittedatleastonedesign.
the non-cash incentive would have responded if they were assigned to the cash incentive
(i.e., we compute ùë¶*+ ‚àíùê∏(ùë¶*(|ùë¶, = 1)) and vice versa to estimate the direct benefit of
) ) )
offering ideators a choice. This suggests an 11% increase in design quality from offering
ideators a choice of incentives compared with simply offering cash to everyone. That is,
using an econometric approach to a3ccount for self selection, the observational data from
13Study 1 provides preliminary evidence for a main effect of incentive choice on idea
quality supporting H1a. Since we do not know how much time ideators spent on creating
their upcyled designs, we cannot test hypothesis H1b (on effort) in Study 1.
Summary
Participants had diverse incentive preferences and chose both cash and non-cash prizes
when given the choice. While cash was the most popular choice, almost half of ideators
chose one of the non-cash options, and about one quarter preferred to not make a choice
at all (receiving the default cash option). We also find preliminary evidence that incentive
choice had a significant main effect on idea quality: Offering ideators a choice of
incentives is an effective strategy for contest organizers to unlock additional value
independent of the incentive offered, supporting H1a.
Study 2: Main Effect of Incentive Choice in Online Experiment with
Random Assignment
To explore the preliminary evidence of a main effect of incentive choice, Study 2 uses
random assignment to give some ideators a choice of incentives while others had no such
choice. Further, as the field study left unanswered why some participants did not actively
choose a prize, Study 2 also tests participants‚Äô indifference between cash and non-cash
prizes as well as the decision to opt out of receiving any prize.
Method
Procedure. We implemented an online experiment that mirrored the task of an ideation
crowdsourcing contest (Figure 3). First, subjects completed a pre-treatment survey to
answer demographic questions, as well as a practice task (a standard ‚Äúunusual uses‚Äù
creativity task [16], and answered three items from the Intrinsic Motivation Battery [51];
Cronbach‚Äôs ùõº = .9). Second, we performed a treatment manipulation in which subjects
were either randomly assigned a prize (‚Äúassigned‚Äù condition), were asked to choose a
prize (‚Äúchoice‚Äù condition), or were not offered a prize (‚Äúcontrol‚Äù condition). Third,
subjects completed the main ideation task. Fourth, we used an external panel to evaluate
idea quality.
Stage 1: Pre-experiment survey
Demographics, practice task, intrinsic
motivation battery
Stage 2: Treatment manipulation
Incentive is Assigned or Choice
(ask subject to choose desired prize)
Stage 3: Main task
Complete idea generation task competing for
the assigned or chosen prize
Stage 4: External panel assesses idea quality
Consensual Assessment Technique
14Figure 3. Study 2 ‚Äì Study procedure and treatment flow.
The main ideation task asked subjects to submit ideas to reduce water consumption,
which they entered through a free-form text field. Again, as in Study 1, the context can be
classified as non-profit as the ideation task contributes to the Sustainable Development
Goals and aims to create impact rather than increase corporate profits. In addition to the
idea itself, we also measured effort in terms of time (in seconds) that participants devoted
to submitting their idea.3 Individuals could type as many ideas as they wanted (in
situations where multiple ideas were submitted, we calculated the overall effort as the
total number of seconds spent entering all of the ideas).
Recruiting. To recruit participants, we advertised the experiment on the Volunteer
Science platform, an online laboratory for experiments in social psychology. We
performed no specific recruiting to attract participants for our study (see [59] for details
and validation of the Volunteer Science platform).
Treatments. All subjects competed either for no prize at all, a $50 cash prize, or a
$50 donation to a charity of their choice. Participation was entirely voluntary and no
additional compensation (such as a flat show-up fee) was paid. The treatment
manipulation was whether the prize was randomly assigned or whether the subject got to
choose what the prize was. We implemented three alternative versions of the choice
treatment manipulation to explore the kinds of choice options contest designers may
consider:
1. Assigned no prize (control condition)
2. Assigned a $50 cash prize (i.e., no choice offered)
3. Assigned a $50 donation to a charity of choice (i.e., no choice offered)
4. Choice between either a $50 cash prize or a $50 donation
5. Choice between either $50 cash or a $50 donation, measured on a 7-point Likert
scale. We treated the central values (3, 4, 5) as indicating indifference between cash
and non-cash incentives, while we treated strong (1) and weak (2) preference for cash
as cash and strong (7) and weak (6) preference for non-cash as non-cash. We
informed ideators that their reward would be determined randomly using the
proportions of their choice (i.e., 50:50 chance between cash and non-cash if they
chose the middle point ‚Äú4‚Äù on the Likert scale; 43:57 chance if they chose ‚Äú5‚Äù and so
on).
6. Choice between either accepting a $50 cash prize or opting out of prizes entirely.
We performed (streaming) random assignment of participants to treatment conditions
as is common in online experiments where the total number of participants is not known
ex ante. We assigned more ideators to the choice conditions to reflect the fact that these
conditions have several nested sub-conditions.
Sample and Measures. We stopped the experiment after 40 days, at which point 221
3 We also implemented a mechanism to detect if they would simply copy & paste text into the text form (none
did).
15individuals had completed it and 208 ideas had been submitted (e.g., we removed ideators
who submitted ideas such as ‚ÄúI don‚Äôt know;‚Äù Appendix 6). Four individuals dropped out
after having been assigned to a treatment condition. The dropout was not correlated with
treatment condition (ùúí((5) = 4.78). Women and men participated in equal proportion
(51% female) with equal proportion in each treatment (ùúí((5) = 2.06). Participants were
young (94% reported age between 18-24) and mostly from the USA (92%).
We measure idea quality using Amabile‚Äôs Consensual Assessment Technique from
an outside panel recruited through Amazon Mechanical Turk, following the same method
and procedure as in Study 1. We collected 1,440 quality ratings in total from 93 different
raters who performed an average of 15.5 ratings each. Inter-coder reliability is excellent
(0.836); Cronbach‚Äôs alpha is good (0.84).
Results
Quantifying incentive preferences. Again, we find heterogeneous incentive preferences:
56% chose the cash incentive, and 44% the donation incentive when given a choice (see
Appendix 6). Individual-level characteristics like gender, age, home country, or intrinsic
motivation are no significant predictors of incentive preference. The field study did not
address whether ideators may simply have been indifferent to our prize options, so we
also explored whether ideators would opt-out or are indifferent. When given the option to
forgo a cash prize, 29% of participants chose to opt out. We find that 37% of individuals
who were given a choice between cash and non-cash indicated that they were indifferent
between the two (they selected one of the middle points on the Likert-scale).
Main effect of incentive choice on quality and effort. We used OLS regression to
analyze the main effect of incentive choice on idea quality and a negative binomial
regression for the effects on effort (Table 3). This analysis contrasts the two levels of the
treatment conditions of offering a choice vs. assigning a fixed incentive to ideators. First,
we find that offering ideators a choice, per se, improved idea quality (Model 1: Œ≤ = .17;
marginally significant at p = 0.076; supportting H1a) but not effort (Model 3: Œ≤ = .263;
n.s.; rejecting H1b). This suggests that incentive choice increases idea quality by 6.6%.
To better understand the main effect of incentive choice, it is crucial to understand
which incentives are most effective when chosen. We explore this through the interaction
between the choice treatment (choice vs. assigned) and the incentive. The interaction
between choice and cash shows a significant negative effect on idea quality (Œ≤ = -.46;
p < 0.05). We also find a significant interaction between choice and the non-cash
incentive on effort (Œ≤ = .85; p < 0.001). This suggests that the effectiveness of incentives
on both idea quality and effort is moderated by the form in which incentives are delivered
such that choice decreases the effect of cash incentives on idea quality and increases the
effect of non-cash incentives on effort.
16Table 3. Study 2 ‚Äì Regression analysis. Omitted category: Assigned, no-prize. Note that Prize: Indifferent
Rimeplgiers eCshosiicoe: nYesT. ables for Study 2-4
Dependent Variable Idea Quality E‚Üµort
(1) (2) (3) (4)
Treatments
Choice: Yes 0.17‚á§ 0.52‚á§‚á§ 0.263 0.12
(0.10) (0.25) (0.212) (0.35)
Prize: Cash 0.27‚á§‚á§ 0.53‚á§‚á§‚á§ 0.607‚á§‚á§‚á§ 0.83‚á§‚á§‚á§
(0.14) (0.20) (0.194) (0.30)
Prize: Non-Cash 0.37‚á§‚á§ 0.55‚á§‚á§‚á§ 0.829‚á§‚á§‚á§ 0.32
(0.15) (0.21) (0.314) (0.30)
Prize: Indi‚Üµerent na na na na
Interaction Terms
Choice: Yes Prize: Cash 0.46‚á§ 0.27
‚á•    
(0.28) (0.43)
Choice: Yes Prize: Non-Cash 0.36 0.85‚á§‚á§
‚á•  
(0.31) (0.42)
Choice: Yes Prize: Indi‚Üµerent 0.11 0.06 0.32 0.41
‚á•  
(0.20) (0.23) (0.29) (0.11)
Intrinsic Motivation 0.00 0.02 0.07 0.10
   
(0.05) (0.05) (0.13) (0.11)
Intercept 2.58‚á§‚á§‚á§ 2.41‚á§‚á§‚á§ 4.33‚á§‚á§‚á§ 4.37‚á§‚á§‚á§
(0.13) (0.17) (0.20) (0.22)
Controls Included Yes Yes Yes Yes
Num. obs. 208 208 208 208
Adj. R2 0.02 0.02
AIC 2597.51 2589.35
Log Likelihood 1286.76 1280.68
   
‚á§‚á§‚á§p<0.01;‚á§‚á§p<0.05;‚á§p<0.1
Table 11: Study 2, regression analysis. Omitted category: Assigned, no-prize. Note that Prize:
Indi‚Üµerent implies Choice: Yes.
Summary
We find a significant main effect showing that choice improves idea quality (confiming
H1a) but not effort (no support for H1b). While the coefficient for the main effect of
choice on effort is insignificant, the direction of the effect is positive. We find that choice
significantly reduces the effectivness of cash incentives on quality and amplifies the
positive effect of the non-cash incentive on effort.
Study 3: Moderator of For-Profit and Non-Profit Context
In Study 3, we explore if market context moderates the effect of incentives on quality and
effort. We conducted a crowdsourcing contest of a typical for-profit organization to
generate ideas that could be commercialized to ensure future profits. To create a realistic
experiment, we replicated the ideation task of the Intel Future Contest, a real-world
ideation challenge sponsored by Intel. In that contest, Intel solicited ideas for new
products or services around a new technology [55]. This technology aims to allow the
building of a new generation of smart devices (e.g., smart wearable technology) and
9
applications. The task provided background information on the new technology adapted
from the Intel Future Contest and then we asked ideators to provide information on
17product features, benefits, uses, and design proposals. We advertised an open call to a
public audience on Craigslist, Reddit, Facebook, and various other technology-related
communities and blogs.
Method
Procedure. We implemented an online experiment which randomly assigned ideators
following the same general setup as in Study 2. The design is a 2 (incentive: cash, non-
cash) √ó 2 (choice: choice, assigned) √ó 2 (context: for-profit, non-profit) between-subject
study, resulting in six treatment conditions (Appendix 7). We manipulated market context
by framing the ideation task as being solicited by either a for-profit or non-profit
organization. The for-profit condition framed the ideation task as ‚Äúa for-profit
multinational corporation wants to develop a for-profit product or service‚Äù, while the
non-profit condition solicited ideas for ‚Äúa non-profit research organization wants to
develop a non-profit product or service.‚Äù
To increase the stakes compared to Study 2, we increased the prize money to $1,000,
split as follows: $500 for 1st prize, $300 for 2nd prize, and $200 for 3rd prize. We
performed (streaming) random assignment of participants to treatment conditions as is
common in online experiments where the total number of participants is not known ex
ante. We stopped the experiment after four weeks. The study was pre-registered before
data collection began (https://osf.io/8qw7t/).
Measures. We measured the effort in seconds spent on the ideation task. Following
the same procedure as in the other studies, we collected data to measure idea quality from
an outside panel recruited through Amazon Mechanical Turk. We collected 770 ratings of
quality from 46 different raters who performed an average of 17 ratings each and five
ratings per idea. Inter-coder reliability is excellent (0.77); Cronbach‚Äôs alpha is good
(0.80).
Results
A total of 120 ideators completed the experiment and submitted at least one idea
(153 ideas were submitted in total). In a post-experiment self-report question, the
manipulation of the profit motive was effective with 76% of ideators correctly recalling
the profit structure of the organization sponsoring the contest (i.e., for-profit vs. non-
profit).
Quantifying incentive preferences across market contexts. Despite qualitatitive
differences, we find no statistically significant difference of preference for cash or non-
cash incentives between for-profit and non-profit contexts (Appendix 8, Model 2). In the
non-profit context, 31% chose the non-cash incentive compared to 23% in the for-profit
context. Within the for-profit context, a simple for equal proportion indicates that cash is
the significantly more popular choice (cash is significantly more popular than non-cash; p
= 0.001). There is no significant difference within the non-profit context.
Moderating effect of market context. We find no significant direct effect of market
context on quality (Table 4: Model 1; Œ≤ = -.06; n.s.) but a significant effect on effort
(Model 6; Œ≤ = -.41; p < 0.05). We find no significant moderation effect between market
18context and incentives for quality (Model 4; Œ≤ = -.21; n.s.). However, the for-profit
context significantly reduces the effect of non-cash incentives on effort (Model 9; Œ≤ = -
.75; p < 0.05). That is, we find evidence that market context moderates the effect of
incentives on effort (H2b) but not quality (H2a).
Table 4. Study 3 ‚Äì Regression analysis. Omitted category: Assigned cash, non-profit.
DependentVariable IdeaQuality E‚Üµort
(1) (2) (3) (4) (5) (6) (7) (8) (9) (10)
Treatments
Choice: Yes 0.18 0.15 0.18 0.19 0.15 0.15 0.12 0.18 0.14 0.12
                   
(0.11) (0.11) (0.11) (0.11) (0.12) (0.21) (0.20) (0.21) (0.21) (0.20)
Prize: Non-Cash  0.33‚á§‚á§‚á§ 0.36‚á§‚á§‚á§ 0.33‚á§‚á§‚á§ 0.33‚á§‚á§‚á§ 0.35‚á§‚á§‚á§ 0.06  0.09  0.08  0.03  0.06
(0.12) (0.12) (0.12) (0.12) (0.12) (0.20) (0.20) (0.20) (0.20) (0.20)
Context: For-Profit  0.06  0.04  0.05  0.09  0.03  0.41‚á§‚á§  0.41‚á§‚á§  0.46‚á§‚á§  0.50‚á§‚á§‚á§ 0.45‚á§‚á§
(0.10) (0.10) (0.10) (0.11) (0.11) (0.18) (0.19) (0.19) (0.19) (0.19)
InteractionTerms
Choice: Yes ‚á•Prize: Non-Cash 0.46‚á§ 0.43‚á§ 0.41 0.37
(0.24) (0.24) (0.39) (0.41)
Choice: Yes Context: For-Profit 0.05 0.10 0.30 0.19
‚á•    
(0.22) (0.23) (0.39) (0.37)
Prize: Non-Cash ‚á•Context: For-Profit  0.21  0.25  0.75‚á§‚á§  0.81‚á§‚á§
(0.24) (0.24) (0.37) (0.39)
Choice: Yes Prize: Non-Cash 0.37 0.89
‚á• ‚á•
Context: For-Profit (0.42) (0.76)
SocialValueOrientation 0.32 0.25 0.31 0.30 0.22 0.23 0.30 0.15 0.37 0.41
         
(0.20) (0.20) (0.21) (0.19) (0.20) (0.38) (0.35) (0.36) (0.36) (0.36)
Intercept 1.65‚á§‚á§‚á§ 1.60‚á§‚á§‚á§ 1.67‚á§‚á§‚á§ 1.70‚á§‚á§‚á§ 1.78‚á§‚á§‚á§ 5.96‚á§‚á§‚á§ 5.90‚á§‚á§‚á§ 5.74‚á§‚á§‚á§ 6.18‚á§‚á§‚á§ 6.18‚á§‚á§‚á§
(0.24) (0.23) (0.27) (0.22) (0.27) (0.36) (0.35) (0.34) (0.39) (0.41)
ControlsIncluded Yes Yes Yes Yes Yes Yes Yes Yes Yes
Num. obs. 120 120 120 120 120 120 120 120 120 120
Adj. R2 0.13 0.16 0.13 0.13 0.14
LogLikelihood 951.22 950.58 950.86 948.80 947.31
         
‚á§‚á§‚á§p<0.01;‚á§‚á§p<0.05;‚á§p<0.1
Table 10: Study 4, regression analysis. Omitted category: Assigned, non-cash, non-profit.
Further, there is no significant effect of the three-way interaction on either idea
quality (Model 5; Œ≤ = .37; n.s.) or effort (Model 10; Œ≤ = .89; n.s.). This suggests that the
DependentVariable IdeaQuality E‚Üµort
effectivness of offering a choice (such as the positive interaction effect between choice
(1) (2)
and non-cash on quality) does not strongly depend on the market context, albeit our
Treatments
Choice: Yes 0.11 0.01
statistical power for this analysis is quite low.  
(0.11) (0.12)
Prize: Cash 0.07 0.29
(0.18) (0.19)
Summary Prize: Non-Cash 0.45‚á§‚á§‚á§ 0.32‚á§
(0.17) (0.18)
IntrinsicMotivation 0.01 0.01
In Study 3 we investigate whether marke(0t. 0c3o)ntext m  (0o.0d3)erates the effect of incentives on
quality (H2a) and efforI tn t (er Hce 2pt b). We find s2 u.9 p3‚á§p‚á§‚á§ort for 4 t.5 h6 i‚á§s‚á§‚á§ moderation effect for effort but
(0.18) (0.22)
not quality. ControlsIncluded Yes Yes
Num. obs. 175 175
Adj. R2 0.02
LogLikelihood 945.81
 
Study 4: Boundary‚á§ ‚á§C‚á§po<0n.01d;‚á§i‚á§tpi<o0.n05; ‚á§op<f 0I.1ncentive Choice Effect
Table 11: Study 3 - AMT Sample. Note that we only include the cash and control groups and
excluded the small group of individuals who chose non-cash or are indi‚Üµerent as those groups are
Finally, we test an important boundary condition in our last experiment (Study 4). So far,
too small to analyze. Consequently, Choice: Yes implies Prize: Cash and there is no separate
ouinrt eervaicdtieonncteer msutghgatecsatns btheaets ttihmea tmeda.in effect of offering ideators a choice derives from
achieving improved fit between ideators‚Äô preferred incentive and the incentive they
actually receive (as opposed to the direct effect of simply asking them to reveal their
preference). That is, actually observing diverse incentive preferences in the population
may be crucial for the main effect of ince6ntive choice to unfold. This is important
because over time some online platforms may evolve an environment in which
individuals have homogeneous incentive preferences despite representing diverse
19populations in terms of gender, home country, and economic background. In this study,
we test this boundary condition by repeating the basic setup from Study 2, using a sample
of ideators drawn from a population of gig workers narrowly focused on earning income.
We recruited participants from Amazon Mechanical Turk (AMT), an online labor market
Here, we expect participating workers to have a homogeneous preference for cash as
transactions in the online labor market are based on strict market relationships.
Prior research has shown that AMT workers are predominantly motivated by
financial incentives [49]. For example, they often give themselves daily or weekly quotas
of how much money they want to earn working on the AMT platform. If we find that the
majority of ideators make the same choice and we find no main effect of incentive
choice, this suggests that heterogeneous incentive preferences are an important boundary
condition to realize a positive direct effect of incentive choice.
Method
Procedure. We recruited 160 workers from the AMT online labor market. Workers were
compensated with a $1 ‚Äúshow-up‚Äù fee and randomly assigned to the same ideation task
and treatment conditions from Study 2: no prize (N=21), cash (N=20), non-cash (N=29),
a choice between cash and non-cash (N=37), and a choice between cash and opt out
(N=46).
Results
Quantifying incentive preferences. As predicted, we find that participants drawn from
AMT showed no interest in non-cash prizes whatsoever (Appendix 9). Zero participants
chose the non-cash prize in the cash/non-cash condition (out of 29) and only two (out of
46) chose to opt out.
Main effect of incentive choice on quality and effort. We used OLS regression to
explore the incentive and choice effects on idea quality and a negative binomial
regression for the effects on effort. Notice that we only included the cash, assigned non-
cash, and no-prize control groups in our sample, and omitted the ‚Äúopt out‚Äù and ‚Äúchose
non-cash‚Äù groups due to the small number of individuals making those choices. We find
no significant main effect of offering a choice on either quality (Table 5: Model 1; Œ≤ = .1;
n.s.) or effort (Model 2; Œ≤ = -.02; n.s.), indicating that the mere choice of the preferred
cash option ‚Äì without interest in other incentive options ‚Äì offered no benefit and did not
lead to increased performance. To directly test if increased agency and self-determination
is a plausible mechanism behind the choice effect, we added the intrinsic motivation
battery to the post-experiment survey. We find no difference in intrinsic motivation
between individuals who chose cash compared to those who were assigned cash (t = .69;
d.f. = 31.14; p = .50), suggesting that simply asking cash motivated individuals to reveal
their cash motivation does not itself lead to increased motivation.
20Table 5. Study 4 ‚Äì Regression analysis of AMT sample. Note that we do not estimate coefficients for the small
number of ideators who chose non-cash or were indifferent as those groups are too small for a meaningful
analysis. Consequently, Choice: Yes implies Prize: Cash and there is no separate interaction term that can be
estimated.
Dependent Variable Idea Quality E‚Üµort
(1) (2)
Treatments
Choice: Yes 0.11 0.01
 
(0.11) (0.12)
Prize: Cash 0.07 0.29
(0.18) (0.19)
Prize: Non-Cash 0.45‚á§‚á§‚á§ 0.32‚á§
(0.17) (0.18)
Intrinsic Motivation 0.01 0.01
 
(0.03) (0.03)
Intercept 2.93‚á§‚á§‚á§ 4.56‚á§‚á§‚á§
(0.18) (0.22)
Controls Included Yes Yes
Num. obs. 175 175
Adj. R2 0.02
Log Likelihood 945.81
 
‚á§‚á§‚á§p<0.01;‚á§‚á§p<0.05;‚á§p<0.1
Table 12: Study 3 - AMT Sample. Note that we only include the cash and control groups and
excluded the small group of individuals who chose non-cash or are indi‚Üµerent as those groups are
too small to analyze. ConsequSeunmtlym, aCrhyo ice: Yes implies Prize: Cash and there is no separate
interaction term that can be estimated.
We find that the population of workers on Amazon Mechanical Turk had a homogeneous
preference for the cash prize. We find no sign that simply asking ideators to reveal their
Dependent Variable Idea Quality E‚Üµort
incentive preference increased their motivation. Together, the findings suggest that the
(1) (2) (3) (4) (5) (6)
benefit of offering a choice unfolds through a better incentive-preference fit. The
Treatments
increased sense of autonomy from the choice itself does not lead to higher performance.
Choice: Yes 0.18 0.15 0.15 0.15 0.12 0.10
           
(0.11) (0.11) (0.12) (0.21) (0.20) (0.20)
Prize: Non-Cash 0.33‚á§‚á§‚á§ 0.36‚á§‚á§‚á§ 0.35‚á§‚á§‚á§ 0.06 0.09 0.05
           
(0.12) (0.12) (0.12) (0.20) (0.20) (0.20)
Context: For-Profit General Discussion a0n.0d6 Theo0.r04etical 0C.04ontrib0.u41t ‚á§i ‚á§on 0.41‚á§‚á§ 0.43‚á§‚á§
           
(0.10) (0.10) (0.11) (0.18) (0.19) (0.19)
Interaction Terms
The research presented in this paper sets out incentive choice (cash vs. non-cash) to alleviate a
Choice: Yes Prize: Non-Cash 0.46‚á§ 0.43‚á§ 0.41 0.37
‚á•
fundamental issue in incentive desig(n0 .a2n4)d enh(a0n.2c4e) the alignment b(0e.3tw9)een in(0c.e41n)tive and
Prize: Non-Cash Context: For-Profit 0.22 0.86‚á§‚á§
‚á• preferences to increase effort and idea quality  in crowdsourcing contests ac ross market
(0.23) (0.39)
Choice: Yes Prize: Non-CacsohnteCxtosn t(efxotr:-Fporro-fPirto vfist. non-profit). 0.39 0.84
‚á• ‚á•
(0.41) (0.79)
We present evidence from four consecutive empirical studies (see result summary in Table
Social Value Orientation 0.32 0.25 0.23 0.23 0.30 0.47
     
6). Our field study (Study 1(0). 2h0e)lped (u0s.2 q0)uantif(y0 .i2d0e)ators(‚Äô0 p.3r8e)feren(c0e.3s5 a)nd su(g0.g3e8)sts they are
Intercept very diverse, with over 49%1. 6 c5 h‚á§o‚á§‚á§osing1 .6 a0 m‚á§‚á§o‚á§ng o1 n.7 e3 o‚á§‚á§f‚á§ the n5. o96 n‚á§-‚á§c‚á§ash i5 n.9 c0 e‚á§n‚á§‚á§tives6 a.3 n2 d‚á§‚á§ ‚á§28%
(0.24) (0.23) (0.25) (0.36) (0.35) (0.41)
Controls Included choosing cash. There may Ybees severaYl eesxplanaYtieosns for tYhees no-choYiecse effecYt:e s1) participants
who did not make a choice were fine with the default cash option and did not want to
Num. obs. 120 120 120 120 120 120
Adj. R2 explicitly reveal their ince0n.1ti3ve pref0e.1r6ence; 20). 1p5articipants may have been indifferent and
Log Likelihood 951.22 950.58 947.44
had no strong preference for any of the offered ince ntives; 3 ) they ma de no choice
‚á§‚á§‚á§p<0.01;‚á§‚á§p<0.05;‚á§p<0.1
because none of the offered incentives matched their preferences; 4) they were opposed
Table 13: Study 4, rteog rreeswsiaorndsa naanldy/soisr. cOhmoiictete adltcoagteegthoeryr :aAndss wignereed ,hcaapsphy, ntoo np-aprrtoifictip.ate without any incentive.
21
10Table 6. Summary Findings.
Key Findings
‚Ä¢ Quantify incentive preferences: > 49% choosing among
Study 1 one of the non-cash incentives; 28% choosing cash; 23%
(Field study n=1,205) prefer to make no choice at all.
‚Ä¢ Preliminary evidence of main effect of choice on quality
‚Ä¢ Choice increases quality (main effect) but not effort
Study 2
(supporting H1a)
(Online experiment with
‚Ä¢ Choice reduces the effect of cash incentives on quality and
random assignment n=208)
increases the effect of non-cash incentives on effort.
‚Ä¢ Market context moderates the effect of incentives on
Study 3
effort (but not quality; supporting H2b)
(Online experiment with
‚Ä¢ No significant difference in preference for non-cash prize
market context as treatment
in for-profit context. Lower effort for non-cash incentive
manipulation, n=120)
in for-profit context.
‚Ä¢ Establishes heterogeneous preferences as important
Study 4 boundary condition: no interest in non-cash incentives in
(Online experiment with pool of gig-workers focused on earning income.
gig-worker sample, n=160) ‚Ä¢ Without sorting, no effect materializes. Indicating
improved incentive-preference fit is driving mechanism.
The field study (Study 1) and the randomized lab experiment (Study 2) both provide
evidence for the main effect of offering a choice on idea quality (not effort; both those studies
were set in a non-profit context). Study 3 finds that market context moderates the effect of
incentives on effort (but not idea quality). One possible explanation for the null-effect on
quality may be that idea quality in creative settings only partially depends on effort or it may
simply be a result of low statistical power (while not statistically significant, the regression
coefficient for quality points in the same direction as that for effort). Ideators exerted less
effort in for-profit settings than in non-profit settings overall and even less when the for-profit
setting is paired with a non-cash incentive. Finally, we point to an important boundary
condition (Study 4): If ideators have uniform incentive preferences for cash such as gig
workers on Amazon Mechanical Turk, offering a choice of incentives has no effect. The lack
of a direct effect of choice per se, suggests that the benefit arises from the improved matching
between incentive preference and the incentive being offered. As a result, we theorize that the
gains from offering a choice do not arise from a feeling of agency but instead from improved
sorting of preferences to incentives. Without heterogeneous incentive preferences, there is no
room for gains from sorting of preferences to actual incentive. This suggests that the strength
of the effect of offering a choice depends both on the diversity of ideators‚Äô incentive
preferences and the diversity of incentives being offered to maximize this sorting effect.
Across our four studies, personal characteristics such as gender, economic background, and
intrinsic motivation served only as weak proxies for incentive preferences while social value
orientation emerged as a strong predictor in Study 3.
Our findings make three main contributions to theory. First, past work on crowdsourcing
design focused on contest design aspects like prize structures [46,54,64], number of
contestants [11], and entry barriers [26]. By contrast, we establish that incentive choice is a
pivotal aspect of incentive design that is little understood [53] and are the first to shed light on
the underlying mechanism why it may work. Our study explains why offering ideators a
22choice of incentives per se can improve performance. We theorize that offering a choice
improves creative performance in crowdsourcing contests because it improves the incentive-
preference fit which increases effort and performance rather than an increased sense of
autonomy and sense of control [15]. This connects with the idea of incentive choice in
research on mass customization, where customers self-configure products that match their
preferences rather than choose standardized products [22]. Our study is the first to shed light
on the mechanism behind the effectiveness of incentive choice and its important boundary
conditions. Outside crowdsourcing, [14,57] are notable exceptions that explored incentive
choice in a lab experiment giving participants a choice between fixed and performance-based
pay.
We contribute to work on crowdsourcing design by explicating an important boundary
condition: offering a choice is ineffective when the incentive preferences in the target
population are homogeneous. Incentive preferences may be homogeneous despite diverse
geographic and economic background when recruiting ideators from online labor markets
such as Amazon Mechanical Turk (see Study 4). Further, the sorting effect seems to
strengthen when many attractive incentive options are offered (Study 1; c.f. [68]).
Additionally, ideators may enjoy various benefits [9] and may hence also be rather indifferent
to the available incentive options. Thus, forcing participants to reveal their preferences by
choosing their preferred incentive may only increase their burden and not offer additional
value [50]. Incentive choice may further consider an opt-out option (see Study 2) as
participants may prefer to forgo any incentive rather than accept an incentive that, in their
eyes, does not match their demonstrated performance [21].
Second, our study contributes to a better understanding of incentives in different
market contexts. While crowdsourcing contests are used equally in for-profit vs. non-
profit market contexts, existing research has studied the direct effect of cash vs. non-cash
incentives [6,24], but not considered market context as a moderator. Our study fills this
gap and extends received knowledge that incentives can sometimes backfire when they
are misaligned with the market context in which they are used [29,65]. We show that
incentive preference and its effect on quality and effort is not only influenced by individual‚Äôs
motives and personal characteristics, but also market context. Researchers [34] have applied
Fiske‚Äôs relationship theory to explain the signaling effect of incentives and their influence on
effort [63], and empirical studies have referred to different effects of incentives in for-profit
and non-profit contexts [12,16]. However, no one has yet considered the classification of
context as a monetary market (for-profit) vs. social market (non-profit) as an important
moderator for predicting incentive preference and its effect on quality and effort.
Third, we expand on previous research that has identified a variety of intrinsic and
extrinsic reasons for why individuals engage in crowdsourcing contests [1,8,11,23,45] by
quantifying of the extent to which this this occurs and demonstrating that individuals not only
have diverse preferences but actually choose different incentives when given the choice.
While our results are consistent with past research showing that cash is generally the most
prevalent single incentive due to its high option value [36], in some settings almost half prefer
non-cash incentives. Our work is one of the first to validate various incentive preferences in a
field setting. This emphasizes the importance of heterogeneous incentives not only as a niche
aspect but a core driver of motivation to participate in crowdsourcing contests. This insight
opens opportunities to improve contest design by considering alternative incentives. We also
23determine that ideators not only have diverse incentive preferences but sometimes even prefer
to opt out of receiving any incentives and sometimes are indifferent, thus suggesting entirely
new forms of incentives to consider. These findings emphasize the existing literature that it is
not easy to offer an appropriate incentive upfront [48,56] and providing incentive choice may
be useful.
Managerial Implications
Our research has four practical implications for open innovation managers to design more
effective incentive regimes. First, offering a choice of incentives may increase the
effectiveness of incentives in crowdsourcing contests, especially when incentive preferences
are diverse and a set of suitable non-cash incentives are available. Offering a choice can
alleviate the concern that managers may not know what the most desirable incentive is and
may worry about missing out if cash is not offered. Second, the incentive choice should be
implemented as an optional choice with a clearly defined cash default option to cater to
ideators who may be indifferent. This choice allows contest organizers to offer unique and
unexpected incentives that may be very effective in special contexts (e.g., NASA offering a
low value artifact like a sticker mentioning ‚Äúflown in space‚Äù; [9,63]). Third, the accentuation
of a non-profit context (social market) matters. Social markets can positively affect
participants‚Äô level of effort. Thus, crowdsourcing contests in social markets should underline
their social character. Fourth, heterogeneous incentive preferences may over time vanish as
online platforms specialize and evolve to cater to a more homogeneous user group (e.g.,
AMT). Crowdsourcing platforms must be aware that if they heavily rely on cash as their
standard incentive, it will not be surprising that their community expects cash. Conversely,
offering non-cash incentives and hosting contests for a variety of market contexts can be a
means to attract heterogeneous ideators, which may improve idea quality throughout the
platform.
Limitations and Future Research
Our findings are not without limitations. Although gathered in various setups and under
realistic conditions, further research is required to establish the dimensions in which they
generalize. Our strongest findings in favor of non-cash incentives come from the field data in
Study 1. This study was set in a non-profit context and those results may not fully generalize
to for-profit settings despite our insights from Studies 2-4. Future research could evaluate if
similar incentive preferences persist in crowdsourcing contests in for-profit contexts. While
our results are consistent in regards to effect of incentives, choice, and context, more research
is required to investigate the effect in additional settings and to enhance the overall
applicability of our conclusions. In addition, numerous new areas necessitate further
investigation, including design of choice options, the effect of indifference, the offering of
incentive bundles, the effect of incentive opt out, and the conditions that create a social
market character.
Further, exploring how incentives over time lead to homogeneous preferences and
adjusted behaviors, e.g., those found at AMT, would be illuminating. Additionally, our study
employed prize purses that are commonly used in current reserach. Higher prizes may
24lead to different outcomes and different incentive choices. In particular, we expect
incentives to function differently in crowdsourcing contests compared with grand
challenges like NASA‚Äôs $1M CO2 Conversion Challenge or the $10M Ansari X-Prize for
Suborbital Flight. We speculate that ideators would be much less likely to either forgo
incentives or choose a non-cash option if the stakes are very high. Consequently, the full
range of ideators‚Äô sensitivity to prize levels remains an open question. Our analysis also
focused on shifts in the mean quality of ideas due to selection and treatment effects.
However, sometimes shifts in maximum quality are more important than shifts in mean
quality, especially in rank-order.
Conclusion
In conclusion, this research significantly advances our understanding of incentive design in
crowdsourcing contests, highlighting the importance of offering a choice between cash and
non-cash incentives to match diverse ideators preferences. It underscores the role of market
context which moderates the effectiveness of these incentives and reveals that personal
characteristics are less indicative of preference than previously thought. The findings open
new pathways for designing more effective crowdsourcing contests, emphasizing the need for
flexibility and customization of incentives to cater to diverse participant motives and market
contexts.
References
1. Acar, O.A. Harnessing the creative potential of consumers: money, participation, and
creativity in idea crowdsourcing. Marketing Letters, 29, 2 (2018), 177‚Äì188.
2. Afuah, A.N. and Tucci, C. Reflection on the 2022 AMR Decade Award:
Crowdsourcing as a Solution to Distant Search. Academy of Management Review, 48, 4
(2023), 597‚Äì610.
3. Amabile, T.M. Social psychology of creativity: A consensual assessment technique.
Journal of Personality and Social Psychology, 43, 5 (1982), 997‚Äì1013.
4. Amabile, T.M., Goldfarb, P., and Brackfield, S.C. Social influences on creativity:
Evaluation, coaction, and surveillance. Creativity Research Journal, 3, 1 (1990), 6‚Äì21.
5. Ariely, D., Bracha, A., and Meier, S. Doing good or doing well? Image motivation and
monetary incentives in behaving prosocially. American Economic Review, 99, 1
(2009), 544‚Äì555.
6. Ashraf, N., Bandiera, O., and Jack, K. No margin, no mission? A field experiment on
incentives for public service delivery. Journal of Public Economics, 120, 1 (2014), 1‚Äì
17.
7. Batson, D.C., Polycarpou, M.P., Harmon-Jones, E., et al. Empathy and attitudes: Can
feeling for a member of a stigmatized group improve feelings toward the group?
Journal of Personality and Social Psychology, 72, 1 (1997), 105‚Äì118.
8. Belenzon, S. and Schankerman, M. Motivation and sorting of human capital in open
innovation. Strategic Management Journal, 36, 6 (2015), 795‚Äì820.
9. B√©nabou, R. and Tirole, J. Incentives and prosocial behavior. American Economic
Review, 96, 5 (September 2006), 1652‚Äì1678.
10. Bommaraju, R. and Hohenberg, S. Self-Selected Sales Incentives: Evidence of their
Effectiveness, Persistence, Durability, and Underlying Mechanisms. Journal of
Marketing, 82, 5 (2018), 106‚Äì124.
2511. Boudreau, K.J., Lacetera, N., and Lakhani, K.R. Incentives and problem uncertainty in
innovation contests: An empirical analysis. Management Science, 57, 5 (April 2011),
843‚Äì863.
12. Cappa, F., Rosso, F., and Hayes, D. Monetary and Social Rewards for Crowdsourcing.
Sustainability, 11, 10 (2019), 2834.
13. De Charms, R. Personal Causation. Academic Press, New York, 1968.
14. Chow, C.W. The Effects of Job Standard Tightness and Compensation Scheme on
Performance: An Exploration of Linkages. Accounting Review, 58, 4 (1983), 667‚Äì685.
15. Deci, E. and Ryan, R. Intrinsic Motivation and Self-Determination in Human Behavior.
Plenum Press, New York, 1985.
16. Eisenberger, R. and Rhoades, L. Incremental Effects of Reward on Creativity. Journal
of personality and social psychology, 81, 4 (2001), 728.
17. Eisenberger, R. and Selbst, M. Does Reward Increase or Decrease Creativity? Journal
of Personality and Social Psychology, 66, 6 (1994), 1116‚Äì1127.
18. Ericsson, K., Krampe, R., and Tesch-R√∂mer, C. The role of deliberate practice in the
acquisition of expert performance. Psychological Review, 100, 3 (1993), 363‚Äì406.
19. Eriksson, T., Teyssier, S., and Villeval, M.-C. Self-selection and the efficiency of
tournaments. Economic Inquiry, 47, 3 (2009), 530‚Äì548.
20. Fehr, E. and Falk, A. Psychological foundations of incentives. European Economic
Review, 46, 4‚Äì5 (2002), 687‚Äì724.
21. Fiske, A.P. The four elementary forms of sociality: Framework for a unified theory of
social relations. Psychological Review, 99, 4 (1992), 689‚Äì723.
22. Franke, N., Keinz, P., and Steger, C.J. Testing the value of customization: when do
customers really prefer products tailored to their preferences? Journal of Marketing,
73, 5 (2009), 103‚Äì121.
23. F√ºller, J. Refining virtual co-creation from a consumer perspective. California
Management Review, 52, 2 (2010), 98‚Äì122.
24. F√ºller, J., Hutter, K., and Fries, M. Crowdsourcing for goodness sake: Impact of
incentive preference on contribution behavior for social innovation. In K.S. Swan and
S. Zou, eds., Advances in International Marketing. Emerald, 2012, pp. 137‚Äì159.
25. F√ºller, J., Hutter, K., Hautz, J., and Matzler, K. User Roles and Contributions in
Innovation-Contest Communities. Journal of Management Information Systems, 31, 1
(2014), 273‚Äì307.
26. Fullerton, R.L. and McAfee, R.P. Auctioning Entry into Tournaments. Journal of
Political Economy, 107, 3 (1999), 573‚Äì605.
27. Gagn√©, M. and Deci, E.L. Self-determination theory and work motivation. Journal of
Organizational Behavior, 26, 4 (June 2005), 331‚Äì362.
28. Gallus, J. and Frey, B.S. Awards: A strategic management perspective. Strategic
Management Journal, 37, 8 (2016), 1699‚Äì1714.
29. Gallus, J., Reiff, J., and Fiske, A.P. Relational incentives theory. Psychological Review,
129, 3 (2022), 586‚Äì602.
30. Gebauer, J., F√ºller, J., and Pezzei, R. The dark and the bright side of co-creation:
Triggers of member behavior in online innovation communities. Journal of Business
Research , 66, 9 (2013), 1516‚Äì1552.
31. Gerhart, B. and Fang, M. Pay, Intrinsic Motivation, Extrinsic Motivation, Performance,
and Creativity in the Workplace: Revisiting Long-Held Beliefs. Annual Review of
Organizational Psychology and Organizational Behavior, 2, 1 (2015), 489‚Äì521.
32. Gneezy, U., Meier, S., and Rey-Biel, P. When and Why Incentives (Don‚Äôt) Work to
Modify Behavior. Journal of Economic Perspectives, 25, 4 (2011), 191‚Äì209.
33. Heyman, J. and Ariely, D. Effort for payment - A tale of two markets. Psychological
Science, 15, 11 (November 2004), 787‚Äì793.
2634. von Hippel, E. Democratizing Innovation. MIT Press, Cambridge, MA, 2005.
35. Hofstetter, R., Zhang, Z.J., and Herrmann, A. The Hidden Pitfall of Innovation Prizes.
Harvard Business Review, 2017, 1‚Äì19. https://hbr.org/2017/11/the-hidden-pitfall-of-
innovation-prizes.
36. Jeffrey, S.A. and Shaffer, V. The Motivational Properties of Tangible Incentives.
Compensation & Benefits Review, 39, 3 (June 2007), 44‚Äì50.
37. Jeppesen, L.B. and Frederiksen, L. Why do users contribute to firm-hosted user
communities? The case of computer-controlled music instruments. Organization
Science, 17, 1 (2006), 45‚Äì63.
38. Kornish, L.J. and Ulrich, K.T. The Importance of the Raw Idea in Innovation: Testing
the Sow‚Äôs Ear Hypothesis. Journal of Marketing Research, 51, 1 (2014), 14‚Äì26.
39. Kunz, A.H. and Pfaf, D. Agency theory, performance evaluation, and the hypothetical
construct of intrinsic motivation. Accounting, Organizations and Society, 27, 3 (2002),
275‚Äì295.
40. Lacetera, N. and Macis, M. Social image concerns and prosocial behavior: Field
evidence from a nonlinear incentive scheme. Journal of Economic Behavior &
Organization, 76, (2010), 225‚Äì237.
41. Lakhani, K.R. and Wolf, R.G. Why Hackers do what they do: Understanding
Motivation and Effort in free/open Source Software Projects. In J. Feller, B. Fitzgerald,
S.A. Hissam and K.R. Lakhani, eds., Perspectives on free and open source software.
MIT Press, Cambridge, 2005, pp. 3‚Äì22.
42. Larkin, J., Mcdermott, J., Simon, D.P., and Simon, H.A. Expert and novice
performance in solving physics problems. Science, 208, 4450 (1980), 1335‚Äì1342.
43. Lazear, E.P. and Rosen, S. Rank-order tournaments as optimum labor contracts.
Journal of Political Economy, 89, 5 (1981), 841‚Äì864.
44. Leimeister, J.M., Huber, M., Bretschneider, U., and Krcmar, H. Leveraging
Crowdsourcing: Activation-Supporting Components for IT-Based Ideas Competition.
Journal of Management Information Systems, 26, 1 (2009), 197‚Äì224.
45. Li, D. and Hu, L. Exploring the effects of reward and competition intensity on
participation in crowdsourcing contests. Electronic Markets, (2017), 199‚Äì210.
46. Liu, J. and Kim, K. Designing contests for data science competitions: Number of stages
and prize structures. Production and Operations Management, (2023).
47. Lovas, B. and Ghoshal, S. Strategy as guided evolution. Strategic Management
Journal, 21, 9 (2000), 875‚Äì896.
48. Majchrzak, A. and Malhotra, A. Towards an information systems perspective and
research agenda on crowdsourcing for innovation. The Journal of Strategic Information
Systems, 22, 4 (December 2013), 257‚Äì268.
49. Mason, W. and Suri, S. Conducting behavioral research on Amazon‚Äôs Mechanical
Turk. Behavior Research Methods, 44, 1 (2012), 1‚Äì23.
50. Matzler, K., Stieger, D., and F√ºller, J. Consumer Confusion in Internet-Based Mass
Customization: Testing a Network of Antecedents and Consequences. Journal
Consumer Policy, 34, (2011), 231‚Äì247.
51. McClelland, D.C. How motives, skills, and values determine what people do. American
Psychologist, 40, 7 (1985), 812‚Äì825.
52. McClelland, D.C., Koestner, R., and Weinberger, J. How do self-attributed and implicit
motives differ? Psychological Review, 96, 4 (1989), 690‚Äì702.
53. Moghaddam, E.N., Aliahmadi, A., Bagherzadeh, M., Markovic, S., Micevski, M., and
Saghafi, F. Let me choose what I want: The influence of incentive choice flexibility on
the quality of crowdsourcing solutions to innovation problems. Technovation, 120,
(February 2023), 102679.
2754. Morgan, J. and Wang, R. Tournaments for ideas. California Management Review, 52, 2
(2010), 77‚Äì97.
55. Mrass, V., Peters, C., and Leimeister, J.M. Managing Complex Work Systems Via
Crowdworking Platforms: How Intel and Hyve Explore Future Technological
Innovations. SSRN Electronic Journal, (January 2018).
56. Nevo, D. and Kotlarsky, J. Crowdsourcing as a strategic IS sourcing phenomenon:
Critical review and insights for future research. The Journal of Strategic Information
Systems, 29, 4 (December 2020), 101593.
57. Niederle, M. and Vesterlund, L. Do women shy away from competition? Do men
compete too much? Quarterly Journal of Economics, 122, 3 (2007), 1067‚Äì1101.
58. von Nordenflycht, A. Clean up Your Theory! Invest in Theoretical Clarity and
Consistency for Higher-Impact Research. Organization Science, 34, 5 (2023), 1651‚Äì
1996.
59. Radford, J., Pilny, A., Reichelmann, A., et al. Volunteer Science: An Online
Laboratory for Experiments in Social Psychology. Social Psychology Quarterly, 79, 4
(2016), 376‚Äì396.
60. Riedl, C. and Seidel, V. Learning from Mixed Signals in Online Innovation
Communities. Organization Science, 29, 6 (2018), 1010‚Äì1032.
61. Ryan, R. and Deci, E. Intrinsic and extrinsic motivations: Classic definitions and new
direction. Contemporary Educational Psychology, 25, 1 (2000), 54‚Äì67.
62. Shadish, W.R., Cook, T.D., and Campbell, D.T. Experimental and Quasi-Experimental
Designs for Generalized Causal Inference. Houghton Mifflin, Boston, MA, USA,
2002.
63. Sittenthaler, H.M. and Mohnen, A. Cash, non-cash, or mix? Gender matters! The
impact of monetary, non-monetary, and mixed incentives on performance. Journal of
Business Economics, 90, (2020), 1253‚Äì1284.
64. Terwiesch, C. and Xu, Y. Innovation contests, open innovation, and multiagent
problem solving. Management Science, 54, 9 (2008), 1529‚Äì1543.
65. Toubia, O. Idea Generation, Creativity, and Incentives. Marketing Science, 25, 5
(2006), 411‚Äì425.
66. Toubia, O. and Netzer, O. Idea Generation, Creativity, and Prototypicality. Marketing
Science, 36, 1 (2017), 1‚Äì20.
67. Vallerand, R.J., Fortier, M.S., and Guay, F. Self-determination and persistence in a
real-life setting: Toward a motivational model of high school dropout. Journal of
Personality and Social Psychology, 72, 5 (1997), 1161‚Äì1176.
68. Williams, S. An organizational model of choice: A theoretical analysis differentiating
choice, personal control, and self-determination. Genetic, Social, and General
Psychology Monographs, 124, 4 (1998), 465‚Äì491.
69. Yan, J.K., Leidner, D.E., and Benbya, H. Differential Innovativeness Outcomes of User
and Employee Participation in an Online User Innovation Community. Journal of
Management Information Systems, 35, 3 (July 2018), 900‚Äì933.
28Online Appendices
Appendix 1. Positioning of Current Paper in Literature on Choice of Incentives
Incentive Application Study Design Context Summary
Dependent Selected
Variable References Choice Intrinsic Extrinsic Creativity in Observational and For profit &
of (non-cash) (cash) Crowdsourcing Experimental Data Non-profit (both)
The current study tests the effectiveness of cash vs. non-cash
Current
Yes Yes Yes Yes Yes Yes incentives ‚Äì assigned to or self-selected by ideators ‚Äì in
article
crowdsourcing contest for-profit vs. non-profit organizers.
The authors test in a single experiment with two rounds how
[26] Yes Yes Yes Yes Yes No providing participants with incentive choice (monetary vs.
symbolic) choice impacts solution quality.
Cappa et al. empirically test if two different types of rewards ‚Äì
[6] No Yes Yes Yes No No monetary and social rewards ‚Äì increase the number of
contributions in crowdsourcing.
Eisenberger and Rhoades examined unrewarded and rewarded
[12] No Yes Yes No No No
creativity training and its impact on creative task performance.
Heymann and Ariely test the relationship between forms of
compensation (cash vs. token), the levels of payment (no, low,
[20] No Yes Yes No Yes No
and medium), and the resulting effort expended in monetary and
social markets.
Sittenthaler and Mohen employs an experiment to test the impact
[31] No Yes Yes No No No of monetary, non-monetary, and a combination of monetary and
non-monetary incentives on performance.
The authors test incentives and their impact on contest
[5] No No Yes Yes Yes No performance in high and low-uncertainty problems with greater
and lower rivalry.
The authors empirically test if incentive and parallel path effects ‚Äì
adding numbers of competitors ‚Äì are of comparable magnitude
[21] No No Yes Yes Yes No
and thus be explicitly considered together when designing
crowdsourcing contests.
Toubia examines if tailored ideation incentives improve creative
[33] No No Yes Yes Yes No
output.
Acar investigates whether the use of monetary rewards is
[1] No No Yes Yes Yes No effective in stimulating creativity and, if so, how large those
rewards should be.
The authors explore the effects of different incentives on
[25] No No Yes Yes No No crowdsourcing participation and contribution quality in
randomized field experiments.
The authors empirically test the effects of extrinsic financial
[28] No No Yes No Yes No
rewards on intrinsic motivation.
1
ecnamrofreP
noitavonnI
&
evitaerCIncentive Application Study Design Context
Dependent Selected
Variable References Choice Intrinsic Extrinsic Creativity in Observational and For profit & Summary
Crowdsourcin Non-profit
of (non-cash) (cash) Experimental Data
g (both)
Deci tests in two laboratory experiments and one field experiment the effects of external rewards on
[8] No No Yes No Yes No
intrinsic motivation to perform an activity.
The authors investigate synergistic extrinsic motivators to foster creativity and innovation of
[15] No No Yes No No No
intrinsically motivated knowledge workers.
Erat and Gneezy empirically test whether piece-rate and competitive incentives affect creativity, and if
[14] No No Yes No No No so, how the incentive effect depends on different types ‚Äì and not merely the presence ‚Äì of extrinsic
incentives.
Eisenberger and Selbst investigate why behaviorists and cognitive
[13] No No Yes No No No oriented investigators show opposite conclusions about reward‚Äôs
effects on creativity.
The authors examine the effect of reward on children‚Äôs and adults‚Äô
[3] No No Yes No No No
creativity.
Amabile test the creativity motivation hypothesis by investigating
[2] No No Yes No No No the effects of a common extrinsic constraint ‚Äì competing for prizes
‚Äì on children‚Äôs artistic creativity in a field setting.
Pinder test additivity versus non-additivity of intrinsic and extrinsic
[27] No No Yes No No No
incentives on work motivation, performance and attitude.
Deci empirically investigates what happens to a person‚Äôs intrinsic
[9] No No Yes No No No motivation for an activity when he is rewarded extrinsically for
performing the activity.
Hammer and Foster test that contingent monetary rewards actually
[19] No No Yes No No No reduced intrinsic task motivation in both a boring and nonboring
task setting.
Eder and Manso test in a controlled experimental setting the effects
[11] No No Yes No No No of different incentives schemes (e.g. fixed wage, pay for
performance, exploration) on innovation and performance.
The authors evaluate in a series of laboratory experiments the fixed
[16] No No Yes No No No prize mechanisms as a means to obtain a given quality of research at
as low a cost as possible under various market conditions.
Deci and Cascio test changes in intrinsic motivation as a function of
[10] No No No No No No
negative feedback and threats.
Our review categorizes the studies along incentives and choice. In addition, we classify the study settings (creativity in crowdsourcing
vs. other settings), how the data was gathered (observational vs. experimental data design), and the context setting (for-profit vs. non-
profit). While our review does not claim to be exhaustive it covers the most relevant and actual studies.
2
ecnamrofreP
noitavonnI
&
evitaerCIncentive Paper - JMR Round 2
Appendix 2. Study 1
E1stimaStiotnu Pdryoce1du‚Äìre:S Wcer aesptimlaatbe the following system of three simultaneous latent
equation1s .1 Model
yS =  S 0xS +‚úèS (1)
i ‚á§ i i
yO1 =  O1 0xO1 +‚úèO1 (2)
i ‚á§ i i
yO2 =  O2 0xO2 +‚úèO2. (3)
i ‚á§ Incentiive Pai per - JMR Round 2
Equation (1) is the selection rule, where an individual‚Äôs i choice ùë¶" is the choice of the
!
1 Study 1 ‚Äì Scr0aplaibf yS < 0
cash incentive or the non-cash incentivey . iS ùë¶#$‚àó and ùë¶#&‚àói a‚á§ re the latent outcomes, only one of (4)
1.1 Model
(1 otherwise
which is observable, depending on the sign oyf Oùë¶1" (that iisf: ywSe= ob0serve either the quality of
y iO (yi iO2!‚á§ ‚á§y iS
‚á§
= o  tS h0xi eS irw+ is‚úè eS
i
( (5 1) )
designs produced under the cash treatment or the y iOq1u ‚á§a =lity   Op1r 0o xdO iu1c +ed ‚úè O iu1nder the non-cash treatme (n 2t )
but not both). Hence, we observe
y iO2
‚á§
= O20xO
i
2+‚úèO
i
2. (3)
‚úèS
‚úèO1 N(0,‚åÉ), (6)
2 3 ‚á†
‚úèO2
0 if yS <0
yS i ‚á§ (4)
4 5i
(1 otherwise
yO1 if yS =0
y1O i‚á¢‚á§ ‚á¢ 13 i (5)
‚åÉ =
‚á¢i (y iO 12
‚á§ ‚á¢
2o 3the .rwise.
(7)
2 3
‚á¢ ‚á¢ 1
13 23
Covariates x( are fixed ideator charact4 eristics‚úè S (home-co5 untry GDP, gender, and western
‚Äô
1.2 Results ‚úèO1 N(0,‚åÉ), (6)
2 3‚á†
‚úèO2
background) and a measure of competition at the time of registration (number of designs that had
4 5
Mean SD Min Max (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11)
already been suDbmesiigtnteQd)u.a Tlithye( v1)ector3 .ùõΩ33") are0 .t6h6e e1s.t0i0mate4d. 7r8egression coefficients and ùúñ" are the
Designs Submitted (2) 2.26 2.65 1.00 21 4.00‚á¢ 10.2‚á¢ 92 !
‚åÉ= ‚á¢ 1 ‚á¢ . (7)
Incentive: No Answer (3) 0.55 0.50 0.00 11.00 0.0823 0.22
error terms for It nh ce
e
ns te ivle e:ct Cio asn
h
e (q 4u )atio 0n ..
2
7Equa 0ti .4o 4n ( 02 .)
0
0an2d‚á¢ ( 213 .)
0
0‚á¢a 2r 3e
-
0t .h 01e
6
o3u -0t .c 1o 4me
-0
e .6q 6uations and model
Comments Written (5) 4.46 10.32 0.00 4115.00 0.14 50.30 0.21 -0.16
design
qualiR tya t cin og ns dS itu i1b om .n2ait lt e od Rn( ec6 s) ouvlatrsi7 a. t1 e1
s
x*18 (. p82 rof0 e. s0 s0 ion1 a6 l5 . d0 e0 sig0. n0 e0
rs,
0 ti.1 m0
e
s0 in.1 c1
e
re- g0. i0 s8 trat0 i. o5 n7
, and
Tenure (7) 31.14 ‚Äô22.06 0.14 70.44 0.00 0.21 0.11 -0.07 0.27 0.22
log(GDP) (8) 10.28 0.61 8.44 11.25 0.02 -0.02 -0.07 0.03 -0.09 0.00 -0.06
counts of ideators‚Äô suWbmesittetrend( d9)esign0s.4, 7comm0M.5eea0nnts0, .a0n0SdD raMt1i.inn00gs)-M.0 Ta.0xh7e( 1o-)0u.t0c6o(2m)0e.0 4e(q3)u-a0t.i0(o44)ns 0a.(0r5e2) -(06.)07 (07.)01 (80).40(9) (10) (11)
FemaleD(e1s0ig)nQua0li.t6y1(1) 0.34.933 0.000.66 11.0.000 -40.7.088 0.09 -0.04 0.03 0.12 -0.01 0.04 0.02 -0.03
CompetitDioensig(n1s1S)ubm29it0te.8d9(2)171.25.526 0.020.655717.0.000 2-40.0.002 0.-209.22 -0.11 0.07 -0.28 -0.21 -0.99 0.08 -0.01 -0.04
estimated separately foInrc eenatcivhe: tNreoaAtnmsweenrt(:3 )Eq. 0(.25)5 is e0s.5t0im0a.t0e0d fo1r.0 i0de0a.0to8rs 0w.22ho choose a non-cash
Professional (12) 0.36 0.48 0.00 1.00 -0.04 -0.03 -0.06 0.04 -0.01 -0.01 0.07 -0.12 0.10 -0.10 -0.08
Incentive: Cash(4) 0.27 0.44 0.00 1.00 -0.06 -0.14 -0.66
CommentsWritten(5) 4.46 10.32 0.00 115.00 0.14 0.30 0.21 -0.16
prize witTh atbhele o1b:seDrveesdc rdRiepatptineigvnsedSeusnbtmta ivtttiaesrdtiia(c6b)slea ùë¶n7d#.1$1caonrd1r8 eE.8l2qa t(0i3.o0)0n iss 1eo65sf.t0ii0mdea0at.0et0do rfso0.rw1 0ihdeo0a.m1to1arsd -w0e.0ha8ot 0cl.eh57aosotseo ne design submission
!
Tenure(7) 31.14 22.06 0.14 70.44 0.00 0.21 0.11 -0.07 0.27 0.22
(N=260)
log(GDP)(8) 10.28 0.61 8.44 11.25 0.02 -0.02 -0.07 0.03 -0.09 0.00 -0.06
Western(9) 0.47 0.50 0.00 1.00 -0.07 -0.06 0.04 -0.04 0.02 -0.07 0.01 0.40
Female(10) 0.61 0.49 0.00 1.00 -0.08 0.09 -0.04 0.03 0.12 -0.01 0.04 0.02 -0.03
Competition(11) 290.89 171.55 0.00 577.00 -0.02 -0.22 -0.11 0.07 -0.28 -0.213 -0.99 0.08 -0.01 -0.04
Professional(12) 0.36 0.48 0.00 1.00 -0.04 -0.03 -0.06 0.04 -0.01 -0.01 0.07 -0.12 0.10 -0.10 -0.08
Table1: Descriptivestatisticsandcorrelationsofideatorswhomadeatleastonedesignsubmission
(N=260)
1
1Incentive Paper - JMR Round 2
Incentive Paper - JMR Round 2
1 Study 1 ‚Äì Scraplab
1 1.S1tuMdoyd1el ‚Äì Scraplab
1.1 Model
y iS
‚á§
=  S0xS
i
+‚úèS
i
(1)
yy iOiSy
y
1‚á§ ‚á§i iO O1 2= =‚á§
‚á§
= =   S O   0 1xO
O
0xS i1
2
O
i0 0+x
x
1O i
O
i
+‚úè1 2S i+
+
‚úèO
i‚úè
‚úè
1O i
O
i
1
2.
( (1 2( () )2 3)
)
the cash prize with the observed dependent variable ùë¶#&. The two vectors ùõΩ#$) and ùõΩ#&) are
y iO2
‚á§
=  O2!0xO
i
2 +‚úèO
i
2. (3)
separate sets of estimated regression coeffici yeSnts 0for theif cyoiS v‚á§ar<ia0tes ùë• !#$ and ùë• !#&, respectively
(4)
i
(1 otherwise
(note, however, that we use the same cova yr Siate0s in y Ob 1oifthy; iSth ‚á§ ia< ft yi0s S ùë• =!#$ 0= ùë• !#&). The error terms (ùúñ 4!" ),
ùúñ#$, and ùúñ#& are trivariate normally distribi uy t( eiO d1 ( wy iti iO h2 o‚á§ ‚á§0t mhe er aw o nti hs aei ner dw ci ose variances [32] given by (5)
! ! yO1 if yS = 0
yO i ‚á§ i (5)
i (y iO ‚úè2
S‚á§
otherwise
‚úèO1 N(0,‚åÉ), (6)
2 3 ‚á†
‚úèO2
‚úèS
4 5
‚úèO1 N(0,‚åÉ), (6)
2 3 ‚á†
with ùõ¥
‚úèO2
1 ‚á¢ ‚á¢
13
4 5
‚åÉ = ‚á¢ 1 ‚á¢ . (7)
23
2 3
‚á¢ ‚á¢ 1
13 23
1 ‚á¢ ‚á¢
1 2
4 5
‚åÉ = ‚á¢ 1 ‚á¢ . (7)
1 23
1.2 Results 2 3
‚á¢ ‚á¢ 1
2 23
4 5
Mean SD Min Max (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11)
1.2 Results
DesignQuality(1) 3.33 0.66 1.00 4.78
In the model, the presence of selection can be quantified by the statistical and substantive
DesignsSubmitted(2) 2.26 2.65 1.00 24.00 0.29
Incentive: NoAnswer(3) 0.55 0.50 0.00 1.00 0.08 0.22
significance correlatioInnc ecnotievfef:icCiaesnht( 4ùúå)M e ba en0tw.27eenS D t0h.4e4M ei rn0r.o00rs M oa f1x t.h00e(1 s)-e0l.0e6c( t2 i) o-0n.1 4e( q3 u)-0a.6ti6o(4 n) (Eq( .5 ) 1), a( n6 d) (7) (8) (9) (10) (11)
CDoemsigmnenQtusaWlitryitt(e1n)(5)$3.334.46 0.6160.321.000.00 41.1758.00 0.14 0.30 0.21 -0.16
DesiRgnatsinSgusbSmuibttmeditt(e2d)(6) 2.267.11 2.6158.821.000.00241.6050.000.209.00 0.10 0.11 -0.08 0.57
the outcome eIqncueanttiivoen:sN fooAr nidswTeeearntuo(r3re)s (w7)h0o.5 3c51h.1o4os0.e52 02a. 0n60o.0n00-.c14ash1. 70p00r.4iz40e.0 0(8E.00q.0 .2202). 2a1nd 0t.h11e co-0r.r0e7lat0i.o2n7 0.22
Incentive:loCga(GshD(P4))(8) 0.2170.28 0.440.610.008.44 1.1010.25-0.006.02-0.-104.02-0.-606.07 0.03 -0.09 0.00 -0.06
Comments WriWtteesnte(r5n)(9) 4.460.4710.320.500.000.00115.010.000.1-40.070.3-00.060.201.04 -0.-106.04 0.02 -0.07 0.01 0.40
coefficient ùúå beRtawtinegesnS tuhbem eiFtretremodar(lse6 )o(1f0 t)h7e. 1s10e.l6e1c1t8i.o82n0. 4e90q.0u00a.0ti01o6n5 .(0E10.q00.0 .10-)00,. 0a8n0d.10 0t.h09e 0o.1u-10t.c04o-m0.00e.80 e3q0u.50a7.t1i2ons- 0f.o01r 0.04 0.02 -0.03
&
ComTepneutirteio(n7)(11)312.1940.89221.0761.550.140.00705.7474.000.0-00.020.2-10.220.1-10.11-0.00.707 0.2-07.280.-202.21 -0.99 0.08 -0.01 -0.04
lPogr(oGfeDssPio)na(8l)(12)10.280.36 0.610.488.440.0011.215.000.0-20.04-0.-002.03-0.-007.060.003.04 -0.-009.010.0-00.01-00.0.067 -0.12 0.10 -0.10 -0.08
ideators who choose the Wcaessthe rpnr(i9z)e (Eq0..4 37). If0 ùúå.5$0/& 0i.s0 0zero1, .t0h0en- 0t.h07e u-n0m.06eas0u.0r4ed f-0a.c0t4ors0 .0w2hic-h0. 07 0.01 0.40
Table 1:FDemesacleri(p10t)ive s0t.a6t1istic0s.4a9nd0.c0o0rrela1.t0i0ons-0o.0f8id0e.a0t9ors-0w.0h4o0m.0a3de0a.1t2lea-s0t.0o1ne0.d04esig0n.02sub-m0.0is3sion
Competition (11) 290.89 171.55 0.00 577.00 -0.02 -0.22 -0.11 0.07 -0.28 -0.21 -0.99 0.08 -0.01 -0.04
influence wheth(eNr =an2 6id0e)ator chooses an incentive are independent of the unmeasured factors
Professional (12) 0.36 0.48 0.00 1.00 -0.04 -0.03 -0.06 0.04 -0.01 -0.01 0.07 -0.12 0.10 -0.10 -0.08
which determTianbel eth1e: qDuaelsictyri potfi tvhees dtaestiigstni cpsroadnudcceodr breyl athtiaotn isdeoaftiodre. aIft oùúårs w ihso pmosaitdiveea tthleena sthteo ne design submission
$/&
(N=260)
unmeasured factors that lead an ideator to choose an incentive are positively correlated with the
unmeasured factors that lead them to produce designs of higher qu1ality. If, on the other hand,
ùúå is negative then the unmeasured factors that lead an ideator to choose an incentive are
$/&
1
negatively correlated with the unmeasured factors that lead them produce designs of higher
quality. We estimate the equations simultaneously using maximum-likelihood in R [29] using the
SampleSelection package [32].
4Construction of Dependent Variable: In this section we provide additional details how
we constructed the baseline rating of design quality. We measure the dependent variable,
Design Quality, for all designs submitted to the contest using the Consensual Assessment
Technique (CAT; Amabile, 1982). We recruited an independent jury that was blind to the
research hypotheses from reliable and experienced workers on Amazon Mechanical Turk. 1
This panel evaluated each product based on the following six dimensions: (1)
creativity, (2) novel use of materials (e.g., materials are used in a unique way), (3) novel
association (e.g., unique or unusual association with existing products or objects), (4)
variation of materials used (e.g., different materials, number of colors, originality), (5) level
of detail and complexity (e.g., of the design or decoration), and (6) appearance (i.e., how
good it would look in a home or office).
Workers were instructed to make relative assessments based on their own definition
of creativity [2]. As part of the instructions, workers were shown a grid of nine randomly
selected designs to facilitate this relative assessment. Workers evaluated designs in random
order and for each design, the assessment items were arranged in random order. We
collected five evaluations for each design, resulting in 2,927 ratings of each of the six
assessment items (17,562 ratings in total) from a total of 77 different raters. We apply the
technique suggested by (Ipeirotis, Provost, and Wang 2010) to identify and then remove
unreliable workers. The technique identified 17 low-quality raters who submitted ratings
with extremely low information content (e.g., rating completely at random or submitting
1 AMT offers a mechanism to restrict the pool of eligible workers using various qualifications. We
restricted our task to workers with the following qualifications:
‚Ä¢ Approval rate for all prior tasks greater than or equal to 99%
‚Ä¢ Number of tasks approved greater than or equal to 10,000.
That is, selecting experienced workers is nothing that we did specifically, but is a feature directly
available on AMT.
5identical ratings for all five items). These raters collectively submitted 432 ratings (15%).
After cleaning the ratings from low-quality raters, 2,495 ratings remain (that is, 14,970
ratings in total), with an average of 4.3 ratings per design and 42 ratings per rater.2 We paid
workers on average $4.20 for their effort.
The key premise of a crowdsourcing contest is to attract submissions from a diverse pool
of participants [23]. Hence, crowdsourcing contests are most effective when they are geared
toward reaching out to outsiders to solicit creative ideas. Research has now shown that 1)
online panels such as those from Amazon Mechanical Turk are appropriate [34], 2) expertise
does not significantly affect the quality of assessments [30], 3) high correlation exists between
the assessments from experts and laypeople across different evaluation methods [4], and 4)
assessments from panels of consumers can be even better than expert panels [24]. Overall, we
conceptualize the performance of ideators in crowdsourcing idea contests as the quality of the
best idea that an individual submits, rather than effort (e.g., measure in time spent on the task
or the length of the submitted idea).
Prior research on ideation has often defined performance as the average quality of ideas
or the number of ideas generated by an individual, ignoring that most organizations seek a
few great ideas [17]. Consequently, in case an ideator made multiple design submissions, we
use the quality of the ideator‚Äôs best submission. That is, at the individual level, the
performance of an ideator is then measured as the quality of the best idea that an individual
submitted. A focus on ideators‚Äô best idea rather than average idea quality is also more
consistent with the nature of a rank-order tournament in which prizes are only awarded to the
2 Robustness tests including all ratings and not dropping low-quality raters do not substantively
change our conclusions but explained variance (R2) is lower, supporting the notion that low-quality raters
added only noise.
6contest winners.3
Cronbach‚Äôs alpha of 0.9 indicates high internal consistency of the six assessment items.
Intercoder reliability ICC (2,k) for the aggregated scale (all six items) is 0.70 indicating good
inter-rater agreement [7]. Individual item ICC (2,k) range from 0.59 to 0.66. The quality of
ideas, i.e., their creativity, is critically important for an innovation‚Äôs success and ultimately
market success [24] and is thus most important from a managerial perspective.
3 We do perform robustness tests using an ideator‚Äôs average quality instead and find substantively similar results. See section on robustness tests
for more details.
7Sample Designs ‚Äì We show example designs submitted to the consumer innovation
contest.
8Robustness Tests Using Alternative Measures of Quality: Since the goal in rank order
contests is to win the contest, we focused the analyses presented in the main paper on the
quality of the best idea submitted by an ideator. We show correlation coefficients of three
different quality measures in the table below and find substantively similar results for any of the
three quality measures. Not surprisingly, the maximum and mean quality are highly correlated
(ùúå = 0.88; p < .001). We find substantively similar results using average quality as the
dependent variable.
Correlation of quality measures (N=259).
Mean SD Min Max (1) (2)
DesignQualityBestIdea(AMT;mainmeasureusedinpaper)(1) 3.33 0.66 1.00 4.78
AverageDesignQuality(AMT)(2) 3.14 0.61 1.00 4.50 0.88***
AverageCommunityRatingBestIdea(3) 3.56 0.73 1.00 4.90 0.37*** 0.28***
Table 5: Correlation of quality measures (N=259).
6
9Appendix 3. Study 1 ‚Äì Descriptive statistics and correlations of main study variables of ideators
who made at least one design submission (N = 259).
1 Study 1 - Scrablab Field Experiment
Mean SD Min Max (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11)
DesignQuality(1) 3.33 0.66 1.00 4.78
DesignsSubmitted(2) 2.26 2.65 1.00 24.00 0.29
Incentive: NoAnswer(3) 0.55 0.50 0.00 1.00 0.08 0.22
Incentive: Cash(4) 0.27 0.44 0.00 1.00 -0.06 -0.14 -0.66
CommentsWritten(5) 4.46 10.32 0.00 115.00 0.14 0.30 0.21 -0.16
RatingsSubmitted(6) 7.11 18.82 0.00 165.00 0.00 0.10 0.11 -0.08 0.57
Tenure(7) 31.14 22.06 0.14 70.44 0.00 0.21 0.11 -0.07 0.27 0.22
log(GDP)(8) 10.28 0.61 8.44 11.25 0.02 -0.02 -0.07 0.03 -0.09 0.00 -0.06
Western(9) 0.47 0.50 0.00 1.00 -0.07 -0.06 0.04 -0.04 0.02 -0.07 0.01 0.40
Female(10) 0.61 0.49 0.00 1.00 -0.08 0.09 -0.04 0.03 0.12 -0.01 0.04 0.02 -0.03
DesignsPriortoRegistration(11) 290.89 171.55 0.00 577.00 -0.02 -0.22 -0.11 0.07 -0.28 -0.21 -0.99 0.08 -0.01 -0.04
Professional(12) 0.36 0.48 0.00 1.00 -0.04 -0.03 -0.06 0.04 -0.01 -0.01 0.07 -0.12 0.10 -0.10 -0.08
Table 1: Study 1 - Descriptive statistics and correlations of main study variables of ideators who
made at least one design subm ission (N = 259).
N Percent Percent
Female >0 E‚Üµort
No Choice 281 (23%) 56% 50%
Cash 333 (28%) 72% 21%
Donation 171 (14%) 82% 6%
Internship 170 (14%) 80% 18%
Workshop 127 (11%) 97% 5%
Party 123 (10%) 90% 1%
Total 1,205 75% 21%
Table 2: Study 1 - Incentive choices and activity. We provide the number of participants who
choose each of the prizes. We give the percentage of ideators (among the total of 1,205) who chose
a given prize in parentheses.
1
10Dependent Variable Non-Cash Preference
(1)
Intercept 0.91
 
(1.67)
log(GDP) 0.05
(0.16)
Western 0.97
‚á§‚á§‚á§
(0.18)
Female 0.38
‚á§
(0.19)
AIC 1152.77
Log Likelihood 572.39
 
Deviance 1144.77
Num. obs. 924
‚á§‚á§‚á§p<0.01;‚á§‚á§p<0.05;‚á§p<0.1
Table 3: StuAdpyp1en-dLixo g2i.s Stitcudreyg 1re -s sBioinvaorifatneo Pn-rcoabsiht oifn cjoeninttiv deecpirseifoenre tnoc ae.nswSaemr pthlee: inAclelnrtievgeis qteureesdtion and
ideators whopeaxrptirceispsaetde i(nmceanktei vaet lperaesfte roennec ed.esign submission). Sample: All registered ideators.
Choose Incentive > 0 E‚Üµort
(1) (2)
Intercept 3.208 4.968
‚á§‚á§‚á§ ‚á§‚á§‚á§
 
(0.834) (0.918)
log(GDP) 0.312 0.539
‚á§‚á§‚á§ ‚á§‚á§‚á§
 
(0.081) (0.086)
Western 0.606 0.281
‚á§‚á§‚á§ ‚á§‚á§
 
(0.093) (0.127)
Female 0.514 0.428
‚á§‚á§‚á§ ‚á§‚á§‚á§
 
(0.092) (0.094)
Designs Prior to Registration 0.049 0.038
 
(0.038) (0.036)
Choose Incentive: Yes 0.621
‚á§‚á§
(0.261)
‚á¢ -0.863
(p-value,  2 test of ‚á¢ = 0) (0.002)
‚á§‚á§‚á§
Total edf 12
Num. obs. 1,205
Pseudo-R2 0.088
‚á§‚á§‚á§p<0.01,‚á§‚á§p<0.05,‚á§p<0.1
Table4: Stud y1-BivariateProbitofjointdecisiontoanswertheincentivequestionandparticipate
(make at least onCehdoesicigen asnudb mbeiscsoiomni)n.gS aamctpivlee:. IAnltlerreegstiisntegrleyd, tihdee a7t7o%rs. (N=924) of participants who actively
chose an incentive show a lower probability to submit an idea 12.8% (N=118) than those 23%
(N=281) participants who made no choice. No-choice participants show a much higher
probability to submit an idea (50%, 2N=140; Table 1 in the main text).
To further explore the effect of incentive choice on becoming active, we conducted a
bivariate probit model [18]. This model allowed us to further explore the effect of the sequential
choice of incentive followed by the choice to exert effort and make a submission. The analysis
shows that choice has a positive effect on becoming active when controlling for participants‚Äô
individual characteristics. Personal characteristics ‚Äì high-income country (Œ≤ = -.54; p < 0.01),
western background (Œ≤ = -.28; p < 0.05), and female (Œ≤ = - .43; p < 0.01) ‚Äì are strongly
negatively correlated with submitting a design. Controlling for these characteristics reveals a
positive effect of choosing an incentive (Œ≤ = .62; p < 0.05) and becoming active. Contrary to our
descriptive observation, we find that choice significantly increases the likelihood of becoming
active by 38.7%.
11Appendix 3. Study 1 - Logistic regression of non-cash incentive preference. Sample: All
registered ideators who expressed incentive preference.
Dependent Variable Non-Cash Preference
(1)
Intercept 0.91
 
(1.67)
log(GDP) 0.05
(0.16)
Western 0.97
‚á§‚á§‚á§
(0.18)
Female 0.38
‚á§
(0.19)
AIC 1152.77
Log Likelihood 572.39
 
Deviance 1144.77
Num. obs. 924
‚á§‚á§‚á§p<0.01;‚á§‚á§p<0.05;‚á§p<0.1
Table 3: Study 1 - Logistic regression of non-cash incentive preference. Sample: All registered
ideators who expressed incentive preference.
Appendix 4. Study 2 (Volunteer Science Sample): Study design and description of participant
choices.
Descriptives for Study 2-4 Choose Incentive > 0 E‚Üµort
(1) (2)
Intercept 3.208 4.968
IncentiveR eceived ‚á§‚á§‚á§ ‚á§‚á§‚á§
Total NoPrize Cash N(o0n-.C8a3sh4) Indi‚Üµerent (0.918) Comment
Assiglonegd(NGoDPrPiz)e 13 13(100%) 0.312 0.539
‚á§‚á§‚á§ ‚á§‚á§‚á§
AssignedCash 23 23(100%)  
Assignednon-Cash 26 26(0(1.0008%1)) (0.086)
Choice1(cWashe/nsotne-rcansh) 41 23(56%) 180(4.46%0)6 ‚á§‚á§‚á§ n0o.s2ig8.1d‚á§i‚Üµ‚á§erence
Choice2(cash/indi‚Üµerent/non-cash) 60 22(37%) 16(27%) 22(37%)  nosig. di‚Üµerence
(0.093) (0.127)
Choice3(cash/opt-out) 45 13(29%) 32(71%) cashsig.morepopular(p<0.007)
Female 0.514 0.428
Total 208 26 100 60 ‚á§‚á§‚á§22 ‚á§‚á§‚á§
 
(0.092) (0.094)
Table 6: Study 2 (VDoelusingtneesrPScriieonrcetoSaRmepglies)t:raSttuiodny design an0d.0d4e9scription of par0t.i0ci3p8ant choices.
 
(0.038) (0.036)
Choose Incentive: Yes 0.621
IncentiveReceived ‚á§‚á§
TreatmentCondition Total NoPrize Cash Non-Cash Indi‚Üµerent (0.261) Comment
Assig‚á¢nedNoPrize 21 21(100%) -0.863
A (pssi -g vn aed luC ea ,sh  2 t2 e0 st of ‚á¢ = 0) 20(100%) (0.002)
Assignednon-Cash 29 29(100%) ‚á§‚á§‚á§
Choice1(cTasho/tnaoln-ecadshf) 22 22(100%) 0(0%) 12 cashsig.morepopular(p<0.001)
Choice2(cash/indi‚Üµerent/non-cash) 46 37(80%) 4(9%) 5(10%) cashsig.morepopular(p<0.001)
Choice3(Ncaushm/op.t-oobuts). 48 2(4%) 46(96%) 1,205 cashsig.morepopular(p<0.001)
PseudoTo-tRal2 186 23 125 33 50.088
Table 7: Study 3‚á§(‚á§O‚á§pnl<in0e.0L1,a‚á§b‚á§opr<M0a.0r5k,e‚á§tpS<am0.1ple): Study design and description of participant
choices.
Table4: Study1-BivariateProbitofjointdecisiontoanswertheincentivequestionandparticipat12e
(make at least one design submission). Sample: All registered ideators.
IncentiveReceived
TreatmentCondition Total Cash Non-Cash Comment
AssignedCash 9 9(100%)
For-Profit AssignedNon-Cash 13 13(100%)
Choice(cash/non-cash) 39 30(77%) 9(23%2) cashsig.morepopularthannon-cash(p=0.001)
AssignedCash 9 9(100%)
Non-Profit AssignedNon-Cash 11 11(100%)
Choice(cash/non-cash) 39 27(69%) 12(31%) cashsig.morepopularthannon-cash(p=0.02)
cashequallypopularinfor-profitvs.non-profit(p=0.79)
Total 120 75 45
Table 8: Study 4 (Framing Study): Study design and description of participant choices. No
significantdi‚Üµerencebetweenchoosingcashinfor-profitvs. non-profitframing(30outof39vs. 27
out of 39; p=0.6.
6Descriptives for Study 2-4
IncentiveReceived
Total NoPrize Cash Non-Cash Indi‚Üµerent Comment
AssignedNoPrize 13 13(100%)
AssignedCash 23 23(100%)
Assignednon-Cash 26 26(100%)
Choice1(cash/non-cash) 41 23(56%) 18(44%) nosig. di‚Üµerence
Choice2(cash/indi‚Üµerent/non-cash) 60 22(37%) 16(27%) 22(37%) nosig. di‚Üµerence
Choice3(cash/opt-out) 45 13(29%) 32(71%) cashsig.morepopular(p<0.007)
Total 208 26 100 60 22
Table 6: Study 2 (Volunteer Science Sample): Study design and description of participant choices.
IncentiveReceived
TreatmentCondition Total NoPrize Cash Non-Cash Indi‚Üµerent Comment
AssignedNoPrize 21 21(100%)
AssignedCash 20 20(100%)
Assignednon-Cash 29 29(100%)
Choice1(cash/non-cash) 22 22(100%) 0(0%) cashsig.morepopular(p<0.001)
Choice2(cash/indi‚Üµerent/non-cash) 46 37(80%) 4(9%) 5(10%) cashsig.morepopular(p<0.001)
Choice3(cash/opt-out) 48 2(4%) 46(96%) cashsig.morepopular(p<0.001)
Appendix 5. Study 3 (Framing Study): Study design and description of participant choices. No
Total 186 23 125 33 5
significant difference between choosing cash in for-profit vs. non-profit framing (30 out of 39 vs.
27 out of T3a9b;l ep 7=: 0S.t6u.d y 3 (Online Labor Market Sample): Study design and description of participant
choices.
IncentiveReceived
TreatmentCondition Total Cash Non-Cash Comment
AssignedCash 9 9(100%)
For-Profit AssignedNon-Cash 13 13(100%)
Choice(cash/non-cash) 39 30(77%) 9(23%) cashsig.morepopularthannon-cash(p=0.001)
AssignedCash 9 9(100%)
Non-Profit AssignedNon-Cash 11 11(100%)
Choice(cash/non-cash) 39 27(69%) 12(31%) cashsig.morepopularthannon-cash(p=0.02)
cashequallypopularinfor-profitvs.non-profit(p=0.79)
Total 120 75 45
Table 8: Study 4 (Framing Study): Study design and description of participant choices. No
significantdi‚Üµerencebetweenchoosingcashinfor-profitvs. non-profitframing(30outof39vs. 27
out of 39; p=0.6.
Appendix 6. Study 3: Social value orientation is strong predictor of preference for non-cash
incentives across both for- and non-profit contexts.
Dependent Variable Non-Cash Preference
(1) (2) (3)
Intercept 3.68‚á§‚á§‚á§ 3.78‚á§‚á§‚á§ 4.19‚á§‚á§
     
(1.09) (1.10)6 (1.78)
SVO 4.20‚á§‚á§‚á§ 4.13‚á§‚á§‚á§ 4.74‚á§
(1.56) (1.55) (2.62)
Context: Non-Profit 0.29 0.95
(0.55) (2.24)
SVO Context: Non-Profit 0.99
‚á•  
(3.25)
AIC 84.55 86.28 88.18
Log Likelihood 40.28 40.14 40.09
     
Deviance 80.55 80.28 80.18
Num. obs. 78 78 78
‚á§‚á§‚á§p<0.01;‚á§‚á§p<0.05;‚á§p<0.1
Table 10: Study 3: Social value orientation is strong predictor of preference for non-cash incentives
across both for- and non-profit contexts.
13
8Descriptives for Study 2-4
IncentiveReceived
Total NoPrize Cash Non-Cash Indi‚Üµerent Comment
AssignedNoPrize 13 13(100%)
AssignedCash 23 23(100%)
Assignednon-Cash 26 26(100%)
Choice1(cash/non-cash) 41 23(56%) 18(44%) nosig. di‚Üµerence
Choice2(cash/indi‚Üµerent/non-cash) 60 22(37%) 16(27%) 22(37%) nosig. di‚Üµerence
Choice3(cash/opt-out) 45 13(29%) 32(71%) cashsig.morepopular(p<0.007)
Appendix 7. Study 4 (Online Labor Market Sample): Study design and description of participant
Total 208 26 100 60 22
choices.
Table 6: Study 2 (Volunteer Science Sample): Study design and description of participant choices.
IncentiveReceived
TreatmentCondition Total NoPrize Cash Non-Cash Indi‚Üµerent Comment
AssignedNoPrize 21 21(100%)
AssignedCash 20 20(100%)
Assignednon-Cash 29 29(100%)
Choice1(cash/non-cash) 22 22(100%) 0(0%) cashsig.morepopular(p<0.001)
Choice2(cash/indi‚Üµerent/non-cash) 46 37(80%) 4(9%) 5(10%) cashsig.morepopular(p<0.001)
Choice3(cash/opt-out) 48 2(4%) 46(96%) cashsig.morepopular(p<0.001)
Total 186 23 125 33 5
Table 7: Study 3 (Online Labor Market Sample): Study design and description of participant
choices.
IncentiveReceived
TreatmentCondition Total Cash Non-Cash Comment
AssignedCash 9 9(100%)
For-Profit AssignedNon-Cash 13 13(100%)
Choice(cash/non-cash) 39 30(77%) 9(23%) cashsig.morepopularthannon-cash(p=0.001)
AssignedCash 9 9(100%)
Non-Profit AssignedNon-Cash 11 11(100%)
Choice(cash/non-cash) 39 27(69%) 12(31%) cashsig.morepopularthannon-cash(p=0.02)
cashequallypopularinfor-profitvs.non-profit(p=0.79)
Total 120 75 45
Table 8: Study 4 (Framing Study): Study design and description of participant choices. No
significantdi‚Üµerencebetweenchoosingcashinfor-profitvs. non-profitframing(30outof39vs. 27
out of 39; p=0.6.
6
14REFERENCES - Appendix
1. Acar, O.A. Harnessing the creative potential of consumers: money, participation, and
creativity in idea crowdsourcing. Marketing Letters, 29, 2 (2018), 177‚Äì188.
2. Amabile, T.M. Social psychology of creativity: A consensual assessment technique.
Journal of Personality and Social Psychology, 43, 5 (1982), 997‚Äì1013.
3. Amabile, T.M., Hennessey, B.A., and Grossman, B.S. Social influences on creativity: The
effects of contracted-for reward. Journal of Personality and Social Psychology, 50, 1
(1986), 14.
4. Blohm, I., Riedl, C., F√ºller, J., and Leimeister, J.M. Rate or Trade? Identifying Winning
Ideas in Open Idea Sourcing. Information Systems Research, 27, 1 (2016), 27‚Äì48.
5. Boudreau, K.J., Lacetera, N., and Lakhani, K.R. Incentives and Problem Uncertainty in
Innovation Contests: An Empirical Analysis. Management Science, 57, 5 (2011), 843‚Äì
863.
6. Cappa, F., Rosso, F., and Hayes, D. Monetary and Social Rewards for Crowdsourcing.
Sustainability, 11, 10 (2019), 2834.
7. Cicchetti, D. V. Guidelines, criteria, and rules of thumb for evaluating normed and
standardized assessment instruments in psychology. Psychological Assessment, 6, 4
(1994), 284‚Äì290.
8. Deci, E.L. Effects of externally mediated rewards on intrinsic motivation. Journal of
personality and Social Psychology, 18, 1 (1971), 105.
9. Deci, E.L. Notes on the theory and metatheory of intrinsic motivation. Organizational
behavior and human performance, 15, 1 (1976), 130‚Äì145.
10. Deci, E.L. and Cascio, W.F. Changes in intrinsic motivation as a function of negative
feedback and threats. (1972).
11. Ederer, F. and Manso, G. Is Pay For Performance Detrimental to Innovation?
Management Science, 59, 7 (2013), 1496‚Äì1513.
12. Eisenberger, R. and Rhoades, L. Incremental Effects of Reward on Creativity. Journal of
personality and social psychology, 81, 4 (2001), 728.
13. Eisenberger, R. and Selbst, M. Does Reward Increase or Decrease Creativity? Journal of
Personality and Social Psychology, 66, 6 (1994), 1116‚Äì1127.
14. Erat, S. and Gneezy, U. Incentives for Creativity. Experimental Economics, 19, 2 (2016),
269‚Äì280.
15. Fischer, C., Malycha, C.P., and Schafmann, E. The influence of intrinsic motivation and
synergistic extrinsic motivators on creativity and innovation. Frontiers in Psychology, 10,
(2019), 137.
16. Fullerton, R.L., Linster, B.G., MCKee, M., and Slate, S. An experimental investigation of
research tournaments. Economic Inquiry, 37, 4 (1999), 624‚Äì636.
17. Girotra, K., Terwiesch, C., and Ulrich, K.T. Idea generation and the quality of the best
idea. Management Science, 56, 4 (2010), 591‚Äì605.
18. Greene, W.H. Econometric Analysis. Prentice Hall, Boston, MA, 2011.
19. Hamner, W.C. and Foster, L.W. Are intrinsic and extrinsic rewards additive: A test of
Deci‚Äôs cognitive evaluation theory of task motivation. Organizational Behavior and
Human Performance, 14, 3 (1975), 398‚Äì415.
20. Heyman, J. and Ariely, D. Effort for payment - A tale of two markets. Psychological
Science, 15, 11 (November 2004), 787‚Äì793.
1521. Hofstetter, R., Zhang, Z.J., and Herrmann, A. The Hidden Pitfall of Innovation Prizes.
(2017).
22. Ipeirotis, P.G., Provost, F., and Wang, J. Quality management on Amazon Mechanical
Turk. Proceedings of the ACM SIGKDD Workshop on Human Computation - HCOMP
‚Äô10, (2010).
23. Jeppesen, L.B. and Lakhani, K.R. Marginality and problem solving effectiveness in
broadcast search. Organization Science, 21, 5 (2010), 1016‚Äì1033.
24. Kornish, L.J. and Ulrich, K.T. The Importance of the Raw Idea in Innovation: Testing the
Sow‚Äôs Ear Hypothesis. Journal of Marketing Research, 51, 1 (2014), 14‚Äì26.
25. Liu, T.X., Yang, J., Adamic, L.A., and Chen, Y. Crowdsourcing with all-pay auctions: A
field experiment on Taskcn. Management Science, 60, 8 (2014).
26. Moghaddam, E.N., Aliahmadi, A., Bagherzadeh, M., Markovic, S., Micevski, M., and
Saghafi, F. Let me choose what I want: The influence of incentive choice flexibility on the
quality of crowdsourcing solutions to innovation problems. Technovation, 120, (February
2023), 102679.
27. Pinder, C.C. Additivity versus nonadditivity of intrinsic and extrinsic incentives:
Implications for work motivation, performance, and attitudes. Journal of Applied
Psychology, 61, 6 (1976), 693.
28. Pritchard, R.D., Campbell, K.M., and Campbell, D.J. Effects of extrinsic financial rewards
on intrinsic motivation. Journal of Applied Psychology, 62, 1 (1977), 9.
29. R Core Team. R: A Language and Environment for Statistical Computing. 2015.
30. Riedl, C., Blohm, I., Leimeister, J.M., and Krcmar, H. The Effect of Rating Scales on
Decision Quality and User Attitudes in Online Innovation Communities. International
Journal of Electronic Commerce, 17, 3 (2012), 7‚Äì36.
31. Sittenthaler, H.M. and Mohnen, A. Cash, non-cash, or mix? Gender matters! The impact
of monetary, non-monetary, and mixed incentives on performance. Journal of Business
Economics, 90, (2020), 1253‚Äì1284.
32. Toomet, O. and Henningsen, A. Sample Selection Models in R: Package sampleSelection.
Journal of Statistical Software, 27, 7 (2008).
33. Toubia, O. Idea generation, creativity, and incentives. Marketing Science, 25, 5 (2006),
411‚Äì425.
34. Toubia, O. and Netzer, O. Idea Generation, Creativity, and Prototypicality. Marketing
Science, 36, 1 (2017), 1‚Äì20.
16