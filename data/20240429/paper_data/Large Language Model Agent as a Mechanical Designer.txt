Large Language Model Agent as
a Mechanical Designer
Conventional mechanical design paradigms rely on experts systematically refining con-
ceptsthroughexperience-guidedmodificationandFiniteElementAnalysis(FEA)tomeet
specificrequirements. However,thisapproachcanbetime-consumingandheavilydepen-
dentonpriorknowledgeandexperience. Whilenumerousmachinelearningmodelshave
YayatiJadhav
beendevelopedtostreamlinethisintensiveandexpert-driveniterativeprocess,thesemeth-
MechanicalEngineering, odstypicallydemandextensivetrainingdataandconsiderablecomputationalresources.
CarnegieMellonUniversity, Furthermore, methods based on deep learning are usually restricted to the specific do-
5000ForbesAve, mains and tasks for which they were trained, limiting their applicability across different
Pittsburgh,PA,USA tasks. This creates a trade-off between the efficiency of automation and the demand for
email:yayatij@andrew.cmu.edu resources. In this study, we present a novel approach that integrates pre-trained large
languagemodels(LLMs)withaFiniteElementMethod(FEM)module. TheFEMmodule
AmirBaratiFarimani1 evaluateseachdesignandprovidesessentialfeedback,guidingtheLLMstocontinuously
learn, plan, generate, and optimize designs without the need for domain-specific train-
MechanicalEngineering,
ing. This methodology ensures that the design process is both efficient and adherent to
CarnegieMellonUniversity,
engineering standards. We demonstrate the effectiveness of our proposed framework in
5000ForbesAve,
managingtheiterativeoptimizationoftrussstructures, showcasingitscapabilitytorea-
Pittsburgh,PA,USA
son about and refine designs according to structured feedback and criteria. Our results
email:barati@cmu.edu
reveal that these LLM-based agents can successfully generate truss designs that comply
with natural language specifications with a success rate of up to 90%, which varies ac-
cording to the applied constraints. Furthermore, employing prompt-based optimization
techniquesweshowthatLLMbasedagentsexhibitoptimizationbehaviorwhenprovided
withsolution-scorepairstoiterativelyrefinedesignstomeetspecifiedrequirements. This
ability of LLM agents to independently produce viable designs and subsequently opti-
mize them based on their inherent reasoning capabilities highlights their potential to
autonomouslydevelopandimplementeffectivedesignstrategies.
Keywords: Designautomation,Deeplearning,LargeLanguageModels
1 Introduction be computationally intensive and slow to converge, especially for
complex problems. BESO and VARTOP methods, may require
Mechanicaldesignisfundamentallyaniterativeprocessandre-
parameter tuning and can struggle with capturing fine details in
lies on a forward design-based approach [1]. To design complex
theoptimizeddesign. Furthermore,theaforementionedoptimiza-
mechanical structures, expert designers navigate massive design
tionmethods,heavilydependonfiniteelementmethods(FEM)to
spaces by making relevant sequential decisions grounded in rea-
simulatestructuralresponses[19]. WhileFEMisinstrumentalin
soningandexperiencetoidentifypromisingsearchdirections,typ-
predictinghowstructuresbehaveundervariousconditions,itsuse
ically guided by finite elements methods (FEM) [2â€“5]. However,
initerativeoptimizationprocessescansignificantlyincreasecom-
thecomplexityofdesigningmechanicalstructuresisfurtherexac-
putational demands, thereby elevating the overall computational
erbatedbylooselydefinedproblems,timeconstraintsandstringent
costandpotentiallylimitingthescopeandspeedoftheoptimiza-
requirements. Moreover, the non-linear material response [6, 7]
tionprocessesinmechanicaldesign.
andnon-linearrelationshipsbetweendesignvariables[8,9]intro-
duce additional complexity to the design process, as optimizing Data-drivendeeplearning(DL)methodshaveenabledefficient
oneobjectivemightinadvertentlycompromiseanother. dataprocessinganddistillationofrelevantinformationfromhigh-
The iterative nature of mechanical design, coupled with the dimensionaldatasets[20â€“22],leadingtohighlyaccuratemodelsin
complexitiesfromnon-linearinteractionsandvariableinterdepen- fields like additive manufacturing [23, 24], solid mechanics [25â€“
dencies, naturally leads to the adoption of sophisticated compu- 28], among others [29, 30]. In recent years these methods have
tational optimization methods. These methods include gradient- shiftedmechanicaldesignfromaniterativephysics-basedapproach
based approaches like the Solid Isotropic Material with Penaliza- toamoredynamic,data-drivenapproach.
tion(SIMP)[10,11]andgradient-freetechniquessuchasGenetic Inrecentyears,theintersectionofdeeplearningandmechanical
Algorithms [12â€“14]. Additionally, the Bidirectional Evolutionary design has seen remarkable progress, transforming the conceptu-
Structural Optimization (BESO) [15, 16] and Variational Topol- alization and realization of 3D structures. This advancement has
ogy Optimization (VARTOP) [17, 18] methods offer alternative facilitated the creation of 3D models across a diverse array of
strategiesfordesignandtopologyoptimization, eachwithunique formats, including voxels [31, 32], point clouds [33â€“35], neural
benefitsfornavigatingthevastdesignspacesinmechanicalengi- radiance fields (NeRF) [36, 37], boundary representation (B-rep)
neering. These optimization methods, while powerful, have their [38, 39], triangular meshes [40, 41], and computer-aided design
disadvantages. Gradient-based methods like SIMP can be sensi- (CAD) operation sequence [42]. The capability to generate 3D
tive to initial design choices, potentially leading to local rather structures from diverse input modalities, including text [43, 44],
than global optima. Genetic Algorithms, although versatile, can images [45], and sketches [46â€“48], has expanded the possibili-
tiesandmadethefieldofmechanicaldesignmoreaccessibleand
1CorrespondingAuthor. versatile. However, a notable limitation is that these models are
Version1.18,April26,2024 notinherentlydesignedtoaccountformechanicalspecificationsor
1Fig.1 Schematicoftheproposedframework. Specifications,boundaries,andloadingconditionsareprovidedinnatural
language.Thelargelanguagemodel(LLM)Agentgeneratesacandidatesolution,whichisthenevaluatedusingfiniteelement
method(FEM)thatservesasadiscriminator. TheFEMprovidesfeedbacktotheLLMAgentintheformofasolution-score
pair,enablingtheLLMtoidentifyandimplementthemodificationsneededtomeetthespecifiedrequirements.
functionalconstraints. ing (ICL) paradigm [64], which has significantly deepened our
Integratingdeeplearningwithtopologyoptimizationpresentsa understanding of LLMsâ€™ capabilities. By utilizing minimal nat-
significant advancement, addressing the challenges posed by tra- ural language templates and requiring no extensive fine-tuning,
ditional 3D modeling in mechanical design and the intrinsic lim- LLMshaveestablishedthemselvesasefficient"few-shotlearners"
itations of standard topology optimization. This approach views [75,76].
topologyoptimizationasaformofdeeplearningproblemakinto TheabilityofLLMstoadapttonewdomainsandlearnincon-
pixel-wise image labeling, optimizing material distribution based text has proven pivotal in scientific research across various disci-
onobjectivesandconstraints[49]. Anotherapproachinvolveshar- plines. Inchemistry,forinstance,LLMshavebeenusedtodesign,
nessingalargedatasetofoptimalsolutionsandemployinggener- plan,andconductcomplexexperimentsindependently[77,78]. In
ativenetworkssuchasconditionalgenerativeadversarialnetworks the realm of mathematics and computer science, LLMs have un-
(cGANs) [50, 51] and diffusion models [52] to generate optimal coverednovelsolutionstolongstandingproblems,suchasthecap
structures. However, duetotheirinherentstochasticnature, these setproblem,andhavedevelopedmoreefficientalgorithmsforchal-
methods cannot guarantee optimal structures, thus necessitating lengeslikethe"bin-packing"problem[79]. LLMshavealsomade
theuseofFEA.Deeplearningbasedsurrogatemodelshavebeen significantcontributionstobiomedicalresearch[80â€“82],materials
shown to predict mechanical responses such as stress and strain science[83,84],andenvironmentalscience[85]. Theirimpactex-
fields[28,53,54],reducingcomputationalcosts. Thesesurrogate tendstootherscientificfieldsaswell,enhancingourunderstanding
modelscanbecombinedwithtopologyoptimization[55â€“57].Ano- and capabilities in these areas [86â€“89]. Additionally LLMs have
tableapproachforoptimizingstructurescombinesneuralnetworks proveneffectiveasoptimizersforfoundationalproblemslikelinear
withmetaheuristicalgorithmslikegeneticalgorithmswhereinneu- regressionandthetravelingsalesmanproblem,oftenmatchingor
ralnetworklearnsthestructureâ€™smechanicalresponseaidingprop- surpassing custom heuristics in finding quality solutions through
erty prediction, while the genetic algorithm navigates the design simpleprompting[90].
spaceforoptimalstructures[58]. In mechanical engineering, the fine-tuned LLM has demon-
Whiledeeplearningoffersremarkablecapabilities,itfacesno- strateditsexcellenceinknowledgeretrieval,hypothesisgeneration,
table challenges and limitations. Notably, generative models like agent-based modeling, and connecting diverse domains through
cGANs [50, 53] and diffusion models [28, 52] often require vast ontological knowledge graphs [91]. Additionally, LLMs have ef-
amounts of diverse datasets to effectively model the dynamics fectively automated the generation of early-stage design concepts
of underlying systems [59â€“61]. This is particularly challenging by synthesizing domainknowledge [92, 93]. Furthermore, LLMs
in contexts like finite element method (FEM) simulations, where have shown significant capabilities in design tasks such as sketch
producing high-fidelity, fine-mesh datasets demands considerable similarityanalysis,materialselection,engineeringdrawinganaly-
computational resources. Additionally, deep learning models are sis,CADgeneration,andspatialreasoningchallenges[94].
generallytask-specific; theyexcelinthetaskstheyaretrainedfor In this study, we introduce a framework that capitalizes on in-
but struggle to adapt to significantly different tasks or scenarios, contextlearningandfew-shotlearningtemplates,enhancedbythe
highlighting a lack of flexibility compared to human problem- inherentreasoningandoptimizationcapabilitiesofLargeLanguage
solving abilities. The limitations highlight the necessity for a Models(LLMs),totacklestructuraloptimizationchallenges. Our
framework capable of utilizing pre-trained networks. Such adap- approachisexemplifiedthroughitsapplicationtotrussdesignprob-
tation of pre-trained models to new tasks counteracts the issues lems, where it enables LLMs to not only generate initial design
of specialization and substantial data demands intrinsic to deep conceptsbutalsoiterativelyrefinethemwithminimalinput,opti-
learning,thusenhancingitsadaptabilityandefficiency. mizingstructuraloutcomeseffectively. Furthermore,wehighlight
Large Language Models (LLMs), powered by transformer ar- the versatility of LLM-based optimization in processing categor-
chitecture[62,63]andtrainedonextensivedatasets[64â€“69],have ical data, a significant departure from traditional optimizers that
achievedremarkableprogressinvariousnaturallanguageprocess- primarilyhandlenumericaldata.
ing(NLP)tasks. Thesetasksincludetextgeneration[70],compli- As illustrated in Figure 1, our framework starts with specifi-
ance with specific task directives [71, 72], and the demonstration cations and initial conditions expressed in natural language, from
of emergent reasoning capabilities [73, 74]. Given the signifi- which the LLM Agent generates an initial truss structure (solu-
cantcomputationalresourcesrequiredfortrainingandfine-tuning tion). ThisstructureisthenevaluatedusingFiniteElementMethod
LLMs for specific downstream tasks, these models have demon- (FEM).Thefeedback,encapsulatedinameta-promptthatincludes
strated an exceptional ability to generalize to new tasks and do- thesolution-scorepairandataskdescriptioninnaturallanguage,
mains. Thisadaptabilityisachievedthroughthein-contextlearn- is re-fed to the LLM. The LLM Agent then uses its reasoning
2to either select a new design or refine the existing one until the each with different levels of maximum allowable stress, ranging
specifications are met. A key advantage of using LLMs in this from lenient to more stringent specifications. Meanwhile, Task 2
contextistheirnaturallanguageunderstanding,whichallowsusers focusesonachievingaspecifiedstress-to-weightratio,withvaria-
toarticulateoptimizationtasksinnaturallanguage. Moreover,the tionsthatspanfromlowtohightargets. Thistableillustratesthe
crucialbalanceofexplorationandexploitationinoptimizationtask range of specifications under which the LLM agents were evalu-
isadeptlymanagedbytheLLMAgent. Theyareprogrammedto ated, showcasing their adaptability to varying constraints and ob-
exploit promising areas of the search space where effective so- jectives.
lutions have been identified while simultaneously exploring new
areastodiscoverpotentiallysuperiorsolutions[90]. 2.2 Prompt Design. Prompt design is a crucial method for
effectively harnessing the capabilities of LLMs, acting as a con-
duitbetweenuserintentandmachineinterpretation. Thisprocess
2 Methodology
involvesthecarefulformulationofinputqueries,or"prompts,"to
2.1 Problem Description. This research examines the effi- directthemodeltowardgeneratingthemostrelevantandaccurate
cacyofLargeLanguageModels(LLMs)inoptimizingtrussstruc- responses [95]. The effectiveness of LLM agents in performing
turesâ€”a fundamental challenge in structural engineering charac- specifictasksreliesheavilyontheprecisionoftheseprompts. By
terized by the need to tailor the configuration and junctions of strategically designing and refining these prompts, users can sig-
memberstomeetpreciseperformancestandardsunderprescribed nificantlyinfluencetheutilityandrelevanceoftheLLMâ€™soutputs,
loads. Ourobjectiveextendsbeyondcraftingtrussesthatmeetro- making prompt design an indispensable skill in optimizing LLM
bustnessbenchmarks;weaimtodeliverdesignsthatalsoalignwith performanceforvariousapplications[96,97].
economicandmaterialefficiencyparameters. ByapplyingLLMs This concept takes on a heightened significance in the design
tothistask,weexploretheirpotentialtointerpretandapplycom- andoptimizationoftrussstructures. Ourmethodologyemploysa
plexengineeringrequirementsinafieldthattraditionallyrelieson finelytunedpromptthatdirectstheLLMAgenttonavigatethein-
numerical optimization techniques, thus broadening the scope for tricatedemandsoftrussdesign,aligningwiththestringentperfor-
innovationinthedesignofcost-effectiveandresource-conservative mancecriteriadictatedbyload-bearingconsiderations. Thisstruc-
structuralsolutions. tured prompting approach ensures the LLMâ€™s solutions are both
accurate within the engineering context and adhere to the prede-
We evaluate the framework on two primary tasks, each with
finedspecifications, thusbolsteringthereliabilityandpracticality
threespecificationvariations, tothoroughlyassessthedesignand
ofLLM-generateddesignsolutionsinstructuraloptimization.
optimization capabilities of Large Language Models (LLMs).
ThisstructuredapproachallowsustotesttheLLMâ€™seffectiveness
under both stringent, challenging conditions and more moderate,
straightforward circumstances. This duality aims to illustrate the
modelâ€™s capacity for both exploration and exploitation within our
design framework. By analyzing the LLMâ€™s performance under
varying degrees of difficulty, we aim to highlight its versatility
and robustness in generating optimal solutions tailored to diverse
engineeringrequirements.
Task1: Thistaskinvolvesdesigningatrussstructurewithspecific
nodes for support and load, complying with strict limitations on
maximumweightandstresslimits(bothcompressiveandtensile).
Task 2: In this task, the objective is to engineer a truss
Fig. 2 Initial prompt for generating initial solution. This
structure that achieves a designated stress-to-weight ratio
prompt outlines the method for constructing a truss using
ğ‘ğ‘ğ‘ (ğ‘ ğ‘¡ğ‘Ÿğ‘’ğ‘ ğ‘ )
( ğ‘™ğ‘’ğ‘›ğ‘”ğ‘¡â„ğ‘šğ‘’ğ‘šğ‘ğ‘’ğ‘Ÿâˆ—ğ‘ğ‘Ÿğ‘œğ‘ ğ‘ âˆ’ğ‘ ğ‘’ğ‘ğ‘¡ğ‘–ğ‘œğ‘› ğ‘ğ‘Ÿğ‘’ğ‘) while adhering to a strict givennodes,loads,supports,andcross-sectionalareasand
maximum stress limit. This problem requires the navigation of describes the procedure for determining the mass of each
complex trade-offs in structural design to balance performance member.
withdurability.
In both tasks, the LLM agent has the flexibility to add nodes In this task, we first guide the LLM methodically in the
at any chosen location, allowing it to explore a wide range of step-by-step development of an optimized closed truss struc-
structuralconfigurations. Thisflexibilitynotonlyteststheagentâ€™s ture, starting from an initial set of node positions specified in
abilitytoinnovateandoptimizebutalsochallengesittobalanceex- ğ‘›ğ‘œğ‘‘ğ‘’_ğ‘‘ğ‘–ğ‘ğ‘¡. The process begins with strategically adding nodes
plorationwithexploitationeffectively. Theagentneedstoexplore and connecting members, ensuring alignment with the speci-
diversedesignpossibilitiestoidentifyoptimalsolutions,whilesi- fied load and support conditions. The LLM is then instructed
multaneously exploiting proven configurations to ensure the de- to construct a ğ‘šğ‘’ğ‘šğ‘ğ‘’ğ‘Ÿ_ğ‘‘ğ‘–ğ‘ğ‘¡ that mirrors the structure seen in
signs are practical, valid, and meet all specified constraints. This ğ‘’ğ‘¥ğ‘ğ‘šğ‘ğ‘™ğ‘’_ğ‘šğ‘’ğ‘šğ‘ğ‘’ğ‘Ÿğ‘ ,usingspecificcross-sectionalareasprovided
strategicapproachisessentialforcraftingoptimalandvaliddesigns fromğ‘ğ‘Ÿğ‘’ğ‘_ğ‘–ğ‘‘.
invarieddesignscenarios. Throughout this process, the LLM is prompted to ensure that
Furthermore, the stochastic nature of LLMs introduces an el- each connection is correctly implemented and that members are
ement of unpredictability, as their outputs may vary with each unique to avoid redundancy in the structureâ€™s design. The opti-
iteration. Thisvariabilityrequirescomprehensivetestingandvali- mizationphasefocusesonmaintainingthemaximumstressineach
dationtoassuretheconsistencyandreliabilityofLLMagent. To memberwhethercompressive(negativevalues)ortensile(positive
addressthis,weconducttentrialsforeachtaskanditsvariationsto values)belowapredefinedthresholdmax_stress_all. Additionally,
determineiftheLLMagentconsistentlymeetsthesetrequirements themodelmanagesthetotalmassofthestructure,whichitcalcu-
withinourproposedframework. Thisstringenttestingregimenis latesbysummingtheproductsofthelengthsofmembersandtheir
critical to ensure that the modelâ€™s performance is robust and not corresponding values from ğ‘ğ‘Ÿğ‘’ğ‘_ğ‘–ğ‘‘. Figure 2 shows the initial
merely a result of randomness, thereby providing a reliable mea- promptusedtogenerateinitialsolution.
sureofitscapabilities. TheoutputrequiredfromtheLLMisprecise,itshouldprovide
Table1providesadetailedoverviewoftheexperimentalsetup onlythemodifiedğ‘›ğ‘œğ‘‘ğ‘’_ğ‘‘ğ‘–ğ‘ğ‘¡ andğ‘šğ‘’ğ‘šğ‘ğ‘’ğ‘Ÿ_ğ‘‘ğ‘–ğ‘ğ‘¡ inacleanPython
for each task and its variations, detailing the specific testing con- code block, omitting any comments to remove bias for the initial
ditionsfortheLLMagent. Eachexperimentbeginswithaninitial proposedsolution. Thisdirectiveensuresthattheoutputisdirectly
setofnodes,loads,andsupports. Task1includesthreevariations, parsableforourFEMmodule.
3Table1 TrussDesignSpecifications
Specifications2
NodePosition LoadPosition SupportPositions
VariationNo. Specifications1 (Totalweight Cross-sectionIDofmemberstobeused
(Node,(x,y)) (Node,(magnitude,direction)) (Node,supporttype)
ofstructureinN)
1 Maximumstress:15(Pa) 30 "0":1,"1":0.195,
"node_1":(0,0),
"node_1":"pinned", 2 Maximumstress:20(Pa) 30 "2":0.782,"3":1.759,
Task1 "node_2":(6,0), "node_3":(-10,-45)
"node_2":"roller", "4":3.128,"5":4.887,
"node_3":(2,0), 3 Maximumstress:30(Pa) 30
"6":7.037,"7":9.578,
"node_1":(0,0), "node_1":"pinned", 1 Stress/Weightratio:0.5 30 "8":12.511,"9":15.834,
Task2 "node_2":(6,0), "node_3":(-15,-30) "node_2":"roller", 2 Stress/Weight:0.75 30 "10":19.548
"node_3":(2,0), "node_3":"roller", 3 Stress/Weight:1 30
modelâ€™sabilitytogeneratenovelanddiversesolutions,potentially
stifling innovation and limiting performance in more exploratory
orcreativedesigntasks.
To address exploration challenges in model training, several
innovative methods have been developed. These include self-
consistencysampling, which involvesgeneratingmultiple outputs
atatemperaturegreaterthanzeroandselectingthebestonefrom
these candidates [105]. Another method is the chain of thought
prompting, where a sequence of short sentences describes step-
by-step reasoning logic, known as reasoning chains or rationales,
culminatinginthefinalanswer[106,107]. Extendingthis,thetree
ofthoughtapproachexploresmultiplereasoningpathsateachstep
Fig.3 Metapromptthatservesasasecondarypromptfol- bybreakingtheproblemintoseveralthoughtstepsandgenerating
lowing the generation of an initial solution. This prompt multiple thoughts per step, effectively creating a tree-like struc-
presentsthesolution-scorepairfromtheinitialsolutionand ture of possibilities [108]. While these methods enhance model
promptsthelanguagemodeltoexplainthereasoningbehind exploration capabilities, they also introduce certain challenges.
itsresponse. Additionally,itrestatestheproblemforclarity. Self-consistency sampling can be computationally intensive, as
it requires generating and evaluating multiple outputs. Chain of
thought prompting, although effective in laying out logical steps,
OncetheinitialsolutionisgeneratedandevaluatedusingFEM, cansometimesleadtoverboseandredundantoutputsifnotcare-
weprovidetheLLMAgentwithastructuredfeedbackmeta-prompt fully managed. Similarly, the tree of thought approach, while of-
thatincludestheFEMresults. Thisfeedbackindicatesthattheini- feringabroadexplorationofpotentialsolutions,canexponentially
tial goals have not been met, presenting the generated solution increasecomputationaldemandsandcomplexity,aseachdecision
alongside the FEM data in a solution-score format. This sub- pointmultipliesthenumberofpossiblepathstoevaluate. TheRe-
sequent prompt explicitly details the stress concentration in each Actframeworkaddressestheseissuesbyemployinglargelanguage
member, prompting the LLM to strategically rethink and modify models to produce interleaved reasoning traces and task-specific
theinitialstructuretomeetthespecifiedcriteria. actions,thusstreamliningprocessesandeffectivelyintegratingex-
ternal data, which enhances dynamic interaction with data and
In this iteration, the LLM is tasked with reasoning and imple-
environments[109].
menting necessary changes to optimize the design. This iterative
Our proposed framework utilizes the ReAct mechanism [109]
prompting process is designed to progressively guide the LLM
toiterativelygenerateandrefinestructuraldesignsusinganLLM
toward an optimal solution by systematically refining the design
(GPT4). The process begins with the LLM generating an initial
basedonempiricaldataandsimulationoutcomes. Figure3shows
structure,whichisthenevaluatedthroughFiniteElementMethod
themeta-promptusedtorefinethegeneratedsolutions.
(FEM) analysis. If the structure fails to meet the specified re-
quirements, a meta-prompt engages the LLM to reconsider and
2.3 Prompt Engineering. Prompt Engineering, also known rationalize its decisions, prompting it to generate an improved
as In-Context Prompting, refers to methods for how to communi- solution. This cycleâ€”evaluation, meta-prompting, and regener-
cate with LLMs to steer their behavior towards desired outcomes ationâ€”continuesuntilthedesignfulfillsallspecifications. InTask
without updating the model weights [98]. This approach is dis- 2,whichfocusesonachievingaspecificstress-to-weightratioanda
tinctfrompromptdesign, whichfocusesoncraftinginitialinputs maximumweightforastructure,amodifiedapproachisemployed.
that optimize the modelâ€™s performance on specific tasks by ex- Initially,theprocessprioritizesmeetingtheweightcriteria. Once
ploitingitspre-existingknowledgeandbiases,ratherthandynami- thisisachieved,thefocusshiftstoadjustingthestructuretosatisfy
callyinteractingwiththemodeltoguideitsresponses. Numerous the stress-to-weight ratio requirements. This sequential method
studies have delved into optimizing the performance of LLMs by ensures that both critical aspects of the design are methodically
strategicallyconstructingin-contextexamples. Thesemethodsin- addressedtomeetthespecificationseffectively.
cludeselectingexamplesthroughsemanticclusteringusingK-NN
in the embedding space [99], constructing directed graphs based
3 ResultsandDiscussion
on embeddings and cosine similarity where each node points to
itsnearestneighbor[100],andapplyingQ-learningtechniquesfor 3.1 Generated Results. Figure 5 illustrates the raw solution
sample selection [101], among other strategies [102â€“104]. How- generated by the LLM agent, designed for simplified parsing and
ever, incorporating these techniques can inadvertently introduce integration into the FEM module for further analysis. The so-
biasesintothemodel,astheytendtoprioritizeexamplesthatare lution is organized into two key dictionaries: "node_dict" and
similartothoseinthetrainingset. Thisbiasmaynotbeconducive "member_dict." These dictionaries are named and formatted ac-
to design optimization, where a broad exploration of possibilities cordingtospecifiedrequirementstoensureconsistencyandeaseof
iscrucial. Relyingheavilyonsimilarpastexamplescanrestrictthe use. "Node_dict"capturesthepositionsofbothoriginalandnewly
4Fig.4 Final,optimizedtrussstructuresproducedbytheLLMagentfor(a)task1and(b)task2. Thetrussdesignsforeach
taskarenotablydistinct,underscoringtheadaptabilityoftheLLMagenttomeetuniquedesignspecificationsacrossthe
designspace.
Fig.5 RawsolutiongeneratedbytheLLMagentpresented
inthespecifiedformat,withreasoninghighlightedinred.
Fig. 6 Success rate of tasks with variations over 10 runs,
alongwiththecorrespondingnumberofiterationsrequired
added nodes, providing a clear layout of the structural elements.
to achieve the specified criteria. The success rate is mea-
Meanwhile,"member_dict"outlinestheconnectionsbetweenthese
suredasthepercentageofsuccessfulrunsoutof10runs.
nodes,specifyingendnodesandareaIDsfromapredefineddictio-
Thelineplotdepictsthemeannumberofiterationswithstan-
narytooptimallybalancemassreductioninstresswithinthetruss
darddeviationacrosstherunstoachievethespecification.
structure.
Providingaclearrationaleforeachdecisiontoperformanaction
iscrucialasitallowsfortheverificationandvalidationofthede-
constraintsofeachspecifiedscenario.
cisionsmadebyautomatedsystems,ensuringthattheyalignwith
intendedgoalsandadheretoexpectedstandards. Forinstance,the
decisiontoaddnode_4directlyabovenode_3istoprovideessential 3.2 Framework performance. The performance of the
verticalsupport,crucialforabsorbingloadseffectively,andnode_5 frameworkisevaluatedbythesuccessrateaswellasthecountof
is introduced to form a triangular configuration that significantly iterationsacrossteniterationsforeachtaskandvariationtomeet
enhances stability by counteracting horizontal loads. Members thespecifications.
such as member_4, member_5, and member_7 are strategically AsobservedinFigure6. theLLMagentachievesa70%success
connectedtodistributeloadssymmetricallyandenhancestructural rate for Task 1 Variation 3 and Variation 2, which are noted for
integrity. Theselectionofeachmemberâ€™sareaIDrepresentsade- theirrelativelylenientspecifications. However,theLLMagenthas
liberatecompromisebetweenminimizingmassandensuringsafety a50%successrateforVariation1ofthesametask,whichhasmore
understress,inaccordancewithstructuralengineeringprinciples. stringent specifications and demands more intensive optimization
This detailed and reasoned approach in the design process un- efforts. The performance of LLM agent is even more notable in
derscores the ability of LLM agent to autonomously develop and Task 2, with a success rate reaching up to 90%, highlighting the
refine complex structures, illustrating its potential to significantly flexibilityofLLMagentwhenconfrontingvarieddegreesoftask
advanceengineeringdesignthroughintelligentautomation. difficulty. Notably,asspecificationsbecomemorestringent,thereâ€™s
Figure4presentsthefinaloptimizedtrussstructuresgenerated adiscernibledecreaseinsuccessrates,highlightingthecorrelation
bytheLLMagent,withdesignsfortasks1and2respectively. The between requirement stringency and the associated challenges in
diversity in the structures highlights the LLM agentâ€™s adeptness achievingsuccess.
at grasping and implementing engineering principles to generate WhileTask1andTask2sharesimilaritiesinoptimizingstress
not just feasible but also distinct structures tailored to the unique valuesandstress-to-weightratiowithamaximumstructuralweight
5Fig.7 OptimizationtrajectoriesforTask1acrossthreedifferentproblemvariations.Eachpanel(a)Variation1,(b)Variation
2,and(c)Variation3,representsasequenceofstepstakentoachievedesignrefinementgeneratedfor3differentruns. The
initialsolutions,indicatedbythestartingpoints,undergosuccessiveiterationswheretheLLMevaluatessolution-scorepairs
andproposessubsequentrefinements. Thedashedlinestracethepathofexplorationandexploitationwithinthesolution
space, convergingtowardsanoptimaldesignzonehighlightedinred. Thiszonerepresentsthetargetedrangeofstress
andmassparameterswheredesignefficiencyismaximized. Eachrunstartingfromauniquestartingpointdemonstratesa
uniquetrajectorytowarddesignoptimization.
limit,thespecificproblemformulationimpactssuccessratediffer- and gradient-free optimization. In gradient-based optimization,
ently. In Task1, theLLM agent is taskedwith minimizing stress the trajectory typically involves iteratively following the gradient
values,consideringbothtensileandcompressivestresseswithpos- of the objective function to ascend towards the optimal solution.
itiveandnegativevalues. Thisinherentlyresultsinalargerdesign Similarly,theLLMagentâ€™siterativeoptimizationprocessinvolves
subspace. Conversely, Task 2 simply presents an absolute ratio, graduallyrefiningsolutionsbasedonfeedback,graduallyconverg-
allowing for the possibility of the ideal value reaching 0. Conse- ingtowardstheoptimalzone.
quently, the success ratio tends to be higher in Task 2 due to its In gradient-free optimization, the trajectory may be less deter-
more straightforward problemformulation. Overall, the nature of ministic,withtheoptimizationprocessexploringthesolutionspace
theproblemposedinTask1andTask2playsasignificantrolein usingmethodssuchasevolutionaryalgorithmsorrandomsearch.
shapingtheoptimizationprocessandinfluencingthesuccessrate, Similarly,theLLMagentâ€™sexplorationphaseencompassesarange
making problem formulation a critical factor in determining the of strategies to explore the solution space, including generating
efficacyofLLMagentbaseddesignoptimization. diverse variations and exploring different directions based on the
Furthermore,itisobservedthatthestringencyofspecifications promptandavailableinformation.
directlyinfluencestheoptimizationprocessoftheLLMagent. As Overall,theiterativeoptimizationprocessoftheLLMagentin-
specificationstighten, theLLMagentnecessitatesmoreiterations volves a dynamic interplay between exploration and exploitation,
tofulfillrequirements. Conversely,looserspecificationsaffordthe guided by prompt-based inputs, to iteratively refine solutions to-
agent a broader design space, fostering more exploration of the wardstheoptimalzone. Thisapproachenablestheagenttoadapt
designspace. However,thisflexibilityposeschallenges, exempli- to diverse optimization tasks and generate high-quality solutions
fiedbyTask2Variation3. Here,explorationwithintheexpansive tailoredtospecificobjectives.
designspaceleadstoanincreasednumberofiterations,adversely
affectingperformance.
4 Conclusion
3.3 Optimizationbehavior. Figure7showstheoptimization Inconclusion,theuseofLLMagentsasoptimizersinengineer-
trajectories of the LLM agent. During iterative optimization, the ing design marks a transformative shift in how design solutions
LLM agent begins by generating an initial solution based on the are conceived and refined. LLMs excel in parsing natural lan-
providedprompt. Thisinitialsolutionservesasastartingpointfor guageinputsand,throughin-contextlearning,caniterativelyadapt
theoptimizationprocess. to meet precise specifications without the need for training for a
As the optimization progresses iteratively, the LLM agent em- specifictask. Thiscapabilityisenhancedbytheiradeptnessatrea-
ploys a combination of exploration and exploitation strategies to soning through and exploring a wide range of design alternatives
refine the solution towards the optimal zone. Initially, the agent whilealsofocusingonthemostpromisingsolutions. Byintegrat-
explores the solution space by generating variations or alterna- ing LLMs with the finite element method (FEM), the framework
tive solutions based on its understanding of the problem and the provides a robust means of assessing and improving design out-
dataprovided. Thisexplorationphaseallowstheagenttoidentify comes. This continuous iterative process, fueled by the feedback
promising directions or areas within the solution space that may loop between the LLM and FEM, ensures that each design itera-
leadtoimprovedoutcomes. tionmovesclosertotheidealspecification. Thesynergybetween
Following the exploration phase, the LLM agent transitions to explorationandexploitationinthiscontextnotonlyacceleratesthe
exploitation,whereitfocusesonrefiningandimprovingthesolu- designprocessbutalsoenhancesitsaccuracy,promisinganewera
tionsidentifiedduringexploration. Thisphaseinvolvesiteratively ofefficiencyinautomatedengineeringsolutions.
adjusting the solution based on feedback obtained from evaluat-
ing its performance against specified criteria or objectives. The
agentmayfine-tuneparameters,adjustdesigns,orincorporatenew References
insightsgainedduringexplorationtofurtheroptimizethesolution.
[1] Zheng,X.,Zhang,X.,Chen,T.-T.,andWatanabe,I.,2023,â€œDeeplearningin
Prompt-based optimization is a key aspect of the LLM agentâ€™s mechanicalmetamaterials: frompredictionandgenerationtoinversedesign,â€
approach. The agent leverages the information contained within AdvancedMaterials,35(45),p.2302530.
the prompt to generate solutions that align with the stated goals, [2] Newell, A., Simon, H.A., etal., 1972, Humanproblemsolving, Vol.104,
Prentice-hallEnglewoodCliffs,NJ.
therebyfacilitatingtargetedoptimization.
[3] Ferguson,E.S.,1994,EngineeringandtheMindâ€™sEye,MITpress.
The optimization trajectory of the LLM agent often mirrors
[4] Cross,N.,2004,â€œExpertiseindesign:anoverview,â€Designstudies,25(5),pp.
that of traditional optimization methods, such as gradient-based 427â€“441.
6[5] Daly,S.R.,Yilmaz,S.,Christian,J.L.,Seifert,C.M.,andGonzalez,R.,2012, [36] Gao, K., Gao, Y., He, H., Lu, D., Xu, L., and Li, J., 2022, â€œNerf: Neu-
â€œDesignheuristicsinengineeringconceptgeneration,â€. ral radiance field in 3d vision, a comprehensive review,â€ arXiv preprint
[6] Besson,J.,Cailletaud,G.,Chaboche,J.-L.,andForest,S.,2009,Non-linear arXiv:2210.00379.
mechanicsofmaterials,Vol.167,SpringerScience&BusinessMedia. [37] Zhang,K.,Riegler,G.,Snavely,N.,andKoltun,V.,2020,â€œNerf++:Analyzing
[7] Gardner,L.andAshraf,M.,2006,â€œStructuraldesignfornon-linearmetallic andimprovingneuralradiancefields,â€arXivpreprintarXiv:2010.07492.
materials,â€Engineeringstructures,28(6),pp.926â€“934. [38] Jayaraman, P. K., Lambourne, J. G., Desai, N., Willis, K. D., Sanghi, A.,
[8] Zahavi,E.andBarlam,D.M.,2000,NonlinearProblemsinMachineDesign, andMorris,N.J.,2022,â€œSolidgen: Anautoregressivemodelfordirectb-rep
CRCPress. synthesis,â€arXivpreprintarXiv:2203.13944.
[9] Gatti,G.andSvelto,C.,2023,â€œExploitingnonlinearityforthedesignoflin- [39] Zhang, S., Guan, Z., Jiang, H., Ning, T., Wang, X., and Tan, P., 2024,
earoscillators:ApplicationtoaninherentlystrongnonlinearX-shaped-spring â€œBrep2Seq:adatasetandhierarchicaldeeplearningnetworkforreconstruction
suspension,â€MechanicalSystemsandSignalProcessing,197,p.110362. andgenerationofcomputer-aideddesignmodels,â€JournalofComputational
[10] BendsÃ¸e,M.P.,1989,â€œOptimalshapedesignasamaterialdistributionprob- DesignandEngineering,11(1),pp.110â€“134.
lem,â€Structuraloptimization,1,pp.193â€“202. [40] Siddiqui,Y.,Alliegro,A.,Artemov,A.,Tommasi,T.,Sirigatti,D.,Rosov,V.,
[11] BendsÃ¸e,M.P.andSigmund,O.,1999,â€œMaterialinterpolationschemesin Dai,A.,andNieÃŸner,M.,2023,â€œMeshgpt: Generatingtrianglemesheswith
topologyoptimization,â€Archiveofappliedmechanics,69,pp.635â€“654. decoder-onlytransformers,â€arXivpreprintarXiv:2311.15475.
[12] Hajela, P., Lee, E., andLin, C.-Y., 1993, â€œGeneticalgorithmsinstructural [41] Feng,Y.,Feng,Y.,You,H.,Zhao,X.,andGao,Y.,2019,â€œMeshnet:Meshneu-
topologyoptimization,â€Topologydesignofstructures,pp.117â€“133. ralnetworkfor3dshaperepresentation,â€ProceedingsoftheAAAIconference
[13] Adeli,H.andCheng,N.-T.,1994,â€œAugmentedLagrangiangeneticalgorithm
onartificialintelligence,Vol.33,PaperNo.01,pp.8279â€“8286.
forstructuraloptimization,â€JournalofAerospaceEngineering,7(1),pp.104â€“ [42] Wu,R.,Xiao,C.,andZheng,C.,2021,â€œDeepcad:Adeepgenerativenetwork
118. for computer-aided design models,â€ Proceedings of the IEEE/CVF Interna-
tionalConferenceonComputerVision,pp.6772â€“6782.
[14] Wang,S.,Tai,K.,andWang,M.Y.,2006,â€œAnenhancedgeneticalgorithmfor
structuraltopologyoptimization,â€InternationalJournalforNumericalMethods [43] Sanghi, A., Chu, H., Lambourne, J. G., Wang, Y., Cheng, C.-Y., Fumero,
inEngineering,65(1),pp.18â€“44. M.,andMalekshan,K.R.,2022,â€œClip-forge:Towardszero-shottext-to-shape
generation,â€ ProceedingsoftheIEEE/CVFConferenceonComputerVision
[15] Radman, A., 2013, â€œBi-directional evolutionary structural optimization
andPatternRecognition,pp.18603â€“18613.
(BESO) for topology optimization of materialâ€™s microstructure,â€ Ph.D. the-
[44] Nichol,A.,Jun,H.,Dhariwal,P.,Mishkin,P.,andChen,M.,2022,â€œPoint-e:A
sis,RMITUniversity.
systemforgenerating3dpointcloudsfromcomplexprompts,â€arXivpreprint
[16] Tang,Y.,Kurtz,A.,andZhao,Y.F.,2015,â€œBidirectionalEvolutionaryStruc-
arXiv:2212.08751.
tural Optimization (BESO) based design method for lattice structure to be
[45] Baretto,V.M.,2018,â€œAutomaticLearningbased2D-to-3DImageConversion,â€
fabricatedbyadditivemanufacturing,â€Computer-AidedDesign,69,pp.91â€“
Internationaljournalofengineeringresearchandtechnology,2.
101.
[46] Para,W.,Bhat,S.,Guerrero,P.,Kelly,T.,Mitra,N.,Guibas,L.J.,andWonka,
[17] Oliver, J., Yago, D., Cante, J., and Lloberas-Valls, O., 2019, â€œVariational
P.,2021,â€œSketchgen:Generatingconstrainedcadsketches,â€AdvancesinNeu-
approachtorelaxedtopologicaloptimization:Closedformsolutionsforstruc-
ralInformationProcessingSystems,34,pp.5077â€“5088.
turalproblemsinasequentialpseudo-timeframework,â€ComputerMethodsin
[47] Willis,K.D.,Jayaraman,P.K.,Lambourne,J.G.,Chu,H.,andPu,Y.,2021,
AppliedMechanicsandEngineering,355,pp.779â€“819.
â€œEngineering sketch generation for computer-aided design,â€ Proceedings of
[18] Yago,D.,Cante,J.,Lloberas-Valls,O.,andOliver,J.,2021,â€œTopologyopti-
the IEEE/CVF conference on computer vision and pattern recognition, pp.
mizationusingtheunsmoothvariationaltopologyoptimization(UNVARTOP)
2105â€“2114.
method: aneducationalimplementationinMATLAB,â€StructuralandMulti-
[48] Li,C.,Pan,H.,Bousseau,A.,andMitra,N.J.,2022,â€œFree2cad:Parsingfree-
disciplinaryOptimization,63,pp.955â€“981.
handdrawingsintocadcommands,â€ACMTransactionsonGraphics(TOG),
[19] Yago,D.,Cante,J.,Lloberas-Valls,O.,andOliver,J.,2022,â€œTopologyopti-
41(4),pp.1â€“16.
mizationmethodsfor3Dstructuralproblems:acomparativestudy,â€Archives
[49] Sosnovik,I.andOseledets,I.,2019,â€œNeuralnetworksfortopologyoptimiza-
ofComputationalMethodsinEngineering,29(3),pp.1525â€“1567.
tion,â€ RussianJournalofNumericalAnalysisandMathematicalModelling,
[20] Lei,S.andTao,D.,2023,â€œAComprehensiveSurveyofDatasetDistillation,â€
34(4),pp.215â€“223.
IEEETransactionsonPatternAnalysisandMachineIntelligence,46,pp.17â€“
[50] Nie,Z.,Lin,T.,Jiang,H.,andKara,L.B.,2021,â€œTopologygan: Topology
32.
optimization using generative adversarial networks based on physical fields
[21] Hinton,G.E.andSalakhutdinov,R.,2006,â€œReducingtheDimensionalityof
overtheinitialdomain,â€JournalofMechanicalDesign,143(3),p.031715.
DatawithNeuralNetworks,â€Science,313,pp.504â€“507.
[51] Parrott, C. M., Abueidda, D. W., and James, K. A., 2023, â€œMultidisci-
[22] Duan, Y., Zhang, J., and Zhang, L., 2023, â€œDataset Distillation in Latent
plinary Topology Optimization Using Generative Adversarial Networks for
Space,â€ArXiv,abs/2311.15547.
Physics-BasedDesignEnhancement,â€JournalofMechanicalDesign,145(6),
[23] Ogoke,O.F.,Johnson,K.,Glinsky,M.,Laursen,C.,Kramer,S.,andFari- p.061704.
mani,A.B.,2022,â€œDeep-learnedgeneratorsofporositydistributionsproduced
[52] MazÃ©, F. and Ahmed, F., 2023, â€œDiffusion models beat gans on topology
duringmetalAdditiveManufacturing,â€AdditiveManufacturing,60,p.103250.
optimization,â€ProceedingsoftheAAAIconferenceonartificialintelligence,
[24] Ogoke,F.,Liu,Q.,Ajenifujah,O.,Myers,A.,Quirarte,G.,Beuth,J.,Malen, Vol.37,PaperNo.8,pp.9108â€“9116.
J.,andFarimani,A.B.,2023,â€œInexpensiveHighFidelityMeltPoolModels [53] Jiang,H.,Nie,Z.,Yeo,R.,Farimani,A.B.,andKara,L.B.,2021,â€œStress-
inAdditiveManufacturingUsingGenerativeDeepDiffusion,â€arXivpreprint gan:Agenerativedeeplearningmodelfortwo-dimensionalstressdistribution
arXiv:2311.16168. prediction,â€JournalofAppliedMechanics,88(5),p.051005.
[25] Haghighat,E.,Raissi,M.,Moure,A.,Gomez,H.,andJuanes,R.,2020,â€œA [54] Yang,Z.,Yu,C.-H.,andBuehler,M.J.,2021,â€œDeeplearningmodeltopredict
deeplearningframeworkforsolutionanddiscoveryinsolidmechanics,â€arXiv complexstressandstrainfieldsinhierarchicalcomposites,â€ScienceAdvances,
preprintarXiv:2003.02751. 7(15),p.eabd7416.
[26] Haghighat,E.,Raissi,M.,Moure,A.,Gomez,H.,andJuanes,R.,2021,â€œA [55] White, D. A., Arrighi, W. J., Kudo, J., and Watts, S. E., 2019, â€œMulti-
physics-informeddeeplearningframeworkforinversionandsurrogatemodel- scaletopologyoptimizationusingneuralnetworksurrogatemodels,â€Computer
inginsolidmechanics,â€ComputerMethodsinAppliedMechanicsandEngi- MethodsinAppliedMechanicsandEngineering,346,pp.1118â€“1135.
neering,379,p.113741. [56] Barmada, S., Fontana, N., Formisano, A., Thomopulos, D., andTucci, M.,
[27] Vlassis,N.N.,Ma,R.,andSun,W.,2020,â€œGeometricdeeplearningforcom- 2021, â€œA deep learning surrogate model for topology optimization,â€ IEEE
putationalmechanicsparti: Anisotropichyperelasticity,â€ComputerMethods TransactionsonMagnetics,57(6),pp.1â€“4.
inAppliedMechanicsandEngineering,371,p.113299. [57] Jeong,H.,Bai,J.,Batuwatta-Gamage,C.P.,Rathnayaka,C.,Zhou,Y.,and
[28] Jadhav,Y.,Berthel,J.,Hu,C.,Panat,R.,Beuth,J.,andFarimani,A.B.,2023, Gu,Y.,2023,â€œAphysics-informedneuralnetwork-basedtopologyoptimiza-
â€œStressD:2DStressestimationusingdenoisingdiffusionmodel,â€ Computer tion(PINNTO)frameworkforstructuraloptimization,â€EngineeringStructures,
MethodsinAppliedMechanicsandEngineering,416,p.116343. 278,p.115484.
[29] Jordan,M.I.andMitchell,T.M.,2015,â€œMachinelearning: Trends,perspec- [58] Li,M.,Cheng,Z.,Jia,G.,andShi,Z.,2019,â€œDimensionreductionandsurro-
tives,andprospects,â€Science,349(6245),pp.255â€“260. gatebasedtopologyoptimizationofperiodicstructures,â€CompositeStructures,
[30] LeCun, Y., Bengio, Y., and Hinton, G., 2015, â€œDeep learning,â€ nature, 229,p.111385.
521(7553),pp.436â€“444. [59] Bostanabad,R.,Chan,Y.-C.,Wang,L.,Zhu,P.,andChen,W.,2019,â€œGlobally
[31] Lambourne,J.G.,Willis,K.,Jayaraman,P.K.,Zhang,L.,Sanghi,A.,and approximategaussianprocessesforbigdatawithapplicationtodata-driven
Malekshan,K.R.,2022,â€œReconstructingeditableprismaticcadfromrounded metamaterialsdesign,â€JournalofMechanicalDesign,141(11),p.111402.
voxelmodels,â€SIGGRAPHAsia2022ConferencePapers,pp.1â€“9. [60] Goh,G.D.,Sing,S.L.,andYeong,W.Y.,2021,â€œAreviewonmachinelearning
[32] Tebyani,M.,Spaeth,A.,Cramer,N.,andTeodorescu,M.,2021,â€œAGeometric in3Dprinting: applications,potential,andchallenges,â€ArtificialIntelligence
KinematicModelforFlexibleVoxel-BasedRobots,â€Softrobotics. Review,54(1),pp.63â€“94.
[33] Barazzetti,L.,2016,â€œParametricas-builtmodelgenerationofcomplexshapes [61] Jin,H.,Zhang,E.,andEspinosa,H.D.,2023,â€œRecentadvancesandapplica-
frompointclouds,â€Adv.Eng.Informatics,30,pp.298â€“311. tionsofmachinelearninginexperimentalsolidmechanics:Areview,â€Applied
[34] Montlahuc,J.,Shah,G.,Polette,A.,andPernot,J.,2018,â€œAs-scannedPoint MechanicsReviews,75(6),p.061001.
cloudsgenerationforVirtualReverseEngineeringofCADAssemblyModels,â€ [62] Vaswani,A.,Shazeer,N.,Parmar,N.,Uszkoreit,J.,Jones,L.,Gomez,A.N.,
ProceedingsofCADâ€™18. Kaiser,Å.,andPolosukhin,I.,2017,â€œAttentionisallyouneed,â€Advancesin
[35] Luo,S.andHu,W.,2021,â€œDiffusionProbabilisticModelsfor3DPointCloud neuralinformationprocessingsystems,30.
Generation,â€ 2021 IEEE/CVF Conference on Computer Vision and Pattern [63] Lin,T.,Wang,Y.,Liu,X.,andQiu,X.,2022,â€œAsurveyoftransformers,â€AI
Recognition(CVPR),pp.2836â€“2844. open,3,pp.111â€“132.
7[64] Brown,T.,Mann,B.,Ryder,N.,Subbiah,M.,Kaplan,J.D.,Dhariwal,P.,Nee- [91] Buehler,M.J.,2024,â€œMechGPT,aLanguage-BasedStrategyforMechanics
lakantan,A.,Shyam,P.,Sastry,G.,Askell,A.,etal.,2020,â€œLanguagemodels andMaterialsModelingThatConnectsKnowledgeAcrossScales,Disciplines,
arefew-shotlearners,â€Advancesinneuralinformationprocessingsystems,33, andModalities,â€AppliedMechanicsReviews,76(2),p.021001.
pp.1877â€“1901. [92] Zhu,Q.andLuo,J.,2023,â€œGenerativetransformersfordesignconceptgener-
[65] Chowdhery,A.,Narang,S.,Devlin,J.,Bosma,M.,Mishra,G.,Roberts,A., ation,â€JournalofComputingandInformationScienceinEngineering,23(4),
Barham,P.,Chung,H.W.,Sutton,C.,Gehrmann,S.,etal.,2023,â€œPalm:Scal- p.041003.
inglanguagemodelingwithpathways,â€JournalofMachineLearningResearch, [93] Makatura,L.,Foshey,M.,Wang,B.,HÃ¤hnLein,F.,Ma,P.,Deng,B.,Tjandra-
24(240),pp.1â€“113. suwita,M.,Spielberg,A.,Owens,C.E.,Chen,P.Y.,etal.,2023,â€œHowCan
[66] Chung,H.W.,Hou,L.,Longpre,S.,Zoph,B.,Tay,Y.,Fedus,W.,Li,Y.,Wang, LargeLanguageModelsHelpHumansinDesignandManufacturing?â€ arXiv
X., Dehghani, M., Brahma, S., et al., 2022, â€œScaling instruction-finetuned preprintarXiv:2307.14377.
languagemodels,â€arXivpreprintarXiv:2210.11416. [94] Picard,C.,Edwards,K.M.,Doris,A.C.,Man,B.,Giannone,G.,Alam,M.F.,
[67] Chang,Y.,Wang,X.,Wang,J.,Wu,Y.,Yang,L.,Zhu,K.,Chen,H.,Yi,X., andAhmed,F.,2023,â€œFromConcepttoManufacturing: EvaluatingVision-
Wang,C.,Wang,Y.,etal.,2023,â€œAsurveyonevaluationoflargelanguage LanguageModelsforEngineeringDesign,â€arXivpreprintarXiv:2311.12668.
models,â€ACMTransactionsonIntelligentSystemsandTechnology. [95] Liu,P.,Yuan,W.,Fu,J.,Jiang,Z.,Hayashi,H.,andNeubig,G.,2023,â€œPre-
[68] Zhao,W.X.,Zhou,K.,Li,J.,Tang,T.,Wang,X.,Hou,Y.,Min,Y.,Zhang,B., train, prompt, and predict: A systematic survey of prompting methods in
Zhang,J.,Dong,Z.,Du,Y.,Yang,C.,Chen,Y.,Chen,Z.,Jiang,J.,Ren,R., naturallanguageprocessing,â€ACMComputingSurveys,55(9),pp.1â€“35.
Li,Y.,Tang,X.,Liu,Z.,Liu,P.,Nie,J.,androngWen,J.,2023,â€œASurvey [96] Wang,L.,Chen,X.,Deng,X.,Wen,H.,You,M.,Liu,W.,Li,Q.,andLi,J.,
ofLargeLanguageModels,â€ArXiv,abs/2303.18223. 2024,â€œPromptengineeringinconsistencyandreliabilitywiththeevidence-
basedguidelineforLLMs,â€npjDigitalMedicine,7(1),p.41.
[69] Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F.L.,
[97] Li, Y., 2023, â€œApracticalsurveyonzero-shotpromptdesignforin-context
Almeida,D.,Altenschmidt,J.,Altman,S.,Anadkat,S.,etal.,2023,â€œGpt-4
learning,â€arXivpreprintarXiv:2309.13205.
technicalreport,â€arXivpreprintarXiv:2303.08774.
[98] Oppenlaender,J.,2023,â€œAtaxonomyofpromptmodifiersfortext-to-image
[70] Zhang,H.,Song,H.,Li,S.,Zhou,M.,andSong,D.,2023,â€œAsurveyofcon-
generation,â€Behaviour&InformationTechnology,pp.1â€“14.
trollabletextgenerationusingtransformer-basedpre-trainedlanguagemodels,â€
[99] Liu, J., Shen, D., Zhang, Y., Dolan, B., Carin, L., and Chen, W., 2021,
ACMComputingSurveys,56(3),pp.1â€“37.
â€œWhat Makes Good In-Context Examples for GPT-3?â€ arXiv preprint
[71] Zhou,J.,Lu,T.,Mishra,S.,Brahma,S.,Basu,S.,Luan,Y.,Zhou,D.,and
arXiv:2101.06804.
Hou,L.,2023,â€œInstruction-FollowingEvaluationforLargeLanguageModels,â€
[100] Su,H.,Kasai,J.,Wu,C.H.,Shi,W.,Wang,T.,Xin,J.,Zhang,R.,Ostendorf,
ArXiv,abs/2311.07911.
M.,Zettlemoyer,L.,Smith,N.A.,etal.,2022,â€œSelectiveannotationmakes
[72] Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N.A., Khashabi, D., and
languagemodelsbetterfew-shotlearners,â€arXivpreprintarXiv:2209.01975.
Hajishirzi, H., 2022, â€œSelf-Instruct: Aligning Language Models with Self-
[101] Zhang,Y.,Feng,S.,andTan,C.,2022,â€œActiveexampleselectionforin-context
GeneratedInstructions,â€,pp.13484â€“13508.
learning,â€arXivpreprintarXiv:2211.04486.
[73] Webb,T.W.,Holyoak,K.,andLu,H.,2022,â€œEmergentanalogicalreasoning [102] Diao,S.,Wang,P.,Lin,Y.,andZhang,T.,2023,â€œActivepromptingwithchain-
inlargelanguagemodels,â€NatureHumanBehaviour,7,pp.1526â€“1541. of-thoughtforlargelanguagemodels,â€arXivpreprintarXiv:2302.12246.
[74] Huang,J.andChang,K.,2022,â€œTowardsReasoninginLargeLanguageMod- [103] Lu,Y.,Bartolo,M.,Moore,A.,Riedel,S.,andStenetorp,P.,2021,â€œFantasti-
els:ASurvey,â€ArXiv,abs/2212.10403. callyorderedpromptsandwheretofindthem: Overcomingfew-shotprompt
[75] Lin, X.V., Mihaylov, T., Artetxe, M., Wang, T., Chen, S., Simig, D., Ott, ordersensitivity,â€arXivpreprintarXiv:2104.08786.
M.,Goyal,N.,Bhosale,S.,Du,J.,Pasunuru,R.,Shleifer,S.,Koura,P.S., [104] Zhao,Z.,Wallace,E.,Feng,S.,Klein,D.,andSingh,S.,2021,â€œCalibratebe-
Chaudhary, V., Oâ€™Horo, B., Wang, J., Zettlemoyer, L., Kozareva, Z., Diab, foreuse:Improvingfew-shotperformanceoflanguagemodels,â€International
M.T.,Stoyanov,V.,andLi,X.,2021,â€œFew-shotLearningwithMultilingual conferenceonmachinelearning,PMLR,pp.12697â€“12706.
LanguageModels,â€ArXiv,abs/2112.10668. [105] Wang,X.,Wei,J.,Schuurmans,D.,Le,Q.,Chi,E.,Narang,S.,Chowdhery,
[76] Perez,E.,Kiela,D.,andCho,K.,2021,â€œTrueFew-ShotLearningwithLan- A.,andZhou,D.,2022,â€œSelf-consistencyimproveschainofthoughtreasoning
guageModels,â€ArXiv,abs/2105.11447. inlanguagemodels,â€arXivpreprintarXiv:2203.11171.
[77] Boiko,D.A.,MacKnight,R.,Kline,B.,andGomes,G.,2023,â€œAutonomous [106] Wei,J.,Wang,X.,Schuurmans,D.,Bosma,M.,Xia,F.,Chi,E.,Le,Q.V.,
chemicalresearchwithlargelanguagemodels,â€Nature,624(7992),pp.570â€“ Zhou,D.,etal.,2022,â€œChain-of-thoughtpromptingelicitsreasoninginlarge
578. languagemodels,â€Advancesinneuralinformationprocessingsystems,35,pp.
[78] Bran,A.M.,Cox,S.,Schilter,O.,Baldassari,C.,White,A.D.,andSchwaller, 24824â€“24837.
P., 2023, â€œChemcrow: Augmenting large-language models with chemistry [107] Fu,Y.,Peng,H.,Sabharwal,A.,Clark,P.,andKhot,T.,2022,â€œComplexity-
tools,â€arXivpreprintarXiv:2304.05376. basedpromptingformulti-stepreasoning,â€TheEleventhInternationalConfer-
[79] Romera-Paredes,B.,Barekatain,M.,Novikov,A.,Balog,M.,Kumar,M.P., enceonLearningRepresentations.
Dupont, E., Ruiz, F.J., Ellenberg, J.S., Wang, P., Fawzi, O., etal., 2024, [108] Yao,S.,Yu,D.,Zhao,J.,Shafran,I.,Griffiths,T.,Cao,Y.,andNarasimhan,
â€œMathematicaldiscoveriesfromprogramsearchwithlargelanguagemodels,â€ K.,2024,â€œTreeofthoughts: Deliberateproblemsolvingwithlargelanguage
Nature,625(7995),pp.468â€“475. models,â€AdvancesinNeuralInformationProcessingSystems,36.
[80] Thapa,S.andAdhikari,S.,2023,â€œChatGPT,bard,andlargelanguagemodels [109] Yao,S.,Zhao,J.,Yu,D.,Du,N.,Shafran,I.,Narasimhan,K.,andCao,Y.,
for biomedical research: opportunities and pitfalls,â€ Annals of biomedical 2022,â€œReact: Synergizingreasoningandactinginlanguagemodels,â€arXiv
engineering,51(12),pp.2647â€“2651. preprintarXiv:2210.03629.
[81] Chen, Q., Sun, H., Liu, H., Jiang, Y., Ran, T., Jin, X., Xiao, X., Lin, Z., [110] Takezawa,A.andKobashi,M.,2017,â€œDesignmethodologyforporouscom-
Chen,H.,andNiu,Z.,2023,â€œAnextensivebenchmarkstudyonbiomedical positeswithtunablethermalexpansionproducedbymulti-materialtopology
textgenerationandminingwithChatGPT,â€Bioinformatics,39(9),p.btad557. optimizationandadditivemanufacturing,â€ CompositesPartB:Engineering,
131,pp.21â€“29.
[82] Lee, J., Yoon, W., Kim, S., Kim, D., Kim, S., So, C. H., and Kang, J.,
[111] Xia,L.andBreitkopf,P.,2014,â€œConcurrenttopologyoptimizationdesignof
2020,â€œBioBERT:apre-trainedbiomedicallanguagerepresentationmodelfor
biomedicaltextmining,â€Bioinformatics,36(4),pp.1234â€“1240. materialandstructurewithinFE2nonlinearmultiscaleanalysisframework,â€
ComputerMethodsinAppliedMechanicsandEngineering,278,pp.524â€“542.
[83] Zaki,M.,Krishnan,N.,etal.,2023,â€œMaScQA:AQuestionAnsweringDataset
[112] Wu,J.,Sigmund,O.,andGroen,J.P.,2021,â€œTopologyoptimizationofmulti-
forInvestigatingMaterialsScienceKnowledgeofLargeLanguageModels,â€
scalestructures:areview,â€StructuralandMultidisciplinaryOptimization,63,
arXivpreprintarXiv:2308.09115.
pp.1455â€“1480.
[84] Xie,T.,Wan,Y.,Huang,W.,Zhou,Y.,Liu,Y.,Linghu,Q.,Wang,S.,Kit,
[113] Deng,B.,Zareei,A.,Ding,X.,Weaver,J.C.,Rycroft,C.H.,andBertoldi,
C.,Grazian,C.,Zhang,W.,etal.,2023,â€œLargelanguagemodelsasmaster
K., 2022, â€œInverse design of mechanical metamaterials with target nonlin-
key: unlocking the secrets of materials science with GPT,â€ arXiv preprint
earresponseviaaneuralacceleratedevolutionstrategy,â€AdvancedMaterials,
arXiv:2304.02213.
34(41),p.2206238.
[85] Zhu,J.-J.,Jiang,J.,Yang,M.,andRen,Z.J.,2023,â€œChatGPTandenvironmen-
[114] Maurizi,M.,Gao,C.,andBerto,F.,2022,â€œInversedesignoftrusslatticema-
talresearch,â€EnvironmentalScience&Technology,57(46),pp.17667â€“17670.
terialswithsuperiorbucklingresistance,â€npjComputationalMaterials,8(1),
[86] Holmes,J.,Liu,Z.,Zhang,L.,Ding,Y.,Sio,T.T.,McGee,L.A.,Ashman, p.247.
J.B.,Li,X.,Liu,T.,Shen,J.,etal.,2023,â€œEvaluatinglargelanguagemodelson [115] Li,M.,Jia,G.,Cheng,Z.,andShi,Z.,2021,â€œGenerativeadversarialnetwork
ahighly-specializedtopic,radiationoncologyphysics,â€FrontiersinOncology, guidedtopologyoptimizationofperiodicstructuresviaSubsetSimulation,â€
13. CompositeStructures,260,p.113254.
[87] Qin,C.,Zhang,A.,Zhang,Z.,Chen,J.,Yasunaga,M.,andYang,D.,2023, [116] Behzadi,M.andIlies,H.,2021,â€œReal-TimeTopologyOptimizationin3Dvia
â€œIschatgptageneral-purposenaturallanguageprocessingtasksolver?â€arXiv DeepTransferLearning,â€ArXiv,abs/2102.07657.
preprintarXiv:2302.06476. [117] Haghighat,E.,Raissi,M.,Moure,A.,GÃ³mez,H.,andJuanes,R.,2021,â€œA
[88] Zeng,F.,Gan,W.,Wang,Y.,Liu,N.,andYu,P.S.,2023,â€œLargelanguage physics-informeddeeplearningframeworkforinversionandsurrogatemodel-
modelsforrobotics:Asurvey,â€arXivpreprintarXiv:2311.07226. inginsolidmechanics,â€ComputerMethodsinAppliedMechanicsandEngi-
[89] Wang,G.,Xie,Y.,Jiang,Y.,Mandlekar,A.,Xiao,C.,Zhu,Y.,Fan,L.,and neering,379,p.113741.
Anandkumar,A.,2023,â€œVoyager: Anopen-endedembodiedagentwithlarge [118] Wang,Y.,Oyen,D.,Guo,W.,Mehta,A.,Scott,C.B.,Panda,N.,FernÃ¡ndez-
languagemodels,â€arXivpreprintarXiv:2305.16291. Godino,M.G.,Srinivasan,G.,andYue,X.,2021,â€œStressNet-Deeplearning
[90] Yang,C.,Wang,X.,Lu,Y.,Liu,H.,Le,Q.V.,Zhou,D.,andChen,X.,2023, topredictstresswithfracturepropagationinbrittlematerials,â€NpjMaterials
â€œLargelanguagemodelsasoptimizers,â€arXivpreprintarXiv:2309.03409. Degradation,5(1),p.6.
8ListofFigures
,
1 Schematic of the proposed framework. Specifications, boundaries, and loading conditions are provided in natural
language. The large language model (LLM) Agent generates a candidate solution, which is then evaluated using finite
element method (FEM) that serves as a discriminator. The FEM provides feedback to the LLM Agent in the form
of a solution-score pair, enabling the LLM to identify and implement the modifications needed to meet the specified
requirements. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
2 Initialpromptforgeneratinginitialsolution. Thispromptoutlinesthemethodforconstructingatrussusinggivennodes,
loads,supports,andcross-sectionalareasanddescribestheprocedurefordeterminingthemassofeachmember.. . . . . 3
3 Metapromptthatservesasasecondarypromptfollowingthegenerationofaninitialsolution. Thispromptpresentsthe
solution-scorepairfromtheinitialsolutionandpromptsthelanguagemodeltoexplainthereasoningbehinditsresponse.
Additionally,itrestatestheproblemforclarity. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
4 Final, optimized truss structures produced by the LLM agent for (a) task 1 and (b) task 2. The truss designs for each
taskarenotablydistinct,underscoringtheadaptabilityoftheLLMagenttomeetuniquedesignspecificationsacrossthe
designspace. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
5 RawsolutiongeneratedbytheLLMagentpresentedinthespecifiedformat,withreasoninghighlightedinred. . . . . . 5
6 Successrateoftaskswithvariationsover10runs,alongwiththecorrespondingnumberofiterationsrequiredtoachieve
the specified criteria. The success rate is measured as the percentage of successful runs out of 10 runs. The line plot
depictsthemeannumberofiterationswithstandarddeviationacrosstherunstoachievethespecification. . . . . . . . . 5
7 OptimizationtrajectoriesforTask1acrossthreedifferentproblemvariations. Eachpanel(a)Variation1,(b)Variation2,
and(c)Variation3,representsasequenceofstepstakentoachievedesignrefinementgeneratedfor3differentruns. The
initialsolutions,indicatedbythestartingpoints,undergosuccessiveiterationswheretheLLMevaluatessolution-score
pairs and proposes subsequent refinements. The dashed lines trace the path of exploration and exploitation within the
solution space, converging towards an optimal design zone highlighted in red. This zone represents the targeted range
of stress and mass parameters where design efficiency is maximized. Each run starting from a unique starting point
demonstratesauniquetrajectorytowarddesignoptimization. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
ListofTables
1 TrussDesignSpecifications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
9