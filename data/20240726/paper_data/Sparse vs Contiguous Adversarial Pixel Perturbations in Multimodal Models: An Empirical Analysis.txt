Sparse vs Contiguous Adversarial Pixel Perturbations in
Multimodal Models: An Empirical Analysis
Cristian-AlexandruBotocan RaphaelMeierâˆ— LjiljanaDolamicâˆ—
cristian-alexandru.botocan@epfl.ch raphael.meier@armasuisse.ch ljiljana.dolamic@armasuisse.ch
EPFL armasuisseS+T armasuisseS+T
Lausanne,Switzerland Thun,Switzerland Thun,Switzerland
armasuisseS+T
Thun,Switzerland
ABSTRACT constructingadversarialattacksusingpixelperturbations.Empiri-
Assessingtherobustnessofmultimodalmodelsagainstadversarial calanalysisoftheirimpactonattackperformancewouldenable
examplesisanimportantaspectforthesafetyofitsusers.Wecraft moreinformeddesignchoiceswhencraftingnoveladversarialpixel
ğ¿0-normperturbationattacksonthepreprocessedinputimages.We perturbationsandultimatelyleadtoabetterunderstandingofthe
launchtheminablack-boxsetupagainstfourmultimodalmodels overallrobustnessofmultimodalmodels.
andtwounimodalDNNs,consideringbothtargetedanduntargeted Inthiswork,wedevelopmethodsandexperimentstoaddress
misclassification.Ourattackstargetlessthan0.04%ofperturbed thisgap.Wefocusontheblack-boxscenariobecausewewantto
imageareaandintegratedifferentspatialpositioningofperturbed confrontthesecurityproblemofanattackerwhodoesnothave
pixels:sparsepositioningandpixelsarrangedindifferentcontigu- anypriorinformationaboutthemodel.Werelyonğ¿0-normper-
ousshapes(row,column,diagonal,andpatch).Tothebestofour turbationstohavecontroloverthenumberofpixelsbeingper-
knowledge,wearethefirsttoassesstherobustnessofthreestate- turbed. We extend Sparse pixel distribution attack presented in
of-the-artmultimodalmodels(ALIGN,AltCLIP,GroupViT)against workbySuetal.[48]toincorporatedifferentspatialencodings
differentsparseandcontiguouspixeldistributionperturbations. resultinginfivedifferentContiguousAttacks(detailsaredescribed
TheobtainedresultsindicatethatunimodalDNNsaremorerobust inSection4.2).Dependingonthenumberanddistributionofper-
thanmultimodalmodels.Furthermore,modelsusingCNN-based turbedpixels,ourmethodexploitspotentialvulnerabilitieshidden
ImageEncoderaremorevulnerablethanmodelswithViTâ€”forun- inthemodelarchitectures,suchasthekernelsizesinthecaseof
targetedattacks,weobtaina99%successratebyperturbingless CNN-basedImageEncoderofmultimodalmodels.Pixelperturba-
than0.02%oftheimagearea. tionsareusuallyperformedintheoriginalimage.Thisassumes
athreatmodelwithminimalinformationavailabletotheadver-
sary(i.e.,doesnotneedtoknowthepreprocessingroutine).How-
KEYWORDS
ever,ifyouperturbthepreprocessedimage,youcanbecertain
AIsecurity,Multimodalmodels,ContiguousAttacks,SparseAt-
thatyourexperimentalresultsarenotconfoundedbythediffer-
tacks,Pixel-perturbations
entpreprocessingpipelines,whichweprioritizedforthisstudy.
Weevaluatetheeffectivenessoftheseattackswithimagesfrom
1 INTRODUCTION
ImageNetonfouropen-sourcemodels(ALIGN[26],AltCLIP[10],
Incomputervision,theresearcherstrytofindnewmethodsforim- CLIP-B/32[43],andGroupViT[60])representativeofthedomain.
provingimageclassificationandothertasksbeyondthat(e.g.given Additionally, we evaluate our approach for two state-of-the-art
asetoftextualdescriptionsandanimage,themodelchoosesthe DeepNeuralNetworks(DNNs),whicharetrainedontheImageNet
mostlikelyimagedescription).Forthat,theresearchcommunity dataset[28].Finally,wealsoreleasethecodeforreproducingthe
developedmultimodalmodels[10,21,26,31,40,43,60,63],which study:https://github.com/ChristianB024/SparseVsContiguityRepo
areusedasabasisforfurtherresearch(CLIP[43]lede.g.tovarious Ourempiricalanalysisledtoseveralkeyinsights:
modificationssuchasRegionCLIP[63])andareincreasinglyalso
consideredforcommercialusage1.Thus,itisessentialtousesuch
models,knowingtheirrobustnessandsecurityimplications.While
priorstudieshavedemonstratedthevulnerabilityofmultimodal â€¢ Wefoundthatthreeoutoffourmultimodalmodelsand
modelstoperturbationsofthewholeimage[34,42],theirvulnera- both unimodal DNN models are most vulnerable to the
bilitytopixel-levelperturbationsremainslargelyunexplored.In SparseAttackforallexaminedattackscenarios(targeted
particular,theimpactofthenumberofperturbedpixelsandtheir anduntargetedmisclassification).
spatial distribution on the attack performance has not been ex- â€¢ ThePatchAttackismosteffectiveagainsttheCNN-based
ploredsofar.Bothofthesebasicaspectsmustbeconsideredwhen multimodalmodel(ALIGN[26]).Inanuntargetedscenario,
wereacha99%successrateonlybyperturbing0.01915%of
âˆ—Sharedseniorauthorship theimage(16pixels).
1Deloittereport:NovelDesignClassificationwithCLIP â€¢ Overall,weobservethatthemultimodalmodelsaremore
vulnerabletopixelperturbationattacksthanthestate-of-
the-artDNNs,whichwesuspecttobelinkedtotheway
ThisworkislicensedunderaCreativeCommonsAttribution4.0InternationalLicense. multimodalmodelsandunimodalDNNsaretrained.
1
4202
luJ
52
]VC.sc[
1v15281.7042:viXraCristian-AlexandruBotocan,RaphaelMeier,andLjiljanaDolamic
2 RELATEDWORKS In addition, both studies [48, 58] performed the pixel pertur-
bationsontheoriginalimages.Inthiswork,weperturbthepre-
2.1 AdvesarialAttacksonmultimodalmodels
processedimagesuchthatourattackisneitherinfluencedbythe
Inrecentyears,multimodalmodels[10,21,26,31,40,43,60,63],
dimensionoftheoriginalimagenortheparticularpreprocessing
whichcombineinformationfromdifferentmodalitiessuchastext,
routines.Therefore,weinvestigatetheattackbasedsolelyonthedif-
image,andaudio,haveemergedrapidlyaspowerfultoolsacross
ferentmodels.Also,theworkbyQiuetal.[41]includedananalysis
variousapplicationsrangingfromnaturallanguageprocessingand
ofcreatingtheimageperturbationswithrespecttotheğ¿ -normin
âˆ
computervisiontospeechrecognition.Previousresearchstudied
ablack-boxsetup,usingdifferentevolutionarystrategiesandchar-
attackingtechniquesonmultimodalmodelsandtriedtoidentify
acterizingwhichevolutionaryalgorithmismoresuitableforthis
certainvulnerabilitiesinthosemodels.
kindofattack.Morerecently,thepaperbyNametal.[36]explored
An adversarial perturbation attack can be defined by the ap-
theone-pixelideabutusinganexhaustivesearchprocedure,andthe
proachusedforperturbingtheinput.Forinstance,theworks[7,16]
perturbationswereidentifieddirectlyontheoriginalimagewhile
exploredtheCLIP[43]multimodalmodelâ€™srobustnessagainstty-
weareattackingthepreprocessedimages.InthestudybyGhoshet
pographicalattacksâ€”theattackerintroducedatextualstickercon-
al.[18],thedifferentialevolution(DE)[47]techniquegeneratedthe
tainingawordontheimagetomisclassifytheimagetotheclass
pixel-perturbationsinablack-boxsetup.Theattackwaslaunched
writtenonthetextualsticker.
againstrelativelyoldCNNmodels(VGG16[46],GoogleNet[49],
ThepaperbyQiuetal.[42]analyzedtherobustnessofmulti-
InceptionV[50],ResNet-50[22]),whileweattackmorerecently
modalmodelsbyaddingnoise/blurtothewholeimagetocreate
proposedmultimodalmodels.Sincewewanttocomparetheirro-
theimageperturbations,whileinourwork,wefocusonperturbing
bustnesswithestablishedunimodaldeepneuralnetworks,wealso
onlyalimitednumberofpixels.Similarly,thestudybyMaoet
comparethemagainsttheResNet-50[22]andtheVAN(VisualAt-
al.[34]quantifiedtherobustnessoftheCLIPmodelbycreating
tentionNetwork[20],whichusedDilatedConvolutionLayers[62]).
adversarialimagesusingwhite-boxPGDattack[33].Theyalso
presentedtwodefensemethodsformitigatingthatkindofattack.
2.3 AdversarialPatchAttacks
Moreover,someworks,suchasYangetal.[61],focusonadversar-
ialperturbationagainstmultimodalmodelsusingonlythePGD Theideaofperturbingpixelsintheformofapatchisnotnew,andit
white-boxscenario.Similarly,intheworkbySchlarmannetal.[44], wasalreadytestedbeforeinthewhite-box[6,27]andblack-boxse-
theylaunchimperceptibleattacksusingthesamePGDwhite-box tups[6,64].Forinstance,theworkbyAlrasheedietal.[1]explored
techniqueonasingleopen-sourcemodel(OpenFlamingo[3]).In theproblemofmakingtheimageperturbationsimperceptibleand
contrast,inourstudy,welimittheadversaryâ€™spowertoconsidering alsofoundcertainboundariesinthewidthlimit.However,theen-
theblack-boxscenariosonly.Amoredifferentattackispresented tireattackwaslaunchedinawhite-boxsetup,whilewefocuson
intheworkbyFreibergeretal.[17]whereitexploitedthevulner- black-boxattackssincetheyaremuchclosertoreal-worldscenarios.
abilityofthemodalitygapinacontrastivelearningapproachby ThestudybyWeietal.[57]performedtheattacksinablack-box
generatingadversarialexamplesusingtheevolutionstrategyfor manner by applying reinforcement learning as an optimization
searchinggenerativemodelsâ€™latentspace. techniquetosimultaneouslyfindthebestpositionandperturba-
tionvaluesforthepatch.Thisprocessissimilartowhatwetryto
achieveinourexperiments,butweusetheDEapproachtoevolve
ourperturbations.Differentmethodswereusedinthecontextof
patchattacksbyevenhidingthepatchasaQRcode[11,12],such
2.2 AdversarialattacksusingGenetic thatthepixelperturbationsbecamelesssuspicioustothehuman
eye.Moreover,thesepatchadversarialattackswerealsoexamined
Algorithms(GA)
concerningobjectdetectionmodelsusingaerialimages[53]and
CertainadversarialperturbationattacksonDeepLearningmodels
deephashingmodels[23].
focusedonlyonthewhite-boxscenarios[2,8,19,29,33,35,37,51],
Lastly,theresearchcommunityreliedonGANstogenerateadver-
whileothersevolvedindirectionofblack-boxattacks[5,9,48,55].
sarialpatchesforimageclassification[4,14,32]orobject-detection
Moreover,forimprovingtheirattacks,therearestudieswherege-
models[24,38].Withthistechnique,therecentpaperbyZhouet
neticalgorithmshavebeenintroduced[48,59].Forinstance,the
al.[65]showedanon-targetedattackagainstthemultimodalmodel
studybySuetal.[48]generatedtheadversarialexamplesagainst
CLIP[43].However,wedonottrainGANmodelssincewetryto
theDNNsbyperturbingaspecificnumberofpixels,thususing
limittheattackerâ€™spower(includingthecomputationalone).
anğ¿0norm.Furthermore,thepaperbyJereetal.[25]usedevolu-
tionarystrategies(includingDifferentialEvolution)forgenerating
scratchperturbationsontheimageagainstDNNsonly.Similarly, 3 ATTACKMODEL
intermsofapplyingtheevolutionaryalgorithmsbutusingsparse Weanalyzetheblack-boxscenarioofanadversarywithaccessto
adversarialperturbationsthroughsimultaneousminimizationof ArtificialIntelligence(AI)modelsduringinference,sotheattacker
ğ¿0andğ¿2norms,theresearchbyWilliamsetal.[58]restrictedthe hasaccessonlytothemodelâ€™sinputandoutput.Figure1presentsa
spaceofpotentialperturbationsquiteaggressivelyandfocusedon visualizationofthedescribedthreatmodel.Toformalizetheattack,
studyingonlysparselydistributedpixelperturbations.Sothereis let the function ğ‘“ : {0,...,255}ğ‘¤Ã—â„Ã—3 â†’ [0,1]ğ¶ represent the
noexplorationregardingtheimpactofcontiguousshapesofthe modelclassificationwhichtakesasaninputğ‘¥ âˆˆ{0,...,255}ğ‘¤Ã—â„Ã—3
perturbationonattackperformance. representing an RGB image with dimensionğ‘¤ andâ„ for width
2SparsevsContiguous
Image
Preprocessor Model
Label's probabilities
Perturbations Observations
Adversary Model
Figure1:ThreatModelVisualization
andheightrespectively.Theoutputcorrespondstoaprobability
distributionfortheğ¶classes.Themaximumprobabilityfromthe
listofallgivenclassesğ¶ yieldsthelabel(ortextualdescription)
ğ‘¦
ğ‘œğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›ğ‘ğ‘™
=argmax ğ‘–âˆˆ{1,...,ğ¶}ğ‘“ ğ‘–(x).Weconsidertwopossiblepixel-
perturbationattacks.Inthefirstone,thegoaloftheattackeristo
findaperturbation(Î”x)suchthatthenewimageisclassifiedas
Figure2:AgentencodingfortheSparseAttack
aspecifictargetlabel(targetedattacknotedastar).Theattackis
presentedintheEquation1wheretheadversaryismaximizingthe
targetlabel(ğ‘ )probabilitybyperturbingatmostğ‘‘pixels.
ğ‘¡ğ‘ğ‘Ÿ
4.1 SparseAttack
AsmentionedinSection3,weuseSuetal.[48]â€™sapproach,the
(cid:40)ğ‘tar=maxğ‘“ ğ‘–:=tar(x+Î”x),
differentialevolution(DE)[47]geneticalgorithm,asanoptimiza-
findÎ”xsuchthat Î”x (1)
and||Î”x||0 â‰¤ğ‘‘ tionmethodforfindingthebestperturbationsformisclassification
tasks.Encodingsoftheperturbationsinspecificvectors(notedas
The second one, untargeted attack (noted as untar), has as the agentsorpopulationmembers)becomeaccessibletotheevolu-
goaltodorandommisclassification(maximizinganyotherclass tionaryapproach,whichtriestoiterativelyyieldbetterperturba-
probability)asitisdescribedsimilarlybytheEquation2. tionsovertime.FortheSparseAttack,wecanusefivevalues,
[ğ‘¥ ğ‘ğ‘œğ‘œğ‘Ÿğ‘‘,ğ‘¦ ğ‘ğ‘œğ‘œğ‘Ÿğ‘‘,ğ‘Ÿ ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’,ğ‘” ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’,ğ‘ ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’], to describe a pixel, namely
findÎ”xsuchthat(cid:40)ğ‘
ğ‘¢ğ‘›ğ‘¡ğ‘ğ‘Ÿ
=m Î”a xxğ‘“ ğ‘–â‰ ğ‘œğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›ğ‘ğ‘™(x+Î”x),
(2)
i at nsp ago esi nt tio in si rn eg prb ey seth ne tec do bo yrd ğ‘ina flt ae ts tea nn ed dit as nR dG coB nv ca al tu ee ns a. tA edsa ver ce ts ou rl st ,,
and||Î”x||0 â‰¤ğ‘‘ whereğ‘ isthenumberofpixelsforwhichtheperturbationisbeing
performed.Section2illustratestheencodedperturbationvector
Theperturbationofourattackiscreatedforthepreprocessed
imageinsteadoftheoriginalimage.Infact,iftheadversaryperturbs
weuseforthistypeofattack.AnimportantpropertyoftheSparse
onepixelina32Ã—32image(dimensionoftheoriginalimage),thenit
Attackisthattherearenoconstraintsonthespatialdistributionof
thepixelsusedfortheattack.
perturbed10.24%oftheimage(approachpresentedinthepaperby
Suetal.[48]),whileonepixelinapreprocessedimageofdimension
224Ã—224representslessthan0.002%oftheimagearea.Table1 4.2 ContiguousAttacks
showstheexactpercentagesoftheperturbedareaforthetarget IncontrasttotheSparseAttack,wecanimposeconstraintsonthe
models.Furthermore,attackingthissmallareaoftheimagemakes spatialdistributionofthepixelsusedforanattack.Inparticular,we
theattacklessperceptibleforthehumaneyeandhardtodetectby choosetoforcepixelstoformspatiallycontiguousregionsintheim-
thesystems,hencehavingpotentiallycatastrophicconsequences age(i.e.,anti-diagonal,diagonal,column,row,patch).Sincewe
inasensitiveapplication.Moreover,thissetupisclosertothereal- alsoaddressthequestionofhowdifferentshapesofcontiguouspix-
worldscenario,wherecompaniesusuallyreleasenewAImodels elscanaffectthemodelrobustness,wecreateappropriateencodings
viaanAPI,whichtakesinputimagesofaspecificdimension(the fortheContiguousAttack.Wedecreasethenumberofthevaluesthat
companyalsoneedtoreleasetheImageProcessorofthemodel)and mustbemutatedforothershapesandstoreonlythecoordinatesof
outputstheprobabilitiesforspecificclasses/textualdescriptions. thefirstpixelfromthatshape.Thus,wehavethegenericencoding
Lastly,theattackislimitedtoğ‘„numberofqueriestothemodel. pattern[ğ‘¥ ğ‘ğ‘œğ‘œğ‘Ÿğ‘‘,ğ‘¦ ğ‘ğ‘œğ‘œğ‘Ÿğ‘‘,ğ‘Ÿ ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’1,ğ‘” ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’1,ğ‘ ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’1,...,ğ‘Ÿ ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’ğ‘›,ğ‘” ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’ğ‘›,ğ‘ ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’ğ‘›],
Hence,theattackercreatestheperturbationsusinganevolutionary wheretheğ‘Ÿ,ğ‘”,ğ‘valuesrepresentthecolorsforeachperturbedpixel
algorithm(differentialevolutionâ€”DE[47])andmakesamaximum inthespecificshape.Thefirsttwovaluesarethexandycoordinates,
ofğ‘„queries. representingdifferentstartingpixels:
Anti-DiagAttack thexandycoordinatesofthelowestpixel
4 EVOLUTIONARYATTACKS oftheshape.
Thissectionpresentstheencodingforeachtypeofattackused DiagonalAttack the x and y coordinates of the up-most
(SparseandContiguousAttacks),followedbyhowweinitializethe pixelofthediagonal.
geneticalgorithmsetup.Theevolutionaryprocessisthenexplained ColumnAttack thexandycoordinatesoftheup-mostpixel
indepth,coveringmutation,crossover,andfitnessfunctions. ofthecolumn.
3Cristian-AlexandruBotocan,RaphaelMeier,andLjiljanaDolamic
Table1:Percentageoftheperturbedareaintheattackedimage
Preprocessedimagedimension\Pixels 4pixels 9pixels 16pixels
ALIGN-289x289 0.00478% 0.01077% 0.01915%
AltCLIP,CLIP-ViT-B/32,GroupViT-224x224 0.00797% 0.01793% 0.03188%
VAN-base,ResNet-50-224x224 0.00797% 0.01793% 0.03188%
RowAttack thexandycoordinatesoftheleft-mostpixelof bytheirfitnessvalues,atpositionzerointhepopulationyieldsthe
therow. bestperturbation.
Pat pc ih xeA lott fa tc hk ept ah te chx .andycoordinatesoftheup-leftcorner ğ¹ ğ‘¡ğ‘ğ‘Ÿ =ğ‘ ğ‘¡ğ‘ğ‘Ÿ âˆ’ ğ‘–m â‰ a tax rğ‘ ğ‘– (3)
Asanexampleonhowthepixelsarepositionedandwhatistheir ğ¹ ğ‘¢ğ‘›ğ‘¡ğ‘ğ‘Ÿ = max ğ‘ ğ‘– âˆ’ğ‘ original (4)
ğ‘–â‰ original
order in the encoding vector depending on the attack type, we
illustratethecasewhereweperturbfourpixelsinFigure3.
ğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ ğ‘ğ‘ğ‘›ğ‘‘ =ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›0+ğ‘šğ‘¢ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘œğ‘› ğ‘Ÿğ‘ğ‘¡ğ‘’ Â·(ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘› ğ‘Ÿ1âˆ’ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘› ğ‘Ÿ2)
TheideaofContiguousAttacksistoactuallytrytoperturbmul-
whereğ‘Ÿ1andğ‘Ÿ2arerandomindicesthatarewithinthepopulationsize
tiplevisualpatches(dependingonthelengthoftheshape)from
(5)
theViTmodel.So,supposeanattackerchoosestherowshape.In
thatcase,itcanperturbanumberofconsecutivevisualpatches(or
Forthenextiteration,wecreatePothernewcandidates(ğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ ğ‘ğ‘ğ‘›ğ‘‘).
Thus,foreachmemberinthepopulation,weapplythemutation
tokens)differentlydependingontheiralignmentwiththerowof
functionfromEquation5andthecrossoveroperation,usingthe
perturbedpixels.Figure4showsanexampleofperturbing6pixels
exponentialstrategyapproach(seeAppendixA).Alistwiththe
indifferentshapes.Wehavemostperturbationsinthemiddlevisual
parametervaluesusedintheDEispresentedintheSection5.1.
patchfortheRowAttackandlessforthebeginningandfinalpatch.
Afterobtainingthecandidates,weperform P queriestothe
Hence,wewanttotestifitisbettertoperturblessinformationbut
modelandcomputethefitnessvaluesbasedontheprobabilities
frommanyverydifferentvisualpatches(SparseAttack),perturb
obtained.Therefore,wedecidewhichPagentsoutof2Â·P(oldand
lessinformationtosomevisualpatchesandmoreinsomeothers
newagents)surviveforthenextgeneration,basedontheirfitness
(RowAttack),orperturbmoreinasmallernumberofvisualpatches
valuesâ€”thePagentswiththehighestfitnessvaluesareselected.
(PatchAttack).Thus,wedonotfocusontheevolutionarymethod
WerepeatthisprocessGtimes,aswearelimitedtothemaximum
forimprovingthepositionofthosepixelshapes.However,weem-
numberofquerieswecando.Theideaoftheevolutionaryapproach
phasizethatifweuseanevolutionaryapproachtofindthebest
isgeneratingincreasinglybetterperturbationsovertimeand,asa
perturbationbasedontheprovidedshape,wecanstillexploithow
result,haveatleastoneperturbationthatcategorizestheattackas
ViTcreatestheimagetokens.
successful.Furtherdetailsabouthowwequantifythesuccessofan
attackareexplainedinSection5.2.
4.3 Initialization
Similarly with the study by Su et al. [48], for the initialization 5 EXPERIMENTS
processofthepopulation,wedothefollowing:
Thissectionpresentstheimagesusedfortheattackandthevalues
â€¢ forğ‘¥ ğ‘ğ‘œğ‘œğ‘Ÿğ‘‘ andğ‘¦ ğ‘ğ‘œğ‘œğ‘Ÿğ‘‘ weassignuniformlyrandominteger for the parameters used. Moreover, we describe the evaluation
valuesbasedonthedimensionoftheattackingimage(i.e., metricsandbaselines.Lastly,wepresentournumericalresults.
ğ‘ˆ(0,ğ‘šğ‘ğ‘¥ ğ‘‘ğ‘–ğ‘š))
â€¢ forRGBvalues,sincetheirvaluesarebetween0and255,we 5.1 Experimentsetup
assignthemasarandomvaluefromanormaldistribution
WeevaluateourattacksonsamplesfromImageNet[28].Itcontains
ğ‘(ğœ‡=128,ğœ =127)
imageswithavariableresolutionlengthand,thus,adifferentnum-
berofpixels.AsexplainedinSection3,weattackthepreprocessed
4.4 Evolutionaryprocess image before it is fetched into the model; we do not apply any
Afterinitializingthefirstpopulation(generatingPperturbations, preprocessingoperationstotheoriginalimagesfromthedataset
also called agents), we calculate the fitness value for each one. toscaleallofthemtoafixedresolution,256Ã—256resolution,as
Thisiscomputedbyapplyingafitnessfunction.Asmentionedin itisdoneintheoriginalpaper[28].Thenumberoflabelsforthis
Section3,wehavetwopossibleattackscenarios.Hence,weuse datasetis1000.
twohingelossfunctions,inspiredbythepaperbyChenetal.[9] Themodelsusedcanbesplitintotwobranchesbasedontheir
andexemplifiedintheEquations3and4â€”fortargetedattacksğ¹ architecture.Inthefirstcategory,wehavethestate-of-the-artmul-
ğ‘¡ğ‘ğ‘Ÿ
andğ¹ forthenon-targetedattacks.Furthermore,wemaximize timodalmodels;intheother,wehavethestate-of-the-artDNNs,
ğ‘¢ğ‘›ğ‘¡ğ‘ğ‘Ÿ
thefitnessfunctionofeverynewgeneration.Sinceweassumea trainedontheImageNetdataset.Table2showsthelistofallthe
black-boxattackscenario,weneedtoconsiderthatwecanonly modelsandtheirmeasuredaccuracyfor10,000imagesfromthe
accesstheprobabilitiesforeachclass.Forinstance,inourcase, testingdatasetofImageNet.Themotivationbehindthisassessment
theğ‘[ğ‘¥]meansweobtainthesoftmax(probability)valuefromthe isgivenbytheconnectionbetweenrobustness,thearchitecture
modelforclassğ‘¥.Also,asthesefunctionsascend,sortingtheagents used,andtheversatilityofthemodels(multimodalmodelscan
4SparsevsContiguous
4 1 1 1 2 3 4 1 2
3 2 2 3 4
2 3 3
1 4 4
(a)Anti-Diagonal (b)Diagonal (c)Column (d)Row (e)Patch
Figure3:SpatialarrangementofpixelsinContiguousAttacksforexemplarycaseoffourperturbedpixels
foreachmodel.Thosearepartofthetestingdataset;consequently,
themodelsdidnotseethoseimagesduringtheirtrainingphase.
Then, after extracting those images, we store the preprocessed
versionbasedoneachmodel.Hence,wetestdifferentattacksetups
Visual Patch 1 Visual Patch 2 Visual Patch 3
onthesameimagestoquantifytheattackâ€™seffectiveness.
(a)SparseAttack Basedonempiricalobservations,weobservethatthebestpa-
rametersfortheDifferentialEvolutionareğ‘šğ‘¢ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘œğ‘›
ğ‘Ÿğ‘ğ‘¡ğ‘’
=0.55and
ğ‘ğ‘Ÿğ‘œğ‘ ğ‘ ğ‘œğ‘£ğ‘’ğ‘Ÿ
ğ‘Ÿğ‘ğ‘¡ğ‘’
=0.8.Moreover,thepopulationofP =300givesthe
bestresultswhenwelimitthenumberofiterationstoG=100.As
aremarkfromSection3,thetotalnumberofqueriesanattacker
Visual Visual Visual
Patch 1 Patch 2 Patch 3 needstodotoperturbanimageisatmostğ‘„,whichistranslatedto
PÂ·G â‰¤ğ‘„,whichmeans300Â·100â‰¤30,000â‰¤ğ‘„.
(b)Contiguous-RowAttack
5.2 EvaluationMetricsandBaselines
AttackperformanceisquantifiedbycomputingtheSR(successrate)
asanempiricalmeasurement.Dependingonthetypeofattack,we
Visual Visual Visual
definethesuccessoftheattackasfollows:targetedattacksinvolves
Patch 1 Patch 2 Patch 3
howmanyimagesmanagedtobemisclassifiedasthetargetlabel,
(c)PatchAttack whileforuntargetedscenarios,wecountthenumberofimages
thataremisclassifiedasadifferentlabelthantheoriginalone.As
Figure4:Pixelperturbationsfordifferentattacksonpatch-based mentioned Section 5.1, for our setup, it translates to using 100
models(e.g.VisionTransformers,ViTs) images and computes how many of them we manage to attack
successfully.Then,sincetheSRisavaluebetween0and1,we
Table2:PerformancecomparisonbetweenMultimodalMod- divideitby100(thenumberofimages).Thus,anSRvalueof1
elsandDNNs meanswecreatesuccessfulperturbationsforallimages.
Lastly,toinvestigatetheeffectivenessoftheevolutionaryattacks,
wecreaterandomversionsforeachtypeofattackandusethemas
Model Accuracy ModelType
baselines.TheseRandomAttacksusethesameparametersasthe
ALIGN[26] 0.5442 Multimodal evolutionaryone(P =300andG =100),butthedifferenceisin
CLIP_ViT-B32[43] 0.5601 Multimodal generatingthoserandomagentswithoutanevolutionaryapproach.
AltCLIP[10] 0.6993 Multimodal Ateachiteration,wegeneratePagentsaccordingtotheirrespective
GroupViT[60] 0.3187 Multimodal encodingspresentedinSections4.1and4.2,andthevaluesare
ResNet-50[22] 0.8087 DNN random and set based on the initialization values presented in
VAN-base[20] 0.8022 DNN Section4.3.However,somecorrectionsareappliedifthevaluesare
outsidetheranges(especiallyfortheRGBvalues).
beappliedtodifferentdatasetswithouttheneedforextensivere- 5.3 Results
trainingduetothezero-shotproperty,whileDNNsusuallyrequire WeevaluatetheperformancesofattacksbasedontheSRmetric
trainingonaspecificdatasetandareoptimizedforthatoneonly). andagainstthebaselinesdescribedinSection5.2.Forinstance,
Inordertousethemultimodalmodelsforimageclassification, Figure5presentstheSRforthetargetedattacksforeachselected
werelyonappropriateinputcaptions.Inparticular,weappend modelandtheshapeoftheattacks,dependingonthenumberof
thestring"aphotoof"infrontoftheoriginallabeloftheimageto pixelsperturbed.Atfirstglance,weobservethatfortheALIGN
enablezero-shotimageclassification. model,themostsuccessfulattackisthePatchAttack,whileforthe
AsobservedinTable2,themodelsperformverydifferently,and others,itistheSparseAttack.Furthermore,thebestattacksagainst
wewantanextensiveanalysisoftheirrobustness.Thus,toavoid themultimodalmodelsachieveanSRhigherthan0.35,whilefor
anypossiblebias,weextract100randomcorrectlyclassifiedimages theDNNs,theSRisgenerallylowerexceptforResNet-50withthe
5Cristian-AlexandruBotocan,RaphaelMeier,andLjiljanaDolamic
ALIGN AltCLIP
0.95 0.95
0.90 0.90 Evolutionary Attacks
0.85 0.85
0.80 0.80 Sparse
0.75 0.75 Anti-Diag
0.70 0.70 Diagonal
0.65 0.65
0.60 0.60 Column
0.55 0.55 Row
0.50 0.50 Patch
0.45 0.45
0.40 0.40
0.35 0.35 Random Attacks
0.30 0.30 Random Sparse
0.25 0.25
0.20 0.20 Random Anti-Diag
0.15 0.15 Random Diagonal
0.10 0.10 Random Column
0.05 0.05
0.00 0.00 Random Row
4 9 16 4 9 16 Random Patch
Pixels Pixels
CLIP-ViT/B32 GroupViT
0.95 0.95
0.90 0.90 Evolutionary Attacks
0.85 0.85
0.80 0.80 Sparse
0.75 0.75 Anti-Diag
0.70 0.70 Diagonal
0.65 0.65
0.60 0.60 Column
0.55 0.55 Row
0.50 0.50 Patch
0.45 0.45
0.40 0.40
0.35 0.35 Random Attacks
0.30 0.30 Random Sparse
0.25 0.25
0.20 0.20 Random Anti-Diag
0.15 0.15 Random Diagonal
0.10 0.10 Random Column
0.05 0.05
0.00 0.00 Random Row
4 9 16 4 9 16 Random Patch
Pixels Pixels
ResNet-50 VAN-base
0.95 0.95
0.90 0.90 Evolutionary Attacks
0.85 0.85
0.80 0.80 Sparse
0.75 0.75 Anti-Diag
0.70 0.70 Diagonal
0.65 0.65
0.60 0.60 Column
0.55 0.55 Row
0.50 0.50 Patch
0.45 0.45
0.40 0.40
0.35 0.35 Random Attacks
0.30 0.30 Random Sparse
0.25 0.25
0.20 0.20 Random Anti-Diag
0.15 0.15 Random Diagonal
0.10 0.10 Random Column
0.05 0.05
0.00 0.00 Random Row
4 9 16 4 9 16 Random Patch
Pixels Pixels
Figure5:TargetedAttacks
SparseAttackandperturbing16pixels.Overall,theprogressionof similar.Moreover,alltheEvolutionaryAttacksmanagetobeatthe
SRvalueswithincreasingperturbedpixelsfortheDEattacksis RandomAttacks,withoneexception:RandomPatchAttack,which
steeperthanfortherandombaselineattacks.Thusdemonstrating hasanSRclosetotheonesoftheContiguousAttacks.Besidesthis
thattheSRoftheproposedattacksisafunctionofthenumber one,therestoftheRandomonesonlyachieveanSRbelow40%,
ofperturbedpixelswithanincreasednumberofpixelsyielding evenafterincreasingthenumberofpixels.
higherSR. Figure5highlightsthatforAltCLIP,theSparseAttackisthebest
ForALIGN,Figure5showsthatthePatchAttackperformsthe attackfor4and9pixelswithSRof0.35and0.46,respectively.For
best(0.74),butthevalueagainsttheSparseAttackfor4pixelsis 16pixels,themostsuccessfulattackisthePatchAttack,withtheSR
relativelyclose(0.58forPatchand0.57forSparse).However,the almost0.5.AlltheContiguousattacksoutperformtheRandomones,
transitionfrom4to6pixelsissteeperforthePatchAttack,starting withthegapbetweenthosebecomingmoreprominentwithmore
from0.57andreaching0.71,whilefortheSparseAttack,itstarts pixels.Initially,thedifferenceisnegligible,whilefor16pixels,the
from0.56andreaches0.64forthe9pixels.Nevertheless,forthe gapbetweentheRowAttack(worstContiguousAttack)andRandom
transition from 9 to 16 pixels, the slopes for both attacks seem Patch (the best Random Attack) is approximately 0.7. However,
6
tegrat-RS
tegrat-RS
tegrat-RSSparsevsContiguous
ALIGN AltCLIP
0.95 0.95
0.90 0.90 Evolutionary Attacks
0.85 0.85
0.80 0.80 Sparse
0.75 0.75 Anti-Diag
0.70 0.70 Diagonal
0.65 0.65
0.60 0.60 Column
0.55 0.55 Row
0.50 0.50 Patch
0.45 0.45
0.40 0.40
0.35 0.35 Random Attacks
0.30 0.30 Random Sparse
0.25 0.25
0.20 0.20 Random Anti-Diag
0.15 0.15 Random Diagonal
0.10 0.10 Random Column
0.05 0.05
0.00 0.00 Random Row
4 9 16 4 9 16 Random Patch
Pixels Pixels
CLIP-ViT/B32 GroupViT
0.95 0.95
0.90 0.90 Evolutionary Attacks
0.85 0.85
0.80 0.80 Sparse
0.75 0.75 Anti-Diag
0.70 0.70 Diagonal
0.65 0.65
0.60 0.60 Column
0.55 0.55 Row
0.50 0.50 Patch
0.45 0.45
0.40 0.40
0.35 0.35 Random Attacks
0.30 0.30 Random Sparse
0.25 0.25
0.20 0.20 Random Anti-Diag
0.15 0.15 Random Diagonal
0.10 0.10 Random Column
0.05 0.05
0.00 0.00 Random Row
4 9 16 4 9 16 Random Patch
Pixels Pixels
ResNet-50 VAN-base
0.95 0.95
0.90 0.90 Evolutionary Attacks
0.85 0.85
0.80 0.80 Sparse
0.75 0.75 Anti-Diag
0.70 0.70 Diagonal
0.65 0.65
0.60 0.60 Column
0.55 0.55 Row
0.50 0.50 Patch
0.45 0.45
0.40 0.40
0.35 0.35 Random Attacks
0.30 0.30 Random Sparse
0.25 0.25
0.20 0.20 Random Anti-Diag
0.15 0.15 Random Diagonal
0.10 0.10 Random Column
0.05 0.05
0.00 0.00 Random Row
4 9 16 4 9 16 Random Patch
Pixels Pixels
Figure6:UntargetedAttacks
RandomPatchisstillthebestRandomattack,usuallyabove3-5% forallpixels,andthePatchAttack,achievingamaximumSRof
fromthesecond-bestRandomAttack.Additionally,thereisabig 47%.Nonetheless,thereisagapbetweenthosetwoattacksand
differencebetweenthePatchandSparseAttacksandtheremaining theothers:for16pixels,theRowAttack reachesavalueof0.45
ContiguousAttacks(10-25%). andbelow,with0.02lessthantheRandomSparseAttack.Thebest
BasedonFigure5,CLIPismorerobusttoourattacksthanALIGN Random Attack is the Sparse one, which outperforms the Patch
butlessrobustwhencomparedagainsttheothermultimodalmodels withapproximately10%for16pixels.Similarly,alltheotherCon-
(GroupViT,AltCLIP).ThebestattackremainstheSparseAttackwith tiguousAttacksarebetterthantheotherRandomones,exceptfor
valuesfrom0.5for4pixelsto0.68for16pixels,followedbythe RandomSparse.
PatchAttackwithvaluesfrom0.33to0.50.Thethirdbestattack FromFigure5weobservethatbothDNNshavesimilarbehavior:
isRowone,andforthe16pixels,itisfollowedbehindwith2%by theyaremorerobustthananymultimodalmodel.WithResNet-50,
Columnone. theSRvaluedoesnotexceed0.45forthebestattack(SparseAttack),
SimilartoCLIP,Figure5showsthatforGroupViT,thetoptwo whilefortheVAN-base,thebestonestopsat0.25.Moreover,the
bestattacksaretheSparseAttack,reachinganSRofmorethan55% trendregardingthebesttwoattacksremainsthesameasforCLIP
7
tegrat-non-RS
tegrat-non-RS
tegrat-non-RSCristian-AlexandruBotocan,RaphaelMeier,andLjiljanaDolamic
and GroupViT, with a significant difference regarding the gaps todeeperlayers,whichtrytoextractcorrectinformationthatcan
betweenthosetwoattacksandtherestâ€”thediscrepancyismuch beusedasfeaturesforclassification.
smaller(approx.5%forResNet-50andlessthan2%fortheVAN- Basedonourresults,ALIGN[26]isthemostvulnerablemodelto
base).Moreover,theRandomAttacksbehaveinthesamemanner theimplementedğ¿0-normperturbations.Thebestmethodtoattack
astherestoftheContiguousAttackswithvaluesfluctuatingwithin theALIGNmodelisbyusingthePatchAttackandnottheSparse
thelimitof5%forbothmodels. one,asitisformostofthecasesintheothermodels.Apotential
Results for the untargeted attacks are presented in Figure 6. explanationforthisobservationcouldbebecauseALIGNusesthe
Overall,thetrendsremainthesameasthetargetedattacks,but EfficientNet[52](CNN-basedarchitecturethatuses3x3Convolu-
theSRvalueisincreasedbyapproximately25%forALIGN,15% tionalLayers)asanImageEncoder.Thisiswhywehaveasteep
forAltCLIP,and10%forCLIPandGroupViT.Interestingly,amuch increaseintheSRforPatchAttackfrom4to9pixels,fromapatchof
smallerincreaseisobservableforbothDNNs(approximately5%). 2x2to3x3(representingthesamesizeastheConvolutionalLayer).
ALIGNappearstohavetheworstsecurityagainstthePatchAttack However,thetransitionfrom9to16pixelsissmootherbecause
foramoresignificantnumberofpixelssince,using16pixels,we wealreadymanagetocreateapatchwiththesamedimensionas
obtainaresultof99%SR.Moreover,theRandomPatchAttackisin theConvolutionallayer,sotheattackdoesnotincreasealotin
thethirdposition,withanSRclosetotheSparseAttackfor16and effectivnessfromtheprevioussize(itincreasedonlyby4%,while
achievingascoreof0.85.ForAltCLIP,thedifferencebetweenthe beforewehaveanincreasingofapproximate10%).Basedonthis
RandomAttacksandtheEvolutionaryonesincreasesproportionally information,theadversarycandeducesomeinformationregarding
withthenumberofpixels.Inaddition,similartothetargetedattack, thearchitectureused(thesizeofthekernelininitialConvolutional
thePatchAttackisslightlybetterthantheSparseoneforthe16 layers)inthemodelandthereforeherewecouldhaveapotential
pixels,whilefor4and9,thewinningoneistheSparseAttack.For privacyissue.Moreover,thisvulnerabilityoftheALIGNmodel
CLIPandGroupViTs,theplotsforrankingtheeffectivenessofthe againstthePatchAttackcanhaveseriousconsequencessince,for
attacksremainthesameasfortargetedattacks,asisthecasefor theuntargetedattack,apatchof16pixelsobtainsa99%success
theDNNs. rate.Weseethattheshapeoftheattack(Patch)additionallycon-
firmsthisvulnerabilitysincetheRandomPatchAttacks achieve
highscoresinbothcases,especiallyintheuntargetedsetting,being
thethirdmostpowerfulattack.
6 DISCUSSION WeobservethatAltCLIPismorerobustthantheoriginalimple-
Atfirstglance,basedontheresultspresentedinSection5.3,wecan mentationofCLIP.Thiscouldbeexplainedbecauseofthearchitec-
seethatthetargetedattackismorechallengingthantheuntargeted tureusedintheImageEncoder.Moreprecisely,AltCLIP[10]uses
one,whichisindeedexpected.However,theaveragedifference theViT-L14,whichhasthedimensionoftheembeddingequalsto
between those two attacks for multimodal models differs from 768,24layers,widthequalsto1024,and16heads,whileCLIP[43]
theDNNs.Also,theDNNsaremorerobusttoourattacksthan usestheViT-B/32whichhasdimensionoftheembedding equals
anymultimodalmodels.Animportantobservationisthatforall to512,12layers,widthequalsto768,and16heads.Hence,since
setupswehaveatleast2-3attackswhicharebetterthananyof the embeddings from AltCLIP are larger, they capture more in-
thebaselines. formation,andtherefore,itishardertofoolthosesystemswith
OurresultssuggestthatmultimodalmodelswithViT(Visual theğ¿0-normperturbations.Moreover,sincetheAltCLIPImageEn-
Transformer)[15]asanImageEncoderaremorepronetotheSparse coderisdeeper(basedonthenumberoflayers),itcancapture
thanthePatchAttack.Toprovideapotentialexplanation,wede- morecomplexpatternsandhierarchicalfeatures.Itmayexhibit
scribewhathappenswhenanimageisfedtoaViT.Initially,ViT betterrobustnessandgeneralizationâ€”thisisalsoprovedbythe
splittheimagesintovisualpatchesandthenconsidersthoseas Table2,whereAltCLIPobtainedthebestperformancecomparedto
tokens.Afterthisstage,thosetokensareprocessedsimilarlytoa theothermultimodalmodels.However,itseemsthatthereexistsa
normalTransformer[56].Supposetheadversaryperturbspixelson connectionbetweenthedepthandthewidthconfigurationofthe
differentvisualpatches(asyouhaveinSparseAttack),thenitcan modelwithlargerpatchessinceforbothnon-targetedandtargeted
altermoretokens.Hence,intheself-attentionlayer[56](corecom- attacksinthecaseof16pixels,thePatchAttackisslightlybetter,
ponentofaTransformerthatalsoprovidesgoodresultsintermsof andthereexistsastagnationintheSparseAttack.Furthermore,Alt-
robustness),thereisahighpossibilityofbreakingthesemantical CLIPusestheXLM-R[13]asaTextEncoder,whileCLIPusesthe
meaninginformationfromdifferentvisualpatches.However,using maskedself-attentiontransformer[15].Althoughthisaspectmight
anyContiguousAttack,theadversarycannotperturbasmanyvisual influencetherobustnessinfavorofAltCLIP,thecorecomponent
patchesaswouldbepossibleusingtheSparseAttack.Additionally, thatimprovesthesecurityaspectistheImageEncodersincewe
thePatchAttackoutperformsanyContiguousAttackbecause,with targetitwithouradversarialexamplesanddonotgiveadversarial
thisshape,wecanaltermoreinformationinasinglevisualpatch textualinput.
thanothercontiguouspixeldistributions. Forthesecondmostrobustmultimodalmodel,GroupViT[60],we
WealsoquestionwhyCNN-basedImageEncoders(ALIGNmodel) considerthatthegoodresultsintermsofrobustnessaredetermined
aremorepronetoPatchAttacks.Basedontheideafromtheprevi- mainlybythegroupingmechanismusedintheImageEncoder.This
ousparagraph,ifonepieceofinformationinthekernelisaltered newarchitectureusesahierarchicalgroupViTâ€”inshort,besides
forthosetypesofarchitectures,itisacompletedisasterforthe theclassicalViTapproach,wheretheimageisinitiallysplitinto
upcomingmax-poolinglayers.Thealteredinformationpropagates visualpatchesandprojectedintotokens(usingLinearProjection),
8SparsevsContiguous
italsocontainstheGroupLearnableTokens.Thosegrouptokens Forfuturework,weproposetostudytheattacksontheğ¿0-norm
describeadifferentsemanticnotion;thus,themodelalsogroups forothertypesofmultimodalmodelsthatfocusonobjectdetection
moresemanticconcepts.Sincethosetokensarelearnedduring and text generation, such as IDEFICS [30], Kosmos-2 [39], and
thetrainingphase,duringthegroupingsemanticphase,themodel Gemini[54].Moreover,wewanttodomoreinvestigationonthe
triestoavoidperturbedvisualtokens;therefore,thismechanism contiguousattacksandfocusonfindingthebesthyperparameters
increasestherobustnessofthemodel. fortheevolutionalgorithmusedforthosespecificpatterns,such
Inaddition,weobservesignificantdifferencesintheSRbetween thatwecanconstructasystematicsearchsetup,wherewecaninfer
theDNNsandtherestofthemultimodalmodels.Apotentialcause differentinformationregardingthemodelarchitecturefromthe
forthisbehaviorcouldberelatedtothefactthatweevaluatethe observedattackperformance.
DNNsontheimageswithspecificclasslabelsforwhichtheywere
originallytrained.Consequently,theseDNNscontainclass-specific
REFERENCES
featuresextractedduringtrainingonImageNet[28]whichrequires
anattackertoperturbmorepixels.IncontrasttoDNNs,multimodal [1] FahadAlrasheediandXinZhong.2023. ImperceptibleAdversarialAttackon
DeepNeuralNetworksfromImageBoundary.arXivpreprintarXiv:2308.15344
modelsweretrainedonlargecorpusesofimageandtextdatawith- (2023).
outexplicitdefinitionoftargetclassesduringtraining(contrastive [2] AnishAthalye,NicholasCarlini,andDavidWagner.2018.Obfuscatedgradients
learning).Hence,theycanbeusedonanydatasetotherthanthe giveafalsesenseofsecurity:Circumventingdefensestoadversarialexamples.
InInternationalconferenceonmachinelearning.PMLR,274â€“283.
onestheyweretrainedon.However,wearguethatthisflexibility [3] AnasAwadalla,IrenaGao,JoshGardner,JackHessel,YusufHanafy,Wanrong
comeswithanincreasedvulnerabilitytopixelperturbations,which Zhu,KalyaniMarathe,YonatanBitton,SamirGadre,ShioriSagawa,etal.2023.
Openflamingo:Anopen-sourceframeworkfortraininglargeautoregressive
isevidentfromourexperiments.
vision-languagemodels.arXivpreprintarXiv:2308.01390(2023).
Lastly,apotentialexplanationwhyVAN-base[20]isthemost [4] TaoBai,JinqiLuo,andJunZhao.2021.Inconspicuousadversarialpatchesfor
resilientmodelisbasedonitsuseofDilatedConvolutionalLay- foolingimage-recognitionsystemsonmobiledevices.IEEEInternetofThings
Journal9,12(2021),9515â€“9524.
ers[62].Attacksbasedoncontiguouspixelsmaybethwartedby [5] WielandBrendel,JonasRauber,andMatthiasBethge.2017. Decision-based
expandingthefilterâ€™sreceptivefieldwhenitiswidenedthrough adversarialattacks:Reliableattacksagainstblack-boxmachinelearningmodels.
introducinggapsbetweensuccessiveelementsâ€”themainfeature arXivpreprintarXiv:1712.04248(2017).
[6] TomBBrown,DandelionManÃ©,AurkoRoy,MartÃ­nAbadi,andJustinGilmer.
ofdilatedconvolutions.Asaresult,theSparseAttackappearstobe 2017.Adversarialpatch.arXivpreprintarXiv:1712.09665(2017).
themosteffectiveattackonVAN-base,whiletheContiguousones [7] LiangliangCao,BowenZhang,ChenChen,YinfeiYang,XianzhiDu,Wencong
Zhang,ZhiyunLu,andYantaoZheng.2023. LessisMore:RemovingText-
behavesimilarlytoRandomAttacks.Moreover,therobustnessof
regionsImprovesCLIPTrainingEfficiencyandRobustness. arXivpreprint
theVAN-basemodelsurpassestheResNet-50[22],whichemploys arXiv:2305.05095(2023).
regularconvolutionallayers,providingfurtherevidenceforthe [8] NicholasCarliniandDavidWagner.2017.Towardsevaluatingtherobustness
ofneuralnetworks.In2017ieeesymposiumonsecurityandprivacy(sp).Ieee,
robustnessofdilatedconvolutions. 39â€“57.
[9] Pin-YuChen,HuanZhang,YashSharma,JinfengYi,andCho-JuiHsieh.2017.
Zoo:Zerothorderoptimizationbasedblack-boxattackstodeepneuralnetworks
withouttrainingsubstitutemodels.InProceedingsofthe10thACMworkshopon
artificialintelligenceandsecurity.15â€“26.
7 CONCLUSIONANDFUTUREWORK [10] ZhongzhiChen,GuangLiu,Bo-WenZhang,FulongYe,QinghongYang,and
LedellWu.2022. Altclip:Alteringthelanguageencoderinclipforextended
Ourworkanalyzestherobustnessoffourmultimodalmodelsand
languagecapabilities.arXivpreprintarXiv:2211.06679(2022).
twostate-of-the-artunimodalDNNsagainstSparseandContigu- [11] AranChindaudom,PrarinyaSiritanawan,KarinSumongkayothin,andKazunori
ousadversarialexamplesdefinedbytheğ¿0-norminablack-box Kotani.2020.AdversarialQR:AnadversarialpatchinQRcodeformat.In2020
Joint9thInternationalConferenceonInformatics,Electronics&Vision(ICIEV)
attackscenario.Forbothtypesofattack(targetedanduntargeted)
and20204thInternationalConferenceonImaging,Vision&PatternRecognition
andallmodels,wehaveatleasttwoevolutionaryattacksthatare (icIVPR).IEEE,1â€“6.
moreeffectivethantherestâ€”allmultimodalmodelsthatuseaViT [12] AranChindaudom,PrarinyaSiritanawan,KarinSumongkayothin,andKazunori
Kotani.2022.SurreptitiousAdversarialExamplesthroughFunctioningQRCode.
asanImageEncoderaremostvulnerabletotheSparseAttack.In JournalofImaging8,5(2022),122.
contrast,intheCNN-basedmultimodalmodel(ALIGN),themost [13] AlexisConneau,KartikayKhandelwal,NamanGoyal,VishravChaudhary,Guil-
laumeWenzek,FranciscoGuzmÃ¡n,EdouardGrave,MyleOtt,LukeZettlemoyer,
effectiveattackisrepresentedbyacontiguouspixelperturbation
andVeselinStoyanov.2019.Unsupervisedcross-lingualrepresentationlearning
intheformofaPatch.Thisattackprovetobesopowerfulagainst atscale.arXivpreprintarXiv:1911.02116(2019).
ALIGNthatwithanincreasedpatchdimensionof4x4(lessthan [14] UgurDemirandGozdeUnal.2018.Patch-basedimageinpaintingwithgenerative
adversarialnetworks.arXivpreprintarXiv:1803.07422(2018).
0.02%oftheimagearea),inanon-targetedscenario,weachieveda [15] AlexeyDosovitskiy,LucasBeyer,AlexanderKolesnikov,DirkWeissenborn,Xi-
99%SR.Furthermore,basedontheoverallSR,werankthemost aohuaZhai,ThomasUnterthiner,MostafaDehghani,MatthiasMinderer,Georg
securemodelsasfollows:VAN-base,ResNet-50,AltCLIP,GroupViT, Heigold,SylvainGelly,etal.2020.Animageisworth16x16words:Transformers
forimagerecognitionatscale.arXivpreprintarXiv:2010.11929(2020).
CLIP-B/32,andALIGN.Ourresultsalsopointtowardsdifferent [16] StanislavFort.2021. Pixelsstillbeattext:attackingtheOpenAICLIPmodel
characteristicsofAImodelarchitectures(e.g.,tokenization,convo- withtextpatchesandadversarialpixelperturbations.StanislavFort[Internet]5
(2021).
lutions,dilatedconvolutions)thatmayberesponsiblefordifferent
[17] MatthiasFreiberger,PeterKun,AndersSundnesLÃ¸vlie,andSebastianRisi.2023.
levelsofrobustnessagainstourattacks.Whencontrastingthere- CLIPMasterPrints:FoolingContrastiveLanguage-ImagePre-trainingUsingLa-
sultsformultimodalandunimodalmodels,weobservethatthere tentVariableEvolution.arXivpreprintarXiv:2307.03798(2023).
[18] ArkaGhosh,SankhaSubhraMullick,ShounakDatta,SwagatamDas,AsitKr
maybeanessentialtrade-offbetweentherobustnessofthemodel Das,andRammohanMallipeddi.2022.Ablack-boxadversarialattackstrategy
anditsadaptabilitytobeusedindiversetasks(i.e.,zero-shotca- withadjustablesparsityandgeneralizabilityfordeepimageclassifiers.Pattern
pability).Bothoftheseaspectsshouldbefurtherinvestigatedina Recognition122(2022),108279.
[19] IanJGoodfellow,JonathonShlens,andChristianSzegedy.2014.Explainingand
follow-upstudy. harnessingadversarialexamples.arXivpreprintarXiv:1412.6572(2014).
9Cristian-AlexandruBotocan,RaphaelMeier,andLjiljanaDolamic
[20] Meng-HaoGuo,Cheng-ZeLu,Zheng-NingLiu,Ming-MingCheng,andShi-Min [44] ChristianSchlarmannandMatthiasHein.2023.Ontheadversarialrobustness
Hu.2023. Visualattentionnetwork. ComputationalVisualMedia9,4(2023), ofmulti-modalfoundationmodels.InProceedingsoftheIEEE/CVFInternational
733â€“752. ConferenceonComputerVision.3677â€“3685.
[21] LukasHaas,SilasAlberti,andMichalSkreta.2023.LearningGeneralizedZero- [45] SciPyContributors.Accessed:2024.scipy.optimize.differential_evolution.
ShotLearnersforOpen-DomainImageGeolocalization.arXiv:2302.00275[cs.CV] [46] KarenSimonyanandAndrewZisserman.2014. Verydeepconvolutionalnet-
[22] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016.Deepresidual worksforlarge-scaleimagerecognition.arXivpreprintarXiv:1409.1556(2014).
learningforimagerecognition.InProceedingsoftheIEEEconferenceoncomputer [47] RainerStornandKennethPrice.1997. Differentialevolutionâ€“asimpleand
visionandpatternrecognition.770â€“778. efficientheuristicforglobaloptimizationovercontinuousspaces. Journalof
[23] ShengshanHu,YechaoZhang,XiaogengLiu,LeoYuZhang,MinghuiLi,andHai globaloptimization11(1997),341â€“359.
Jin.2021.Advhash:Set-to-settargetedattackondeephashingwithonesingle [48] JiaweiSu,DaniloVasconcellosVargas,andKouichiSakurai.2019. Onepixel
adversarialpatch.InProceedingsofthe29thACMInternationalConferenceon attackforfoolingdeepneuralnetworks. IEEETransactionsonEvolutionary
Multimedia.2335â€“2343. Computation23,5(2019),828â€“841.
[24] Yu-Chih-TuanHu,Bo-HanKung,DanielStanleyTan,Jun-ChengChen,Kai- [49] ChristianSzegedy,WeiLiu,YangqingJia,PierreSermanet,ScottReed,Dragomir
LungHua,andWen-HuangCheng.2021.Naturalisticphysicaladversarialpatch Anguelov,DumitruErhan,VincentVanhoucke,andAndrewRabinovich.2015.
forobjectdetectors.InProceedingsoftheIEEE/CVFInternationalConferenceon Goingdeeperwithconvolutions.InProceedingsoftheIEEEconferenceoncomputer
ComputerVision.7848â€“7857. visionandpatternrecognition.1â€“9.
[25] MalharJere,LorisRossi,BrilandHitaj,GabrielaCiocarlie,GiacomoBoracchi,and [50] ChristianSzegedy,VincentVanhoucke,SergeyIoffe,JonShlens,andZbigniew
FarinazKoushanfar.2019.Scratchthat!Anevolution-basedadversarialattack Wojna.2016. Rethinkingtheinceptionarchitectureforcomputervision.In
againstneuralnetworks.arXivpreprintarXiv:1912.02316(2019). ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.
[26] ChaoJia,YinfeiYang,YeXia,Yi-TingChen,ZaranaParekh,HieuPham,QuocLe, 2818â€“2826.
Yun-HsuanSung,ZhenLi,andTomDuerig.2021.Scalingupvisualandvision- [51] ChristianSzegedy,WojciechZaremba,IlyaSutskever,JoanBruna,Dumitru
languagerepresentationlearningwithnoisytextsupervision.InInternational Erhan,IanGoodfellow,andRobFergus.2013.Intriguingpropertiesofneural
conferenceonmachinelearning.PMLR,4904â€“4916. networks.arXivpreprintarXiv:1312.6199(2013).
[27] DannyKarmon,DanielZoran,andYoavGoldberg.2018.Lavan:Localizedand [52] MingxingTanandQuocLe.2021. Efficientnetv2:Smallermodelsandfaster
visibleadversarialnoise.InInternationalConferenceonMachineLearning.PMLR, training.InInternationalconferenceonmachinelearning.PMLR,10096â€“10106.
2507â€“2515. [53] GuijianTang,TingsongJiang,WeienZhou,ChaoLi,WenYao,andYongZhao.
[28] AlexKrizhevsky,IlyaSutskever,andGeoffreyEHinton.2012.Imagenetclassifi- 2023.Adversarialpatchattacksagainstaerialimageryobjectdetectors.Neuro-
cationwithdeepconvolutionalneuralnetworks.Advancesinneuralinformation computing537(2023),128â€“140.
processingsystems25(2012). [54] GeminiTeam,RohanAnil,SebastianBorgeaud,YonghuiWu,Jean-Baptiste
[29] AlexeyKurakin,IanGoodfellow,andSamyBengio.2016.Adversarialmachine Alayrac,JiahuiYu,RaduSoricut,JohanSchalkwyk,AndrewMDai,AnjaHauth,
learningatscale.arXivpreprintarXiv:1611.01236(2016). etal.2023.Gemini:afamilyofhighlycapablemultimodalmodels.arXivpreprint
[30] HugoLaurenÃ§on,LucileSaulnier,LÃ©oTronchon,StasBekman,Amanpreet arXiv:2312.11805(2023).
Singh,AntonLozhkov,ThomasWang,SiddharthKaramcheti,AlexanderM [55] Chun-ChenTu,PaishunTing,Pin-YuChen,SijiaLiu,HuanZhang,JinfengYi,
Rush,DouweKiela,etal.2023.Obelisc:Anopenweb-scalefiltereddatasetof Cho-JuiHsieh,andShin-MingCheng.2019. Autozoom:Autoencoder-based
interleavedimage-textdocuments.arXivpreprintarXiv:2306.16527(2023). zerothorderoptimizationmethodforattackingblack-boxneuralnetworks.In
[31] JunnanLi,DongxuLi,CaimingXiong,andStevenHoi.2022.Blip:Bootstrapping ProceedingsoftheAAAIConferenceonArtificialIntelligence,Vol.33.742â€“749.
language-imagepre-trainingforunifiedvision-languageunderstandingandgen- [56] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,
eration.InInternationalConferenceonMachineLearning.PMLR,12888â€“12900. AidanNGomez,ÅukaszKaiser,andIlliaPolosukhin.2017. Attentionisall
[32] AishanLiu,XianglongLiu,JiaxinFan,YuqingMa,AnlanZhang,HuiyuanXie, youneed.Advancesinneuralinformationprocessingsystems30(2017).
andDachengTao.2019. Perceptual-sensitiveganforgeneratingadversarial [57] XingxingWei,YingGuo,JieYu,andBoZhang.2022.Simultaneouslyoptimiz-
patches.InProceedingsoftheAAAIconferenceonartificialintelligence,Vol.33. ingperturbationsandpositionsforblack-boxadversarialpatchattacks.IEEE
1028â€“1035. transactionsonpatternanalysisandmachineintelligence(2022).
[33] AleksanderMadry,AleksandarMakelov,LudwigSchmidt,DimitrisTsipras,and [58] PhoenixNealeWilliamsandKeLi.2023.Black-BoxSparseAdversarialAttack
AdrianVladu.2017. Towardsdeeplearningmodelsresistanttoadversarial viaMulti-ObjectiveOptimisation.InProceedingsoftheIEEE/CVFConferenceon
attacks.arXivpreprintarXiv:1706.06083(2017). ComputerVisionandPatternRecognition.12291â€“12301.
[34] ChengzhiMao,ScottGeng,JunfengYang,XinWang,andCarlVondrick.2022. [59] ChenwangWu,WenjianLuo,NanZhou,PeilanXu,andTaoZhu.2021.Genetic
Understandingzero-shotadversarialrobustnessforlarge-scalemodels.arXiv algorithmwithmultiplefitnessfunctionsforgeneratingadversarialexamples.
preprintarXiv:2212.07016(2022). In2021IEEECongressonEvolutionaryComputation(CEC).IEEE,1792â€“1799.
[35] Seyed-MohsenMoosavi-Dezfooli,AlhusseinFawzi,andPascalFrossard.2016. [60] JiaruiXu,ShaliniDeMello,SifeiLiu,WonminByeon,ThomasBreuel,JanKautz,
Deepfool:asimpleandaccuratemethodtofooldeepneuralnetworks.InProceed- andXiaolongWang.2022.Groupvit:Semanticsegmentationemergesfromtext
ingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2574â€“2582. supervision.InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
[36] WonhongNamandHyunyoungKil.2023.AESOP:AdjustableExhaustiveSearch PatternRecognition.18134â€“18144.
forOne-PixelAttacksinDeepNeuralNetworks.AppliedSciences13,8(2023), [61] KarrenYang,Wan-YiLin,ManashBarman,FilipeCondessa,andZicoKolter.2021.
5092. Defendingmultimodalfusionmodelsagainstsingle-sourceadversaries.InPro-
[37] NicolasPapernot,PatrickMcDaniel,SomeshJha,MattFredrikson,ZBerkayCelik, ceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.
andAnanthramSwami.2016.Thelimitationsofdeeplearninginadversarial 3340â€“3349.
settings.In2016IEEEEuropeansymposiumonsecurityandprivacy(EuroS&P). [62] FisherYuandVladlenKoltun.2015.Multi-scalecontextaggregationbydilated
IEEE,372â€“387. convolutions.arXivpreprintarXiv:1511.07122(2015).
[38] SvetlanaPavlitskaya,Bianca-MarinaCodÄƒu,andJMariusZÃ¶llner.2022.Feasibil- [63] YiwuZhong,JianweiYang,PengchuanZhang,ChunyuanLi,NoelCodella,Liu-
ityofinconspicuousGAN-generatedadversarialpatchesagainstobjectdetection. nianHaroldLi,LuoweiZhou,XiyangDai,LuYuan,YinLi,etal.2022.Regionclip:
arXivpreprintarXiv:2207.07347(2022). Region-basedlanguage-imagepretraining.InProceedingsoftheIEEE/CVFCon-
[39] ZhiliangPeng,WenhuiWang,LiDong,YaruHao,ShaohanHuang,ShumingMa, ferenceonComputerVisionandPatternRecognition.16793â€“16803.
andFuruWei.2023.Kosmos-2:GroundingMultimodalLargeLanguageModels [64] XingyuZhou,ZhisongPan,YexinDuan,JinZhang,andShuaihuiWang.2021.A
totheWorld.arXivpreprintarXiv:2306.14824(2023). dataindependentapproachtogenerateadversarialpatches.MachineVisionand
[40] Hieu Pham, Zihang Dai, Golnaz Ghiasi, Kenji Kawaguchi, Hanxiao Liu, Applications32(2021),1â€“9.
AdamsWeiYu,JiahuiYu,Yi-TingChen,Minh-ThangLuong,YonghuiWu,etal. [65] ZiqiZhou,ShengshanHu,MinghuiLi,HangtaoZhang,YechaoZhang,andHai
2023. Combinedscalingforzero-shottransferlearning. Neurocomputing555 Jin.2023.Advclip:Downstream-agnosticadversarialexamplesinmultimodal
(2023),126658. contrastivelearning.InProceedingsofthe31stACMInternationalConferenceon
[41] HaoQiu,LeonardoLucioCustode,andGiovanniIacca.2021. Black-boxad- Multimedia.6311â€“6320.
versarialattacksusingevolutionstrategies.InProceedingsoftheGeneticand
EvolutionaryComputationConferenceCompanion.1827â€“1833.
[42] JielinQiu,YiZhu,XingjianShi,FlorianWenzel,ZhiqiangTang,DingZhao,
BoLi,andMuLi.2022. AreMultimodalModelsRobusttoImageandText
Perturbations?arXivpreprintarXiv:2212.08044(2022).
[43] AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,Sand-
hiniAgarwal,GirishSastry,AmandaAskell,PamelaMishkin,JackClark,etal.
2021.Learningtransferablevisualmodelsfromnaturallanguagesupervision.In
Internationalconferenceonmachinelearning.PMLR,8748â€“8763.
10SparsevsContiguous
A EXPONENTIALSTRATEGYIN Algorithm1ExponentialStrategy[45]
DIFFERENTIALEVOLUTION 1: functionCrossoverExp(ğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ ğ‘œğ‘™ğ‘‘,ğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ ğ‘ğ‘ğ‘›ğ‘‘,ğ‘ğ‘Ÿğ‘œğ‘ ğ‘ ğ‘œğ‘£ğ‘’ğ‘Ÿ ğ‘Ÿğ‘ğ‘¡ğ‘’)
Algorithm1wasusedfortheCrossoveroperation-Exponential 2: ğ‘ğ‘–ğ‘” ğ‘Ÿ â†randomindexvalueoftheğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ ğ‘ğ‘ğ‘›ğ‘‘
StrategyintheDifferentialEvolution.Theideaofthisalgorithmis 3: ğ‘– â†0
torecombinetheagentsbasedonsomeğ‘ğ‘Ÿğ‘œğ‘ ğ‘ ğ‘œğ‘£ğ‘’ğ‘Ÿ ğ‘Ÿğ‘ğ‘¡ğ‘’â€”howmuch 4: whileğ‘– <sizeofğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ ğ‘ğ‘ğ‘›ğ‘‘ do
informationfromtheoldagents(ğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ )shouldalsobepreserved 5: ğ‘Ÿ â†randomnumberbetween0and1
ğ‘œğ‘™ğ‘‘
in the new ones (ğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ ğ‘ğ‘ğ‘›ğ‘‘). Thus, we directly modify the new 6: ifğ‘ğ‘Ÿğ‘œğ‘ ğ‘ ğ‘œğ‘£ğ‘’ğ‘Ÿ ğ‘Ÿğ‘ğ‘¡ğ‘’ <ğ‘Ÿ then
agentsintheğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ vectorandreturnitforfurtherprocess- 7: break
ğ‘ğ‘ğ‘›ğ‘‘
ing.ThiscodewasadaptedfromtheDifferential Evolution 8: ğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ ğ‘ğ‘ğ‘›ğ‘‘[ğ‘ğ‘–ğ‘” ğ‘Ÿ] â†ğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ ğ‘œğ‘™ğ‘‘[ğ‘ğ‘–ğ‘” ğ‘Ÿ]
implementedinScipy[45]. 9: ğ‘ğ‘–ğ‘” ğ‘Ÿ â†(ğ‘ğ‘–ğ‘” ğ‘Ÿ +1) modğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ ğ‘ğ‘ğ‘›ğ‘‘_ğ‘ ğ‘–ğ‘§ğ‘’
10: ğ‘– â†ğ‘–+1
11: returnğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ ğ‘ğ‘ğ‘›ğ‘‘
11