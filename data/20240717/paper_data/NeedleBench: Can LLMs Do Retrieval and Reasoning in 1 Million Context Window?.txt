TechnicalReport
NeedleBench: Can LLMs Do Retrieval and Reasoning in 1
Million Context Window?
MoLi1,2,SongyangZhang1‚Ä°,YunxinLiu2,KaiChen1‚Ä°
1ShanghaiAILaboratory2TsinghuaUniversity
{limo,zhangsongyang}@pjlab.org.cn
Abstract
Inevaluatingthelong-contextcapabilitiesoflargelanguagemodels(LLMs),
identifying content relevant to a user‚Äôs query from original long docu-
ments is a crucial prerequisite for any LLM to answer questions based
on long text. We present NeedleBench, a framework consisting of a se-
riesofprogressivelymorechallengingtasksforassessingbilinguallong-
contextcapabilities,spanningmultiplelengthintervals(4k,8k,32k,128k,
200k,1000k,andbeyond)anddifferentdepthranges,allowingthestrate-
gicinsertionofcriticaldatapointsindifferenttextdepthzonestorigor-
ously test the retrieval and reasoning capabilities of models in diverse
contexts. WeusetheNeedleBenchframeworktoassesshowwelltheleading
open-source models can identify key information relevant to the ques-
tionandapplythatinformationtoreasoninginbilinguallongtexts. Fur-
thermore,weproposetheAncestralTraceChallenge(ATC)tomimicthe
complexity of logical reasoning challenges that are likely to be present
inreal-worldlong-contexttasks,providingasimplemethodforevaluat-
ing LLMs in dealing with complex long-context situations. Our results
suggestthatcurrentLLMshavesignificantroomforimprovementinprac-
tical long-context applications, as they struggle with the complexity of
logical reasoning challenges that are likely to be present in real-world
long-contexttasks. AllcodesandresourcesareavailableatOpenCompass:
https://github.com/open-compass/opencompass.
1 Introduction
ThecapabilityofLLMstoprocesslongtextsisparticularlycrucialacrossvarioussituations.
LLMscanrapidlyidentifyandsummarizerelevantinformationwithinlengthydocuments,
makingtheminvaluableforlegaldocumentretrieval,academicresearch,andaggregating
businessintelligence,amongotherapplications.
Modern LLMs have recently been developed to support longer context windows. For
example,GPT-4Turbo(OpenAI,2023)offerslong-contextcapabilitiesupto128Ktokens.
Similarly,Claude2.1(Anthropic,2024a)hasbeenenhancedtomanagecontextsupto200K
tokens,withtheClaude3series(Anthropic,2024b)beingspecificallyengineeredtodigest
inputssurpassing1milliontokens. Furthermore,Gemini1.5supportscontextwindowsof
millionsoftokens(GeminiTeam,2024). Moreover,therecentopen-sourcemodels,GLM4-
9B-ChatandInternLM2.5-7B-Chatalsosupportthe1millioncontextwindow. Asmodels
accommodatelongertextlengths,verifyingtheircomprehensionofdetailswithinthetext
becomesincreasinglyessential.
ConsideringthecriticalroleofLLMsinhandlinglongtexts,numerousapproacheshave
beensuggestedtoevaluatetheirlong-contextcapabilities. Existingdatasets,suchasthe
LongBenchdataset(Baietal.,2023),provideabilingual(ChineseandEnglish)benchmark
forlongtextcomprehension,featuringtaskswithlengthsgenerallyrangingfrom5kto15k
tokens. However,accuratelyassessingtheperformanceoflong-contextLLMs,especiallyat
the1Mtokenlevel,continuestobeasignificantchallenge.
‚Ä°Correspondingauthor.
1
4202
luJ
61
]LC.sc[
1v36911.7042:viXraTechnicalReport
Ancestral Trace Challenge (ATC) Results
100
GPT4-Turbo
Claude-3-Opus
80 GLM-4
60
40
20
0920 / 2 1134 / 17 1347 / 32 1561 / 47 1775 / 62 1988 / 77
Context Length(tokens) / Needle Count
Figure1: OurATCtest,evenwithamodestcontextlengthof2K,revealssurprisinglimita-
tionsoftheseleadingmodelsinreal-worldcomplexlong-contextquestions.
Therearesomeinitialattemptsinthisdirection,Mohtashami&Jaggi(2023)introducesthe
passkeytestingapproach,whichembedskeyinformationpasskeysinrepetitivelysimilar
textsandqueriesforthisinformationattheend,toevaluatethebasicinformationextraction
capabilityoftheLLaMA-7Bmodelattextlengthsof32K.InfiniteBenchbyZhangetal.(2023)
extendsthepasskeymethodtolengthsbeyond100K,insertingpasskeysatvariousdepths
withinlongtexts. Kamradt(2023)developstheNeedleInAHaystack(NIAH)test,which
usesamorediversesetofnon-repetitivepersonalessaysasfillerinformationunrelatedto
thepasskeys. Thistestfurtherextendsthecontextwindowto200Kandperformsstresstests
ontheClaude2.1andGPT-4Turbo1models.TheresultsfromKamradt(2023)andAnthropic
(2024b)indicatethatleadingmodelsaregenerallycapableofpassingtheNIAHtestwith
excellentperformance.
Doespassingthe‚Äùneedle-in-a-haystack‚Äùtest‚Äîextractingkeyinfofromlengthytexts‚Äîreallyindicate
that LLMs can handle complex real-world long context problems? Typically, real-world tasks
require models to retrieve and integrate multiple pieces of dispersed, question-related
information rather than just a single piece. For instance, in legal case analysis, a model
mustextractvariousrelevantfactsandlegalprovisionsfromacasefileandsynthesizethis
informationtoanswerspecificlegalquestions. Similarly,inbusinessintelligenceanalysis,
amodelmayneedtoaggregateinformationonmarkettrends,competitorstrategies,and
consumerbehaviorsfrommultiplereportstoprovideacomprehensivemarketanalysis.
Thisrequiresmodelsthatcanidentifymultiplekeyinformationpointsandintegrateawide
rangeofrelevantcontentwithinthetext,offeringin-depthandaccurateanalyses.
Therefore,improvingthelong-contextabilityofLLMsforrealisticapplicationsnotonly
requirestheaccurateinformationretrievalbutalsothestrongreasoningcapabilities. To
address the limitations of existing long-context information extraction evaluation meth-
ods and their misalignment with real-world application scenarios, we introduce the
NeedleBench dataset. NeedleBench comprises a series of advanced long-context informa-
tion capability evaluation methods, aimed at providing a comprehensive and targeted
assessmentofmodels‚Äôabilitiestoextractandanalyzeinformationwithinthecontextoflong
texts. Furthermore,wedeveloptheAncestralTraceChallenge(ATC)testasthesimplified
proxyformeasuringmulti-steplogicalreasoning. Ourfindingsdemonstratethatcurrent
LLMsstruggletohandlereasoningtaskswithcomplexlogicalrelationships,evenwithtexts
shorterthan2Ktokens(seeFigure1). Ourmajorcontributionsareasfollows:
‚Ä¢ WeintroduceNeedleBench,acustomizabledatasetframeworkthatincludestasksfor
evaluatingthebilinguallong-contextcapabilitiesofLLMsacrossmultiplelength
intervals(4k,8k,32k,128k,200k,1000kandbeyond)andvarioustextdepthranges,
allowingthestrategicinsertionofcriticaldatapointsindifferenttextdepthzones
1GPT-41106-previewversion
2
egarevA
ECTechnicalReport
torigorouslytestbothretrievalandreasoningcapabilitiesofmodelsinadiverse
context.
‚Ä¢ WeproposetheATCtosimulatecomplexlong-contexttasksinreal-worldscenarios,
providingasimplemethodforevaluatingLLMsincomplicatedlong-contextsitu-
ations. ThroughtheexperimentalresultsoftheATC,wediscoverthatallcurrent
LLMshavesignificantroomforimprovementinpracticallong-contextapplications,
strugglingwiththecomplexityofreal-worldlong-contexttasks.
‚Ä¢ We conduct a fine-grained evaluation and analysis of the performance of main-
stream models in identifying key question-relevant information and reasoning.
Additionally,allreproduciblescripts,code,anddatasetsareprovidedinOpenCom-
passContributors(2023).
2 TasksandDatasets
Single-Needle Retrieval(S-RT) Multi-NeedleReasoning(M-RS) Ancestral Trace Challenge(ATC)
Insertneedleatcertaindepth Michael Roberta
Doc1 Inserting needles, shifting Scott Hill
Hidden on Emerald Island is across depths at a fixed
the legendary Stardust Shard. distance
Doc2 James John
¬∑¬∑¬∑{ Haystack Smith Johnson
withneedle }¬∑¬∑¬∑¬∑¬∑¬∑
T la er ng ge tt h Doc3 H Qu um era yn : W i Is s lh h aa i ndt dd l ?ee ng e on nd Ear my e i rt ae ldm T k ornh aoe nw gL n eo a sv se Lf 'o ar m T oh ur re de e O s r ta rn og ise s is WRo ilb lie ar mt s BL rin od wa n
Doc4
The legendary item Elizabet William
Doc Hn aystack ResL pL oM nse h E t Shi m td e aed rlre dean g ul d e so t nn I d Sst al hh a r ae yn r d d i .s T i Ps rh oae k s oL a fo t iv i ere vi cf ao lr o T ph er re a e b O y r Sa en rg ge es i Hill‚Äòs fathh e rRJ . eo Epn ar ce e hs s e nn et es d M le i sc ih ga ne ifl iS eJ c so o an t te k is i ns s R ho ipb erta
Construction between two individuals.
Sergei Prokofiev died on 5 Question:{Shuffled Kinship Needles
Multi-Needle Retrieval(M-RT) March 1953. }¬∑¬∑¬∑¬∑¬∑¬∑Who is the eldest relative that ' Elizabeth
Jones' can trace back to in the context?
A.Linda Brown B. Roberta Hill
C.James Smith D.Michael Scott
Doc1 Doc2 Doc3 Doc4 Docn
¬∑¬∑¬∑{ Hayst }a ¬∑c ¬∑¬∑k ¬∑¬∑¬∑withneedles DifferentTopologiesofATC
When did the Soviet
¬∑¬∑¬∑{ Haystackwithneedles }¬∑¬∑¬∑¬∑¬∑¬∑ composer of French language
H Qu um era yn : W W ‚Ä¶(h h ada ot di s il te itg ohe nen a ld r u qa l ur ey er s i tt o ie f om nt s hi s e n oh P ti od l sad hre oin s w o s nn t )a E rm se yr sa tl ed m I ?s land? H Qu um era yn : t oi rt ale ng L e' sa m dio eu ?r des trois Chain
The legendary item hidden on the Emerald Island is The Soviet composer of the Tree
Eternal Flame. opera titled "L'amour des trois
ResL pL oM nse T t ‚Ä¶hh (aee d Sr du t itale ir or s n .o af l at nh se w P eo rl sa r ni os t s st har o ws ny )stem is Voyager of ResL pL oM nse: o dr iea dn g oe ns , 5" MSe ar rg ce hi 1P 9r 5o 3ko .fiev, Graph
Figure2: NeedleBenchFramework
Inordertoconstructadatasetcapableofcomprehensivelyevaluatingmodels‚Äôcapabilities
inlong-contextinformationextractionandreasoning,wedesignaseriesofprogressively
morechallengingtestschemes. WeshowthecompositionoftheNeedlebenchframework
inFigure2. Specifically,wedividetheoveralltaskintothreesubtasks: ‚ÄùSingleRetrieval
Task(S-RT)‚Äù(whereasinglepieceofinformationisinsertedatonedepth),‚ÄùMulti-Retrieval
Task(M-RT)‚Äù, and‚ÄùMulti-ReasoningTask(M-RS)‚Äù. Eachsubtaskincludesthedesignof
thekeyinformation(needledesign)andtheunrelatedtext(haystackdesign). Inaddition,
wedesigntheAncestralTraceChallenge(ATC)totesttheabilityoftheLLMstohandle
multi-steplogicalchallengesthatarelikelypresentinrealworldlong-contextscenarios.The
instantiationofeachtaskisdetailedinAppendixC,whereactualexamplesofeachtaskare
provided.
2.1 NeedleBench Tasks
WefirstintroducetheseveraldifferentsubtaskswithinNeedleBench.
‚Ä¢Single-NeedleRetrievalTask(S-RT):TestsLLMs‚Äôabilitytorecallasinglekeyinformation
insertedatvariouspositionsinalongtext,highlightingtheirprecisioninnavigatingand
recallingsingledetailwithinextensivetexts.
3TechnicalReport
‚Ä¢Multi-NeedleRetrievalTask(M-RT):ExploresLLMs‚Äôabilitytoretrievemultiplepieces
ofrelatedinformationscatteredacrossalengthytext,simulatingcomplexreal-worldqueries
thatrequireextractingseveraldatapointsfromcomprehensivedocuments.
‚Ä¢Multi-NeedleReasoningTask(M-RS):EvaluatesLLMs‚Äôabilityforcomplexreasoning
byextractingmultiplepiecesofinformationfromlongtextsandusingthemtologically
answerquestionsthatdemandanintegratedunderstandingandreasoningofvarioustext
segments.
2.2 AncestralTraceChallenge(ATC)
Inextremescenarios,weenvisionmodelscapableofrecallingandanalyticallyunderstand-
ingeverydetailofeverysentencewithintheinputlongtextondemand. Thus,weintroduce
theAncestralTraceChallenge(ATC)tosimulatecomplexlong-contexttasksinreal-world
scenarios.
InATCexperiments,weconstructtheproblemusingaseriesofsimplefirst-orderlogical
inferences,forminganinformationchainthatLLMsneedtofullyunderstandinorderto
answerthequestion. Forgettinganykeyinformationinthelongcontextdirectlyresults
intheinabilityoftheLLMstoprovidethecorrectanswer.LLMswillbeaskedtochoose
one correct answer from the four given options, This method can be expanded to more
challenginglogicalrelationshipsinthestudybyBestaetal.(2024)
Inpracticalscenarios,longertextlengthsinevitablymeanthatLLMsneedtounderstand
morecomplexlayersoflogicalrelationships. UsingtheATCtest,wecaneasilystresstest
themulti-stepreasoningcapabilitiesofLLMs. Thismethodologyisscalableandcanbe
extendedtoextensivecontextlengths.WhiletheNIAHtestaimtostresstesttheinformation
retrievalcapabilitiesofLLMswithinlongtexts,theATCtestspecificallyaimstostresstest
theirreasoningabilitiesinsimilarlong-contextscenarios. ActualexamplesofATCtestcan
befoundintheAppendix,Figures21and22.
2.3 DatasetConstruction
2.3.1 NeedleDesign
Distribution of Reasoning Steps
Histogram
2000
1670
1500
1000
520
500
133
56
0
1 2 3 4 5 or more
Number of Reasoning Steps
Figure3: DistributionofReasoningStepsinMulti-NeedleReasoningTask
To prevent the model‚Äôs inherent knowledge from interfering with its ability to retrieve
information,wedeliberatelydesigntheneedlesinboththeSingle-NeedleRetrieval(S-RT)
andMulti-NeedleRetrievaltaskstobeabstractandnonexistentintherealworld. Models
arerequiredtoanswerquestionsbasedsolelyonthekeyinformationprovidedduringthe
test.
For the Multi-Needle Reasoning task, we construct the needle corpus utilizing the R4C
dataset(Inoueetal.,2019),anenhancementoftheHotpotQAdataset(Yangetal.,2018)that
incorporates ‚ÄùDerivation‚Äù information detailing each reasoning step needed to answer
4
tnuoCTechnicalReport
questions,whilealsoaddressingtheissueofunclearpronounspresentinHotpotQA.The
corpusisthentranslatedintoChinesetoensureahigh-qualitydatasetforevaluatingthe
bilingual reasoning capabilities of the models.As illustrated in Figure 3, the majority of
reasoningquestionsinvolvetwoorthreesteps,withfewerquestionsrequiringfourormore
steps.
2.3.2 HaystackDesign
WefollowthemethoddescribedinKamradt(2023),usingthePaulGrahamEssaysdatasetto
extendtheprompttothetargetlength.
InthedesignoftheChineseHaystack,weutilizetheChineseDomainModelingEvaldataset
releasedbyWeietal.(2023)toensurethediversityandqualityofChinesetextsources. This
datasetcoversawiderangeoftopicsfromfinancetotechnology,providinghigh-quality,
up-to-dateChinesearticlesandastablebenchmarkforevaluatingtheabilityofdifferent
modelstohandledomain-specificlongtexts.
3 Experiments
Weprimarilyevaluatetheperformanceofmainstreamopen-sourceLLMsonNeedleBenchat
varioustokenlengthsof4K,8K,32K,and200Kduetothesignificanttokenconsumption
involved.FortheATCexperiment,weexpandourevaluationtoincludeleadingAPImodels,
suchasGPT-4TurboandClaude-3-Opus,andperformmultiplelogicalstresstestsacross
bothopen-sourceandAPImodels.ThecompletelistofLLMsevaluatedinourresearchis
detailedintheTable1. Detailedexperimentssettingsforeachtaskparametercanbefound
intheTable7.
Series Models
Claude Claude-3-Opus
OpenAI GPT4-Turbo
ZhipuAI GLM4,GLM4-9B-Chat-1M,ChatGLM3-6B,ChatGLM3-6B-32K
LLaMA-2 LLaMA-2-7B,LLaMA-2-13B,LLaMA-2-70B
Baichuan2 Baichuan2-7B,Baichuan2-13B
Gemma Gemma2B,Gemma7B
Yi Yi-6B
OrionStarAI Orion-14B-LongChat,OrionStar-Yi-34B
DeepSeek DeepSeek-67B
WizardLM WizardLM-70B
Qwen Qwen-7B,Qwen-14B,Qwen-72B,Qwen-72B-vLLM,Qwen-1.5-
0.5B,Qwen-1.5-1.8B,Qwen-1.5-4B,Qwen-1.5-14B-vLLM,Qwen-
1.5-72B-vLLM
InternLM InternLM-7B, InternLM2-7B, InternLM2-20B, InternLM2-7B-
200K,InternLM2-20B-200K,InternLM2.5-7B-Chat-1M
Zephyr Zephyr-7BBeta
Mistral Mistral-7BInstructv0.2,Mixtral-8x7BInstructv0.1
Table1: EvaluatedLLMs. The‚Äù-200K‚Äùsuffixindicatesmodelsconfiguredforupto200,000
context token length, deployed with LMDeploy(Contributors, 2023). ‚ÄùvLLM‚Äù denotes
deploymentviavLLM(Kwonetal.,2023).
3.1 PerformanceofNeedleBenchTasks
ExperimentalSetting Weusetherecallaccuracyofneedlesplacedatdifferentpositions
as a metric to evaluate the performance of the models. By sequentially averaging the
performanceacrossdatasetsofdifferentlengthsanddepths,weobtaintheperformance
of the models on each task within NeedleBench. Further averaging of the scores from
differenttasksprovidedanoverallscore,ensuringabalancedrepresentationofeachtask‚Äôs
5TechnicalReport
contribution to the overall score. To ensure the stability of our results, we ran multiple
iterationsofeachtest. Thenumberoftokensiscalculateduniformlyusingthetokenizer
fromGPT-42. Inaddition,weintroduceddifferentbuffersizetomitigatetheproblemof
significantdifferencesbetweentokenizersofdifferentmodels,whichcouldpreventamodel
fromreceivingthefullprompt. Inourexperiments,weconsistentlypositionthequestion
commandpromptsattheendoftheextendedtexts. Weexamintheimpactofthequestion
prompt‚ÄôsplacementasdetailedinSection4.
To evaluate the similarity between predictions and references under each specific task,
we use the Levenshtein distance, with P and R representing the lists of predictions and
references,respectively,eachoflengthn. ThescoreforeachpairP andR isadjustedfor
i i
thepresenceofcorekeywordswithinP,definedbythesetW foreachR. Apenaltyfactor
i i i
Œ± =0.2isappliedtothescorecalculationforpredictionsmissinganycorekeywordsfrom
R. Theformulaforanindividualscore,Score,isasfollows:
i i
(cid:40) 100 ifP ‚à©W Ã∏= ‚àÖ,
i i
Score i = 100¬∑Œ±¬∑(cid:16) 1‚àí d(Pi,Ri) (cid:17) otherwise,
max(|Pi|,|Ri|)
whered(P,R )istheLevenshteindistancebetweenP andR,and|P|and|R |denotetheir
i i i i i i
lengths. ThefinalscoreistheaverageofScore acrossnrepetitions.
i
Focusingonkeyfindings,wepresentmainresultsfor32Kand200KcontextlengthsinTable
2and3. MorecomprehensiveresultsareavailableintheAppendixB.
Model Single-Retrieval Multi-Retrieval Multi-Reasoning Overall
Chinese English Overall Chinese English Overall Chinese English Overall
ModelswithFewerThan7BParameters
Qwen-1.5-4B 99.80 96.64 98.22 90.68 93.50 92.09 55.79 54.70 55.24 83.49
ChatGLM3-6B-32K 98.43 80.24 89.34 82.50 87.91 85.20 69.86 73.90 71.88 82.86
InternLM2-7B-200K 100.00 100.00 100.00 24.77 58.50 41.64 58.72 89.79 74.25 74.77
Mistral-7BInstructv0.2 79.84 47.92 63.88 79.36 92.05 85.70 49.92 71.86 60.89 69.53
Qwen-1.5-1.8B 71.62 39.44 55.53 37.45 25.64 31.55 46.34 29.42 37.88 43.04
Qwen-7B 56.71 29.47 43.09 22.09 14.86 18.48 35.60 21.62 28.61 31.36
Qwen-1.5-0.5B 40.09 28.99 34.54 5.45 6.18 5.82 24.48 11.04 17.76 20.89
Zephyr-7BBeta 13.73 21.33 17.53 0.23 4.09 2.16 19.80 33.79 26.79 15.70
Modelswith7-20BParameters
Qwen-1.5-14B-vLLM 82.68 88.83 85.75 94.27 96.91 95.59 67.05 66.05 66.55 82.94
Orion-14B-LongChat 99.37 89.40 94.39 88.05 87.36 87.70 64.63 59.42 62.02 82.67
InternLM2-20B-200K 100.00 100.00 100.00 13.86 12.91 13.39 64.15 89.26 76.70 67.03
ModelsLargerThan20BParameters
Mixtral-8x7BInstructv0.1 94.74 93.23 93.99 93.00 99.45 96.23 73.84 78.93 76.39 89.38
Qwen-1.5-72B-vLLM 96.67 63.97 80.32 84.95 82.41 83.68 82.53 85.02 83.77 82.36
Qwen-72B-vLLM 95.59 35.70 65.65 90.77 79.18 84.98 74.82 59.76 67.29 71.94
Table2: MainResultsofNeedleBench32K.
Model Single-Retrieval Multi-Retrieval Multi-Reasoning Overall
Chinese English Overall Chinese English Overall Chinese English Overall
ModelswithFewerThan7BParameters
InternLM2-7B-200K 98.98 98.69 98.83 12.45 25.50 18.98 48.90 63.96 56.43 62.15
Modelswith7-20BParameters
InternLM2-20B-200K 100.00 100.00 100.00 10.68 12.00 11.34 50.72 70.98 60.85 61.66
Orion-14B-LongChat 78.07 32.84 55.45 33.45 30.32 31.89 33.14 27.36 30.25 40.82
Table3: MainResultsofNeedleBench200K.
NeedleBench32Kand200K InternLM2-7B-200KachievesperfectioninSingle-Retrieval,in-
dicatingstrongcapabilitiesinaccuratelyretrievingsingleinformationpoints.Qwen-1.5-72B-
vLLMexcelsinMulti-Reasoningwithitssubstantialparametercountof72B,demonstrating
2https://github.com/openai/tiktoken
6TechnicalReport
itsadvantageinunderstandingandreasoningaboutcomplexrelationshipsbetweenpieces
ofinformation. Mixtral-8x7BInstructv0.1demonstratesformidableoverallperformance,
particularlyinretrievaltasks. Modelswithlargerparametercountstendtoachievehigher
averagescores(seeFigure4).
Model Performance Comparison on Needlebench 32K InternLM2-7B-200K InternLM2-7B-200K
100   6 L Q J O H  5 H W U L H Y D O  2 Y H U D O O  6 F R U H       0 Multi-Retrieval Overall 100
Single-Needle Retrieval
Multi-Needle Retrieval    21 80
Multi-Needle Reasoning >20B Params    42
80 7-20B Params 60
   63
40
   84
60 0-7B Params: Aver. Score     100 20
   N    N    N     N     N     N     N     N 1k4k8k 16k 48k 80k 112k 128k 144k 176k 200k 0
 7 R N H Q  / H Q J W K Token Length
40 InternLM2-20B-200K Orion-14B-LongChat
  0 X O W L  5 H D V R Q L Q J  2 Y H U D O O  6 F R U H         6 L Q J O H  5 H W U L H Y D O  2 Y H U D O O  6 F R U H      
100
      80 20
     
60
     
40
0 Zephyr-7B Be Qt wa en-1.5-0.5B Qwen- Q7 wB en-1. Mi5 s- t1 r. al8 -B 7B I Ins nt t. erv n0. L2 M2-7B C- h2 a0 t0 GK LM3-6B-32K Qwe In nt- e1. r5 n- L4 MB 2-20 OriB- o2 n-0 10 4K B-L Qon wg enC -h 1a .t 5-14B-v QLL weM n-72 QB w- ev nL -L 1.M 5-7 Mi2 xtB r- av l-L 8L xM 7B Inst. v0.1       
   N    N    7  N  R N   H   Q  N   /   H    Q N  J   W K   N     N     N
      
   N    N    7  N  R N   H   Q  N   /   H    Q N  J   W K   N     N     N
020
Figure 4: Model Performance Comparison on Figure5: SelectiveVisualizationResults
NeedleBench32K inNeedleBench200K
As the context length further extends to 200K, fewer open-source LLMs are capable of
supportingsuchextendedcontexts,asillustratedinFigure5. InternLM2-7B-200Kcontinues
to exhibit its consistent strength in Single-Retrieval tasks but experiences a significant
performancedeclineinMulti-Retrievaltests. Uponfurtherinvestigation,itisconfirmed
thatthisisduetoInternLM2overfittingtheSingle-Retrievaltasksinthetrainingcorpus,
leadingittooftenrespondwithonlyoneneedleintheMulti-Retrievaltests.Thisindicates
thatalongercontextlengthmayrequireenhancedcapabilitiesininstructionfollowingand
information retrieval from the model. On the other hand, Orion-14B-LongChat is more
adeptatMulti-Retrievaltasksbutfailstoeffectivelymanagethechallengesofextendedtexts
inSingle-Retrievaltasks,showingadeclinewhenthecontextlengthreachesapproximately
80K.
NeedleBench1000K Inourextendedevaluation,wepushthecontextlengthfurtherto
1000Ktokens. WeevaluatetheInternLM2.5-7B-1MandGLM4-9B-Chat-1Mmodelsunder
thiscontextlength.
First,wepresentthecomprehensiveresultsofthetwomodelsunderNeedleBenchinTable
4. Itcanbeseenthatinthevastmajorityoftasks,theInternLM2.5-7B-Chat-1Mperforms
bettercomparedtotheGLM4-9B-Chat-1M.
Model Single-Retrieval Multi-Retrieval Multi-Reasoning Overall
Chinese English Overall Chinese English Overall Chinese English Overall
ModelsSupport1Mtokens
InternLM2.5-7B-Chat-1M 95.73 95.13 95.43 57.91 70.95 64.43 72.37 69.89 71.13 78.84
GLM4-9B-Chat-1M 89.99 11.6 50.8 74.64 24 49.32 52.58 42.35 47.47 49.35
Table4: MainResultsofNeedleBench1000K.
We investigate why the performance of GLM4-9B-Chat-1M is significantly worse than
InternLM2.5-7B-Chat-1M.OneofthetaskswithalargeperformancedifferenceistheSingle-
Retrieval task. We show the results under the default prompt settings in Figure 6. It is
foundthattheEnglishversionoftheGLM4-9B-Chat-1Mmodelperformpoorly(indicated
byalmostallredscores),evenatrelativelylowercontextlengths.
Byexaminingthemodeloutputs,wefindthattheGLM4-9B-Chat-1Mmodeloftenfailto
answerquestionsduetothinkingthattherewasnorelevantcontentintheoriginaltext. For
example,thefollowingscenariosinFigure7:
7
erocS
llarevO
    W Q H F U H 3  K W S H '
    W Q H F U H 3  K W S H '
)%(tnecreP
htpeD
    W Q H F U H 3  K W S H '
erocS
erocSTechnicalReport
GLM4-9B-Chat-1M GLM4-9B-Chat-1M
0 Single-Needle-Retrieval-ZH-1000K:89.99 100 0 Single-Needle-Retrieval-EN-1000K:11.60 100
95.84 96.71 93.42 92.61 92.64
87.71
21 79.71 81.28 80 21 80
42 42
60 60
63 63
40 40
84 84
20 21.88 19.16 20
100 Average Depth Score 100 Average D1 e3 p.0 th6 Score 9.96 7.19 7.19 7.19 7.19
20k 160k 300k 440k 580k 720k 860k 1000k 0 20k 160k 300k 440k 580k 720k 860k 1000k 0
Token Length Token Length
(a)GLM4-9B-Chat-1M:ZH (b)GLM4-9B-Chat-1M:EN
InternLM2.5-7B-Chat-1M InternLM2.5-7B-Chat-1M
0 100.00 100.00 S1in00g.l0e0-Needl 9e 9- .R 1e 0trieval-ZH-1000K:95.73 100 0 98.30 99.12 Si 9n 8g .2le 0-Needle-Retrieval-EN-1000K:95.13 100
94.62 93.71 90.10 88.31 93.75 92.91 92.91 92.91 92.91
21 80 21 80
42 42
60 60
63 63
40 40
84 84
20 20
100 100
Average Depth Score Average Depth Score
20k 160k 300k 440k 580k 720k 860k 1000k 0 20k 160k 300k 440k 580k 720k 860k 1000k 0
Token Length Token Length
(c)InternLM2.5-7B-Chat-1M:ZH (d)InternLM2.5-7B-Chat-1M:EN
Figure6: PerformanceComparisonofInternLM2.5-7B-Chat-1MandGLM4-9B-Chat-1M
Modelsat1000KContextLengthunderDefaultSettings
GLM4-9B-Chat-1M‚ÄôsMostCommonErrorCasesinSingleRetrieval
Prompt:
You are an intelligent AI assistant skilled in answering user questions based on
documentsprovidedbytheuser. Pleasekeepyouranswersconciseandclear. Do
nottalkaboutirrelevanttopicsorrepeatyouranswers. Thedocumentgiventoyou
bytheuseris:
HiddenonEmeraldIslandisthelegendaryStardustShard.
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGraham
Essays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚Äî
PaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul
Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham
Essays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
Now,thequestionis: WhatlegendaryitemishiddenonEmeraldIsland? Before
answering,pleaseconsiderwhatinthedocumentismostrelevanttothisquestion. Please
answerintheformat‚ÄôThelegendaryitemhiddenontheEmeraldIslandis ‚Äô
GLM4-9B-Chat-1M‚ÄôsResponse:
Thedocumentdoesnotprovideanyinformationaboutalegendaryitemhidden
onEmeraldIsland. Itdiscussesprogramminglanguages,startupfunding,andthe
natureofworkandcreativity.‚Äù
Figure7: GLM4-9B-Chat-1M‚ÄôsMostCommonErrorCasesinSingleRetrieval
Therefore,wetryremovingtherequirementforthemodeltofirstrecallthemostrelevant
sentenceinthedocumenttothequestion,andinsteadinstructthemodeltoanswerdirectly.
TheresultsobtainedareshowninthenewFigure8,whereweobservethattheperformance
isnownearlyperfect(allgreen).
8
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeDTechnicalReport
GLM4-9B-Chat-1M GLM4-9B-Chat-1M
0 97.66 Si 9n 8g .4le 1-Needl 9e 7- .R 5e 6trieval 9-E 7N .4- 91000K: 99 77 .4.0 97 97.49 97.49 100 0 99.18 Single-Needle-Retrieval-ZH-1000K:88.00 100
92.95 93.42 90.96 90.17
86.87
21 80 21 81.92 81.13 80.34 80
42 42
60 60
63 63
40 40
84 84
20 20
100 100
Average Depth Score Average Depth Score
20k 160k 300k 440k 580k 720k 860k 1000k 0 20k 160k 300k 440k 580k 720k 860k 1000k 0
Token Length Token Length
(a)GLM4-9B-Chat-1M (w/oRecallStep) (b)GLM4-9B-Chat-1M (w/oRecallStep)
EN ZH
InternLM2.5-7B-Chat-1M InternLM2.5-7B-Chat-1M
0 100.00 98.23 Si 9n 7g .4le 1-Needl 9e 4- .R 7e 7trieval 9-E 3N .9- 41000K: 99 35 .9.7 47
93.94 93.94
100 0 100.00 100.00 Si 9n 8g .4le 1-Needl 9e 5- .R 8e 5trieval 9-Z 2.H 7- 81000K: 99 04 .5.3 96
90.36
100
86.89
21 80 21 80
42 42
60 60
63 63
40 40
84 84
20 20
100 100
Average Depth Score Average Depth Score
20k 160k 300k 440k 580k 720k 860k 1000k 0 20k 160k 300k 440k 580k 720k 860k 1000k 0
Token Length Token Length
(c)InternLM2.5-7B-Chat-1M (w/oRecallStep)(d)InternLM2.5-7B-Chat-1M (w/oRecallStep)
EN ZH
Figure 8: Performance comparison of InternLM2.5-7B-Chat-1M and GLM4-9B-Chat-1M
modelsat1000Kcontextlengthafterremovingtherequirementforthemodeltofirstrecall
themostrelevantsentenceinthedocumenttothequestion.
ThesignificantdifferencecausedbythispromptindicatesthattheGLM4-9B-Chat-1Mis
highly sensitive to the prompt used. This suggests that the GLM4-9B-Chat-1M has the
inherentcapabilitytohandle1000Kcontextlengthbutmaynotalwaysdemonstratethis
abilityunderdifferentpromptsettings. Thisimpliesthatmoresophisticatedfine-tuningor
alignmentstrategiesmayneedtobeintroducedtofullyutilizethemodel‚Äôscapabilities.
3.2 AncestralTraceChallenge(ATC)
Weperformextremestresstestingwithmulti-steptestsontheATCformainstreamLLMs.
Specifically, we test LLMs on bilingual multi-step logical reasoning problems, with the
numberofstepsrangingfrom2to19. Foreachstepcountsetting,modelswererequiredto
respondinasingle-choiceformat. Weemployfew-shotlearningtoinstructtheLLMs,where
thefew-shotexamplecountis4. Inthedirectversiontest,modelswereaskedtoprovide
optionsA,B,C,orDwithouthavingtodemonstratetheirreasoningpath. Incontrast,we
introducereasoningpathsintheresponsesforthefew-shotexamplestoinstructLLMson
howtoanswereachquestion. ThisversionofthetestislabeledastheReasoning(Rea.)
version.
TomitigatetheriskofLLMsrandomlyguessingcorrectlyonmultiple-choicequestions,
weusetheCircular-Eval(CE)method(Liuetal.,2023),whichsystematicallychangesthe
optionsoneachquestion.
LetP representthescoreachievedinatask,whichconsistsofquestionsdesignedtobe
Step
solvedinaspecificnumberofsteps,precisely,inStepsteps,whereP = ‚àëR CE(Q(i) ),
Step i=1 Step
(i)
andCE(Q )denotesthecircularevaluationscorefortheithiterationofquestionQat
Step
agivennumberofsteps,withthescorebeing100/RiftheLLMaccuratelyidentifiesthe
correctanswerregardlessofitspositionamongtheoptionsA,B,C,andD,and0otherwise.
9
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeDTechnicalReport
Here, R represents the number of repetitions, and in our experiments, R is set to 10. L
denotesthenumberofreasoningstepsinthemostcomplextask,withLbeingsetto19in
ourcase. Theoverallscore(OverallScore)isobtainedbyaveragingthescoresforeachtask.
Thescoreforeachtasksetting(TaskScore)iscalculatedasfollows:
R ‚àëL (P √óStep)
‚àë (i) Step=2 Step
P = CE(Q ) TaskScore=
Step Step ‚àëL Step
i=1 Step=2
Model ZH-Direct EN-Direct ZH-Rea. EN-Rea. Overall
APIModels
Claude-3-Opus 45.34 56.77 58.15 70.16 57.61
GPT4-Turbo 21.69 66.24 40.26 64.97 48.29
GLM-4 28.47 57.46 35.82 50.21 42.99
ModelswithFewerThan7BParameters
InternLM2-7B 11.53 18.10 25.34 34.23 22.30
InternLM2-7B-200K 12.49 16.03 23.33 32.43 21.07
Yi-6B 7.14 11.53 13.33 10.69 10.67
Qwen-7B 1.96 11.01 10.26 14.55 9.45
Zephyr-7BBeta 2.28 6.72 5.82 16.03 7.71
Mistral-7BInst. v0.2 6.35 6.35 6.56 10.95 7.55
InternLM-7B 4.23 6.88 7.88 10.16 7.29
Baichuan2-7B 0.32 4.87 12.38 6.40 5.99
ChatGLM3-6B-32K 3.17 5.66 5.71 6.88 5.35
Gemma-7B 3.49 2.22 5.19 8.68 4.89
ChatGLM3-6B 4.55 4.50 4.60 5.24 4.72
Qwen-1.5-4B 0.63 2.06 3.07 1.75 1.88
LLaMA-2-7B 0.74 0.00 0.42 4.13 1.32
Gemma-2B 1.06 0.21 0.00 0.26 0.38
Qwen-1.5-1.8B 0.00 0.11 0.63 0.26 0.25
Qwen-1.5-0.5B 0.00 0.21 0.00 0.00 0.05
Modelswith7-20BParameters
InternLM2-20B 26.72 42.43 23.65 31.06 30.96
InternLM2-20B-200K 26.14 35.08 32.75 29.47 30.86
Qwen-14B 12.01 27.46 31.85 23.92 23.81
Qwen-1.5-14B-vLLM 19.84 8.25 36.72 2.96 16.94
Baichuan2-13B 1.06 12.86 21.90 10.11 11.48
LLaMA-2-13B 1.75 6.08 3.39 12.22 5.86
Orion-14B-LongChat 1.38 7.94 1.43 11.43 5.54
ModelsLargerThan20BParameters
DeepSeek-67B 27.88 46.51 38.68 63.07 44.03
Qwen-72B-vLLM 22.91 23.49 29.89 35.24 27.88
Qwen-1.5-72B-vLLM 35.66 12.75 36.93 2.80 22.04
OrionStar-Yi-34B 2.91 28.25 18.99 25.98 19.03
Mixtral-8x7BInst. v0.1 15.50 13.65 19.63 26.51 18.82
Yi-34B 11.48 20.95 18.68 18.10 17.30
LLaMA-2-70B 7.83 15.45 17.14 25.82 16.56
WizardLM-70B 12.75 18.36 10.79 19.05 15.24
Table5: ATCResults
10TechnicalReport
WepresenttheresultsoftheATCexperimentsasfollows. InTable5,wepresentthescores
ofvariousmodelsonATCsubtasksaswellastheiroverallperformance,wecanobserve
severalkeyinsights:
AddingReasoningPathsImprovesModelPerformance:Itisevidentthattheversionswith
reasoningpathsgenerallyscorehigherthanthosewithoutreasoningpaths. Forinstance,
theEN-Rea. versionofClaude-3-Opusscores70.16,whilethecorrespondingEN-Direct.
versionscores56.77. Thisalignswiththeobservationthatchain-of-thought(CoT)reasoning
canenhancemodelperformance.
LargerParameterCountImprovesModelATCScores: Furthermore,formodelswithinthe
sameseries,suchasBaichuanandLLaMA,thereisanoticeabletrendwhereanincreasein
parametercountcorrespondstohigherscores. Forexample,Baichuan2-7Bhasanoverall
scoreof5.99,whileBaichuan2-13Bachievesasignificantlyhigherscoreof11.48. Similarly,
LLaMA-2-7Bscores1.32overall,LLaMA-2-13Bscores5.86,andLLaMA-2-70Breaches16.56,
demonstratingthesameupwardtrend. Thisindicatesthatlargermodelstendtoperform
betterinthesetasks.
SuperiorityofClosed-SourceModels: WealsoobserveaclearsuperiorityofAPImodels
overopen-sourceLLMs,particularlyhighlightedbytheperformancesofClaude-3-Opus
and GPT4-Turbo. However, DeepSeek-67B stands out with reasoning abilities that are
close to those of the top API models, suggesting a promising direction for bridging the
performancegapbetweenAPIandopen-sourcemodels.
API Models Series Baichuan Series ChatGLM Series DeepSeek Series Gemma Series
100
Baichuan2-7B ChatGLM3-6B DeepSeek-67B Gemma-2B
80 Baichuan2-13B ChatGLM3-6B-32K Gemma-7B
60
40
GPT4-Turbo
20 GLM-4
Claude-3-Opus
0 1020 / 9 1120 / 16 920 / 2 1020 / 9 1120 / 16 920 / 2 1020 / 9 1120 / 16 920 / 2 1020 / 9 1120 / 16 920 / 2 1020 / 9 1120 / 16
Context Length / Needle Count Context Length / Needle Count Context Length / Needle Count Context Length / Needle Count Context Length / Needle Count
InternLM2 Series Mistral Series Qwen 1.5 Series Yi Series Prompt Length in ATC
100 InternLM2-7B Mistral-7B Inst. v0.2 Qwen-1.5-0.5B Yi-6B 4000 English
80 InternLM2-7B-200K Mixtral-8x7B Inst. v0.1 Qwen-1.5-1.8B OrionStar-Yi-34B 3500 Chinese
InternLM2-20B Qwen-1.5-4B Yi-34B
60 InternLM2-20B-200K Q Qw we en n- -1 1. .5 5- -1 74 2B B- -v vL LL LM M 23 50 00 00
40 2000
20 1500
1000
0 1020 / 9 1120 / 16 920 / 2 1020 / 9 1120 / 16 920 / 2 1020 / 9 1120 / 16 920 / 2 1020 / 9 1120 / 16 0 25 50 75 100
Context Length / Needle Count Context Length / Needle Count Context Length / Needle Count Context Length / Needle Count Needle Count
Figure9: PerformancedeclinetrendofvariousmodelsonATC
InFigure9,wepresenttheperformancedeclinetrendofvariousmodelsonATCwiththe
increase in the number of reasoning steps. The vertical axis represents the accuracy of
differentmodelsinaddressingthecorrespondingquestionsatagivennumberofreasoning
steps (number of needles). As the number of reasoning steps increases.The majority of
modelsstruggletocopewiththecomplexityoflongtextswhiletheaccuracyofnearlyall
open-sourceLLMsdropsbelow10%whenthenumberofreasoningstepsreachesaround
16,atwhichpointthepromptlengthismerelyapproximately1120tokens,indicatingtheir
difficulty in handling complex logical problems that are likely present in long-context
questions.
4 Discussion
In this section, we present a series of ablation studies to explore the factors influencing
model performance on long-context tasks. We focus on three key aspects: the effect of
modelsizeonlong-textcapabilities,theimpactofinstructionfollowinginmulti-retrieval
tasks,andtheinfluenceofpromptpositiononmodelscores,withtheaimofprovidinga
comprehensiveunderstandingofhowthesefactorsaffecttheperformanceandreliabilityof
LLMsindifferentscenarios.
11
egarevA
EC
egarevA
EC
htgneL
nekoT
egarevATechnicalReport
EffectofModelSizeonLong-textCa- Model Parameters Score TaskType
pabilities Weexamintherelationship Baichuan2-7B 7B 81.30 Overall
betweenmodelsizeandperformance Baichuan2-13B 13B 92.28 Overall
LLaMA-2-7B 7B 62.09 Overall
onlongtexttasksinNeedleBench4K,as
LLaMA-2-13B 13B 61.82 Overall
detailed in table 6. Our results show
LLaMA-2-70B 70B 69.35 Overall
a pattern that is in most cases consis- Qwen-1.5-0.5B 0.5B 59.40 Overall
tentwiththescalinglaws(Kaplanetal., Qwen-1.5-1.8B 1.8B 82.49 Overall
2020)whicharguethatlargermodels Qwen-1.5-4B 4B 86.98 Overall
Qwen-1.5-14B 14B 77.88 Overall
typicallyexhibitsuperiorperformance,
Qwen-1.5-72B 72B 94.76 Overall
suchastheBaichuan,LLaMA,andIn-
Qwen-7B 7B 74.7 Overall
ternLM2modelseries. Qwen-14B 14B 83.71 Overall
Qwen-72B 72B 59.55 Overall
However, for the Qwen series LLMs, Qwen-7B 7B 80.18 S-RT
as detailed in Table 6, the Qwen- Qwen-14B 14B 94.12 S-RT
72Bmodelshowsasignificantperfor- Qwen-72B 72B 33.04 S-RT
mancedegradation,especiallyonthe InternLM2-7B 7B 85.19 M-RS
InternLM2-20B 20B 90.66 M-RS
NeedleBench 4K single retrieval task.
Uponverification,itisconfirmedthat
Table6: ModelSizeImpactonScoresbySeries
the Qwen-72B model often fail by as-
sumingthatthereisnocontentrelevanttothequerywithinthedocuments.Suchfindings
indicate the need for more focused training and optimization strategies tailored to the
specificsoflongtexttasksinordertofullyexploittheirincreasedcapacitiesandconformto
thepredictionsofthescalinglaw.
ExploringInstructionFollowinginMulti-RetrievalTasks InourevaluationoftheMulti-
Needle Retrieval tasks in NeedleBench 8K, we investigate how changing the number of
‚Äùneedles,‚Äùorkeypiecesofinformationthatmodelsneedletoretrievefromextensivetexts,
affectstheirinformationretrievalcapabilitiesFigure10.
100 100
75 80
50
60
25
40
0
1 5 10 15 20 1 5 10 15 20
NumberofNeedles NumberofNeedles
InternLM2-7B ChatGLM3-6B-32K ChatGLM3-6B Mixtral-8x7BInst.v0.1
Qwen-14B Zephyr-7BBeta InternLM2-20B Qwen-7B
Qwen-72B Orionstar-14B-LongChat InternLM-7B Mistral-7BInst.v0.2
(a)ModelswithStableScores (b)ModelswithFluctuatingScores
Figure10: Initialneedlerecallrateinmulti-retrievaltasksbyrequestedneedlecount.
Interestingly,ratherthanobservingastraightforwarddeclineinrecallscoreswithanincrease
inthenumberofneedles,wenoteexceptionsintheperformanceofcertainmodels. For
instance, the Mixtral-8*7b-instruct-v0.1 model, presented in Figure 10b, demonstrate an
unexpectedbehaviorinitsabilitytorecalltheveryfirstneedle. Whenthemodelistasked
withrecallingalargersetofneedlesatdifferentpostions(includingtheinitiallyrequested
firstneedle),itsaccuracyinrecallingtheinitialpieceofkeyinformationactuallyimproved.
Thispatternindicatesthatwhilethesemodelshavetheinherentcapabilitytoaccurately
recallinitialkeyinformation,thispotentialisnotalwaysfullyutilized,suggestingroomfor
improvementintheirinstruction-followingabilities. Thefluctuatingperformance,which
paradoxicallyimproveswithmoredemandinginstructions,reflectsaneedforenhancing
therobustnessofthemodels‚Äôcapabilitytofollowinstructions,particularlyfortasksthat
requirepreciseinformationretrieval.
12
erocS erocSTechnicalReport
EffectofPromptPositiononModelScore Performance Difference by Prompt Position in Needlebench 32K Tasks
100
InNeedleBench32K,westudyhowprompt Overall -9.11 -18.81 -7.91 7.07 -6.61 -25.75-18.39 5.62 -11.21
S-RT -12.91-13.47 0.90 9.00 -0.46 -43.07-24.97 -0.40 -9.68
position (whether the question prompt is
S-RT-ZH -21.78-29.22 -0.51 15.76 -13.83-64.13-42.98 0.00 -9.96 75
placed before the long text or at the end S-RT-EN -4.04 2.28 2.31 2.23 12.92 -22.00 -6.97 -0.79 -9.40
ofthelongtext)affectsmodelperformance M-RT -1.55 -23.03-23.29 2.86 -7.34 -0.68 -12.81 49.36 3.50 50
on various subtasks. The results, shown M-RT-ZH -2.22 -29.68-39.91 4.64 -2.09 -0.32 8.91 60.46 -2.31
in Figure 11, are the changes in perfor- M-RT-EN -0.86 -16.37 -6.68 1.09 -12.59 -1.04 -34.55 38.27 9.32 25
M-RS -11.59-21.73 -4.26 8.70 -14.08-27.71-15.17-30.07-27.94
manceduetomovingthepromptposition M-RS-EN -1.72 -12.92 3.84 10.87 -5.16 -11.75 0.67 -33.25-27.32
0
frombeforethelongtextstoafterthelong M-RS-ZH -21.46-30.54-12.37 6.53 -23.01-43.67-31.02-26.91-28.58
M-RS-2-EN 0.11 -9.79 13.92 13.69 -5.09 -14.36 -0.78 -41.77-27.08
text.The predominance of red blocks sug- M-RS-3-EN -3.63 -10.37 -6.60 14.14 -4.47 -19.16 5.13 -32.85-28.43 25
gests that the majority of models tend to M-RS-4-EN -3.06 -21.33 -2.28 11.13 -2.66 -6.99 1.33 -34.67-23.71
performworsewhenthequestionprompt M-RS-5-EN -0.31 -10.20 10.34 4.51 -8.41 -6.48 -3.01 -23.73-30.05 50
M-RS-2-ZH -16.81-31.36 -7.84 1.70 -18.63-58.30-52.50-22.50-31.14
isplacedatthebeginningofthetext. How-
M-RS-3-ZH -24.09-35.13-22.93 -2.84 -17.20-44.40-41.18-13.75-30.68 75
ever, for InternLM2-7B-200K, placing the M-RS-4-ZH -20.74-24.14 -6.93 13.64 -30.11-36.02-19.66-43.75-20.11
question prompt of the M-RT task before M-RS-5-ZH -24.21-31.52-11.75 13.64 -26.10-35.98-10.75-27.61-32.39
100
t t shh uee ltm il no gon dg inelt s‚Äôe s cx oct o reh me immlp pas n rs odi vg f en o mi llfi o ec nwa tn i sn .tl gy ai bm ilp itr yo ,v ree - Qwen-1.5-0. Q5 wB en-1.5-1.8 QB wen Q- w1. e5 n- -4 1.B 5-14B C- hv aL t ML iG xM L trM a3 l- -6 8xB- 73 B 2 IK n Mist sr tru ac lt
-
7v B0 . I1 nstr Iu nc tt erv n0. L2 M2 I- n7 tB e- r2 n0 L0 MK 2-20B-200K
Figure11: PerformanceChanges
5 Conclusion
Inthisreport,wethoroughlyevaluatetheabilityofLLMstohandlelong-contextinformation
retrieval and reasoning. Our research uncovers notable limitations in the current open-
sourceLLMs‚Äôabilitytointerpretandreasonoverlongtexts. Despitetheprogressinsingle
informationretrievalcapabilitiesunderextendedcontextlengthofmodelssuchasGPT-4
TurboandClaude3,ourfindingsunderscorethedifficultiesthesemodelsencounterdue
tothecomplexityoflogicalreasoningchallengesthatarelikelypresentinreal-world
long-contexttasks.. Thissuggeststhatthereissignificantroomforimprovingtheutilityof
LLMsinscenariosrequiringintricateinformationretrievalandnumerousreasoningsteps.
OurreportrevealstheimportanceofconcentratedeffortswithintheAIresearchcommunity
to improve LLMs‚Äô long-context comprehension and reasoning abilities. Addressing the
shortcomings identified in the NeedleBench assessments could enable future models to
performmoreaccurateandsophisticatedanalyses, equippingthemmoreeffectivelyfor
intricatelong-contexttasksinreal-worldscenarios.
6 LimitationsandFutureWork
Limitations: One limitation identified in our experiments is related to the multi-needle
reasoning task. The needles used in this task are derived from datasets curated from
Wikipedia.Itischallengingtodeterminewhetherthetestedmodelsaregenuinelyreasoning
overthecontextorsimplyutilizinginternalknowledge. Weplantoaddressitinfuture
workbyincorporatingATCneedlesintothemulti-needlereasoningtasktofurtherrefine
thisaspect.
FutureWork: TheATCtestinthisstudydemonstratesthatforLLMs,long-textcomprehen-
sionshouldnotbeconfinedtoretrievaltasksalone. Itrevealsthatlogicalreasoningwithin
longtextsisinherentlymorecomplex. FutureLLMscouldbespecificallyoptimizedfor
long-contextreasoningtohandletheintricatelogicalchallengesthatarelikelytoarisein
suchscenarios.
Additionally,futureworkshouldfocusonimprovingtherobustnessoflong-contextmodels‚Äô
abilities,asourfindingsinNeedleBench1000Kexperimentsindicatethatthesemodelsare
highlypromptsensitive. Developingstrategiestomitigatepromptsensitivitywillbecrucial
toensureconsistentperformanceacrossdifferentpromptsandenhancetheoverallreliability
ofthesemodelsinhandlingextensivetextualdata.
13
tesatadTechnicalReport
References
Anthropic. Introducing claude 2.1. https://www.anthropic.com/index/claude-2-1,
2024a. Accessed: 2024-01-23.
Anthropic. Introducingthenextgenerationofclaude. https://www.anthropic.com/news/
claude-3-family,2024b. Accessed: 2024-03-27.
YushiBai,XinLv,JiajieZhang,HongchangLyu,JiankaiTang,ZhidianHuang,Zhengxiao
Du,XiaoLiu,AohanZeng,LeiHou,YuxiaoDong,JieTang,andJuanziLi. Longbench: A
bilingual,multitaskbenchmarkforlongcontextunderstanding,2023.
Maciej Besta, Florim Memedi, Zhenyu Zhang, Robert Gerstenberger, Nils Blach, Piotr
Nyczyk,MarcinCopik,GrzegorzKwas¬¥niewski,Ju¬®rgenMu¬®ller,LukasGianinazzi,Ales
Kubicek,HubertNiewiadomski,OnurMutlu,andTorstenHoefler. Topologiesofreason-
ing: Demystifyingchains,trees,andgraphsofthoughts,2024.
LMDeployContributors. Lmdeploy: Atoolkitforcompressing,deploying,andservingllm.
https://github.com/InternLM/lmdeploy,2023.
GeminiTeam. Gemini1.5: Unlockingmultimodalunderstandingacrossmillionsoftokens
of context. https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_
5_report.pdf,2024. Accessed: 2024-03-17.
NozomuInoue,PontusStenetorp,andKentaroInui. R4c: Abenchmarkforevaluatingrc
systemstogettherightanswerfortherightreason.arXiv:ComputationandLanguage,arXiv:
ComputationandLanguage,Oct2019.
Greg Kamradt. LLMs Need Needle In A Haystack Test-Pressure Testing LLMs. https:
//github.com/gkamradt/LLMTest_NeedleInAHaystack,2023.
JaredKaplan,SamMcCandlish,TomHenighan,TomB.Brown,BenjaminChess,Rewon
Child,ScottGray,AlecRadford,JeffreyWu,andDarioAmodei. Scalinglawsforneural
languagemodels,2020.
WoosukKwon,ZhuohanLi,SiyuanZhuang,YingSheng,LianminZheng,CodyHaoYu,
JosephE.Gonzalez,HaoZhang,andIonStoica. Efficientmemorymanagementforlarge
languagemodelservingwithpagedattention. InProceedingsoftheACMSIGOPS29th
SymposiumonOperatingSystemsPrinciples,2023.
YuanLiu,HaodongDuan,YuanhanZhang,BoLi,SongyangZhang,WangboZhao,Yike
Yuan,JiaqiWang,ConghuiHe,ZiweiLiu,KaiChen,andDahuaLin. Mmbench: Isyour
multi-modalmodelanall-aroundplayer?,2023.
AmirkeivanMohtashamiandMartinJaggi. Landmarkattention: Random-accessinfinite
contextlengthfortransformers,2023.
OpenAI. Gpt-4andgpt-4turbo-documentation. https://platform.openai.com/docs/
models/gpt-4-and-gpt-4-turbo,2023. Accessed: 2024-01-23.
OpenCompassContributors. OpenCompass: Auniversalevaluationplatformforfounda-
tionmodels. https://github.com/open-compass/opencompass,2023.
TianwenWei,LiangZhao,LichangZhang,BoZhu,LijieWang,HaihuaYang,BiyeLi,Cheng
Cheng,WeiweiLu¬®,RuiHu,ChenxiaLi,LiuYang,XilinLuo,XuejieWu,LunanLiu,Wen-
junCheng,PengCheng,JianhaoZhang,XiaoyuZhang,LeiLin,XiaokunWang,Yutuan
Ma,ChuanhaiDong,YanqiSun,YifuChen,YongyiPeng,XiaojuanLiang,ShuichengYan,
HanFang,andYahuiZhou. Skywork: Amoreopenbilingualfoundationmodel,2023.
ZhilinYang,PengQi,SaizhengZhang,YoshuaBengio,WilliamCohen,RuslanSalakhut-
dinov, and Christopher D. Manning. Hotpotqa: A dataset for diverse, explainable
multi-hopquestionanswering. InProceedingsofthe2018ConferenceonEmpiricalMeth-
ods in Natural Language Processing, Jan 2018. doi: 10.18653/v1/d18-1259. URL http:
//dx.doi.org/10.18653/v1/d18-1259.
14TechnicalReport
XinrongZhang,YingfaChen,ShengdingHu,QihaoWu,JunhaoChen,ZihangXu,Zhenning
Dai, Xu Han, Shuo Wang, Zhiyuan Liu, and Maosong Sun. Infinitebench: 128k long-
contextbenchmarkforlanguagemodels,2023.
7 Appendix
A ParameterSettings
Wehavecarefullyadjustparameterssuchasbuffersize,repeats,depths,andlengthsfor
varioustasks,languages,andcontentlengthsinNeedleBench. Thisensurestestdurations
arekeptwithinacceptablelimits,experimentsremainreproducible,andtheinfluenceof
tokenizerdiscrepanciesamongdifferentmodelsisminimized. Buildingonthisfoundation,
wefurtherrefineourevaluationapproachbyquantifyingtheoverallperformanceofmodels
usingaweightedscoringsystem. Thissystemisdesignedtocapturethecomprehensive
abilitiesofmodelsinperformingarangeoftasks,fromsingle-itemretrievaltocomplex
reasoningacrossmultiplecontexts.
Followingthemeticulousconfigurationoftheseparameters,thecomputationoftheOverall
Score (O) is derived from the weighted averages of scores from different tasks. This is
formalizedas:
O =W S‚àíRT¬∑Score S‚àíRT+W M‚àíRT¬∑Score M‚àíRT+W M‚àíRS¬∑Score M‚àíRS
WhereW S‚àíRT =0.4,W M‚àíRT =0.3,andW M‚àíRS =0.3aretheweightsassignedtothescores
oftheSingle-RetrievalTask(S-RT),Multi-RetrievalTask(M-RT),andMulti-ReasoningTask
(M-RS)respectively.
TheLevenshteindistancedweuseinscorecalculationisdefinedasfollows:
Ô£±
max(i,j) if min(i,j) =0,
Ô£¥Ô£¥Ô£≤ Ô£±
d(i‚àí1,j)+1,
Ô£º
d(i,j) = Ô£≤ Ô£Ω
min d(i,j‚àí1)+1, otherwise.
Ô£¥Ô£¥Ô£≥
Ô£≥ d(i‚àí1,j‚àí1)+1 Ô£æ
(s1[i]Ã∏=s2[j])
Here, 1 denotes an indicator function that equals 1 when s [i] Ã∏= s [j] and 0
(s1[i]Ã∏=s2[j]) 1 2
otherwise. Thetermd(i,j)representstheLevenshteindistancebetweenthefirsticharacters
ofs andthefirstjcharactersofs .
1 2
15TechnicalReport
Table7: NeedlebenchParameterSettings:
Task Repeats Buffersize #ofDepth #ofLength
Intervals Intervals
2-Needle-Reasoning-EN-4K 10 600 20 4
3-Needle-Reasoning-EN-4K 10 600 20 4
4-Needle-Reasoning-EN-4K 10 600 20 4
5-Needle-Reasoning-EN-4K 10 600 20 4
Single-Needle-Retrieval-EN-4K 10 600 20 4
Multi-Needle-Retrieval-EN-4K 25 1000 20 4
2-Needle-Reasoning-ZH-4K 10 200 20 4
3-Needle-Reasoning-ZH-4K 10 200 20 4
4-Needle-Reasoning-ZH-4K 10 200 20 4
5-Needle-Reasoning-ZH-4K 10 200 20 4
Single-Needle-Retrieval-ZH-4K 10 200 20 4
Multi-Needle-Retrieval-ZH-4K 25 200 20 4
2-Needle-Reasoning-EN-8K 10 1000 20 4
3-Needle-Reasoning-EN-8K 10 1000 20 4
4-Needle-Reasoning-EN-8K 10 1000 20 4
5-Needle-Reasoning-EN-8K 10 1000 20 4
Single-Needle-Retrieval-EN-8K 10 800 20 4
Multi-Needle-Retrieval-EN-8K 25 1300 20 4
2-Needle-Reasoning-ZH-8K 10 200 20 4
3-Needle-Reasoning-ZH-8K 10 200 20 4
4-Needle-Reasoning-ZH-8K 10 200 20 4
5-Needle-Reasoning-ZH-8K 10 200 20 4
Single-Needle-Retrieval-ZH-8K 10 200 20 4
Multi-Needle-Retrieval-ZH-8K 25 200 20 4
2-Needle-Reasoning-EN-32K 10 3000 10 8
3-Needle-Reasoning-EN-32K 10 3000 10 8
4-Needle-Reasoning-EN-32K 10 3000 10 8
5-Needle-Reasoning-EN-32K 10 3000 10 8
Single-Needle-Retrieval-EN-32K 10 3000 10 8
Multi-Needle-Retrieval-EN-32K 25 3000 10 8
2-Needle-Reasoning-ZH-32K 10 200 10 8
3-Needle-Reasoning-ZH-32K 10 200 10 8
4-Needle-Reasoning-ZH-32K 10 200 10 8
5-Needle-Reasoning-ZH-32K 10 200 10 8
Single-Needle-Retrieval-ZH-32K 10 200 10 8
Multi-Needle-Retrieval-ZH-32K 25 200 10 8
2-Needle-Reasoning-EN-200K 10 600 10 8
3-Needle-Reasoning-EN-200K 10 600 10 8
4-Needle-Reasoning-EN-200K 10 600 10 8
5-Needle-Reasoning-EN-200K 10 600 10 8
Single-Needle-Retrieval-EN-200K 10 600 10 8
Multi-Needle-Retrieval-EN-200K 25 3000 10 8
2-Needle-Reasoning-ZH-200K 10 200 10 8
3-Needle-Reasoning-ZH-200K 10 200 10 8
4-Needle-Reasoning-ZH-200K 10 200 10 8
5-Needle-Reasoning-ZH-200K 10 200 10 8
Single-Needle-Retrieval-ZH-200K 10 200 10 8
Multi-Needle-Retrieval-ZH-200K 25 200 10 8
16TechnicalReport
B DetailedExperimentalResults
Inthissection,wepresenttheperformanceofmodelsfordifferenttokenlengths(4K,8K,32K,
and200K)inNeedleBench. Themodelsaregroupedaccordingtotheirmaximumsequence
length,allowingafocusedanalysisonappropriatesubtasksforeachgroup. Detailedresults
foreachlengthandtaskarepresentedinthecorrespondingtables: for4Ktextlengthin
table8,for8Ktextlengthintable9
B.1 NeedleBench4K
Model Single-Retrieval Multi-Retrieval Multi-Reasoning Overall
Chinese English Overall Chinese English Overall Chinese English Overall
ModelswithFewerThan7BParameters
InternLM2-7B-200K 100.00 100.00 100.00 94.00 99.90 96.95 74.17 95.29 84.73 94.50
InternLM2-7B 100.00 100.00 100.00 91.15 99.85 95.50 74.98 95.39 85.19 94.21
ChatGLM3-6B-32K 99.77 99.53 99.65 94.50 91.10 92.80 71.55 80.67 76.11 90.53
Qwen-1.5-4B 100.00 100.00 100.00 92.55 93.20 92.88 58.45 68.97 63.71 86.98
Yi-6B 83.75 99.77 91.76 86.05 84.80 85.43 71.91 81.93 76.92 85.41
Qwen-1.5-1.8B 99.16 96.45 97.81 77.80 78.60 78.20 67.68 65.01 66.34 82.49
Baichuan2-7B 91.42 94.13 92.78 80.00 69.45 74.72 72.33 72.80 72.57 81.30
InternLM-7B 95.12 89.77 92.44 62.00 82.85 72.42 53.06 75.60 64.33 78.00
Qwen-7B 79.26 81.10 80.18 75.25 79.25 77.25 63.19 66.48 64.83 74.70
Gemma-7B 75.32 74.31 74.82 82.15 90.80 86.47 55.74 60.33 58.03 73.28
ChatGLM3-6B 87.12 84.15 85.64 78.75 86.30 82.53 43.69 45.06 44.38 72.33
Mistral-7BInst.v0.2 68.02 38.23 53.12 91.75 99.05 95.40 34.11 76.92 55.52 66.52
LLaMA-2-7B 32.42 93.84 63.13 41.20 84.25 62.73 31.61 88.52 60.07 62.09
Qwen-1.5-0.5B 75.67 92.13 83.90 35.75 49.90 42.82 41.40 45.20 43.30 59.40
Zephyr-7BBeta 69.22 45.70 57.46 52.25 53.30 52.78 53.63 54.60 54.12 55.05
Gemma-2B 21.47 20.29 20.88 56.90 80.20 68.55 12.72 31.68 22.20 35.57
Modelswith7-20BParameters
Orion-14B-LongChat 99.51 99.29 99.40 98.15 98.55 98.35 68.24 87.29 77.76 92.59
Baichuan2-13B 99.31 98.73 99.02 94.45 96.90 95.67 80.76 79.01 79.89 92.28
InternLM2-20B-200K 100.00 100.00 100.00 65.75 86.70 76.23 84.49 96.77 90.63 90.06
InternLM2-20B 100.00 100.00 100.00 63.20 82.40 72.80 84.49 96.83 90.66 89.04
Qwen-14B 98.82 89.43 94.12 93.40 92.30 92.85 66.24 55.15 60.69 83.71
Qwen-1.5-14B-vLLM 49.78 84.57 67.18 94.80 93.60 94.20 71.62 83.36 77.49 78.38
LLaMA-2-13B 44.22 86.94 65.58 25.20 87.55 56.38 37.22 87.25 62.24 61.82
ModelsLargerThan20BParameters
Qwen-1.5-72B-vLLM 99.32 95.67 97.50 95.05 98.85 96.95 87.10 95.91 91.50 95.53
Yi-34B 92.86 94.41 93.63 99.15 99.50 99.33 78.14 83.26 80.70 91.46
Mixtral-8x7BInst.v0.1 87.22 84.89 86.05 99.15 99.45 99.30 71.19 83.76 77.48 87.45
DeepSeek-67B 95.44 85.21 90.33 80.40 78.35 79.38 85.11 76.60 80.86 84.20
Qwen-72B-vLLM 73.32 29.37 51.34 99.15 92.55 95.85 71.45 63.76 67.60 69.57
LLaMA-2-70B 41.35 98.43 69.89 40.70 98.55 69.62 43.37 93.30 68.34 69.35
OrionStar-Yi-34B 82.42 41.24 61.83 82.05 72.25 77.15 63.76 77.44 70.60 69.06
WizardLM-70B 63.95 42.61 53.28 49.25 77.45 63.35 53.93 62.98 58.46 57.85
Table 8: Main Results of NeedleBench 4K. Overall stands for the score calculated from
anaverageofmetricsonallsubsets. (bolddenotesthebestscoreamongallmodels,and
underlinedenotesthebestscoreunderthesamemodelscale. Forthefollowingtables,the
samenotationapplies.)
From Table 8, it is evident that the InternLM2 models are particularly adept at Single-
Retrievaltasks,whilealsodemonstratingcommendablecross-documentinferenceabilities
inMulti-Reasoningtasks. Notably,InternLM2-7B-200Kachievethebestoverallscoreamong
models with fewer than 7 billion parameters, although it is outperformed by the larger
Qwen-1.5-72B-vLLMmodel.
Figure12showsdetailedgraphsforselectedrepresentativemodelsatvariouslengthsand
depths: The InternLM2 models show superior overall performance, while the LLaMA
modelsshowsignificantlyweakerChineselanguagecapabilitiescomparedtoEnglish. The
Gemmaseriesshowsasignificantimprovementincombinedscoresastheparametersize
increasesfrom2Bto7B.
17TechnicalReport
InternLM2-7B-200K LLaMA-2-70B LLaMA-2-70B
0 Overall Score:94.50 0 Overall Score:69.35 0 Single-Needle-Retrieval-ZH-4K:41.35 100
10 10 10
21 21 21 80
31 31 31
42 42 42 60
52 52 52
63 63 63 40
73 73 73
84 84 84 20
94 94 94
1k 2k 3k 4k 1k 2k 3k 4k 1k 2k 3k 4k 0
Token Length Token Length Token Length
LLaMA-2-70B Gemma-2B Gemma-7B
0 Single-Needle-Retrieval-EN-4K:98.43 0 Overall Score:35.57 0 Overall Score:73.28 100
10 10 10
21 21 21 80
31 31 31
42 42 42 60
52 52 52
63 63 63 40
73 73 73
84 84 84 20
94 94 94
1k 2k 3k 4k 1k 2k 3k 4k 1k 2k 3k 4k 0
Token Length Token Length Token Length
Qwen-1.5-72B-vLLM ChatGLM3-6B ChatGLM3-6B-32K
0 Overall Score:95.53 0 Multi-Reasoning Overall Score:44.38 0 Multi-Reasoning Overall Score:76.11 100
10 10 10
21 21 21 80
31 31 31
42 42 42 60
52 52 52
63 63 63 40
73 73 73
84 84 84 20
94 94 94
1k 2k 3k 4k 1k 2k 3k 4k 1k 2k 3k 4k 0
Token Length Token Length Token Length
Baichuan2-7B Baichuan2-13B Baichuan2-13B
0 Multi-Reasoning Overall Score:72.57 0 Multi-Reasoning Overall Score:79.89 0 Overall Score:92.28 100
10 10 10
21 21 21 80
31 31 31
42 42 42 60
52 52 52
63 63 63 40
73 73 73
84 84 84 20
94 94 94
1k 2k 3k 4k 1k 2k 3k 4k 1k 2k 3k 4k 0
Token Length Token Length Token Length
Figure12: SelectiveVisualizationinNeedleBench4K
18
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
)%(tnecreP
htpeD
erocS
erocS
erocS
erocSTechnicalReport
Model Performance Comparison on Needlebench 4K
100
Single-Needle Retrieval
Multi-Needle Retrieval
7-20B Params
Multi-Needle Reasoning
80 >20B Params
0-7B Params: Aver. Score
60
40
20
0
Ge Zem pm ha y- r-2 Q7B wB eB n-et 1.a M5 L i- L s0 t. a r5 aM lB -A 7-2 B - I7 n CB st h. atv0 G. L2 M3 G- e6 mB ma-7 QB w Ie ntn- er7 n BB L aiM c- h7 u QB a wn e2 n- -7 1.B 5-1.8B Q CY hwi- ae t6 n- GB 1 L.5 M- 34 - I IB 6 n ntB t- e er3 rn2 nL LK M M2 2- -7 7 QLB B- L w2 a e0 nM -0 A 1K - .2 5- -1 13 4B B-vL QL I Iw n nM te ten er- rn1 nL4 LB M M2 2- -2 20 B0 OaB B i r- ic2 oh0 nu -0 a 1K n 42 B- -1 L3 o WB n izg aC r Orh d ia L ot nM- St7 a0 r- LB Y Li- a3 QM4 wAB - e2 n- -7 7 M0 2 D iB B xe t- e rv p aL l-SL 8eM xe 7k- B 6 I7 n QB st.
w
ev n0 -. 11 .Yi 5- -3 74 2B B-vLLM
Figure13: ModelPerformanceComparisononNeedleBench4K
B.2 NeedleBench8K
Model Single-Retrieval Multi-Retrieval Multi-Reasoning Overall
Chinese English Overall Chinese English Overall Chinese English Overall
ModelswithFewerThan7BParameters
ChatGLM3-6B-32K 100.00 99.04 99.52 87.90 89.55 88.73 73.26 82.48 77.87 89.79
InternLM2-7B 100.00 100.00 100.00 49.90 98.90 74.40 65.29 90.62 77.96 85.71
InternLM2-7B-200K 100.00 100.00 100.00 46.25 99.00 72.62 65.09 91.38 78.23 85.26
Qwen-1.5-4B 99.89 97.96 98.92 92.05 92.35 92.20 56.25 57.41 56.83 84.28
Qwen-1.5-1.8B 99.20 94.01 96.61 65.85 62.75 64.30 61.15 51.65 56.40 74.85
Mistral-7BInstructv0.2 76.63 40.92 58.78 86.55 97.90 92.22 42.59 76.48 59.54 69.04
ChatGLM3-6B 85.42 48.67 67.04 57.45 65.85 61.65 42.97 24.14 33.55 55.38
Gemma-7B 76.51 55.55 66.03 54.50 44.05 49.28 50.10 31.36 40.73 53.41
Qwen-1.5-0.5B 69.53 78.60 74.07 13.80 23.35 18.58 36.67 29.00 32.84 45.05
Qwen-7B 63.41 53.55 58.48 22.95 17.90 20.43 49.45 51.71 50.58 44.69
InternLM-7B 59.62 38.87 49.25 12.65 12.65 12.65 48.26 52.32 50.29 38.58
Zephyr-7BBeta 34.16 42.73 38.45 0.10 11.35 5.73 34.57 44.88 39.73 29.01
Gemma-2B 15.57 5.59 10.58 16.90 14.80 15.85 11.66 10.12 10.89 12.25
Modelswith7-20BParameters
Orion-14B-LongChat 100.00 99.41 99.71 95.05 94.75 94.90 65.33 79.96 72.65 90.15
Qwen-1.5-14B-vLLM 67.67 83.33 75.50 88.55 94.30 91.42 66.64 74.57 70.60 78.81
InternLM2-20B 100.00 100.00 100.00 23.75 47.55 35.65 73.87 94.73 84.30 75.99
InternLM2-20B-200K 100.00 100.00 100.00 26.55 44.55 35.55 73.84 94.76 84.30 75.96
Qwen-14B 90.35 46.28 68.32 79.85 59.15 69.50 57.46 34.74 46.10 62.01
ModelsLargerThan20BParameters
Qwen-1.5-72B-vLLM 99.39 79.27 89.33 92.40 93.65 93.03 86.23 93.87 90.05 90.65
Mixtral-8x7BInstructv0.1 94.83 83.67 89.25 98.70 100.00 99.35 71.55 81.31 76.43 88.43
Qwen-72B-vLLM 89.19 16.29 52.74 99.10 73.05 86.08 66.79 45.42 56.11 63.75
Table9: MainResultsofNeedleBench8K.
In NeedleBench 8K, we observe a general upward trend in scores with increasing model
parameters,withQwen-1.5-72B,themodelwiththelargestnumberofparameters,achieving
the highest score of 90.65. The InternLM2 series, however, does not maintain a leading
position,primarilyduetonoticeableissueswithcommandfollowinginMulti-Retrieval
tasks (recalling only a single needle instead of multiple needles as per the command).
19
erocS
llarevOTechnicalReport
Amongmodelswithlessthan7Bparameters,ChatGLM3-6Bscoresthehighestwithinthe
8KlengthandcloselytrailsbehindQwen-1.5-72Binperformance.
Model Performance Comparison on Needlebench 8K
100
Single-Needle Retrieval
Multi-Needle Retrieval
Multi-Needle Reasoning >20B Params
80 7-20B Params
0-7B Params: Aver. Score
60
40
20
0
Ge Zm em pa h- y2 r-B 7B IB ntet era nLM-7B Qw Qe wn- e7 n-B 1.5-0. G5 eB m Cm ha- a Mit7 stGB rL alM -3 7- B6 IB ns Qt. wv e0 n. -2 1.5- Q I1. nw t8 e eB n r- n1 L.5 M- 24 -B 7B- I2 nt0 e C0 r hnK aL tGM L2- M7 3B -6B I- nt3 e2 Q rK nw Len M- 21 -4 2B 0 IB- nt2 Qe0 r w0 n eLK n-M 12 .- O5 r2 - i0 1 oB 4 n-B 1-v 4L B-L LM Qon w Mg e in xC t-h r7a alt 2 -B 8- xv 7 QL BL
w
I eM n n-st 1. . 5v -0. 71 2B-vLLM
Figure14: ModelperformancecomparisononNeedleBench8K
Qwen-14B InternLM2-20B InternLM2-20B
0 Overall Score:62.01   6 L Q J O H  5 H W U L H Y D O  2 Y H U D O O  6 F R U H           0 X O W L  5 H D V R Q L Q J  2 Y H U D O O  6 F R U H       100
10      
21       80
31      
42       60
52      
63       40
73      
84       20
94      
5k 6k 7k 8k   N   N   N   N   N   N   N   N 0
Token Length  7 R N H Q  / H Q J W K  7 R N H Q  / H Q J W K
Qwen-1.5-14B InternLM2-20B Orion-14B-LongChat
0 Overall Score:77.27    0 X O W L  5 H W U L H Y D O  2 Y H U D O O  6 F R U H          0 X O W L  5 H W U L H Y D O  2 Y H U D O O  6 F R U H       100
10      
21       80
31      
42       60
52      
63       40
73      
84       20
94      
5k 6k 7k 8k   N   N   N   N   N   N   N   N 0
Token Length  7 R N H Q  / H Q J W K  7 R N H Q  / H Q J W K
Figure15: SelectiveVisualizationResultsinNeedleBench8K:InternLM2-20Bmodelexcels
in Single-Retrieval, but shows a significant decline in Multi-Retrieval due to command-
followingissues,whiledemonstratingstrongEnglishMulti-Reasoningabilities. Orion-14B-
LongChatachievesthehighestscoreofthe7-20Bmodelswithitsoutstandingperformance
intheMulti-RetrievalTask.
20
)%(tnecreP
htpeD
)%(tnecreP
htpeD
erocS
llarevO
    W Q H F U H 3  K W S H '
    W Q H F U H 3  K W S H '
    W Q H F U H 3  K W S H '
    W Q H F U H 3  K W S H '
erocS
erocSTechnicalReport
C NeedleBenchPromptExamples
Single-NeedleRetrieval(NeedleFirst-DemonstrationwithEnglishVersion)
Prompt:
You are an intelligent AI assistant skilled in answering user questions base on
documentsprovidedbytheuser. Pleasekeepyouranswersconciseandclear. Do
nottalkaboutirrelevanttopicsorrepeatyouranswers.Thedocumentgiventoyou
bytheuseris:
HiddenonEmeraldIslandisthelegendaryStardustShard.
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGraham
Essays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚Äî
PaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul
Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham
Essays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
Now,thequestionis: WhatlegendaryitemishiddenonEmeraldIsland? Before
answering,pleaseconsiderwhatinthedocumentismostrelevanttothisquestion.
Pleaseanswerintheformat‚ÄôThelegendaryitemhiddenontheEmeraldIslandis
‚Äô
Figure16: AnexamplepromptofSingle-NeedleRetrievalshowcasingkeyinformationwith
thesingleneedlepositionedattheverybeginning. Inactualtests,theneedleisplacedat
variousdepthswithinextendedtextstoevaluateperformanceunderdifferentconditions.
Single-NeedleRetrieval(NeedleMiddle-DemonstrationwithEnglishVersion)
Prompt:
You are an intelligent AI assistant skilled in answering user questions base on
documentsprovidedbytheuser. Pleasekeepyouranswersconciseandclear. Do
nottalkaboutirrelevanttopicsorrepeatyouranswers.Thedocumentgiventoyou
bytheuseris:
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGraham
Essays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚Äî
PaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
HiddenonEmeraldIslandisthelegendaryStardustShard.
‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul
Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham
Essays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
Now,thequestionis: WhatlegendaryitemishiddenonEmeraldIsland? Before
answering,pleaseconsiderwhatinthedocumentismostrelevanttothisquestion.
Pleaseanswerintheformat‚ÄôThelegendaryitemhiddenontheEmeraldIslandis
‚Äô
Figure17: AnexamplepromptofSingle-NeedleRetrievalshowcasingkeyinformationwith
thesingleneedlepositionedatthemiddle
21TechnicalReport
Single-NeedleRetrieval(NeedleLast-DemonstrationwithEnglishVersion)
Prompt:
You are an intelligent AI assistant skilled in answering user questions base on
documentsprovidedbytheuser. Pleasekeepyouranswersconciseandclear. Do
nottalkaboutirrelevanttopicsorrepeatyouranswers.Thedocumentgiventoyou
bytheuseris:
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGraham
Essays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚Äî
PaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul
Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham Essays‚Äî ‚ÄîPaul Graham
Essays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
HiddenonEmeraldIslandisthelegendaryStardustShard.
Now,thequestionis: WhatlegendaryitemishiddenonEmeraldIsland? Before
answering,pleaseconsiderwhatinthedocumentismostrelevanttothisquestion.
Pleaseanswerintheformat‚ÄôThelegendaryitemhiddenontheEmeraldIslandis
‚Äô
Figure18: AnexamplepromptofSingle-NeedleRetrievalshowcasingkeyinformationwith
thesingleneedlepositionedatlast
Multi-NeedleRetrieval(DemonstrationwithFiveNeedlesEnglishVersion)
Prompt:
You are an intelligent AI assistant skilled in answering user questions base on
documentsprovidedbytheuser. Pleasekeepyouranswersconciseandclear. Do
nottalkaboutirrelevanttopicsorrepeatyouranswers.Thedocumentgiventoyou
bytheuseris:
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
TherulerofthePolarisstarsystemisOriontheHunter.
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
HiddenonHeavenIslandisthelegendaryLuckyClover.
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
HiddenonMysteriousIslandisthelegendaryCounterclockwiseCrystal.
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
TheruleroftheOrionstarsystemisGuardianofTimeLightspeed.
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
HiddenonPhantomIslandisthelegendaryGoodnessHeart.
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
Now,thequestionsare: WhoistherulerofthePolarisstarsystem?,Whatlegendary
itemishiddenonHeavenIsland?,WhatlegendaryitemishiddenonMysterious
Island?,WhoistheruleroftheOrionstarsystem?,Whatlegendaryitemishidden
onPhantomIsland?Beforeanswering,pleaseconsiderwhatinthedocumentismost
relevanttothisquestion. Pleaseanswerintheformatof‚ÄôTherulerofthePolaris
starsystemis ,ThelegendaryitemhiddenontheHeavenIslandis ,The
legendaryitemhiddenontheMysteriousIslandis ,TheruleroftheOrionstar
systemis ,ThelegendaryitemhiddenonthePhantomIslandis ‚Äô
Figure19: AnexamplepromptofMulti-NeedleRetrieval
22TechnicalReport
Multi-NeedleReasoning(DemonstrationwithThreeNeedlesEnglishVersion)
Prompt:
You are an intelligent AI assistant skilled in answering user questions base on
documentsprovidedbytheuser. Pleasekeepyouranswersconciseandclear. Do
nottalkaboutirrelevanttopicsorrepeatyouranswers. Thedocumentgiventoyou
bytheuseris:
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
TheLoveforThreeOrangesisknownasL‚Äôamourdestroisoranges.
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
TheLoveforThreeOrangesisasatiricaloperabySergeiProkofiev.
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
SergeiProkofievdiedon5March1953.
‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî‚ÄîPaulGrahamEssays‚Äî
Now, the question is: When did the Soviet composer of French language title
L‚Äôamour des trois oranges die? Before answering, please consider what in the
documentismostrelevanttothisquestion.
Figure20: AnexamplepromptofMulti-NeedleReasoning
23TechnicalReport
AncestralTraceChallenge(4-shotSix-StepExampleswithoutReasoningPaths)
Few-shotPrompt1:
Question:DavidHouse,asJessicaStewart‚Äôsfather,hasasignificantimpactonJessica
Stewart‚Äôsupbringing. Giventhescrambledfamilyrelationshipsdescribedabove,
whoistheeldestrelativethat‚ÄôJessicaStewart‚Äôcantracebacktointhecontext?
A.JackBurch
B.JessicaStewart
C.DavidHouse
D.CarolynJackson
BotResponse:
Answer: C
Few-shotPrompt2
Question:ForRobertaHill,MichaelScottisnotjustapaternalgrandfather,butalsoa
friend. JacobOconnor‚ÄôspaternalgrandmotherisRobertaHill. Giventhescrambled
familyrelationshipsdescribedabove,whoistheeldestrelativethat‚ÄôJacobOconnor‚Äô
cantracebacktointhecontext?
A.LauraHolland
B.RobertaHill
C.JacobOconnor
D.MichaelScott
BotResponse:
Answer: D
[...Continuewithotherfew-shotexamples...]
FinalChallengeQuestion:
Question: Victoria Dean is not only Danielle Yates‚Äôs maternal grandmother but
alsoDanielleYates‚Äôsrolemodel. CarlosSmith,asMartinGary‚Äôsgrandfather,has
asignificantimpactonMartinGary‚Äôsupbringing. VictoriaDeanconsidersMartin
Garyastheirgrandfather. MarcusMiller,asCarlosSmith‚Äôspaternalgrandfather,has
asignificantimpactonCarlosSmith‚Äôsupbringing. DanielleYatesisnotonlyDavina
Hernandez‚ÄôspaternalgrandmotherbutalsoDavinaHernandez‚Äôsrolemodel.Davina
HernandezisJenniferWilliams‚Äôsmom. Giventhescrambledfamilyrelationships
describedabove,whoistheeldestrelativethat‚ÄôJenniferWilliams‚Äôcantracebackto
inthecontext?
A.MarcusMiller
B.CarlosSmith
C.MartinGary
D.VictoriaDean
ExampleAnswerfromGPT4-Turbo:
Answer: A
Figure21:Examplesof4-shotpromptsandresponsesintheAncestralTraceChallenge(ATC)
withoutreasoningpathsforsix-steplogicrelations
24TechnicalReport
AncestralTraceChallenge(4-shotSix-StepExampleswithReasoningPaths)
Few-shotPrompt1:
Question:DavidHouse,asJessicaStewart‚Äôsfather,hasasignificantimpactonJessica
Stewart‚Äôsupbringing. Giventhescrambledfamilyrelationshipsdescribedabove,
whoistheeldestrelativethat‚ÄôJessicaStewart‚Äôcantracebacktointhecontext?
A.JackBurch
B.JessicaStewart
C.DavidHouse
D.CarolynJackson
BotResponse:
Answer: Basedontheprovidedinformation,wecanconstructthefollowingfamily
relationshipchain:
-DavidHouse,asJessicaStewart‚Äôsfather,hasasignificantimpactonJessicaStewart‚Äôs
upbringing.
Therefore,theeldestrelativethat‚ÄôJessicaStewart‚Äôcantracebacktointhecontextis
DavidHouse. Theansweris: C
[...Continuewithotherfew-shotexamples...]
FinalChallengeQuestion:
Question: CarlosSmith,asMartinGary‚Äôsgrandfather,hasasignificantimpacton
MartinGary‚Äôsupbringing. VictoriaDeanconsidersMartinGaryastheirgrandfather.
VictoriaDeanisnotonlyDanielleYates‚ÄôsmaternalgrandmotherbutalsoDanielle
Yates‚Äôsrolemodel. DanielleYatesisnotonlyDavinaHernandez‚Äôspaternalgrand-
motherbutalsoDavinaHernandez‚Äôsrolemodel. MarcusMiller,asCarlosSmith‚Äôs
paternalgrandfather,hasasignificantimpactonCarlosSmith‚Äôsupbringing. Davina
HernandezisJenniferWilliams‚Äôsmom. Giventhescrambledfamilyrelationships
describedabove,whoistheeldestrelativethat‚ÄôJenniferWilliams‚Äôcantracebackto
inthecontext?
A.MarcusMiller
B.CarlosSmith
C.MartinGary
D.VictoriaDean
ExampleAnswerfromGPT4-Turbo:
Answer: Basedontheprovidedinformation,wecanconstructthefollowingfamily
relationshipchain:
-DavinaHernandezisJenniferWilliams‚Äôsmom.
- Danielle Yates is not only Davina Hernandez‚Äôs paternal grandmother but also
DavinaHernandez‚Äôsrolemodel.
-VictoriaDeanisnotonlyDanielleYates‚ÄôsmaternalgrandmotherbutalsoDanielle
Yates‚Äôsrolemodel.
-VictoriaDeanconsidersMartinGaryastheirgrandfather.
- Carlos Smith, as Martin Gary‚Äôs grandfather, has a significant impact on Martin
Gary‚Äôsupbringing.
-MarcusMiller,asCarlosSmith‚Äôspaternalgrandfather,hasasignificantimpacton
CarlosSmith‚Äôsupbringing.
Therefore,theeldestrelativethat‚ÄôJenniferWilliams‚Äôcantracebacktointhecontext
isMarcusMiller. Theansweris: A
Figure22:Examplesof4-shotpromptsandresponsesintheAncestralTraceChallenge(ATC)
withreasoningpathsforsix-steplogicrelations
25