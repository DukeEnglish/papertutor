A Picture Is Worth a Graph: Blueprint Debate on Graph for
Multimodal Reasoning
ChangmengZheng DayongLiang WengyuZhang
csczheng@comp.polyu.edu.hk ft_ldy@mail.scut.edu.cn wengyu.zhang@connect.polyu.hk
TheHongKongPolytechnic SouthChinaUniversityofTechnology TheHongKongPolytechnic
University University
Xiao-YongWeiâˆ— Tat-SengChua QingLi
x1wei@polyu.edu.hk dcscts@nus.edu.sg qing-prof.li@polyu.edu.hk
TheHongKongPolytechnic NationalUniversityofSingapore TheHongKongPolytechnic
University University
ABSTRACT ofsemantics,includingbearsedge,earthworm,collaredlemming,
Thispaperpresentsapilotstudyaimedatintroducingmulti-agent andothers.Asaconsequence,thiscanresultinthecontextand
debateintomultimodalreasoning.Thestudyaddressestwokey summarybeingtrivialized,shiftingtheemphasisfromlichentoa
challenges:thetrivializationofopinionsresultingfromexcessive moregeneralizedconceptofthetundraecosystem,whereinboth
summarizationandthediversionoffocuscausedbydistractorcon- bilberryandmushroomexhibitahighdegreeofcorrelation.Similar
cepts introduced from images. These challenges stem from the issueexistswhenMADisemployed,wherethesummarizercon-
inductive (bottom-up) nature of existing debating schemes. To cludesthediversesemanticsintogeneralwordslikeecosystemand
address the issue, we propose a deductive (top-down) debating foodweb,makingtheconclusionlessspecific.Inaddition,MAD
approach called Blueprint Debate on Graphs (BDoG). In BDoG, mayencountertheissueoffocusdiversion,whichoccurswhen
debatesareconfinedtoablueprintgraphtopreventopiniontrivi- Chain-of-Thoughts(CoT)isutilizedandnewconceptsintroduced
alizationthroughworld-levelsummarization.Moreover,bystoring arehighlycorrelatedwithaparticularconcepts(e.g.,mathematical
evidenceinbrancheswithinthegraph,BDoGmitigatesdistractions model[5]),leadingtoanincreasedweightingofthatconceptwithin
causedbyfrequentbutirrelevantconcepts.Extensiveexperiments thecontext.
validateBDoG,achievingstate-of-the-artresultsinScienceQAand Wearguethatthesechallengesariseduetotheinductivenature
MMBenchwithsignificantimprovementsoverpreviousmethods. ofexistingdebatingschemes,whereinagentopinionsaregathered
fromdisparateconceptsatword-levelandconsensusisachieved
1 INTRODUCTION throughbottom-upsummarization.Thisapproachmaybeeffective
inconfinedNLPtasks[8,9],wherethetopicisoftenlimitedto
Multimodalreasoningdependsontwokeyaspects:thecreation
asmallnumberofconceptsandtheapplicationofCoTremains
ofaunifiedrepresentationofsemanticsfromdifferentmodalities
constrained.However,inamultimodalscenario,certainmodalities
andtheintegrationofthesediversesemanticswhileensuringlogi-
(e.g.,images)areinformation-richandhaveahigherlikelihoodof
calconsistency.Whiletheadvancementinlargelanguagemodels
introducingdistractingconcepts[20].Consequently,itincreases
(LLMs)hasmadeitpossibletorepresentthesemanticsinnatu-
thesemanticdivergencewithinthecontextandthelikelihoodof
rallanguages[1],theintegrationofdiversesemanticsremainsa
trivialization.Thesemanticdivergenceincreasesfurtherwhenthe
challengingissue,eveninexclusiveNLPtasks.Oneapproachto
impactsofthoseconceptsareamplifiedthroughCoT,particularly
tacklethischallengeismulti-agentdebate(MAD),wheremultiple
whenthenewlyintroducedconceptsexhibitbiasestowardscertain
LLMsactasagents,eachcontributingtheirownperspectiveson
concepts,resultinginfocusdiversion.
thetargettopicandreachingaconsensusthroughdebates[4,16].
Toaddressthisissue,weproposeandeductivereasoningscheme
ThisschemecouldbeadoptedbyincorporatingaspecificLLMfor
called Blueprint Debate on Graph (BDoG, pronounced bee-dog).
eachmodalityasanagent.
BDoGisinspiredbytheblueprintdebatethathasbeenwidelyem-
Despitebeingrelativelyunexploredinthemultimodaldomain,
ployedinreal-worlddebates,whichdistinguishesitselffromother
MADencountersnumerouschallengesinabroadercontext.MAD
debatesbyitsconcentrationonevaluatingandrefiningaproposal
maysufferfromthetrivializationofopinions,whichisaresultof
(e.g.,blueprint)toaddressspecificchallengesorissues.BDoGbe-
thesummarizationstepperformedattheconclusionofeachdebat-
ginsbyaggregatingconceptsfrommodalitiesandincorporating
inground.Theobjectiveofthisstepistoseekagreementamong
withtheirrelationshipsintoainitialgraph.Thisgraphservesas
theparticipatingagentsregardingtheiropinions.Consequently,
ablueprintthatconfinesthescopeofthediscussionratherthan
thisprocesscanleadtothedebateâ€™sfocusbeingdirectedtowards
havingitopentoirrelevantsemanticsasinexistingschemes.More
ageneralconcept,servingasanadaptationtoaccommodatethe
importantly,BDoGconductsthedebateinatop-downmannerby
diverserangeofsemantics.Oneexamplecanbeobservedinthe
markingdownconclusionsonthegraph.Thispreventstrivializa-
reasoningoftheMultimodalLanguageModel(MLLM)depicted
tionasspecificconceptsarepreservedratherthanmergedinto
inFigure1,wheretheimagemodalitypresentsadiverserange
generalones.ThiscanbefoundfromtheexampleshowninFigure
1,wherethescopeislimitedtothetundraecosystemwhilespecific
âˆ—CorrespondingAuthor
4202
raM
22
]IA.sc[
1v27941.3042:viXraChangmengZheng,DayongLiang,WengyuZhang,Xiao-YongWei,Tat-SengChua,andQingLi
Input MAD BDoG
W coh ni tc ah
in
o sf
m
th ae tts ee
r
o tr hg aa tn wis am
s
s ( (A B))B Mil ub se hr rr oy
om
A- f- f- ir- m--- a- t- iv-- e-- S- i- d- eF :irst-roundDebate-------------- B-- l- u- e- p-- r- i- n- t- :-----DebateInitializ ea art ti ho won rm-------------
once part of the lichen? The lichen is at the bottom of the food web, so caribou lemming
the matterâ€¦Therefore, all of these organisms eateat decomposedecompose
c No en gt aa ti in vâ€¦ eSide: C byonsumed p or ney eal tichen preyo en at a forc xtic
The lichen is eaten by the lemming, â€¦the lichen mushroom bilberry
bear
will be found in the lemming,â€¦.
----------------First-roundDebate--------------
Summarizer: AffirmativeGraph: NegativeGraph:
The debate solution is correct inâ€¦The matter
t d bh i afa lf at e nrw e ca ens ,t a. o. ne r dgco a â€¦ns ,y i iss tmt ce asm .
n
T a hhn aed
v
f
e
ois ao u d rs
i
pe wd pe lb b
e
y ei sm
f
fa ea d cn tey l
o
ic na tt he
e I ds
es coo mil
posed
car Ii sbo eu atenIse ba et ae rnby g n fre u ot t ms rient cs ons to ai il
n
ca Isri eb ao tu enI bs yeaten
entire system. (TrivializationofOpinion). into by by bear
Baselines ---------------Second-roundDebate------------ lichen mushroom d lice hc eo nmposed lichen
MLLM: AffirmativeSide: ---------------Second-roundDebate------------
We could use a mathematical model to track the
B mo at th tet rh e th b ai tl b we arr sy o a nn cd e t ph ae r tm ou f s th hr eo lo icm he c no .ntain movement of matterâ€¦ AffirmativeGraph: NegativeGraph:
NegativeSide: mushroom lichen mushroom lichen
MLLM-CoT:
Rationale:The image shows a food relation Humansare a part of the ecosystem, and they contains contains
between several animals and plants in a tundra can have a significant impact on the movement ----------------DebateTermination--------------
ecosystemâ€¦ The lichen is a composite organism of matter through the ecosystemâ€¦ BlueprintDebate-on-Graph:
that consists of a fungus and an alga. The fungus Summarizer: Rationale:The lichen is decomposed into soil.
provides the physical structure of the lichen, We could use a combinationof mathematical The mushroom gets its nutrients from the soil.
while the alga provides the food for the fungus.. modeling and experimentation to track the Sothe mushroom contains matter that was once
(FocusDiversion) movement of matter throughâ€¦(FocusDiversion) part of the lichen.
Answer:Botharecorrect. Answer:(A)bilberry. Answer:(B)mushroom
Figure1:ComparisonresultsfromScienceQAdatasetofdirectanswerfromMLLM,MultimodalChain-of-Thought(CoT),
Multi-agentDebate(MAD)andOurBlueprintDebateonGraph(BDoG).
conceptslikemushroomandlichenareretained.Furthermore,the sub-questionstoenabledeep-layerreasoning.SCITUNE[10]and
graphprovideacompactandhigh-levelguidanceforthediscussion T-SciQ[30]aimtoteachlargelanguagemodelstoanswerscience
process.Thenewlyintroducedconceptsareincorporatedintorele- questionsviathegenerationofmixedrationalesderivedfromboth
vantbranchesinsteadofremainingasaword-levelthoughtswithin largepretrainedmodelsandhumanannotators.Chameleon[21]
thecontext.Thisreducesthelikelihoodoffocusdiversionsince, accomplishescomplexmultimodalreasoningtasksbyintegrating
inDBoG,thecompetitionofsemanticsoccursatthebranchlevel variousexternaltools(e.g.,largelanguagemodels,off-the-shelf
ratherthanthewordlevel.ThiscanbeseenfromFigure1,where vision models, and web search engines). Nevertheless, existing
themostrelevantbranchesrelatedtothesoilandcariboustandout methods exhibit limitations as they heavily rely on either few-
fromthecompetition,eliminatingtheirrelevantsemantciseffec- shotlearningorsupervisiontoâ€œguideâ€thereasoningprocess.In
tively.Inadditiontotheadvantagesofscope-confinedguidance ordertoovercomethisdependency,weproposetheincorporation
andbranch-levelcompetition,BDoGalsoincreasesexplainability, ofdebatingfeaturesintoourmethod.Thisenablestheagentsto
allowingforthetrackingofdiscussionprogress.Thisisevidentin engageinanadversarialdiscussion,allowingthemtoâ€œfigureoutâ€
Figure1,inwhichtheprogressofdebatingismoreunderstandable thecorrectdirectionautonomously.Asaresult,ourapproachmakes
thanword-levelreasoning(i.e.,MLLM-CoTorMAD). zero-shotlearningfeasiblebyreducingtherelianceonexternal
guidanceorsupervision.
2 RELATEDWORKS
2.2 Multi-agentDebate
2.1 MultimodalReasoning
TomitigatethesusceptibleerrorinCoTreasoning,Shinnetal.[26]
Multimodalreasoningisacrucialcomponentinthedevelopment andMadaanetal.[22]employmodeltoreflectontaskfeedback
ofadvancedartificialintelligence(AI)systemsthataimtoreplicate signalsthatcaninducebetterdecision-makinginsubsequenttrials.
human-likeintelligence[20].ThistypeofreasoningenablesAI [39]exploitpreviouslygeneratedanswerashinttoprogressively
systemstoprocessandanalyzeinformationfromvarioussources guidetowardscorrectanswer.Althoughthesemethodseffectively
andforms,suchastext,images,audio,andvideo,inaintegratedand enhancetheperformanceofLLM,theystruggletoproducenovel
coordinatedmanner[3,25].Thelatestadvancementsinmultimodal ideasoncetheyhavedeterminedaresponse,astheyrelysolely
largelanguagemodels,suchasBLIP2[14],KOSMOS[13]andLLaVA oninternalrepresentationsforgeneration[12].Researchersare
[18]havedemonstratedsignificantprogressincomplexreasoning, currentlydevelopingmulti-agentcollaborativesystemstoaddress
asthesemodels[38]nowhavethecapabilitytogeneratestep-by- aboveissuesinpure-textualscenarios[36].Bydesigningthesesys-
step rationalesprior toproducing the finalanswer, following a tems,largelanguagemodels(LLMs)canworktogethertocomplete
chain-of-thought(CoT)manner.Zhengetal.[40]proposeaduty- tasksorengageinproductivedebatesbyofferingcontrastingper-
distinctpromptingmethodwhereinquestionsaredecomposedinto spectives[4,7,16].Zhangetal.[37]furtherrevealthecollaborationAPictureIsWorthaGraph:BlueprintDebateonGraphforMultimodalReasoning
mechanismfromasocialpsychologyview.Thispaperrepresents steps.Contrarytopriorworkonconversationalagents,Zhenget
aninitialendeavortoexpanduponthismethodtofacilitatemul- al.[40]employtheinstructionpleasedecomposethequestionse-
timodalreasoning.Byincorporatingmultipleperspectivesfrom quentiallyintonecessarysub-inquiriestoacquirethesub-question
differentmultimodallanguagemodels,wecanhelpaddresssome sequenceğ‘„ 1,ğ‘„ 2,...,ğ‘„ ğ‘¡ inasingleinteraction.Withinthisframe-
ofthelimitationsofindividualmodels.Moreover,weaddressthe work,thefinalresponseğ´isobtainedbyaggregatingtheanswers
trivializationofopinionsandfocusdiversionproblemsofvanilla ğ´ ğ‘– toeachsub-questionğ‘„ ğ‘– andthegeneratedCoTrationaleğ‘… ğ‘–.
multi-agentdebateviaBlueprintDebateonGraph(BDoG). Self-Correction.Self-correctiontechniques[34]endeavortoitera-
tivelyenhancemodelpredictionsbyleveragingfeedbackgenerated
2.3 Graph-augmentedLLMs
fromthemodelitself.Inparticular,afeedbackfunctionğ‘“ :ğ‘…â†’ğ‘…â€²
isadoptedtoiterativelymapmodeloutputstotherefinedresponses.
Priorresearchhasinvestigatedtheintegrationofstructuredgraphs,
MAD.Multi-agentDebate[16]presentsapromisingframework
suchasknowledgegraphs(KGs),intolargelanguagemodels(LLMs)
that fosters discursive exchange and cross-pollination of ideas
byembeddingtheknowledgeintotheunderlyingneuralnetworks
betweenconversationalmodels.Consideradebatecomprising ğ‘—
[17,32].Nevertheless,embeddingKGswithinLLMsmaycompro-
roundsamongstasetoflargelanguagemodelsactingasinterlocu-
misetheinherentexplainabilityandadaptabilityassociatedwith tors.Ineachround,Theproponent generatesarationaleğ‘… ğ‘â€² and
knowledgereasoningandupdating[11].Totacklethesechallenges,
responseğ´ ğ‘ revisedinlightoftherationalesğ‘… ğ‘œ presentedbythe
recentstudieshaveputforthinnovativesolutions.Lietal.[15]
opponentinpriorturns.
proposedanadaptivequerygenerator,facilitatingthecreationof
queriesacrossvariousquerylanguages(e.g.,SPARQL)toinferratio-
4 BLUEPRINTDEBATEONGRAPH
nales.Wangetal.[29]devisedastructuredmulti-roundquestion-
answering(QA)format,whichextractsexternalknowledgeand Inthissection,weintroduceBlueprintDebate-on-Graph(BDoG).
generatescoherentreasoningtracesgroundedinpreciseanswers. AsillustratedinFigure2,BDoGtakesadeductiveapproachinstead
Sunetal.[27]introducedThink-on-Graph(ToG),amethodthat ofinducinganswersfromword-levelthoughts.Itutilizesgraphs
sequentiallyreasonsoverKGstolocaterelevanttriples,thereby tostructuretheopinionsandproposalsprovidedbyagents.This
supporting the LLM in predicting the final answer. In the con- graph-levelstructuringofthedebatingcontexthelpsminimizeopin-
textofmultimodalreasoning,CCoT[23]substitutestherationale iontrivializationandfocusdiversion.Furthermore,BDoGadopts
generationprocesswithscenegraphextractiontoenhancethecom- antop-downapproachwhichimprovesmultimodalreasoningby
positionalcapabilitiesoflargemultimodalmodels.KAM-CoT[24], iterativelyrefininganinitialproposal,representedasablueprint
ontheotherhand,incorporatesexternalKGsduringthetwo-stage graph.Thisintegratesopinionsfromdiverseperspectivesthrough
trainingprocess,yieldingstate-of-the-artfine-tuningoutcomesin thecompetitionandcooperationamongmultipleagents.
multimodalreasoning.Incontrasttoexistingmethodsthatutilize
ThedebatingprogressofBDoGattheğ‘–ğ‘¡â„
roundcanbeformu-
staticgraphs,ourproposedBDoGpreservesthedynamicsandpre- latedasaquadruple
cisionofKGsthroughiterativeupdatesofentities,attributes,and Tğ‘– =(Gğ‘–,S,A,F) (1)
relationships,guidedbyablueprintdebateprocess.
where,givenamultimodalsourcesetS = {ğ‘„,ğ¼,ğ¶},thedebating
isconductedamongasetofagentsA = {ğ‘ ğ‘—},ğ‘— âˆˆ Z+,inwhich
3 PRELIMINARY
eachagentcanuseoperationsfromthesetofF ={ğ‘“ ğ‘˜},ğ‘˜ âˆˆZ+to
Webeginbyoutliningexistingapproachesfortacklingthemul- propose/summarizeopinionsbyrefiningthegraph-of-thoughtsGğ‘– .
timodalreasoningproblem.Figure2showsthespecificdistinct Attheendoftheğ‘–ğ‘¡â„ round,Gğ‘– isupdatedtoGğ‘–+1toinitiatethe
amongthem.Formally,givenaquestionğ‘„consistingofğ‘¡ tokens, nextround.
ourgoalistoidentifythecorrectanswerğ´fromasetofcandidate
answers.Inthecontextofmultimodalreasoning,theexpectedan- 4.1 BlueprintG0 Initialization
swerisintendedtobeinferredbasedonavisualcontextğ¼ anda
Toinitiatethedebating,weneedtoconvertthemultimodalsources
textualclueğ¶,inadditiontothequestionitself.
intoablueprintgraph.Thisconversionisachievedthroughthe
V anan anil sl wa eP rr ğ´om bypt ai un gg m. eV na tn inil gla tp hr eo im npp uti tn wg ia thpp ilr lo ua sc trh ae ts iva eim ext ao mp pr le ed si ğ·ct o twpe or aa dti do in tiofu nn ac lt si uon b-ğ‘“ f0 unâˆˆ ctF ion: sS
ğ‘“
ğ‘¡â†¦â†’ anG d0 ğ‘“. ğ‘£T fo oi rm ep xl te ram ce tin nt gğ‘“ 0 e, nw tie tied sefi ann de
inadditiontothequestionğ‘„,visualcontextğ¼,andtextualclueğ¶.
relationsfromthetextualsources(i.e.,ğ‘„andğ¶)andvisualsource
MultimodalCoT.AsnotedbyLuetal.[20],incorporatingin- (i.e.,ğ¼),respectively.Theimplementationofğ‘“ 0isformulatedas
termediatereasoningsteps(rationales)canaidinpredictingthe
correctanswer,especiallyforcomplexmultimodalreasoningtasks. ğ‘“ 0: Sâ†¦â†’G0
Toaddressthis,wefirstgeneratearationaleğ‘…={ğ‘Ÿ 1,ğ‘Ÿ 2,...,ğ‘Ÿ ğ‘˜}given ğ‘“ ğ‘¡(ğ‘„)âˆªğ‘“ ğ‘£(ğ¼)âˆªğ‘“ ğ‘¡(ğ¶)â†¦â†’âŸ¨V0,E0âŸ©
theinput.Thegeneratedrationaleğ‘…isthenconcatenatedwiththe
ğ‘¤.ğ‘Ÿ.ğ‘¡ ğ‘†ğ‘–ğ‘§ğ‘’, ğ‘…ğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’ (2)
originallanguageinputtoupdatethelanguagerepresentation.This
augmentedlanguageinputisfedtogetherwiththeoriginalvisual whereâˆªdenotestheunionoftwosetsofgraphs.The2constraints
inputğ¼ intothesamemodeltoinferthefinalanswer. are as follows: 1) Size Constraint: The size of G0 needs to be
DDCoT.TheDuty-DistinctChainofThoughtframeworkproposes restrictedwithinaspecificrangetopreventanexcessivenumber
anovelapproachfordeconstructingquestionsintofundamental ofcluesthatcoulddistracttheinferenceoraninsufficientnumber
sub-questions,similartobreakingdownreasoningintoelementary toanswerthequestioneffectively.2)RelevanceConstraint:WeChangmengZheng,DayongLiang,WengyuZhang,Xiao-YongWei,Tat-SengChua,andQingLi
ğ‘„,ğ¼,ğ¶ ğ‘„,ğ¼,ğ¶ ğ‘„,ğ¼,ğ¶ ğ‘„,ğ¼,ğ¶ ğ‘„,ğ¼,ğ¶
Deconstruct Proponent Opponent Blueprint
Initialization
Debate
ğ‘„ 1 ğ‘„ 2 ğ‘„ 3 ğ‘… ğ‘… ! ğ‘… # Prop. ğº Oppo.
Refine Refine
ğ‘… Refine
Debate Debate
ğ‘…
1
ğ‘…
2
ğ‘…
3
ğ‘… !" ğ‘… #" ğº$ ğº%
ğ‘…â€²
ğ´ 1 ğ´ 2 ğ´ 3 ğ´ ! ğ´ # ğºâˆ— Refine
ğ´ ğ´ ğ´ ğ´ ğ´
(a)CoT (b)DDCoT (c)Self-Correction (d)MAD (e)BDoG
Figure2:ComparisonofCoT,Duty-DistinctCoT(DDCoT),Self-Correction,Multi-agentDebate(MAD)andOurproposed
BlueprintDebateonGraph(BDoG).Q:inputquestion,I:inputimage,C:contextorhint,A:answer,R:rationale,G:blueprint.
shouldmergetherelationshipsextractedfromğ¼ andğ¶ towards ourfocusliesondiscussingtheseguidingprinciplesandconstraints.
thoseofthequestionğ‘„,ensureingalltheknowledgeencapsulated OurpromptimplementationswillbeprovidedinAppendix.
inG0isrelevanttothequestion.
Extensivelibrariesareavailableforğ‘“ ğ‘¡ andğ‘“ ğ‘£,astheyhavebeen 4.2 AgentsandRoles
extensivelyresearched(e.g.,namedentityrecognition,relationex-
Inthedebate,wecantreateachLLMasanagentthatparticipates
tractionforğ‘“ ğ‘¡,imagecaptioning,visualgroundingforğ‘“ ğ‘£).However,
inthediscussionbyrefiningtheblueprintgraphG0.Justlikeina
the recent advancements in multimodal large language models
realdebate,eachagentğ‘ ğ‘— âˆˆAhasadistinctroleassigned.Wede-
(MLLM)havemadeitconvenienttoimplementthesesub-functions
finethreerolesasasetofR ={ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡,ğ‘‚ğ‘ğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡,ğ‘€ğ‘œğ‘‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘œğ‘Ÿ}.
usingin-contextlearningbasedprompts.Forexample,toextend
Theserolesnotonlyhelpstructurethediscussionbutalsopro-
thequeryğ¼ inthecontext,wecanemployCoTtoimplementğ‘“ ğ‘¡ as
motecriticalthinkingandensureacomprehensiveandin-depth
ğ‘“ ğ‘¡(ğ‘„):Giventhequestion{Q},pleaseprovidethenecessarysteps
explorationofthetopic.
toanswerthisquestion.
Proponentagentsadvocateanddefendthecurrentblueprint
byrefiningcurrentGğ‘– intoanaffirmativeevidencegraphG+.A
wherethe{}denotestheplaceholderintheprompt.
Forğ‘“ ğ‘£(ğ¼),itsimplementationvariesdependingonLLMsused. debatingfunctionisassignedforthispurposeas
ForGPT-4,theimageneedstobeencodedinBase64format.Gem- ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡ ğ‘“+: Gğ‘– Ã—Sâ†¦â†’G+
iniutilizesPILforimageencoding.InstructBLIPoffersitsEVA-G
encodertoconverttheimageintoaneigenvector.Theğ‘“ 0canthen âŸ¨Vğ‘–,Eğ‘– âŸ©âˆªğ‘“ ğ‘¡(ğ‘„)âˆªğ‘“ ğ‘£(ğ¼)â†¦â†’âŸ¨V+,E+âŸ©
beimplementedas ğ‘¤.ğ‘Ÿ.ğ‘¡ ğ‘†ğ‘–ğ‘§ğ‘’, ğ‘…ğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’, ğ¶ğ‘œğ‘šğ‘ğ‘ğ‘ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘  (3)
ğ‘“ 0: Given the image{ğ‘“ ğ‘£(ğ¼)} andquestion {ğ‘“ ğ‘¡(ğ‘„)}, generate a
scenegraphwithevidencetoanswerthequestion.Pleaseensure Anexemplarimplementationis
adherencetofollowingconstrains:{ğ‘†ğ‘–ğ‘§ğ‘’},{ğ‘…ğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’}. ğ‘“ +:As{ğ‘ğ‘’ğ‘Ÿğ‘ ğ‘œğ‘›ğ‘ğ‘™ğ‘–ğ‘¡ğ‘¦},youareassignedasanaffirmativede-
baterandhavebeenprovidedwithanevidencegraph{Gğ‘–
}for
wheretwoexemplarconstraintsare
ğ‘†ğ‘–ğ‘§ğ‘’ :Thegraphmustnotbeempty.Pleaserestrictthemaximum
answeringthequestion{ğ‘“ ğ‘¡(ğ‘„)}relatedtotheimage{ğ‘“ ğ‘£(ğ¼)}.Try
toenhancethegraphbyincorporatingyourinsightstowards
numberofobjectsinthegraphto20.
anoptimalsolution.Pleaseensureadherencetofollowingcon-
ğ‘…ğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’ :Theobjectsandrelationswithinthegraphshould strains:{ğ‘†ğ‘–ğ‘§ğ‘’},{ğ‘…ğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’},{ğ¶ğ‘œğ‘šğ‘ğ‘ğ‘ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ }.
bepertinenttoaddressingthequestion.
Notethatwehaveincorporatedtheconclusionfrom[7,36]that
Itworthmentioningthatalthoughweprovidesomeexemplar theagentâ€™sunderstandingoftherolecanbeimprovedbyusing
implementationsoffunctionsandconstraints,theeffectivenessof
the{ğ‘ğ‘’ğ‘Ÿğ‘ ğ‘œğ‘›ğ‘ğ‘™ğ‘–ğ‘¡ğ‘¦}fortargetedpersonalityinjection.Furthermore,
promptscanvarysignificantlydependingontheMLLMused.The thepersonalitycanbetailoredtobespecific,suchasâ€œBen,ahigh
successofmultimodalreasoningreliesmoreonthedevelopmentof schoolstudentwithanimpressiveacademicrecordandrespected
guidingprinciplesforpromptingthemodelsandconstraintsforreg- bypeersforyourknowledgeandlogicalthinking.â€TheProponent
ularizingtheresultinggraph.Therefore,intherestofthissection, debateadherestotheSizeandRelevanceconstraintsdefinedin
Eq.(3),anditalsoincludestheCompactnessConstraint:TheAPictureIsWorthaGraph:BlueprintDebateonGraphforMultimodalReasoning
refinedgraphshouldbeasconciseaspossible,ensuringthatthe StoppingCriteria:Theconditiontoconcludethedebatecanbe
blueprintremainsfocused. determinedbyassessingthemodificationsmadetotheevidence
Opponentagentschallengeandpresentargumentsagainstthe graphcomparedtothepreviousroundas
blueprintG+byupdatingitintoanegativeevidencegraphGâˆ’ as (cid:13) (cid:13)Gğ‘–+1âˆ’Gğ‘–(cid:13) (cid:13)â‰¤ğœ– (6)
ğ‘‚ğ‘ğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡ ğ‘“âˆ’ : G+Ã—Sâ†¦â†’Gâˆ’
whereâˆ¥Â·âˆ¥isadistancemetricdefinedonthegraphs.Therationale
âŸ¨V+,E+âŸ©âˆªğ‘“ ğ‘¡(ğ‘„)âˆªğ‘“ ğ‘£(ğ¼)â†¦â†’âŸ¨Vâˆ’,Eâˆ’âŸ©
isthatwitheachsuccessfulroundofdebate,theevidencebecomes
ğ‘¤.ğ‘Ÿ.ğ‘¡ ğ‘†ğ‘–ğ‘§ğ‘’, ğ‘…ğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’, ğ¶ğ‘œğ‘šğ‘ğ‘ğ‘ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘  (4) moreconcise,leadingtothecondensationoftheevidencegraph.
Therefore,wecanquantifythemodificationbytallyingthenumber
Anexemplarimplementationis
ofentities(relations)thathavebeenupdatedandprunedas
ğ‘“ +:As{ğ‘ğ‘’ğ‘Ÿğ‘ ğ‘œğ‘›ğ‘ğ‘™ğ‘–ğ‘¡ğ‘¦},youareassignedasanegativedebater
and have been provided with an affirmative evidence graph
(cid:13) (cid:13)Gğ‘–+1âˆ’Gğ‘–(cid:13) (cid:13)=(cid:13) (cid:13)âŸ¨Vğ‘–+1,Eğ‘–+1âŸ©âˆ’âŸ¨Vğ‘–,Eğ‘– âŸ©(cid:13)
(cid:13)
{G+}foransweringthequestion{ğ‘“ ğ‘¡(ğ‘„)}regardingtheimage =(cid:13) (cid:13){Vğ‘–+1âˆ©Vğ‘– }(cid:13) (cid:13)+(cid:13) (cid:13){Eğ‘–+1âˆ©Eğ‘– }(cid:13)
(cid:13)
{ğ‘“ ğ‘£(ğ¼)}.Trytodetectpotentialflawsanddrawbacksofthegraph
andupdateitwithyourinsights.Pleaseensureadherenceto +(cid:13) (cid:13){Vğ‘– âˆ’Vğ‘–+1âˆ©Vğ‘– }(cid:13) (cid:13)+(cid:13) (cid:13){Eğ‘– âˆ’Eğ‘–+1âˆ©Eğ‘– }(cid:13) (cid:13). (7)
followingconstrains:{ğ‘†ğ‘–ğ‘§ğ‘’},{ğ‘…ğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’},{ğ¶ğ‘œğ‘šğ‘ğ‘ğ‘ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ }.
5 EXPERIMENTS
Theutilizationofthefunctions ğ‘“ + and ğ‘“ âˆ’ fostersanadversarial
5.1 BackboneModels
dynamicbetweentheProponentandOpponent,ensuringadiverse
andcomprehensivediscussion. Toevaluateitsperformanceandgeneralizability,wehaveimple-
Tofacilitatethedebating,Moderatoragentssynthesizesthe mentedBlueprintDebate-on-Graph(BDoG)usingdifferentpreva-
argumentsandopinionspresentedbyboththeproponentandop- lentmultimodallargelanguagemodelsasbackbones,including
ponentbymergingthe G+ and Gâˆ’ intoaconclusiongraph Gâˆ— 1)GeminiProVision[28],anextensivelyparameterizedmodel
as developedbyGoogle,2)InstructBLIP[6],whichpossessesmore
ğ‘€ğ‘œğ‘‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘œğ‘Ÿ ğ‘“ âˆ—: G+âˆªGâˆ’ â†¦â†’Gâˆ— constraineddimensionsandcomputationalresourcesrelativeto
alternativearchitectures,and3)GPT-4whichisthefourthitera-
âŸ¨V+,E+âŸ©âˆªâŸ¨Vâˆ’,Eâˆ’âŸ©â†¦â†’âŸ¨Vâˆ—,Eâˆ—âŸ©
tionoftheGPTmodeldevelopedbyOpenAI.Moreimplementation
ğ‘¤.ğ‘Ÿ.ğ‘¡ ğ‘†ğ‘–ğ‘§ğ‘’, ğ‘…ğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’, ğ¶ğ‘œğ‘šğ‘ğ‘ğ‘ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘  (5) detailscanbefoundfromtheAppendix.
Anexemplarimplementationis
5.2 DatasetsandMetrics
ğ‘“ âˆ—: As {ğ‘ğ‘’ğ‘Ÿğ‘ ğ‘œğ‘›ğ‘ğ‘™ğ‘–ğ‘¡ğ‘¦}, you are assigned as a moderator in a
Inlinewiththegeneralsetupdescribedin[21,40],weperformour
debateandhavebeenprovidedwithanaffirmativeevidence
graph{G+}andanegativeevidencegraph{Gâˆ’}toaddressthe experimentsusingtwoextensivelyadoptedmultimodalquestion
question{ğ‘“ ğ‘¡(ğ‘„)}regardingtheimage{ğ‘“ ğ‘£(ğ¼)}.Trytoconsolidate answering(QA)datasets.Thesedatasetsarewidelyrecognizedas
standard benchmarks, specifically designed to evaluate the per-
thetwographsintoasinglegraphtowardstheoptimalsolution,
formanceandeffectivenessofmodelsinaddressingmultimodal
andprovideaconclusiveanswertothequestion.
reasoning tasks. The two benchmarks are: 1) ScienceQA-IMG
(SQA-IMG)[20]representsthefirstmultimodalscientificquestion-
4.3 DebateProgressandGraphCondensation answeringcorpuscomprising21,000inquiriespairedwithmultiple
InitializationandRoleAssignment:OncetheblueprintG0has choicesandaccompanyingimages.Asatraining-freeapproach,
beeninitialized,thedebatecommenceswiththeassignmentofroles wesolelyutilizetheTESTandDEVpartitionsofScienceQA-IMG
toagentsinA.Denotetheassignmentofaroleğ‘Ÿ âˆˆRtoanagent followingpriorwork[20]forcomparativeassessment.Addition-
ğ‘ ğ‘— asğ‘ ğ‘— := ğ‘Ÿ,toensureabalanceddebate,anequalnumberof ally,thequestionswithinScienceQAcanbecategorizedintothree
agentsareassignedasProponentsandOpponents,withonlyone subdomains:naturalsciences(NAT),socialsciences(SOC),andlin-
agentassignedastheModerator.TheRoleAssignmentRegulation guisticsciences(LAN).2)MMbench[19]offersamoresystematic
iswritten androbustmeansforreasoningevaluationcomparedtoexisting
benchmarkssuchasVQAv2orCOCOCaptions.Weemploythe
(cid:13) (cid:13){ğ‘ ğ‘—|ğ‘
ğ‘—
:=ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡}(cid:13) (cid:13)=(cid:13) (cid:13){ğ‘ ğ‘˜|ğ‘
ğ‘˜
:=ğ‘‚ğ‘ğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡}(cid:13) (cid:13),
officialdatasplit(MMBench-Dev)andcodereleasedbytheorigi-
(cid:13) (cid:13){ğ‘ ğ‘™|ğ‘ ğ‘™ :=ğ‘€ğ‘œğ‘‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘œğ‘Ÿ}(cid:13) (cid:13)=1. natingauthors.Thestatisticsofthetwobenchmarksaredelineated
inAppendix.Wereporttheaccuracymetricasdeterminedthrough
Debating:Afterrolesareassigned,thedebatecanbeconducted
aheuristicmatchingprocedure,followingthesamesettingofthe
iterativelybetweentheProponentsandOpponentsasillustrated
officialbenchmark[20].
inFigure2.TheinitialblueprintG0isthenupdatedinsubsequent
debaterounds.Ineachround,theModeratorsummarizestheaffir-
5.3 PerformanceComparisontoSOTAMethods
mativeandnegativegraphsinaconclusiongraphonthebasisof
whichatentativeanswerisalsoprovided.Ifthedebateisnotcon- Weevaluatetheproposedmethodbybycomparingitagainsttwo
cluded,theModeratorinitiatesthenextroundbyassignGâˆ’ asthe setsofstate-of-the-artapproachesasfollows:
blueprintGğ‘–+1.Otherwise,theModeratorâ€™sanswerisconsidered â€¢ Open-SourceMultimodalLLMswithRelativelyModeratePa-
finalandadopted. rametersincludingMiniGPT-4[41],Qwen-VLandQwen-VL-ChangmengZheng,DayongLiang,WengyuZhang,Xiao-YongWei,Tat-SengChua,andQingLi
Model Size SQA-IMG MMBench theirnatureofobtainingvisualinformationthroughimagecap-
MiniGPT-4[41] 7B 37.7 24.3 tioning). Even the open-source VL models of the former group
Qwen-VL[2] 7B 58.6(67.1) 38.2 achievescomparableperformancetothoseofthelatterone,with
Qwen-VL-Chat[2] 7B 68.6(68.2) 60.6 muchsmallerparameterscales.WithBDoG,whichreinforcesmul-
mPLUG-Owl2[35] 8B 63.9 66.5 timodalreasoningbygraphregulation,theperformanceofdirect
CogVLM-Chat[31] 17B 69.6 63.7 multimodalreasoningofInstructBLIPandGeminiProVisionhave
LLaVA-v1.5[18] 13B 71.9(71.6) 68.2 beenimprovedby6.1%and19.8%ontheMMBenchdataset.
InstructBLIP[6] 13B 59.2(63.1) 36.0
InstructBLIP+BDoG 13B 63.5 55.8 5.4 AblationStudy
GPT-3.5+CoT[33] 175B 67.4 -
InordertogainacomprehensiveunderstandingofBDoG,wecon-
GPT-3.5+DDCoT[40] 175B 72.5 -
ductanablationstudywherewedecomposeBDoGintotwovari-
GPT-4+CoT[33] - 71.5 75.1
ants:
GPT-4+BDoG - 77.2 79.2 â€¢ BDoGğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’ :weremovethegraphregulationandconstraints,
GeminiProVision[28] - 76.5 75.2
resultinginadebate-onlyapproach(i.e.,vanillamulti-agentde-
GeminiProVision+BDoG - 81.1 81.3
bate)forinvestigatingthespecificcontributionofthedebating
Table1:Overallzero-shotresultsonScienceQA-IMGtestset componentofBDoG.
andMMBenchdevset.Size=backbonemodelsize.Thereare â€¢ BDoGğºğ‘Ÿğ‘ğ‘â„ : we remove the debating rounds, resulting in a
limitedzero-shotresultspreviouslypublishedonScienceQA- graph-basedreasoningmethodforinvestigatingthespecificcon-
IMG, so we reimplemented above models and report our tributionofthegraphregulationcomponentofBDoG.
findings.Wherepossible,weincluderesultsfromtheLLaVA
Moreover,weanalyzetheperformanceofthetwovariantsonthe
paperforcomparison(showninparentheses).ForMMBench,
benchmarksbybreakingitdownintosubcategories.Thisanalysis
werefertothescoreslistedontheofficialpublicleaderboard.
allowsustoinvestigatethepreferencesofthesetwovariantsfor
differenttypesofquestions.TheresultsarepresentedinTable2,
whereitcanbeobservedthatbothvariantsdemonstratecompara-
bleperformanceacrossvariousbenchmarks.Thissuggeststhatthe
Chat[2],CogVLM-Chat[31],mPLUG-Owl2[35],LLaVA-v1.5 debateandgraphcomponentsofBDoGcontributetoitseffective-
[18],andInstructBLIP[6].Thesemodelshaveparameterscales nessinasimilarmanner.Throughthecombinationofthesetwo
rangingfrom7Bto17B componentsinBDoG,theperformancehasexperiencedfurther
â€¢ Closed-SourceMultimodalLLMswithLarge-ScaleParameters: improvementcomparedtotheindividualvariants.However,when
GPT-3.5[33],GPT-4V[1]andGeminiProVision[28].Following consideringspecificcategories,distinctionsinthecontributionsof
thegeneralstandard,GPT-3.5andGPT-4havebeenincorporated thedebateandgraphcomponentsbecomeapparent.
withtheCoT[33]orDDCoT[40](builtbasedonimagecaption- Impactofthedebatecomponent:BDoGğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’ demonstrates
ingresults).Thesemodelsareknownfortheirparameterscales consistentimprovementsacrossbothbenchmarkswithadebate-
above175Bandareconsideredtohavethebestperformancein onlysetting,whichencouragesLLMagentstocollaborativelyrefine
mostoftheliterature. andcorrectpriorresponses.Forsciencequestions,BDoGğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’ fa-
TheresultsareshowninTable1.TheintegrationofBDoGhas cilitatesthemodelâ€™sfocusonspecificerrors,suchasdirection,size,
resultedinasignificantimprovementacrossdifferentbackbones, andposition,leadingtoimprovedperformanceinthenaturalsci-
asevidencedbytheperformancegainsof4.3% âˆ¼ 5.7%onSQA- encedomain(boostingaccuracyfrom53.7to59.7forInstructBLIP
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’
IMGand6.1% âˆ¼ 19.8%onMMBench.Notably,whencombined and68.9to73.3forGeminiProVision).Additionally,BDoG
withGeminiProVision,BDoGachievesSOTAperformanceonthe significantlyenhanceslogicalreasoningtasks(improvingaccuracy
ScienceQA-IMGtestsetandMMBenchdevelopmentset,achieving from 14.2 to 43.7). However, the debate-only nature has limita-
accuraciesof81.1%and81.3%,respectively.Otherobservationsthat tions,includingtrivializationandfocusdiversionissues.Without
indicateBDoGâ€™sadvantageoverSOTAmethodsinclude: thegraphregulation,overallperformancedecreasesfrom55.8to
BDoGhelpsreducetheperformancegapbetweenlarge 42.6forInstructBLIP,particularlywhenaddressingquestionsthat
andsmallmodels.Itiscommonlybelievedthatmodelswithlarger requireattentiontospecificattributesandrelations.
parameterscalestendtoperformbetterthansmallerones.This Impactofthegraphregulation:Withagraph-regularizedknowl-
ğºğ‘Ÿğ‘ğ‘â„
observationgenerallyholdstrue,asshowninTable1formodels edgebaseforthediscussion,BDoG alsodemonstratesconsis-
withoutBDoG.However,theintroductionofBDoGhasledtoa
tentimprovementof2.3%âˆ¼15.1%oversthebasemodelsonboth
reductionintheperformancegapbetweenthesetwotypesofmod- benchmarks.Comparedtothetext-basedanddebate-onlymethod
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’
els.ThiscanbeseenintheimprovementachievedbyInstructBLIP, BDoG , it performs evidently better on the MMBench by
whichhasexperiencedaboostof4.3%andachievesanaccuracyof 1.4%âˆ¼8.5%.Thisisnotasurprise,becauseMMBenchemphasizes
63.5%onSQA-IMG,comparabletothatofGPT-3.5. moretheattributeandrelationswhichchallengesamodelâ€™sability
BDoGreinforcesthemultimodalreasoning.FormTable1,we onstructuralreasoning.Althoughincorporatingfact-relatedgraph
ğºğ‘Ÿğ‘ğ‘â„
canalsoobservetheadvantageofdirectmultimodalreasoning(e.g., informationprovesbeneficialinBDoG ,theabsenceoftheit-
open-sourceVLmodels,andGeminiProVision)overindirectmul- erativelyrefineddebateprocedureresultsindecreasedperformance
timodalreasoning(e.g.,GPT3.5+CoTandGPT3.5+DDCoTdueto duetothecoarseanddistortedextractionofblueprintinformation.APictureIsWorthaGraph:BlueprintDebateonGraphforMultimodalReasoning
ScienceQA-IMG-Dev ScienceQA-IMG-Test MMBench-Dev
Model Method
NAT SOC LAN Avg NAT SOC LAN Avg LR AR RR FP-S FP-C CP Avg
MniGPT-4[41] 42.9 30.6 43.7 38.4 42.0 30.1 50.0 37.7 7.5 31.3 4.3 30.3 9.0 35.6 24.3
Qwen-VL[2] 52.1 59.8 58.3 55.0 55.7 62.0 77.3 58.7 16.1 44.7 34.8 35.2 39.2 46.6 38.2
Qwen-VL-Chat[2] 60.9 67.4 62.5 63.3 67.7 69.6 75.0 68.6 32.2 59.8 43.5 66.2 48.3 79.4 60.6
Base
mPLUG-Owl2[35] 60.6 68.0 45.8 62.8 62.5 66.2 61.4 63.9 32.2 72.4 60.9 68.6 60.1 79.4 66.5
CogVLM-Chat[31] 63.1 69.2 77.1 65.6 68.0 72.2 70.4 69.7 29.7 65.8 60 66.9 58 76.7 63.7
LLaVA-v1.5[18] 66.1 74.9 72.9 69.4 70.1 74.2 81.8 71.9 44.1 67.3 60.0 72.0 59.4 82.1 68.2
Base 53.7 57.3 47.9 54.8 58.1 61.0 61.4 59.2 14.2 46.3 22.6 37.0 21.4 49.0 36.0
+BDoGğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’ 59.7 55.6 54.2 58.1 63.1 58.2 72.7 61.4 43.7 57.8 31.5 42.7 19.5 39.1 42.6
InstructBLIP[6] +BDoGğºğ‘Ÿğ‘ğ‘â„ 58.1 61.3 52.1 59.0 60.6 62.6 68.2 61.5 58.8 65.5 41.2 51.2 18.6 46.1 51.1
+BDoG 61.1 64.0 52.1 61.9 61.1 66.5 75.0 63.5 63.3 71.9 37.8 56.3 20.3 59.1 55.8
Base 68.9 81.6 75.0 73.7 72.9 81.5 88.6 76.5 55.9 80.4 73.9 79.5 61.5 82.1 75.2
+BDoGğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’ 73.3 81.1 77.1 76.2 75.3 82.8 93.2 78.5 71.1 85.1 83.1 78.9 71.9 81.3 79.3
GeminiProVision[28] +BDoGğºğ‘Ÿğ‘ğ‘â„ 69.8 84.8 87.5 75.6 74.7 86.8 88.6 79.6 75.0 84.5 80.7 81.4 73.0 83.6 80.7
+BDoG 73.6 86.2 85.4 78.4 76.6 87.4 93.2 81.1 74.0 84.8 83.4 81.3 73.7 84.4 81.3
Table2:AblationstudyonScienceQA-IMGdevandtestsetandMMBenchdevset.Questionclasses:NAT=naturalscience,SOC
=socialscience,LAN=languagescience,LR=LogicalReasoning;AR=AttributeReasoning;RR=RelationReasoning;FP-S=
Fine-grainedPerception(SingleInstance);FP-C=Fine-grainedPerception(CrossInstance);CP=CoarsePerception.
Which country is highlighted? Arethetwocandyjarsinthepicture
Options: thesameshape?
A.Haiti Options:
B.Dominica A.Same
C.the Dominican Republic B.Notthesame
D.Trinidad and Tobago C.Canâ€™tjudge
Round1 Round1
BDoGDebate: BDoG: Haiti BDoGDebate: BDoG:
Small Small
The highlighted country is the Dominica. Located The two candy jars in the picture arenot the Square Blue Round Purple
Dominica is an island country in the Trinidad _in same shape. The first candy jar is a cylinder,
Caribbean Sea,â€¦There are a few possible andTobago Caribbean Sea while the second candy jar is a sphere....
s oo f l eu cti oo nn os m to ic t h de e vp er lo ob pl mem en o t.f OD no em si on li uc ta i' os n l a ic s k t o Located_in D jae rss p ai rt ee nth oe t s te h es i sm amila er i st hie as p, e t .h Te htw eyo ac ra en dy Contains Candy1 Contains Ca And ny s2 wer:C
focus on developing the tourism industryâ€¦ Dominica D Reo pm ui bn li ic ca different in height, diameter, and shape. Jar1 Jar2
Round2 Round2
BDoGDebate: BDoG: GeneratedMarks: BDoGDebate: BDoG: Candy2
Green The highlighted Contains
I believe that these three solutions would Haiti Color country is Dominica. The two candy jars in the picture are the Candy1 Jar2 Shape
help to address the problem of Dominicaâ€˜s The other islands are same shape. They are both cylindrical jars Contains Radius
l c pa o ec m ok p mo lef i t oe m fc eo Dnn oto mfm ro ii nc m i cd ate h .v ee glo op vm ere nn mt. e . n. ta al no dn g th-t ee rm T a Tnr odi bn aid ga od DC omol io nr ica HIs ighlighten q do ut e sr te il oe nv .a ..n t to the w o isn i tt l ah y l la d e i rr f o f te hu r an e nd n c tb hea e s â€¦ e ja a ri n s o d t nh a ta htr eo t hu ren ig d j ha t tro . op n. T thh ee left R 5a cd miusJar1 Shap Ce ylin5 dc em r Cylinder
Round3 Round3
BDoGDebate: BDoG: BDoGDebate: BDoG:
Country Cylinder Answer:
I think the highlighted country is Barbados. Green Answer: I think that the best solution to this problem A.Same
It is an island country located in the Type B.Dominica is to use a different type of candy jar. There
Caribbean Sea. It is known for its beautiful Color Is are many different types of candy jarsâ€¦, so Shape
b ise aa lc sh oe as , p.. oa pn ud la f rr i te on ud ril sy t p de eo stp il ne a. t T ioh ne . country Dominica Highlighted i st h s ah po eu al sd tb he e e oa ts hy e rt o c af nin dd y o jan re . that is the same Jar1 Same Cylinder
Jar2
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’
Figure3:CasestudyofourproposedBlueprintDebateonGraph(BDoG)andvallinaMulti-agentDebate(BDoG )on
ScienceQA-IMG (left) and MMBench (right) datasets. Green color indicates the correct answer/rationale and Red means
incorrect/irrelevantpredictions.
Impactofcombiningthedebateandgraphcomponents:By enhanceslogicalreasoning(LR)throughamechanismthatrefines
combiningthetwocomponents,BDoGachievesgainsacrossnearly thereasoningprocessiteratively,emphasizingtheimportanceof
allcategories.IntheScienceQA-IMGdataset,BDoGexhibitscon- multi-stepreasoningrationales.Theblueprintgraphstructureof
sistentandsteadyimprovements,averagingaround5%compared BDoG,whichexplicitlymodelsobjects,attributes,andrelations,
to the baseline models. This suggests that BDoG is robust and contributestoimprovedreasoningabilitiesinAttributeReasoning
generalizeswellforscience-relatedquestions.Remarkably,BDoG (AR)andRelationReasoning(RR).TheGeminiProVisionmodel
significantlyoutperformsthebaselinemodel(InstructBLIP)onthe alsoexhibitscomparableperformanceimprovements,withBoG
MMBench-Devset,particularlyintheareasofLogicalReasoning contributingtoenhancedfine-grainedperceptionacrossinstances
(LR)withamarginof49.1%,AttributeReasoning(AR)withamargin
of26.6%,andRelationReasoning(RR)withamarginof15.2%.BDoGChangmengZheng,DayongLiang,WengyuZhang,Xiao-YongWei,Tat-SengChua,andQingLi
(FP-C),resultinginagainof12.2%.Thisimprovementcanbeattrib-
utedtotheconnectionsestablishedbetweenvariousobjectswithin 1600 #Update 3500 #Update
thedebate-on-graphframework. 1400 #Prune 3000 #Prune
#Add #Add
Acasestudyfortheiterativeimprovementontheblueprint: 1200 2500
BDoGleveragestheadvantagesofbothstructuredevidencethrough 1000 2000
800
graphregulationanditerativerefinementthroughdebating.Thisis 1500
600
evidentintheconsistentimprovementobservedontheblueprint 400 1000
graph,showcasingthecombinedbenefitsofthesetwocomponents. 200 500
Figure3providesrunningexamplesdemonstratingthesuperiorrea- R1 R2 Round R3 R4 R1-R2 RR o2 u-R n3 d R3-R4
soningperformanceofourproposedBDoGframeworkcompared
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’ Figure 4: Statistics of intra-round (left) and inter-round
totheBDoG method.
(right)BlueprintcondensationofBDoGwithGeminiProVi-
TheleftcasedrawsfromtheScienceQAdataset,testinggeo-
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’ sionforScienceQA-IMGtestset.#Update:numberofupdated
graphicknowledgeandmapinterpretation.WhileBDoG
attributes;#Add:numberofnewly-addedentities/relations;
correctlyansweredDominicaishighlighted,italsogeneratedirrele-
#Prune:numberofprunedentities/relations.
vantinformationaboutDominicaâ€™seconomicdevelopment.This
misguidedtheagentsintooff-topicdiscussion,concludingincor-
rectlywithBarbados.Incontrast,BDoGconcentratedontheques-
modelâ€™sperformancetendedtoconvergewithinthesecondorthird
tion and options, iteratively refining the blueprint entities and
round.Thiscanbeattributedtotheunderlyingreasoningtypically
relationstoarriveattherightanswerofDominica.
beingabletoanswerquestionswithin2-3steps.
TheexampleontherightcomesfromtheMMBenchdataset
Additionally,Figure4illustratesthenumberofupdatedattributes,
requiringcross-instanceperception.Astheimagecontainedboth
newlyaddedorremovedentitiesorrelationsbetweenandwithin
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’
candiesandjars,itposedachallenge.WithBDoG relyingon
rounds.AstrengthofourproposedBDoGframeworkisitsability
textalone,agreementwasrarelyreachedasresponseschangedover
toquantifythedebateprocessbyinspectinggraphchanges.This
debaterounds.However,BDoGfirstgeneratedablueprintdefin-
demonstratestheeffectivenessofdynamicallyadjustingtheinitial
ingimageobjectsandattributes.Thisestablishedthediscussion
graphbasedonthediscussion.TheresultsinFigure4arealsocon-
scope.BDoGthenprunedirrelevantcandyinformation,focusing
sistentwithourhypothesisthatdisagreementsanderrorscanbe
discussiononthespecificobject-jars.Itoutputthefinalanswer
decreasedasthedebateprogresses.
bycomparingandconnectingthetwojarsub-graphs.
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’
Insummary,Figure3demonstratesthatBDoGbeatsBDoG
onbothdatasetsthroughitsblueprint-drivenapproach.Thiscon-
centratesgraph-basedreasoningonsalienttopicsandprunesirrel- 1.0 0.9
BDoG (Debate)
evantdetailstoarriveatwell-supportedconclusions. BDoG
0.811 0.813
0.8 0.784 0.8
0.765
0.752 0.736
ScienceQA-IMG-Test MMBench-Dev
Round 0.6 0.7
BDoG-S BDoG-L BDoG-S BDoG-L
1 60.5 80.6 51.6 81.0 0.4 0.6
2 63.5 80.9 54.6 81.1
3 63.1 81.1 55.8 81.3
0.2 0.5
4 63.3 81.4 55.8 80.9
Table 3: Model performance with respect to the iteration
0.0 0.4
roundofdebate.BDoG-S:InstructBLIPwithBDoG,BDoG-L: SQA-IMG-Test SQA-IMG-Dev MMBench-Dev
Datasets
GeminiProVisionwithBDoG.
Figure5:Effectivenessvs.efficiencyresults,comparingour
proposed Blueprint Debate-on-Graph (BDoG) and vanilla
Multi-agent Debate (BDoG (Debate)) on GeminiProVision.
5.5 MonitoringTheDebatingProgress Thebarchartindicatestheinferencetimeonthreedatasets
andlinesindicatethezero-shotperformance(Accuracy).
We evaluated the modelâ€™s performance against the termination
criteriaacrossmultipledebateroundsbasedonthedatainTable
3.Ouranalysisshowedthatformodelswithsmallerparameters
5.6 EfficiencyAnalysis
likeInstructBLIP,movingfromasingleroundtotworoundsledto
significantgainsinperformance.Thisimprovementwasparticu- We further compared the effectiveness versus efficiency of our
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’
larlynotablewhenincreasingthenumberofroundsfromoneto BDoGframeworkagainstBDoG ,withresultsshowninFig-
two.However,forlargermodelsthatmayreachagreementmore ure 5. Maintaining concise content focused on key aspects, the
easily,theperformanceenhancementwasrelativelymodestwhen graphstructureofBDoGdemonstratedsuperiorefficiency,requir-
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’
amplifyingthenumberofdebaterounds.Ingeneral,wefoundthe ingapproximately50%lessinferencetimethanBDoG .By
tnuoC
noitacifidoM
hparG
ycaruccA
tnuoC
noitacifidoM
hparG
emiT
ecnerefnIAPictureIsWorthaGraph:BlueprintDebateonGraphforMultimodalReasoning
firstgeneratingablueprint,BDoGdefinesthescopeofthecurrent onKnowledgeandDataEngineering(2023).
state,therebyimprovingmodelefficiencybyfilteringirrelevant [12] JieHuang,XinyunChen,SwaroopMishra,HuaixiuStevenZheng,AdamsWei
Yu,XinyingSong,andDennyZhou.2023. LargeLanguageModelsCannot
information.Concurrently,Figure5showsBDoGoutperformed
Self-CorrectReasoningYet.InTheTwelfthInternationalConferenceonLearning
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’
BDoG ineffectiveness,achievingover5percentagepoints Representations.
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’ [13] ShaohanHuang,LiDong,WenhuiWang,YaruHao,SakshamSinghal,Shuming
higheraccuracythanBDoG acrossthreetestsets.
Ma,TengchaoLv,LeiCui,OwaisKhanMohammed,BarunPatra,etal.2024.Lan-
ThisenhancedeffectivenesscanbeattributedtoBDoGâ€™sframe- guageisnotallyouneed:Aligningperceptionwithlanguagemodels.Advances
workconcentratingonimportantknowledgeratherthangenera- inNeuralInformationProcessingSystems36(2024).
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’ [14] JunnanLi,DongxuLi,SilvioSavarese,andStevenHoi.2023.Blip-2:Bootstrapping
tionaltextualcontentwithoutguidance,asinBDoG .Defin- language-imagepre-trainingwithfrozenimageencodersandlargelanguage
ingablueprinttoestablishthediscussionboundariesbeforegener- models.arXivpreprintarXiv:2301.12597(2023).
[15] XingxuanLi,RuochenZhao,YewKenChia,BoshengDing,ShafiqJoty,Soujanya
atingagraphstructureenhancesbothefficiencyandeffectiveness
Poria,andLidongBing.2023.Chain-of-Knowledge:GroundingLargeLanguage
byrestrictingthemodelâ€™sreasoningtosalienttopics.Insummary, ModelsviaDynamicKnowledgeAdaptingoverHeterogeneousSources.InThe
Figure5illustratesBDoGdemonstratedbettertimeperformance TwelfthInternationalConferenceonLearningRepresentations.
ğ·ğ‘’ğ‘ğ‘ğ‘¡ğ‘’ [16] TianLiang,ZhiweiHe,WenxiangJiao,XingWang,YanWang,RuiWang,Yujiu
andpredictivepowercomparedtoBDoG ,validatingtheutil-
Yang,ZhaopengTu,andShumingShi.2023. EncouragingDivergentThink-
ityofourapproachinbalancingcomputationalcostandpredictive inginLargeLanguageModelsthroughMulti-AgentDebate. arXivpreprint
accuracythroughfocused,blueprint-drivendebate. arXiv:2305.19118(2023).
[17] BillYuchenLin,XinyueChen,JaminChen,andXiangRen.2019. KagNet:
Knowledge-AwareGraphNetworksforCommonsenseReasoning.InProceedings
6 CONCLUSION ofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessingand
the9thInternationalJointConferenceonNaturalLanguageProcessing(EMNLP-
Thispaperhaspresentedapioneeringpilotstudythatintroduces IJCNLP).2829â€“2839.
multi-agentdebateintotherealmofmultimodalreasoning.We [18] HaotianLiu,ChunyuanLi,QingyangWu,andYongJaeLee.2024. Visualin-
structiontuning.Advancesinneuralinformationprocessingsystems36(2024).
tackledtwoprominentchallengesfacedinthiscontext:theissue [19] YuanLiu,HaodongDuan,YuanhanZhang,BoLi,SongyangZhang,Wangbo
ofopinionsbeingtrivializedandfocusdiversion.Byrecognizing Zhao,YikeYuan,JiaqiWang,ConghuiHe,ZiweiLiu,etal.2023.Mmbench:Is
yourmulti-modalmodelanall-aroundplayer?arXivpreprintarXiv:2307.06281
thelimitationsofexistingdebatingschemes,weproposeBlueprint
(2023).
DebateonGraphs(BDoG),whichconfinesdebatestoablueprint [20] PanLu,SwaroopMishra,TanglinXia,LiangQiu,Kai-WeiChang,Song-Chun
graphandstoresevidenceingraphbranches,toaddressthechal- Zhu,OyvindTafjord,PeterClark,andAshwinKalyan.2022.Learntoexplain:
Multimodalreasoningviathoughtchainsforsciencequestionanswering.Ad-
lengesofword-levelopiniontrivializationanddistractioncaused
vancesinNeuralInformationProcessingSystems35(2022),2507â€“2521.
byirrelevantconcepts.ExtensiveexperimentsconductedinSci- [21] PanLu,BaolinPeng,HaoCheng,MichelGalley,Kai-WeiChang,YingNianWu,
enceQAandMMBenchvalidatetheefficacyofBDoG,surpassing Song-ChunZhu,andJianfengGao.2024.Chameleon:Plug-and-playcomposi-
tionalreasoningwithlargelanguagemodels.AdvancesinNeuralInformation
previousmethodsandestablishingnewstate-of-the-artresults. ProcessingSystems36(2024).
[22] AmanMadaan,NiketTandon,PrakharGupta,SkylerHallinan,LuyuGao,Sarah
REFERENCES Wiegreffe,UriAlon,NouhaDziri,ShrimaiPrabhumoye,YimingYang,etal.
2024.Self-refine:Iterativerefinementwithself-feedback.AdvancesinNeural
[1] JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,Floren- InformationProcessingSystems36(2024).
ciaLeoniAleman,DiogoAlmeida,JankoAltenschmidt,SamAltman,Shyamal [23] ChancharikMitra,BrandonHuang,TrevorDarrell,andRoeiHerzig.2023.Com-
Anadkat,etal.2023. Gpt-4technicalreport. arXivpreprintarXiv:2303.08774 positionalchain-of-thoughtpromptingforlargemultimodalmodels. arXiv
(2023). preprintarXiv:2311.17076(2023).
[2] JinzeBai,ShuaiBai,ShushengYang,ShijieWang,SinanTan,PengWang,Junyang [24] Debjyoti Mondal, Suraj Modi, Subhadarshi Panda, Rituraj Singh, and Go-
Lin,ChangZhou,andJingrenZhou.2023. Qwen-vl:Afrontierlargevision- dawariSudhakarRao.2024. KAM-CoT:KnowledgeAugmentedMultimodal
languagemodelwithversatileabilities.arXivpreprintarXiv:2308.12966(2023). Chain-of-ThoughtsReasoning.arXivpreprintarXiv:2401.12863(2024).
[3] RemiCadene,HediBen-Younes,MatthieuCord,andNicolasThome.2019.Murel: [25] HyeonseobNam,Jung-WooHa,andJeongheeKim.2017.Dualattentionnetworks
Multimodalrelationalreasoningforvisualquestionanswering.InProceedingsof formultimodalreasoningandmatching.InProceedingsoftheIEEEconferenceon
theIEEE/CVFconferenceoncomputervisionandpatternrecognition.1989â€“1998. computervisionandpatternrecognition.299â€“307.
[4] Chi-MinChan,WeizeChen,YushengSu,JianxuanYu,WeiXue,Shanghang [26] NoahShinn,FedericoCassano,AshwinGopinath,KarthikNarasimhan,and
Zhang,JieFu,andZhiyuanLiu.2023. ChatEval:TowardsBetterLLM-based ShunyuYao.2024.Reflexion:Languageagentswithverbalreinforcementlearn-
EvaluatorsthroughMulti-AgentDebate.InTheTwelfthInternationalConference ing.AdvancesinNeuralInformationProcessingSystems36(2024).
onLearningRepresentations. [27] JiashuoSun,ChengjinXu,LumingyuanTang,SaizhuoWang,ChenLin,Yeyun
[5] KarlCobbe,VineetKosaraju,MohammadBavarian,MarkChen,HeewooJun, Gong,LionelNi,Heung-YeungShum,andJianGuo.2023.Think-on-Graph:Deep
LukaszKaiser,MatthiasPlappert,JerryTworek,JacobHilton,ReiichiroNakano, andResponsibleReasoningofLargeLanguageModelonKnowledgeGraph.In
etal.2021. Trainingverifierstosolvemathwordproblems. arXivpreprint TheTwelfthInternationalConferenceonLearningRepresentations.
arXiv:2110.14168(2021). [28] GeminiTeam,RohanAnil,SebastianBorgeaud,YonghuiWu,Jean-Baptiste
[6] WenliangDai,JunnanLi,DongxuLi,AnthonyMengHuatTiong,JunqiZhao, Alayrac,JiahuiYu,RaduSoricut,JohanSchalkwyk,AndrewMDai,AnjaHauth,
WeishengWang,BoyangAlbertLi,PascaleFung,andStevenC.H.Hoi.2023.In- etal.2023.Gemini:afamilyofhighlycapablemultimodalmodels.arXivpreprint
structBLIP:TowardsGeneral-purposeVision-LanguageModelswithInstruction arXiv:2312.11805(2023).
Tuning.ArXivabs/2305.06500(2023). [29] KehengWang,FeiyuDuan,SiruiWang,PeiguangLi,YunsenXian,Chuantao
[7] YilunDu,ShuangLi,AntonioTorralba,JoshuaBTenenbaum,andIgorMor- Yin,WengeRong,andZhangXiong.2023. Knowledge-drivencot:Exploring
datch.2023.ImprovingFactualityandReasoninginLanguageModelsthrough faithfulreasoninginllmsforknowledge-intensivequestionanswering.arXiv
MultiagentDebate.arXivpreprintarXiv:2305.14325(2023). preprintarXiv:2308.13259(2023).
[8] JieHe,TaoWang,DeyiXiong,andQunLiu.2020. Theboxisinthepen: [30] LeiWang,YiHu,JiabangHe,XingXu,NingLiu,HuiLiu,andHengTao
Evaluatingcommonsensereasoninginneuralmachinetranslation.InFindings Shen.2023. T-SciQ:TeachingMultimodalChain-of-ThoughtReasoningvia
oftheAssociationforComputationalLinguistics:EMNLP2020.3662â€“3672. LargeLanguageModelSignalsforScienceQuestionAnswering.arXivpreprint
[9] DanHendrycks,CollinBurns,StevenBasart,AndyZou,MantasMazeika,Dawn arXiv:2305.03453(2023).
Song,andJacobSteinhardt.2020.MeasuringMassiveMultitaskLanguageUn- [31] WeihanWang,QingsongLv,WenmengYu,WenyiHong,JiQi,YanWang,Junhui
derstanding.InInternationalConferenceonLearningRepresentations. Ji,ZhuoyiYang,LeiZhao,XixuanSong,etal.2023.Cogvlm:Visualexpertfor
[10] SameeraHorawalavithana,SaiMunikoti,IanStewart,andHenryKvinge.2023. pretrainedlanguagemodels.arXivpreprintarXiv:2311.03079(2023).
Scitune:Aligninglargelanguagemodelswithscientificmultimodalinstructions. [32] YananWang,MichihiroYasunaga,HongyuRen,ShinyaWada,andJureLeskovec.
arXivpreprintarXiv:2307.01139(2023). 2023. VQA-GNN:ReasoningwithMultimodalKnowledgeviaGraphNeural
[11] LinmeiHu,ZeyiLiu,ZiwangZhao,LeiHou,LiqiangNie,andJuanziLi.2023.A NetworksforVisualQuestionAnswering.InProceedingsoftheIEEE/CVFInter-
surveyofknowledgeenhancedpre-trainedlanguagemodels.IEEETransactions nationalConferenceonComputerVision.21582â€“21592.ChangmengZheng,DayongLiang,WengyuZhang,Xiao-YongWei,Tat-SengChua,andQingLi
[33] JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,FeiXia,EdChi, [37] JintianZhang,XinXu,andShuminDeng.2023.Exploringcollaborationmecha-
QuocVLe,DennyZhou,etal.2022.Chain-of-thoughtpromptingelicitsreason- nismsforllmagents:Asocialpsychologyview.arXivpreprintarXiv:2310.02124
inginlargelanguagemodels.AdvancesinNeuralInformationProcessingSystems (2023).
35(2022),24824â€“24837. [38] ZhuoshengZhang,AstonZhang,MuLi,HaiZhao,GeorgeKarypis,andAlex
[34] SeanWelleck,XimingLu,PeterWest,FaezeBrahman,TianxiaoShen,Daniel Smola.2023.Multimodalchain-of-thoughtreasoninginlanguagemodels.arXiv
Khashabi,andYejinChoi.2022. GeneratingSequencesbyLearningtoSelf- preprintarXiv:2302.00923(2023).
Correct.InTheEleventhInternationalConferenceonLearningRepresentations. [39] ChuanyangZheng,ZhengyingLiu,EnzeXie,ZhenguoLi,andYuLi.2023.
[35] HaiyangXu,QinghaoYe,MingshiYan,YayaShi,JiaboYe,YuanhongXu,Chen- Progressive-hintpromptingimprovesreasoninginlargelanguagemodels.arXiv
liangLi,BinBi,QiuchenQian,WeiWang,GuohaiXu,JiZhang,SongfangHuang, preprintarXiv:2304.09797(2023).
FeiranHuang,andJingrenZhou.2023.mPLUG-2:AModularizedMulti-modal [40] GeZheng,BinYang,JiajinTang,Hong-YuZhou,andSibeiYang.2023.DDCoT:
FoundationModelAcrossText,ImageandVideo.InInternationalConferenceon Duty-DistinctChain-of-ThoughtPromptingforMultimodalReasoninginLan-
MachineLearning. guageModels.InThirty-seventhConferenceonNeuralInformationProcessing
[36] ZhangyueYin,QiushiSun,ChengChang,QipengGuo,JunqiDai,Xuan-Jing Systems.
Huang,andXipengQiu.2023.Exchange-of-thought:Enhancinglargelanguage [41] DeyaoZhu,JunChen,XiaoqianShen,XiangLi,andMohamedElhoseiny.2024.
modelcapabilitiesthroughcross-modelcommunication.InProceedingsofthe2023 MiniGPT-4:EnhancingVision-LanguageUnderstandingwithAdvancedLarge
ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.15135â€“15153. LanguageModels.InTheTwelfthInternationalConferenceonLearningRepresen-
tations. https://openreview.net/forum?id=1tZbq88f27