DISCOVER: A Data-driven Interactive System for Comprehensive
Observation, Visualization, and ExploRation of Human Behaviour
DominikSchiller TobiasHallmen DaksithaWithanageDon
dominik.schiller@uni-a.de tobias.hallmen@uni-a.de daksitha.withanage.don@uni-a.de
UniversityofAugsburg UniversityofAugsburg UniversityofAugsburg
Augsburg,Bavaria,Germany Augsburg,Bavaria,Germany Augsburg,Bavaria,Germany
ElisabethAndr√© TobiasBaur
elisabeth.andre@uni-a.de tobias.baur@uni-a.de
UniversityofAugsburg UniversityofAugsburg
Augsburg,Bavaria,Germany Augsburg,Bavaria,Germany
3
1
(Self-)Hosted
DISCOVER
Processor Assistant 2
4
Figure1:OverviewoftheDISCOVERArchitecture
ABSTRACT Content Exploration, Visual Inspection, Aided Annotation, and
Understanding human behavior is a fundamentalgoal of social MultimodalSceneSearch.Byillustratingtheseworkflows,weaim
sciences,yetitsanalysispresentssignificantchallenges.Conven- toemphasizetheversatilityandaccessibilityofDISCOVERasa
tional methodologies employed for the study of behavior, char- comprehensiveframeworkandproposeasetofblueprintsthatcan
acterized by labor-intensive data collection processes and intri- serveasageneralstartingpointforexploratorydataanalysis.
cateanalyses,frequentlyhindercomprehensiveexplorationdue
to their time and resource demands. In response to these chal- 1 INTRODUCTION
lenges,computationalmodelshaveproventobepromisingtools Understandinghumanbehaviorisacorepursuitinsocialsciences,
thathelpresearchersanalyzelargeamountsofdatabyautomat- crucialforunravelingthecomplexitiesofhumaninteractionsand
icallyidentifyingimportantbehavioralindicators,suchassocial societaldynamics.However,analyzinghumanbehaviorcomeswith
signals.However,thewidespreadadoptionofsuchstate-of-the- itsfairshareofchallenges,particularlywithtraditionalmethods
artcomputationalmodelsisimpededbytheirinherentcomplex- thatinvolvelaboriousdatacollectionandintricateanalyses,often
ityandthesubstantialcomputationalresourcesnecessarytorun limitingthoroughexplorationduetoresourcedemands.
them,therebyconstrainingaccessibilityforresearcherswithout Toaddressthesechallenges,computationalmodelshaveemerged
technicalexpertiseandadequateequipment.Toaddressthesebar- aspromisingalternatives,offeringautomatedidentificationofkey
riers,weintroduceDISCOVER‚Äìamodularandflexible,yetuser- behavioralcueslikesocialsignals.Yet,theirwidespreadadoption
friendlysoftwareframeworkspecificallydevelopedtostreamline faceshurdles,mainlyduetotheircomplexityandtheheftycom-
computational-drivendataexplorationforhumanbehavioranal- putationalresourcestheyrequire,makingthemlessaccessibleto
ysis.Ourprimaryobjectiveistodemocratizeaccesstoadvanced researcherswithouttechnicalexpertiseoradequateequipment.
computationalmethodologies,therebyenablingresearchersacross Inlightoftheseissues,weintroduceDISCOVER1,aflexibleopen-
disciplinestoengageindetailedbehavioralanalysiswithoutthe sourcesoftwareframeworktailoredtostreamlinecomputational-
needforextensivetechnicalproficiency.Inthispaper,wedemon- drivendataexplorationforhumanbehavioranalysis.Ourprimary
stratethecapabilitiesofDISCOVERusingfourexemplarydataex-
plorationworkflowsthatbuildoneachother:InteractiveSemantic 1https://github.com/hcmlab/discover
4202
luJ
81
]CH.sc[
1v80431.7042:viXraSchiller,etal.
goal is to democratize access to advanced computational tools, computing.Itprovidesaccessiblefunctionsforanalyzingusers‚Äô
empoweringresearchersfromdiversebackgroundstoconductin- affectivestatesviaagraphicaluserinterface,includingavariety
depthbehavioralanalysiswithoutextensivetechnicalknow-how. ofemotionrecognitionmodelsfordifferentmodalitiesaswellas
Throughoutthispaper,weshowcaseDISCOVER‚Äôsversatility aunifiedmultimodalassessment.TheConAnTool[33]hasbeen
throughfourillustrativedataexplorationworkflows.First,wede- developedwithafocusongroupconversationanalysis.Tothis
scribetheinteractivesemanticcontentexplorationoftranscriptions, end,itautomaticallyanalyzesthegazebehavior,bodymovement,
achievedthroughdirectintegrationoflargelanguagemodels.Sec- speakeractivity,andfacialexpressionsofparticipantsusingasingle
ond,weillustratehowtheintegratedsocialsignalprocessingcapa- 360¬∞camera.
bilitiesofDISCOVERcanaidresearchersinthevisualexploration Allthesevisualization-basedmethodsweredevelopedwithspe-
ofdata.Third,weshowhowDISCOVERcanbeusedtoaidthean- cificgoalsandtargetgroupsinmind.Asaresult,thechoiceof
notationofmeaningfulbehavioralcues.Lastly,weshowcaseour featurestobedisplayedisusuallytailoredtothisspecificusecase.
framework‚Äôscapabilitiesformultimodalscenesearch,enablingusers Thereforethesesolutionssufferfromalackofcustomizabilitythat
toautomatetheidentificationofkeysceneswithindatasets. preventsusersfromadaptingthefeaturestotheirindividualneeds.
Althoughallsuggestedworkflowscanbeappliedindividually TheSocialSignalInterpretationFramework(SSI)byWag-
andadaptedtouser-specificneeds,wesuggesttoconsiderthemas neretal.[42]presentsanalternativeapproach,byimplementinga
blueprintsforstartingdataexplorationwithDISCOVER. modular,multimodalsignalprocessingpipeline,facilitatingboth
onlineandofflinerecognitiontasks.Theplug-insystemwithinSSI
allowsuserstodevelopcustommodulesandintegratetheminto
2 RELATEDWORK
theprocessingpipeline.SimilartoSSItheOpensense[1]platform
Previousresearchinthefieldofhuman-computerinteractionhas hasbeendesignedtofacilitatereal-timeacquisitionandrecogni-
suggestedmethodsfordisplayingmultimodalcharacteristicswithin tionofsocialsignalsthroughmultiplemodalities.Italsofollows
particularconversationalcontextstoanalyzehumanbehavior. amodularpipelinedesignandbuildsonMicrosoft‚ÄôsPlatformfor
Overtime,arangeofannotationtoolsconcentratingonaffective SituatedIntelligence[8],whichenablestheprocessingofhuman
computingandsocialcueshasemerged,offeringassistancetousers behavioralsignalsandsupportsvarioussensordevicesandmachine
intheirefforts.ProminentexamplesincludeELAN[44],ANVIL[28], learningtools.Barzetal.[6]developedtheMultiSensorPipeline,
andEXMARALDA[38].Thesetoolsofferlayer-basedtierstoinsert alightweightandadaptableframeworkforcreatingmultimodal-
time-anchoredlabeledsegments,thatwecalldiscreteannotations. multisensorinterfacesusingreal-timesensordata.Whiletheframe-
Continuousannotations,ontheotherhand,allowanobserverto workisconceptuallysimilartoSSIandOpensenseitfocusesona
trackthecontentofanobservedstimulusovertimebasedona concisesetofconceptsandfunctionalitiesthateasethecreationand
continuous scale. One of the first tools that allowed labelers to executionofcomplexprocessingpipelines.Theprocessofimple-
traceemotionalcontentinreal-timeontwodimensions(activation mentingspecificmodulesislefttotheuser,makingthetoolbetter
andevaluation)wasFEELTRACE[13].ItsdescendantGTRACE suitedfordevelopingprototypesofcustommultimodal-multisensor
(generaltrace)[14]allowstheusertodefinetheirowndimensions processingpipelinesthanforusingstandardmodulestoanalyze
andscales.Morerecenttoolstoaccomplishcontinuousdescriptions socialsignals.Incontrasttothepurevisualexplorationofdata,
areCARMA(continuousaffectratingandmediaannotation)[21] Providenceimplementsascenesearchapproachtoinvestigate
andDARMA(dualaxisratingandmediaannotation)[22]. socialbehaviorinmultimodaldata.Hereby,ahumananalystcan
Recently,thesetoolshaveevolvedtoincludeautomaticcalcula- formulatequeriescontainingnon-verbal(e.g.nodding,facialex-
tionofbehavioralcuesandsocialsignals,eliminatingtheneedfor pressions),linguistic(e.g.sentiment),orpara-linguistic(e.g.speech
themanualannotationofdata.ForexampleEmodash[19]hasbeen speedorvolume)tosearchforspecificscenesinahumanconver-
designedtoenhancetutors‚Äôretrospectiveunderstandingoflearners‚Äô sation.Providenceautomaticallyextractstherespectivefeatures
emotions,basedonfacialexpressions,withinavideo-conferencing requiredbyaqueryandsearchesforscenesfulfillingthespecified
learningsetting.REsCUE[2]helpstoaidcoachingpractitioners conditionsinthedata.
todetectedunconsciousbehavioroftheirclients.Tothisend,REs- Althoughtheapproachespresentedhavetheirrespectivead-
CUEusesanunsupervisedanomalydetectionalgorithmtocluster. vantagesanddisadvantages,therearetwocommonshortcomings:
MultiSense[45]canassesstheaffectivestateofapersonbyin- Efficientuseofcomputingresourcesandacompromisebetween
ferringvariousindicatorsfromaudio-visualinputsignals.Thetool flexibilityandcomplexity.ExceptforProvidence,allthetoolsin-
focuses on the application within the mental health domain to troducedaresolelyintendedforoperationonlocalmachines.This
assessindicatorsofpsychologicaldistresssuchasdepressionor leadstoinefficientuseinmulti-userscenarios,inwhichuserseither
post-traumaticstressdisorder.MeetingCoach[36]isanAI-driven havetotaketurnsonalocalmachineoreachuserrequireshisown
feedbackdashboarddesignedtoenhancetheeffectivenessandin- workstationthatiscapabletorunsuchtools.Consideringhard-
clusivelyofvideo-conferencingmeetingsbyprovidingpersonalized waredemandsandenergyconsumptionofstate-of-the-artmachine
insightsintomeetingdynamics,suchasengagementsummariesof learningmodels,thisissueextendsbeyondfinancialconcernstoeco-
participantsorspeakingtimedistribution.MACH[25]socialskills logicalones.Further,itbecomesevidentthatoff-the-shelfsolutions
training,particularlyfocusingonjobinterviewpreparation,that haveconstraintsintheirapplicability,whereasmoreadaptableap-
analysesnon-verbalbehaviorofaninterviewee.TheAffectTool- proachesnecessitategreatertechnicalproficiency,therebyposing
box[31]providesasoftwaresystemaimedataidingresearchers abarriertoentry.
indevelopingaffect-sensitivestudiesandprototypesinaffectiveDISCOVER:AData-drivenInteractiveSystemforComprehensiveObservation,Visualization,andExploRationofHumanBehaviour
3 FRAMEWORK
Processing
LLM
Interfaces Storage
CHAT PROMPT Read /
NOVA
PROMPT
DISCOVER Assistant
Write
Media
REQUEST
DISCOVER Server
REQUEST Read /
Write
Script Annotation
Figure3:NOVAallowstovisualisevariousmediaandsig-
naltypesandsupportsdifferentannotationschemes.From
Module
topdownwards:upper-bodyvideosalongwithfacetrack-
ing,audiostreamsoftwopersonsduringaninteraction,and
Figure 2: Overview of the system components for the activationoftheactionunits.Inthelowerpart,free-value,
DISCOVERecosystem discrete,andcontinuousannotationtiersaredisplayed.
ThearchitectureofDISCOVERfollowsamodulardesign,which coefficient,Spearman‚ÄôscorrelationcoefficientorCohen‚ÄôsùúÖcanbe
facilitatesflexibility,scalability,andeaseofmaintenance.Atitscore, appliedtoidentifyinter-rateragreement.
theframeworkcomprisesseveralkeycomponents,eachservinga
distinctpurposeinenablinglaymentoperformdataexploration 3.2 AnnotationDatabase
tasksefficiently.Anoverviewofthesystemarchitectureisshown
Tosupportacollaborativeannotationprocess,DISCOVERmaintains
inFigure2.Below,weprovideatextualskeletonoutliningthemain
adatabaseback-end,whichallowsuserstoloadandsaveanno-
componentsandtheirfunctionalities.
tationsfromandtoaMongoDB2 databaserunningonacentral
server.Thisgivesannotatorsthepossibilitytoimmediatelycom-
3.1 UserInterface
mitchangesandfollowtheannotationprogressofothers.Besides
EachelementintheDISCOVERframeworkutilizesAPIstocom- humanannotators,adatabasemayalsobevisitedbyoneormore
municate over the network, granting users with programming ‚Äúmachineusers‚Äù.Justlikeahumanoperator,theycancreateand
skillssignificantflexibilitybyallowingaccessviascripts,irrespec- accessannotations.Hence,thedatabasealsofunctionsasamedia-
tive of the programming language employed. In order to make torbetweenhumanandmachine.DISCOVERprovidesinstruments
DISCOVERmore user-friendly for individuals without technical tocreateandpopulateadatabasefromscratch.Atanytimenew
expertise, we‚Äôve incorporated its API into the open-source tool annotators,schemes,andadditionalsessionscanbeadded.
NOVA[24],toserveasthegraphicaluserinterface.NOVAaims
toenhancethestandardannotationprocesswiththelatestdevel- 3.3 MediaFileStorage
opmentsfromcontemporaryresearchfieldssuchasCooperative
DISCOVERusesadatastoragecomponentthatfollowsthestructure
MachineLearningandeXplainableArtificialIntelligencebygiving
oftheopen-sourcecloudhostingframeworkNextcloud3.Datacan
annotatorseasyaccesstoautomatedmodeltrainingandprediction
behostedonalocaldriveandbesharedondemandwithpeople
functionalities,aswellassophisticatedexplanationalgorithmsvia
whohavebeengrantedaccesstotherespectiveDatabase.Boththe
itsuserinterface.
NOVAuserinterface,aswellastheprocessingbackendcanaccess
TheNOVAuserinterfacehasbeendesignedwithaspecialfocus
thesefilesforvisualizationandprocessingrespectively.
ontheannotationoflongandcontinuousrecordingsinvolving
multiplemodalitiesandsubjects.Ascreenshotofaloadedrecording 3.4 ProcessingServer
sessionisshowninFigure3.Onthetop,severalmediatracksare
Theprocessingserveractsasthecomputationalenginepowering
visualizedandreadyforplayback.Notethatthenumberoftracks
dataanalysistaskswithinourframework.Itimplementsalight-
thatcanbedisplayedatthesametimeisnotlimitedandvarious
weightwebserverthatinteractswiththeannotationanddatastor-
typesofsignals(video,audio,facialfeatures,skeleton,depthimages,
agecomponentstoextractmeaningfulinformationfromthedata,
etc.)aresupported.Inthelowerpart,weseemultipleannotation
thatcansubsequentlybevisualizedinNOVA.Theserver-based
tracksofdifferenttypes(discrete,continuous,andtranscriptions)
describingthevisualizedcontent.
architectureofDISCOVERprovideskeyadvantagesconcerningflex-
ibility,accessibility,andresourceefficiency.Firstofall,exposinga
NOVA provides several functions to process the annotations
createdbymultiplehumanormachineannotators.Forinstance,
2https://www.mongodb.com/
statisticalmeasuressuchasCronbach‚Äôsùõº,Pearson‚Äôscorrelation 3https://nextcloud.com/de/Schiller,etal.
RESTAPImakestheservernotonlyaccessiblefromtheNOVAuser infersanapproximate3Dmeshrepresentationofahumanface
interfacebutalsoviascripts.Thisresultsinalowentrybarrierfor fromasinglecamera.
notcodingaffineresearch,whilemaintainingtheabilitytoinclude
theprocessingfunctionalityincustomscripts.Second,theserver- ActionUnits. Facialactionunitsoriginatefromananatomical
examinationofthefaceandcanbecategorizedaccordingtothe
basedapproachenablesmultipleuserstoprocessdatainacentral
FacialActionCodingSystem(FACS)outlinedbyEkmanandFriesen
placetoensureoptimalusageofcomputationalresources.Thestan-
[16].Forautomaticactionunitdetectionandintensityestimation,
dardizedinputandoutputformatsoftheprocessingmodulesalso
weintegratedtheLibreFace[11]frameworkwhichachievesstate-
enablethesharingandfurtherusageofresults.
of-the-artperformanceinbothtaskswhileimprovinginference
timesoverothermethods.
3.5 Assistant
Recentlylargelanguagemodels(LLM),likeChat-GPT4orLLama FacialExpression. Facialexpressionanalysisinvolvesautomati-
[41]havedemonstratedremarkablecapabilitiesfortextualanaly- callydetectingsubtlemovementsinfacialmusclesandidentifying
sistasksliketextsummarization[29,30,39],sentimentanalysis typicalfacialdisplays.Therecognitionoftheseexpressionsyields
[20,46]orargumentmining[26,34].Toincorporatesuchcapa- valuableinsightsintousers‚Äôsocialandemotionalstates.Tofacilitate
bilitiesintoDISCOVER,wesupplementtheprocessorcomponent robustfacialexpressionpredictionweintegratedmultiplemodels
withanassistant.Fundamentallytheassistantisalightweightweb intoDISCOVEREmonet[40],Relevance-baseddatamasking[37],
serverthataimstointegratenumerousLLMswiththerestofthe LibreFace[11].
DISCOVERinfrastructure.Tothisend,theassistantisexposinga
4.2 Voice
unified API that reroutes requests to either an external service
provider(e.g.OpenAI),aself-hostedlargelanguagemodel(e.g.via Whenanalyzinghumanspeechtogainbehavioralinsights,one
Ollama5.ThroughseamlessintegrationwiththeUI,userscanin- needs to distinguish between the verbal and vocal components
teractwithAIassistantsviaachatinterfacetoanalyzetextualdata, of speech. Verbal refers to communication that is expressed in
suchasdialoguetranscripts.Dependingontheperformanceofa wordsorlanguage.Itinvolvestheuseoflanguagetoconveyideas,
modelforspecifictasksandprivacyrequirementsausercanswitch thoughts,orinformation.Vocalontheotherhandreferstothe
betweenavailableservicesdynamicallyduringtheexplorationpro- soundsproducedbythevoiceortheactofspeaking.Inthecontext
cess. ofcommunication,"vocal"canrefertothetone,pitch,volume,and
otherqualitiesofspeech.
4 MODULES
4.2.1 Verbal. Aprerequisitetotheanalysisoftheverbalcontentof
DISCOVERreliesonexchangeablemodulestoinferbehavioralindi- spokenlanguageistheconversionfromspeechtotext(STT).STT-
catorsfromrecordeddata.Eachofthesemodulescanbeunderstood Systemshavebeenanactiveareaofresearchfordecades.Forthe
asaconfigurablebuildingblock,consistingofpredefinedinputsand implementationofourSTTmodulewerelyonWhisperX[3],an
outputswithmodule-specificoptions.DISCOVERisfullyextend- adaptationoftheWhisperModelRadfordetal.[35],thatprovides
ablewithcustommodules.However,tokeeptheentrancebarrier improvedtimestampaccuracy,supportforlongeraudiosequences,
low and provide value for a non-coding affine target group we andfastertranscriptionperformance.
alsoprovideanumberofready-to-useprocessingmodules.The
followingsectionprovidesanoverviewofthecurrentlyintegrated SpeakerDiarization. Theavailabledatasetsaretypicallyrecorded
withthefocusofmanualhumananalysisratherthanautomatic
modules.
processing.Acommonexampleofthisistherecordingofasingle
4.1 Face audiosignalforseveralspeakers.Whileitisamostlytrivialtask
forahumanlistenertodistinguishbetweenthevoicesofspeak-
BoundingBoxDetector. Theautomaticderivationofbehavioral ersandmapthecontentofthespokenlanguagetotherespective
indicatorsfromahumanfaceusuallyrequiresthelocalizationof
person,thisinformationgetslostduringtheSTTprocess.Toac-
thefacialareainanimageorvideo.Tothisend,werelyonthe
countforthislossofinformationDISCOVERimplementsaspeaker
BlazeFacemodelproposedby[7]etal.TheBlazeFacemodelisa
diarisationmodule,whichmapssegmentsofacommondialogue
lightweightfacedetectionmodelthathasbeendevelopedtorunon
transcripttoindividualspeakers.TothisendwerelyonPyannote
mobiledevicesandthusrequiresonlyaminimumofcomputational
[9,10]toclustervoicedsegmentsintheaudiosignal.Wethenuse
resourcestoachievesuper-realtimeperformance.
anoracleapproachtoassignthoseclusterstoindividualspeakers,
byprovidingreferencespeakingtermswithintheaudiosignal.
LandmarksandMeshes. Forthefurtherprocessingofthelocal-
izedimage,it‚Äôsitisacommonproceduretoalignfacialimages SentimentAnalysis. Sentimentanalysisistheprocessofcompu-
basedonlocalizedlandmarks[11].Facialimagealignmentinvolves tationallydeterminingtheemotionaltonebehindapieceoftext,
geometrictransformationsliketranslation,rotation,andscalingto whetherit‚Äôspositive,negative,orneutral.Itcanbeavaluabletool
converttheinputfaceimageintoastandardizedform.Tothisend, foranalyzinghumanbehavior,asitcanprovideadeeperunder-
weemploythefacemeshmodelbyKartynniketal.[27],which standingofindividuals‚Äôemotionsandopinions.Toenabletheauto-
maticpredictionofsentiment,DISCOVERcurrentlyintegratestwo
approaches.Amulti-lingual[4])andaGermanlanguagespecific
4https://chatgpt.com/
5https://ollama.com/ [23]model.DISCOVER:AData-drivenInteractiveSystemforComprehensiveObservation,Visualization,andExploRationofHumanBehaviour
4.2.2 Vocal. Speechemotionrecognition(SER)referstothetask Module
of automatically detecting and interpreting emotions conveyed
throughspeech.Itinvolvesanalyzingvariousacousticfeatures,
suchaspitch,intensity,andrhythm,toinfertheunderlyingemo-
tionalstateofthespeaker.DISCOVERintegratesapretrainedmodel, Visual Inspection
proposedbyWagneretal.[43]toautomaticallydetectvalence,
arousal,anddominancevaluesfromahumanvoice.
4.3 MultimodalFeatureExtraction
2
Besidestheabove-mentionedmodules,whichdirectlyprovidein-
AidedAnnotation
sightsaboutimportantindicatorsforhumanbehaviortoananalyst, Interactive semantic content
DISCOVERalsoimplementsmodality-specificfeatureextraction exploration
modules,thatcanbeusedtotraincustomdetectionmodels.
Video. For the video modality we use the DinoV2 pretrained 3
visiontransformermodels[15,32]toextractfeatures.Thosemodels Multimodal Scene
1 Search
arepretrainedinaself-supervisedmanneronalargedatasetof
142millionimages.Asaresult,DINOv2modelshavedemonstrated
robustperformancebeyondtrainingdata,deliveringusablegeneral-
purposefeatureswithouttheneedforfine-tuning.
4
Audio. For the audio modality we rely on a pretrained w2v-
BERT2.0encoder[5].SimilartotheDinoV2model,thismodel
Figure4:Schematicrepresentationoftheexploratorydata
wastrainedunsupervisedonalargedatasetof4.5millionhours
analysisworkflow.1.Explorethecontentofaconversation
ofaudio,anddemonstratesexcellentperformanceforavarietyof
downstreamtaskslikespeechtotext,orexpressivespeechtospeech
usingtheDISCOVERassistant.2.Computeandvisualizebe-
havioralcues.3.Annotateadditionalindicatorswiththehelp
translation.However,itisrecommendedtofine-tunethew2v-BERT
ofcooperativemachinelearning.4.Identifyscenesthatcon-
2.0modelbeforeusingitforadownstreamtask.Sincethismight
sistofaninterplayofseveralindicators.Everystepinthe
notbefeasiblefortechnicalunsavvyuserswealsointegratedthe
workflowcanberepeatedandadaptedasnecessary.
openSMILElibrary[18],whichextractsvarioushandcraftedfeature
sets for the audio domain. Specifically, the GeMaps feature set
[17]hasbeendevelopedforgeneralvoiceresearchandaffective
computingtasksandprovidesagoodstartingpointforanyspeech-
relatedclassificationtask.
Text. Whenitcomestoextractingfeaturesfromtextrepresenta-
tions,thelanguageofthetextisanecessaryconsideration.Since
itisakeyaspectofourframeworktobeemployableinversatile
scenariosacrossmultiplelanguages,DISCOVERintegratesamulti-
lingualtextualfeatureextractionusingtheXLMroBERTa(XLM-R)
modelbyConneauetal.[12]Thismodelconsistsofatransformer-
basedarchitecture,trainedonvastamountsofmultilingualdata
crawledfromtheinternet.Intheirexperiments,theauthorsana-
lyzedthecapabilitiesofXLM-Rforseveraltasks,includingname
entityrecognition,cross-lingualquestionanswering,paraphrasing,
andsentimentanalysis.Thereportedresultsindicatethatthemodel
performs close to or even better than comparable monolingual
modelsforlanguageswherevasttrainingresourcesareavailable.
Furthermore,themodelshowedsubstantialimprovementsover
otherstate-of-the-artmodelsonlow-resourcelanguagesacrossall
tasks.
Figure5:Auserengageswiththeassistanttoexplorethe
5 INTERACTIVEDATAEXPLORATION semanticsofaconversationinteractively.
5.1 SemanticContentExploration
Inthefollowingsection,wedemonstratethecapabilitiesofDISCOVERusing
fourexemplaryworkflowstoexamineunseendataandgathernew
insights.WhileeachofourshowcasesisbuildingupontheresultsSchiller,etal.
Figure6:VisualdatainspectionwithNOVAandDISCOVER.Thesessionoverviewprovidesacomprehensivesummaryof
theextractedbehaviorindicatorsacrosstheentiresession.Zoominginatthebottomenablesadetailedanalysisofidentified
scenesofinterest.
ofthepreviousone,everyworkflowcanalsobecarriedoutinde- "Context-Aware"checkboxinthebottomNOVAthetranscriptthat
pendentlyoftheothers.Thecompleteiterativedataexploration hasbeenloadedintoNOVAbeforewillbeautomaticallysentto
pipelineisdepictedinFigure4. theassistantaccompanyingeachmessage.Thatwayausercan
Wedemonstratehowourworkflowoperatesbyutilizingrecord- directly ask the assistant any questions regarding the semantic
ingsofinteractionsbetweenteachersandparents.Thesevideos contentofthedialogue.Firstlytheuserrequestsasummaryofthe
arecapturedtoevaluatethecommunicationabilitiesofaspiring interaction.Theassistantreplieswithaconcisesummaryofthe
teachersinconsultativesituationsandofferthemconstructivefeed- transcript,providingtheuserwithinformationaboutthegeneral
back.Withinthiscontext,theteacherisatrainee,whiletheroleof setting and topic of the dialogue, the roles of the interlocutors,
theparentisportrayedbyanactor.Thesubjectofthediscussion andthecourseoftheconversation.Astheuserhasgainedthose
revolvesaroundthechildoftheparent,whoisfacingchallenges insightsaboutthedata,thenextstepistogathermoreinformation
inschool.SincetheoriginaldiscussionisinGermanatranslated on relevant behavioral aspects to look out for. To this end, the
versioncanbefoundinAppendixA1.Thefollowingisanexample useraskstheassistantdirectlyaboutimportantcriteriatoassess
workflowoftheusecasefordataanalysisfromananalyst‚Äôspoint thequalityofcommunicationinparent-teacherconferences.The
ofview. assistantanswersbyprovidingtenindicatorsfortheassessment
Asafirststeptowardsfindingindicatorsofcommunicativequal- ofdialoguequality,likePositiveoutcomeorCollaborativeapproach.
ityintherecordedinteractions,auserwantstogetfamiliarwith Eachpointisaccompaniedbyashortdescriptiontoclarifythe
thedataandthetask.Tofacilitatethosetasks,DISCOVERassistant meaning.Fromtheprevioussummary,itisalreadyclearthatthe
enablestheinteractiveexplorationofthesemanticcontentofthe teacherandparentareworkingtogetherandtheoutcomeofthe
dialogue.TobeginusingtheassistantauserfirstutilizestheWhis- dialogispositiveasbothpartiesagreeonhowtheywanttoproceed
perXprocessingmoduletocreateatemporal-alignedtranscriptfor inthefuturetosupportthechild‚Äôslearning.Theuserthencontinues
eachspeakerfromtherecordedaudiosignal(seeAppendixA1). toasktheassistanttoevaluatethetranscriptconcerningthenow-
AfterloadingthetranscriptiondataintoNOVAtheuserclicks identifiedindicatorstogetdeeperinsightsbeyondthesummary.In
on the Assistant tab and a chat window opens that establishes return,theassistantprovidesfurtherinformationaboutindicators
a connection with the assistant (see Figure 5). By checking the like Empathy and Active Listening, based on the full transcript.DISCOVER:AData-drivenInteractiveSystemforComprehensiveObservation,Visualization,andExploRationofHumanBehaviour
Finally,theuseralsowantstoknowaboutnon-verbalindicatorsfor
communicationquality,towhichtheassistantagainprovidesalist Figure7:Samplecodedemonstratinghowtocreateananno-
ofkeypointstolookoutforlikeFacialExpressions/Smiles,Gaze tationfordetectingsmilemirroring.
orVocalInflectionsandTone.AppendixA2showsthecomplete
# Inputs
dialoguebetweentheuserandtheassistant. smile_teacher = {
"src": "db:annotation:Discrete",
"type": "input",
"id": "smile_teacher",
5.2 AidedAnnotation "scheme": "smile",
"role": "teacher",
TheprocessingmodulesdescribedinSection4areacoreaspect "annotator": "DISCOVER",
}
ofDISCOVER.However,theylargelydependontheavailability
smile_parent = {
ofpre-trainedmodelsforprocessing.Dependingontheusecase "src": "db:annotation:Discrete",
"type": "input",
there might be no fitting model available for the task that the "id": "smile_parent",
"scheme": "smile",
userislookingfor.Toalleviatethisproblem,DISCOVERprovides "role": "parent",
supportforfeatureextraction,thatcanbeusedtotraincustom "annotator": "DISCOVER",
}
modelsdirectlyfromwithintheNOVAuserinterface.Tothisend,
ds_iterator = DatasetIterator(
NOVAimplementsacooperativemachinelearningworkflowthat dataset="dataset_name",
session_names="session_name",
consistsofthefollowing5steps:Initially,themodelundergoes data_description=[smile_teacher, smile_parent],
frame_size=40,
training(Step1)andisthenutilizedtopredictunseendata(Step left_context=1960,
source_context=<DB_CREDENTIALS>,
2).Followingthis,anactivelearningmoduledetermineswhich )
portionsofthepredictionnecessitatemanualreviewbyhuman ds_iterator.load()
annotators(Step3).Subsequently,thoselabelsarethenreviewed # Processing
output = []
byahumanandcorrectedifnecessary.Finally,theinitialmodel for sample in ds_iterator:
mirror = ((sample["smile_teacher"][0] != 0) and
isretrainedusingtheupdatedlabeleddata(Step5).Thisiterative (sample["smile_parent"][0] != 0))
score = int(mirror)
processcontinuesuntilalldataisannotated.Byactivelyintegrating confidence = 1
output.append((score, confidence))
humanexpertiseintothelearningprocess,weenableinteractive
guidanceandenhancementofautomaticpredictions.Following # Creating the annotation
annotation_scheme = ContinuousAnnotationScheme(
thesuggestionsoftheDISCOVERAssistant,theusertrainsanew n sa am me p= l" es _m rai tl ee_ =mi 2r 5ro ,ring",
modelthatisabletodetectsmiles,basedontheextractedfacemesh min_val=0,
max_val=1
data.Beforecontinuingthenextstepthemodelisusedtodetect )
annotation = ContinuousAnnotation(
allinstancesofsmilesfortheteacheraswellastheparent. scheme=annotation_scheme,
data=np.asarray(output, dtype=annotation_scheme.label_dtype)
)
fh = FileHandler()
5.3 VisualInspection fh.save(data=annotation, fp='./smile_mirroring.annotation')
Duringthisstage,theuservisuallyexaminesthesessionbynav-
igatingthroughsessionsandtheirtimeline.Theobjectiveatthis
stageistoidentifypatternsandformulatehypothesesregarding parentmightsimplybedisplayingaseriousexpression.Inaddition,
theirmanifestation,aimingtoextractfurtherinsights.Toconfirm theusernowloadsthesmileannotationgeneratedintheprevious
orquestionthesehypotheses,userscanselectaprocessingmodule step(seeSection5.2).
(seeSection4)directlyfromtheNOVAUserinterfaceandstart Smilingoccursnotablymoreoftenatthebeginningandendof
anextractionjobontheprocessingserver.Oncetheprocessingis theconversationforbothroles,withtheteacherexhibitingsmiles
done,theresultscanbedirectlyvisualizedintheUI.Thisiterative morefrequentlythroughouttheconversation.Astheincreased
processcanberepeatedasoftenasnecessaryfordifferentmod- numberofsmilesatthebeginningandendcanlikelybeattributedto
ules.Sincetheresultsofthepreviousmodulesarestoredeither formalpolitenesstheuserfirstfocusesonthemiddlesectionsofthe
intheannotationdatabaseoronthemediastorage,theusercan conversation.Especiallyvisuallyidentifying,mirroringbehavior
reusethematanytime,withoutrecomputingthem.Toprovide wherethesmileofoneinterlocutorismirroredbytheotherone,
aclearerillustrationofthisprocess,wepickupontheprevious providesinterestinginsights.Forexample,thereisanotablescene
example.Buildingupontheresultsofthesemanticcontentexplo- inwhichtheparents‚Äôsmilesmirrortheteacher‚Äôssmile,amomentin
rationdescribedin5.1thenextstepsareanalyzingthenon-verbal whichtheparentsreceivenewandhelpfulinformation,indicating
cuesfromtheaudioandthevideosignalandfindingadditional activeparticipationinthedialog.
semanticindicatorstoassessthequalityofcommunicationbased This observation underscores the significance of integrating
onthetranscript. visualandverbalcuestocapturethedynamicsofcommunication
Tocontinuetheexploration,theuserpredictsthefacialexpres- andemotionalexpressionwithintheinteraction.
sionsofboththeteacherandtheparentusingtheEmoNetmodule.
5.4 SceneSearch
Uponloadingthemodel‚ÄôspredictionsintoNOVA.Asdepictedin
Figure6itbecomesapparentthattheteacher‚Äôsfacialexpressions Asevidenced,theexplorationofconversationalscenesthrough
predominantlyoscillatebetween"happy"and"surprised,"whereas theanalysisofparticipants‚Äômultimodalbehaviorpresentsconsid-
theparent‚Äôsexpressionstendtoskewtowardsangerorsadness, erablepromiseforinvestigatingsocialdynamics.Theprocessof
althoughit‚Äôsnotedthatangermaynotalwaysbeaccurateasthe visualinspectionprovidesaneffectivemethodofidentifyingtheSchiller,etal.
constellationofsocialcuesinherentinaspecificscene.However, andcomprehensivenessofanalysis,giventhevariednatureofhu-
it is of limited use when it comes to retrieving all instances of manbehaviorexamination.Ontheotherhand,theserver-based
suchscenesinarecordingsession.Firstofall,it‚Äôseasytooverlook architectureandmodularstructureofDISCOVERpresentnotable
certainsceneswhenscrollingthroughthetimelineoflongerrecord- advantages,facilitatingtheseamlessexchangeofprocessingcom-
ingsessions.Second,theanalysisofsocialcueconstellationsthat ponentsandenablinguserstoeasilyincorporatenewmodulesor
requirepreciseassessmentofeithertimings(e.g.theimmediate tailormodulestotheirspecificneeds.Thisadaptabilityempowers
facialexpressiontoanevent)orvalues(e.g.thedegreetowhichan researcherstocustomizethetoolaccordingtotheirpreferencesand
actionunitisactivated),cannotbeefficientlyperformedthisway. requirements.Furthermore,DISCOVERexcelsinfosteringcollabo-
Lastly,itiseasytoseehowthereliableidentificationofpatterns rationamongresearchersbyfacilitatingthesharingofprocessed
thatconsistoftheinterplayofmultiplecluescanquicklybecome resultsandcomputingresources,therebypromotingefficientcol-
overwhelmingforahumananalyst.Totakealltheseaspectsinto laborationandnurturingasenseofcommunitywithintheresearch
account,DISCOVERprovidesanAPIthatallowstheusertodefine domain.Thiscollaborativeaspectenhancesthepotentialforcollec-
asetofrulesthatareusedtoautomaticallyidentifyscenesbased tiveinsightsanddiscoveries.
onpreviouslydefinedconditions.Buildingupontheresultsofthe Moreover,DISCOVERintroducesinnovativeworkflowcompo-
visualinspectionworkflow(seeSection5.3),ausercannowfol- nentssuchastheassistantandcooperativemachinelearningfunc-
lowablueprintscripttodownloadthesmiledetectionannotations tionalities,whichenhancetheefficiencyandeffectivenessofthe
forbothrolesfromthedatabase,moveaslidingwindowoverthe analysisprocess,ultimatelyyieldingmorerobustandinsightful
annotationsandcreateanewannotationbasedonapredefined results.Despiteitsweaknesses,includingpotentialmoduleimper-
mirroringcondition(seeFigure7). fectionsandmissingfunctionalities,DISCOVER‚Äôsstrengthsinits
modulararchitecture,collaborativefeatures,anduniqueworkflow
6 DISCUSSION componentspositionitasapromisingtoolfordemocratizingac-
cesstoadvancedcomputationalmethodologiesinhumanbehavior
Feedback. Toobtaininitialfeedback,wepresentedDISCOVERand
analysis.
theproposedworkflowtoanAIcommunicationresearcherwho
isinvolvedintheinterviewandfeedbackprocessfortheprospec-
tiveteachersintheanalyzedvideorecordings.Inhiscommentshe 7 CONCLUSION
statedthatthepotentialspeed-upofdataexplorationthroughthe
WeintroducedDISCOVER,anopen-sourcetooldesignedforhu-
proposedworkflowisbeneficialforthesocialsciencecommunity:
manbehaviouranalysisutilizingstate-of-theartmachinelearning
"Basicallyyouaremakingvideossearchable.Youcansearchforspe- modelsforfeatureextraction.Ourframeworkoffersauser-friendly
cificeventsasyousearchforawordinatranscript.Thisfunctionality interfacethroughNOVA,streamliningtheprocessanddiminishing
greatlyimprovestheanalysisoflargevolumesofdata." thenecessityforlaboriousvideoandaudioannotation.
Further,hementionsthatheconsideredDISCOVERtobeespe-
DISCOVERcanbeusedtoextractvarioushelpfulindicatorsto
ciallyusefulforinductiveanalyticstrategies,wherearesearcher
analyzehumanbehaviorsuchastranscription,facialexpression,
readsthroughthedataandallowsnewconceptstoemerge:"Ican
oremotions.Furthermore,wepresentedaprototypicalworkflow
seehowthiswouldbeusefulforgroundedtheoryapproaches.Inthis fortheexploratoryanalysisofhumanbehaviorinnewdata.Inthe
process,researchersexploredataiterativelywithoutanypreviousas- future,weplantofurtherenhancethepredictivecapabilitiesof
sumptionsaboutthefindingstocomeupwithnewhypothesesand DISCOVERbyintegratingnewprocessingmodulesandimproving
theories." theworkflow.
Ontheotherhand,healsomentionedhowskepticalheisabout
usingthetooltoaiddeductivestrategieswherearesearcherapplies
REFERENCES
anexistingtheoryonnewdata.Hestatedthatwrongormissing
predictionsoftheautomaticallyinferredcuescouldhaveacrucial [1] KarlAberer,SaketSathe,DipanjanChakraborty,AlcherioMartinoli,Guillermo
Barrenetxea,BoiFaltings,andLotharThiele.2010.Opensense:opencommu-
impactontheresults:"WhenIanalyzedthetranscriptsgenerated
nitydrivensensingofenvironment.InProceedingsoftheACMSIGSPATIAL
withWhisper,Iwaslookingforfillerandbackchannels.Ittookme InternationalWorkshoponGeoStreaming.39‚Äì42.
[2] RikuArakawaandHiromuYakura.2019.REsCUE:AframeworkforREal-time
awhiletorealize,thatmostofthoseshortsequencesarefilteredout
feedbackonbehavioralCUEsusingmultimodalanomalydetection.InProceedings
duringthetranscriptionprocess.Ineededtoaddthemagainmanually ofthe2019CHIConferenceonHumanFactorsinComputingSystems.1‚Äì13.
tobeabletousethetranscription." [3] MaxBain,JaesungHuh,TengdaHan,andAndrewZisserman.2023.WhisperX:
Lastly,healsosuggestedhowDISCOVERcouldbedeployedas
T (2i 0m 2e 3- )A .ccurateSpeechTranscriptionofLong-FormAudio.INTERSPEECH2023
aninteractivefeedbacktoolinthefuture:"Thisvisualizationcould [4] FrancescoBarbieri,LuisEspinosaAnke,andJoseCamacho-Collados.2022.XLM-
T:MultilingualLanguageModelsinTwitterforSentimentAnalysisandBeyond.
alsobeinterestingforthestudentswhenprovidingfeedbackabout
InProceedingsoftheThirteenthLanguageResourcesandEvaluationConference.
theircommunicationskills.Itmightbeinterestingtoevenletthem EuropeanLanguageResourcesAssociation,Marseille,France,258‚Äì266. https:
exploretheirownconversationsinteractively." //aclanthology.org/2022.lrec-1.27
[5] Lo√ØcBarrault,Yu-AnChung,MarianoCoriaMeglioli,DavidDale,NingDong,
LimitationsandProspects. WhileDISCOVERboastsamodular MarkDuppenthaler,Paul-AmbroiseDuquenne,BrianEllis,HadyElsahar,Justin
Haaheim,etal.2023.Seamless:MultilingualExpressiveandStreamingSpeech
architecture,it‚Äôsworthnotingthatcertainmodulesmaynotyield Translation.arXivpreprintarXiv:2312.05187(2023).
perfectresults,potentiallyintroducinginaccuraciesorlimitations, [6] MichaelBarz,OmairShahzadBhatti,BengtL√ºers,AlexanderPrange,andDaniel
especiallyinscenariosrequiringpreciseresults.Additionally,theab- Sonntag.2021.Multisensor-pipeline:alightweight,flexible,andextensibleframe-
workforbuildingmultimodal-multisensorinterfaces.InCompanionPublication
senceofcertainmoduleswithinDISCOVERcouldrestrictthescope ofthe2021InternationalConferenceonMultimodalInteraction.13‚Äì18.DISCOVER:AData-drivenInteractiveSystemforComprehensiveObservation,Visualization,andExploRationofHumanBehaviour
[7] ValentinBazarevsky,YuryKartynnik,AndreyVakunov,KarthikRaveendran, [31] SilvanMertes,DominikSchiller,MichaelDietz,ElisabethAndr√©,andFlorian
andMatthiasGrundmann.2019.Blazeface:Sub-millisecondneuralfacedetection Lingenfelser.2024. TheAffectToolbox:AffectAnalysisforEveryone. arXiv
onmobilegpus.arXivpreprintarXiv:1907.05047(2019). preprintarXiv:2402.15195(2024).
[8] DanBohus,SeanAndrist,AshleyFeniello,NickSaw,MihaiJalobeanu,Patrick [32] MaximeOquab,Timoth√©eDarcet,TheoMoutakanni,HuyV.Vo,MarcSzafraniec,
Sweeney,AnneLoomisThompson,andEricHorvitz.2021.PlatformforSituated VasilKhalidov,PierreFernandez,DanielHaziza,FranciscoMassa,Alaaeldin
Intelligence. arXiv:2103.15975[cs.AI] El-Nouby,RussellHowes,Po-YaoHuang,HuXu,VasuSharma,Shang-WenLi,
[9] Herv√©BredinandAntoineLaurent.2021.End-to-endspeakersegmentationfor WojciechGaluba,MikeRabbat,MidoAssran,NicolasBallas,GabrielSynnaeve,
overlap-awareresegmentation.InProc.Interspeech2021.Brno,CzechRepublic. IshanMisra,HerveJegou,JulienMairal,PatrickLabatut,ArmandJoulin,and
[10] Herv√©Bredin,RuiqingYin,JuanManuelCoria,GregoryGelly,PavelKorshunov, PiotrBojanowski.2023. DINOv2:LearningRobustVisualFeatureswithout
MarvinLavechin,DiegoFustes,HadrienTiteux,WassimBouaziz,andMarie- Supervision.
PhilippeGill.2020.pyannote.audio:neuralbuildingblocksforspeakerdiarization. [33] AnnaPenzkofer,PhilippM√ºller,FelixB√ºhler,SvenMayer,andAndreasBulling.
InICASSP2020,IEEEInternationalConferenceonAcoustics,Speech,andSignal 2021.Conan:Ausabletoolformultimodalconversationanalysis.InProceedings
Processing.Barcelona,Spain. ofthe2021InternationalConferenceonMultimodalInteraction.341‚Äì351.
[11] DiChang,YufengYin,ZongjianLi,MinhTran,andMohammadSoleymani. [34] Mircea-LuchianPojoni,LorikDumani,andRalfSchenkel.2023. Argument-
2024.LibreFace:AnOpen-SourceToolkitforDeepFacialExpressionAnalysis. MiningfromPodcastsUsingChatGPT.InInprocs.oftheWorkshopsatInterna-
InProceedingsoftheIEEE/CVFWinterConferenceonApplicationsofComputer tionalConferenceonCase-BasedReasoning(ICCBR-WS2023)co-locatedwiththe
Vision(WACV). Toappear. 31stInternationalConferenceonCase-BasedReasoning(ICCBR2023),Aberdeen,
[12] AlexisConneau,KartikayKhandelwal,NamanGoyal,VishravChaudhary,Guil- Scotland,UK,Vol.3438.129‚Äì144.
laumeWenzek,FranciscoGuzm√°n,EdouardGrave,MyleOtt,LukeZettle- [35] AlecRadford,JongWookKim,TaoXu,GregBrockman,ChristineMcLeavey,and
moyer,andVeselinStoyanov.2019. UnsupervisedCross-lingualRepresenta- IlyaSutskever.2023.Robustspeechrecognitionvialarge-scaleweaksupervision.
tionLearningatScale. CoRRabs/1911.02116(2019). arXiv:1911.02116 http: InInternationalConferenceonMachineLearning.PMLR,28492‚Äì28518.
//arxiv.org/abs/1911.02116 [36] SamihaSamrose,DanielMcDuff,RobertSim,JinaSuh,KaelRowan,JavierHer-
[13] RoddyCowie,EllenDouglas-Cowie,SusieSavvidou*,EdelleMcMahon,Martin nandez,SeanRintel,KevinMoynihan,andMaryCzerwinski.2021.Meetingcoach:
Sawey,andMarcSchr√∂der.[n.d.].‚ÄôFEELTRACE‚Äô:Aninstrumentforrecording Anintelligentdashboardforsupportingeffective&inclusivemeetings.InPro-
perceivedemotioninrealtime.InISCATutorialandResearchWorkshop(ITRW) ceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems.
onSpeechandEmotion(2000). 1‚Äì13.
[14] RoddyCowie,GaryMcKeown,andEllenDouglas-Cowie.2012.TracingEmotion: [37] DominikSchiller,TobiasHuber,MichaelDietz,andElisabethAndr√©.2020.
AnOverview.IJSE3,1(2012),1‚Äì17. Relevance-baseddatamasking:amodel-agnostictransferlearningapproach
[15] Timoth√©eDarcet,MaximeOquab,JulienMairal,andPiotrBojanowski.2023. forfacialexpressionrecognition.FrontiersinComputerScience2(2020),6.
VisionTransformersNeedRegisters. [38] ThomasSchmidt.[n.d.].TranscribingandannotatingspokenlanguagewithEX-
[16] PaulEkmanandWallaceVFriesen.1976.Measuringfacialmovement.Environ- MARaLDA.InProceedingsoftheInternationalConferenceonLanguageResources
mentalpsychologyandnonverbalbehavior1(1976),56‚Äì75. andEvaluation:WorkshoponXMLbasedrichlyannotatedcorpora,Lisbon2004
[17] FlorianEyben,KlausRScherer,Bj√∂rnWSchuller,JohanSundberg,Elisabeth (Paris,2004).ELRA,879‚Äì896. EN.
Andr√©,CarlosBusso,LaurenceYDevillers,JulienEpps,PetriLaukka,ShrikanthS [39] MayankSoniandVincentWade.2023.Comparingabstractivesummariesgener-
Narayanan, et al. 2015. The Geneva minimalistic acoustic parameter set atedbychatgpttorealsummariesthroughblindedreviewersandtextclassifica-
(GeMAPS)forvoiceresearchandaffectivecomputing. IEEEtransactionson tionalgorithms.arXivpreprintarXiv:2303.17650(2023).
affectivecomputing7,2(2015),190‚Äì202. [40] AntoineToisoul,JeanKossaifi,AdrianBulat,GeorgiosTzimiropoulos,andMaja
[18] FlorianEyben,MartinW√∂llmer,andBj√∂rnSchuller.2010.Opensmile:themunich Pantic.2021.Estimationofcontinuousvalenceandarousallevelsfromfacesin
versatileandfastopen-sourceaudiofeatureextractor.InProceedingsofthe18th naturalisticconditions.NatureMachineIntelligence(2021). https://www.nature.
ACMinternationalconferenceonMultimedia.1459‚Äì1462. com/articles/s42256-020-00280-0
[19] MohamedEz-Zaouia,Aur√©lienTabard,andEliseLavou√©.2020.EMODASH:A [41] HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-Anne
dashboardsupportingretrospectiveawarenessofemotionsinonlinelearning. Lachaux,Timoth√©eLacroix,BaptisteRozi√®re,NamanGoyal,EricHambro,Faisal
InternationalJournalofHuman-ComputerStudies139(2020),102411. Azhar,etal.2023.Llama:Openandefficientfoundationlanguagemodels.arXiv
[20] GeorgiosFatouros,JohnSoldatos,KalliopiKouroumali,GeorgiosMakridis,and preprintarXiv:2302.13971(2023).
DimosthenisKyriazis.2023.Transformingsentimentanalysisinthefinancial [42] JohannesWagner,FlorianLingenfelser,TobiasBaur,IonutDamian,FelixKistler,
domainwithChatGPT.MachineLearningwithApplications14(2023),100508. andElisabethAndr√©.2013. Thesocialsignalinterpretation(SSI)framework:
[21] JeffreyMGirard.[n.d.]. CARMA:Softwareforcontinuousaffectratingand multimodalsignalprocessingandrecognitioninreal-time.InProceedingsofthe
mediaannotation.2,1([n.d.]),e5. 21stACMinternationalconferenceonMultimedia.831‚Äì834.
[22] JeffreyMGirardandAidanGCWright.[n.d.].DARMA:DualAxisRatingand [43] JohannesWagner,AndreasTriantafyllopoulos,HagenWierstorf,Maximilian
MediaAnnotation.([n.d.]). Schmitt,FelixBurkhardt,FlorianEyben,andBj√∂rnWSchuller.2023.Dawnof
[23] OliverGuhr,Anne-KathrinSchumann,FrankBahrmann,andHansJoachim theTransformerErainSpeechEmotionRecognition:ClosingtheValenceGap.
B√∂hme.2020. TrainingaBroad-CoverageGermanSentimentClassification IEEETransactionsonPatternAnalysisandMachineIntelligence(2023),1‚Äì13.
ModelforDialogSystems.InProceedingsofThe12thLanguageResourcesand [44] PeterWittenburg,HennieBrugman,AlbertRussel,AlexanderKlassmann,and
EvaluationConference.EuropeanLanguageResourcesAssociation,Marseille, HanSloetjes.2006.ELAN:aProfessionalFrameworkforMultimodalityResearch.
France,1620‚Äì1625. https://www.aclweb.org/anthology/2020.lrec-1.202 InProceedingsoftheFifthInternationalConferenceonLanguageResourcesand
[24] AlexanderHeimerl,TobiasBaur,FlorianLingenfelser,JohannesWagner,and Evaluation,LREC2006,Genoa,Italy,May22-28,2006.,NicolettaCalzolari,Khalid
ElisabethAndr√©.2019. NOVA-AtoolforeXplainableCooperativeMachine Choukri,AldoGangemi,BenteMaegaard,JosephMariani,JanOdijk,andDaniel
Learning.In20198thInternationalConferenceonAffectiveComputingandIntelli- Tapias(Eds.).EuropeanLanguageResourcesAssociation(ELRA),1556‚Äì1559.
gentInteraction(ACII).109‚Äì115. https://doi.org/10.1109/ACII.2019.8925519 [45] YouweiZeng,DanWu,JieXiong,JinyiLiu,ZhaopengLiu,andDaqingZhang.
[25] MohammedHoque,MatthieuCourgeon,Jean-ClaudeMartin,BilgeMutlu,and 2020.MultiSense:Enablingmulti-personrespirationsensingwithcommodity
RosalindWPicard.2013.Mach:Myautomatedconversationcoach.InProceed- wifi. ProceedingsoftheACMonInteractive,Mobile,WearableandUbiquitous
ingsofthe2013ACMinternationaljointconferenceonPervasiveandubiquitous Technologies4,3(2020),1‚Äì29.
computing.697‚Äì706. [46] WenxuanZhang,YueDeng,BingLiu,SinnoJialinPan,andLidongBing.2023.
[26] ArmanIrani,JuYeonPark,KevinEsterling,andMichalisFaloutsos.2024.WIBA: Sentimentanalysisintheeraoflargelanguagemodels:Arealitycheck.arXiv
WhatIsBeingArgued?AComprehensiveApproachtoArgumentMining.arXiv preprintarXiv:2305.15005(2023).
preprintarXiv:2405.00828(2024).
[27] YuryKartynnik,ArtsiomAblavatski,IvanGrishchenko,andMatthiasGrund-
mann.2019.Real-timefacialsurfacegeometryfrommonocularvideoonmobile
GPUs.arXivpreprintarXiv:1907.06724(2019).
[28] MichaelKipp.[n.d.].ANVIL:TheVideoAnnotationResearchTool.InHandbook
ofCorpusPhonology.OxfordUniversityPress.
[29] YongLiu,ShenggenJu,andJunfengWang.2024. Exploringthepotentialof
ChatGPTinmedicaldialoguesummarization:astudyonconsistencywithhuman
preferences.BMCMedicalInformaticsandDecisionMaking24,1(2024),75.
[30] ZhehengLuo,QianqianXie,andSophiaAnaniadou.2023. Chatgptasafac-
tualinconsistencyevaluatorforabstractivetextsummarization.arXivpreprint
arXiv:2303.15621(2023).