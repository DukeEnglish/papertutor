TowardsthenewXAI:AHypothesis-DrivenApproachtoDecisionSupportUsing
Evidence
THAOLE,SchoolofComputingandInformationSystems,TheUniversityofMelbourne,Australia
TIMMILLER,SchoolofElectricalEngineeringandComputerScience,TheUniversityofQueensland,Australia
RONALSINGH,CSIROâ€™sData61,Australia
LIZSONENBERG,SchoolofComputingandInformationSystems,TheUniversityofMelbourne,Australia
PriorresearchonAI-assistedhumandecision-makinghasexploredseveraldifferentexplainableAI(XAI)approaches.Arecentpaper
hasproposedaparadigmshiftcallingforhypothesis-drivenXAIthroughaconceptualframeworkcalledevaluativeAIthatgivespeople
evidencethatsupportsorrefuteshypotheseswithoutnecessarilygivingadecision-aidrecommendation.Inthispaperwedescribeand
evaluateanapproachforhypothesis-drivenXAIbasedontheWeightofEvidence(WoE)framework,whichgeneratesbothpositive
andnegativeevidenceforagivenhypothesis.Throughhumanbehaviouralexperiments,weshowthatourhypothesis-drivenapproach
increasesdecisionaccuracy,reducesreliancecomparedtoarecommendation-drivenapproachandanAI-explanation-onlybaseline,
butwithasmallincreaseinunder-reliancecomparedtotherecommendation-drivenapproach.Further,weshowthatparticipants
usedourhypothesis-drivenapproachinamateriallydifferentwaytothetwobaselines.
CCSConcepts:â€¢Computingmethodologiesâ†’Artificialintelligence;â€¢Human-centeredcomputingâ†’HCItheory,concepts
andmodels.
AdditionalKeyWordsandPhrases:XAI,decision-making,hypothesis-driven,evidence,evaluativeAI
1 INTRODUCTION
ResearchhasshownthatAIrecommendations,evenwhenaccompaniedwithexplanations,arenotalwayshelpfulin
supportingdecision-making[4,6,15,36].Thedirectcausesofthisareunder-relianceandover-reliance[35].Withunder-
reliance,decision-makersrejectAIrecommendations,evenwhentheymaybecorrect.Alternatively,decision-makers
mayoverlyrelyonAIrecommendations,hencebeledtoerrorswhentheAIisincorrect.Ineithercase,theytendto
fixateonaparticularhypothesiswithoutsufficientlyconsideringothers[25].Approachessuchascognitiveforcing,
basedonideasfromhumanpsychology,havebeenproposedtoaddresslimitationsoftheAIrecommendationapproach
[6],withrecentworkindictingthatwithholdingAImodeltherecommendations,atleastforashorttime,whilestill
providingtheuserwithanexplanationofthatrecommendation,canbehelpful[15].Recently,Miller[25]proposeda
so-scalledhypothesis-drivendecision-makingparadigmcalledevaluativeAI.Themainaimofthisparadigmisto
focusthedecisionlooponthehumandecisionmaker,providingthemwiththerightevidencetosupporttheirown
intuitions,ratherthanfocusingthedecisionlooponmachinerecommendations.Thisparadigmoffersapromising
directioninbuildingbetterdecisionsupportinexplainableAI(XAI)researchbyfocusingonhumandecisionmakers
consideringmultiplepossiblehypotheses.
Inthispaper,wedescribeandevaluateanapproachforbuildingahypothesis-drivendecision-makingmodelthat
usestheWeightofEvidence(WoE)framework[2].Ourcontributionsare:
â€¢ TheEvidence-InformedHypothesis-DrivenDecisionMakingmodel,buildingontheWeightofEvidence(WoE)
frameworktothehypothesis-drivenapproach.
â€¢ Asetofhumanbehaviouralexperimentscomparingourhypothesis-drivenapproachwithtwocommondecision-
aidapproaches:(1)thestandardmodelrecommendationwithexplanation;and(2)adesignusingaformof
cognitiveforcingbyprovidingonlyAIexplanations[15].Theresultsshowthathypothesis-drivenapproach
1
4202
beF
2
]IA.sc[
1v29210.2042:viXraLe,etal.
significantlyreducesover-reliancecomparedtostandardrecommendation-drivenapproaches,atthecostof
aslightincreaseinunder-reliance.Furthermore,thehypothesis-drivenreducesunder-reliancesignificantly
comparedtotheAI-explanation-only.Moreover,ourqualitativeanalysisidentifiessomelimitationsandchal-
lengesinthethreedecision-makingapproaches,butalsoshowsthatparticipantsusedthehypothesis-driven
approachinamateriallydifferentwaythantherecommendation-drivenorAI-explanation-onlyconditions,
withparticipantsfocusingmoreontheevidencethanontheirownbackgroundknowledge.
2 BACKGROUNDANDRELATEDWORK
Inthissection,wegiveabriefoverviewofrelatedworkoncommonAI-assisteddecision-makingparadigms.Furthermore,
wehighlightkeyliteratureaboutapplyingexplainableAIinsupportingdecision-making.
2.1 AI-AssistedDecisionMakingParadigms
Intheliterature,therearetwoworkflowsthatareoftenusedinAI-assisteddecision-making:(1)AI-firstdecision-making;
and(2)human-firstdecision-making.AI-firstworkflowprovidestheAIrecommendationfirstandthenhumansdecide
iftheywanttoacceptornottherecommendation,whereashuman-firstdecision-makingrequireshumanstomakea
provisionaldecisionbeforetheyareprovidedwithanyAIrecommendations.
2.1.1 AI-firstWorkflow. IntheAI-firstdecision-makingworkflow,ithasbeendemonstratedthatparticipantsfeel
moreconfidentandarealsofasterindecision-making[13].TheseparticipantsalsoratedAIasmorepractical.In
termsoflimitations,theanchoringeffectisreportedtooccurmoreoftenintheAI-firstworkflow[6,13,27]inwhich
peopleoverlyrelyontheAIrecommendation(alsocalledover-reliance).Anchoringeffect[32]referstogivingstronger
preferencetotheearlierknowledgeratherthandoingafullrevisionandconsideringthelatestevidence.Bycontrast,
Fogliatoetal.[14]didnotfindanysignificantdifferenceintheparticipantsâ€™performance,whichismeasuredby
accuracybetweenthetwoworkflows(AI-firstandhuman-first).However,theyalsofoundthatparticipantsare65%
morelikelytorevisetheiranswersinthehuman-firstsettingthanthoseintheAI-firstsetting.
2.1.2 Human-firstWorkflow. Human-firstdecisionworkflowhasbeenshowntohelpreducetherelianceonerroneous
AIrecommendations[6,13].However,expertsmayinteractwithdecision-makingsystemsdifferentlyfromlaypeople
(crowdworkers).Forexample,Fogliatoetal.[13],Gaubeetal.[16]ranstudieswithradiologistswhoweretheexperts.
Theirtaskistoreviewpatientsâ€™X-rayimages.Thestudiesconcludethatinhuman-firstworkflowwithexpertparticipants,
theyarelesslikelytoleverageAIadviceeventhoughtheAIismoreaccurate.Infact,thisisreferredtoalgorithm
aversion[12]orunder-reliance.
Ahuman-firstparadigmcalledcognitiveforcing,basedonearlierideasinpsychologyforinterventionsthatelicit
humanthinkingatdecision-makingtime[22],hasbeenproposedasawaytoimproveusersâ€™engagementandalso
increasetheirlearningwheninteractingwiththeAI[6,15].Fourcognitiveforcingdesignshavebeenintroduced:(1)
Ondemand:ParticipantscanonlyseetheAIrecommendationwhentheyrequestit;(2)Update:Participantsfirstmade
adecisionwithoutseeingtheAIrecommendation.Then,theywereshowntheAIpredictionandcouldupdatetheir
decisionlater;(3)Wait:Participantshadtowaitfor30secondsbeforetheAIdecisionwasshown;and(4)OnlyAI
explanation:ProvidingjusttheAIexplanationandnoAIrecommendation,onthebasisthatthismayhelppeopleprocess
theAIexplanationmorecarefullyandtherefore,improvetheirknowledgeandmakebetterdecisions[15].Importantly,
cognitiveforcinghasbeenshowntoreduceover-reliancecomparedtothestandardAIsuggestionapproach,although
APreprint 2TowardsthenewXAI:AHypothesis-drivenApproach
thatstudyhadalimitationinthattheAIpredictionwasalwayscorrect.Therearealsosomerecognisedtrade-offsof
cognitiveforcingdesigns:moretime-consuming[15],andlesstrust[6].
2.1.3 EvaluativeAI(Hypothesis-driven)Paradigm. Miller[25]arguesthatAI-assisteddecisionsupportisonthecuspof
aparadigmshift.Thisshiftisawayfromtheideaofhuman-firstorAI-first,andintoaframeworkhecallsevaluative
AI.ThekeyinsightofevaluativeAIistonotnecessarilyprovidearecommendation,andinsteadtosupportthehuman
cognitivedecision-makingprocessbyprovidingevidencethatsupportsoragainsttheparticularhypothesisthata
humandecisionmakerisconsidering.Millerarguesthatthiswouldhelptopreventover-andunder-reliance,andwould
helpthedecisionmakertoretaintheirinternallocusoncontrol[29].
2.2 ExplainableAI(XAI)inSupportingDecisionMaking
Inthissection,wereviewsomeAI-firstexplainableAIapproachesthathavebeenusedtoprovideexplanationsfor
theAIrecommendationbasedonfeatureanalysis.Ourdecision-makingmodelwillapplytheWeightofEvidence
framework,whichhassimilaritieswithotherfeature-basedexplanations.Therefore,wewilldiscusssomepopular
evidence-basedexplanationsthathavebeenusedinsupportingdecision-making.
2.2.1 Humandecision-makingrelianceonAIsupport. Thereisnostraightforwardpositionregardingwhenhumans
arewellcalibratedtoacceptAI-generatedadvice[35].Overall,studyparticipantsappearmorelikelytoacceptanAIâ€™s
recommendationwhenprovidedwithexplanations,regardlessofthemodelâ€™scorrectness[4,18,33].Explanations
canincreasetheaccuracyofthehuman-AIteamwhentheAIiscorrect,butdecreaseitwhenitiswrong,resultingin
over-relianceontheAIâ€™srecommendations.Arguably,thisisbecausethecurrentexplanationstylesdonotprovide
detailsoftheunderlyingrationaleoftheAImodelbehaviour[33].Wethereforeshouldbecarefulwhenselectingthe
explanationtypeasitcanhaveasignificanteffectonwhetherusersdecidetorelyonthem[7,23].
2.2.2 Evidence-basedExplanations. Inthispaper,wewillgenerateevidence-basedexplanations,whicharesimilar
tofeatureimportanceexplanations.ThemaindifferenceisthatWeightofEvidenceusesloglikelihoodsandlogodds
ratiostogenerateexplanations,whereasLIME[28]andSHAP[24]findfeatureimportancebymodifyingthepredictive
posteriorprobabilityinvariousways.
Evidence-basedexplanationshavebeenappliedtosupportdecision-makinganddebugmodelsinseveralprior
research [19, 20, 26] other than from Alvarez Melis et al. [2]. A closely related work to Alvarez Melis et al. [2]
isfromPoulinetal.[26].Poulinetal.[26]proposeaframeworkcalledExplainD thatusesadditiveevidence.The
frameworkalsomeasurestheweightofevidenceusingaNaiveBayesclassifieralongwithhighlightingthenegativeand
positiveevidenceforadecision.However,theproblembeingconsideredisabinaryclassification.Furthermore,thereis
stillroomforimprovementbyconductingexperimentstoevaluatetheframework.Kuleszaetal.[19,20]introduce
EluciDebuginemailclassificationusingMultinomialNaiveBayesclassifier(MNB).TheEluciDebugprototypeprovides
aninterfacethatincludesimportantwordsandthefoldersizethatbothcontributetotheemailclassification.However,
theprototypedidnotspecificallygivepositiveandnegativeevidenceindecision-makingsituations.
3 EVIDENCE-INFORMEDHYPOTHESIS-DRIVENDECISIONMAKINGMODEL
Wedefinetheevidence-informedhypothesis-drivendecision-makingmodelbyimplementingtheevaluateAI (hypothesis-
driven)paradigm[25]usingtheWoEmodel.Specifically,givenaclassificationproblem,decisionmakersexplore
APreprint 3Le,etal.
evidenceforandagainsteachhypothesis(i.e.anoutputclass).Weallowdecision-makerstointeractwiththemodelby
repeatedlyselectingahypothesisforwhichtheycanthenseethepositive(ornegative)evidence.
3.1 EvidenceGeneration
Inaclassificationproblem,ahypothesisâ„ âˆˆ ğ‘Œ,whereğ‘Œ = {â„,â„ 1,â„ 2,...,â„ ğ‘›}includesallpossiblehypotheses,asan
outputclass.Then,â„Â¯=ğ‘Œ\{â„}referstoallhypothesesotherthanâ„.Forexample,ifadoctorassertsasetofhypotheses
ğ‘Œ ={â„ 1,â„ 2,â„ 3}whereâ„ 1=thepatienthasCovid,â„ 2=thepatienthasInfluenzaandâ„ 3=thepatienthaspneumonia,then
â„Â¯ 1=thepatientdoesnothaveCovidwhichincludesallpossiblehypothesesexcepthavingCovid,thatisâ„Â¯ 1={â„ 2,â„ 3}.
WegeneratetheweightofevidenceforpossiblehypothesesusingWeightofevidence(WoE),whichisaprobabilistic
approachforanalysingvariableimportance,introducedinthecontextofexplainabilitybyAlvarezMelisetal.[2]
buildingonGood[17].Itprovidesaquantitativeresponsetothequestionofwhyamodelpredictedoutputâ„fora
particularinputğ‘¥intermsofhowmucheachinputfeatureğ‘¥
ğ‘–
providesinfavourof,oragainst,â„,relativetoalternatives.
ThroughBayesrule,WoEcanbeunderstoodasanadjustmenttothepriorlogoddscausedbyobservingtheevidence.
Forhypothesisâ„andinputfeatureğ‘¥ ğ‘–,weightofevidence,woe,isdefinedasfollows:
ğ‘ƒ(ğ‘¥ ğ‘– |â„) ğ‘ƒ(â„ |ğ‘¥ ğ‘–) ğ‘ƒ(â„)
woe(â„ |ğ‘¥ ğ‘–)=log =log âˆ’log (1)
ğ‘ƒ(ğ‘¥ ğ‘– |â„Â¯) ğ‘ƒ(â„Â¯|ğ‘¥ ğ‘–) ğ‘ƒ(â„Â¯)
Basedontheweightofevidence,wesaytheevidencesupportsorrefutesahypothesis:
â€¢ Ifwoe(â„ |ğ‘¥ ğ‘–) >0,evidenceğ‘¥ ğ‘– supportshypothesisâ„
â€¢ Ifwoe(â„ |ğ‘¥ ğ‘–) <0,evidenceğ‘¥ ğ‘– refuteshypothesisâ„
â€¢ Ifwoe(â„ |ğ‘¥ ğ‘–)=0,evidenceğ‘¥ ğ‘– neithersupportsorrefuteshypothesisâ„
3.2 Howdecision-aidmodelscanuseWoEtomakeadecision
Usingtheweightofevidenceforeachfeatureğ‘¥ ğ‘– asinEquation1,adecision-aidmodelcanmakeapredictionbasedon
thetotalweightofevidenceofahypothesisâ„bysumminguptheweightofevidenceofthishypothesisbasedoneach
featureğ‘¥ ğ‘–.Thetotalweightofevidenceisdefinedasfollows.
ğ‘›
âˆ‘ï¸
woe(â„)= woe(â„ |ğ‘¥ ğ‘–) (2)
ğ‘–=1
whereğ‘›isthenumberoffeatures.
Thedecision-aidmodelwillselectthebesthypothesisbasedonthemaximumposterior,thatis,ğ‘¦=argmaxâ„âˆˆğ‘Œğ‘ƒ(â„ |
ğ‘‹).Ifwehavethesamepriorforallhypotheses,wecanalsousethetotalweightofevidenceasanotherwaytofindthe
besthypothesisusingEquation1.Therefore,adecision-aidmodelcanselectthehypothesiswiththemaximumtotal
weightofevidenceasitspredictionasfollows(onlyapplytouniformpriors).
ğ‘¦=argmaxwoe(â„) (3)
â„âˆˆğ‘Œ
3.3 HowWoEcanincorporateahumanapproachtomakingadecision
Toassistuserswithinterpretability,AlvarezMelisetal.[2]complementthedisplayofthemagnitudeoftheweight
oftheevidencewithanotionofsignificanceleveloftheevidence,usingascaleofsevencategories:decisive-against,
strong-against,substantial-against,not-significant,substantial-in-favor,strong-in-favor,decisive-in-favor.Thedetailscan
befoundintherule-of-thumbguidelineshere[3].
APreprint 4TowardsthenewXAI:AHypothesis-drivenApproach
Inadditiontotheweightofevidenceofafeature,wesuggestitisusefultodistinguishtheimportanceofafeatureâ€“
withimportancebeingdomainspecificanddeterminedbythedomainexpertusingthemodel.Specifically,ifafeature
hassignificantweightofevidenceaccordingtotheWoEmodel,butthatfeatureisnotseenasimportantbythehuman
decisionmaker,thenitisreasonabletoanticipatetheimpactofthatevidenceonthedecisionwouldbereducedbythe
decisionmaker.Forexample,ifaclinicianlooksataskincancerimageandalsoisawareofsomeirrelevantbuthigh
weightofevidencefeaturesuchasdensehair,theyshouldignorethatevidenceinmakingaprediction.
Formally,byconsideringtheimportanceoftheevidence,were-definethetotalweightofevidencefromahuman
decisionmakingperspectiveasfollows:
ğ‘›
âˆ‘ï¸
woe(â„)= ğ›¾ ğ‘– Ã—woe(â„ |ğ‘¥ ğ‘–) (4)
ğ‘–=1
whereğ›¾ ğ‘– isaparameteroffeatureğ‘¥ ğ‘– thatadjuststheweightofevidencebasedonimportance,i.e.,ğ›¾ ğ‘– >ğ›¾ ğ‘— represents
thatfeatureğ‘¥ ğ‘– ismoreimportantthanfeatureğ‘¥ ğ‘—.
Then,fortheskincancerexamplejustmentioned,ineffectinEquation4,theclinicianhassetğ›¾ =0forthatfeature.
4 EXPERIMENTDESIGN
Inthissection,wedescribethetaskimplementedinthehumanbehaviourexperimentandtheexperimentdesign.In
selectingadecision-makingtask,weidentifiedrequirementssimilartothoseusedinotherstudiesofhowexplanations
canassisthumandecisionmakersinteractingwithAIdecisionsupport,e.g.Vasconcelosetal.[34]:thetaskshouldnot
betooeasyforhumanstocompletewithoutadecisionaid,butalso,aswewereusinglaysubjectsfromProlificforthis
particularstudy,thetaskcannotrequirespecialistknowledge.
WechoseaversionofthehousingpricepredictiontaskstudiedpreviouslyinanXAIcontext[1,10].Inthistask,par-
ticipantsareprovidedwithinformationabouthousefeaturesandwithotherinformationwhichvariesbyexperimental
condition,andareaskedtochoosewhetherthegivenhousewouldhaveasalepriceoflow,mediumorhigh.Asnoted
byothers[10],realestatevaluationisadomainwhereMLmodelshavebeendevelopedtohelppeoplemakebetter
decisions,predictinghousepricesisataskthatlaypeoplemayneedtodoinreallife,soitisnotunrealistictoexpect
theyhavesufficientday-to-dayknowledgetomakepredictionsanddecidewhetherornottorelyonanAImodel.
Experimentingwiththistask,wecomparedthehypothesis-drivenapproachwithtwostate-of-the-artdecision-making
approachesusingquantitativemeasuresforefficiency,performanceandrelianceandaqualitativeanalysisofinformation
use.IntheterminologyofarecentreviewofXAIevaluation[21],thefirsttwopointsofcomparisonareaformof
evaluationwithrespecttothedecisiontask,andthelattertwofocusonusersâ€™perceptionanduseoftheAIsystemitself.
4.1 DatasetandModelImplementation
Tobuildourmodel,weusedtheAmesHousingDataset[11]andtheopensourcecodeonGitHub[31]fordatapre-
processing.Thedataafterpre-processinghasatotalof2616instancesand28features.Weprocessedthedatasetfurther
byconvertingthehousepriceintothreeoutputclasses(lowprice,mediumpriceandhighprice).Wealsobalancedthe
datasettoensurethatthethreeclasseshadthesamenumberofinstancesbyusingNear-MissUndersampling.Finally,
wehadatotalof1920instanceswith640instancesforeachclass.
Weselectedsixfeaturesforthehumanexperimentinthehouse-pricedecisionmakingtaskbyapplyingGradient
BoostingClassificationmodeloverthedata.Consideringdomainspecificdecisionmakingabouthouseprices,we
proposetheretobethreeimportantfeatures(qualityofconstruction,houseageandlocation)andthreeunimportant
APreprint 5Le,etal.
features(fireplaces,kitchenqualityandcentralairconditioning).Wedividedthedatasetinto80%forthetrainingsetand
20%forthetestset.FollowingAlvarezMelisetal.[2],weuseaGaussianNaÃ¯veBayes(GNB)classifiertoobtainğ‘ƒ(ğ‘¥
ğ‘–
|â„).
Thisassumesthatfeaturesareindependent,butthemodelandimplementationworkforanyprobabilisticclassifier.
Wechosethismodelbecauseitisasimplediscriminativeclassifierthatalignswithpreviousworkonevidence-based
explanations[19,26].
4.2 ExperimentalConditions
Allparticipants1weregiventhesixhousefeaturevaluesplusotherinformation,whichvariedbyconditionassetout
below.Participantsthenchosewhetherthegivenhousewouldhaveapriceoflow,mediumorhigh.
Usingabetween-subjectdesign,participantswererandomlyassignedtooneofthreeconditions:
â€¢ (C1)Recommendation-driven:ParticipantsseetheAIprediction(i.e.,eitherlowormediumorhigh)andalsothe
weightofevidenceforthatprediction;
â€¢ (C2)AI-explanation-only:ParticipantsseetheweightofevidenceassociatedwiththeAIprediction,buttheAI
predictionitselfishidden;
â€¢ (C3)Hypothesis-driven:Participantsseetheweightofevidenceforallhypotheses(low,mediumandhigh),but
theAIpredictionitselfishidden.
AlthoughparticipantsintheExplanation-onlyandHypothesis-drivenconditionsdidnotseearecommendation,it
wasexpectedthatthedisplayedinformationfromtheWoEframeworkwouldprovideinsightthatparticipantscould
usetosupporttheirdecisionmaking.WenoteasimilarExplanation-onlyapproachhasbeenexploredpreviously[15].
4.3 ResearchQuestionsandHypotheses
Ouroverarchingresearchquestionswereasfollows:
â€¢ RQ1:(Efficiency)WhatformofAIassistancehelpsparticipantsmakefasterdecisions?
â€¢ RQ2:(Performance)WhatformofAIassistancehelpsparticipantsmakebetterdecisions?
â€¢ RQ3:(Reliance)WhatformofAIassistancehelpsreduceover-relianceandunder-reliance?
â€¢ RQ4:(Informationuse)Howdopeoplemakedecisionsdifferentlyinrecommendation-driven,AI-explanation-only
andhypothesis-drivenparadigm?
ForRQ1,weevaluatedtheparticipantsâ€™speedinmakingadecision.Weusethemostcommonmetric-completion
timetomeasurethetimetakenonthetask.Thecorrespondinghypothesesforthisquestionare:
â€¢ H1a/b:(C3)Hypothesis-drivenparadigmwillcostlesstimetofinishthetaskthan(C1)Recommendation-driven
and(C2)AI-explanation-only.
ForRQ2,weevaluatedthequalityofthedecision.Inthetask,weaskedtheparticipantstoassignthelikelihoodfor
eachpricerange(low/medium/high)where100isthemostlikelyand0istheleastlikely.Thesumofthreelikelihoods
mustbeequalto100.Weexpecttheparticipantstobeconfidentwhentheymakeacorrectprediction,andnotbe
confidentwhentheymakeawrongdecision.WeapplyBrierscoreasexplainedbelowtomeasurethetaskperformance.
Thehypothesesforthisquestionare:
â€¢ H2a/b:(C3)Hypothesis-drivenparadigmwillhelpparticipantsmakebetterdecisionsthan(C1)Recommendation-
drivenand(C2)AI-explanation-only.
1Wereceivedethicsapprovalfromourinstitutionbeforeconductingthehumanexperiment.
APreprint 6TowardsthenewXAI:AHypothesis-drivenApproach
ForRQ3,weinvestigatedtheparticipantsâ€™capabilityofappropriatelycalibratingtheirdecision.Participantsshould
followthemodelâ€™spredictionwhenitiscorrectandshouldnotusethemodelâ€™spredictionwhenitiswrong.Weapplied
twomeasuresover-relianceandunder-relianceasshownbelowwiththefollowinghypotheses:
â€¢ H3a:(C3)Hypothesis-drivencanreduceover-reliancecomparedto(C1)Recommendation-driven.
â€¢ H3b:(C3)Hypothesis-drivencanreduceunder-reliancecomparedto(C2)AI-explanation-only.
ForRQ4,welookedintothetextwrittenbyparticipantswhentheyexplainedwhytheyselectedanoptionaftereach
questiontoknowhowtheyusedtheprovidedinformationineachdecision-makingparadigmtomaketheirdecisions.
Therefore,wecanidentifythelimitationsofeachparadigmandthegeneratedevidencethatleadtheparticipantsto
makeawrongdecision.
4.4 Measures
Wetookthefollowingmeasures:
(1) TaskEfficiency(Completiontime):Thetimeparticipantstaketocompletethetask.
(2) TaskPerformance(Brierscore):Thismetricquantifiestheeffectivenessoftaskperformance.ThebestBrier
score(i.e.equalsto0)iswhenyouanswerthequestioncorrectlywith100%likelihood,andalsowhenyouhave
awronganswerbutwith0%likelihoood.Therefore,aparticipanthasbettertaskperformancewhentheyhave
alowerBrierscore.Theformulais:
BSğ‘,ğ‘– =(ğ¶ ğ‘,ğ‘– âˆ’ğ´ ğ‘,ğ‘–)2 (5)
where:ğ¶ ğ‘,ğ‘– isthelikelihoodlevelofparticipantğ‘inquestionğ‘–,rangingfrom0to1;ğ´ ğ‘,ğ‘– istheanswerscoreof
participantğ‘inquestionğ‘–,either0(wronganswer)or1(rightanswer).
Wethenmeasuretheover-relianceandunder-reliance[36].SincestudyparticipantscanonlyseetheAIrecommen-
dationinC1(Recommendation-driven),wemeasurewhetherparticipantshavethesamepredictionordifferfromthe
modelâ€™spredictionintheothertwoconditions.
(3) Over-reliance:thefractionoftaskswhereparticipantshavethesamedecisionasamodelâ€™spredictionwhen
itwaswrong:Î£ ğ‘–(ğ´ ğ‘,ğ‘– =ğ‘€ ğ‘– =0)/Î£ ğ‘–(1âˆ’ğ‘€ ğ‘–),whereğ´ ğ‘,ğ‘– isasaboveandğ‘€ ğ‘– =1ifthemodeliscorrectand0
otherwise.
(4) Under-reliance:thefractionoftaskswhereparticipantshaveadifferentdecisionfromamodelâ€™sprediction
whenitwascorrect:Î£ ğ‘–(ğ´ ğ‘,ğ‘– â‰ ğ‘€ ğ‘– =1)/Î£ ğ‘–ğ‘€ ğ‘–.
4.5 Conduct
Weconductedtwoseparatehumanexperimentsinwhichparticipantsweregiventhesametaskintheformofaquestion
set,withtheonlydifferencebeingthewaytheyansweredthequestion.
â€¢ Inexperiment1,participantswereaskedtomakeadecisionabouttherelativelikelihoodforeachpricerange
(low/medium/high)ofgivenhouseinstances.WeanswerRQ1,RQ2andRQ3byanalysingtheresultsoffour
measuresmentionedabove(completiontime,Brierscore,over-relianceandunder-reliance).
â€¢ Inexperiment2,werecruitedanewandsmallercohortandaskedthemtodothesametasksasinexperiment
1,butinaddition,weaskedparticipantstoexplaintheirdecisionsusingfreetext.Weconductthisexperiment
separatelyfromthequantitativedatainexperiment1becauseaskingparticipantstoexplaintheirreasoning
cognitivelyforcesthemtoengagewiththeinstance,interferingwiththeirnaturaldecision-makingprocess,
APreprint 7Le,etal.
andthereforepotentiallyaffectingthequantitativeresults.Wethenperformedadeductivethematicanalysisof
theirexplanationstoanswerRQ4.
TheexperimentwasdesignedasaQualtrics2surveyandparticipantsaccessedthesurveythroughProlific3.The
experimentrequiredamaximumof25minutestofinish.Therewere12houseinstancesgiven,equivalentto12questions.
These12questionswereevenlydistributedintofourquestioncategories:(1)wherethemodelgivescorrectpredictions
withhighuncertainty,(2)wherethemodelgivescorrectpredictionswithlowuncertainty,(3)wherethemodelgives
wrongpredictionswithhighuncertaintyand(4)wherethemodelgiveswrongpredictionswithlowuncertainty.Thus,
therearethreequestionsineachcategory.
Theuncertaintyismeasuredbythecrossentropyasfollows.
âˆ‘ï¸
ğ‘¢(â„)=âˆ’ ğ‘(â„)logğ‘(â„) (6)
â„âˆˆğ»
whereğ‘¢(â„)istheuncertaintylevelofhypothesisâ„giventheprobabilisticoutputisğ‘(â„).Weselectinstanceswith
lowuncertaintybychoosinginstancesentropylessthan0.3.Forhighuncertainty,wechooseinstanceswithentropy
greaterthan0.7.Participantsdidnotknowhowmanytestinstanceswerecorrect/incorrect.Eachparticipantwaspaida
minimumof4GBPfortheirtime,plusabonusof2GBPiftheycouldansweratleast9outof12questionscorrectly.
Participantswerealsogivenaplainlanguagestatement,andconsentformanddidatrainingphasewith3example
questionsbeforeansweringthe12testquestions.
â€¢ Inexperiment1,participantswereaskedtomakeadecisionabouttherelativelikelihoodforeachpricerange
(low/medium/high)ofgivenhouseinstances.WeanswerRQ1,RQ2andRQ3byanalysingtheresultsoffour
measuresmentionedabove(completiontime,Brierscore,over-relianceandunder-reliance).
â€¢ Inexperiment2,participantswereaskedtoexplaintheirdecisionsusingfreetextandweundertookadeductive
analysisoftheirexplanationstoanswerRQ4.
ForRQ4thetextisaresponsetoâ€œCanyoupleaseexplainwhyyouselectedthisoption?".Weanalysedatotalof
12(questions)Ã—95(participants)=1140responses.Thefinalanalysisincludes1,031responsesafterremoving109
responsesduetopoorquality.Eachresponseisassignedtoatleastonecategory(orcode):UsingfeaturevaluesorUsing
evidence.Wethenperformadeductivethematicanalysisbyreadingeachresponseandassigntherelevantcodes.We
explaineachcodeasfollows.
â€¢ UsingFeatureValues:Participantsrelyonthefeaturevaluesandtheirbackgroundknowledgetomakethefinal
decisionwithoutusingthemodelevidence.Forexample,inFigure9,featurevaluesarethesixhousefeatures
onthetop.
â€¢ UsingEvidence:Participantsrelyontheevidenceprovidedbythemodelandpossiblytheirbackgroundknowledge
tomakethefinaldecision.Forexample,inFigure9,theevidenceistheWeightofEvidencechartoftheprediction.
Wechosethesetwocodesbasedontheideaofmachineexplanationandhumanintuition[8,9].Specifically,using
evidencereferstousingthemachineexplanationandtherefore,makinguseofthemodelevidencetosupportdecision-
making.Ontheotherhand,usingfeaturevaluesisrelevanttousingpeopleâ€™sintuitionsofthetaskbasedontheinput
featurevalues.Therefore,usingthequalitativeanalysis,weexplorehowpeopleusethemodelevidenceandtheir
intuitionsinthethreedecision-makingparadigms.
2https://www.qualtrics.com
3https://www.prolific.com
APreprint 8TowardsthenewXAI:AHypothesis-drivenApproach
Fig.1. Completiontimeinseconds.Lowerisbetter.Meansrepre-
sentedasdots. Fig.2. Brierscore.Lowerisbetter.Meansrepresentedasdots.
4.6 Participants
4.6.1 Participantsinexperiment1. UsingthepoweranalysisforF-testforonefactorANOVAandassumingthepower
of0.8andsignificantalphaof0.05,wefoundthatasamplesizeof300participantsinthreegroupsguaranteesasmall
effectsizeof0.2.Intotal,werecruitedğ‘ =302participantsonProlific,distributedintothreeconditions:102participants
inC1,99participantsinC2and101participantsinC3.ParticipantsareselectedfromtheUnitedStates,UnitedKingdom,
andAustraliaandmustbefluentinEnglish.Gender-wise,192werewomen,103weremen,4self-specifiedtheirgender
and3declinedtostatetheirgender.Age-wise,94participantswerebetweenAges18and29,91werebetweenAges30
and39,44werebetweenAges40and49,and73wereoverAge50.
4.6.2 Participantsinexperiment2. Werecruitedğ‘ =95participantsonProlific,distributedintothreeconditions:30
participantsinC1,34participantsinC2and31participantsinC3.ParticipantsareselectedfromtheUnitedStates,
UnitedKingdom,andAustraliaandmustbefluentinEnglish.Gender-wise,52werewomen,41weremen,and2
declinedtostatethegender.Age-wise,38participantswerebetweenAges18and29,37werebetweenAges30and39,
10werebetweenAges40and49,and10wereoverAge50.
5 EXPERIMENTRESULTS
Inthissection,weshowtheresultsoftwoexperiments.Inthefirstexperiment,weexplorewhetherhypothesis-drivencan
improvetaskefficiency,taskperformanceandreducereliancecomparedtorecommendation-drivenandAIexplanation
only.Inthesecondexperiment,weunderstandhowparticipantsusedourhypothesis-drivenapproachdifferently
comparedtotheothertwobaselines.
5.1 Experiment1:QuantitativeResults
WeperformedaShapiro-Wilkstesttocheckthedatanormalityandwefoundthatourdatawasnotnormallydistributed
(ğ‘ <0.05).Therefore,weapplynon-parametricKruskal-Wallistest.Wethenperformpost-hocMann-WitneyUtestto
dopairwisecomparisons.TheresultsarevisualisedinFigure1andFigure2.Thesignificantdifferencesbetweentwo
conditionsarehighlightedinitalicredinthefigureswhereğ‘ <0.05.
APreprint 9Le,etal.
Fig.3. Over-reliance.Lowerisbetter.Meansrepresentedasdots.Fig.4. Under-reliance.Lowerisbetter.Meansrepresentedasdots.
5.1.1 Taskefficiency. Figure1showsthecompletiontimeinthreeconditions.Thereisnostatisticallysignificant
differenceamongthesethreeconditions(ğ‘ â‰ˆ0.9).WerejectH1a/b.Thisshowsthathypothesis-drivenisnotmore
mentallydemandingthanrecommendation-drivenandAI-explanation-only.
5.1.2 Taskperformance. Weevaluateparticipantsâ€™decision-makingperformancebyusingtheBrierscore.ABrier
scoreofzeroindicatesthatparticipantsscoredperfectlywellinthetask.AsseeninFigure2,participantsinthe
hypothesis-drivencondition(ğ‘€ =0.267,ğ‘†ğ· =0.063)performsignificantlybetterthantheothertwoapproaches
(C1:(ğ‘€ = 0.290,ğ‘†ğ· = 0.071),C2:(ğ‘€ = 0.295,ğ‘†ğ· = 0.073)).WeacceptH2a/b.Therefore,hypothesis-drivenhelps
participantsbeconfidentwhentheymakeacorrectdecision,andbelessconfidentwhentheymakeawrongdecision.
5.1.3 Over-reliance. InFigure3,hypothesis-driven(ğ‘€ =53.30,ğ‘†ğ· =22.73)reducedover-reliancesignificantly
comparedtorecommendation-driven(ğ‘€ =73.86,ğ‘†ğ· =20.91)(ğ‘ =1.5Ã—10âˆ’8,ğ‘Ÿ =0.449).WeacceptH3a.Moreover,
AI-explanation-only (ğ‘€ = 54.21,ğ‘†ğ· = 22.51)alsoreducesover-reliancecomparedtotherecommendation-driven
approach(ğ‘ =1.6Ã—10âˆ’8,ğ‘Ÿ =0.450).
5.1.4 Under-reliance. InFigure4,hypothesis-driven(ğ‘€ =24.42,ğ‘†ğ· =18.19)significantlyreducedunder-reliance
comparedtoAI-explanation-only(ğ‘€ =41.25,ğ‘†ğ· =27.18)(ğ‘ =1.09Ã—10âˆ’6,ğ‘Ÿ =0.387),WeacceptH3b.Thisisnot
surprisingbecauseweexpectthatparticipantsintheAI-explanation-onlyconditionarethemostlikelytounder-rely
ontheAIrecommendationastheywerenotgiventheAIrecommendationexplicitly(onlygiventheAIexplanation).
Recommendation-driven(ğ‘€ =17.81,ğ‘†ğ· =20.35)hastheleastunder-reliancevaluebecauseparticipantsweregivenAI
recommendations.
5.2 Experiment2:QualitativeResults
InFigure5aand5b,weillustratethenumberoftimesthatparticipantsusedfeaturevaluesandevidencetomaketheir
decisionsbasedonthetextanalysis.
Fortherecommendation-drivenparadigm,participantsusethefeaturevaluestoconfirmwhetherthe
decisionaidâ€™spredictionandexplanationarereliableornot.Ifparticipantsthinkthefeaturevaluesdonotmatch
theevidenceexplanation,theywillgowiththefeaturevaluestomakethefinaldecision.Someexamplesthatthestudy
participantsintherecommendation-drivenconditiongoagainstthedecisionaidâ€™sprediction:
APreprint 10TowardsthenewXAI:AHypothesis-drivenApproach
(a)Numberoftimesthatparticipantsusedevidencetomakeadecision.
(b)Numberoftimesthatparticipantsusedfeaturevaluestomakeadecision.
Fig.5. Qualitativefindings
â€œHere,Ibelievethedecisionaidismistaken.Myratingwouldbemediumbecausethehouseisveryold
whichisoverlookedbythemodel.Otherfeaturesarealldecentorabovedecentbutthehouseageisan
importantfeature.â€â€“Q11
â€œThelocationofthepropertyislowsoIthoughtthatwouldbringdownthepriceâ€â€“Q7
Ignoringevidenceis,ofcourse,agoodstrategyifthedecisionmakerbelievesthattheevidenceiswrong.However,
recommendation-driven does not help participants to be aware of the high uncertainty among multiple
predictions.Thislimitationismitigatedbythehypothesis-drivenparadigm.
FortheAIexplanationonlyparadigm,participantsoftenrelyonthefeaturevaluesandnotontheevidence
explanationtomakeadecision.Thisisnotsurprisingbecauseparticipantscanfinditdifficulttointerprettheevidence
withoutseeingthelabelthattheevidenceisreferredto.Weattributethistothecognitiveefforttolinkevidenceto
hypotheses,leadingtoparticipantsignoringevidenceandrelyingoninputfeaturevaluestomaketheirdecisions.This
APreprint 11Le,etal.
Fig.6. Anexampleofuncertaintyawarenessinhypothesis-driven(Q6).
isanoteworthylimitationofAI-explanation-onlyasitmakespeopleoverlooktheexplanationifthelinktotheevidence
isunclear.InthestudybyGajosandMamykina[15],thelinkfromfeatureattributionstothetasksolutionismore
straightforwardthaninourstudy,whichmayexplainthedivergenceofresults.
Participantsmoreoftenusetheevidenceexplanationtomakeadecisioninthehypothesis-driventhanin
recommendation-drivenorAIexplanationonly.Thisisimportantbecausepeoplecantakeadvantageofthemodel
evidence.Inthetwobaselineconditions,participantstendedtoignoreevidenceseeminglyduetotheinabilityto
interpretit,whichmeanstheywillfailtotakeadvantageoftheunderlyingmodel.InFigure5a,thereareonlytwo
exceptionsatQ6andQ11wheretheevidenceisnotthemostusedinthehypothesis-drivencondition.
Wefoundthatinhypothesis-driven,participantsreportedthatitwasdifficulttomakedecisionsfortwomainreasons:
â€¢ Uncertaintyawareness:Thisiswheretherearemultiplehypotheseswithsimilarstrengthevidence.Participants
areawareoftheuncertaintyinthemodelsolelybasedonthepositiveandnegativeevidenceprovidedforall
hypotheses.Inthiscase,participantsusetheinputfeaturevaluesorchoosethehypothesisthattheythinkis
slightlybetterthantheotherswhenmakingthefinaldecision.Figure6showsanexamplewheretwohypotheses
lowandmediumbothhaveapositiveandnegativeweightofevidence,especiallyinthetopthreeimportant
features.Forinstance,someparticipantsexplicitlyexplaintheiruncertaintyinthetextasfollows.
â€œI was choosing between high and medium. Quality of construction, age and location are the most
importantfeatures.Whenitwasathigh,thesewereallpositive.Kitchenqualityandfireplaceswere
negative,butthesearenotasimportant.â€â€“Q0
â€œTheamountofnegativeorpositiveevidenceforlowormediumisthesame,includingthethreemore
importantfactors.Bothmediumorlowcouldbeviablebutmediumhaslessvarianceandisoverallmore
balanced.â€â€“Q6
APreprint 12TowardsthenewXAI:AHypothesis-drivenApproach
Fig.7. Anexampleofdeceptiveevidenceinhypothesis-driven(Q9).
â€œThehouseisclearlynotinahighbracket,butitissomewhatdifficulttodecidebetweenlowandmedium.
Therearestrongerindicatorsinlow,goingbothways,whilemediumhaslargelyinsignificantindicators.
Lowhasasignificantnegativeweightingforhouseageandthispushedmetowardsmedium.â€â€“Q6
â€¢ Deceptiveevidence:Whentheevidencewasstrongestforanincorrectoption.Inthiscase,manyparticipants
justfollowtheevidenceandmakethewrongdecision.Figure7illustratesanexampleofQ9wherewehave
allpositiveevidenceinhypothesismedium,butstrongnegativeevidenceinhypothesishigh.Therefore,all
participantschoosehypothesismedium,buthypothesishighisthegroundtruth.Futureworkwillneedto
addressthechallengeofbuildingtrustworthyevidence.
In summary, the qualitative analysis showed that participants took advantage of the decision aid more in the
hypothesis-drivenconditionthaninrecommendation-drivenandexplanation-onlyconditions.Further,wealsofound
thatparticipantsrecognisedmodeluncertaintyinthehypothesis-drivencondition.However,therestillremainsalimit
ofhavingdeceptiveevidence.
6 DISCUSSIONSANDCONCLUSIONS
Inthissection,wewilldiscussourfindingsaboutthehypothesis-drivenapproach.
6.1 Strengthsandweaknessesofourhypothesis-drivenapproach
First,participantsusingthehypothesis-drivenapproachrequiredasimilartimetocompletethetaskcomparedtothe
recommendation-drivenapproach.Participantsinthehypothesis-drivenconditionalsomadehigherqualitydecisions
APreprint 13Le,etal.
thanrecommendation-drivenandAIexplanationonlybasedontheBrierscore.Theresultsindicatedthatthehypothesis-
drivengavestudyparticipantsamorecompletepictureoftheunderlyingdecisionaidthantheothertwoapproaches,
helpingthemtomakeuseoftheAImodelswhentheyareright,andbelessconfidentwhenthemodelsarewrong.
Moreover,hypothesis-drivenreducedover-reliancesignificantlycomparedtothestandardAIrecommendation.
Similarly,hypothesis-drivenalsoreducedunder-reliancecomparedtoAIexplanationonly.Importantly,thepositive
resultforunder-relianceusingrecommendation-drivenisnotcancelledoutbythepoorover-relianceresult,compared
tohypothesis-driven.Theprimaryaimindicatingpotentialfortheuseofuncertainty/confidence[5]andconformal
prediction[30]todirectdecisionmakersâ€™attentiontowardsasetofhypothesesthatitisconfidentabout.
Usingthequalitativeanalysis,hypothesis-drivenhelpedparticipantstakeadvantageofthedecisionsupporttoolâ€™s
evidence,andalsorecognisetheuncertaintyunderlyingthemodel.Usingthestrengthofevidence,participantsare
awareoftheuncertaintybetweenmultiplehypotheses.Therefore,theymadeanattempttogaugethemodeluncertainty
bycalibratingtheweightofevidencedependingonwhetherthefeatureisimportantornot.Also,theycouldmakeuse
oftheinputfeaturevaluesandchoosethehypothesisthattheyperceivemostlikelymatcheswiththosevalues.
Ontheotherhand,recommendation-drivenandAIexplanationonlydonotsupportthis.Wefoundthatinrecommendation-
driven,peoplecouldusefeaturevaluestoconfirmthevalidityofthedecisionaidâ€™sprediction.However,theyarenot
awareoftheuncertaintyamongdifferenthypotheses.InAIexplanationonly,peopleoftenignoreusingtheevidence
andsolelyfocusonusingthefeaturevaluestomakeadecisionbecauseinterpretingtheevidencewiththisapproach
canbealotmorementallydemanding.
6.2 Studylimitations
Therearealsosomelimitationswiththestudy.First,werantheexperimentononedataset(AmesHousing),whichlimits
generalisability.Inaddition,asthereisnogroundtruthforthepriceofahouse,theexperimentalparticipantsâ€™tasks
aresomewhatsubjective.Further,thistaskhasonlythreeoutputclasses,soonlythreehypotheses,andweanticipate
theresultswouldbemoreinterestingwhenweconsidermorehypotheses.Finally,thehumanexperimentiscurrently
conductedwithlaypeoplewhileexpertslikelyinteractwiththedecision-aidingtooldifferentlyfromlaypeople[13].
6.3 Conclusions
Inthispaper,weshowthatthehypothesis-drivenapproachusingWeightofEvidence(WoE)cansignificantlyreducere-
liance,improvedecision-makingqualitycomparedtotwootherprevalentdecision-makingapproaches(recommendation-
drivenandAIexplanationonly).Furthermore,hypothesis-drivenhelpsparticipantstobeawareoftheuncertainty
amongmultipleoptions.Nevertheless,therestillremainsachallengeofstudyparticipantsrelyingonthewrong(or
misleading)evidence.Therefore,futureworkcanaddressthischallengebyexploringdifferentapproachesforpresenting
trustworthyevidence.Moregenerally,potentialfutureworkistoconsidertheuncertaintyinthegeneratedevidence.
ACKNOWLEDGMENTS
ThisresearchwassupportedbytheUniversityofMelbourneResearchScholarship(MRS)andpartlyfundedbyAustralian
ResearchCouncilDiscoveryGrantDP190103414.
REFERENCES
[1] AshrafAbdul,ChristianvonderWeth,MohanKankanhalli,andBrianYLim.2020.COGAM:measuringandmoderatingcognitiveloadinmachine
learningmodelexplanations.InProceedingsofthe2020CHIConferenceonHumanFactorsinComputingSystems.1â€“14.
APreprint 14TowardsthenewXAI:AHypothesis-drivenApproach
[2] DavidAlvarezMelis,HarmanpreetKaur,HalDaumÃ©III,HannaWallach,andJenniferWortmanVaughan.2021.FromHumanExplanationtoModel
Interpretability:AFrameworkBasedonWeightofEvidence.ProceedingsoftheAAAIConferenceonHumanComputationandCrowdsourcing9,1
(2021),35â€“47.
[3] DavidAlvarezMelis,HarmanpreetKaur,HalDaumÃ©III,HannaWallach,andJenniferWortmanVaughan.2021.UserStudyonInterpretability-
Tutorial.https://github.com/dmelis/interpretwoe/blob/master/notebooks/WoE_UserStudy_Tutorial.ipynb. Accessed:2023-05-30.
[4] GaganBansal,TongshuangWu,JoyceZhou,RaymondFok,BesmiraNushi,EceKamar,MarcoTulioRibeiro,andDanielWeld.2021.Doesthe
WholeExceedItsParts?TheEffectofAIExplanationsonComplementaryTeamPerformance.InProceedingsoftheCHIConferenceonHuman
FactorsinComputingSystems.
[5] UmangBhatt,JavierAntorÃ¡n,YunfengZhang,Q.VeraLiao,PrasannaSattigeri,RiccardoFogliato,GabrielleMelanÃ§on,RanganathKrishnan,Jason
Stanley,OmeshTickoo,LamaNachman,RumiChunara,MadhulikaSrikumar,AdrianWeller,andAliceXiang.2021.UncertaintyasaFormof
Transparency:Measuring,Communicating,andUsingUncertainty.InProceedingsoftheAAAI/ACMConferenceonAI,Ethics,andSociety.401â€“413.
[6] ZanaBuÃ§inca,MajaBarbaraMalaya,andKrzysztofZ.Gajos.2021.ToTrustortoThink:CognitiveForcingFunctionsCanReduceOverrelianceon
AIinAI-AssistedDecision-Making.Proc.ACMHum.-Comput.Interact.5,CSCW1(2021).
[7] RichCaruana,YinLou,JohannesGehrke,PaulKoch,MarcSturm,andNoemieElhadad.2015. IntelligibleModelsforHealthCare:Predicting
PneumoniaRiskandHospital30-DayReadmission.InProceedingsofthe21thACMSIGKDDInternationalConferenceonKnowledgeDiscoveryand
DataMining.1721â€“1730.
[8] ChachaChen,ShiFeng,AmitSharma,andChenhaoTan.2023.MachineExplanationsandHumanUnderstanding.InProceedingsofthe2023ACM
ConferenceonFairness,Accountability,andTransparency(Chicago,IL,USA)(FAccTâ€™23).AssociationforComputingMachinery,NewYork,NY,USA,
1.
[9] ValerieChen,Q.VeraLiao,JenniferWortmanVaughan,andGaganBansal.2023. UnderstandingtheRoleofHumanIntuitiononReliancein
Human-AIDecision-MakingwithExplanations.Proc.ACMHum.-Comput.Interact.7,CSCW2(2023).
[10] Chun-WeiChiangandMingYin.2022.ExploringtheEffectsofMachineLearningLiteracyInterventionsonLaypeopleâ€™sRelianceonMachine
LearningModels.In27thInternationalConferenceonIntelligentUserInterfaces(Helsinki,Finland)(IUIâ€™22).AssociationforComputingMachinery,
NewYork,NY,USA,148â€“161.
[11] DeanDeCock.2011.Ames,Iowa:AlternativetotheBostonhousingdataasanendofsemesterregressionproject.JournalofStatisticsEducation19,
3(2011).
[12] BerkeleyJDietvorst,JosephPSimmons,andCadeMassey.2015.Algorithmaversion:peopleerroneouslyavoidalgorithmsafterseeingthemerr.
JournalofExperimentalPsychology:General144,1(2015).
[13] RiccardoFogliato,ShreyaChappidi,MatthewLungren,PaulFisher,DianeWilson,MichaelFitzke,MarkParkinson,EricHorvitz,KoriInkpen,and
BesmiraNushi.2022.WhoGoesFirst?InfluencesofHuman-AIWorkflowonDecisionMakinginClinicalImaging.InProceedingsofthe2022ACM
ConferenceonFairness,Accountability,andTransparency(Seoul,RepublicofKorea)(FAccTâ€™22).AssociationforComputingMachinery,NewYork,
NY,USA,1362â€“1374.
[14] RiccardoFogliato,AlexandraChouldechova,andZacharyLipton.2021.TheImpactofAlgorithmicRiskAssessmentsonHumanPredictionsandIts
AnalysisviaCrowdsourcingStudies.Proc.ACMHum.-Comput.Interact.5,CSCW2(2021).
[15] KrzysztofZ.GajosandLenaMamykina.2022.DoPeopleEngageCognitivelywithAI?ImpactofAIAssistanceonIncidentalLearning.In27th
InternationalConferenceonIntelligentUserInterfaces.794â€“806.
[16] SusanneGaube,HariniSuresh,MartinaRaue,AlexanderMerritt,SethJ.Berkowitz,EvaLermer,JosephF.Coughlin,JohnV.Guttag,ErrolColak,
andMarzyehGhassemi.2021.DoasAIsay:susceptibilityindeploymentofclinicaldecision-aids.npjDigitalMedicine4,1(2021).
[17] IJGood.1985.Weightofevidence:Abriefsurvey.InBayesianstatistics,J.M.Bernardo,M.H.DeGroot,D.V.Lindley,andSmithA.F,M(Eds.).Vol.2.
Elsevier,249â€“270.
[18] MaiaJacobs,MelanieF.Pradier,ThomasH.McCoy,RoyH.Perlis,FinaleDoshi-Velez,andKrzysztofZ.Gajos.2021. Howmachine-learning
recommendationsinfluencecliniciantreatmentselections:theexampleofantidepressantselection.TranslationalPsychiatry11,1(2021).
[19] ToddKulesza,MargaretBurnett,Weng-KeenWong,andSimoneStumpf.2015.PrinciplesofExplanatoryDebuggingtoPersonalizeInteractive
MachineLearning.InProceedingsofthe20thInternationalConferenceonIntelligentUserInterfaces(Atlanta,Georgia,USA)(IUIâ€™15).Associationfor
ComputingMachinery,126â€“137.
[20] ToddKulesza,SimoneStumpf,Weng-KeenWong,MargaretM.Burnett,StephenPerona,AmyJ.Ko,andIanOberst.2011.Why-OrientedEnd-User
DebuggingofNaiveBayesTextClassification.ACMTrans.Interact.Intell.Syst.1,1(2011).
[21] VivianLai,ChachaChen,AlisonSmith-Renner,Q.VeraLiao,andChenhaoTan.2023.TowardsaScienceofHuman-AIDecisionMaking:AnOverview
ofDesignSpaceinEmpiricalHuman-SubjectStudies.InProceedingsofthe2023ACMConferenceonFairness,Accountability,andTransparency
(Chicago,IL,USA)(FAccTâ€™23).AssociationforComputingMachinery,NewYork,NY,USA,1369â€“1385.
[22] KathrynAnnLambe,GaryOâ€™Reilly,BrendanDKelly,andSarahCurristan.2016. Dual-processcognitiveinterventionstoenhancediagnostic
reasoning:asystematicreview.BMJQuality&Safety25,10(2016),808â€“820.
[23] TaniaLombrozo.2007.Simplicityandprobabilityincausalexplanation.CognitivePsychology55,3(2007),232â€“257.
[24] ScottM.LundbergandSu-InLee.2017.AUnifiedApproachtoInterpretingModelPredictions.InProceedingsofthe31stInternationalConferenceon
NeuralInformationProcessingSystems.4768â€“4777.
APreprint 15Le,etal.
[25] TimMiller.2023.ExplainableAIisDead,LongLiveExplainableAI!Hypothesis-drivenDecisionSupportusingEvaluativeAI.InProceedingsofthe
2023ACMConferenceonFairness,Accountability,andTransparency(Chicago,IL,USA)(FAccTâ€™23).AssociationforComputingMachinery,NewYork,
NY,USA,333â€“342.
[26] BrettPoulin,RomanEisner,DuaneSzafron,PaulLu,RussGreiner,D.S.Wishart,AlonaFyshe,BrandonPearcy,CamMacDonell,andJohnAnvik.
2006.VisualExplanationofEvidenceinAdditiveClassifiers.InProceedingsofthe18thConferenceonInnovativeApplicationsofArtificialIntelligence-
Volume2.1822â€“1829.
[27] CharviRastogi,YunfengZhang,DennisWei,KushR.Varshney,AmitDhurandhar,andRichardTomsett.2022.DecidingFastandSlow:TheRoleof
CognitiveBiasesinAI-AssistedDecision-Making.Proc.ACMHum.-Comput.Interact.6,CSCW1(2022).
[28] MarcoTulioRibeiro,SameerSingh,andCarlosGuestrin.2016. "WhyShouldITrustYou?":ExplainingthePredictionsofAnyClassifier.In
Proceedingsofthe22ndACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining.1135â€“1144.
[29] BenShneiderman,CatherinePlaisant,MaxineCohen,StevenJacobs,NiklasElmqvist,andNicholasDiakopoulos.2016.DesigningtheUserInterface:
StrategiesforEffectiveHuman-ComputerInteraction(6thed.).Pearson.
[30] EleniStraitouri,LequnWang,NastaranOkati,andManuelGomezRodriguez.2023.ImprovingExpertPredictionswithConformalPrediction.In
Proceedingsofthe40thInternationalConferenceonMachineLearning(ProceedingsofMachineLearningResearch,Vol.202),AndreasKrause,Emma
Brunskill,KyunghyunCho,BarbaraEngelhardt,SivanSabato,andJonathanScarlett(Eds.).PMLR,32633â€“32653.
[31] AlvinT.Tan.2021.CrackingtheAmesHousingDatasetwithLinearRegression.https://github.com/at-tan/Cracking_Ames_Housing_OLS.Accessed:
2023-05-30.
[32] AmosTverskyandDanielKahneman.1974.JudgmentunderUncertainty:HeuristicsandBiases.Science185,4157(1974),1124â€“1131.
[33] JaspervanderWaa,ElisabethNieuwburg,AnitaCremers,andMarkNeerincx.2021.EvaluatingXAI:Acomparisonofrule-basedandexample-based
explanations.ArtificialIntelligence291(2021).
[34] HelenaVasconcelos,MatthewJÃ¶rke,MadeleineGrunde-McLaughlin,TobiasGerstenberg,MichaelSBernstein,andRanjayKrishna.2023.Explana-
tionsCanReduceOverrelianceonAISystemsDuringDecision-Making.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW1(2023),
1â€“38.
[35] MorVered,TaliLivni,PiersDouglasLionelHowe,TimMiller,andLizSonenberg.2023.TheEffectsofExplanationsonAutomationBias.Artificial
Intelligence(2023),103952.
[36] XinruWangandMingYin.2022.EffectsofExplanationsinAI-AssistedDecisionMaking:PrinciplesandComparisons.ACMTrans.Interact.Intell.
Syst.(2022).
APreprint 16TowardsthenewXAI:AHypothesis-drivenApproach
A STATISTICSOFEXPERIMENT1
count mean std min 25% 50% 75% max
condition (median)
(C1)Recommendation-driven 102.000 1075.186 560.534 306.000 689.500 946.000 1307.500 4021.000
(C2)AIExplanationOnly 99.000 1117.162 675.505 210.000 742.500 928.000 1345.000 5559.000
(C3)Hypothesis-driven 101.000 1085.228 555.319 358.000 711.000 944.000 1287.000 3350.000
Table1. Statisticsofcompletiontimepercondition.
count mean std min 25% 50% 75% max
condition (median)
(C1)Recommendation-driven 102.000 0.290 0.071 0.183 0.239 0.277 0.333 0.484
(C2)AIExplanationOnly 99.000 0.295 0.073 0.140 0.242 0.281 0.337 0.594
(C3)Hypothesis-driven 101.000 0.267 0.063 0.154 0.228 0.252 0.304 0.474
Table2. StatisticsofBrierscore percondition.
count mean std min 25% 50% 75% max
condition (median)
(C1)Recommendation-driven 102.000 73.856 20.913 33.333 66.667 66.667 100.000 100.000
(C2)AIExplanationOnly 99.000 54.209 22.505 0.000 41.667 50.000 66.667 100.000
(C3)Hypothesis-driven 101.000 53.300 22.733 16.667 33.333 66.667 66.667 100.000
Table3. Statisticsofover-reliancepercondition.
count mean std min 25% 50% 75% max
condition (median)
(C1)Recommendation-driven 102.000 17.810 20.346 0.000 0.000 16.667 33.333 100.000
(C2)AIExplanationOnly 99.000 41.246 27.183 0.000 16.667 33.333 50.000 100.000
(C3)Hypothesis-driven 101.000 24.422 18.191 0.000 16.667 16.667 33.333 100.000
Table4. Statisticsofunder-reliancepercondition.
B SUBJECTIVEQUESTIONSINEXPERIMENT1
Afterdoingtheexperiment1,participantswereaskedtoanswer12subjectivequestionsasfollows.
(1) Incontrol:Ifeelincontrolofthedecision-makingprocesswhenusingthisdecisionaid.(0=Disagreestrongly;
10=Agreestrongly)
(2) Preference:Iwouldliketousethisdecisionaidfrequently.(0=Disagreestrongly;10=Agreestrongly)
(3) Mentaldemand:Ifoundthistaskdifficult.(0=Disagreestrongly;10=Agreestrongly)
APreprint 17Le,etal.
(4) Systemcomplexity:Thedecisionaidwascomplex.(0=Disagreestrongly;10=Agreestrongly)
(5) Trust:Iamconfidentinthedecisionaid.Ifeelthatitworkswell.(0=Disagreestrongly;10=Agreestrongly)
(6) Trust:Thedecisionaidisverypredictable.(0=Disagreestrongly;10=Agreestrongly)
(7) Trust:Thedecisionaidisveryreliable.Icancountonittobecorrectallthetime.(0=Disagreestrongly;10=
Agreestrongly)
(8) Trust:IfeelsafethatwhenIrelyonthedecisionaidIwillgettherightanswers.(0=Disagreestrongly;10=
Agreestrongly)
(9) Trust:Thedecisionaidisefficientinthatitworksveryquickly.(0=Disagreestrongly;10=Agreestrongly)
(10) Trust:Iamwaryofthedecisionaid.(0=Disagreestrongly;10=Agreestrongly)
(11) Trust:Thedecisionaidcanperformthetaskbetterthananovicehumanuser.(0=Disagreestrongly;10=
Agreestrongly)
(12) Trust:Ilikeusingthedecisionaidfordecisionmaking.(0=Disagreestrongly;10=Agreestrongly)
We evaluate Q1-4 separately to measure 4 measures (In control, Preference, Mental demand and System
complexity).WeaggregateQ5-12tomeasureTrust.
InFigure8,AI-explanation-onlyissignificantlyworsethantheotherconditionsinallfacets.Moreover,recommendation-
drivenandhypothesis-drivenarequitesimilarandthereisnostatisticaldifferencebetweenthesetwoconditions.The
reasonisthatweconductbetween-subjectexperimentssoeachparticipanthasaccesstoonlyoneconditionandtheydo
nothaveanotherconditiontocompareto.Ifwerunwithin-subjectexperimentstomeasuresubjectivequestionsinthe
future,participantscancomparedifferentdecision-makingapproachesandevaluatewhichonetheypreferthemost.
C EXAMPLEQUESTIONSINHUMANEXPERIMENT
ExamplequestionsareshowninFigure9andFigure10.
APreprint 18TowardsthenewXAI:AHypothesis-drivenApproach
(a)Incontrol(Higherisbetter) (b)Preference(Higherisbetter)
(c)Mentaldemand(Lowerisbetter) (d)Systemcomplexity(Lowerisbetter)
(e)Trust(Higherisbetter)
Fig.8. SubjectiveMeasuresinExperiment1.Meansrepresentedasdots.
APreprint 19Le,etal.
(a)(C1)Recommendation-driven (b)(C2)AIexplanationonly
Fig.9. AnexamplequestioninC1andC2.TheonlydifferenceisthatinC1,participantscanseetheAIprediction(i.e.lowpricein
thiscase)andtheweightofevidence(theexplanation)forthatprediction.InC2,theAIpredictionishidden.Therefore,eventhough
theparticipantscanseetheexplanation,theydonotknowwhichclass(low/medium/high)theevidencerefersto.
APreprint 20TowardsthenewXAI:AHypothesis-drivenApproach
Fig.10. AnexamplequestioninC3.ThehousefeaturesselectedaresimilartotheexamplequestioninFigure9.Weshowparticipants
theevidenceforallhypotheses(low,mediumandhigh),andthehousefeaturesbeforetheevidenceasshowninFigure9.Wedo
notgivethemtheAIprediction.Specifically,wehavesupportiveevidenceinmostfeaturesforhypothesislow.Bycontrast,strongly
negativeevidencerefutehypothesishigh.Thecorrectanswerhereislow.
APreprint 21