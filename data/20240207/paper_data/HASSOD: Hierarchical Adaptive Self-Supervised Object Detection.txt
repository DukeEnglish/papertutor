HASSOD: Hierarchical Adaptive Self-Supervised
Object Detection
ShengcaoCao1 DhirajJoshi2 Liang-YanGui1 Yu-XiongWang1
1UniversityofIllinoisatUrbana-Champaign 2IBMResearch
1{cao44,lgui,yxw}@illinois.edu 2djoshi@us.ibm.com
Abstract
Thehumanvisualperceptionsystemdemonstratesexceptionalcapabilitiesinlearn-
ingwithoutexplicitsupervisionandunderstandingthepart-to-wholecomposition
ofobjects. Drawinginspirationfromthesetwoabilities,weproposeHierarchical
Adaptive Self-Supervised Object Detection (HASSOD), a novel approach that
learnstodetectobjectsandunderstandtheircompositionswithouthumansupervi-
sion.HASSODemploysahierarchicaladaptiveclusteringstrategytogroupregions
intoobjectmasksbasedonself-supervisedvisualrepresentations,adaptivelyde-
termining the number of objects per image. Furthermore, HASSOD identifies
thehierarchicallevelsofobjectsintermsofcomposition,byanalyzingcoverage
relations between masks and constructing tree structures. This additional self-
supervisedlearningtaskleadstoimproveddetectionperformanceandenhanced
interpretability. Lastly,weabandontheinefficientmulti-roundself-trainingprocess
utilized in prior methods and instead adapt the Mean Teacher framework from
semi-supervisedlearning,whichleadstoasmootherandmoreefficienttraining
process. Throughextensiveexperimentsonprevalentimagedatasets,wedemon-
stratethesuperiorityofHASSODoverexistingmethods,therebyadvancingthe
state of the art in self-supervised object detection. Notably, we improve Mask
ARfrom20.2to22.5onLVIS,andfrom17.0to26.0onSA-1B.Projectpage:
https://HASSOD-NeurIPS23.github.io.
1 Introduction
Thedevelopmentofhumanvisualperceptionisremarkablefortwokeyabilities: 1)Humansbegin
learningtoperceiveobjectsintheirenvironmentthroughobservationalone[25],withoutneeding
to learn the names of these objects from external supervision. 2) Moreover, human perception
operatesinahierarchicalmanner,enablingindividualstorecognizethepart-to-wholecompositionof
objects[2,23]. Thesecharacteristiccapabilitiesoffervaluableinsightsintothelearningprocesses
ofobjectdetectors,whichstillheavilyrelyontheavailabilityandqualityoffine-grainedtraining
data. For example, the state-of-the-art detection/segmentation model, Segment Anything Model
(SAM)[18],isdevelopedonadatasetof11millionimagesand1billionobjectmasks. Itremainsan
openquestionhowtoeffectivelylearntodetectobjectsandrecognizetheircompositionsfromeven
larger-scaledatasets(e.g.,LAION-5B[26])withoutsuchobject-levelannotations.
Inpriorworkonself-supervisedobjectdetection[37,38],atwo-stagediscover-and-learnparadigmis
adopted: 1)Self-supervisedvisualrepresentations[5,15]areobtained,andasaliency-basedmethod
isemployedtoextractthemostprominentoneorfewobjects. 2)Subsequently,anobjectdetector
istrainedbasedonthesepseudo-labels, sometimesinvolvingmultipleroundsofself-trainingfor
refinement. However,despitesuchattemptstoeliminatetheneedforexternalsupervision,several
weaknessespersistintheseapproaches:1)Narrowcoverageofobjects.Thefocusononlyoneorfew
objectsperimageinpreviousmethodsunderminestheirabilitytofullyexploitthelearningsignalsin
37thConferenceonNeuralInformationProcessingSystems(NeurIPS2023).
4202
beF
5
]VC.sc[
1v11330.2042:viXraInput CutLER HASSOD (Ours) HASSOD (Ours)
Whole Objects Whole + Part + Subpart
Figure1:Fullyself-supervisedobjectdetectionandinstancesegmentationonprevalentimagedatasets.
Ourapproach,HASSOD,demonstratesasignificantimprovementoverthepreviousstate-of-the-art
method,CutLER[38],bydiscoveringamorecomprehensiverangeofobjects. Moreover,HASSOD
understandsthepart-to-wholeobjectcompositionlikehumansdo,whilepreviousmethodscannot.
naturalsceneimagescontainingdozensofobjects,suchasthoseintheMS-COCOdataset[20]. This
narrowfocusalsorestrictsthecapabilityofthesemethodstoaccuratelydetectandsegmentmultiple
objectswithinanimage. 2)Lackofcomposition. Priorworkoftenoverlooksthecompositionof
objects,neglectingtheidentificationofhierarchicallevelsforwholeobjects,partobjects,andsubpart
objects(e.g.,consideringanimageofabicycle;thebicycleisawholeobject,itswheelsandhandles
areparts,andthespokesandtiresaresubparts). Thisoversightnotonlylimitstheinterpretabilityof
learnedobjectdetectors,butalsohindersthemodel‚Äôsabilitytotackletheintrinsicambiguityinthe
taskofsegmentation. 3)Inefficiency. Therelianceonmulti-roundself-traininginearliermethods
canresultininefficientandnon-smoothtrainingprocesses,whichfurtherconstrainsthepotentialof
self-supervisedobjectdetectionandcomprehensionofobjectcomposition.
Inspiredbytheunsupervised,hierarchicalhumanvisualperceptionsystem,weproposeHierarchi-
cal Adaptive Self-Supervised Object Detection (HASSOD), aiming to address these limitations
mentionedaboveandbetterharnessthepotentialofself-supervisedobjectdetection,asdepictedin
Figure1. First,unlikepreviousmethodsthatlimittheirfocustooneorfewprominentobjectsper
image,HASSODemploysahierarchicaladaptiveclusteringstrategytogroupregionsintoobject
masks,basedonself-supervisedvisualrepresentations. Byadjustingthethresholdforterminatingthe
clusteringprocess,HASSODiscapableofeffectivelydeterminingtheappropriatenumberofobjects
perimage,thusbetterleveragingthelearningsignalsinimageswithmultipleobjects.
ThesecondkeycomponentofHASSODisitsabilitytoidentifyhierarchicallevelsofobjectsinterms
ofcomposition. Byanalyzingthecoveragerelationsbetweenmasksandbuildingtreestructures,
ourapproachsuccessfullyclassifiesobjectsaswholeobjects,partobjects,orsubpartobjects. This
novelself-supervisedlearningtasknotonlyimprovesdetectionperformance,butalsoenhancesthe
interpretabilityandcontrollabilityofthelearnedobjectdetector,apropertythatpriorself-supervised
detectors lack. Therefore, HASSOD users can comprehend how the detected whole objects are
assembledfromsmallerconstituentparts. Simultaneously,theycancontrolHASSODtoperform
detectionattheirpreferredhierarchicallevel,therebycateringmoreeffectivelytotheirneeds.
Finally, HASSOD abandons the multi-round self-training used in previous methods which lacks
efficiencyandsmoothness. Instead,wetakeinspirationfromtheMeanTeacher[22,31]framework
insemi-supervisedlearning, employingateachermodelandastudentmodelthatmutuallylearn
fromeachother. Thisinnovativeadaptationfacilitatesasmootherandmoreefficienttrainingprocess,
resultinginamoreeffectiveself-supervisedobjectdetectionapproach.
Insummary,thekeycontributionsofHASSODinclude:
2
SIVL
563stcejbO
B1-AS‚Ä¢ Ahierarchicaladaptiveclusteringstrategythatgroupsregionsintoobjectmasksbasedonself-
supervisedvisualrepresentations,adaptivelydeterminingthenumberofobjectsperimageand
effectivelydiscovermoreobjectsfromnaturalscenes.
‚Ä¢ Theabilitytoidentifyhierarchicallevelsofobjectsintermsofcomposition(whole/part/subpart)
byanalyzingcoveragerelationsbetweenmasksandbuildingtreestructures,leadingtoimproved
detectionperformanceandenhancedinterpretability.
‚Ä¢ AnoveladaptationoftheMeanTeacherframeworkfromsemi-supervisedlearning,whichreplaces
themulti-roundself-traininginpriormethods,leadingtosmootherandmoreefficienttraining.
‚Ä¢ State-of-the-artperformanceinself-supervisedobjectdetection,enhancingMaskARfrom20.2to
22.5onLVIS[11],andfrom17.0to26.0onSA-1B[18]. Remarkably,theseresultsareachieved
throughtrainingwithonly1/5oftheimagesand1/12oftheiterationsrequiredbypriorwork.
2 RelatedWork
Unsupervisedobjectdetection/discovery. Identifyingandlocatingobjectsinimageswithoutusing
any human annotations is a challenging task, as it requires learning the concept of objects from
image data without any external supervision. OSD [33] formulates this task as an optimization
problemonagraph, wherethenodesareobjectproposalsgeneratedbyselectivesearch, andthe
edges are constructed based on visual similarities. rOSD [34] improves the scalability of OSD
with a saliency-based region proposal algorithm and a two-stage strategy. LOD [35] formulates
unsupervisedobjectdiscoveryasarankingoptimizationproblemforimprovedcomputationefficiency.
FollowingtheobservationthatDINO[5],aself-supervisedpre-trainingmethod,cansegmentthemost
prominentobjectineachimage,LOST[29],FOUND[30],andFreeSOLO[37]trainobjectdetectors
using saliency-based pseudo-labels. TokenCut [39] and CutLER [38] also use self-supervised
representations, but generate pseudo-labels by extending Normalized Cuts [28]. Saliency-based
regionproposalandNormalizedCutsarebothfocusedontheprominentobjectsineachimage,and
usually only propose one or few objects per image. Different from these approaches, HASSOD
producesinitialpseudo-labelsusingahierarchicaladaptiveclusteringstrategy,whichcanadaptively
determinethenumberofobjectsdependingontheimagecontents.
Objectdetectionbyparts. Detectingobjectsbyidentifyingtheircomposingpartshasbeenwidely
studiedincomputervision. DeformablePartsModel(DPM)[9]isaseminalapproachthatutilizes
discriminativelytrainedpart-basedmodelsforobjectdetection,whicheffectivelymodelscomplex
objectstructuresandimprovesovermonolithicdetectors. Afollowingmethod[6]notonlydetects
theobjects,butalsosimultaneouslyrepresentsthemusingbodyparts,highlightingtheimportanceof
bothholisticmodelsandpart-basedrepresentations. Thisideaisextendedbyleveragingbothwhole
objectandpartdetectionstoinferhumanactionsandattributes[10],suggestingtheadvantageofa
combinedapproach. Inthiswork,werevisitthisclassicideaofrepresentinganddetectingwhole
objectsaswellastheirpartsinthecontextofself-supervisedlearning.
3 Approach
In this section, we introduce the learning process in our proposed approach, Hierarchical Adap-
tiveSelf-SupervisedObjectDetection(HASSOD).Followingpriorworkonunsupervisedobject
detection[29,30,37‚Äì39],HASSODadoptsatwo-stagediscover-and-learnprocesstolearnaself-
supervised object detector, as illustrated in Figure 2. In the first stage, we discover objects from
unlabeledimagesusingself-supervisedrepresentations,andgenerateasetofinitialpseudo-labels.
Theninthesecondstage,welearnanobjectdetectorbasedontheinitialpseudo-labels,andsmoothly
refinethemodelbyself-training. Thefirststageisbasedonpre-trained,fixedvisualfeatures,andthe
secondstagelearnsanobjectdetectortoimproveoverthefixedvisualfeaturesandpseudo-labels. In
thefollowingsubsections,wedescribethethreecorecomponentsofHASSODindetail.
3.1 HierarchicalAdaptiveClustering
In the first stage, HASSOD creates a set of pseudo-labels as the initial self-supervision source.
Weproposeahierarchicaladaptiveclusteringstrategytodiscoverobjectmasksaspseudo-labels,
usingonlyunlabeledimagesandafrozenself-supervisedvisualbackbone. Figure3providesan
overviewofthisprocedure. Ourhierarchicaladaptiveclusteringalgorithmextendsagglomerative
3Stage 1: Initial Pseudo-Label Discovery Stage 2: Object Detector Learning
(Section 3.1) (Sections 3.2 & 3.3)
Unlabeled Frozen Initial Pseudo- Object Detector
Raw Images DINO ViT Labeled Masks Cascade Mask R-CNN
Mean Teacher
Self-Training
Figure2: Two-stagediscover-and-learnprocessinHASSOD.Stage1usesafrozen,self-supervised
DINO[5]ViTbackbonetodiscoverinitialpseudo-labelsfromunlabeledimages. Stage2learnsan
objectdetectortoimproveoverthepre-trainedfeaturesandinitialpseudo-labels.
ùúÉ‚Äô"#$%#=0.1 Whole Hierarchical
Post- Levels of Objects
Process
Patch-Level Merge All Initial
Features ùúÉ!"#$%#=0.2 Pseudo-Labels Part
DINO Post- Ensem-
ViT Process ble Split
Merge
ùúÉ&"#$%#=0.4 Subpart
Merge
Post-
Process
Figure3:Hierarchicaladaptiveclusteringandhierarchicallevelsofobjects.Theprocedureofcreating
initial pseudo-labels for training the object detector without any human annotations includes the
followingsteps: (Initialize)VisualfeaturesareextractedfromthegivenimagebyaViTpre-trained
withDINO[5],andeach8√ó8patchisinitializedasoneindividualregion. (Merge)Adjacentregions
withthehighestfeaturesimilaritiesareprogressivelymergedintoobjectmasks, untilthepre-set
thresholdsŒ∏merge arereached. (Post-Process)Objectmasksareselectedandrefinedusingsimple
i
post-processingtechniques. (Ensemble)Resultsfrommultiplethresholds{Œ∏merge}3 arecombined
i i=1
toensurebettercoverageofpotentialobjects. (Split)Analysisofcoveragerelationsdividesobjects
intothreehierarchicallevels: whole,part,andsubpart. Theexampleontherightillustratesthetree
structureofobjectcomposition: Thewholeaircraftiscomposedofanupperandalowerpart. The
upperpartfurtherconsistsofaleftwing,arightwing,andapersonstandingonit.
clustering [12], grouping adjacent image patches into semantically coherent masks based on the
similarity of self-supervised visual representations. More specifically, we use a frozen ViT-B/8
model [8] pre-trained on unlabeled ImageNet [7] by DINO [5], a self-supervised representation
learningmethod,toextractvisualfeatures. Foreachimage,wetakethefeaturemapgeneratedby
thismodelatitsfinalTransformerlayer[32]. Eachspatialelementinthefeaturemapcorrespondsto
a8√ó8patchintheoriginalimage.
Toinitiatethehierarchicaladaptiveclusteringprocess,wetreateachpatchasanindividualregion.
Wethencomputethepairwisecosinesimilaritybetweenthefeaturesofadjacentregionstomeasure
their closeness in the semantic feature space. The regions are gradually merged into masks that
representobjectsbyiterativelyperformingthefollowingsteps:1)Identifythepairofadjacentregions
withthehighestfeaturesimilarity. 2)Ifthesimilarityissmallerthanthepre-setthresholdŒ∏merge,stop
themergingprocess. 3)Mergethetworegions,andcomputethefeatureofthemergedregionby
averagingallthepatch-levelfeatureswithinit. 4)Updatethepairwisesimilaritybetweenthisnewly
mergedregionanditsneighbors. ThismergingprocessisvisualizedinFigure3,columns1-3.
Oncethemergingprocessiscomplete,weperformaseriesofautomatedpost-processingstepsto
refineandselectthemasks,includingConditionalRandomField(CRF)[19]andfilteringoutmasks
thataresmallerthan100pixelsorcontainmorethantwocornersoftheimage. Thesestepsarebased
onstandardpracticesinpreviouswork[38]andrequirenomanualintervention. Ourhierarchical
adaptiveclusteringstrategyeffectivelygroupsregionsintoobjectmasksbasedonself-supervised
visual representations, adaptively determining the appropriate number of objects per image. In
4imagescontainingmultipleobjectswithheterogeneoussemanticfeatures,themergingprocessstops
earlier, resultinginalargernumberofregionscorrespondingtodifferentobjects. Conversely, in
highlyhomogeneousimages,moreregionsaremerged,leadingtofewerobjectmasks. Thisadaptive
approachenablesHASSODtocovermoreobjectsforself-supervisedlearning,ratherthanbeing
limitedbyoneorafewprominentobjectsineachimageinpriorwork[38,39].
In practice, we are not restricted to one single fixed threshold Œ∏merge to determine the stopping
criterionfortheclusteringprocess. Instead,wefinditbeneficialtoensembleresultsfrommultiple
(e.g.,3)pre-setthresholds{Œ∏merge}3 . Whenthecurrentlyhighestfeaturesimilarityreachesoneof
i i=1
thesethresholds,werecordthederivedobjectmasksfromthemergedregionsatthatstep. Utilizing
multiplethresholdsallowsustocaptureobjectsofvarioussizesandatdifferenthierarchicallevels
of composition, enabling a more comprehensive coverage of objects in scene images. The post-
processingandensemblearevisualizedinFigure3,columns4-5.
3.2 HierarchicalLevelPrediction
Inthefollowingsecondstage,HASSODlearnsanobjectdetectionandinstancesegmentationmodel,
e.g.,CascadeMaskR-CNN[4],usingtheinitialpseudo-labelsgeneratedinthefirststage. Bytraining
onsuchpseudo-labels,themodellearnstorecognizecommonobjectsacrossdifferenttrainingimages,
andthusachievesenhancedgeneralizationtoimageswhichthemodelhasnotseenduringtraining.
Inadditiontothestandardobjectdetectionobjective,weaimtoequipourdetectorwiththeability
tounderstandthehierarchicalstructureamongobjectsandtheirconstituentparts. InHASSOD,we
incorporatetheconceptofhierarchicallevelsintoobjectmasksbyleveragingthecoveragerelations
betweenthem. Formally,wesaymaskAiscoveredbymaskBwhenthreeconditionsaresatisfied
(withrespecttoapre-setcoveragethresholdŒ∏cover%): 1)MorethanŒ∏cover%ofpixelsinmaskAare
alsoinmaskB.2)LessthanŒ∏cover%ofpixelsinmaskBareinmaskA.3)MaskBisthesmallest
amongallmaskssatisfyingtheprevioustwoconditions. Intuitively,ifmaskBcoversmaskA,it
suggests that A is a part of B and B is at a higher level than A. If we consider A and B as tree
nodes,AshouldbeachildofB.Usingallsuchcoveragerelations,wecanconstructaforestoftrees
thatcontainallmasksinanimage. Ultimately,therootsofalltreesinthisimageareconsidered
as‚Äúwhole‚Äùobjects,theirdirectchildrenare‚Äúpart‚Äùobjects,andalltheremainingdescendantsare
‚Äúsubpart‚Äùobjects. AnexampleisshownontherightsideofFigure3.
After identifying the hierarchical levels of object masks in the pseudo-labels, we attach a new
classificationheadtotheobjectdetectorforlevelprediction,whichclassifieseachpredictedobjectas
awholeobject,apartobject,orasubpartobject. ThisnewcomponentenablesHASSODtomodel
objectcompositioneffectively,resultinginimprovedobjectdetectionperformanceandenhanced
interpretabilitycomparedwithpreviousself-supervisedobjectdetectionmethods. Thehierarchical
levelpredictionheadisaddedalongsidetheexistingforeground/backgroundclassificationhead,box
regressionhead,andmaskpredictionhead. Subsequently,wetraintheobjectdetectorusingtheinitial
setofobjectmaskpseudo-labelsobtainedfromthehierarchicaladaptiveclusteringprocess,aswell
astheadditionallevelpredictiontask.
3.3 MeanTeacherTrainingwithAdaptiveTargets
Notably,theinitialpseudo-labelsderivedinthefirststagecontainnoiseandarenotperfectlyaligned
withrealobjects. Toimproveoversuchnoisypseudo-labels,priorwork[37,38]usuallyemploys
multi-roundself-trainingtorefinethemodel,i.e.,usingawell-traineddetectortore-generatepseudo-
labelsandre-trainanewdetector. Forthefirsttime,HASSODrefinestheobjectdetectorefficiently
and smoothly by adapting the Mean Teacher learning paradigm [22, 31] from semi-supervised
learningtothefullyself-supervisedsetting.
Before introducing our innovative adaptation of Mean Teacher in the self-supervised setting, we
firstbrieflysummarizethemutual-learningprocessinMeanTeacher(seeFigure4). MeanTeacher
employstwomodels,ateacherandastudent,whichlearnfromeachother. Theteachertakesweakly-
augmented,unlabeledimagesasinputandprovidesdetectionoutputsastrainingtargetsforthestudent.
Thestudent‚Äôsweightsareupdatedtominimizethediscrepancybetweenitspredictionsandthetargets
given by the teacher on the same unlabeled images but with strong augmentation. In the semi-
supervisedsetting,thestudentreceivessupervisionfromtwosourcessimultaneously. Onesource
isthe‚Äúteacher-to-student‚Äùbranchmentionedabove,andtheotheristhe‚Äúlabel-to-student‚Äùbranch
5Teacher-to-Student Branch
Teacher's
Predict
Predictions A
Weak Teacher
Aug. Detector
ùêø!"#$%"&
Unlabeled Student's
Image Batch A
EMA Predict
Predictions A
√óùõº!"#$%"&‚Üó
Strong Student Supervise
Aug. Detector
ùêø!)!#‚Äô
Unlabeled Student's
Image Batch B
Predict
Predictions B
√óùõº‚Äô#("‚Äô‚Üò
ùêø‚Äô#("‚Äô
Initial
Discover
Pseudo-Labels B
Label-to-Student Branch
Figure4: MeanTeacherself-trainingwithadaptivetargetsinHASSOD.Twodetectorsofthesame
architecture,theteacherandthestudent,learnfromeachothertoimproveovertheinitialpseudo-
labels. The teacher is updated as the exponential moving average (EMA) of the student. The
studentreceivessupervisionfromtwobranches: Theteacher-to-studentbranch(top)encourages
thestudenttomimictheteacher‚Äôspredictions;thelabel-to-studentbranch(bottom)minimizesthe
discrepancybetweenthestudent‚Äôspredictionsandtheinitialpseudo-labels. Duringtraining, our
proposedadaptivetargetstrategyincreasestheweightfortheteacher-to-studentbranch,Œ± ,and
teacher
decreasestheweightforthelabel-to-studentbranch,Œ± ,sincetheteacherbecomesamoreand
label
morereliableself-supervisionsourcecomparedwiththeinitialpseudo-labels.
wherethestudentlearnsfromimageswithground-truthlabels. Bothbranchescomputestandard
detectionlosses(e.g.,boundingboxclassificationandregression),andthestudentisoptimizedto
minimizethetotalloss. Theteacher‚Äôsweightsareanexponentialmovingaverageofthestudent‚Äôs
weights,ensuringsmoothandstabletrainingtargets.
InHASSOD,wedonothaveanylabeledimagesfromhumansupervisionbutinsteadutilizetwo
sourcesofself-supervision. Onesourceistheinitialpseudo-labelsobtainedfromourhierarchical
adaptiveclustering,whichfunctionssimilarlytothelabels-to-studentbranchinthesemi-supervised
setting. Theothersourceisthedetectionpredictionsmadebytheteachermodel,whichcorresponds
totheteacher-to-studentbranchinMeanTeacher. DifferentfromstandardMeanTeacher,ourmethod
employs adaptive training targets, as we gradually adjust the loss weights for the two branches.
Thisisbecausetheinitialpseudo-labelsmaynoteffectivelycoverallpossibleobjects, whilethe
teachermodelwillprogressivelyimproveasabettersourceofsupervision. Consequently,during
MeanTeacherself-training,wecontinuouslydecreasethelossweightŒ± forthebranchthatuses
label
theinitialpseudo-labelsandincreasethelossweightŒ± forthebranchbasedontheteacher‚Äôs
teacher
predictions,followingacosineschedule.
4 Experiments
Inthissection,weconductextensiveexperimentstoevaluateHASSODincomparisonwithprevious
methods. WefirstdescribethetrainingdetailsandefficiencyinSection4.1. Section4.2introduces
thedatasetsandmetricsusedforevaluation. Section4.3presentsourmainresultsofself-supervised
objectdetectionandinstancesegmentation. Section4.4providessomequalitativeresultsandanalysis.
Section 4.5 conducts further experiments to verify the effects of each component in HASSOD.
Additionalquantitativeandqualitativeresultsareincludedintheappendix.
4.1 Data-EfficientandComputation-EfficientTraining
WetrainaCascadeMaskR-CNN[4]withaResNet-50[13]backboneonMS-COCO[20]images.
ThebackboneisinitializedfromDINO[5]self-supervisedpre-training. Weuseboththetrainand
unlabeled splits of MS-COCO, totaling to about 0.24 million images. Notably, this amount of
imagesisonly1/5ofImageNetusedbypriorworkCutLER[38]. ComparedwithImageNet-like[7]
iconicimages, imagesinMS-COCOaremostlycapturedincomplexscenescontainingmultiple
objectswithdiverselayoutsandcompositions. Therefore,eachimageoffersricherlearningresources
forobjectdetectors,enablingeffectivedetectortrainingwithsignificantlyfewerimages. Thewhole
6training process spans 40,000 iterations, taking about 20 hours on 4 NVIDIA A100 GPUs. The
efficiencyandsmoothnessintroducedbytheMeanTeacherself-trainingapproachreducesthetraining
iterationsto1/12ofthatrequiredbyCutLER[38],highlightingthecomputationefficiencyofour
trainingstrategy. ImplementationdetailsareincludedinAppendixJ.
4.2 EvaluationDatasetsandMetrics
Wemainlyconductourexperimentsinazero-shotmanneronthevalidationsetsofthreebenchmark
datasets, namelyObjects365[27], LVIS[11], andSA-1B[18]. Giventhatself-supervisedobject
detectionmethods,includingHASSOD,donotutilizeclasslabelsasaformofsupervision,wefollow
prior work [37‚Äì39] and evaluate these models as class-agnostic detectors, comparing them only
againsttheboundingboxesandmasksprovidedinthedatasetannotations.
‚Ä¢ Objects365[27]isalarge-scaleobjectdetectiondatasetcontaining365objectcategories. The
combinedvalidationsetsofObjects365v1andv2include80,000imagesintotal.
‚Ä¢ LVIS[11]isadatasetthatfeaturesawidevarietyofover1,200objectclasses, usingthesame
images as MS-COCO [20]. LVIS v1.0 validation set has 19,809 images, each annotated with
objectmasksforinstancesegmentation.
‚Ä¢ SA-1B[18]isarecentdatasetthatincludes11millionimagesand1billionfine-grained,model-
generatedobjectmasks. SA-1Bprovidesamorecomprehensivecoverageofallpotentialobjects,
facilitatingamorerobustevaluationofself-supervisedobjectdetectors.AsSA-1Bdoesnotprovide
avalidationsplit,weutilizearandomsubsetof50,000imagesforourassessment.
Intermsofevaluationmetrics,wefocusprimarilyonaveragerecall(AR)ratherthanaverageprecision
(AP).ThechoiceofARoverAPismotivatedbythenatureoftheself-supervisedtask. Inadataset
withafixednumberofclasses,objectsnotlabeledbyhumans‚Äìsimplybecausetheydonotfallunder
thedesignatedclasses‚Äìmaystillbedetectedbyaself-superviseddetectionmodel. StandardAP
calculationwouldpenalizesuchpredictionsasfalsepositives,despitethembeingvaliddetections.
Incontrast,ARdoesnotsufferfromthisissue,makingitamoreappropriatemetricforourcontext.
Byprioritizingrecall,wecanmoreaccuratelyassesstheabilityofourmodeltoidentifyallrelevant
objects in an image, which aligns with the goal of the self-supervised object detection task. We
evaluateARbasedonbothboundingboxesforobjectdetection(‚ÄúBoxAR‚Äù)andmasksforinstance
segmentation(‚ÄúMaskAR‚Äù).AppendixAdiscussestheevaluationmetricsindetail.
4.3 Self-SupervisedDetectionandSegmentation
After we use HASSOD to train the object detection and instance segmentation model, Cascade
Mask R-CNN, on MS-COCO images, we evaluate our model on Objects365, LVIS, and SA-1B
datasetsinazero-shotmanner,i.e.,nofurthertrainingonthesethreedatasets. Thewholetrainingand
evaluationprocessisrepeatedforthreetimes,andwereportthemeanperformanceforconciseness.
ThestandarddeviationofARislessthan0.6onallthreedatasets. Completeevaluationresultsare
includedinAppendixH.
WecompareHASSODwithpriorstate-of-the-artself-supervisedobjectdetectionmethods,including
FreeSOLO[37]andCutLER[38].WealsoincluderesultsfromSAM[18],thelatestsupervisedclass-
agnosticdetection/segmentationmodel,togainunderstandingofthegapbetweenself-supervisedand
supervisedmodels,andhowHASSODiseffectivelyclosingthisgap. Tobeconsistentwithother
models,weprovideSAMwithonlytherawimagesbutnoboundingboxesorpointsasprompts.
ForpriormethodsFreeSOLO,CutLER,andSAM,wedirectlyevaluatethepubliclyavailablemodel
checkpointsonthegivendatasets. Consideringthatthenumberofground-truthlabelsperimagemay
begreaterthan100,weallowallmodelstooutputupto1,000predictionsperimage.
AsshowninthemainresultssummarizedinTable1,HASSODsignificantlyimprovesthedetection
andsegmentationperformanceoverpreviousself-supervisedmodelsFreeSOLOandCutLER.On
Objects365,weimprovetheBoxARby3.2;onLVIS,weimproveBoxARby3.3,andMaskARby
2.3. ThemostremarkableperformancegainisobservedonSA-1B.WeimproveBoxARfrom18.8
to29.0(relatively+54%)andimproveMaskARfrom17.0to26.0(relatively+53%).
Wegainimprovedrecallsforobjectsofallscales, butsmallandmedium-sizedobjectsrelatively
benefitmorethanlargeobjects. Forinstance,ourAR is2.6√óasCutLER‚ÄôsAR onSA-1B.Itis
S S
worthnotingthatdetectingsmallobjectsisintrinsicallyharderthanlargeobjects‚Äìeventhoughthe
7Table 1: Comparison of self-supervised object detection and instance segmentation methods on
prevalentimagedatasets. Weconsidertheaveragerecall(AR)insteadofaverageprecision(AP)
as the main metric, because valid detection of objects outside the categories defined by human
annotationsispenalizedbyAP.HASSODsignificantlyoutperformsthepreviouslybestmethods
FreeSOLO[37]andCutLER[38]intermsofARatallobjectscales(Small,Medium,andLarge). To
understandtheextentofimprovements,wealsoincluderesultsfromstate-of-the-artsupervisedmodel
SAM[18]. HASSODleadstoareducedgapbetweenfullyself-supervisedmodelsandsupervised
SAM.Notably,HASSODonlyuses1/5oftrainingimagesand1/12oftrainingiterationsasCutLER.
Box Mask
Method AR AR AR AR AP AR AR AR AR AP
S M L S M L
Objects365[27]
SAM[18] 54.9 32.1 60.5 67.6 11.9
FreeSOLO[37] 10.2 0.2 5.8 23.4 3.4 Noground-truthmask
CutLER[38] 35.8 17.6 36.1 50.5 11.5 annotationsinObjects365
HASSOD(Ours) 39.0 21.4 40.4 52.1 11.0
LVIS[11]
SAM[18] 42.7 27.7 66.3 75.5 6.1 46.1 31.1 71.3 74.6 6.7
FreeSOLO[37] 6.4 0.3 9.7 34.6 1.9 5.9 0.2 9.2 31.7 1.9
CutLER[38] 23.6 13.1 36.2 55.6 4.5 20.2 11.3 31.1 46.2 3.6
HASSOD(Ours) 26.9 15.6 42.2 56.9 4.9 22.5 12.7 36.1 47.8 4.2
SA-1B[18]
SAM[18] 60.5 19.8 59.8 81.5 38.2 60.8 20.0 59.9 82.2 38.9
FreeSOLO[37] 2.4 0.0 0.1 7.4 1.5 2.2 0.0 0.2 6.9 1.5
CutLER[38] 18.8 5.1 14.6 32.8 9.0 17.0 4.9 13.9 28.5 7.8
HASSOD(Ours) 29.0 13.3 25.1 43.8 15.5 26.0 12.9 22.8 38.3 13.8
labels in SA-1B are produced by the same SAM model, when the bounding box prompts are no
longeravailable,SAMcanonlyreacha20.0MaskARforsmallobjects. Meanwhile,wehalvethe
performancegapbetweenself-supervisedCutLERandsupervisedSAMfrom15.1MaskAR
S
to7.1MaskAR . Bylearningfromhierarchicallevelsofobjectcompositions, HASSODmore
S
effectivelycapturessmallobjectswhicharepartofwholeobjects.
4.4 QualitativeResults
Inthissection,weanalyzesomequalitativeresultsonimagesfromLVIS.Thevisualizationisshown
inFigure5. QualitativeresultsonotherdatasetsareincludedinAppendixK.
As shown in the examples, our proposed HASSOD exhibits a more comprehensive coverage of
all objects incomplex scenes, compared with theprevious state-of-the-artself-supervised object
detectionmethodCutLER[38]. Thisadvantageoriginatesfromthepseudo-labelsgeneratedbyour
hierarchical adaptive clustering, which includes a proper number of candidate objects per image
accordingtotheimagecontents,ratherthanonlyfocusingonafixednumberofobjects. Furthermore,
HASSODcanpredictthehierarchicallevelofeachdetectedobject. Beingafullyself-supervised
model, HASSOD has surprisingly gained the human-like ability to comprehend the composition
ofobjects. Thisabilityleadstobetterinterpretabilityandcontrollability: UsersofHASSODcan
understandthecompositionofeachobjectdetectedbythemodel. Meanwhile,userscanalsocontrol
thesegmentationgranularitybyselectingthepredictionsatthedesiredhierarchicallevel.
ThequalitativeresultsalsoshowsomelimitationsofHASSOD.Bycomparingthelasttwocolumns,
itcanbeobservedthatHASSODproducesrelativelyfewerpredictionsfor‚Äúsubpart‚Äùobjects. Thisis
duetothedistributionimbalanceintheinitialpseudo-labels,inwhichonlyabout10%objectsare
subparts. Also,thehierarchicallevelslearnedbyHASSODaresometimesinconsistentwithhuman
perception. Forexample,insteadofrecognizingthepersonasawholeobjectinthelastexample
image,HASSODdetectstheupperandlowerpartsofthebodyaswholeobjects. Duetothelackof
humansupervision,thehierarchicalpredictionofHASSODisnotalwaysalignedwithhumans. We
furtheranalyzethislimitationinAppendixI.
8Input CutLER HASSOD (Ours) HASSOD (Ours) HASSOD (Ours)
Whole Objects Whole + Part Whole + Part + Subpart
Figure 5: Qualitative results on LVIS images. Overall, our HASSOD successfully detects more
objectscomparedwithCutLER[38]. CutLERtendstodetectonlyoneorfewprominentobjects
intheimage,whileHASSODcapturesotherobjectsaswell(e.g.,breadinrow1,andtrafficsign
inrow3). Moreover,HASSODlearnsthecompositionofobjects(e.g.,cat-face-eyeinrow2,and
vehicle-wheel-tireinrow4),whichissimilartohumanperception.
4.5 AblationStudy
Inthissection,weconductanablationstudytounderstandtheeffectsofeachcomponentinHASSOD.
Toevaluatetheperformancemorerobustlyagainstalargersetofhuman-annotatedobject-levellabels,
wecombinetheannotationsofMS-COCO[20]andLVIS[11]ontheval2017split,becausethey
arecomplementarytoeachother: LVISusesthesameimagesasMS-COCO,butlabelsmoreobject
classes. However,LVISannotationsarenotasexhaustiveasMS-COCO,meaningthatobjectswithin
LVIScategoriesmaynotbelabeledonallimages. Aftercombiningthetwosetsofannotationsand
removingduplicates,therearearound20object-levellabelsperimage. Weusethiscombineddataset
forevaluationinalltheablationstudyexperiments,unlessotherwisespecified.
Quality of initial pseudo-labels. We first examine how the design choices in our hierarchical
adaptive clustering influence the quality of initial pseudo-labels. The results are summarized in
Table2. EachthresholdŒ∏merge ‚àà{0.1,0.2,0.4}leadstoadifferenttrade-offbetweenthenumberof
i
labelsperimageandtherecall. Ahigherthresholdstopsthemergingprocessearlier,andthusresults
inmorepseudo-labels. Withpost-processing, wecanimprovepseudo-labelqualitybyremoving
abouthalfofthelabels,andincreaseAPsignificantlywithoutlosingmuchAR.Finally,theensemble
ofmultiplemergingthresholdsŒ∏merge ‚àà{0.1,0.2,0.4}bringsthebestoverallpseudo-labelquality.
i
AppendicesD,E,andFpresentmoredetailsregardingthechoiceofŒ∏merge,computationcosts,and
ViTbackbonesinthisstage.
EffectsofhierarchicallevelpredictionandMeanTeacher. Aftergeneratingtheinitialpseudo-
labels with hierarchical adaptive clustering, we train the object detector with several techniques,
includinghierarchicallevelprediction,MeanTeacherself-training,andadaptivelyadjustinglearning
targets. The contribution of each technique is summarized in Table 3. Each component brings
anadditional0.3-0.5MaskARimprovement, andwhentheyfunctiontogether, thebestoverall
performancecanbeachieved.
9Table2: Ablationstudyonfactorsinfluencingthequalityofinitialpseudo-labels. Thethreshold
Œ∏merge controls the stopping criterion of the merging process, and affects AR and the number of
pseudo-labels. Applyingpost-processingcanremovelow-qualitypseudo-labelswithoutdecreasing
ARbyalargemargin. Ensembleofmultiplepseudo-labelsourcesleadstothebestoverallquality.
Post- Labels Mask
Method Œ∏merge Process perImg AR AR AR AR AP
S M L
MaskCut[38] ‚Äì ‚úì 1.85 3.5 0.0 2.0 20.0 1.5
0.1 5.33 4.4 0.8 5.1 16.6 1.2
0.1 ‚úì 2.58 4.1 0.6 5.1 15.6 1.8
Hierarchical 0.2 8.36 5.5 1.2 7.0 18.9 1.3
adaptive 0.2 ‚úì 4.20 5.3 0.9 7.0 18.4 1.8
clustering 0.4 23.33 7.9 2.1 12.0 21.7 0.7
(Ours) 0.4 ‚úì 11.61 7.8 1.7 12.1 22.1 1.3
ensemble ‚úì 12.69 8.9 1.7 12.4 29.1 1.7
Table3: Ablationstudyonfactorsinfluencingthetrainingoftheobjectdetector. Hierarchicallevel
predictionisintroducedasanauxiliarytaskforself-supervision. MeanTeacherself-trainingreplaces
thevanillamulti-roundself-trainingandbringsasmootherandmoreefficienttrainingprocess. The
weightsoftwolearningtargets,initialpseudo-labelsandteacherpredictions,areadaptivelyadjusted
tobuildamoreeffectivecurriculum. Allthethreekeydesignsarecombinedforthebestoverall
performanceofHASSOD.
Level Mean Adaptive Mask
Prediction Teacher Targets AR AR AR AR AP
S M L
20.2 9.2 30.4 42.5 5.7
‚úì 20.6 9.7 30.1 43.9 6.1
‚úì ‚úì 22.1 10.9 32.9 44.5 5.5
‚úì ‚úì ‚úì 22.4 11.3 32.9 45.0 6.3
Improvement over initial pseudo-labels. Although the initial pseudo-labels are produced by a
frozenDINObackboneandtheytendtobenoisyandcoarse,HASSODisnotupper-boundedbythe
qualityofthefixedinitialpseudo-labelsorthepre-trainedbackbone. Thisisbecauseofthefollowing
reasons: 1)Whiletheinitiallydiscoveredpseudo-labelsarenoisy,inthelearningstagewetraina
detectionmodeltolearncommonobjectsandtheirhierarchicalrelationsforenhancedgeneralization
tounseenimages. Bylearningthisdetector,weboostthedetectionARandAPfrom8.9and1.7
(thelastrowinTable2)to20.6and6.1(thesecondrowinTable3),respectively. Meanwhile,the
pre-trainedbackbonefeaturesareadaptedforthedetectiontaskinanend-to-endmanner. 2)We
furtherleverageMeanTeacherforcontinualself-enhancement,andgraduallyminimizethenegative
impactofnoisyinitialpseudo-labels. Theevolvingteacherdetectoranditsfeaturesprovideimproved
pseudo-labelstothestudent. Notably,wecandirectlyreadoutthepredictionsfromtheteacherasthe
refinedhierarchicalpseudo-labels,insteadofinefficientlyrunningtheclusteringalgorithmusingthe
enhancedbackbone. Consequently,wefurtherimprovethedetectionARandAPto22.4and6.3(the
lastrowinTable3),respectively.
5 Conclusion
WepresentHierarchicalAdaptiveSelf-SupervisedObjectDetection(HASSOD),anapproachinspired
byhumanvisualperceptionthatlearnstodetectobjectsandunderstandobjectcompositioninaself-
supervisedmanner. HASSODusesahierarchicaladaptiveclusteringstrategytoproposeavarying
numberofobjectsperimage,andlearnshierarchicallevelsofobjectsbyanalyzinggeometricrelations
betweenobjects. MeanTeacherself-trainingwithadaptivetargetsfacilitatesthedetectortraining
process with smooth learning objectives and improved training efficiency. Empirical evaluation
on recent large-scale image datasets Objects365, LVIS, and SA-1B demonstrates our significant
improvementoverpriorself-superviseddetectors. Wedetailthelimitationsandbroaderimpactsof
HASSODinAppendixI.
10Acknowledgments
ThisworkwassupportedinpartbytheIBM-IllinoisDiscoveryAcceleratorInstitute,NSFGrant
#2106825,NIFAAward#2020-67021-32799,theJumpARCHESendowmentthroughtheHealth
CareEngineeringSystemsCenter,theNationalCenterforSupercomputingApplications(NCSA)
attheUniversityofIllinoisatUrbana-ChampaignthroughtheNCSAFellowsprogram,theIllinois-
InsperPartnership,andtheAmazonResearchAward. ThisworkusedNVIDIAGPUsatNCSADelta
throughallocationsCIS220014,CIS230012,andCIS230013fromtheAdvancedCyberinfrastructure
CoordinationEcosystem: Services&Support(ACCESS)program[3],whichissupportedbyNSF
Grants#2138259,#2138286,#2138307,#2137603,and#2138296.
References
[1] AnkanBansal,KaranSikka,GauravSharma,RamaChellappa,andAjayDivakaran. Zero-shotobject
detection. InECCV,2018. 15
[2] IrvingBiederman. Recognition-by-components:Atheoryofhumanimageunderstanding. Psychological
review,94(2):115,1987. 1
[3] TimothyJ.Boerner,StephenDeems,ThomasR.Furlani,ShelleyL.Knuth,andJohnTowns. ACCESS:
Advancinginnovation:NSF‚Äôsadvancedcyberinfrastructurecoordinationecosystem:Services&support.
InPracticeandExperienceinAdvancedResearchComputing,2023. 11
[4] ZhaoweiCaiandNunoVasconcelos. CascadeR-CNN:Delvingintohighqualityobjectdetection. In
CVPR,2018. 5,6,15,16,21
[5] MathildeCaron,HugoTouvron,IshanMisra,Herv√©J√©gou,JulienMairal,PiotrBojanowski,andArmand
Joulin.Emergingpropertiesinself-supervisedvisiontransformers.InICCV,2021.1,3,4,6,15,18,20,21
[6] XianjieChen,RoozbehMottaghi,XiaobaiLiu,SanjaFidler,RaquelUrtasun,andAlanYuille. Detectwhat
youcan:Detectingandrepresentingobjectsusingholisticmodelsandbodyparts. InCVPR,2014. 3
[7] JiaDeng,WeiDong,RichardSocher,Li-JiaLi,KaiLi,andLiFei-Fei.ImageNet:Alarge-scalehierarchical
imagedatabase. InCVPR,2009. 4,6,15,20
[8] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas
Unterthiner,MostafaDehghani,MatthiasMinderer,GeorgHeigold,SylvainGelly,JakobUszkoreit,and
NeilHoulsby. Animageisworth16x16words: Transformersforimagerecognitionatscale. InICLR,
2021. 4,20
[9] PedroFFelzenszwalb,RossBGirshick,DavidMcAllester,andDevaRamanan. Objectdetectionwith
discriminativelytrainedpart-basedmodels. TPAMI,32(9):1627‚Äì1645,2009. 3
[10] GeorgiaGkioxari,RossGirshick,andJitendraMalik. Actionsandattributesfromwholesandparts. In
ICCV,2015. 3
[11] AgrimGupta,PiotrDollar,andRossGirshick. LVIS:Adatasetforlargevocabularyinstancesegmentation.
InCVPR,2019. 3,7,8,9,14,19
[12] TrevorHastie,RobertTibshirani,JeromeHFriedman,andJeromeHFriedman. Theelementsofstatistical
learning:datamining,inference,andprediction. Springer,2009. 4
[13] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun. Deepresiduallearningforimagerecognition.
InCVPR,2016. 6,21
[14] KaimingHe,GeorgiaGkioxari,PiotrDoll√°r,andRossGirshick. MaskR-CNN. InICCV,2017. 16
[15] KaimingHe,XinleiChen,SainingXie,YanghaoLi,PiotrDoll√°r,andRossGirshick.Maskedautoencoders
arescalablevisionlearners. InCVPR,2022. 1
[16] Tarun Kalluri, Weiyao Wang, Heng Wang, Manmohan Chandraker, Lorenzo Torresani, and Du Tran.
Open-world instance segmentation: Top-down learning with bottom-up supervision. arXiv preprint
arXiv:2303.05503,2023. 15
[17] DahunKim,Tsung-YiLin,AneliaAngelova,InSoKweon,andWeichengKuo. Learningopen-world
objectproposalswithoutlearningtoclassify. IEEERoboticsandAutomationLetters,7(2):5453‚Äì5460,
2022. 15
11[18] AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,LauraGustafson,TeteXiao,
SpencerWhitehead,AlexanderC.Berg,Wan-YenLo,PiotrDoll√°r,andRossGirshick. Segmentanything.
InICCV,2023. 1,3,7,8,14,17,18,19,21,23
[19] PhilippKr√§henb√ºhlandVladlenKoltun. EfficientinferenceinfullyconnectedCRFswithGaussianedge
potentials. InNeurIPS,2011. 4,20
[20] Tsung-YiLin,MichaelMaire,SergeBelongie,JamesHays,PietroPerona,DevaRamanan,PiotrDoll√°r,
andCLawrenceZitnick. MicrosoftCOCO:Commonobjectsincontext. InECCV,2014. 2,6,7,9,14,15,
17,20,21
[21] YangLiu,IdilEsenZulfikar,JonathonLuiten,AchalDave,DevaRamanan,BastianLeibe,Aljo≈°aO≈°ep,
andLauraLeal-Taix√©. Openingupopenworldtracking. InCVPR,2022. 15
[22] Yen-ChengLiu,Chih-YaoMa,ZijianHe,Chia-WenKuo,KanChen,PeizhaoZhang,BichenWu,Zsolt
Kira,andPeterVajda. Unbiasedteacherforsemi-supervisedobjectdetection. InICLR,2021. 2,5,21
[23] StephenEPalmer.Hierarchicalstructureinperceptualrepresentation.Cognitivepsychology,9(4):441‚Äì474,
1977. 1
[24] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen,ZemingLin,NataliaGimelshein,LucaAntiga,AlbanDesmaison,AndreasK√∂pf,EdwardZ.Yang,
ZachDeVito,MartinRaison,AlykhanTejani,SasankChilamkurthy,BenoitSteiner,LuFang,JunjieBai,
andSoumithChintala. Pytorch:Animperativestyle,high-performancedeeplearninglibrary. InNeurIPS,
2019. 21
[25] JeanPiaget. Theconstructionofrealityinthechild. JournalofConsultingPsychology,19(1):77,1955. 1
[26] ChristophSchuhmann,RomainBeaumont,RichardVencu,CadeWGordon,RossWightman,Mehdi
Cherti,TheoCoombes,AarushKatta,ClaytonMullis,MitchellWortsman,PatrickSchramowski,SrivatsaR
Kundurthy,KatherineCrowson,LudwigSchmidt,RobertKaczmarczyk,andJeniaJitsev. LAION-5B:
Anopenlarge-scaledatasetfortrainingnextgenerationimage-textmodels. InNeurIPSDatasetsand
BenchmarksTrack,2022. 1
[27] ShuaiShao,ZemingLi,TianyuanZhang,ChaoPeng,GangYu,XiangyuZhang,JingLi,andJianSun.
Objects365:Alarge-scale,high-qualitydatasetforobjectdetection. InICCV,2019. 7,8,17,19,21,22
[28] JianboShiandJitendraMalik. Normalizedcutsandimagesegmentation. TPAMI,22(8):888‚Äì905,2000. 3
[29] OrianeSim√©oni,GillesPuy,HuyVVo,SimonRoburin,SpyrosGidaris,AndreiBursuc,PatrickP√©rez,
RenaudMarlet,andJeanPonce. Localizingobjectswithself-supervisedtransformersandnolabels. In
BMVC,2021. 3
[30] OrianeSim√©oni,Chlo√©Sekkat,GillesPuy,Anton√≠nVobecky`,√âloiZablocki,andPatrickP√©rez. Unsuper-
visedobjectlocalization:Observingthebackgroundtodiscoverobjects. InCVPR,2023. 3
[31] AnttiTarvainenandHarriValpola. Meanteachersarebetterrolemodels:Weight-averagedconsistency
targetsimprovesemi-superviseddeeplearningresults. InNeurIPS,2017. 2,5
[32] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,≈Åukasz
Kaiser,andIlliaPolosukhin. Attentionisallyouneed. InNeurIPS,2017. 4
[33] HuyVVo,FrancisBach,MinsuCho,KaiHan,YannLeCun,PatrickP√©rez,andJeanPonce. Unsupervised
imagematchingandobjectdiscoveryasoptimization. InCVPR,2019. 3
[34] HuyVVo,PatrickP√©rez,andJeanPonce. Towardunsupervised,multi-objectdiscoveryinlarge-scale
imagecollections. InECCV,2020. 3
[35] VanHuyVo,ElenaSizikova,CordeliaSchmid,PatrickP√©rez,andJeanPonce. Large-scaleunsupervised
objectdiscovery. InNeurIPS,2021. 3
[36] WeiyaoWang,MattFeiszli,HengWang,JitendraMalik,andDuTran. Open-worldinstancesegmentation:
Exploitingpseudogroundtruthfromlearnedpairwiseaffinity. InCVPR,2022. 15
[37] XinlongWang,ZhidingYu,ShaliniDeMello,JanKautz,AnimaAnandkumar,ChunhuaShen,andJoseM
Alvarez. FreeSOLO:Learningtosegmentobjectswithoutannotations. InCVPR,2022. 1,3,5,7,8
[38] Xudong Wang, Rohit Girdhar, Stella X Yu, and Ishan Misra. Cut and learn for unsupervised object
detectionandinstancesegmentation. InCVPR,2023. 1,2,3,4,5,6,7,8,9,10,14,15,16,20,21
12[39] Yangtao Wang, Xi Shen, Yuan Yuan, Yuming Du, Maomao Li, Shell Xu Hu, James L Crowley, and
Dominique Vaufreydaz. TokenCut: Segmenting objects in images and videos with self-supervised
transformerandnormalizedcut. InCVPR,2022. 3,5,7
[40] YuxinWu,AlexanderKirillov,FranciscoMassa,Wan-YenLo,andRossGirshick. Detectron2. https:
//github.com/facebookresearch/detectron2,2019. 21
13Appendix
Inthisappendix,SectionAfirstexplainsthedeficiencyoftraditionalMS-COCOAPevaluationin
theself-supervisedsettingandreasonsforadoptingARonmoreclass-extensively-annotateddatasets
likeLVIS.SectionsBandCaddresspotentialconcernsaboutunfaircomparisonwithCutLER[38]
regardingthetrainingdataandthedetectorarchitecture. SectionsD,E,andFpresentadditional
ablationstudyregardingthethresholdchoice,computationcost,andpatchsizeoftheViTbackbone
inourhierarchicaladaptiveclusteringalgorithm. SectionGstudiesdifferentbehaviorsofSAMand
ourproposedHASSODindetectingpartsofobjects. SectionsHandKpresentmorecomprehensive
quantitativeandqualitativeevaluationresultsforcompleteness. SectionIprovidesthefailurecases
ofHASSODandanalyzesitscurrentlimitations. SectionJdescribesthedetailedhyper-parameter
andimplementationsetup.
A DeficiencyofMS-COCOAPEvaluationinSelf-SupervisedObject
Detection
Traditionally, the Average Precision (AP) metric on the MS-COCO dataset [20] has been a gold
standardforassessingtheperformanceofsupervised objectdetectionandinstancesegmentation
models,whicharetrainedandevaluatedonafixedsetofobjectcategoriespre-definedbyhuman
annotators. However,wefindthismetricmisleadinginthecontextofself-supervisedobjectdetection,
whereclasslabelsarenotavailabletothemodelandclass-agnosticpredictionsarenecessary. Inthis
work,weadvocateforevaluatingAverageRecall(AR)ondatasetswithextensiveclassannotations
(e.g., LVIS [11]) as a more reliable metric for comparing different methods. In this section, we
discusstheinherentdeficienciesofMS-COCOAPevaluationusinganillustrativeexample.
To demonstrate this problem objectively, we compare two previous methods, CutLER [38] and
SAM[18]. Bothmodelsfunctionasclass-agnosticobjectdetectors,butSAM,trainedwithhuman
supervision,evidentlyoutperformsCutLERintermsofdetectingandsegmentingobjects,asdepicted
inFigure6. Surprisingly,whenevaluatedonMS-COCOannotations,SAMattainsamere6.7AP,
whichisapproximatelyhalfofCutLER‚Äôs12.3AP.Inthiscase,theAPmetriciscontradictingwith
theobservedperformanceofthetwomodelsintermsofaccuratelydetectingandsegmentingasmany
objectsaspossible.
Input CutLER SAM
12.3 AP on MS-COCO 6.7 AP on MS-COCO
Figure 6: MS-COCO average precision (AP) evaluation may not accurately reflect the perfor-
mance of class-agnostic object detectors. We compare two previous class-agnostic object detec-
tion/segmentationmodels,CutLER[38]andSAM[18]. DespiteSAM,asupervisedmodel,detecting
moreobjectswithsuperiorlocalizationthanCutLER,itachievesonlyhalftheAPofCutLER.
TheprimaryreasonforthisdiscrepancyliesintheannotationsofMS-COCO.MS-COCOlabelsonly
80objectcategories,andmodelpredictionsareconsideredastruepositivesonlyiftheyfallwithin
14thesecategories. Consequently,correctpredictionsforobjectsoutsidethe80categoriesareunjustly
deemedfalsepositivesandpenalizedbytheAPmetric,contradictingtheobjectiveofclass-agnostic
objectdetectionandrevealingtheshortcomingsofAPevaluation.
To correct these deficiencies in the evaluation metric, we need two changes: 1) Adopt a dataset
withcomprehensiveannotationsthatincludeasmanyobjectcategoriesaspossible. Ifwesubstitute
MS-COCOground-truthannotationswithLVIS,whichlabelsover1,200objectcategoriesdespite
usingthesameimages,theAPcomparisonisreversed: CutLERscores4.5APonLVIS,whileSAM
attains a higher 6.1 AP. 2) Replace AP with the AR metric. Even with LVIS annotations, not all
objectcategoriesarelabeledineveryimage,resultingincertainvalidobjectdetectionpredictionsstill
beingpenalized. Conversely,ARdoesnotpenalizesuchpredictionsandexhibitsamorepronounced
differencebetweenCutLERandSAM(23.6ARvs.42.7AR).
Insummary,weadvocateforARonclass-extensively-annotateddatasetsastheprimarycomparison
metric,whichcanmoreaccuratelyreflecttheactualperformanceofclass-agnosticobjectdetectors
withreducedbias. Thischoiceofmetricalignswithpriorworkonopen-worlddetection[1,17],
segmentation[16,36],andtracking[21]aswell.
B ComparisonofCutLERandHASSODwithEqualTrainingData
Asdescribedinthemainpaper,HASSODutilizesaResNet-50backboneinitializedwithDINO[5]
weights pre-trained in a self-supervised manner on ImageNet [7], while subsequent training is
conductedonMS-COCO[20]images. WechooseMS-COCOforitscompactsizeandrichnessin
objectsperimage.Duetolimitedcomputationresources,weareunabletoperformHASSODtraining
onImageNet,andweleavelarge-scaletrainingasoneinterestingfuturedirection. Thisdistinctionin
thetrainingdatasetmayleadtoconcernsregardingthefairnessofcomparisonwithpriorwork,such
asCutLER[38],whichtrainsexclusivelyonImageNetdata. However,itisimportanttonotethat
usingbothImageNetandMS-COCOdatainHASSODdoesnotgrantHASSODadditionalbenefit
comparedwithCutLERfortwomainreasons: 1)Thetwodatasetsareleveragedinseparatestages
andnotinablendedmanner. Specifically,ImageNetdataareonlyusedintheDINOpre-training
stage,whileMS-COCOisemployedfordetectortraining. 2)ImageNetcontainsapproximately5√ó
asmanyimagesasMS-COCO.Thus,ifImageNetisemployedinthedetectortrainingstage,asisthe
casewithCutLER,thiswouldactuallyleadtoastrongerdetector.
Table4: ComparisonbetweenCutLER[38]andHASSODconcerningthetrainingimagedataset.
AlthoughbothCutLERandHASSODleverageDINO[5]weightspre-trainedonImageNet,employ-
ingMS-COCOimagesinthedetectortrainingstagedoesnotleadtosuperiorperformance. CutLER
trainedonImageNetsurpassesCutLERtrainedonMS-COCOacrossallmetrics. Simultaneously,
HASSODoutperformsbothCutLERmodels,despiteusingMS-COCOtrainingdataandrequiring
fewertrainingiterations.
Training Training Mask
Method Images Iterations AR AR AR AR AP
S M L
CutLER[38] MS-COCO[20] 160,000 17.3 6.2 24.2 46.1 5.8
CutLER[38] ImageNet[7] 160,000 18.8 7.2 27.6 46.6 6.2
HASSOD(Ours) MS-COCO[20] 40,000 22.4 11.3 32.9 45.0 6.3
Inordertoaddresstheseconcernsmoreeffectivelyandensureanequalusageoftrainingdata,we
conductanadditionalexperiment. Specifically,wetrainaCascadeMaskR-CNN[4]detectorusing
theCutLERapproachonMS-COCOimagesforoneround(160,000iterations),withtheResNet-50
backboneinitializedwithDINOpre-trainedweights. WeadoptCutLER‚Äôsoriginalimplementation,
withthesolemodificationbeingtheuseofMS-COCOimagesfortraining. Wecomparethismodel
with a CutLER model trained on ImageNet for one round and our HASSOD model trained on
MS-COCO. The evaluation is conducted against MS-COCO+LVIS annotations, as described in
Section4.5. TheresultsarepresentedinTable4.
By comparing the two CutLER models trained with MS-COCO and ImageNet, we observe that
utilizingdistinctdatasetsforbackbonepre-traininganddetectortrainingdoesnotuniversallyimprove
performance.TheCutLERmodel,exclusivelytrainedonImageNet,surpassesitscounterpartthatuses
15ImageNetforDINOpre-trainingandMS-COCOfordetectortraining,exhibitinggainsof1.5Mask
ARand0.4MaskAP.Meanwhile,HASSOD,despitebeingtrainedonthesmallerMS-COCOdataset
andforashorterduration,outperformsCutLERby3.6MaskAR.Thisremarkableperformanceis
attributedtoHASSOD‚Äôscomprehensiveobjectcoverageinimagesanditsefficientusageoftraining
data.
C AdditionalResultsonMaskR-CNN
InHASSOD,wetrainaCascadeMaskR-CNN[4]objectdetectionandinstancesegmentationmodel.
WechoosethisarchitecturefollowingCutLER[38]andweensureafaircomparisonwiththisprior
work. Infact,HASSODcanbeappliedondifferentdetectorarchitectures. Asanexample,wealso
trainaMaskR-CNN[14]andcompareitsLVISperformancewithCutLERinTable5. Withthe
samedetectorarchitecture,HASSODproducesabetterdetectorthanCutLER.Moreimpressively,
our Mask R-CNN (weaker architecture) outperforms CutLER‚Äôs Cascade Mask R-CNN (stronger
architecture)onLVIS,highlightingtheadvantageofourapproach.
Table5: ComparisonbetweenCutLER[38]andHASSODwithdifferentdetectorarchitectureson
theLVISdataset. Whentrainingmodelsofthesamearchitecture,HASSODoutperformsCutLER
(row1vs.2,row3vs.4). Notably,HASSODhasastrongerARevenwithaweakerarchitecture(row
2vs.3)ascomparedwithCutLER.
Box Mask
Architecture Method AR AR AR AR AP AR AR AR AR AP
S M L S M L
CutLER[38] 20.7 10.4 33.3 52.0 4.1 18.5 9.6 29.1 44.9 3.4
MaskR-CNN
HASSOD(Ours) 23.8 13.5 38.3 50.9 4.3 21.5 11.8 35.1 46.6 4.1
CutLER[38] 23.6 13.1 36.2 55.6 4.5 20.2 11.3 31.1 46.2 3.6
Cas.MaskR-CNN
HASSOD(Ours) 26.9 15.6 42.2 56.9 4.9 22.5 12.7 36.1 47.8 4.2
D ChoosingThresholdsforHierarchicalAdaptiveClustering
Whendeterminingthemergingthresholds{Œ∏merge},wemainlyconsiderourcomputationalconstraints
i
andempiricalobservations. Thedecisionofmergingthresholdsisnot madebasedonvalidation
performance(Table2),ensuringthatHASSODisfullyself-supervised.
100
80
60
40
20
0
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
Merging threshold
Figure7: Relationbetweenthenumberofpseudo-labelsperimageafterpost-processing(y-axis)
andthemergingthresholdŒ∏merge(x-axis). WhenŒ∏merge ‚â•0.5,thenumberofpseudo-labeledmasks
growsrapidly. Empirically,wefindthatwhenthenumberofmasksperimageexceeds20,generating,
loading,andtransformingsuchpseudo-labelsbecomesamajorbottleneckinHASSOD.Therefore,we
choosethreethresholds{Œ∏merge}={0.1,0.2,0.4},mainlyguidedbyacomputationalconsideration.
i
16
egami
rep
slebal-oduesp
fo
rebmuNGuidancebynumberofpseudo-masks. Ourchoicefor{Œ∏merge}isprimarilyguidedbythenumber
i
ofpseudo-labelmasksproducedperimage. Figure7showstherelationshipbetweenthenumber
ofmasksperimageanddifferentthresholds. WhenŒ∏merge ‚â• 0.5,thenumberofmasksperimage
escalatesrapidly. Thissteepincreaseincurssignificantcomputationalcosts,bothduringtheinitial
generationofpseudo-labelsandthesubsequentdataloadingandpre-processingproceduresduring
modeltraining.Tostrikeabalancebetweencomputationalefficiencyandthedesiredmaskgranularity,
thresholdsof{Œ∏merge}={0.1,0.2,0.4}arechosen.
i
Table6: Generalizabilityofthemergingthresholds{Œ∏merge}. Withthesamemergingthreshold,the
i
numberofgeneratedpseudo-labelsisnotsignificantlychangingacrossdifferentimagedatasets.
Numberofpseudo-labelsperimage
Œ∏merge
MS-COCO[20] Objects365[27] SA-1B[18]
0.1 2.58 3.49 2.91
0.2 4.20 5.78 4.88
0.4 11.61 12.15 12.70
Thresholdgeneralizationacrossdatasets. Anothernoteworthyobservationisthegeneralizabilityof
thesethresholdsacrossvariousdatasets.InTable6,wepresentthenumberofgeneratedpseudo-labels
perimageonthreedatasets. WiththemergingthresholdŒ∏mergefixed,thenumberofgeneratedlabels
is relatively stable, regardless of the source image dataset. Therefore, our pre-set thresholds are
generalizable and require no further tuning when transferred to other datasets. Meanwhile, our
detectionmodelwastrainedonMS-COCOimageswithpseudo-labelsgeneratedusingourpre-set
{Œ∏merge},andcouldgeneralizewelltootherdatasetsinazero-shotmanner,asshowninTable1. This
i
factshowsthatthethresholds{Œ∏merge}areeffectiveregardlessofevaluationdatasets.
i
E ComputationalCostsinHierarchicalAdaptiveClustering
Weadoptthehierarchicaladaptiveclusteringstrategytogenerateourinitialpseudo-labels. Inthis
section,weprovideadditionaldetailsregardingcomputationcostsinthisprocedure.
AsshowninFigure3,thehierarchicaladaptiveclusteringcontainsfoursteps‚Äúmerge,‚Äù‚Äúpost-process,‚Äù
‚Äúensemble,‚Äùand‚Äúsplit.‚Äù Amongthem,the‚Äúmerge‚Äùstepaccountsforthemajorcomputationcosts.
Wecananalyzeitstimecomplexity: Supposewehavenpatchesinthebeginning,thenthereare
atmostnmergingstepsbeforestopping. Eachmergingsteprequiresretrievingthemostsimilar
pairofadjacentregions. ThecollectionofadjacentpairshassizeatmostO(n),andeachoperation
requirestimeO(logn)ifthiscollectionisorganizedasabalancedbinarytree.Therefore,themerging
processhastimecomplexityO(nlogn). Inourpractice,theinputimagehasresolution480√ó480,
son= 480 √ó 480 =3,600. Thistimecomplexityisaffordable.
8 8
Moreconcretely,welistthetimecostsinthehierarchicaladaptiveclusteringonourcomputation
platform in Table 7. Since the procedure is learning-free, we can parallelize the processing of
imagesusingmorethanoneworker. Onourcomputationnodesequippedwith4NVIDIAA100
GPUs,wecanreducetheprocessingtimeto1.59sec/image. With4suchnodes,wecancomplete
thepseudo-labelgenerationforMS-COCOtrainandunlabeledsplits(0.24millionimages)in
1.59√ó0.24√ó106 ‚âà1day.
4√ó86400
Table7: Timecostsinthestepsofthehierarchicaladaptiveclustering. Notably,withmultipleparallel
workers,wecanreducethetotalprocessingtimeofMS-COCO[20]imagestooneday.
TimeCost ParallelizedCost
Step Workers
(sec/image) (sec/image)
MergeandPost-Process 11.7 8 1.46
EnsembleandSplit 2.1 16 0.13
Total 13.8 - 1.59
17F ImpactofPatchSizeinHierarchicalAdaptiveClustering
WeusetheDINO[5]pre-trainedViT-B/8backbonetogeneratetheinitialpseudo-labelsthrough
our hierarchical adaptive clustering. We observe that the small patch size 8√ó8 leads to better
pseudo-labelquality. InTable8,wecomparethemaskqualityofpseudo-labelsgeneratedbyViT-B/8
(patch size 8√ó8) vs. ViT-B/16 (patch size 16√ó16). For a fair comparison, we use 480√ó480
input resolution for ViT-B/8 and 960√ó960 for ViT-B/16, so that they have the same number of
initialpatches. WiththesamemergingthresholdŒ∏merge,ViT-B/16leadstoslightlyfewerlabelsper
image,andthequalityissignificantlyworsethanViT-B/8,especiallyforsmallandmediumobjects.
Therefore, we apply ViT-B/8 in our experiments for its localized visual features and subsequent
high-qualitypseudo-labels.
Table8:ComparisonbetweenDINOViTbackboneswithdifferentpatchsizes8√ó8and16√ó16. The
backbonewiththesmallerpatchsizeleadstohigher-qualityinitialpseudo-labelsinthehierarchical
adaptiveclusteringprocedure.
DINO Labels Mask
Œ∏merge
Backbone perImg AR AR AR AR AP
S M L
0.1 2.58 4.1 0.6 5.1 15.6 1.8
ViT-B/8 0.2 4.20 5.3 0.9 7.0 18.4 1.8
0.4 11.61 7.8 1.7 12.1 22.1 1.3
0.1 1.97 3.0 0.3 2.3 14.6 1.1
ViT-B/16 0.2 3.19 3.8 0.4 3.3 17.4 1.2
0.4 10.15 5.7 0.9 6.6 21.7 1.3
G DifferentBehaviorsofSAMandHASSODinObjectPartDetection
SegmentAnythingModel(SAM)[18],asupervisedsegmentationmodel,hasdemonstrateditsability
increatinghigh-quality,fine-grainedsegmentationofimages. Directlycomparingtheperformance
betweenSAMandHASSODwouldbeunbalanced,consideringSAMrequiresextensivehuman-
labeledimagesfortraining,whileHASSODoperatesentirelyunderself-supervision. Despitethis,it
remainsintriguingtounderstandtheirdifferentbehaviors. Inthissection,wedelveintoaqualitative
comparisonbetweenSAMandourproposedHASSODapproach,payingparticularattentiontotheir
respectiveabilitiestodetectconstituentpartsofwholeobjects. Figure8presentsavisualizationfor
thiscomparison.
BothSAMandHASSODcanperformfine-grainedsegmentationwithincomplexscenes,successfully
detectingindividualobjectpartsthatconstituteawholeentity. However,acleardistinctionarisesin
theirrespectiveapproachestowardsthesegmentationoftheseobjectparts.Forscenesinwhichobjects
followagridpattern,wherethewholeentityispartitionedbyregularboundarylinesintosemantically
similarpieces,SAMtendstoperceiveeachgridasadistinctobject. Conversely,HASSODadheresto
aholisticperspectiveforsuchcases,groupingthegridpartstogetherevenatthesubpartlevel,dueto
theirsemanticallyanalogousfeatures.
Inparticular,HASSODexcelsatdistinguishingobjectpartsthatcontaindifferentcontentswithin
wholeobjects. ThisskillofHASSODisespeciallyadvantageousincertainreal-worldapplications.
Forexample,inmedicalimaging,HASSOD‚Äôsfine-grainedsegmentationcanpotentiallyassistin
identifyingandseparatingdifferenttissuesoranatomicalstructureswithinascan. Additionally,inthe
manufacturingindustry,HASSODcouldbeusedinqualitycontroltocheckandcompareindividual
componentsofanassembledproduct. WhilebothsegmentationstrategiesofSAMandHASSODare
valid,HASSOD‚Äôsuniqueabilitytodistinguishsemanticallydifferentpartswithinobjectsprovides
distinctadvantagesinawiderangeofpracticalscenarios.Comprehensivelyquantifyingandanalyzing
such an ability is crucial for advancement of self-supervised object detection and segmentation
approaches,andweconsideritasanimportantfuturedirection.
18Input SAM HASSOD (Ours) HASSOD (Ours)
Whole Objects Whole + Part + Subpart
Figure8: AnalysisofdifferentbehaviorsinobjectpartdetectionbetweensupervisedSAM[18]and
self-supervisedHASSODthroughqualitativevisualization. Whilebothmodelsgeneratefine-grained
segmentation, they exhibit distinct preferences concerning object parts. SAM inclines towards
separatingobjectsfollowingagridpattern(e.g.,comforters,keyboards,tiles),whereasHASSOD
discriminatesobjectsintosemanticallydiverseparts(e.g.,eyesandbeardofacat,handleandbutton
ofacabinet).
H AdditionalEvaluationResultsforCompleteness
AsanadditiontoTable1inthemainpaper,wepresentacomprehensiveevaluationofHASSOD
ontheObjects365[27], LVIS[11], andSA-1B[18]datasetsinTable9. Forarobustmeasureof
performance, we incorporate the standard deviation, estimated from three independently trained
models.
Table9: ComprehensiveevaluationresultsofHASSODacrossthreedatasets. Wesetthemaximum
number of predictions per image to 1,000. The number superscript on AR (e.g., AR10) denotes
thenumberofmostconfidentpredictionstakenintoaccountwhencomputingAR.Thesubscript
onAP(e.g.,AP )representstheIntersection-over-Union(IoU)thresholdutilizedwhenmatching
50
predictionswithgroundtruthlabels. Size-specificmetricsforsmall,medium,andlargeobjectsare
indicatedbythesubscripts , ,and ,respectively. Weincludethestandarddeviation,estimated
S M L
fromthreeindependentruns.
Dataset AR10 AR100 AR1000 ARS ARM ARL AP AP50 AP75 APS APM APL
Box(ObjectDetection)
15.20 36.63 39.03 21.40 40.43 52.10 10.97 20.33 10.27 2.90 10.37 19.47
Objects365[27]
¬±0.10 ¬±0.06 ¬±0.06 ¬±0.10 ¬±0.12 ¬±0.17 ¬±0.15 ¬±0.31 ¬±0.15 ¬±0.10 ¬±0.25 ¬±0.25
10.58 25.01 26.87 15.64 42.22 56.90 4.94 9.03 4.75 2.82 7.90 12.19
LVIS[11]
¬±0.07 ¬±0.02 ¬±0.03 ¬±0.05 ¬±0.08 ¬±0.17 ¬±0.09 ¬±0.09 ¬±0.10 ¬±0.01 ¬±0.14 ¬±0.20
5.52 23.92 29.02 13.34 25.12 43.79 15.47 26.20 15.90 5.39 15.06 21.81
SA-1B[18]
¬±0.02 ¬±0.03 ¬±0.18 ¬±0.27 ¬±0.21 ¬±0.12 ¬±0.08 ¬±0.09 ¬±0.03 ¬±0.06 ¬±0.13 ¬±0.08
Mask(InstanceSegmentation)
9.69 21.11 22.50 12.68 36.14 47.79 4.21 7.99 3.95 1.88 6.96 13.67
LVIS[11]
¬±0.06 ¬±0.05 ¬±0.01 ¬±0.01 ¬±0.11 ¬±0.17 ¬±0.20 ¬±0.25 ¬±0.24 ¬±0.19 ¬±0.21 ¬±0.18
5.27 21.62 25.99 12.90 22.76 38.33 13.85 24.78 13.67 4.09 13.45 20.36
SA-1B[18]
¬±0.01 ¬±0.07 ¬±0.22 ¬±0.37 ¬±0.24 ¬±0.21 ¬±0.09 ¬±0.08 ¬±0.11 ¬±0.04 ¬±0.10 ¬±0.07
19I LimitationsandBroaderImpacts
Limitations. Duetotheself-supervisednatureofHASSOD,thelearnedobjecthierarchicallevels
maynotbeperfectlyalignedwithhumanperception. Thismismatchmayleadtoover-segmentor
under-segmentofobjectsinreal-worldapplications.
Input CutLER HASSOD (Ours)
Figure9: FailurecasesofHASSOD.Top: Overlappingandsimilarobjectsarehardtodistinguish.
Middle: Thewholeobjectcomprisingdiversepartsisnotidentified. Bottom: Textcontentsarenot
preciselylocalized.
We observe that HASSOD performs unsatisfactorily in certain scenes due to this lack of human
supervision. Figure 9 provides a visualization of the failure cases. In the first row, HASSOD
mistakenlytreatsthelowerpartsofthetwoplayersasasinglecoherentobject. Duetotheirsimilar
color and texture, multiple overlapping instances of the same class can sometimes be perceived
as one object. In the second row, HASSOD fails to predict a mask that encompasses the entire
motorcycle. Thisobjectconsistsofhighlyheterogeneousparts,makingitchallengingtorecognize
themascomponentsofasingleentity.Inthethirdrow,HASSODfailstodetectthetext‚ÄúKoelnmesse,‚Äù
andtheboundariesforothertextarenotclear. Wealsoobservethatsucherrorsarenotuniqueto
HASSOD;theyappearinpriorself-supervisedobjectdetectionmethodslikeCutLERaswell. We
believethatfurtherhumansupervisionwouldbenecessaryforcorrectingthesemistakes.
Broader impacts. Detecting object parts with self-supervision may be beneficial to real-world
applicationsincludingroboticmanipulationandinspection. Asageneralobjectdetectionmethod,we
sharerisksassociatedwithapplyingrecognitionmodelssuchasabuseofsurveillancesystems.
J Hyper-ParametersandImplementationDetails
In the initial pseudo-label generation process, we use a frozen ViT-B/8 model [8] pre-trained on
unlabeledImageNet[7]byDINO[5],aself-supervisedrepresentationlearningmethod,toextract
visual features of train and unlabeled images in MS-COCO [20]. Following prior work Cut-
LER[38],weresizetheresolutionofeachimageto480√ó480,leadingto60√ó60patchesasinitial
regions. ThemergingprocessstopsatthreethresholdsŒ∏merge =0.4,Œ∏merge =0.2,Œ∏merge =0.1,and
1 2 3
resultsfromthesethreethresholdsareensembledafterpost-processing. Thepost-processingsteps
includeConditionalRandomField(CRF)[19]andfillingtheholesineachmask. Wealsofilterout
low-qualitymasksthat1)haveanIntersection-over-Union(IoU)smallerthan0.5beforeandafter
CRF,2)aresmallerthan100pixels,or3)containmorethantwocornersoftheimage(whicharelikely
20background). Thesepost-processingstepsarealsousedinpriorworkincludingCutLER[38]. After
ensemblingresultsfromthethreethresholds{Œ∏merge}3 ,weidentifythehierarchicallevelsofeach
i i=1
objectmaskbasedonthecoveragerelationanalysis. ThecoveragethresholdissettoŒ∏cover%=90%.
Inthedetectortrainingstage,wetrainaCascadeMaskR-CNN[4]withaResNet-50[13]backbone
onthesameMS-COCO[20]images. ThebackboneisinitializedfromDINO[5]self-supervised
pre-training. Ourhyper-parametersettingforMeanTeachermostlyfollowsthepracticeofUnbiased
Teacher[22]. Thewholetrainingprocessstartswitha‚Äúburn-in‚Äùstage, duringwhichthestudent
modelisonlytrainedontheinitialpseudo-labelswithafixedlearningrate0.01andfixedlossweights.
Aftertheburn-instage,theteachermodelisintroduced,andwegraduallyadjustthelearningrate
from0.01to0,thelossweightinthelabel-to-studentbranchfrom1.0to0.0,andthelossweightin
theteacher-to-studentbranchfrom2.0to3.0,allfollowingacosineschedule. Thewholetraining
processspans40,000iterationswithabatchsizeof16images. Thetrainingisperformedon4√ó
NVIDIAA100GPUs. OurcodeisdevelopedbasedonPyTorch[24]andDetectron2[40].
K AdditionalQualitativeResults
In this section, we present visualization of detection results by CutLER [38] and HASSOD on
Objects365[27]inFigure10andSA-1B[18]inFigure11(seenextpages). Qualitativeresultson
LVIShasbeenincludedinthemainpaper,Figure5.
21Input CutLER HASSOD (Ours) HASSOD (Ours)
Whole Objects Whole + Part + Subpart
Figure10: QualitativeresultsonObjects365[27]. Ineachrow,weshowdetectionresultsofprior
state-of-the-artself-supervisedobjectdetectorCutLER,wholeobjectspredictedbyHASSOD,and
allobjectpredictedbyHASSOD.
22Input CutLER HASSOD (Ours) HASSOD (Ours)
Whole Objects Whole + Part + Subpart
Figure 11: Qualitative results on SA-1B [18]. In each row, we show detection results of prior
state-of-the-artself-supervisedobjectdetectorCutLER,wholeobjectspredictedbyHASSOD,and
allobjectpredictedbyHASSOD.
23