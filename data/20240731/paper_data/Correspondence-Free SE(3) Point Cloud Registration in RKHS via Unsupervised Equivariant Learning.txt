Correspondence-Free SE(3) Point Cloud
Registration in RKHS via Unsupervised
Equivariant Learning
Ray Zhang1, Zheming Zhou2, Min Sun2 Omid Ghasemalizadeh2, Cheng-Hao
Kuo2, Ryan M. Eustice1, Maani Ghaffari1, and Arnie Sen2
1 University of Michigan, Ann Arbor MI 48109, USA
{rzh,eustice,maanigj}@umich.edu
2 Amazon Lab126, Sunnyvale CA 94089, USA
{zhemiz,minnsun,ghasemal,chkuo,senarnie}@amazon.com
Abstract. This paper introduces a robust unsupervised SE(3) point
cloud registration method that operates without requiring point corre-
spondences. The method frames point clouds as functions in a repro-
ducing kernel Hilbert space (RKHS), leveraging SE(3)-equivariant fea-
tures for direct feature space registration. A novel RKHS distance met-
ric is proposed, offering reliable performance amidst noise, outliers, and
asymmetrical data. An unsupervised training approach is introduced to
effectively handle limited ground truth data, facilitating adaptation to
realdatasets.Theproposedmethodoutperformsclassicalandsupervised
methods in terms of registration accuracy on both synthetic (Model-
Net40)andreal-world(ETH3D)noisy,outlier-richdatasets.Toourbest
knowledge,thismarksthefirstinstanceofsuccessfulrealRGB-Dodom-
etrydataregistrationusinganequivariantmethod.Thecodeisavailable
at https://sites.google.com/view/eccv24-equivalign.
Keywords: Point Cloud Registration Â· Equivariant Learning Â· Kernel
Method Â· Unsupervised Learning
1 Introduction
Point cloud registration estimates the relative transformation between two sets
of3Dspatialobservations[3,9,34,61,64].Itiscommonlyformulatedasanonlin-
ear optimization problem, with data inputs from varied sensors such as RGB-D
cameras, stereo cameras, and LiDAR. This technique is vital in computer vi-
sion and robotics, especially for applications like visual odometry [29] and 3D
reconstruction [56]. Despite its wide use, point cloud registration encounters
numerous challenges. These include complexities in nonlinear optimization on
Riemannianmanifolds,addressingnon-overlappingobservations,andmitigating
the impact of sensor noise and outliers [42,58]. These challenges stem from two
tightly coupled components in traditional point cloud registration: point repre-
sentationsandcorrespondences.Pointrepresentationreferstotheactualformat
of the point data in the process. Given a representation, point correspondences
are related to the construction of the residuals from point pairings.
4202
luJ
92
]VC.sc[
1v32202.7042:viXra2 R. Zhang et al.
ğ‘ğšğ° ğğ¨ğ¢ğ§ğ­ ğ‚ğ¥ğ¨ğ®ğ ğ’ğ„ğŸ‘ ğ„ğªğ®ğ¢ğ¯.ğ…ğğšğ­ğ®ğ«ğ ğ‘ğğ ğ¢ğ¬ğ­ğ«ğšğ­ğ¢ğ¨ğ§ ğ¯ğ¢ğš ğ…ğ®ğ§ğœğ­ğ¢ğ¨ğ§ğ¬ ğ¢ğ§ ğ‘ğŠğ‡ğ’
: ğ‘¥(cid:3036)âŠ•ğŸ(cid:3561) (cid:3036)
ğ“ ğ’‡
ğ“ğ‘¿ ğ“(ğ‘¿)
Euclidean Equiv. Feature ğ“ğ‘¿ ğ“ğ’ (cid:3009)
Space â„ğŸ‘ Space ğ“
ğ“(ğ’)
ğ“ ğ’‡
ğ“ğ’
Fig.1: Registration in RKHS with Unsupervised Learning of Equivariant
Features: The registration process takes equivariant feature embeddings Ï•(X) and
Ï•(Z) from point clouds X = {x } âŠ‚ R3 and Z = {z } âŠ‚ R3. The point cloud em-
i j
beddings are represented as continuous functions f and f in RKHS, allowing
Ï•(X) Ï•(Z)
fortheutilizationofadistancemetric,âˆ¥f âˆ’hf âˆ¥2 ,fordirectestimationofthe
Ï•(X) Ï•(Z) H
pose h âˆˆ SE(3) in the feature space. In the feature space, each point is denoted as
x âŠ•Ëœf andrepresentsthe3Dcoordinate,naturallyexhibitingtranslationequivariance.
i i
This, combined withËœf , the SO(3) equivariant vectors, achieves SE(3) equivariance.
i
Classical methods represent points using hand-crafted geometric primitives
such as 3D point coordinates [3,47], planes [9], Gaussian mixtures [28,34], and
surfels [8,56]. These representations, typically as low-dimensional vectors, al-
low residuals to be computed directly as Euclidean or Mahalanobis distances.
However, they often struggle with handling noisy and outlier-rich observations
becausetheyrelyonstrictdatacorrespondence.Correctdataassociationischal-
lenging [30], especially when the features are not discriminative enough. Robust
optimization strategies are often needed to minimize these limitations [58].
In contrast, Continuous Visual Odometry (CVO) [13,24,61] introduces a
robust registration framework that represents each point cloud as a continuous
functioninRKHS.Itsiterativeregistrationprocessminimizesthedistanceofthe
twopointcloudfunctionsinRKHSanddoesnâ€™trequirestrictpair-wisepointcor-
respondences. Although it demonstrates superior robustness compared to clas-
sical geometric registration methods, the iterative framework is constrained by
limited expressiveness because the framework is not differentiable.
Advancements in deep neural networks bring differentiable point set regis-
tration by learning point representations that embody geometric invariance [10,
19,31,41,54,60] or equivariance. Invariant-feature-based approaches focus on
learning point-wise local and global features that remain invariant under pose
transformations, leading to semantic-aware data association [27,59]. Once one-
to-onecorrespondencesareestablished,methodslikeRANSACorweightedSVD
areemployedforposeregression[3,22].However,challengespersistinthegener-
alization of invariant learning. During training, excessive data augmentation is
required for sampling transformations in SE(3) and simulating the noise pertur-
bations. Besides, their supervised nature rely on extensive ground truth labels.EquivAlign: Corr.-Free Point Cloud Reg. via Unsupervised Equiv. Learning 3
Equivariant-feature-based methods provide an alternative deep representa-
tion for point clouds [15,17,50,55]. Equivariance is a property for a map such
that given a transformation in the input, the output changes in a predictable
way determined by the input transformation: A function f :X â†’Y is equivari-
ant to a set of transformations G, if for any g âˆˆG, g f(x)=f(g x),âˆ€xâˆˆX .
Y X
Recent strides in equivariant learning have expanded to include SO(3) [18,65],
SE(3)[7,64],andE(n)[45]equivariantnetworks.Comparedtoinvariantfeature-
based methods, these networks relax the need for extensive data augmentation
and thereby leading to improved generalization [64]. While equivariant learning
has shown promise within physics and chemistry, its effectiveness in real-world
robotic tasks like point cloud registration is not well-established. For existing
works,commonpracticesincludetrainingashapeembeddingtore-establishthe
one-to-one correspondence [65], or pooling point-wise equivariant features into
global equivariance features [7,64]. These approaches undermine the complexi-
ties of the noisy and outlier-rich real data where the two input point clouds are
not exactly the same, i.e., the equivariance does not fully hold.
In this work, we introduce an unsupervised feature space registration frame-
work, EquivAlign, as depicted in Figure 2. This framework focuses on learning
point-wise representations that respect the intricate geometric structure in fea-
turespace.Theproposedequivariantkernellearninginterpretstheneuralfeature
embeddings of these point clouds as nonparametric functions within a specified
RKHS. This unique perspective allows for feature space registration without
strict correspondences, further supporting the fully differentiable and unsuper-
vised nature of our proposed method. The contributions are outlined as follows:
1. AniterativeandfullydifferentiableSE(3)registrationframeworkthatfacili-
tates correspondence-free feature space pose regression, enabling robustness
to unseen noise and outliers.
2. Alightweightfeaturerepresentationequivariantto3Drotationsandtransla-
tions via a novel direct sum construction. This construction is modular and
can easily benefit from future advances in equivariant encoders.
3. An unsupervised inner-outer loop training scheme for equivariant feature
learning, incorporating a curriculum learning schedule, demonstrates en-
hanced accuracy compared to classical and supervised baselines and shows
effectiveness in real-world applications.
2 Related Work
2.1 Classical Registration with ICP and GMM
The Iterative Closest Points (ICP) algorithm and its variants use hand-crafted
geometricprimitiveslikecoordinatesandsurfacesasthepointrepresentation[3,
9,35,47]. They alternatively search correspondences with the closest geometric
distances and then obtain pose estimates with the one-to-one data association.
Later works incorporate invariant features into the association for improved ro-
bustness, including color [36,48], intensity [38], and semantic features [37].4 R. Zhang et al.
GaussianMixtureModel(GMM)registrationrepresentspointcloudsasprob-
abilistic densities [6,12,20,21,26,28]. Gaussian mixture models are fitted to
the point cloud inputs, followed by soft data associations. Normal Distribution
Transform(NDT)providesaparticularlyefficientwayofmodelinglocalgeomet-
ric structures through voxelization [4,34].
2.2 Registration with Invariant Feature Matching
Early works like FPFH [44] create histogram-based local invariant features that
areusedinglobalregistration.Deepinvariantfeaturesprovidearicherpointrep-
resentation that assists in feature space correspondence search. Encoders such
as MLP [41], Graphic Neural Networks [54], and KPConv [49] are used for fea-
ture extraction that contribute to permutations invariance and local structures.
In the correspondence step, direct supervision on inlier and outlier matches is
usually required. This class of methods requires one-to-one pairwise matching,
with either RANSAC or weighted SVD. To make the data association robust,
complicatedoutlierrejectiontrainingmechanismsareadopted,assumingenough
labeledtrainingdata.FCGF[11]usesfeaturespacemetriclearningwithnegative
miningtofiltertheoutliers.Itsamplesbothpositiveinliersandnegativeoutliers
soastopreventthefeaturesbeingbiasedonthepositivesamples.Coarse-to-fine
strategies in D3FeatNet [1], DCP [53], Cofinet [59], PREDATOR [27], and Geo-
Transformer [42] enhance match precision by initially focusing on overlapping
areas with superpixel or local patch matching, followed by finer point corre-
spondences. Particularly, PREDATOR [27] and GeoTransformer [42] leverage
Graph Neural Networks (GNN) and cross-attention mechanisms for feature en-
hancementandadopttop-Kneighborsforassociations.Thesedeeplearningtech-
niques,integratedwithrobustoptimizationmethodslikethoseinTeaser++[58],
representasignificantstrideinachievingmoreaccurateandreliablepointcloud
registration.However,theirmethodsrelyoncostlylabelingofgroundtruthand
extensive data augmentation for generalization.
2.3 Equivariant Learning and Applications in Registration
Inthefieldofequivariantlearningandregistration,groupconvolutionextendsto
variousdomains,beginningwithCohenâ€™s[15]workonliftingconvolutionkernels
toSO(2)rotationsforimageprocessing.Thisincludesbothdiscretizingrotations
into finite groups like the dihedral group and continuous sampling with Monte
Carlo[33].For3Ddata,theicosahedronconvolutiontheory[14]andapplications
such as EPN [7] and E2PN [64] leverage finite group discretization in point
cloud analysis. These methods efficiently encode features across various angles
inSO(3).Additionally,tolearntranslation-equivariantfeatures,theyincorporate
traditional convolution layers.
Anotherapproachinvolvescontinuoussteerablefeaturemapsinhigher-order
group representations, demanding significant computational resources for calcu-
lating coefficients [16,23,50]. VectorNeuron [18] offers a more computationally
efficient solution using only type-1 features. Existing equivariant methods with
continuous group representations are mainly applied in physics and chemistry,EquivAlign: Corr.-Free Point Cloud Reg. via Unsupervised Equiv. Learning 5
whereastheirperformanceinrealroboticsdatarequiresfurthertesting.Inspired
by TFN [50] and VectorNeuron [18], we construct a lightweight equivariant rep-
resentation as a direct sum of point coordinates and SO(3) steerable vectors to
enable efficient translation and rotation equivariance.
2.4 Nonparametric Registration in RKHS
Continuous Visual Odometry (CVO) [25] introduces a novel point cloud regis-
trationformulationbyrepresentingcoloredpointcloudsascontinuousfunctions
in an RKHS and aligns these functions using gradient ascent. The optimization
step size is estimated through a fourth-order Taylor expansion. Kernel corre-
lation [51], a specific instance of CVO, focuses solely on geometric registration
and optimizes the loss using a first-order approximation. AdaptiveCVO [32] op-
timizes the kernel length scale, while SemanticCVO [61] integrates hierarchical
semantic information, such as color and semantics, with geometric data.
EquivAlign sets itself apart from the above methods by reformulating the
approachtoensuredifferentiability,thusenablingthelearningoffeaturesmetic-
ulously designed for the registration task. Such features are required to support
iterativeposeupdatesattheinferencestage,underscoringthenecessityforequiv-
ariantfeatures.Incontrast,whileSemanticCVOcanalsoleveragedeepfeatures,
it employs them in a non-differentiable fashion, depending on features derived
from a pretrained network.
3 Problem Formulation
Before delving into the proposed EquivAlign in the following section, we briefly
review the notations and core principles of the problem.
Consider two (finite) collections of points, X = {x ,...,x } âŠ‚ R3, Z =
1 N
{z ,...,z } âŠ‚ R3, with N,M not necessarily being equal. We aim to find an
1 M
elementhâˆˆSE(3),whichminimizesadistancemetricbetweentwopointclouds
X and hZ ={hz }:
j
hË† =arg min d(X,hZ). (1)
hâˆˆSE(3)
An SE(3) group element h = (R,t) with R âˆˆ SO(3),t âˆˆ R3 acting on a point
xâˆˆR3 is given by hx=Rx+t.
Thepointclouds,X andZ,arefirstrepresentedasfunctionsf ,f :R3 â†’I
X Z
thatliveinsomereproducingkernelHilbertspace(RKHS),denotedas(H,âŸ¨Â·,Â·âŸ© ).
H
The group action SE(3)â†·R3 induces an action on the RKHS, SE(3)â†·H, de-
noted as h.f(x) := f(hx). Inspired by this observation, we set h.f := f .
Z hZ
Furthermore, each point might contain pose-invariant information in different
dimensions, such as color or intensity, described by a point in an inner product
space, (I,âŸ¨Â·,Â·âŸ© ). To represent pose-invariant information, we introduce two la-
I
beling functions, l : X â†’ I and l : Z â†’ I for the two point clouds with
X Z
l (hx) = l (x),l (hz) = l (z), respectively. With the kernel formulation [5],
X X Z Z
the point cloud functions are
(cid:88) (cid:88)
f (Â·):= l (x )k(Â·,x ), f (Â·):= l (z )k(Â·,hz ), (2)
X X i i hZ Z j j
xiâˆˆX zjâˆˆZ6 R. Zhang et al.
wherethekernelsaresymmetricandpositivedefinitefunctions.k :R3Ã—R3 â†’R.
To measure the alignment of the two point clouds given an isometry trans-
formation hâˆˆSE(3) that preserves norms, we can use the distance between the
two point cloud functions [13]
d(f ,f )=âˆ¥f âˆ’f âˆ¥2 =âŸ¨f ,f âŸ© +âŸ¨f ,f âŸ© âˆ’2âŸ¨f ,f âŸ© . (3)
X hZ X hZ H X X H Z Z H X hZ H
The distance is well-defined because RKHS is endowed with a valid inner
product. With the reproducing property [2], each inner product becomes
(cid:88)
âŸ¨f ,f âŸ© = âŸ¨l (x ),l (z )âŸ©k(x ,hz ).
X hZ H X i Z j i j
xiâˆˆX,zjâˆˆZ
4 EquivAlign Framework
Figure 2 illustrates the EquivAlign framework. The process begins with the in-
troduction of a lightweight SE(3) equivariant feature representation as detailed
in Section 4.1. Subsequently, we focus on optimizing the pose and kernel pa-
rameters within this feature space (Sections 4.2 and 4.3). The training phase
is distinctive due to the disparate stages and frequencies at which updates for
the equivariant feature encoder, as well as for the kernel and pose, take place.
To address this, we perform an unsupervised inner-outer loop learning strategy
with curriculum learning, as discussed in Section 4.5.
4.1 Equivariant Point Representation
Unlike raw 3D coordinates, feature maps extracted from deep neural networks
produce a more expressive representation of the point clouds. Instead of repre-
sentingeachpointasanelementinR3 asinCVO,wedesignequivariantfeatures
torepresentthem,xâŠ•Ëœf:adirectsumofxâ€™scoordinateandmultiplechannelsof
3-dimensional steerable vectorsËœf :=Ï•(x), with Ï• being the equivariant encoder
with weights Î¸. The steerable features are a specific type-1 feature [50] for rota-
tions in VectorNeuron [18]. VectorNeuron proposes that SE(3)-equivariance can
be realized by centering the point cloud coordinates. However, in real applica-
tions, the two input point clouds do not fully overlap. Thus, we cannot simply
centralize them and process the rotation-only registration. Instead, we incorpo-
rateanadditionaltype-0featureâ€”the3Dcoordinateitself.Eachchannelofthis
representation can be visualized as a vector field defined on R3, as shown in
Figure 3. This straightforward yet effective representation is modular, allowing
for easy adaptation to future advancements in equivariant encoders.
The rotation R and translation t of the pose h can be applied directly to the
point-wise feature representations as follows:
R(xâŠ•Ëœf)=RxâŠ•RËœf, t(xâŠ•Ëœf)=(t+x)âŠ•Ëœf. (4)
Therotationâ€™sactiononthefeaturesisonboththecoordinatesandthesteerable
vectors.Thetranslationâ€™sactionwillonlyalterthecoordinatesbutwillnotaffect
the vector field elementsâ€™ directions.EquivAlign: Corr.-Free Point Cloud Reg. via Unsupervised Equiv. Learning 7
Outer Loop: Equiv. Learning Inner Loop: Iterative Pose Update
ğ‘¿ Correspondence-free KernelEvaluationModule Pose Regression Objective:
Equiv. â€¦ â€¦ â€¦ â€¦
Encoder â€¦ â€¦ â€¦ â€¦ â€¦
â€¦ â€¦ â€¦ â€¦ â€¦
Iterative Step
Equiv. â€¦ â€¦ â€¦ â€¦ â€¦ Update to ğ‘»
Encoder â€¦ â€¦ â€¦ â€¦ â€¦
ğ’€ Unsupervised Training
SE(3) Equiv.
Feature of ğ—,ğ’€ Iterate until Convergence
+ Training
Inference
Fig.2: EquivAlign Architecture: An iterative, fully differentiable, and inner-outer
loopstructuredunsupervisedSE(3)registrationframeworkenablescorrespondence-free
feature space pose regression. During the training phase, the outer loop accumulates
loss from the inner loop, which is dedicated to iterative pose adjustments aimed at
refining the encoder. During the inference stage, raw point clouds are processed in a
singlepassbytheencoder.Subsequently,theinnerloopproceedstoiterativelyoptimize
the pose that acts on the feature space, continuing until convergence is reached.
The linear multiplications by weights W and the nonlinearity [18] that acts
solely on the steerable features can be defined as follows:
W(xâŠ•Ëœf)=xâŠ•(ËœfW), Ïƒ(xâŠ•Ëœf)=xâŠ•Ïƒ(Ëœf). (5)
The graph convolution over point x is similar to DGCNN [54] and VectorNeu-
ron [18], but with the additional direct sum of 3D coordinate x itself:
W âˆ—(xâŠ•Ëœf)=xâŠ•Ïƒ(ËœfW + (cid:88) (Ëœf âˆ’Ëœf)W ) (6)
k k
xkâˆˆN(x)
where x âŠ•Ëœf are the neighborsâ€™ features and W,W are the weights to learn.
k k k
4.2 Pose Optimization and Kernel Learning in the Feature Space
Toestimatethetransformation,theobjectiveistominimizethedistancebetween
the two functions within the RKHS:
d(f ,f )=âˆ¥f âˆ¥2+âˆ¥f âˆ¥2âˆ’2âŸ¨f ,f âŸ© (7)
Ï•(X) hÏ•(Z) Ï•(X) Ï•(Z) Ï•(X) hÏ•(Z) H
where each function is represented as f = (cid:80) l (x )k (x âŠ•Ëœf ,Â·). Let Ëœf :=
Ï•(X) X i â„“ i i i
Ï•(x ) and gËœ :=Ï•(z )=Ï•(z ), then we have:
i j j j
d(f ,f )=(cid:88) âŸ¨(l (x ),l (x )âŸ©k(x âŠ•Ëœf ,x âŠ•Ëœf )
Ï•(X) hÏ•(Z) X i X j i i j j
i,j
+(cid:88) âŸ¨l (z ),l (z )âŸ©k(z âŠ•gËœ ,z âŠ•gËœ )âˆ’2(cid:88) âŸ¨l (z ),l (z )âŸ©k(x âŠ•Ëœf ,h(z âŠ•gËœ )) .
Z i Z j i i j j X i Z j i i j j
i,j i,j
As the label function (color, intensity, etc.) remains invariant under the pose
change,thefollowingvariablescanbetreatedasconstants:cX,cZ,c .Thefinal
ij ij ij8 R. Zhang et al.
Fig.3: SE(3)-Equivariant Representation of Point Feature: (Left) Visualiza-
tion of the two raw input point clouds in blue and red, being the 3D coordinate itself.
(Middle) The direct sum representation of equivariant point features of the two point
clouds at the initial relative pose, with each point appending its steerable vectors
(for simplicity, three arrows per point are used in the illustration, representing three
channelsofeachpointâ€™ssteerablefeatures).(Right)AppliedgroundtruthSE(3)trans-
formationtothefeaturespace,resultinginanexactoverlapofthetworepresentations
of the point set, affirming the precision of the equivariant representation.
objective function becomes:
d(f ,f )=(cid:88) cXk(x âŠ•Ëœf ,x âŠ•Ëœf )+(cid:88) cZk(z âŠ•gËœ ,z âŠ•gËœ )
Ï•(X) hÏ•(Z) ij i i j j ij i i j j
i,j i,j
âˆ’2(cid:88) c k(x âŠ•Ëœf ,h(z âŠ•gËœ )). (8)
ij i i j j
i,j
4.3 Kernel Choice
TheRKHS,inwhichthepointcloudfunctionsreside,necessitatesawell-defined
Mercerkernel[2].Characterizedbyahyperparameterâ„“,thiskernelisafunction
of two variables within the equivariant feature space and has to be symmetric
and positive-definite: k :Ï•Ã—Ï•â†’I.
â„“
Theselectionofkernelisguidedbytwocriticalcriteria.Firstly,itnecessitates
aminimalnumberofhyperparameters.IntheclassicalCVOframework[61],the
kerneloperatesonthree-dimensionalinputs,wherehyperparameterssignificantly
influence the outcomes. Managing these hyperparameters becomes increasingly
complex with higher-dimensional inputs, such as the direct sum of the 3D coor-
dinate and the multi-channel steerable vectors. Secondly, the kernelâ€™s hyperpa-
rametersshouldbeinterpretable,enablinganunderstandingofitsimpactonthe
modelâ€™s performance. The kernel is defined as the product of the Radial Basis
Function (RBF) kernel and the hyperbolic tangent kernel, as described in [43]:
k (x âŠ•Ëœf ,z âŠ•gËœ ):=RBF (x ,z )Â·tanh(1+Ëœf Â·gËœ ). (9)
â„“ i i j j â„“ i j i j
The RBF kernel is utilized for the coordinate part and the hyperbolic tangent
kernel for the steerable feature maps. The RBF kernel includes a kernel param-
eter, the lengthscale â„“, which is optimized during pose inference:
âˆ¥x âˆ’z âˆ¥2
RBF (x ,z )=exp( i j 3). (10)
â„“ i j 2â„“2EquivAlign: Corr.-Free Point Cloud Reg. via Unsupervised Equiv. Learning 9
The RBF kernel is adopted to leverage the lengthscale parameter in promoting
sparsity and minimizing the number of non-trivial terms in the loss calculation.
AparameterizedkernelisnotselectedforthesteerablevectorsËœf todecreasethe
number of parameters requiring optimization during test time.
4.4 Inference
During the inference stage, the goal is to minimize the distance between two
functions with respect to the pose h and the kernel parameter â„“, while keeping
the encoder weights Î¸ fixed:
hË†,â„“Ë†=argmind(f ,f ). (11)
Ï•(X) hÏ•(Z)
h,â„“
Itâ€™s important to note that for each iteration of pose optimization, thereâ€™s no
need to process the transformed point cloud through the encoder again. In-
stead, the approach involves directly transforming the equivariant features and
re-evaluating the kernels during the loss calculation.
4.5 Unsupervised Training of Equivariant Encoder
In practical scenarios such as visual odometry, ground truth transformation la-
bels are often scarce. To adapt the encoder weights to new environments, unsu-
pervised bi-level training [40] is employed:
Inner Loop:argmind(f ,f ),Outer Loop:argmind(f ,f ).
Ï•(X) hÏ•(Z) Ï•(X) hË†Ï•(Z)
h,â„“ Î¸
(12)
Duringtraining,thetwopointcloudsX,Z areinitiallyprocessedthroughthe
equivariant encoder Ï• to derive the point-wise equivariant features Ï•(X),Ï•(Z).
Subsequently, in each iteration, the loss is minimized with respect to the trans-
formation h and the kernel parameter â„“, facilitating a stepwise update of the
transformation. Using the latest pose estimate hË†, the gradient is retained in
the computation graph, and the encoder parameters are updated. This training
strategy does not require ground truth pose labels.
Additional aspects of the training procedure are necessary to ensure satis-
factory convergence properties. A curriculum training strategy is employed to
initiate training from random initial weights, starting with smaller angles at 1â—¦
and progressively advancing to larger angles up to 90â—¦. Moreover, there is a
tendency for the kernel parameter to change too rapidly, potentially causing its
values effectively becoming zero. To mitigate this issue, a learning rate that is
100 times smaller is utilized specifically for updating the kernel lengthscale â„“.
5 Experiments
Inthissection,qualitativeandquantitativeexperimentalresultsarepresentedon
both a simulated dataset, the ModelNet40 dataset [57], and a real-world RGB-
D dataset, ETH3D [46]. The assessment focuses on EquivAlignâ€™s registration10 R. Zhang et al.
accuracy in rotations and translations, along with its robustness to different
perturbations. The implementation is based on Pytorch [39] and PyPose [52].
Baselines: Three types of baselines are chosen: a) Classical non-learning
registration methods, including ICP [3], GICP [47] and the classical CVO [61].
For a fair comparison, CVOâ€™s label function l (x ) is set to 1 to exclude ex-
X i
tra information like color. b) Invariant feature-matching based methods, includ-
ing RANSAC [22] with FPFH features, FGR [62] with FPFH features, and
GeoTransformer [42]. GeoTransformerâ€™s official implementation is used, with
the author-provided pretrained weights on ModelNet40 and our custom-trained
weights on ETH3D. c) An equivariant feature method based on finite groups,
E2PN [64], trained under the same setup as EquivAlign.
5.1 Simulation Dataset: ModelNet40 Registration
(a) 90â—¦ InitialRot. (b) ICP (c) GICP (d) FPHF+RANSAC
(e) FPHF+FGR (f) GeoTransformer (g) E2PN (h) EquivAlign
Fig.4: An airplane example of the point cloud registration at 90â—¦ initial angle, with
Gaussian noise N(0,0.01) along the surface normal direction and 20% uniformly dis-
tributedoutliers.TheequivariantregistrationsoutperformtheinvariantandICP-based
methods. EquivAlign has a better yaw angle compared to E2PN.
Setup: In this experiment, we perform point cloud registration of all meth-
odsontheModelNet40dataset,whichcomprisesshapesgeneratedfrom3DCAD
models.Toavoidtheposeambiguityofobjectswithsymmetricrotationalshapes,
only the non-rotational symmetric categories are used in this experiment, with
60%trainingdata,20%validationdata,and20%testdata.Apointcloudisgen-
eratedbyrandomlysubsampling1,024pointsonthesurface,anditisrandomly
rotated to form a pair. The initial rotation angle is set at 45â—¦ and 90â—¦ around
randomaxes.Theerrormetricisthemeanofthematrixlogarithmerrorbetween
the resulting pose and the ground truth pose, i.e., ||log(h hâˆ’1)||. To assess
result gt
the modelâ€™s robustness under various noise perturbations, three types of noises
are injected: a) Gaussian noise N(0,0.01) distributed along each pointâ€™s surface
normal. b) 20% uniformly distributed outliers along each pointâ€™s surface normal
c)upto20%randomcroppingalongarandomaxis.Thesenoisesarenot applied
during training time for EquivAlign and E2PN. Note that only GeoTransformer
includes these perturbations as data augmentations in its pretrained model.EquivAlign: Corr.-Free Point Cloud Reg. via Unsupervised Equiv. Learning 11
Type Method
TestInitAngle<45â—¦ TestInitAngle<90â—¦
Ïƒ=0,Î³=0Ïƒ=0.01,Î³=0Ïƒ=0.01,Î³=20%Ïƒ=0,Î³=0Ïƒ=0.01,Î³=0Ïƒ=0.01,Î³=20%
ICP 1.11 1.21 1.38 34.52 36.15 38.00
Non-Learning
GICP 2.44 2.74 2.53 49.88 46.42 48.40
Geometric-CVO 5.67 5.93 6.28 23.90 26.92 30.84
InvariantFeatures FPFH+RANSAC 0.02 42.50 42.43 0.73 85.63 85.60
FPFH+FGR 0.07 2.27 12.62 0.14 11.69 43.88
GeoTransformer 0.67 0.71 0.92 42.82 43.28 42.58
E2PN 3.86 46.84 70.88 3.78 48.19 70.61
EquivariantFeatures
EquivAlign 0.61 1.93 1.96 1.14 4.08 4.12
Type Method
TestInitAngle<45â—¦ TestInitAngle<90â—¦
crop5% crop10% crop20% crop5% crop10% crop20%
ICP 2.25 2.73 5.94 37.00 39.23 45.04
Non-Learning
GICP 3.33 3.34 5.68 49.28 49.90 53.78
Geometric-CVO 11.04 15.90 23.40 31.77 45.24 52.47
FPFH+RANSAC 42.56 42.37 43.10 85.60 85.51 85.17
InvariantFeatures
FPFH+FGR 37.93 44.73 57.15 78.66 82.22 90.94
GeoTransformer 1.13 1.22 1.39 41.41 42.04 45.45
E2PN 76.90 84.30 92.41 76.06 83.42 94.70
EquivariantFeatures
EquivAlign 9.88 14.23 19.20 15.01 28.87 43.32
Table 1: Rotation Error Analysis on the ModelNet40 Dataset: (Top) Com-
parative performance of baselines under varying noise and outlier conditions. Ïƒ is the
variance of the Gaussian noise applied on the surface normal direction of each point.
Î³ istheratioofpointsperturbedbyuniformlydistributedoutliers.(Bottom)Baseline
comparisons across different crop ratios.
Results:ThequantitativeresultsarepresentedinTable1andthequalitative
results are shown in Figure 4. We denote the variance of the Gaussian noise as
Ïƒ and the ratio for the uniform outlier perturbation as Î³.
Innoise-freeconditions,bothclassicalandproposedmethodsexcelatsmaller
angles(45â—¦),withinvariantfeature-matchingmethodsshowinglowererrorscom-
pared to equivariant-learning-based approaches. EquivAlign demonstrates per-
formanceonparwithclassicalICPmethodsandsuperiortoE2PN.However,at
initial angles of 90â—¦, ICP and GICP show larger errors due to their reliance on
accurate initial guesses for data association. In these scenarios, EquivAlign sur-
passes E2PN, but invariant feature-matching methods achieve the best results.
When encountering Gaussian noise, EquivAlign reaches a slightly better ac-
curacy than the invariant feature matching methods at 45â—¦ (except GeoTrans-
former) and is the best-performing method at 90â—¦. GeoTransformer tops the
benchmark at 45â—¦. Similar to the noise-less situation, non-learning methodsâ€™
result degenerate at larger initial angles.
With 20% uniformly distributed outliers, methods assuming Gaussian errors
will degrade. Invariant feature matching is severely affected by this type of per-
turbation and fails to register at smaller or larger angles, unless extensive data
augmentationisusedduringtraining.ICP-basedmethodscanreachsatisfactory
resultsatsmallanglesbutnotlargerones.EquivAlignremainslargelyunaffected
bythisperturbation,achievingthebestresultsat90â—¦byasignificantmarginand
performingcomparablytoICP-typemethodsat45â—¦.Thisdemonstrateshowthe
expressiveness of equivariant features helps in the robustness of the registration
process, even when only noise-free data is used in training.
In tests involving random cropping of input data (with no cropping in train-
ing),asreportedinTable1(Bottom),allmethodsexperienceperformancedips.12 R. Zhang et al.
Similar to the third case, ICP-based methods are not substantially affected by
the cropping at 45â—¦ but are easily trapped in the local minima at larger an-
gles. Classical invariant feature-based baselines cannot converge at either ini-
tial angle, but with sufficient data augmentation, GeoTransformer becomes the
best-performing method. Both equivariant methods also experienced larger er-
rors, not as severe as the classical invariant feature matching methods though.
The proposed learning-based RKHS formulation natively annihilates the outlier
disturbance because, at larger distances, the kernel will return trivial values. In
contrast, as E2PN directly performs global pooling over all the points to obtain
a single global feature, missing cropped components will reduce the quality of
the global feature, especially when the crop is unseen in the training data.
5.2 Real Dataset: ETH3D RGB-D Registration
Setup: In this experiment, EquivAlign is benchmarked against other baselines
using a real RGB-D dataset. We utilize the ETH3D dataset [46], comprising
real indoor and outdoor RGB-D images. In this setup, two point cloud pairs are
sampled sequentially. Unlike the simulated ModelNet40 dataset, a pair of point
clouds will not fully overlap even without noise injections due to the viewpoint
change. Additionally, the ground truth pose will contain rotation and transla-
tion but at smaller angles than the ModelNet40 experiment. A random rotation
perturbation of 10â—¦ is injected into each pair of testing data. 6 sequences are
used for training: (cable_3, ceiling_1, repetitive, einstein_2, sfm_house
_loop, desk_3), 2 sequences for validation: (mannequin_3, sfm_garden), and 4
sequences for testing: (sfm_lab_room_1, plant_1, sfm_bench, table_3). Given
the varying number of frames in each sequence, frame pairs are subsampled to
ensure no more than 1000 pairs per sequence. This results in 5919 training in-
stances, 2000 validation instances, and 2702 test instances. For all the methods,
input point clouds are downsampled into 1024 points with the farthest_point
_down_sample method from Open3D [63]. For a fair comparison, color informa-
tion is excluded in EquivAlign by setting the label function l (x)=1 in Eq. (2)
X
as the baselines similarly abstain from using color.
Results: The quantitative results are shown in Table 2. On the test se-
quences,EquivAlign demonstratesthebestaccuracyinbothrotationandtrans-
lationevaluations,witha0.53â—¦ rotationerror,0.01mtranslationerror,andlow-
estvariations.Theinvariantfeature-basedbaselineshavesignificantlylargertest
errors.Thisisduetothechallengeofgeneralizingtoreal-worldnoise,particularly
for supervised learning methods. ICP-based methods have comparable transla-
tion errors, but their rotation error is 60% and 25% larger, respectively. This
comparison indicates that EquivAlign produces fine-grained registration alone
in real data and thus can be adopted in applications like frame-to-frame pose
tracking. It does not have the necessity of using coarse-to-fine strategies with
ICP, as adopted in recent invariant-learning-based works like PREDATOR [27].
Moreover, the other equivariant baseline, E2PN, is also not as accurate as
EquivAlign,thoughitiscorrespondence-freeandhassuperiorglobalregistration
ability.Wearguethattherearethreepotentialreasonsbehindthis:First,E2PNEquivAlign: Corr.-Free Point Cloud Reg. via Unsupervised Equiv. Learning 13
Type Method
Rot.Error(â—¦)Trans.Error(m)
Mean STD. Mean STD.
ICP 0.88 1.30 0.03 0.05
Non-Learning
GICP 0.69 3.54 0.02 0.11
Geometric-CVO 0.71 0.94 0.02 0.02
FPFH+RANSAC 8.75 2.95 0.17 0.40
InvariantFeatures
FPFH+FGR 3.60 12.61 0.08 0.17
GeoTransformer 2.23 13.09 0.07 0.31
E2PN 5.20 NA NA NA
EquivariantFeatures
EquivAlign 0.53 0.99 0.01 0.02
Table2:QuantitativeandQualitativeResultsontheETH3DDataset:(Left)
Among competing baselines, EquivAlign achieves the lowest rotation and translation
errors. E2PN, while SE(3)-equivariant, lacks translation predictions in the official im-
plementationandismarkedas"NA"inourtable.(Right)ReconstructionusingEquiv-
Align frame-to-frame transformations on the first 150 frames of table_3 sequence.
uses a finite group rotation representation on equivariance learning, resulting in
amuchfasterrunningspeedviafeaturepermutation.However,thediscretization
comes at a cost; that is, it will have resolution challenges at fine-grained regis-
tration,especiallycomparedtoEquivAlignâ€™scontinuousrotationrepresentation.
Secondly, EquivAlign does not require training labels and thus is not tightly
coupledtothetrainingdatadistribution.Incontrast,E2PNneedsgroundtruth
supervision, which means there would be overfitting challenges if the test set is
a new scene. Thirdly, EquivAlign adopts the RKHS representation whose ker-
nel can eliminate the influence of non-overlapped areas, while E2PN assumes
complete symmetry of the input pair, which is often violated in real data. Re-
cent works such as SE3-Transformer [23] and GeoTransformer [42] attempt to
bring the attention mechanism to address this issue. But training the attention
network will also need ground truth labels.
5.3 Ablation Study
Kernel Choice The chosen kernel, although not our primary focus, prefers
minimal hyperparameters and is interpretable, or any suitable kernel satisfying
these. Even with a 3D kernel in the classical CVO [61], the hyperparameters
significantlyimpacttheresults.Morecomplexityincontrollingthemcouldarise
with higher dimensional inputs like the higher dimensional steerable vectors.
The current kernel choice links RBF kernel lengthscales to Euclidean point dis-
tances, whereas the tanh kernel only considers steerable vector directions. To
demonstrate that, we train and test the network with a single RBF kernel on
ModelNet40 of 45â—¦ initial angles in Table 3 (a).
InitialKernelParameter EquivAlignhasahyperparameter,thekernellength-
scale â„“, which controls the coarse-grain and fine-grain resolution of the loss [13,
61]. It is optimized during pose regression but still requires an initial value. In
this ablation study shown in Table 3 (b), we test how the initial lengthscale will
affect the registration accuracy on the ModelNet40 dataset. The outcome cor-
roboratesinsightsfromtheCVOworks:Registeringatlargeranglesnecessitates
a greater initial lengthscale for a comprehensive global perspective.14 R. Zhang et al.
KernelChoice Rot.Error(â—¦) Curriculum [45â—¦] [1â—¦,10â—¦,20â—¦,30â—¦,45â—¦]
InitAngle<45â—¦
MeanSTD.Mean STD.
RBFÃ—Tanhkernel 0.29
RBFkernelonly 81.97 InitAngle:45â—¦ 2.73 9.1 0.29 0.469
(a) (b) (c)
Table 3: (a) Kernel Comparison: ThetablecontraststheRBFÃ—tanhkernelwith
theRBFkernelaloneonequivariantfeatures.TrainingontheModelNet40datasetfor
initialanglesupto45â—¦,onlytheRBFÃ—tanhkernelsuccessfullycompletesregistration,
unlike the RBF kernel alone. (b) Lengthscale Study: An analysis of four kernel
lengthscales across two initial angles reveals a direct relationship between problem
scale and lengthscale, suggesting larger initial errors require larger lengthscales. (c)
Necessity of Curriculum Learning: Starting with small, incremental angles on
the ModelNet40 dataset yields lower error means and STDs than starting from larger
angles, underscoring curriculum learningâ€™s efficacy in training.
Curriculum Learning vs. Direct Training As an unsupervised approach,
onesignificantchallengeweaddressedwasthebootstrapoftherandomly-initialized
network weights. To investigate this issue, we conducted an ablation study be-
tweencurriculum-basedtraininganddirecttrainingatmaximalangularpertur-
bations,aspresentedinTable3(c).Ourfindingsshowthatagradualcurriculum
with incremental steps significantly enhances model accuracy and reduces un-
certainty, highlighting the effectiveness of curriculum learning for optimizing
network performance from randomly initialized weights.
6 Limitations and Conclusion
There are trade-offs with our method, including lengthy training times and re-
duced performance with limited overlap. Our unsupervised training approach
uses a curriculum learning strategy that progresses from smaller to larger rota-
tions, resulting in extended training times. Training on the ModelNet40 dataset
with 8 NVIDIA V100 GPUs takes a week for 90â—¦ registrations. Performance de-
creasesinlow-overlapscenarios,asindicatedinTable1,where60%overlap(20%
cropping) reduces registration accuracy. However, data augmentation, longer
training cycles, and a denser curriculum can improve low-overlap performance,
whileasparsercurriculumcanreducetrainingtime.Besidestheextendedtrain-
ingtime,ourmethodhasaninferencetimeof0.03to0.1secondsperiterationon
a single V100 GPU. Future directions include incorporating SE(3)-equivariant
transformers into the encoder to capture more extended feature correlations,
enhancing robustness and efficiency.
In summary, this paper introduces a differentiable, iterative point cloud reg-
istrationframeworkthatleveragescorrespondence-freeposeregressioninRKHS.
EquivAlign achieves fine-grained feature space registration and effectively han-
dlesnoise,outliers,andlimitedlabeleddata.ResultsonModelNet40andETH3D
datasets show our method outperforming established methods particularly in
noise resilience. This study lays a foundation for further research in unsuper-
vised equivariant learning within 3D vision and opens its application to numer-
ous fields, including but not limited to robotics and the medical domain.EquivAlign: Corr.-Free Point Cloud Reg. via Unsupervised Equiv. Learning 15
References
1. Bai, X., Luo, Z., Zhou, L., Fu, H., Quan, L., Tai, C.L.: D3feat: Joint learning of
densedetectionanddescriptionof3Dlocalfeatures.In:Proc.IEEEConf.Comput.
Vis. Pattern Recog. pp. 6359â€“6367 (2020)
2. Berlinet,A.,Thomas-Agnan,C.:ReproducingKernelHilbertSpaceinProbability
andStatistics.SpringerScienceandBusinessMedia(012004).https://doi.org/
10.1007/978-1-4419-9096-9
3. Besl, P.J., McKay, N.D.: A method for registration of 3-d shapes. IEEE Trans.
Pattern Anal. Mach. Intell. 14(2), 239â€“256 (Feb 1992). https://doi.org/10.
1109/34.121791
4. Biber,P.,Fleck,S.,StraÃŸer,W.:Aprobabilisticframeworkforrobustandaccurate
matchingofpointclouds.In:JointPatternRecognitionSymposium.pp.480â€“487.
Springer (2004)
5. Bishop, C.M.: Pattern recognition and machine learning. Springer (2006)
6. Campbell, D., Petersson, L.: An adaptive data representation for robust point-set
registration and merging. In: Proc. IEEE Int. Conf. Comput. Vis. pp. 4292â€“4300
(2015)
7. Chen,H.,Liu,S.,Chen,W.,Li,H.,Hill,R.:Equivariantpointnetworkfor3Dpoint
cloudanalysis.In:Proc.IEEEConf.Comput.Vis.PatternRecog.pp.14514â€“14523
(2021)
8. Chen, X., Milioto, A., Palazzolo, E., Giguere, P., Behley, J., Stachniss, C.:
Suma++: Efficient lidar-based semantic slam. In: Proc. IEEE/RSJ Int. Conf. In-
tell. Robots and Syst. pp. 4530â€“4537. IEEE (2019)
9. Chen,Y.,Medioni,G.G.:Objectmodelingbyregistrationofmultiplerangeimages.
Image Vision Comput. 10(3), 145â€“155 (1992)
10. Choy, C., Park, J., Koltun, V.: Fully convolutional geometric features. In: Pro-
ceedingsoftheIEEEInternationalConferenceonComputerVision.pp.8958â€“8966
(2019)
11. Choy, C., Park, J., Koltun, V.: Fully convolutional geometric features. In: Proc.
IEEE Int. Conf. Comput. Vis. pp. 8958â€“8966 (2019)
12. Chui,H.,Rangarajan,A.:Afeatureregistrationframeworkusingmixturemodels.
In: Proceedings IEEE Workshop on Mathematical Methods in Biomedical Image
Analysis. pp. 190â€“197. IEEE (2000)
13. Clark,W.,Ghaffari,M.,Bloch,A.:Nonparametriccontinuoussensorregistration.
J. Mach. Learning Res. 22(271), 1â€“50 (2021)
14. Cohen, T., Weiler, M., Kicanaoglu, B., Welling, M.: Gauge equivariant convolu-
tionalnetworksandtheicosahedralCNN.In:Proc.Int.Conf.Mach.Learning.pp.
1321â€“1330. PMLR (2019)
15. Cohen, T., Welling, M.: Group equivariant convolutional networks. In: Proc. Int.
Conf. Mach. Learning. pp. 2990â€“2999. PMLR (2016)
16. Cohen, T.S., Geiger, M., KÃ¶hler, J., Welling, M.: Spherical cnns. arXiv preprint
arXiv:1801.10130 (2018)
17. Cohen, T.S., Welling, M.: Steerable cnns. arXiv preprint arXiv:1612.08498 (2016)
18. Deng, C., Litany, O., Duan, Y., Poulenard, A., Tagliasacchi, A., Guibas, L.J.:
Vector neurons: A general framework for SO(3)-equivariant networks. In: Proc.
IEEE Int. Conf. Comput. Vis. pp. 12200â€“12209 (2021)
19. Deng,H.,Birdal,T.,Ilic,S.:Ppfnet:Globalcontextawarelocalfeaturesforrobust
3dpointmatching.In:ProceedingsoftheIEEEconferenceoncomputervisionand
pattern recognition. pp. 195â€“205 (2018)16 R. Zhang et al.
20. Eckart,B.,Kim,K.,Kautz,J.:Hgmr:HierarchicalGaussianmixturesforadaptive
3D registration. In: Proc. European Conf. Comput. Vis. pp. 705â€“721 (2018)
21. Evangelidis, G.D., Horaud, R.: Joint alignment of multiple point sets with batch
and incremental expectation-maximization. IEEE Trans. Pattern Anal. Mach. In-
tell. 40(6), 1397â€“1410 (2017)
22. Fischler, M.A., Bolles, R.C.: Random sample consensus: a paradigm for model
fittingwithapplicationstoimageanalysisandautomatedcartography.Communi-
cations of the ACM 24(6), 381â€“395 (1981)
23. Fuchs, F., Worrall, D., Fischer, V., Welling, M.: SE(3)-transformers: 3D roto-
translationequivariantattentionnetworks.Proc.AdvancesNeuralInform.Process.
Syst. Conf. 33, 1970â€“1981 (2020)
24. Ghaffari,M.,Clark,W.,Bloch,A.,Eustice,R.M.,Grizzle,J.W.:Continuousdirect
sparse visual odometry from RGB-D images. In: Proc. Robot.: Sci. Syst. Conf.
Freiburg, Germany (June 2019)
25. Ghaffari, M., Clark, W., Bloch, A., Eustice, R.M., Grizzle, J.W.: Continuous di-
rectsparsevisualodometryfromRGB-Dimages.arXivpreprintarXiv:1904.02266
(2019)
26. Horaud, R., Forbes, F., Yguel, M., Dewaele, G., Zhang, J.: Rigid and articulated
pointregistrationwithexpectationconditionalmaximization.IEEETrans.Pattern
Anal. Mach. Intell. 33(3), 587â€“602 (2010)
27. Huang, S., Gojcic, Z., Usvyatsov, M., Wieser, A., Schindler, K.: Predator: Regis-
tration of 3D point clouds with low overlap. In: Proc. IEEE Conf. Comput. Vis.
Pattern Recog. pp. 4267â€“4276 (2021)
28. Jian,B.,Vemuri,B.C.:RobustpointsetregistrationusingGaussianmixturemod-
els. IEEE Trans. Pattern Anal. Mach. Intell. 33(8), 1633â€“1645 (Aug 2011)
29. Kerl, C.: Dense Visual Odometry (DVO). https://github.com/tum-vision/dvo
(2013)
30. Li,F.,Fujiwara,K.,Okura,F.,Matsushita,Y.:Generalizedshuffledlinearregres-
sion. In: Proceedings of the IEEE/CVF International Conference on Computer
Vision. pp. 6474â€“6483 (2021)
31. Li, Y., Bu, R., Sun, M., Wu, W., Di, X., Chen, B.: Pointcnn: Convolution on x-
transformed points. In: Proc. Advances Neural Inform. Process. Syst. Conf. pp.
820â€“830 (2018)
32. Lin, T.Y., Clark, W., Eustice, R.M., Grizzle, J.W., Bloch, A., Ghaffari, M.:
Adaptive continuous visual odometry from RGB-D images. arXiv preprint
arXiv:1910.00713 (2019)
33. MacDonald, L.E., Ramasinghe, S., Lucey, S.: Enabling equivariance for arbitrary
liegroups.In:Proc.IEEEConf.Comput.Vis.PatternRecog.pp.8183â€“8192(2022)
34. Magnusson,M.,Lilienthal,A.,Duckett,T.:Scanregistrationforautonomousmin-
ing vehicles using 3D-NDT. J. Field Robot. 24(10), 803â€“827 (2007)
35. Mitra, N.J., Gelfand, N., Pottmann, H., Guibas, L.: Registration of point cloud
data from a geometric optimization perspective. In: Proceedings of the 2004 Eu-
rographics/ACM SIGGRAPH Symposium on Geometry Processing. p. 22â€“31.
SGP â€™04, Association for Computing Machinery, New York, NY, USA (2004).
https://doi.org/10.1145/1057432.1057435
36. Park, J., Zhou, Q.Y., Koltun, V.: Colored point cloud registration revisited. In:
Proc. IEEE Int. Conf. Comput. Vis. pp. 143â€“152 (2017)
37. Parkison, S.A., Gan, L., Jadidi, M.G., Eustice, R.M.: Semantic iterative closest
pointthroughexpectation-maximization.In:Proc.BritishMach.Vis.Conf.p.280
(2018)EquivAlign: Corr.-Free Point Cloud Reg. via Unsupervised Equiv. Learning 17
38. Parkison, S.A., Ghaffari, M., Gan, L., Zhang, R., Ushani, A.K., Eustice, R.M.:
Boosting shape registration algorithms via reproducing kernel Hilbert space regu-
larizers. IEEE Robotics and Automation Letters 4(4), 4563â€“4570 (2019)
39. Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,
Desmaison, A., Antiga, L., Lerer, A.: Automatic differentiation in pytorch (2017)
40. Pineda,L.,Fan,T.,Monge,M.,Venkataraman,S.,Sodhi,P.,Chen,R.T.,Ortiz,J.,
DeTone, D., Wang, A., Anderson, S., et al.: Theseus: A library for differentiable
nonlinear optimization. Proc. Advances Neural Inform. Process. Syst. Conf. 35,
3801â€“3818 (2022)
41. Qi, C.R., Su, H., Mo, K., Guibas, L.J.: Pointnet: Deep learning on point sets for
3d classification and segmentation. In: Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition. pp. 652â€“660 (2017)
42. Qin, Z., Yu, H., Wang, C., Guo, Y., Peng, Y., Ilic, S., Hu, D., Xu, K.: Geotrans-
former:Fastandrobustpointcloudregistrationwithgeometrictransformer.IEEE
Trans. Pattern Anal. Mach. Intell. (2023)
43. Rasmussen,C.,Williams,C.:Gaussianprocessesformachinelearning,vol.1.MIT
press (2006)
44. Rusu, R.B., Blodow, N., Beetz, M.: Fast point feature histograms (fpfh) for 3d
registration. In: 2009 IEEE international conference on robotics and automation.
pp. 3212â€“3217. IEEE (2009)
45. Satorras, V.G., Hoogeboom, E., Welling, M.: E(n) equivariant graph neural net-
works. In: Proc. Int. Conf. Mach. Learning. pp. 9323â€“9332. PMLR (2021)
46. Schops, T., Sattler, T., Pollefeys, M.: Bad SLAM: Bundle adjusted direct RGB-D
SLAM. In: Proc. IEEE Conf. Comput. Vis. Pattern Recog. pp. 134â€“144 (2019)
47. Segal,A.,Haehnel,D.,Thrun,S.:Generalized-ICP.In:Robotics:scienceandsys-
tems. vol. 2(4), p. 435. Seattle, WA (2009)
48. Servos, J., Waslander, S.L.: Multi channel generalized-ICP. In: Proc. IEEE Int.
Conf. Robot. and Automation. pp. 3644â€“3649. IEEE (2014)
49. Thomas,H.,Qi,C.R.,Deschaud,J.E.,Marcotegui,B.,Goulette,F.,Guibas,L.J.:
Kpconv:Flexibleanddeformableconvolutionforpointclouds.In:Proc.IEEEInt.
Conf. Comput. Vis. pp. 6411â€“6420 (2019)
50. Thomas,N.,Smidt,T.,Kearnes,S.,Yang,L.,Li,L.,Kohlhoff,K.,Riley,P.:Tensor
field networks: Rotation-and translation-equivariant neural networks for 3D point
clouds. arXiv preprint arXiv:1802.08219 (2018)
51. Tsin,Y.,Kanade,T.:Acorrelation-basedapproachtorobustpointsetregistration.
In: Proc. European Conf. Comput. Vis. pp. 558â€“569. Springer (2004)
52. Wang, C., Gao, D., Xu, K., Geng, J., Hu, Y., Qiu, Y., Li, B., Yang, F., Moon,
B., Pandey, A., Aryan, Xu, J., Wu, T., He, H., Huang, D., Ren, Z., Zhao, S., Fu,
T., Reddy, P., Lin, X., Wang, W., Shi, J., Talak, R., Cao, K., Du, Y., Wang, H.,
Yu, H., Wang, S., Chen, S., Kashyap, A., Bandaru, R., Dantu, K., Wu, J., Xie,
L., Carlone, L., Hutter, M., Scherer, S.: PyPose: A library for robot learning with
physics-based optimization. In: IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR) (2023)
53. Wang, Y., Solomon, J.M.: Deep closest point: Learning representations for point
cloud registration. In: Proc. IEEE Int. Conf. Comput. Vis. pp. 3523â€“3532 (2019)
54. Wang,Y.,Sun,Y.,Liu,Z.,Sarma,S.E.,Bronstein,M.M.,Solomon,J.M.:Dynamic
graph cnn for learning on point clouds. ACM Transactions on Graphics (TOG)
(2019)
55. Weiler, M., Geiger, M., Welling, M., Boomsma, W., Cohen, T.S.: 3D steerable
CNNs: Learning rotationally equivariant features in volumetric data. Proc. Ad-
vances Neural Inform. Process. Syst. Conf. 31 (2018)18 R. Zhang et al.
56. Whelan,T.,Salas-Moreno,R.F.,Glocker,B.,Davison,A.J.,Leutenegger,S.:Elas-
ticfusion: Real-time dense slam and light source estimation. Int. J. Robot. Res.
35(14), 1697â€“1716 (2016)
57. Wu,Z.,Song,S.,Khosla,A.,Yu,F.,Zhang,L.,Tang,X.,Xiao,J.:3Dshapenets:A
deeprepresentationforvolumetricshapes.In:ProceedingsoftheIEEEconference
on computer vision and pattern recognition. pp. 1912â€“1920 (2015)
58. Yang,H.,Shi,J.,Carlone,L.:Teaser:Fastandcertifiablepointcloudregistration.
IEEE Transactions on Robotics 37(2), 314â€“333 (2020)
59. Yu, H., Li, F., Saleh, M., Busam, B., Ilic, S.: Cofinet: Reliable coarse-to-fine cor-
respondences for robust pointcloud registration. Proc. Advances Neural Inform.
Process. Syst. Conf. 34, 23872â€“23884 (2021)
60. Zeng, A., Song, S., NieÃŸner, M., Fisher, M., Xiao, J., Funkhouser, T.: 3dmatch:
Learning local geometric descriptors from rgb-d reconstructions. In: Proceedings
oftheIEEEconferenceoncomputervisionandpatternrecognition.pp.1802â€“1811
(2017)
61. Zhang,R.,Lin,T.Y.,Lin,C.E.,Parkison,S.A.,Clark,W.,Grizzle,J.W.,Eustice,
R.M., Ghaffari, M.: A new framework for registration of semantic point clouds
from stereo and RGB-D cameras. Proc. IEEE Int. Conf. Robot. and Automation
pp. 12214â€“12221 (2020)
62. Zhou,Q.Y.,Park,J.,Koltun,V.:Fastglobalregistration.In:Proc.EuropeanConf.
Comput. Vis. pp. 766â€“782. Springer (2016)
63. Zhou,Q.Y.,Park,J.,Koltun,V.:Open3d:Amodernlibraryfor3ddataprocessing.
arXiv preprint arXiv:1801.09847 (2018)
64. Zhu, M., Ghaffari, M., Clark, W.A., Peng, H.: E2PN: Efficient SE(3)-equivariant
point network. In: Proc. IEEE Conf. Comput. Vis. Pattern Recog. pp. 1223â€“1232
(2023)
65. Zhu,M.,Ghaffari,M.,Peng,H.:Correspondence-freepointcloudregistrationwith
SO(3)-equivariant implicitshaperepresentations.In:Conference onRobotLearn-
ing. pp. 1412â€“1422. PMLR (2022)