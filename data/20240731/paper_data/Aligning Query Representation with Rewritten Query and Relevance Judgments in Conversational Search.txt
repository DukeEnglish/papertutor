Aligning Query Representation with Rewritten Query and
Relevance Judgments in Conversational Search
FengranMo ChenQu KelongMao
RALI,UniversitÃ©deMontrÃ©al UniversityofMassachusettsAmherst RenminUniversityofChina
MontrÃ©al,QuÃ©bec,Canada Amherst,MA,USA Beijing,China
fengran.mo@umontreal.ca mail@cqu.org mkl@ruc.edu.cn
YihongWu ZhanSu KaiyuHuang
RALI,UniversitÃ©deMontrÃ©al UniversityofCopenhagen BeijingJiaotongUniversity
MontrÃ©al,Canada Copenhagen,Denmark Beijing,China
yihong.wu@umontreal.ca zhan.su@di.ku.dk kyhuang@bjtu.edu.cn
Jian-YunNie
RALI,UniversitÃ©deMontrÃ©al
MontrÃ©al,QuÃ©bec,Canada
nie@iro.umontreal.ca
Abstract Keywords
Conversational search supports multi-turn user-system interac- ConversationalDenseRetrieval,QueryRepresentationAlignment,
tionstosolvecomplexinformationneeds.Differentfromthetra- RewrittenQuery,RelevanceJudgments
ditionalsingle-turnad-hocsearch,conversationalsearchencoun-
tersamorechallengingproblemofcontext-dependentqueryun- ACMReferenceFormat:
derstandingwiththelengthyandlong-tailconversationalhistory FengranMo,ChenQu,KelongMao,YihongWu,ZhanSu,KaiyuHuang,
context.Whileconversationalqueryrewritingmethodsleverage andJian-YunNie.2024.AligningQueryRepresentationwithRewritten
explicitrewrittenqueriestotrainarewritingmodeltotransform QueryandRelevanceJudgmentsinConversationalSearch.InProceedings
thecontext-dependentqueryintoastand-stonesearchquery,this ofthe33rdACMInternationalConferenceonInformationandKnowledge
isusuallydonewithoutconsideringthequalityofsearchresults.
Management(CIKMâ€™24),October21â€“25,2024,Boise,ID,USA.ACM,New
York,NY,USA,11pages.https://doi.org/10.1145/3627673.3679534
Conversationaldenseretrievalmethodsusefine-tuningtoimprove
apre-trainedad-hocqueryencoder,buttheyarelimitedbythe
conversationalsearchdataavailablefortraining.Inthispaper,we
leveragebothrewrittenqueriesandrelevancejudgmentsinthe 1 Introduction
conversationalsearchdatatotrainabetterqueryrepresentation Conversationalsearchenablesuserstointeractwiththesystemin
model.Thekeyideaistoalignthequeryrepresentationwiththose amulti-turnfashiontosatisfytheircomplexinformationneeds.It
ofrewrittenqueriesandrelevantdocuments.Theproposedmodelâ€“ isenvisionedtobetheinteractionmodefornext-generationsearch
QueryRepresentationAlignmentConversationalDenseRetriever, engines[16].Comparedtothetraditionalsingle-turnad-hocsearch
QRACDR,istestedoneightdatasets,includingvarioussettingsin scenario,thelengthyandlong-tailhistoricalcontextinconversa-
conversationalsearchandad-hocsearch.Theresultsdemonstrate tionalsearchraisesthedifficultyforsearchintentunderstanding
thestrongperformanceofQRACDRcomparedwithstate-of-the-art incontext-dependentconversationturns.
methods,andconfirmtheeffectivenessofrepresentationalignment. Tocapturetherealinformationneedsineachqueryturn,anintu-
itivemethodisConversationalQueryRewriting(CQR)[14],which
leveragesarewritingmodeltotransformthecontext-dependent
CCSConcepts
queries into stand-alone ones, which can then be used by any
â€¢Informationsystemsâ†’Queryrepresentation;Usersand
ad-hocsearchmodelsforretrieval.Nevertheless,optimizingthe
interactiveretrieval.
rewritingmodelforthedownstreamsearchtaskinatwo-stage,
rewrite-then-search,approachischallenging.Thisdifficultyarises
duetotheseparategenerationprocessinrewriting,whichdisrupts
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor theback-propagationofgradients,resultinginsub-optimalperfor-
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation mance[30,35,48].AnothertypicalmethodisConversationalDense
onthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe retrieval(CDR)[52],whichtriestolearn,inanend-to-endmanner,
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
aconversationaldenseretrievertoencodetheuserâ€™srealsearch
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/orafee.Requestpermissionsfrompermissions@acm.org. intentandcandidatedocumentsintoalearnedembeddingspace.
CIKMâ€™24,October21â€“25,2024,Boise,ID,USA Theimplicitqueryunderstandingabilityisexpectedtobeimproved
Â©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM. viafine-tuningwithdocumentrelevancesignalsinconversational
ACMISBN979-8-4007-0436-9/24/10
https://doi.org/10.1145/3627673.3679534 searchsessions.
4202
luJ
92
]RI.sc[
1v98102.7042:viXraCIKMâ€™24,October21â€“25,2024,Boise,ID,USA FengranMoetal.
Conversational Conversational Conversational Our Model:
Search Session Query Rewriting Dense Retrieval QRACDR
Rewritten
Context: Ad-hoc Search Retriever Collection Conversational Collection QRA Conversational Queries
! !: Can the bottom of the Dense Retriever Dense Retriever
ocean freeze?
" !: Ocean water freezes ranking ranking ranking explicit search
just like freshwater,â€¦, signals signals signals intent
because of the salt in it.
! ": How does water Whathappens to water â€¦ â€¦
freeze? molecules when it freezes? Session-Q Rep. Session-Q Rep. Rewritten-Q Rep.
" ": Freezing happens Without Query With Query
when the molecules,â€¦, Explicit Search Intent Representation Alignment Representation Alignment
forming a solid crystal.
Current Query:
! : What happensto its
# Rewriter Ad-hoc Search Retriever Ad-hoc Search Retriever
molecules?
Figure1:Aconceptualillustrationforthethreetypesofmethods.QRACDRhasaQueryRepresentationAlignmentgoalto
helpachievemoreeffectiveend-to-endoptimizationtowardsearchwithinanongoingconversation.
However,mostoftheexistingconversationaldenseretrieval behindmanyrelevancefeedbackapproaches[25,43]usedininfor-
models[22,26,37,52]aresimplylearnedbyfine-tuningthepre- mationretrieval,whichtriestocreateaqueryrepresentationfrom
trainedad-hocencodersviacontrastivelearningonconversational theoriginalquerytobecomeclosertorelevantdocuments,and
searchdata[1,2].Thisisbecause1)theinitialad-hocencodersun- farawayfromirrelevantones.Intermsofconversationalsearch,
dergopre-trainingexclusivelyusingconcisead-hocqueries;and2) thekeyideaweexploitinthispaperistoalignasessionquery
thecurrentconversationalsearchdata,primarilyhuman-generated, representationwiththoseoftherewrittenqueryandtherelevant
is not as abundant as ad-hoc search data due to the limited de- documentintheneuralrepresentationspace.Thealignmentlosses
ploymentofrealconversationalsearchsystems.Consequently,the wouldpushthequeryrepresentationclosertothem.Inaddition,
straightforwardfine-tuningapproachlackssufficientsupervision wealsoconsidernegativesamples,andthequeryrepresentationis
informationtoeffectivelyadaptad-hocencoderstotheintricate pushedawayfromthem.
andnoisyconversationalsearchsetting.Thisproblemismadeeven TheaboveideaisimplementedinanQueryRpresentationAlignment
worsebythelimitedrelevancejudgmentsavailableinconversa- ConversationalDenseRetriever,QRACDR,withseveraltraining
tionalsearchdata:onlyasinglerelevantdocumentperqueryis strategiesthatincorporatedifferentalignmentmechanisms.Specif-
providedinthedatasets(i.e.,thesupervisionsignalsareweak.). ically,wefirstdesignastraightforwardandeffectivestrategyto
Apart from the aforementioned issues, most existing studies optimizethedistancebetweenthelearnablesessionquerywith
onlyleverageeithertherewrittenqueryinCQRortherelevance boththepre-encodedrewrittenqueryandtherelevantdocument,
judgmentbetweenqueryturnanddocumentinCDRassupervi- whichisbasedontheMeanSquareError(MSE)paradigm.Wethe-
sionsignals,ratherthanbothtogether.Yuetal.[52]attemptto oreticallydefinetheâ€œalignmentâ€areaintherepresentationspace
incorporatemanualqueriesbyknowledgedistillationwithindense astheregionwheretheencodedsessionqueryissupposedtofall
retrieval(ConvDR).Althoughthisworkconsidersthealignment in, and provide preliminary experiments to confirm the useful-
betweentheconversationsessionandtherewrittenquery,itdoes nessofsuchalignments.Tofurtherfacilitatetheconversational
notdeliberateonthealignmentbetweenthesessionandthegold denseretrievertraining,weincorporatenegativesamplesonboth
document(northemisalignmentwiththenegativedocuments).As thealignment-originatedMSEandthecommonlyusedcontrastive
wefurtherrevealinSection3,thisgapcanresultinafundamental learning(CL)paradigm.Comparedwithpreviousdenseretrieval
degradationinalignmentpower. models,QRACDRexploitsanewprincipledideaforqueryrepresen-
Tobetterunderstandtheusersearchintentwithintheongoing tation.Experimentalresultsoneightdatasets,coveringusualand
conversation,weleverageavailablerewrittenqueriesused/produced low-resourceconversationalsearch,andad-hocsearchscenarios,
bytheCQRandrelevancejudgmentsintrainingdatatolearna showthatQRACDRcanconsistentlyoutperformstate-of-the-art
bettermodelthroughqueryrepresentationalignment.Figure1il- baselinesintheusualevaluationandiseffectiveinothersettings.
lustratesthedifferencesbetweenthetwoexistingparadigmsand A series of thorough analyses are conducted to understand the
ourmethod.Weexpectthequeryencoderthatleveragesboththe behind-the-scenebehaviorofthemodels.
rewrittenqueryandrelevancesignalstoapproximatethesession Thecontributionsofthispaperinclude:(1)WeproposeQRACDR
queryrepresentationtowardnotonlytherelevantdocumentbut toleverageavailablerewrittenqueriesandconversationalsearch
alsotherewrittenquery.Thisissimilartotheveryassumption datatosupervisethemodeltobuildbetterqueryrepresentationforAligningQueryRepresentationwithRewrittenQueryandRelevanceJudgmentsinConversationalSearch CIKMâ€™24,October21â€“25,2024,Boise,ID,USA
searchintentviaalignment,enhancingthemodelperformancevia fortrainingtheconversationaldenseretriever.Besides,astand-
thecomplementaryeffectsofbothexistingCQRandCDRmeth- alonerewrittenqueryğ‘â€²,providedeitherbymanualannotation
ğ‘–
ods.(2)Weprovidetheoreticalassumptionsandperformempir- orautomaticgenerationforeachturn,ishelpfultoobtainsuch
icalverificationoftheneedforqueryrepresentationalignment understandingwiththesuitablydesignedmechanism.
inconversationalsearchanddesignseveraltrainingstrategiesin
QRACDR.(3)WedemonstratetheeffectivenessofourQRACDR 3.2 HypothesisVerification
oneightdatasetswithdifferentsettings,wherethebeststrategy Intuitively,anidealconversationaldenseretrieverisexpectedto
surpassesthestate-of-the-artCQRandCDRbaselines.Ouranalyses encodethesessionqueryrepresentationğ‘ğ‘  closetoitsrelevant
ğ‘›
helptounderstandthebehind-the-scenebehaviorofthemodels. documentsğ‘‘+.Inthiscase,minimizingthedistancebetweenğ‘ğ‘  and
ğ‘› ğ‘›
ğ‘‘+viaasingleMSElossfunctionwouldbedesirable.However,it
ğ‘›
2 RelatedWork doesnotworkasexpectedinpractice,duetothelimitationofusing
Conversationalsearchisaninformation-seekingprocessthrough onlyoneMSElossobjectiveforğ‘ğ‘  andğ‘‘+,whichonlyshrinksthe
ğ‘› ğ‘›
interactionswithaconversationsystem[53].Inpractice,itcanbe distancebetweenğ‘ğ‘  andğ‘‘+butdoesnotrestrictthelocationofğ‘ğ‘ 
ğ‘› ğ‘› ğ‘›
consideredasatasktoiterativelyretrievedocumentsforusersâ€™ intherepresentationspace.Thelocationofğ‘ğ‘  affectsthequery
ğ‘›
queriesinamulti-rounddialog.Tworesearchlinesareconducted representationalignmenteffect,whichwewillfurtherexplainin
toachieveconversationalsearch:conversationalqueryrewriting thefollowingsections.
(CQR)andconversationaldenseretrieval(CDR).TheCQRmeth-
3.2.1 TheImportanceofQueryRepresentationAlignment. Incon-
odstrytoconvertthecontext-dependentqueryintoastandalone
versationaldenseretrieval,twoassumptionshavebeenintroduced
query,andthenapplyanoff-the-shelfretrieverasthead-hocsearch.
in[52]:1)Therepresentationoftherewrittenqueryğ‘â€² andthe
Existingstudiestrytoselectusefultokensfromtheconversation ğ‘›
sessionqueryğ‘ğ‘  shouldbesimilarbecausetheysharethesame
context[15,24,47]ortrainagenerativerewritermodelwithcon- ğ‘›
underlyinginformationneeds.2)Therepresentationofmeaningful
versationalsessionstomimicthehumanrewrites[27,45,51].To
informationinadocumentremainsthesamewhetherservingad-
optimizequeryrewritingforthesearchtask,somestudiesadopt
hocorconversationalsearch,allowingforsharedrepresentation
reinforcementlearning[7,48]orapplytherankingsignalswith
inbothscenarios.Theassumptionsencouragebetterqueryrepre-
therewritingmodeltraining[30,35],whileothersjointlylearn
sentationalignmentbetweentherewrittenqueryandthesession
queryrewritingandcontextmodeling[41].Besides,somerecent
querytoachievebetterconversationalsearchresults.Thus,the
methodsareproposedtodirectlyprompttheLLMstogenerate
explicitsearchintentcontainedintherewrittenqueryğ‘â€²,which
therewrites[18,29,34,39,50].Ontheotherhand,conversational ğ‘›
couldbeaddressedbytheinitialad-hocsearchretriever,becomes
denseretrieval[28,42]directlyencodesthewholeconversational
acrucialfeaturetoachievethequeryrepresentationalignment.
searchsessiontoperformend-to-enddenseretrieval.Thecommon
practiceistoemploycontrastivelearningwithpositiveandneg- 3.2.2 HypothesisofAlignmentArea. Intuitively,weshouldencode
ativepassages.AlthoughasimilarConvDR[52]studyconsiders the session queryğ‘ğ‘  in an area around the rewritten queryğ‘â€²
ğ‘› ğ‘›
thealignmentbetweentheconversationsessionandthemanual andrelevantdocumentğ‘‘+ intherepresentationspace,i.e.,close
ğ‘›
queriesthroughknowledgedistillation,itdoesnotspecificallycon- toboththerewrittenqueryandtherelevantdocument.Toverify
siderthealignmentbetweenthesessionandtherelevantdocument ourassumption,weconductthepreliminaryexperimentsandre-
(northediscrepancywiththenegativedocuments)asourmethod portinTable1.Withthebackbonead-hocsearchdenseretriever
does.Besidesthat,existingmethodsalsotrytoimprovetheses- ANCE[49],wefirstencodetherelevantdocumentandtherewrit-
sionrepresentationthroughcontextdenoising[8,19,23,26,31,36], tenqueryasğ‘‘+ andğ‘â€² anddefinethealignedandnon-aligned
ğ‘› ğ‘›
dataaugmentation[6,9,32,38],andhardnegativemining[22,37]. representationsasEq.1.Thenwedirectlyperformretrievalwith
Differentfromthem,wecombinethesupervisionsignalfromboth them.FromTable1,weobserveahugeperformancegapbetween
CQRandCDRmethodstoachievequeryrepresentationalignment therepresentationwithandwithoutgoodqueryrepresentation
withtheoreticalandempiricalstudies. alignment.Inaddition,theoriginalrepresentationcannotdirectly
obtainsatisfactoryresults,indicatingthenecessityofconversa-
3 QueryRepresentationAlignmentHypothesis tionalfine-tuningandqueryrepresentationalignment.
inConversationalSearch Valign= (cid:0)ğ‘ ğ‘›â€² +ğ‘‘ ğ‘›+(cid:1)/2, Vnon-align= (cid:0)ğ‘ ğ‘›â€² âˆ’ğ‘‘ ğ‘›+(cid:1)/2 (1)
3.1 TaskDenfinition FromTable1,wecanseethereisahugeperformancegapbe-
FollowingtheliteraturedescribedinSection2,wedefinethecon- tweentherepresentationwithandwithoutgoodqueryrepresen-
versationalsearchtaskasfindingtherelevantdocumentsğ‘‘+from tationalignment.Inaddition,theoriginalrepresentationcannot
alargecollectionğ·tosatisfytheinformationneedsofthecurrent directlyobtainsatisfactoryresults,indicatingthenecessityofcon-
queryturnğ‘ basedonthegivenhistoricalconversationalcon- versationalfine-tuningandqueryrepresentationalignment.The
ğ‘›
textH = {ğ‘ ğ‘–,ğ‘Ÿ ğ‘–}ğ‘› ğ‘–=âˆ’ 11,whereğ‘ ğ‘– andğ‘Ÿ ğ‘– denotetheğ‘–-thqueryturn observationssuggestthatthereshouldbesomeareasintherepre-
andthesystemâ€™sresponse.Comparedwiththead-hocsearch,the sentationspacewithbetterqueryrepresentationalignmenteffect
currentqueryturnğ‘ iscontext-dependent,andthus,requiresthe whentherewrittenqueryandrelevantdocumentareconstrained
ğ‘›
retrievertoformulateasearchquerybyconsideringitscontext.A and available. To figure out such an aligned area, we assume a
commonpracticeistoreformulatethecurrentturnintoasession hyper-sphereSğœ– withradiusğœ–existsinthelearnedrepresentation
queryğ‘ ğ‘›ğ‘  =Hâ—¦ğ‘ ğ‘›byconcatenatingwiththecontextastheinput spaceX âˆˆ Rğ‘š,andSğœ– âŠ† X.Thesmallerrorğœ– âˆˆ RisdefinedasCIKMâ€™24,October21â€“25,2024,Boise,ID,USA FengranMoetal.
Table1:Preliminaryexperimentsforqueryrepresentationalignmenthypothesisverification,showingtheassumptionofthe
existingofâ€œalignedareaâ€forbettersessionqueryrepresentation.
TopiOCQA QReCC
Representation
MRR NDCG@3 Recall@10 Recall@100 MRR NDCG@3 Recall@10 Recall@100
Aligned(Valign) 89.7 90.1 96.5 99.3 94.1 92.2 96.5 98.2
Orignal(ğ‘â€²) 10.3 9.12 19.1 35.7 42.5 39.8 62.6 79.3
ğ‘›
Non-aligned(Vnon-align) 1.10 1.02 1.09 1.25 1.13 1.06 1.08 1.22
||ğ‘ ğ‘›ğ‘  âˆ’ğ‘‘ ğ‘›+||2.Thenthehyper-spherecorrespondingtothealigned
areaisdefinedas
Sğœ– ={ğ’™ âˆˆRğ‘š | ||ğ’™âˆ’ğ‘‘ ğ‘›+||2=ğœ–} (2)
Withoutanypriorknowledge,ğ‘ğ‘  isassumedtobeuniformly
ğ‘›
distributedonthesphereSğœ–.Sincetheavailablerewrittenquery
ğ‘â€² isalsopre-encoded,togetherwiththeobservationintheprelim-
ğ‘›
inaryexperiments,thereshouldbesomeareaswithbetterquery
representationalignmentimpactonthesphereSğœ–,wherewecalled
â€œalignedareaâ€inthispaper.Ourgoalofencodingğ‘ğ‘  istomakeit
ğ‘›
fallinthealignedarea.
Figure 2: A conceptual illustration of the defined hyper-
3.2.3 AlignedandNon-AlignArea. Inthissection,wefirstdefine sphereSğœ– andthecorrespondingconceptionsonit.There-
thealignedandnon-alignedareas,andthenweanalyzetheimpact
gionoutsidethehyper-spheredenotesthewholerepresen-
ofğ‘ğ‘  fallingineacharea.Intuitively,thealignedareaonthesphere
ğ‘› tationspaceX.Thegoalofachievingqueryrepresentation
shouldbearoundtheanchorğ’‚(intersectionpointofthelinecon- alignmentistoenablethelearnedsessionqueryğ‘ ğ‘›ğ‘  fallinto
nectingğ‘â€² andğ‘‘+onthesphere),whilethenon-alignareashould
ğ‘› ğ‘› thealignedareawiththehelpofthefixedrepresentationof
betheremainingarea.Theirdefinitionsare: rewrittenqueryğ‘ ğ‘›â€² andrelevantdocumentğ‘‘ ğ‘›+.
fineD defi asni tt hio en an3. c1 h( oA rn oc nho thr) e. sT ph he erp eo .intğ’‚ = ğœ– ||ğ‘ğ‘ ğ‘›â€²ğ‘›â€² âˆ’âˆ’ ğ‘‘ğ‘‘ ğ‘›+ğ‘›+ ||2 âˆˆ Sğœ– isde- theprobabilityofğ‘ ğ‘›ğ‘  landinginthealignedareawouldbepropor-
tionaltotheratio.Consideringthehighdimensionalityofexisting
Definition3.2(AlignedArea). Forğ›¼ âˆˆ [0,1),thespaceGğ›¼ ={ğ’™ âˆˆ PLMmodels,e.g.,BERT[13]with768embeddingsizes,theğ‘ ğ‘›ğ‘  lands
Sğœ– | ğ’‚ğ‘‡ğ’™ â‰¥ğ›¼}isdefinedasthealignedareaonthesphere. onthenon-alignedareawithhighprobabilityisinevitablewithout
||ğ’‚||Â·||ğ’™|| additionalconstraint.Fortunately,theavailablerewrittenquery
Definition3.3(Non-AlignedArea). ThespaceBğœƒ = {ğ’™ âˆˆ Sğœ– | ğ‘ ğ‘›â€² withexplicitsearchintentcouldhelpalleviatethissituation.
ğ’™ âˆ‰Gğ›¼}isdefinedasthenon-alignedareaonthesphere. Toachievequeryrepresentationalignmentbyenablingğ‘ ğ‘›ğ‘  tofall
inthealignedarea,adirectwayistominimizethedistancebe-
TheTo ale igla nb eo dr aa rte e, ağ’‚ isis deth fie ner des ac sal te hd ev see tct oo fr eo mf bğ‘ eğ‘›â€² dâˆ’ dinğ‘‘ ğ‘› g+ so wn ht oh se es cp oh se inre e. tweenğ‘ ğ‘›ğ‘  andğ‘ ğ‘›â€².Becausethedefinedanchorğ’‚isthecenterofthe
wsim hii ll ear ti ht ey nw oi nth -ağ’‚ ligis neg dre aa rt ee ar it sha dn efiğ›¼ n, ei d.e. a, sth the eh cy op mer p- ls ep mhe er ni tca ol fc ta hp e, a thli egn smed ala lere sa tda in sd tat nh ce ep wr io tj hec ğ‘t ğ‘›â€²io in no thf eğ‘ ğ‘›â€² wo hn ols ep rh ee pr re esS eğœ– n, tğ’‚ ats ioh nou sl pd ach eav Xe
.
Then,sincetherewrittenqueryğ‘â€² ispre-encodedandğ‘ğ‘  always
alignedareaonthesphere.Thesizeofthecapisaffectedbythe ğ‘› ğ‘›
existsonthesphere,minimizingthedistancebetweenğ‘ğ‘  andğ‘â€²
parameterğ›¼,thegreaterğ›¼,thesmallerthesizeofthecap(i.e.,the ğ‘› ğ‘›
forachievingqueryrepresentationalignmentisequivalenttobring
smalleralignedarea).Toprovideanintuitiveunderstanding,we
describesuchathree-dimensionalsphereasshowninFigure2.With
ğ‘ ğ‘›ğ‘  closertotheanchorğ’‚,i.e.,fallintothealignedarea.
theabovedefinition,Theorem3.4describestherelationbetween
dimensionsandtheprobabilityoflandingonthealignedarea1. 4 Methodology
4.1 ConversationalDenseRetrieval
Theorem3.4. Letğœ‡betheLebesguemeasure[17]onRğ‘› .Theratio
Acommonpracticeforconversationaldenseretrieverfine-tuning
of the measure of aligned area Gğ›¼ to the sphere Sğœ– is subject to
exponentialdecaywithrespecttoğ‘›: istodeploythecontrastivelearning(CL)lossontheğ‘›-thsession
queryğ‘ğ‘  withitsrelevantdocumentğ‘‘+andnegativesğ‘‘âˆ’ encoded
ratio=
ğœ‡(Gğ›¼)
â‰¤exp(âˆ’ğ‘›ğ›¼2 /2). (3)
byanağ‘› d-hocsearchretrieverasEq.4ğ‘› .Thereformulatğ‘›
edsession
ğœ‡(Sğœ–) queryğ‘ğ‘  istheconcatenationofthehistoricalcontext,whichis
ğ‘›
ThisTheorem3.4indicatesthattheratioofthemeasureonthe longandnoisy,withthecurrentquery.Theresultingquerycan
alignedareatothewholehyper-sphereisatleastexponentially hardlycapturepreciselytherealsearchintent.
smallwithrespecttothedimensionoftherepresentationspace.
1S Tin hece Tht eh oe res mes is si po rn ovq edue inry thğ‘ eğ‘›ğ‘  liti es rad tuis rt er [i 4b ,u 5,te 44d ]uniformlyonthesphereSğœ–,
LCL(ğ‘ ğ‘›ğ‘ ,ğ‘‘ ğ‘›+,ğ‘‘ ğ‘›âˆ’)=âˆ’log
exp(ğ‘ ğ‘›ğ‘  Â·ğ‘‘
ğ‘›+e )x +p (cid:205)(cid:0)ğ‘ ğ‘‘ğ‘›ğ‘  ğ‘›âˆ’Â· âˆˆğ‘‘ ğ·ğ‘›+ e(cid:1)
xp(ğ‘ ğ‘›ğ‘  Â·ğ‘‘ ğ‘›âˆ’)
(4)AligningQueryRepresentationwithRewrittenQueryandRelevanceJudgmentsinConversationalSearch CIKMâ€™24,October21â€“25,2024,Boise,ID,USA
4.2 QueryRepresentationAlignment inthesestrategies,weincorporatethequeryrepresentationalign-
Toenhancetheconversationalsearchability,accordingtotheafore- mentandusageof(hard)negativesinbothMSEandCLtogether
mentioned theoretical analysis (Section 3), we can leverage the asEq.9.
availablerewrittenqueries(eitherautomaticgenerationormanual
annotations)toinducethelearnedsessionqueryrepresentationin L Qco Rn At. =L Qba Rs Ae +LCL(ğ‘ ğ‘›ğ‘ ,ğ‘‘ ğ‘›+,ğ‘‘ ğ‘›âˆ’) (8)
theâ€œalignmentareaâ€.Toachievethis,astraightforwardandeffec-
t thiv ee sw esa sy ioi ns qto uee rm yp ğ‘l ğ‘ oy wt ih the bM oe than thS eq ru ea wre ritE tr er no qr u(M erS yE ğ‘) â€²lo as ns db te ht ew re ee len
-
L Qbo Rt Ah =L Qne Rg A. +LCL(ğ‘ ğ‘›ğ‘ ,ğ‘‘ ğ‘›+,ğ‘‘ ğ‘›âˆ’) (9)
ğ‘› ğ‘›
vantdocumentğ‘‘+.Comparedwithonlyminimizingthesimilarity
ğ‘› 5 ExperimentalSetup
betweenthesessionqueryandtherelevantdocument,deploying
anotherMSElosscanestablishthequeryrepresentationalignment 5.1 DatasetsandEvaluationMetric
toenablethesessionqueryğ‘ ğ‘›ğ‘  toapproachboththerelevantdocu- Datasets.Weusefiveconversationalsearchdatasetsandanad-
mentsğ‘‘+andtherewrittenqueryğ‘â€².Then,thetwooptimization hocsearchdataset[3]withthreesubsetsseparatelytoevaluate
ğ‘› ğ‘›
objectives ensure neither ||ğ‘ ğ‘›ğ‘  âˆ’ğ‘‘ ğ‘›+||2 = 0 nor ||ğ‘ ğ‘›ğ‘  âˆ’ğ‘ ğ‘›â€²||2 = 0, ourmethodsindifferentsettings.Alldatasetscontainavailable
butpushtherepresentationofğ‘ğ‘  tothebalancedanchorpointto rewrittenqueriesforeachoriginalqueryandthestatisticinfor-
ğ‘›
achieveabetteralignmenteffect.Besides,itenhancestherobust- mationisprovidedinTable2.TheTopiOCQA[1]andQReCC[2]
nessoftheretriever,becauseofthescarcityofrelevancejudgment datasetsareusedtotrainconversationaldenseretrieversforthe
annotationinexistingconversationalsearchdatasets,whilethere usualtraining-testevaluation.TheTopiOCQAcontainscomplex
shouldbemorerelevantdocumentsinreal-worldscenarios.Such topic-shiftphenomenawithinitsconversationsessions,whilethe
abasestrategyisshownasEq.5.Notethattherewrittenquery constructionofQReCCfocusesmoreonqueryrewriting.Thethree2
andrelevantdocumentsareonlyusedassupervisionsignalsinthe CAsTdatasets[10â€“12]withonlyafewsamplesareusedforboth
trainingphasetoobtainanalignedqueryrepresentation,whilenot out-of-domainzero-shotevaluation(i.e.,directlyapplythemodels
necessarilybeingusedduringtheinferencephase. trained on QReCC to the CAsT datasets) and in-domain cross-
evaluation (i.e., train models on two of the CAsT datasets and
evaluateontheremainingCAsTdataset).Thethreesubsetsin[3]
L Qba Rs Ae =MSE(cid:0)ğ‘ ğ‘›ğ‘ ,ğ‘‘ ğ‘›+(cid:1)+MSE(cid:0)ğ‘ ğ‘›ğ‘ ,ğ‘ ğ‘›â€²(cid:1) (5)
areusedtoexploreourmethodsinthead-hocsearchscenario.
Evaluation.Forathoroughcomparisonwithexistingsystems,
4.3 UsingHardNegatives we use four standard metrics: MRR, NDCG@3, Recall@10, and
Thenegativesplayanimportantroleinthetrainingofdensere- Recall@100toevaluatetheretrievaleffectiveness.Weadoptthe
trievalmodels,especiallythehardnegatives[21].Thougheffective, pytrec_evaltool[46]formetriccomputation.
theutilizationofnegativesislackinginthepreviousbasestrategy.
Toincorporatethehardnegative,wefurtheraddonemoreMSE 5.2 Baselines
losstomovethesessionqueryrepresentationğ‘ ğ‘›ğ‘  awayfromthe Wecompareourmethodwithtwolinesofconversationalsearch
hardnegativeğ‘‘Ë† ğ‘›âˆ’ asinEq.6. approaches.Thefirstlineperformsconversationalqueryrewriting
(CQR)basedongenerativerewritermodelsandoff-the-shelfre-
L Qne Rg A. =MSE(cid:0)ğ‘ ğ‘›ğ‘ ,ğ‘‘ ğ‘›+(cid:1)+MSE(cid:0)ğ‘ ğ‘›ğ‘ ,ğ‘ ğ‘›â€²(cid:1)âˆ’MSE(cid:16) ğ‘ ğ‘›ğ‘ ,ğ‘‘Ë† ğ‘›âˆ’(cid:17) (6) trievers,including(1)QuReTeC[47]:Aweakly-supervisedmethod
totrainasequencetaggertodecidewhethereachtermcontained
ThisstrategysharesasimilarsolutionwiththeCLparadigm,which inhistoricalcontextshouldbeusedtoexpandthecurrentquery.(2)
triestoenabletherepresentationofquerytowardtherelevantdocu- T5QR[27]:AstrongT5-basedmodelforqueryreformulation.(3)
mentsandkeepawayfromthenegativesduringthetraining.How- CONQRR[48]:AT5-basedmodelapplyingreinforcement-learning
ever,theutilizationofthehardnegativesinMSElacksanadaptive forqueryreformulation.(4)ConvGQR[35]:CombiningtwoT5-
gradientupdatecomparedtoCL.IntermsofCL,thederivativesof basedmodelsforqueryrewriteandqueryexpansioninqueryre-
LCLwithrespecttoğ‘ ğ‘›ğ‘  is: formulation.(5)EDIRCS[30]:Atext-editingmethodtoconstruct
thesearch-orientedconversationalquery.(6)IterCQR[18]:An
ğœ• ğœ•L ğ‘C ğ‘›ğ‘ L = (cid:18) (cid:205)ex exp p(ğ‘ (ğ‘ğ‘›ğ‘  ğ‘›ğ‘ Â·ğ’… Â·ğ’…)
)
âˆ’1(cid:19) ğ‘‘ ğ‘›++âˆ‘ï¸ (cid:205)ex exp p(ğ‘ (ğ‘ğ‘›ğ‘  ğ‘›ğ‘ Â·ğ’… Â·ğ’…) )ğ‘‘ ğ‘›âˆ’ (7) i st ie gr na at li sve feeco dbn av ce kr .sa (7ti )o In na sl trq uu ce tr oy rRref [o 1r 9m ]:u Ala nti uo nn sua ps eso rvc ii sa et ded cow ni vt eh rsI aR
-
ğ’…âˆ’
tionaldenseretrievalmethodinstructedbyLLM.(8)LLM-Aided
Thus,thecoefficient
exp(ğ‘ ğ‘›ğ‘ Â·ğ’…)
coulddynamicallyadjusttheweight
IQR[50]:Aninformativequeryrewritingmethodaidedbyprompt-
onğ‘‘âˆ’,whichenable(cid:205) thex ep a( dğ‘ ğ‘›ğ‘  apÂ·ğ’… t)
ivepenaltyonnegativesamples,i.e,
ingLLM.(9)Human-Rewritten[2]:Manualannotationsprovided
ğ‘› inoriginaldatasets.Thesecondlineconductsconversationaldense
ifğ‘ğ‘  isclosetoğ‘‘âˆ’,theweightonğ‘‘âˆ’ wouldbecomelargetokeep
ğ‘› ğ‘› ğ‘› retrieval(CDR)fine-tuningbasedonad-hocsearchdenseretriev-
themfurtheraway.Toinheritthisadaptivelearningmechanismfor
erstolearntherepresentationofthesessionquery,including(10)
hardnegative,weincorporatethequeryrepresentationalignment
CQE-sparse[26]:Aweakly-supervisedmethodtoexpandimpor-
mechanismwiththeCLasEq.8.Thecontrastiveparadigmcom-
tanttokensfromthecontextviacontextualizedqueryembeddings.
binedstrategycanalsoleveragethein-batchnegativemechanism
forpotentialbenefittoimprovetheconversationaldenseretriever
2TheCAsT-22testset[40]isdesignedformixed-initiativeconversationalsearch,
performance.Tofurtherexplorethecombinedimpactofnegatives whichisnotappropriateusedforourevaluationscenario.CIKMâ€™24,October21â€“25,2024,Boise,ID,USA FengranMoetal.
Table2:Statisticsofdatasetswithdifferentevaluationsettings.
TopiOCQA QReCC CAsT-19 CAsT-20 CAsT-21 Diamond Platinum Gold
Statistics
Train Test Train Test Test Test Test Train Test Train Test Train Test
#Conversations 3,509 205 10,823 2,775 20 25 18 - - - - - -
#Turns(Queries) 45,450 2,514 29,596 8,124 173 208 157 150,718 18,838 343,353 42,918 407,151 50,293
#Passages/Docs 25M 54M 38M 40M 8.8M
Thesecondlineperformsconversationaldenseretrieval(CDR), Thesuperioreffectivenesscanbeattributedtotwodifferentas-
whichareinitializedfromanad-hocsearchretrieverandfine-tunes pects.(i)Makingthesessionqueryrepresentationclosertoboth
withconversationalsearchdata.(11)ConvDR[52]:Aconversa- therepresentationofrewrittenqueriesandrelevantdocumentscan
tionaldenseretrieverfine-tunedfromANCEbymimickingtherep- betterhelpthefine-tunedconversationaldenseretrieveraddress
resentationsofhumanrewrites,whichhasasimilaralignmentgoal usersearchintentimplicitly.(ii)Incorporatingnegativesamples
andisamaincompetitorwithourmethods.However,asdiscussed withsuitablemechanisms,e.g.,adaptivenegativelearninginCL,
inSection2,thisworksdoesnotconsiderthealignmentbetween helpsachievebetterperformance(thanConvDRandConv-ANCE).
thesessionqueryandthegoldpassage(northemisalignmentwith (2)AmongdifferenttrainingstrategiesforourQRACDR,thebase
thenegativepassages).(12)SDRConv[22]ANCEfine-tunedon modelcanstillsurpassallcomparedsystemsonTopiOCQAwhose
conversationalsearchdatawithadditionallyminedhardnegatives. retrieversarethesameandachievecomparableresultsonQReCC,
(13)Conv-ANCE[33]:ANCEfine-tunedonconversationalsearch showingthesimplicityandeffectivenessofqueryrepresentation
dataonlyusingthecontrastiveloss,whichisanothermaincom- alignment.Besides,furtheraddinghardnegativescanimprovethe
petitortoourmethods.(14)HAConvDR[37]:ANCEfine-tunedon searchresults,andemployingthecontrastiveparadigmwithnega-
context-denoisingreformulatedqueryandadditionalsignalsfrom tivesisthebestvariant.Suchimprovementsindicatetheimportance
historicalturnsbasedontheimpactofretrievaleffectiveness.(15) ofincorporatingnegativesindenseretrievertraining.However,
LeCoRe[33]:Thecurrentstate-of-the-artmethod,whichextends simultaneouslyincorporatinghardnegativesinMSEandCLloss
SPLADEwithtwowell-matchedmulti-leveldenoisingmethods, functionswoulddamagethemodelperformance.Thismightbebe-
whichcannotbefairlycomparedwiththeothermethods.3 causetheeffectivenessofleveragingnegativesisfullyexploitedby
CL,whichhasabetteradaptivemechanismasdiscussedinSec.4.3.
5.3 ImplementationDetails (3)ComparingtheCQRandCDRmethods,weseethatCDRsys-
WeimplementtheconversationaldenseretrieverbasedonANCE[49] temsgenerallyhavebetterperformance(e.g.ConvDR,Conv-ANCE,
usingthePyTorchandHuggingfacelibraries.Theconversational andLeCoRe).ThismightbebecauseCQRistrainedtooptimize
denseretrieversarefine-tunedwitheachcorrespondingtraining queryrewritingonly,withouttakingintoaccountthequalityof
strategyLQRA.Followingpreviousstudies[33,36,52],onlythe searchresults.However,incorporatingtherewritesproducedby
sessionqueryencoderwillbetrainedwhiletheencodersforrewrit- CQRintoCDR,suchasConvDR,LeCoRe,andourQRACDR,can
tenqueriesanddocumentsarefrozen.Thelengthsofthequery furtherimprovetheretrievalperformance,suggestingthatcombin-
turn,sessionquery,anddocumentaretruncatedinto64,512,and ingCDRandCQRisbeneficial.Thisisalsotheintuitivemotivation
384,respectively,tofitthemajorityofexamplesinthedataset.The fordesigningourmethods,i.e.,makingqueryrepresentationalign-
batchsizeissetto32inaccordancetoourcomputationalresources. mentwithbothrewrittenqueryandrelevantdocument.Besides,
WeuseAdamoptimizerwith1e-5learningrateandsetthetraining weobservethatLLM-basedCQRsystems(IterCQRandLLM-Aided
epochto10.ThedenseretrievalisperformedusingFaiss[20].More IQR)andCDRsystems(InstructorR)cannotoutperformexisting
detailscanbefoundinourreleasedcode.4 state-of-the-artCDRsystems.Westillneedtofindabetterwayto
leverageLLM,possiblyinconnectionwithconversationalsearch.
6 Results
6.1 EvaluationResults 6.2 Low-resourceEvaluation
Wefirstconducttheusualtraining-testingevaluationonTopiOCQA Wethenconductlow-resourcetestingonthreeCAsTdatasetsto
andQReCCwithdifferenttrainingstrategies.Theoverallperfor- evaluatethetransferringabilitiesofourQRACDRandexplorethe
manceisshowninTable3.Wecanmakethefollowingobservations: impact of data distribution. The results are reported in Table 4,
(1)ThebestvariantsofourQRACDRconsistentlyoutperformall whichshowsthefollowingobservations:
comparedmethodsacrossfourmetricsontwodatasets,demonstrat- (1)ThegeneralizabilityofeachvariantofourQRACDRisdiffer-
ingsuperioreffectivenessonconversationalsearch.Weobserve ent,andthebaseQRACDRemployedwithhardnegativeperforms
thatourbestresultshave16.2%and1.2%NDCG@3relativegains thebestinboththeOODandIDscenarios.AmongOODsettings,
onTopiOCQAandQReCCoverthestate-of-the-artLeCoRe(based our best approach outperforms the compared systems on most
onSPLADE)and38.3%and7.7%NDCG@3gainsoverthesecond- metricsandachievescomparableresultsontheremaining,which
bestcomparedsystemwiththesameretriever(basedonANCE). confirmsthetransferringabilitiesofQRACDR.
(2)TheQRACDRmodelstrainedwithcontrastivelossdonot
3AllcomparedmodelsareinitializedfromANCEexceptLeCoReisfromSPLADE. performwellontop-rankresults,implyingthatitmightnotbe
SinceTopiOCQAandQReCCareopenbenchmarks,wecomparewiththeperformance
necessarytoincorporatetoomanymechanismsforthedesired
reportedinthecorrespondingbaselinepapers.
4https://github.com/fengranMark/QRACDR transferringability,thoughtheymightperformbetteronrecall.AligningQueryRepresentationwithRewrittenQueryandRelevanceJudgmentsinConversationalSearch CIKMâ€™24,October21â€“25,2024,Boise,ID,USA
Table3:Performanceofdifferentdenseretrievalmethodsontwodatasets.â€ denotessignificantimprovementswitht-testat
ğ‘ <0.05overeachofthecomparedCDRsystems.Boldandunderlineindicatethebestandthesecond-bestresults.
TopiOCQA QReCC
Category Method
MRR NDCG@3 Recall@10 Recall@100 MRR NDCG@3 Recall@10 Recall@100
QuReTeC 11.2 10.5 20.2 34.4 35.0 32.6 55.0 72.9
T5QR 23.0 22.2 37.6 54.4 34.5 31.8 53.1 72.8
CONQRR - - - - 41.8 - 65.1 84.7
ConvGQR 25.6 24.3 41.8 58.8 42.0 39.1 63.5 81.8
CQR
EDIRCS - - - - 42.1 - 65.6 85.3
IterCQR 26.3 25.1 42.6 62.0 42.9 40.2 65.5 84.1
LLM-AidedIQR - - - - 43.9 41.3 65.6 79.6
Human-Rewritten - - - - 38.4 35.6 58.6 78.1
CQE-sparse 14.3 13.6 24.8 36.7 32.0 30.1 51.3 70.9
InstructorR 25.3 23.7 45.1 69.0 43.5 40.5 66.7 85.6
SDRConv 26.1 25.4 44.4 63.2 47.3 43.6 69.8 88.4
Conv-ANCE 22.9 20.5 43.0 71.0 47.1 45.6 71.5 87.2
ConvDR 27.2 26.4 43.5 61.1 38.5 35.7 58.2 77.8
CDR HAConvDR 30.1 28.5 50.8 72.8 48.5 45.6 72.4 88.9
LeCoRe(SPLADE) 32.0 31.4 54.3 73.5 51.1 48.5 73.9 89.7
OurQRACDR 31.8 30.6 50.0 67.6 47.1 44.5 71.4 87.1
+negative 32.4â€  31.3 51.5 71.4 48.5 45.8 72.1 88.1
+contrastive 37.7â€  36.5â€  57.1â€  75.8â€  51.6â€  49.1â€  74.8â€  89.7
+both 34.6â€  33.5â€  54.4 74.0â€  50.9 48.3 74.1 88.9
Table4:DenseretrievalperformanceonthreeCAsTdatasets.Out-of-domain(OOD)denoteszero-shotevaluationbydirectly
applyingthemodelstrainedonQReCCtotheCAsTdatasets.In-domain(ID)denotescross-evaluationbytrainingmodelson
twooftheCAsTdatasetsandevaluatingontheremainingCAsTdataset.AllthecomparedsystemsaretestedwiththeOOD
setting.â€ denotessignificantimprovementswitht-testatğ‘ <0.05overthemaincompetitors,Conv-ANCEandConvDR.Bold
andunderlineindicatethebestandthesecond-bestresults.
CAsT-19 CAsT-20 CAsT-21
Method
MRR NDCG@3 Recall@100 MRR NDCG@3 Recall@100 MRR NDCG@3 Recall@100
QuReTeC 68.9 43.0 33.7 43.0 28.7 34.6 - - -
T5QR 70.8 42.6 33.2 42.8 30.7 35.3 36.3 24.9 29.0
ConvGQR 70.8 43.4 33.6 46.5 33.1 36.8 43.3 27.3 33.0
CQE-sparse 67.1 40.9 33.5 42.3 28.9 35.6 - - -
InstructorR 61.2 46.6 34.4 43.7 29.6 40.8 - - -
Conv-ANCE 66.2 40.1 29.2 42.5 26.5 31.6 36.3 23.5 34.3
ConvDR 71.7 43.9 32.2 43.9 32.4 33.8 45.6 36.1 37.6
OurQRACDR(OOD) 71.2 44.7â€  34.1â€  42.7 29.2 32.2 41.6 29.0 35.2
+negative 73.1â€  45.1â€  35.2â€  44.2â€  30.3 32.4 47.1â€  31.3 37.6
+contrastive 65.1 38.4 32.6 41.5 27.1 33.7 46.5 30.4 35.9
+both 64.5 37.6 32.8 39.5 25.6 33.3 44.9 29.4 36.0
OurQRACDR(ID) 63.7 39.9 29.7 38.0 25.8 27.4 41.5 26.2 32.6
+negative 64.6 40.4 30.8 38.4 25.9 27.1 43.4 28.2 31.5
+contrastive 61.1 36.3 27.8 36.6 22.0 28.6 43.0 28.0 32.3
+both 58.1 33.6 26.6 34.6 21.4 27.0 38.8 22.7 28.9
(3)ThemodelsinOODperformbetterthantheonesinID,which searchdata.(ii)Thedatadistributiongapbetweeneachdataset
mightbeattributedtotwoaspects.(i)Thoughthein-domaintrain- mightnotfitwithourintuition.Forexample,thedatadistribution
ingdatamighthavebetterdatadistribution,thesamplesarestill similaritybetweenQReCCwitheachCAsTdatasetmightbelarger
notenoughtoachievebetterretrievalperformance,comparedwith thanthatamongtheCAsTdataset,sinceeachCAsTdatasetiscon-
themodelstrainedwithmuchmoreout-of-domainconversational structedwithdifferentinformation-seekinggoalsandthetopicofCIKMâ€™24,October21â€“25,2024,Boise,ID,USA FengranMoetal.
Table5:EffectofincorporatingrewrittenqueriesandrelevantdocumentsviaourbaseQRACDRonfivedatasets.
TopiOCQA QReCC CAsT-19 CAsT-20 CAsT-21
MRR NDCG@3 MRR NDCG@3 MRR NDCG@3 MRR NDCG@3 MRR NDCG@3
BaseQRACDR(Eq.5) 31.8 30.6 47.1 44.5 73.1 45.1 42.7 29.3 41.6 29.0
w/oMSE(cid:0)ğ‘ğ‘ ,ğ‘â€²(cid:1) 30.8 29.4 40.8 38.4 59.2 35.3 34.2 22.8 39.9 25.1
ğ‘› ğ‘›
w/oMSE(cid:0)ğ‘ğ‘ ,ğ‘‘+(cid:1) 24.7 23.7 41.5 38.5 64.9 39.6 34.9 21.2 40.0 26.2
ğ‘› ğ‘›
lacksregularizationincalculatingquery-documentsimilarity.Thus,
ConvDR w/o Reg. ConvDR w/o Reg.
ConvDR w/. Reg. 70 ConvDR w/. Reg. wealsoinvestigatetheeffectofregularizationunderthesettingof
50 CL + MSE w/o Reg. Term CL + MSE w/o Reg. Term conversationaldenseretrieval(ConvDR).
CL + MSE w/o Neg. D.P. 60 CL + MSE w/o Neg. D.P.
40 50 MSE(ğ‘ ğ‘›ğ‘ ,ğ‘£)=||ğ‘ ğ‘›ğ‘  âˆ’ğ‘£||2 =||ğ‘ ğ‘›ğ‘  ||2 +||ğ‘£||2 âˆ’ 2Â·ğ‘ ğ‘›ğ‘  Â·ğ‘£ (10)
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)
30 40 (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
regularizedterm neg.dotproduct
30
20
TheresultsareshowninFigure3,wherewefindthatadding
20
10 regularizationimprovestheperformanceofConvDR,whichismore
10
significantonQReCC.However,itstillcannotsurpasstheperfor-
0 MRR NDCG@3 Recall@10 0 MRR NDCG@3 Recall@10 manceofourQRACDR,whichdemonstratesourapproachescan
(a) TopiOCQA (b) QReCC
betteraddressthesearchintent.Withinthedecompositionterms
Figure3:ImpactsofdecompositiontermsinMSEbasedon inMSE,theregularizationcontributesmoretoQReCC,whilethe
ourbestQRACDR(CL+MSE)andregularizationinConvDR. negativedotproductshowshigherimportanceonTopiOCQA.Intu-
itively,consideringthattheconversationsessionsaremorecomplex
conversationsessionsvariesfromeachyear.Thus,thelarge-scale andchallenginginTopiOCQA,thenegativedotproductmechanism
conversationalsearchdataarevaluableforbuildingtransferable shouldbemoreimportanttoenablesessionqueryrepresentation
conversationalretrievalmodels. ğ‘ğ‘  tobecomeclosertothealignedarea,whiletheregularization
ğ‘›
termpreventstheover-fittingontherelativelyeasyQReCC.
6.3 AblationStudies
Inthissection,wefirstconductablationstudiestoinvestigatethe 6.4 Ad-hocSearchScenariosAnalysis
effectsofincorporatingvariousfeaturesviaourbaseQRACDR. In this section, we explore our method to understand whether
Then,weexploretheimpactsofdifferentdecompositiontermsin leveragingavailablerewrittenqueriesisalsoeffectiveinad-hoc
combiningMSEandCLlossfunctions,whichisthebestvariantof searchviaalignmentofqueryrepresentation.
QRACDRinsupervisedevaluation. Table6showsthecomparisonamongmodelsusingQRACDR
(Eq.8),thecommonCLwithoutqueryrepresentationalignment
6.3.1 Supervisioneffectiveness. Table5showstheeffectivenessof (Eq.4),andwithoutfurtherfine-tuninginthreesubsetswithdiffer-
leveragingrewrittenqueriesandrelevantdocumentsinourbase
enttypesofrewrittenqueries[3].Thequalityofbothoriginaland
QRACDR(Eq.5)onfivedatasets.Weobservethatremovingany
rewrittenqueriesdecreaseswiththeorder:Diamond,Platinum,and
informationleadstoperformancedegradation,indicatingtheuse-
Gold,wheretheDiamondsethasthebestrewrittenqueries.Overall,
fulnessoftrainingthemodelwitheachinformation.Theutilization
ourQRACDRachievesvariousdegreesofimprovementacrossall
ofrewrittenqueriesismorecrucialthantherelevantdocuments,
metrics,whichdemonstratestheeffectivenessofthequeryrepre-
exceptinTopiOCQA.ThismightbeattributedtoTopiOCQAhaving
sentationalignmentmechanism.Theimprovementismuchlarger
lower-qualityrewrittenqueries,whichhavebeenautomatically
inthePlatinumandGoldthaninDiamond.Thismaysuggestthat
generated.Besides,theresultsshowthattheretrievercouldremain
ourmethodbasedonqueryrepresentationalignmentisparticularly
relativelyeffectivewhentrainedwithoutrelevantdocumentsuper-
effectiveinimprovingtheoriginalqueriesoflowerquality.
vision.Thisobservationindicatesthattherewrittenqueriescould
indeedprovideusefulsignalsforaligningwiththesearchintent.
6.5 LearnedQueryRepresentationsAnalysis
6.3.2 ImpactsofCombiningMSEandCL. Thebestvariantofour Inthissection,weanalyzethemodelbehaviorwithdifferenttrain-
QRACDR (Eq. 8) for normal evaluation is to combine the MSE ingstrategiesaccordingtotheirlearnedrepresentation.Toshow
functionandtheCLfunction.ComparedwithcommonlyusedCL, theeffectofqueryrepresentationalignment,thecomparisonsare
thecoreofQRACDRistheadditionaltwoMSEfunctionsaimingfor conductedamongthevariantsofourQRACDRandamaincom-
queryrepresentationalignment.Tobetterunderstandtheimpact petitorConvDR,withoutspecificqueryrepresentationalignment.
ofthemechanismsbehind,wefirstrewritethetwodeployedMSE Thisallowsustofullyattributethedifferenceinperformanceto
functionsintotwoterms,namely,aregularizedtermandanegative differentalignmentstrategies.
dotproducttermasinEq.10.Thus,theğ‘£ couldbeeitherğ‘‘ ğ‘›+ or Q-QSimilarities.Wefirstanalyzetheaveragedotproductsim-
ğ‘â€² inEq.5.Then,weanalyzethesetwodecompositiontermsby ilaritybetweentherepresentationofthesamequerylearnedby
ğ‘›
separately incorporating them with CL. Besides, the compared differentmodelsontwodatasets,whichisshowninFigure4.We
systemConvDRwithasimilaruseofrewrittenquerysupervision canfindthatthequeryrepresentationofConvDRisverydifferentAligningQueryRepresentationwithRewrittenQueryandRelevanceJudgmentsinConversationalSearch CIKMâ€™24,October21â€“25,2024,Boise,ID,USA
Table6:EffectofincorporatingourQRACDRapproachonthreead-hocsearchsubsetswithavailablerewrittenqueries.
Diamond Platinum Gold
Method
MRR NDCG@3 Recall@10 MRR NDCG@3 Recall@10 MRR NDCG@3 Recall@10
OurQRACDR 25.69 23.14 47.79 27.92 24.40 53.90 26.03 23.02 47.80
w/oQRA 23.90 21.23 46.78 19.21 15.79 39.69 23.08 19.99 43.96
w/oFine-tuning 23.37 20.64 41.95 17.79 14.23 33.80 21.83 18.65 41.81
740 TopiOCQA QReCC
55
50 Conv-ANCE (CL)
720 ConvDR
45 QRACDR-base
QRACDR-neg. 50
700 40 QRACDR-cont.
QRACDR-both
680 35
45
660 30
640 25 40
20
ConvDR QRACDR +neg. +cont. +both ConvDR QRACDR +neg. +cont. +both 620
(a) TopiOCQA (b) QReCC 15 35
2 4 6 8 10 12 14 2 4 6 8 10
Figure4:Modelbehaviorattheaveragedotproductscoreof Turn Turn
tworepresentationsofthesamequeryontwodatasets.
Figure6:ModelbehaviorattheNDCG@3scorewithdifferent
conversationturnsontwodifferentdatasets.
720 720
715 710
models.Weusetheirper-turnretrievalperformanceforevalua-
700
710 tion.AsshowninFigure6,theNDCG@3ofQRACDRvariants
690 dropsastheconversationgoeson,similartotheexistingsystems
705
(Conv-ANCEandConvDR).Thisisbecausethequeriesinlater
680 conversationturnsaremorelikelytodependonpreviousturns,
700
whilethetopic-shiftandlong-tailphenomenonmakesthecontext
670
695 dependencyhardertoresolve.Nevertheless,ourQRACDRmain-
ConvDR QRA (aC )D TR opiO+ Cn Qe Ag . - Mo+ deco lsnt. +both ConvDR QRAC (bD )R QRe+ Cn Ce g - . Mod+ elc sont. +both tainsitsperformanceaboveConv-ANCEandConvDRthroughout
theconversationturns,indicatingourqueryrepresentationalign-
Figure5:Modelbehaviorattheaveragedotproductscoreof menttechniquehelpstheretrievalmodeltocapturethecontext
queriesandtheirnearestrelevantdocumentsontwodatasets. informationrequiredtounderstandtheuserâ€™sinformationneeds.
fromourQRACDR.Thisshowsdirectlytheeffectofapplyingour
7 Conclusion
alignmenttechniques.Therepresentationdifferencesaremoredis-
tinctonTopiOCQAthanonQReCC,showingamorepronounced Inthispaper,weproposeamethodforconversationaldensere-
impactofqueryrepresentationalignmentinTopiOCQAforlonger trieverexploitingtheideaofqueryrepresentationalignment,QRACDR.
andmorecomplextopic-shiftconversations.Amongourproposed Itleveragesboththerewrittenqueryandtherelevantdocument
approaches,theincorporationofcontrastivelossornegativesalso tobetterdeterminetheusersearchintent.Severaltrainingstrate-
affectsthesimilarity. giesareproposedtoincorporatevariousinformationindensere-
Q-D Similarities. The effects on query representation also in- trieval.Experimentalresultsoneightdatasetswithdifferentsettings
fluencetheirsimilaritieswithrelevantdocuments.Asshownin demonstratetheeffectivenessofourmethods.Thedetailedanalysis
Figure5,thevariantofourQRACDRincorporatedwithcontrastive providesanunderstandingofthebehaviorofthemodelsandcon-
paradigmhasthehighestsimilarityonbothdatasets,whichiscon- firmstheeffectivenessofqueryrepresentationalignment.Inthe
sistentwiththepreviousmainevaluationofperformance(Table3). future,weplantoexplorebetterwaysofintegratingtheadvantages
Besides,thegapintheresultsismuchmoresignificantonTop- oftheCQRandCDRmethods,i.e.,amoreeffectivewaytofusethe
iOCQAandthemaincompetitorConvDRisstilllowerthanour representationofrewrittenqueriesandthecandidatedocuments,
proposedmethods,again,confirmingtheeffectivenessofquery tofurtherimprovetheperformanceofconversationalsearch.
representationalignmentonlengthyandcomplexconversations.
Acknowledgments
6.6 ImpactofContext This work is supported by a discovery grant from the Natural
Inthisexperiment,westudytheimpactofthecontext(multi-turn ScienceandEngineeringResearchCouncilofCanadaandaTalent
conversations)forthequeryrepresentationlearnedbydifferent FundofBeijingJiaotongUniversity(2024JBRC005).
htob+
.tnoc+
.gen+
RDCARQ
RDvnoC
tcudorP
toD
htob+
.tnoc+
.gen+
RDCARQ
RDvnoC
3@GCDNCIKMâ€™24,October21â€“25,2024,Boise,ID,USA FengranMoetal.
References LanguageProcessing.
[1] VaibhavAdlakha,ShehzaadDhuliawala,KaheerSuleman,HarmdeVries,and [25] VictorLavrenkoandWBruceCroft.2017.Relevance-basedlanguagemodels.In
SivaReddy.2022.TopiOCQA:Open-domainConversationalQuestionAnswering ACMSIGIRForum,Vol.51.ACMNewYork,NY,USA,260â€“267.
withTopicSwitching.TransactionsoftheAssociationforComputationalLinguistics [26] Sheng-ChiehLin,Jheng-HongYang,andJimmyLin.2021.ContextualizedQuery
10(2022),468â€“483. EmbeddingsforConversationalSearch.InProceedingsofthe2021Conferenceon
[2] RavitejaAnantha,SvitlanaVakulenko,ZhuchengTu,ShayneLongpre,Stephen EmpiricalMethodsinNaturalLanguageProcessing.1004â€“1015.
Pulman,andSrinivasChappidi.2021.Open-DomainQuestionAnsweringGoes [27] Sheng-ChiehLin,Jheng-HongYang,RodrigoNogueira,Ming-FengTsai,Chuan-
ConversationalviaQuestionRewriting.InProceedingsofthe2021Conference JuWang,andJimmyLin.2020. Conversationalquestionreformulationvia
oftheNorthAmericanChapteroftheAssociationforComputationalLinguistics: sequence-to-sequencearchitecturesandpretrainedlanguagemodels. arXiv
HumanLanguageTechnologies.520â€“534. preprintarXiv:2004.01909(2020).
[3] Negar Arabzadeh, Amin Bigdeli, Shirin Seyedsalehi, Morteza Zihayat, and [28] KelongMao,ChenlongDeng,HaonanChen,FengranMo,ZhengLiu,Tetsuya
EbrahimBagheri.2021. MatchesMadeinHeaven:ToolkitandLarge-Scale Sakai,andZhichengDou.2024.ChatRetriever:AdaptingLargeLanguageModels
DatasetsforSupervisedQueryReformulation.InProceedingsofthe30thACM forGeneralizedandRobustConversationalDenseRetrieval. arXivpreprint
InternationalConferenceonInformation&KnowledgeManagement.4417â€“4425. arXiv:2404.13556(2024).
[4] KeithBalletal.1997.Anelementaryintroductiontomodernconvexgeometry. [29] KelongMao,ZhichengDou,HaonanChen,FengranMo,andHongjinQian.2023.
Flavorsofgeometry31,1â€“58(1997),26. LargeLanguageModelsKnowYourContextualSearchIntent:APrompting
[5] AnjaBecker,LÃ©oDucas,NicolasGama,andThijsLaarhoven.2016.Newdirections FrameworkforConversationalSearch.(2023).
innearestneighborsearchingwithapplicationstolatticesieving.InProceedings [30] KelongMao,ZhichengDou,BangLiu,HongjinQian,FengranMo,XiangliWu,
ofthetwenty-seventhannualACM-SIAMsymposiumonDiscretealgorithms.SIAM, XiaohuaCheng,andZhaoCao.2023. Search-OrientedConversationalQuery
10â€“24. Editing.InFindingsoftheAssociationforComputationalLinguistics:ACL2023.
[6] HaonanChen,ZhichengDou,KelongMao,JiongnanLiu,andZiliangZhao. 4160â€“4172.
2024. GeneralizingConversationalDenseRetrievalviaLLM-CognitionData [31] KelongMao,ZhichengDou,andHongjinQian.2022.CurriculumContrastive
Augmentation.arXivpreprintarXiv:2402.07092(2024). ContextDenoisingforFew-shotConversationalDenseRetrieval.InProceedings
[7] ZhiyuChen,JieZhao,AnjieFang,BesnikFetahu,RokhlenkoOleg,andShervin ofthe45thInternationalACMSIGIRConferenceonResearchandDevelopmentin
Malmasi.2022. ReinforcedQuestionRewritingforConversationalQuestion InformationRetrieval.176â€“186.
Answering.(2022). [32] KelongMao,ZhichengDou,HongjinQian,FengranMo,XiaohuaCheng,and
[8] YiruoCheng,KelongMao,andZhichengDou.2024.InterpretingConversational ZhaoCao.2022.ConvTrans:TransformingWebSearchSessionsforConversa-
DenseRetrievalbyRewriting-EnhancedInversionofSessionEmbedding.arXiv tionalDenseRetrieval.InProceedingsofthe2022ConferenceonEmpiricalMethods
preprintarXiv:2402.12774(2024). inNaturalLanguageProcessing.2935â€“2946.
[9] ZhuyunDai,ArunTejasviChaganty,VincentYZhao,AidaAmini,QaziMamunur [33] KelongMao,HongjinQian,FengranMo,ZhichengDou,BangLiu,XiaohuaCheng,
Rashid,MikeGreen,andKelvinGuu.2022.DialogInpainting:TurningDocuments andZhaoCao.2023.LearningDenoisedandInterpretableSessionRepresentation
intoDialogs.InInternationalConferenceonMachineLearning.PMLR,4558â€“4586. forConversationalSearch.InProceedingsoftheACMWebConference2023.3193â€“
[10] JeffreyDalton,ChenyanXiong,andJamieCallan.2020.TRECCAsT2019:The 3202.
conversationalassistancetrackoverview.arXivpreprintarXiv:2003.13624(2020). [34] FengranMo,AbbasGhaddar,KelongMao,MehdiRezagholizadeh,BoxingChen,
[11] JeffreyDalton,ChenyanXiong,andJamieCallan.2021.CAsT2020:TheConver- QunLiu,andJian-YunNie.2024. CHIQ:ContextualHistoryEnhancement
sationalAssistanceTrackOverview.TechnicalReport. for Improving Query Rewriting in Conversational Search. arXiv preprint
[12] JeffreyDalton,ChenyanXiong,andJamieCallan.2022.TRECCAsT2021:The arXiv:2406.05013(2024).
conversationalassistancetrackoverview.InInProceedingsofTREC. [35] FengranMo,KelongMao,YutaoZhu,YihongWu,KaiyuHuang,andJian-YunNie.
[13] JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2019.BERT: 2023.ConvGQR:GenerativeQueryReformulationforConversationalSearch.
Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding.In InProceedingsofthe61stAnnualMeetingoftheAssociationforComputational
ProceedingsofNAACL-HLT.4171â€“4186. Linguistics.4998â€“5012.
[14] AhmedElgohary,DenisPeskov,andJordanBoyd-Graber.2019. CanYouUn- [36] FengranMo,Jian-YunNie,KaiyuHuang,KelongMao,YutaoZhu,PengLi,and
packThat?LearningtoRewriteQuestions-in-Context.InProceedingsofthe2019 YangLiu.2023.LearningtoRelatetoPreviousTurnsinConversationalSearch.In
ConferenceonEmpiricalMethodsinNaturalLanguageProcessingandthe9th
29thACMSIGKDDConferenceOnKnowledgeDiscoverandDataMining(SIGKDD).
InternationalJointConferenceonNaturalLanguageProcessing(EMNLP-IJCNLP). [37] FengranMo,ChenQu,KelongMao,TianyuZhu,ZhanSu,KaiyuHuang,and
5918â€“5924. Jian-YunNie.2024.History-AwareConversationalDenseRetrieval.arXivpreprint
[15] Hung-ChiehFang,Kuo-HanHung,Chen-WeiHuang,andYun-NungChen.2022. arXiv:2401.16659(2024).
Open-DomainConversationalQuestionAnsweringwithHistoricalAnswers. [38] FengranMo,BoleYi,KelongMao,ChenQu,KaiyuHuang,andJian-YunNie.2024.
InFindingsoftheAssociationforComputationalLinguistics:AACL-IJCNLP2022. ConvSDG:SessionDataGenerationforConversationalSearch.InCompanion
319â€“326. ProceedingsoftheACMonWebConference2024.1634â€“1642.
[16] JianfengGao,ChenyanXiong,PaulBennett,andNickCraswell.2022.Neuralap- [39] FengranMo,LongxiangZhao,KaiyuHuang,YueDong,DegenHuang,andJian-
proachestoconversationalinformationretrieval.arXivpreprintarXiv:2201.05176 YunNie.2024.HowtoLeveragePersonalTextualKnowledgeforPersonalized
(2022). ConversationalInformationRetrieval.arXivpreprintarXiv:2407.16192(2024).
[17] PaulRHalmos.2013.Measuretheory.Vol.18.Springer. [40] PaulOwoicho,JeffreyDalton,MohammadAliannejadi,LeifAzzopardi,JohanneR
[18] YunahJang,Kang-ilLee,HyunkyungBae,SeungpilWon,HwanheeLee,and Trippas,andSvitlanaVakulenko.2022. TRECCAsT2022:Goingbeyonduser
KyominJung.2023. IterCQR:IterativeConversationalQueryReformulation askandsystemretrievewithinitiativeandresponsegeneration.NISTSpecial
withoutHumanSupervision.arXivpreprintarXiv:2311.09820(2023). Publication(2022),500â€“338.
[19] ZhuoranJin,PengfeiCao,YuboChen,KangLiu,andJunZhao.2023.InstructoR: [41] HongjinQianandZhichengDou.2022.ExplicitQueryRewritingforConversa-
InstructingUnsupervisedConversationalDenseRetrievalwithLargeLanguage tionalDenseRetrieval.InProceedingsofthe2022ConferenceonEmpiricalMethods
Models.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023. inNaturalLanguageProcessing.4725â€“4737.
6649â€“6675. [42] ChenQu,LiuYang,CenChen,MinghuiQiu,WBruceCroft,andMohitIyyer.
[20] JeffJohnson,MatthijsDouze,andHervÃ©JÃ©gou.2019. Billion-scalesimilarity 2020.Open-retrievalconversationalquestionanswering.InProceedingsofthe43rd
searchwithgpus.IEEETransactionsonBigData7,3(2019),535â€“547. InternationalACMSIGIRconferenceonresearchanddevelopmentinInformation
[21] VladimirKarpukhin,BarlasOguz,SewonMin,PatrickLewis,LedellWu,Sergey Retrieval.539â€“548.
Edunov,DanqiChen,andWen-tauYih.2020.DensePassageRetrievalforOpen- [43] TaoTaoandChengXiangZhai.2007.Anexplorationofproximitymeasuresin
DomainQuestionAnswering.InProceedingsofthe2020ConferenceonEmpirical informationretrieval.InProceedingsofthe30thannualinternationalACMSIGIR
MethodsinNaturalLanguageProcessing(EMNLP).6769â€“6781. conferenceonResearchanddevelopmentininformationretrieval.295â€“302.
[22] SungdongKimandGangwooKim.2022.Savingdenseretrieverfromshortcut [44] TomaszTkocz.2012.AnUpperBoundforSphericalCaps.Am.Math.Mon.119,7
dependencyinconversationalsearch.InProceedingsofthe2022Conferenceon (2012),606â€“607.
EmpiricalMethodsinNaturalLanguageProcessing.AssociationforComputational [45] SvitlanaVakulenko,ShayneLongpre,ZhuchengTu,andRavitejaAnantha.2021.
Linguistics,10278â€“10287. Questionrewritingforconversationalquestionanswering.InProceedingsofthe
[23] AntoniosMinasKrasakis,AndrewYates,andEvangelosKanoulas.2022.Zero- 14thACMInternationalConferenceonWebSearchandDataMining.355â€“363.
shotQueryContextualizationforConversationalSearch.InProceedingsofthe45th [46] ChristopheVanGyselandMaartendeRijke.2018.Pytrec_eval:AnExtremely
InternationalACMSIGIRconferenceonresearchanddevelopmentinInformation
FastPythonInterfacetotrec_eval.InSIGIR.ACM.
Retrieval(SIGIR). [47] NikosVoskarides,DanLi,PengjieRen,EvangelosKanoulas,andMaartende
[24] VaibhavKumarandJamieCallan.2020.MakingInformationSeekingEasier:An Rijke.2020.Queryresolutionforconversationalsearchwithlimitedsupervision.
ImprovedPipelineforConversationalSearch.InEmpiricalMethodsinNatural InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchand
developmentinInformationRetrieval.921â€“930.AligningQueryRepresentationwithRewrittenQueryandRelevanceJudgmentsinConversationalSearch CIKMâ€™24,October21â€“25,2024,Boise,ID,USA
[48] ZeqiuWu,YiLuan,HannahRashkin,DavidReitter,andGauravSinghTomar. [51] ShiYu,JiahuaLiu,JingqinYang,ChenyanXiong,PaulBennett,JianfengGao,
2022.CONQRR:ConversationalQueryRewritingforRetrievalwithReinforce- andZhiyuanLiu.2020. Few-shotgenerativeconversationalqueryrewriting.
mentLearning.(2022). InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchand
[49] LeeXiong,ChenyanXiong,YeLi,Kwok-FungTang,JialinLiu,PaulNBennett, developmentinInformationRetrieval.1933â€“1936.
JunaidAhmed,andArnoldOverwijk.2020.ApproximateNearestNeighborNeg- [52] ShiYu,ZhenghaoLiu,ChenyanXiong,TaoFeng,andZhiyuanLiu.2021.Few-
ativeContrastiveLearningforDenseTextRetrieval.InInternationalConference shotconversationaldenseretrieval.InProceedingsofthe44thInternationalACM
onLearningRepresentations. SIGIRConferenceonResearchandDevelopmentinInformationRetrieval.829â€“838.
[50] FanghuaYe,MengFang,ShenghuiLi,andEmineYilmaz.2023.EnhancingConver- [53] HamedZamani,JohanneR.Trippas,JeffreyDalton,andFilipRadlinski.2022.
sationalSearch:LargeLanguageModel-AidedInformativeQueryRewriting.In ConversationalInformationSeeking.Found.TrendsInf.Retr.17(2022),244â€“456.
FindingsoftheAssociationforComputationalLinguistics:EMNLP2023.5985â€“6006. https://api.semanticscholar.org/CorpusID:246210119