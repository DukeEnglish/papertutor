TowardsUser-FocusedResearchinTrainingDataAttributionfor
Human-CenteredExplainableAI
ELISANGUYEN,T√ºbingenAICenter,UniversityofT√ºbingen,Germany
JOHANNESBERTRAM,T√ºbingenAICenter,UniversityofT√ºbingen,Germany
EVGENIIKORTUKOV,FraunhoferHeinrichHertzInstitute,Germany
JEANY.SONG,InformationandInteractionDesign,YonseiUniversity,SouthKorea
SEONGJOONOH,T√ºbingenAICenter,UniversityofT√ºbingen,Germany
WhileExplainableAI(XAI)aimstomakeAIunderstandableandusefultohumans,ithasbeencriticisedforrelyingtoomuchon
formalismandsolutionism,focusingmoreonmathematicalsoundnessthanuserneeds.Weproposeanalternativetothisbottom-up
approachinspiredbydesignthinking:theXAIresearchcommunityshouldadoptatop-down,user-focusedperspectivetoensureuser
relevance.WeillustratethiswitharelativelyyoungsubfieldofXAI,TrainingDataAttribution(TDA).WiththesurgeinTDAresearch
andgrowingcompetition,thefieldrisksrepeatingthesamepatternsofsolutionism.Weconductedaneedfindingstudywithadiverse
groupofAIpractitionerstoidentifypotentialuserneedsrelatedtoTDA.Throughinterviews(N=10)andasystematicsurvey(N=31),
weuncoverednewTDAtasksthatarecurrentlylargelyoverlooked.WeinvitetheTDAandXAIcommunitiestoconsiderthesenovel
tasksandimprovetheuserrelevanceoftheirresearchoutcomes.
CCSConcepts:‚Ä¢Human-centeredcomputing‚ÜíUserstudies;EmpiricalstudiesinHCI;‚Ä¢Computingmethodologies‚ÜíArtificial
intelligence;Machinelearning.
AdditionalKeyWordsandPhrases:Needfinding,TrainingDataAttribution,ExplainableAI,Human-centredExplainableAI
1 INTRODUCTION
UnderstandingAImodelbehaviouriscriticalforusingAImodelsinpractice,especiallyinhigh-stakesdomainssuchas
medicine,law,orfinance[55].End-usersrequiretheunderstandingofmodelbehaviourstomakeinformeddecisions,
whiledevelopersneedthistobuildreliablemodelswithlimitedbiases[16].ExplainableAI(XAI)aimstoprovideinsights
intoAIsystems‚Äôfunctioningforhumans.Ithasproducedavarietyofexplanationmethodsthataddressdifferentmodel
architecturesanddatamodalities[16,26].
Despitetheprogress,theXAIcommunityhasfacedcriticismforitspredominanttechno-centricfocusonsolutionsas
opposedtotheproblemofhelpingusersunderstandmodelbehaviour[18].Historically,XAIresearchprogressedbottom-
up:startingwithmethodsprovidingqualitativeobservations,thenstructuringthefieldwithquantitativeevaluations,
andeventuallyconsideringapplicationinreal-worldenvironmentsincludingusers(seeFigure1).Consequently,XAI
wasmainlydrivenby‚Äú[solutionism(seekingtechnicalsolutions)and]formalism(seekingabstract,mathematical
solutions)‚Äù[18,p.2].Anexampleofthisbottom-upapproachisthedevelopmentofthesubfieldoffeatureattribution.
Featureattributionexplanationsquantifyeachinputfeature‚Äôscontributiontothemodelprediction,highlightingkey
inputs.Oneofthefirstfeatureattributionmethodsinthecontextofdeeplearningwaspresentedin2013introducing
thevisualisationofneuralnetworkinputgradientsassaliencymapexplanationsandproviding15qualitativeexamples
asevidencethatsaliencymapsexplain[68].Severalothermethodsfollowed,eitherbuildingonthisworkandproposing
Authors‚Äôaddresses:ElisaNguyen,elisa.nguyen@uni-tuebingen.de,T√ºbingenAICenter,UniversityofT√ºbingen,Germany;JohannesBertram,T√ºbingen
AICenter,UniversityofT√ºbingen,Germany;EvgeniiKortukov,FraunhoferHeinrichHertzInstitute,Germany;JeanY.Song,InformationandInteraction
Design,YonseiUniversity,SouthKorea;SeongJoonOh,T√ºbingenAICenter,UniversityofT√ºbingen,Germany.
1
4202
peS
52
]CH.sc[
1v87961.9042:viXra2 Nguyen,etal.
Fig.1. Comparisonofbottom-upandproposedtop-downdevelopmentofresearchwithselectedexamplesfromXAI.
changestosatisfyspecificformalaxioms(e.g.,[69,70]),orproposingmodel-agnosticmethodsinaquestforaone-
fits-allsolution(e.g.,[47,63]).Around2017,XAIreachedaninflectionpointwhereresearchersstartedtore-assess
thepracticalityofexplanationmethodsandproposedstandardevaluationprotocolstomeasurehowwellexplanation
methodsachievetheirgoalofexplaining[1,8,15].Subsequently,recommendationsfromthesocialscienceviewof
explanationsemphasisethatexplanationsarepartofasocialprocessandshiftedthefocusofthefieldin2019[49].
XAIwascriticisedforitsstrongsolutionismwithanincreasingamountofworksstudyingXAIasasociotechnical
systemfocusingontheuser[10,18,19,23,38‚Äì40,44,48,65,76]andnamingthissubfieldhuman-centredXAI(HCXAI)
in2020[20].
DespitetheeffortstorectifythesolutionismandformalisminXAIcommunities,weobserverepeatingpatternsin
sub-fieldsofXAI.Forexample,suchpatternsareemergingintherelativelyyoungfieldoftrainingdataattribution
explanations(TDA),wherethemodelbehaviourisexplainedbasedonthetrainingdata[29].TDAwasintroduced
tounderstanddeeplearningmodelsin2017[41]andhasproducedseveraltechnicalapproachestoprovideTDA
explanationssincethen[4,13,27,54,61,66].Thisdevelopmentdemonstratesastrongfocusonseekingtechnical
solutionsintheTDAfieldsimilartohowfeatureattributionresearchstarted.Currently,TDAresearchisgaining
momentumduetostudiesshowingthatTDAcanbeappliedtoaddressissueslikedatavaluation,debiasing,memorisation
andcopyrightinfoundationalmodels[14,22,24,34,43,46,78,80].Yet,thecurrentTDAlandscapesshowssolutionism
andformalism,withfewuser-focusedstudies,leadingtoapossibleriftbetweenTDAmethodsanduserneeds.
Inthiswork,weproposefutureresearchdirectionsfortheTDAcommunitythatareentirelysourcedandmotivated
bythepotentialusersofTDA.Westronglybelievethattheactualusecasesanduserneedsshouldinformandguide
XAIresearch,echoingthecallforHCXAI[20].Webreakdownourresearchquestionintothreeparts:
‚Ä¢ RQ1:WhatdousersneedTDAexplanationsfor?
‚Ä¢ RQ2:WhatdousersneedfromTDAexplanations?
‚Ä¢ RQ3:TowhatextentdoexistingTDAapproachesalignwithuserneeds?
Weconductatwo-stageneedfindingstudywithpotentialusersofTDAtechnologytoanswerourresearchquestions.
ThroughaqualitativeinterviewstudywithAIpractitioners(N=10),weidentifymodeldevelopersasakeyusergroup
forTDAexplanationsasopposedtomodelusers.WederiveadesignspaceforTDAexplanationsrepresentingdifferent
TDAtasks(e.g.,identifyingthetrainingsampleswiththelargesteffectonmodelbehaviourwhenremovedincontrast
towhengivenalargerweightduringtraining).Westudywhichtasksareneededinmodeldevelopmentinasubsequent
mixed-methodssurveystudy(N=31)withmodeldevelopers.Byconsideringtheuserandtheirusagescenarios,we
identifytasksrelevanttousersbutlargelyoverlookedbycurrentTDAresearch.Weinvitetheresearchcommunityto
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 3
addressthesegapsandshiftthefocusofTDAresearchfromsolutionismtouser-servingquestions,i.e.,atop-down
approach.WeadvocateforadoptingthisapproachinotherareasofXAIandAIasawholetoavoidfocusingon
technicallyelegantsolutionsthatmayoverlookuserneeds.Ourcontributionsare:
‚Ä¢ Weproposeatop-downapproachtoXAIresearchdrivenbyuserneedsanddemonstratethisapproachonthe
emergingTDAsubfield.
‚Ä¢ Throughaneedfindingstudy,weidentifypotentialusecases,wheremodeldevelopersemergedaskeyusers
ofTDA.WefindthattheyrequireTDAexplanationstobe(1)flexibleandadapttotheuser‚Äôsintuitionsin
debuggingand(2)reliableandstable.Generally,weobserveapreferencefortrainingdatagroupattribution
overindividualattribution.
‚Ä¢ Asaresultofstudyingtheuserneeds,weidentifytasksandresearchdirectionsforuser-focusedTDAthatare
currentlyunderstudied.
2 RELATEDWORK
Ourworkproposesatop-downapproachtoXAIresearch,groundedinuserneeds,whichpositionsitinhuman-centered
explainableAI(HCXAI).Weapplythisapproachtotherelativelyyoungsubfieldoftrainingdataattribution(TDA)to
provideearlyinsightsintousersandtheirneeds.Tothisend,weutilisemethodsfromneedfinding.Inthefollowing,we
relateourworktoHCXAI,TDAandneedfinding.
2.1 Human-centredexplainableAI
TheaimofexplainableAI(XAI)researchistostudymethodsthatexplainthebehaviourofAImodels[26].Thefieldhas
developedvariousexplanationmethodsovertheyearstoexplaindifferenttypesoftasksandmodels.Yet,explanationsare
onlymeaningfulinfrontofanaudience.ThishumanaspectwasoftenneglectedinXAIstudies[50,64].Toovercomethis
gap,Human-centredXAI(HCXAI)emphasisesthehumanintheexplanationprocessandfocusesonuserperspectivesin
XAI[20].InHCXAI,explanationsofblack-boxmodelsarestudiedholisticallyassociotechnicalsystemscentredaround
theuser[19].HCXAIexploreshowtodesignAItechnologyandexplanationsthatfocusonuserunderstandingand
practicality[20].Workinthisareacoversmultipleaspectsthataffecttheuser,e.g.human-AI-collaboration[40,44,67,71],
designguidelines[28,45,76],evaluationofhumanunderstandingofexplanations[28,39,64,65]andunderstandinguser
needsandrequirements[10,35,37,38].OurworkcontributestotheHCXAIfieldbyproposinganearlyconsideration
ofuserneedstoinformongoingresearchinXAImethods.WefocusparticularlyonTDAexplanationswhichhavenot
beenexploredwidelyinHCXAIbefore.
2.2 Trainingdataattribution
Trainingdataattribution(TDA)explainsmodelpredictionsbypointingtotrainingdatasamplesrelevanttothemodel
predictions[29].TDAdiffersfromthemainstreamXAIapproachknownasfeatureattribution(FA)wherethemodel
predictionsareattributedtothefeaturesofaninputgiventothemodel,disregardingtheimpactoftrainingdata.Interest
inTDAhasrecentlyacceleratedwiththeparadigmshifttowardsdata-centricAI(DCAI)[36],wheretheimportance
ofusingtherighttrainingdataisemphasisedoverotherfactorslikemodelarchitectureandoptimisationalgorithms.
UnderthecontextofDCAI,TDAhasbeenutilisedtoenhancedataqualitybycleaningfaultydatalabels[72]and
detectingmodelbiases[11,34,60,77].Therecentriseoffoundationalmodels,suchaslargelanguagemodels(LLMs)
anddiffusion-basedimage-generationmodels,furthercontributedtotheinterestinTDA,asithasproveneffective
Preprint.Underreview.4 Nguyen,etal.
forstudyingtheinnermechanismsaswellasunderstandingtheassociatedcopyrightandprivacyleakageissues
therein[14,22,24,46,80].Withtheacceleratedgrowth,weobserveagainageneralfocusontechnicalandmathematical
solutionsintheTDAcommunity[4,13,14,27,41,43,54,61,66],withoutadeepunderstandingofuserneeds,evenin
studiesapplyingTDAtoadownstreamtasks[2,22,34,80].Ourworkaddressesthisgapbystudyingpracticalneeds
andprovidingconcreterecommendationsforthefield.
2.3 Needfinding
Needfindingisanexploratoryandqualitativeapproachtouserresearchtounderstandusers‚Äôneedsbeyondwhatsimply
askingusersmaytell[57].Itaimsatstudyingthetrueuserneeds,regardlessofsolutions,whichmaynotbeapparent
totheusersthemselves.Needfindingstemsfromthefieldofdesignthinking[74],whichisaniterativedesignapproach
drivenbyuserneeds.Needfindingisaniterativeprocessinvolvinguserswherethesubsequentstudiesextractgreater
informationabouttheirproblemsandneedsthroughfieldstudies,interviews,andlabstudies.InXAI,needfinding
hasbeenusedtostudygeneralneedssuchasuserexpectationsforXAI[10]orend-usertransparencyneedsinAI
decision-supportsystems[46,73]byusingsemi-structuredinterviews,scenario-basedstudydesignsandqualitative
analysesofcase-studyrelatedtextfiles.Needfindinghasalsobeenappliedtomorenarrowquestions,likeextractinguser
needsforweb-searchexplanationsthroughsurveysandsemi-structuredinterviews[37]orunderstandingexplainability
needsinhuman-AIcollaborations[40].Ourworkextendsthisoverallresearchdirectionbystudyingtheuserneedsof
TDAexplanationsthroughatwo-stagestudyinvolvingsemi-structuredinterviewsandasystematicsurveystudy.
3 TRAININGDATAATTRIBUTION
Ourworkstudiesuserneedsfortrainingdataattribution(TDA)explanations.ThissectionprovidesbackgroundonTDA.
TDAislinksspecificmodelbehaviourtothetrainingdata,treatingthedataastherootcauseforlearnedbehaviours[29].
Byprovidingtrainingdatarelevanttowhatthemodelhaslearnt,TDAgivesinsightsintothemodel.TDAhasbeen
appliedtoenhancingdataqualityandreducingmodelbiases,aswellasansweringquestionsarounddatavaluation,
memorisationandcopyrightissuesinfoundationalmodelsintherecentyears[14,24,46,80],attractingunprecedented
attention.
Formaldefinition. TheTDAcommunityhasfocusedonaparticularinstanceofattributingamodelpredictionona
singletestsampleonasingletrainingsample.Moreformally,letusconsideratrainingsampleùëß train:=(ùë• train,ùë¶ train)
andatestsampleùëß test:=(ùë• test,ùë¶ test),whereùë•indicatestheinputandùë¶indicatesthetrueanswerthemodelissupposed
topredict.Wedefinetheattributionscoreùúè forùëß trainandùëß testasthechangeinthecorrectnessofthemodelprediction
onùëß test,measuredviathemodellossL(ùëì ùúÉ(ùë• test),ùë¶ test),beforeandafterremovingthesampleùëß trainfromthetraining
procedure[30]:
(cid:16) (cid:17)
ùúè(ùëß train,ùëß test;ùëì ùúÉ):=L ùëì ùúÉ \ùëßtrain(ùë• test),ùë¶ test ‚àíL(ùëì ùúÉ(ùë• test),ùë¶ test). (1)
Here,weindicatethemodeltrainedwithalltrainingsamplesasùëì ùúÉ andtheonetrainedwithoutùëß trainasùëì ùúÉ \ùëßtrain.
MainfocusofTDAresearch. Computingùúè directlybyre-trainingamodelwithouteachtrainingsampleùëß train is
computationallyprohibitive.Toidentifythemostinfluentialtrainingsample,there-traininghastoberepeatedasmany
timesasthenumberoftrainingsamples.ThemainfocusoftheTDAcommunityhasbeenonefficientapproximationsof
Equation1.In2017,Koh&Liang[41]introducedagradient-basedapproximationcalledinfluencefunctions(IF).Since
IFwasstillcomputationallyprohibitiveduetotheneedtocomputeandinvertamassiveHessianmatrix,subsequent
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 5
worksin2020and2021havefocusedonspeedingupthealgorithmbytradingoffprecisionandcomputationalcosts
[13,27,61,66].AftertheadventofChatGPTinlate2022[53]andtheboominlargelanguagemodelsin2023[51],the
communityhasdevelopedfurtherenhancementstoapplytheTDAmethodsonbillion-scaleLLMs[4,14,24].
Critique. WeobservehintsofsolutionismandformalisminthedevelopmentofTDAresearch,asthemajorityof
thecommunityeffortisdedicatedtoaddressingcomputationalinefficienciesofthemethoditself,withoutquestioning
thepracticalrelevanceanduservaluesofTDAasdefinedinEquation1.ThisparticularformulationofTDAhasnot
gonewithoutcriticismwithinthecommunity:apriorwork[52]discussedthestatisticalinsignificanceofremovinga
singletrainingsampleinmodernneuralnetworktrainingand[33]recognisedthelimitationandarguedforexamining
theremovalofmultipletrainingsamples.SomeTDAworkshaveexploredpossibleapplicationsthatarepotentially
interestingtouserssuchasfixingmislabelleddata[41]oridentifyingbrittleclasses[33].However,theseapplications
arestillnotdrivenbyuserneeds.ThereisnoknownworkintheTDAdomaininvolvingactualuserstoidentifytheir
needstoassesstherelevanceofthecurrentTDAtasksandidentifyresearchdirectionsgroundedinuserneedsthatthe
communityshouldfocuson.
4 UNDERSTANDINGUSERNEEDSOFTDAEXPLANATIONSTHROUGHNEEDFINDINGSTUDY
Ourworkstudiesuserneedsoftrainingdataattribution(TDA)explanationstofacilitateuserneed-drivenTDAresearch.
Tothisend,weconductatwo-stageneedfindingstudy.First,weidentifyusecasesforTDAexplanationsusingsemi-
structuredinterviews.Theexperimentalsetupisdescribedin¬ß4.1.¬ß4.2presentstheinterviewfindings.Wederivea
designspacerepresentingdifferenttypesofinformationthatmaybeneededfromTDAin¬ß4.3.Second,weconducta
systematicsurveystudytargetedatextractinguserneedsfromthisspace(¬ß4.4).IRBapprovalwasobtainedfromone
oftheauthors‚Äôinstitutions.
4.1 Interviewstudy
Intheinterviewstudy,weconductsemi-structuredinterviewswithusersofmachinelearning(ML)applicationsoutside
ofMLresearch.Thisservesasanexploratorystudytogainanimpressionofpotentialusagescenariosanduserneeds
forTDARQ1‚ÄìWhatdousersneedTDAexplanationsfor?
4.1.1 Participants. TogetarealisticimpressionofuserneedsforTDAexplanationsinpractice,wetargetparticipants
whoworkwithMLapplicationsoutsideofacademia.Ourinclusioncriteriaare:Participantsshould(1)haveatleastone
monthofexperienceinworkingwithMLsystemsand(2)workinahigh-riskapplicationareaaccordingtotheEU
AIAct[55](e.g.,healthcare,lawenforcement,completelistinAppendixA).Thiscriterionservestofinduserswho
arelikelytouseexplanations,astheseareasaresubjecttofurtherregulations[15,26].Recruitingparticipantsposesa
challenge,especiallyinhigh-riskapplicationareas.Hence,weusepurposivesampling[25]andapproachparticipants
fromtheauthors‚Äônetwork.Werecruit10participantsfromvariousdomainsanddegreesofexperience(seeTable1).
4.1.2 Interviewprocess. TheinterviewswereconductedduringJune‚ÄìSeptember2023,eitherinpersonorremotely
throughvideocallusingZoom1.Allinterviewsareone-on-oneconversationsinEnglish,exceptforP10inGerman.
Participantswerefirstbriefedaboutthepurposeofthestudyanddataprocessing.Uponreceivinginformedconsent,we
begantheinterviewrecording.Ingeneral,theinterviewslastedbetween30and60minutes.Eachinterviewaddresses
thefollowingtopicstoanswerRQ1-WhatdousersneedTDAexplanationsfor?:
Preprint.Underreview.6 Nguyen,etal.
Table1. Interviewparticipantinformation.HR=Humanresources,AV=autonomousvehicles,TC=telecommunications,CV=
Computervisionforautomation.P5didnotmeettheinclusioncriteria.
ID Location Domain Type Jobexperience/withML TypeofML
P1 DE HR User 3years/1months Chatbot
P2 US AV Developer 2years/7years Predictionmodel
P3 NL TC Developer 3years/5years Predictionmodel
P4 FI CV Developer 4years/6years Predictionmodel
P6 CH Health User 2years/2years Predictionmodel
P7 NL Health Developer 1year/3years Predictionmodel
P8 BE Health Developer 2years/6years Predictionmodel
P9 PK Health Developer 5years/2years Predictionmodel
P10 DE HR User 3years/1year Chatbot
P11 DE Health User 10years/6years Clustering,Chatbot
‚Ä¢ Job-relatedinformation.Perspectivesmayvarybetweendifferentdomains,levelsofseniorityandexperience
withtheMLtool.Thisinformationprovidesusercontextandwillhelpindifferentiatingusergroups.
‚Ä¢ Interviewee‚ÄôsworkflowwithMLsystems.ByaskingabouttheworkflowwiththeMLtool,wewishto
understandthepatternsofusageandchallengesparticipantsencounter.Wecollectthisinformationtoidentify
challengesthatcouldpotentiallyaddressedbyTDA.
‚Ä¢ Perspectivesontrainingdata.SinceweinvestigateTDAexplanations,weexplicitlyaskparticipantsabout
theroletrainingdataplaysintheirtasks.Thisindicateswhattypeofdata-centricinformationisrelevanttothe
participant‚Äôsworkandforwhichtasks.
‚Ä¢ PerspectivesonXAIandTDA.Weaddresstheparticipant‚ÄôsperspectivesonXAIandparticularlyonTDAto
understandcurrentexplanationusagescenariosandexploreparticipant‚ÄôsopinionsaboutTDA,adata-centric
approachtoXAI.
4.1.3 Dataanalysis. WeanalysetheinterviewdataandextractrelevantinformationforansweringRQ1.Theinterviews
aretranscribedautomaticallyusingWhisper[62]andcleanedupmanuallybytheauthors.Thetranscriptisthen
pseudonymised.WetranslatedP10‚ÄôsGermantranscripttoEnglishusingDeepL2.Wethenanalysethetranscripts
throughaninductivethematicanalysis[9]bytwocoders,wherethecodesaredirectlyannotatedinthetranscript.The
analysisisiterative:TheinterviewtranscriptofP1isfirstjointlyanalysedinaninitialcodingworkshopthatresulted
inaninitialsetofthemes.Afterwards,thecodersindependentlycodefivetranscripts,expandingonthethemesfound
intheinitialanalysis.Duringanintermediatecodingworkshop,agreementsanddisagreementsbetweenthecoder‚Äôs
themesarediscussed.Theworkshopresultedinamergeddefinitionofthethemesthatareusedfortheremaining
transcripts.Attheintermediatecodingworkshop,theinterrateragreementis77.3%measuredbythepercentage
ofagreementparticipantscodedtothemes.Thefinalcodingworkshoptakesplaceafterbothcodersreviewedthe
remainingtranscripts.Thefinalinterrateragreementis80.3%.
4.2 Interviewfindings
TheinterviewstudyaimstoprovideinsightsintothepotentialusefulnessofTDA,answeringRQ1-Whatdousers
needTDAexplanationsfor?Theanalysisyieldssixthemeareas,whicharecommonacrossallparticipants(seelight
1https://zoom.us/
2https://www.deepl.com/translator
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 7
Fig.2. Themeareaswithcorrespondingthemesfoundintheinductivethematiccodinganalysisoftheinterviewtranscripts.Training
dataandTDArelatedthemesareorangeandmarkedwithastar.FulldescriptionofthemesinAppendixB.
greyboxesinFigure2):theroleoftheMLsystemasanapplication,theworkflowofparticipantswithMLsystems,
theroleoftrainingdataforparticipant‚Äôswork,themainchallengesinworkingwithMLsystems,theuseandroleof
explanationtools,andperspectivesandopinionsaboutdata-centricexplanationslikeTDA.Weelaborateoneacharea
belowandprovideafulloverviewinAppendixB:
4.2.1 RoleofMLsystems. OurparticipantsworkwithdifferenttypesofMLmodelsacrossseveraldomainsandin
differentpositions(seeTable1).WefindthatMLsystemsareusedasworkassistants(P1,P10,P11),decisionsupport
systems(P3,5,6,7,8,9),andforautomationinsystemslikeautonomousvehiclesormachinery(P2,P4).Theseroles
providecontextforouranalysis,astheneedsandusagescenariosofXAImaydifferbasedonthelevelofuserinteraction.
Forexample,P4developsautomatedcomputervisionmodelsforanimalpopulationmonitoringwithminimalhuman
involvement,whileP10usesachatbottohandlesmallertaskslikeansweringemployeequestions.Ouranalysisisset
againstthebackdropoftheseusecases.
4.2.2 WorkflowwithMLsystems. AsMLsystemstakedifferentroles,theworkflowsdiffer.WenoticethatMLsystems
arenotanessentialpartoftheworkflowforsystemusers,asopposedtodevelopers.Systemusersonlyintegratethe
MLsystemintheirworkwhenitdelivershelpfulsuggestionsandreportbugsorignoreitotherwise(P6,P10).We
recogniseaseparationofdomainknowledge(collaborationwithdomainexperts):‚ÄúBecausepersonally,Icannot
knowifthemodelisdoingthecorrectthing[...]businesshavetotellme"(P3).Fordeveloperswhosejobrevolves
aroundtheMLsystem,weidentifythemesthatarerelevantforunderstandingusagescenariosofXAIandTDA.We
findthatthedevelopmentworkflowisheavilycentredarounddata:‚Äú[What]drivesyourmodelisyourdata.[...]‚Äù(P8)
(data-focuseddebuggingprocess,dataqualitychecks).Often,standardmodelarchitecturesareemployedwith
standardhyperparameters(standardmodelchoices)andthemainworkliesindatacuration(P2,P4,P3,P7,P8,
P9).Thisthemeareashowsthattherearetwodistinctusergroups,systemuserswhoutiliseMLsystemsandmodel
developerswhobuildMLsystems.TheyhavedifferentworkflowsandpotentialXAIusecases.
Preprint.Underreview.8 Nguyen,etal.
4.2.3 Roleoftrainingdata. Thetrainingdataplaysdifferentrolestosystemusersandmodeldevelopers.Whileitis
themostimportantvariableinamodelfordevelopers(P3,P4,P8),trainingdataisgenerallynotinterestingto
systemusers(P1,P10).SystemusersoftendonothavecapacitytointeractmuchwiththeMLsystemtoverifymodel
behaviour,eveniftheyaninterestintheunderlyingmechanismsexists,becausetheyarepreoccupiedwiththeirown
tasks(interestingbutnocapacity)(P6).However,fordevelopers,trainingdataisaleverformodelperformance
(increasingtrainingdataasabugfix,trainingdataartifactsasmainbugcauses)(P2,P4,P3,P7,P8,P9,P11).
TheseinsightsunderlinethatXAIneedstobeintuitive,andTDAisparticularlysuitedformodeldevelopmentandless
forsystemusers.
4.2.4 ChallengesinworkingwithMLsystems. Intheinterviews,weaskparticipantsaboutchallengesintheirML
workflowtoexploreifXAIcanaddressthem.Weidentifiedsixthemesinthisthemearea.WeconfirmKimetal.‚Äôs[40]
observationthatsystemusers‚ÄômainchallengeforworkingwithMLsystemsistrustcalibration(P1,P6,P8,P11).
Inaddition,wefindthatsystemusersfeartheymaymisusetheMLsystemduetolackingknow-how(P1,P10,
P11),highlightingtheneedforusertrainingtomakeeffectiveuseofMLsystemsinpractice.Formodeldevelopers,we
identifyseveralchallenges:Dataqualityissuesareoftentherootcauseofmodelmalfunction(dataqualityissues)
(P2,P4,P3,P7,P8,P9,P11),inturnimpactingmodelvalidationandevaluation.Forinstance,participantsencounter
difficultiesduetomissingdataorabsentlabels(P2,P4,P3,P7,P8,P9).Additionally,resourceconstraints(P2,P4,P11)
andthestochasticnatureofMLmodels(P2)arepainpointsforthedevelopmentandevaluationofMLsystems.
Ouranalysisshowsthatthechallengesfacedbysystemusersrequiresociotechnicalconsideration,whereaschallenges
facedbymodeldevelopersaremoretechnicalwithdataqualityandevaluationbeingmostpressing.Webelievethatthe
latterisasuitableusagescenarioforTDA.
4.2.5 UseofXAIinpractice. ThisthemeareagroupssixthemesabouttheuseorlackofXAIinpractice.Ouranalysis
revealsthatXAIisusuallynotastandardpartofanMLsysteminpractice(XAIisnotused,XAIislittleused)
(P1,P4,P6,P7,P9,P10,P11).Infact,theusesofXAI,inparticularfeatureattribution,amongourparticipantsare
limitedtomodeldevelopment(P2,P3,P8).XAIoffersexplanationsforper-exampledebuggingoractasasanity
checkformodelreasoning(P8,P9).Unexpectedly,developerparticipantsalsouseXAItounderstandreal-world
phenomenamodelledbytheirMLsystem(P3)andasacommunicationmeanstogetcustomerbuy-infortheir
MLsystems(P8).Whileexplanationshavedifferentpurposes,wenotethatparticipantsuseXAItoolsmainlyasan
out-of-the-boxfunctionality(e.g.,theSHAPlibrary[47]).Wefindthatimplementationthresholdsmustbelowforthe
adoptionofXAIinpractice.
4.2.6 UserperspectivesonTDA. NoneoftheparticipantswerefamiliarwithTDA,highlightingagapbetweenresearch
andpractice.Ouranalysis,basedondiscussionsabouttheconceptofTDA,identifiesfourthemesreflectingparticipants‚Äô
viewsonXAIandTDA.Overall,participantsfindXAIusefulfordebuggingandcommunication,thoughtheynotedits
usefulnessisuse-casedependentandnotalwaysguaranteed.TheyexpectTDAnottobeanexception(P3,P6,P8,
P11),butareoptimisticaboutitspotential,especiallyformodeldevelopment.Forinstance,P2mentionedthatTDA
couldsavetimebyidentifyingfaultytrainingdata.OneparticipantsuggestedcombiningTDAwithfeatureattribution
fordebugging(P3).Weobservedthatparticipantshavedifferentnotionsofinterestingtrainingsamples,with
somefocusedonfindingfaultydata(P2,P11)andothersonidentifyingsamplessimilartoaspecificone(P6,P7,P8).
Inconclusion,weidentifythatTDAcouldbevaluableformodeldebugging,leadingustofocusonthisusergroup
andusecaseintheremainderofthiswork.
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 9
Table2. Codesbelongingtothemesdataqualityissuesanddifferentnotionsofinterestingtrainingsamplesthatcorrespond
tocommondebuggingusecasesandinterestingquestionsforTDAmentionedbyparticipantsintheinterviewstudy.
ThemeA:Dataqualityissues
ThemeB:Differentnotionsofinterestingtrainingsamples
ID Theme Code Description Participants
#1 A Distributionshifts Ifthedifferenceindatadistributionbetweentrain- P3,P4
ingandtestingdataistoolarge,themodeldoesnot
learn.Thiscanalsohappenovertime.
#2 A Dataunavailability Missingdataentriesormissinglabelsarecommon P2,P3,P7,P8,P9
problems,particularlyfortabulardata.
#3 A&B Wronglabels Annotationisanexpensivetasksubjecttohuman P2,P4
error.mislabelleddataishenceapossiblereason
formodelerror.
#4 A Datascaling Wrongdatascalingintabulardata(e.g.usingmeters P3
insteadofcentimetres)canleadmodelstolearn
wrongcorrelations.
#5 A Historicaldata Outdateddatathatisnotcleanedoutofthetraining P9
datasetcancontaminatethetraining.
#6 B Outlierdatapoints Dataoutliers,i.e.mislabelleddataor‚Äúunusualdata P3,P8
points‚Äù(P3)canaidformodeldebugging.
#7 B Decisionboundarysamples Samplesatdecisionboundaryareinterestingto P7
understandthemodelbehaviour.
#8 B High-confidencesamples Samplesthatthemodelissureabouttendtorepre- P7
sentwhatthemodelhaslearntandhelpinunder-
standingthemodelbehaviour.
#9 B Similartrainingsamples Trainingsamplesthataresimilarinfeaturestothe (P6),P7,P8
testsampleandhowthemodelbehavesontheseis
helpfulforunderstandingmodelbehaviour.
#10 B Groupofsamples Inspectingmultipletrainingsamplesisgenerally P8
moreinterestingtoestimatemodelbehaviour.
4.3 DefiningadesignspaceofTDAexplanations
TheinterviewanalysisrevealsmodeldevelopersasakeyaudienceforTDAexplanations,withmodeldebuggingasa
promisingusecase.BeforeaddressingRQ2‚ÄìWhatdousersneedfromTDAexplanations?,wetranslatethese
insightsintoadesignspaceofTDAexplanationsinmodeldebugging.Thespaceshallillustratehowexplanatory
informationabouttrainingsamplesandmodeloutputcouldlooklike,formingthebasisforthestudyaddressingRQ2.
Interviewparticipantsprovidedrichinformationaboutwhattheyusuallylookoutforinthetrainingdatawhen
debuggingamodel.Wecodedthisinformationintothefollowingthemes:Dataqualityissues,anddifferentnotions
ofinterestingtrainingsamples.WepresentthedescriptionsofthecorrespondingcodesinTable2andusethemto
identifydifferentaxesofinformationthatcouldberepresentedbyTDAexplanations.Specifically,wefindthatdifferent
dataartefactsaredebuggedusingdifferentactions,withusersinterestedinvariousmetricsandconsideringdifferent
numbersoftrainingsamples.Fromtheseobservations,wedefineathree-dimensionaldesignspace(seeFigure3).Inthe
following,wedetailthereasoningbehindeachaxisandconnectittothecodesinTable2viatheIDcolumn.
Preprint.Underreview.10 Nguyen,etal.
Fig.3. Three-dimensionaldesignspaceofTDAexplanationsrepresentingthetypeofdata-centricinformationusefultothemodel
developmentprocess.Derivedfromourinterviewstudyfindings.
4.3.1 Axis1:Actiondefiningrelevance. Thefirstaxiscorrespondstotheactionsparticipantsproposefordifferenttypes
ofdataartefacts:Removingdata,changingthelabel,reweightingdataandcollectingmoredata(x-axisofFigure3).
Participantslookatdatatoremovewhenitisclearlymaliciousdataandlikelyhurtsmodellearning,forinstance
mislabelled(#3)oroutdated,historicaldata(#5).Additionally,wefindthatparticipantslookfordatathattheywish
tochange,forexamplefillinginorimputingmissingdata(#2),orcorrectingwrongdatascales(#4)andlabels(#3).
Especiallywhendataishardtoobtain(e.g.inthemedicaldomain),removingdataisnotanoptionandcorrecting
dataispreferred(P6).Anotheractionisthereweightingoftrainingsamplesandcollectingmoredatarelatedtothe
error.Theseactionsemphasisespecificsamplesinthetrainingprocesstoencouragethemodeltolearnthem.Thisis
particularlyrelevanttolearningoutliers(#6)andhandlingdistributionshifts(#1).
Removal,changeandadditionofdatahavedifferenteffectsonamodelandthereforerepresentdifferentquantifications
ofattribution:Forinstance,removalasintraditionalTDA(Equation1in¬ß3)orbyadditionofdata.Essentially,these
examplesmaptothequestions:Howwouldthemodelbehaviourchangeifonewereto(a)excludeatrainingsample?
or(b)addmoretrainingsampleslikethetestsampletothedataset?Byunderstandingpreferencesinthisaxis,weaim
toidentifywhatisneededfordataattributiontobeactionableandreflectthedebuggingprocess.
4.3.2 Axis2:Metric. Thesecondaxiscorrespondstothesample-wisemetricsparticipantsusedwhenreferringto
modelbehaviour:theloss,theprobabilityofthetrueclasslabel,andtheprobabilityofthepredictedclasslabel(y-axis
ofFigure3).Theinterviewsshownotallparticipantsthinkofmodelbehaviourintermsofsampleloss,butalsoin
classificationprobability.Whilehighlosscanbeanindicatorforwrongoroutliersamples(#3,#6),participantsvoiced
theirinterestinsampleswherethemodelhashighorlowclassificationprobability (#7,#8).Suchsamplesprovide
contextoftheglobalmodelbehaviourtothemodeldeveloper,andcanthereforebehelpfulfortheirwork.
Themetriccanbeseenasameasurebywhichparticipantsprimarilyperceivemodelbehaviourinthedebugging
process.Byunderstandingmetricpreferences,weaimtoidentifythemetricthathelpsmodeldevelopersmostin
debugging,testingwhetherthelossasintraditionalTDAisthemostactionablemeasure.
4.3.3 Axis3:Numberoftrainingsamples. Thethirdaxiscorrespondstothenumberoftrainingsamplesparticipants
needtomakesenseofamodelerrorthroughthetrainingdata.Weidentifytwomainoptions:Asinglesampleanda
groupofsamples(z-axisofFigure3).Wefoundthatmodeldevelopersusuallydonotinspectjustonetrainingdata
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 11
Fig.4. Histogramsshowingtheanswerdistributionsforthepreliminarydemographicquestionsofthesurveystudy(N=31).DL=
Deeplearning.
samplebutthinkmoregloballyastheyusuallyrefertotrainingdataandsamplesinpluralform(#10).Thisaspectis
addressedinTDAresearchbyworksstudyinggroupattribution[7,42,54].Byunderstandingpreferencesinthisaxis,
weaimtoidentifywhetherindividualattributionlikeintraditionalTDAorrathertrainingdatagroupsneedtobein
focusofTDAresearch.
4.4 Surveystudy
Buildingonthefindingsoftheinterviewstudy,weaimtostudytheneedsofmodeldevelopersandunderstandwhat
kindofinformationisuseful,addressingRQ2‚ÄìWhatdousersneedfromTDAexplanations?Wedesignanonline
surveythatexploresthedesignspaceofTDAexplanations(seeFigure3)usingscenario-baseddesign[12].Wepiloted
thesurveytoensureclearphrasingandcompatibilityacrossdevices.DatawascollectedfromJune‚ÄìAugust2024.
4.4.1 Participants. Werecruitparticipantswithpriorexperienceindevelopingmachinelearningmodelstoclosely
alignwithpotentialrealusers.Torecruitexpertparticipants,weusedsnowballsamplingalongsidesocialmediaadson
XandLinkedIn,reachingouttocontactsandaskingthemtosharethestudylink.Weexpectthematicsaturationin
thequalitativeanalysisandmeaningfulstatisticsinthequantitativeanalysisataround30replies.Of34responses,we
excludedthreeforlow-qualityanswers(shortandnon-sensical),leaving31participants(ninefemale).18participants
workinindustrywhile14workinacademia,withmosthaving1-5yearsofmachinelearningexperience.Fourdonot
workwithdeepmodels.Participantscomefromdiversefields,includingbiology,health,logistics,andmore.Whilethe
datatypesusedbyparticipantsarediversetoo,themajorityofparticipantsworkwithimageortabulardata,asusedin
ourstudy(seeFigure4).Theparticipantswerecompensatedwith25‚Ç¨viaTremendous1.
4.4.2 Scenario-baseddesign. Themainpartofthestudyisconstructedwithscenario-baseddesign[12]tobasethe
analysisonatangibleusagescenario.Wecreatetwoscenariosofmodeldebugginginaninteractivemock-upofamodel
developmentsuite(seeFigure5).Thechoiceofdatatypes(imageandtabulardata)isbasedonthedominantmodalities
ofinterviewparticipants.Thestudyputsparticipantsintwoimaginaryscenarioswheretheyaremodeldevelopers
inacompanythatbuilds(1)abirdclassificationapp,and(2)acreditscoringapp.Thecompanyrecentlyacquireda
data-centrictooltohelpmodeldevelopersdebugtheirmodelsbyunderstandingerrorsandidentifyingtrainingdata
relevanttothoseerrors.Thetooliscustomisabletoadapttothedeveloper‚Äôspreferences.Thecustomisationchoices,
basedontheTDAdesignspace(seeFigure3)are:
1https://www.tremendous.com/
Preprint.Underreview.12 Nguyen,etal.
Fig.5. Screenshotoftheinterfaceusedinthebirdclassificationscenario.Thedarkpartsideshowsthemaininterfaceconsisting
oftheleftpanel(1)whichshowsinformationaboutthetesterrorandisstatic,andtherightpanel(2)whichshowsinformation
aboutthetrainingdataanalysisandisdynamic.Theinformationin(2)changesbasedonthechosensettingusingthecustomisation
controls(3)(expandablemenuwithlightbackground).
(1) Actiondefiningrelevance:(a)Removal,(b)Labelchange(tothenextmostlikelyclass),(c)Upweighting
(implementedwithafactorof10).Weomitnewdatacollectionbecauseitisdifficulttopredictwhatkindof
dataparticipantswouldliketoadd.Instead,wetakeupweightingasanapproximationofaddingnewdata.
(2) Metric:(a)Loss,(b)Groundtruthclassprobability,(c)Predictedclassprobability.
(3) Numberoftrainingsamples:Participantscanchoosebetweenthe1‚Äì10trainingsamplestoinspect.We
limitthenumberto10toexplorepreferencesformoretrainingsampleswhilekeepingcomputationeffortslow.
Inbothscenarios,participantsarepresentedwithaspecificmisclassificationasthemodelerror(leftsideofFigure5).
Thiserrorisrandomisedacrossparticipantstopreventbiasfromaspecificsample.Participantsareaskedtochoose
whichtypeoftrainingdata-relatedinformation(rightsideofFigure5)ismostusefultounderstandthereasonsforthe
error.Thisway,weaimtoelicitparticipants‚Äôintuitionsaboutthemostactionableinformationfordebuggingthemodel
error.Participantsareencouragedtoexploredifferentsettingsandsubmittheirdesiredcustomisationtocompletethe
task.Thedataforthesescenarioswasgeneratedusingrealmachinelearningmodelsandopenlyavailabledatasets.We
detailthedatagenerationprocessinAppendixC.
4.4.3 Surveystructure. ThesurveystructureisshowninFigure6.Participantsarefirstbriefedonthestudy‚Äôsobjective
anddataprocessing.Afterprovidingconsentandconfirmingtheymeetinclusioncriteria,theyareaskedpreliminary
demographicquestionsforcontexttothelateranalysis.Intheremainingstudy,weaimtoextracttheparticipant‚Äôs
preferences through a usage scenario (¬ß 4.4.2). The participants are presented with the scenario description and
promptedwith‚ÄúImagineyouareamodeldeveloperinacompany[...]‚Äùtoimmersethemintheusecase.Then,weask
theparticipantsfollow-upquestionstounderstandthereasoningbehindtheirchoicesthroughfree-textquestions.
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 13
Fig.6. Structureofthesurvey.
Thesefree-textquestionsareaboutunderstandingtheparticipants‚Äôintuitionsofwhythemodelmayhavemadean
error,andhowtheywouldfixit.Aftercompletingoneusecase,theparticipantsarepresentedwiththeotherusecase,
wheretheorderisrandomisedacrossuserstopreventanorderbias.
4.4.4 Dataanalysis. Weanalysethesurveystudybothquantitativelyandqualitatively.Forthequantitativeanalysis,
weaimtounderstandwhetheraspecificnotionofTDAispreferredacrossparticipantsbecausepreviousTDAstudies
havebeencentredaroundasinglenotionofTDA(¬ß3).SincethetraditionalTDAsettingisalreadyapartofthedesign
space,studyingpreferencesgivesananswertowhetherparticipantsreallypreferredthisparticularscenario.Wefurther
assessifparticipantspreferaspecificscenario‚Äî-ifnot,itisastrongsignalthattheresearchshouldbediversifiedinto
multiplepossiblescenariosservingdifferentuserneeds.
To this end, we compute the distribution of the participants‚Äô choices (action, metric and number of samples).
Furthermore,wetestwhetherthecollecteddataindicatesastatisticallysignificantpreferenceforaspecificsetting.We
performaùúí2testasthedataiscategorical[58].Forthenumberoftrainingsamplesaxis,weperformFisher‚Äôsexacttest
asthechoicefrequenciesarelow[17].Specifically,ourhypothesesare:
ùêª 0:ThereisnoclearpreferenceforaspecificTDAsetting.
ùêª 1:ThereisaclearpreferenceforaspecificTDAsetting.
Inotherwords,wetestthegoodnessoffitofourobservationsagainstauniformdistributionacrosscategoriesofan
axis.Sinceweconductmultipletestsonthesamedata,weapplyaBonferronicorrection[79]anddefinestatistical
significanceatùëù <0.05.Additionally,wecomputeeachaxiscategory‚ÄôsentropyH(X)andnormalisedentropyH(X)
norm
(normalisedbylog (ùëò)withùëòasthenumberofcategoriesinanaxis,e.g.threeforthemetricaxis)togetanindicator
2
ofthediversityofpreferences[3].
‚àëÔ∏Å
H(X)= ùëù(ùë•)logùëù(ùë•) (2)
ùë•‚ààX
Iftheentropyishigh,theparticipant‚Äôspreferencesarehighlydiverse,meaningthereisnoagreementonacertain
preferrednotionoftherelevanceoftrainingdata.
Thequalitativeanalysisaimstounderstandthereasonsbehindparticipantchoicesandgetdeeperinsightinto
userpreferences.Thefree-textresponsesinthefollow-upquestionsareanalysedusinginductivethematiccoding[9]
bytwocoders.Perquestion,weanalysethecommonthemesamongparticipantstoextractthereasonsbehinduser
preferencesandneeds.TheanalysisconsistsofseveralcodingworkshopsandisdepictedinFigure7.Wemeasure
interrateragreementbythepercentageofoverlappingthemes.Thefinalagreementis97.1%.
Preprint.Underreview.14 Nguyen,etal.
Fig.7. Iterativethematicanalysisprocessshowingtheevolvementofthemesandinterrateragreement.
4.5 Surveyfindings
WeconductthesurveystudytoanswerRQ2‚ÄìWhatdousersneedfromTDAexplanations?Thesurveydata
analysisindicatesaclearconnectionbetweenusers‚ÄôintuitionofwhatcausesamodelerrorandtheirTDApreferences.
Weelaboratefurtherinthefollowing.
4.5.1 Quantitativeresults. Thequantitativeanalysisbuildsonthecustomisationchoicesofthedebugginginterface
(seeQuantitativedatacollectioninFigure6).Table3showsthefrequencyofselectionsandtheassociatedp-values.
Wetestifthereexistsasettingofaction,metricandnumberoftrainingsampleswhichisconsistentlychosenand
particularlyusefultomodeldevelopers.Weareespeciallyinterestedinwhetherthereisaclearpreferenceforremoval,
lossandonetrainingsampleasthesecorrespondtothetraditionalnotionofTDAintroducedin¬ß3.Fortheaction
axis,thereisnostatisticallysignificantpreferenceforanychoiceandthedistributionisratheruniformacrosschoices.
Whiletheresultsmayshowahigherfrequencyofparticipantschoosinglossasametric,weobservenostatistically
significantpreference.Hence,wefailtorejectùêª 0fortheactionandmetricaxesandconcludethatthereisnodominant
preferenceforaparticularTDAsetting.Forthenumberofsamplesaxis,however,wefindastatisticallysignificant
preferenceforagroupof10samples.
Theentropyanalysissupportsthisconclusion(seeTable4).Asameasureofdiversity,normalisedentropyscores
rangefrom0.588to0.997,showingahighlydiverse(>0.5)distributionofchoices.ThisisespeciallytruefortheAction
definingrelevanceandMetricaxeswithhighscores(>0.8).Thereislessdiversityinthenumberoftrainingsamplesbut
aclearpreferenceforchoosinggroupsofsamples,confirmingIlyasetal.‚Äôs[33]intuitionsforstudyinggroupattribution.
In conclusion, the quantitative analysis reveals that the preferred TDA explanations represent highly diverse
informationwithaclearneedforgroupattribution.
4.5.2 Qualitativeresults. Theinductivethematiccodinganalysisofthefree-textanswersresultedinfourthematic
areasandthemetypescovering30themes(seeFigure8):(1)Actiondependsontheuser‚Äôshypothesis,(2)Individual
metricpreferences,(3)Groupattributionpreferences,and(4)Reliabilityofexplanations.Forthethemetypes,we
findthemesthatcorrespondtotheuser‚Äôshypothesisabouttheerrorandobservethattheseareoftencodedtogether
withacorrespondingproposedaction.However,preferredmetricsandpreferrednumberoftrainingsamplesdonot
correspondtotheuser‚Äôshypothesis.Additionally,weidentifyfourthemesthatdonotcorrespondtoanycategorybut
giveinterestinginsightsandcontexttotheanalysis.ThefulldescriptionofeachthemeisinAppendixD.
Actiondependsonuser‚Äôshypotheses. Thethematicanalysiscomplementsourquantitativefindings:Userpreferences
inmodeldebuggingarehighlyindividual.Theanalysisprovidesareason:Individualpreferencesareoftenlinkedtothe
user‚Äôsunderstandingandintuitions,inotherwords,theirhypothesisaboutanerror.Theuser‚Äôshypothesisdetermines
theircourseofaction.Hypothesesarehighlyindividualbecauseusersformulatethembasedontheirexpertiseandpast
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 15
Table3. Quantitativeanalysisofaxeschoicesacrossparticipantsinthefrequencyofchoice(%)fortheimageandtabularusecase,as
wellastogether.ùëùdenotestheBonferroni-correctedp-valuecomputedfromtheùúí2testforstatisticalsignificance.GT=Groundtruth.
NumberofSamples
ActionandMetric
Image Tabular Both
Image Tabular Both Choice % ùëù % ùëù % ùëù
Choice % ùëù % ùëù % ùëù
Num.ofsamples
Action
1 0.00% 1 0.00% 1 0.00% 1
Removal 33.33% 1 41.97% 1 37.70% 1 2 0.00% 1 0.00% 1 0.00% 1
LabelChange 30.00% 1 16.13% 1 22.95% 1 3 3.33% 1 9.68% 1 6.56% 1
Upweighting 36.67% 1 41.94% 1 39.34% 1 4 6.67% 1 3.23% 1 4.92% 1
5 13.33% 1 19.35% 1 16.39% 1
Metric
6 3.33% 1 3.23% 1 3.28% 1
Loss 60.00% 1 35.48% 1 47.54% 1 7 0.00% 1 3.23% 1 1.64% 1
Pred.cls.prob. 10.00% 1 41.94% 1 26.23% 1 8 3.33% 1 0.00% 1 1.64% 1
GTclassprob. 30.00% 1 22.58% 1 26.23% 1 9 3.33% 1 0.00% 1 1.64% 1
10 66.67% <0.001 61.29% 0.002 63.93% <0.001
Table4. Resultsoftheentropyanalysisperaxisasameasureofdiversity.
Image Tabular Both
Axis H Hnorm H Hnorm H Hnorm
Action 1.095 0.997 1.023 0.931 1.073 0.976
Metric 0.898 0.817 1.068 0.972 1.056 0.961
Num.samples 1.173 0.603 1.176 0.657 1.224 0.588
experiences.Forexample,weidentifiedthethemeoflowdatasetdiversityasahypothesisparticipantshaveabouta
modelerror:‚Äú[Images][...]inthetrainingsetarenotdiverseenough‚Äù,‚Äú[Oneclass]wasnotrepresentativeenough‚Äù.
Correspondingtothishypothesis,participantsoftensuggestedaddingnewdataorapplyingdataaugmentationsto
diversifythetrainingset,whichweidentifiedascollectspecificnewdataandsynthesise/augmentdatathemes.
Individualmetricpreferences. Forindividualmetricpreferences,weidentifyalinkwiththetaskathand.Inthecase
ofbinaryclassification,participantsshowedapreferenceforprobabilitymetrics,asitiseasiertounderstandthanthe
lossandallowsaninspectionofthedecisionboundary(‚ÄúThelossisnotveryintuitive‚Äù).Inmulti-classclassification,
moreparticipantspreferredthelossasitconsidersallpossibleclasses(‚Äú[Theloss]containsinformationonallclasses‚Äù).
However,asthequantitativeanalysisshows,thesedifferencesinpreferencearenotstatisticallysignificant.Therefore,
themetricpreferencesarelikelyindividualtotheuserandtheirhabits.
Groupattributionpreferences. Thequantitativestudyshowsaclearpreferenceforattributiontogroupsoftraining
samplesasopposedtoindividualtrainingsamples.Thequalitativeanalysisfindsthatthisisduetotheuser‚Äôsneedfor
havingagoodoverviewofthemodelerror.Inspectingagroupoftrainingsamplesprovidesabetteroverviewthana
singlesample,andallowstheusertounderstandwhethertheirhypothesisabouttheerrorisvalidornot(Groupfor
overviewoftheerror).Asecondthemehighlightsanotherangle:Whilevarietyinthegroupisdesiredforagood
overviewoftheerror(e.g.groupconsistingofsampleswithdiversefeatures),thegroupshouldbeconciseenoughto
‚Äúkeeptheanalysismanageable‚Äù(Balancebetw.varietyandconciseness).
Preprint.Underreview.16 Nguyen,etal.
Fig.8. Themeoverviewfromthequalitativeanalysisofthesurvey.Thethemesgiveinsightintoparticipants‚Äôreasonsfortheirchoices
andneedsforreliabilityandacomprehensiveunderstandingoftheerror.Wefinddifferentthemetypes,indicatedbycoloursand
shapes:Hypothesesabouttherootcauseofmodelerroraremarkedwithacircle,preferredactionswithaplus,preferredmetrics
withastar,preferrednumberoftrainingsampleswithatriangle.FulldescriptionsofthethemesinAppendixD.
Reliabilityofexplanations. Ouranalysisfindsthatsomethemesarerelatedtotheoverallconceptofexplanation
reliability,whereparticularlythechoiceofhowmanytrainingsamplestoinspectisassociatedwithreliability.Partic-
ipantsstatedthatgroupsizesshouldbelargeenoughfortheattributionscorestobereliable.Atthesametime,
hegroupsizeshouldbesmallenoughtoensurereliableattributionscores,aschangingthedatasetcouldchangethe
model‚Äôsreasoning(Smallgrouptopreventreasoningchange).Weinterpretthisneedforreliabilitytoreflectin
themotivationtouncovercausaleffects(‚ÄúByremoving[...]Icandetermineif[thetrainingsamples]werecausing
confusionwithinthemodel‚Äù).
Unintendedthemes. Weidentifiedfourunintendedthemesoutsidethestudydesignthatprovideadditionalcontext.
Wenoticedthatparticipantsfocusedeitheronthemodelerror(Focusonmodelerror)orthefinalaccuracy(Focuson
finalaccuracy).Therefore,someoftheparticipantsexploredallchoiceoptionsinthesurveyandsubmittedthesetting
withthelargestperformancegain.Thisindicatesthattheendgoalofperformanceimprovementinthetaskishighly
valued.Someparticipantsmentionedthatthestudyinterfaceisunfamiliar(Unfamiliarstudyinterface),whichcan
beconfusing.Weconsideredthispointintheanalysisthroughdiscussionsatthecodingworkshops.However,italso
indicatesthatparticipantswereunfamiliarwithTDAexplanationsoverallastheyarenotusedinpracticeyet.Thelast
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 17
themehighlightstheimportanceofgroupingerroneoustestsamples.Participantsnotedthatasingleerroneoustest
samplemayrepresentabroaderissue,andunderstandingthelinkbetweentrainingdataandgroupsoftestsamples
withsimilarerrorscouldenhancedebugging.
5 DISCUSSION
ThisworkpresentsaneedfindingstudywithAIpractitionersfortrainingdataattribution(TDA)explanationstoinform
user-focusedTDAresearchinatop-downapproach.Wesummariseourfindingstoprovideanswerstotheinitial
researchquestions(¬ß5.1),identifyresearchgapsthatneedtobeaddressedformoreuser-focusedTDA(¬ß5.2)and
discusslimitations(¬ß5.3).
5.1 Answerstotheresearchquestions
5.1.1 RQ1:WhatdousersneedTDAexplanationsfor? Toanswerthisquestion,weconductedtheinterviewstudy
(¬ß4.1).OurfindingssuggestthatTDAasanexplanationmethodhasthepotentialtoservesimilarhigh-levelpurposes
asotherexplanationtechniques,namelyenablinguserstounderstandmodelbehaviour,especiallyunexpectedmodel
behaviour.Byofferinginsightsintomodelbehaviour,TDAcanassistend-usersincalibratingtrustbyprovidingcontext
formodeldecisionsandsupportmodeldevelopersindebuggingerrorsbyidentifyingrootcausesinthetrainingdata.
Thisdata-centricapproachisparticularlyvaluableinmodeldevelopment,leadingustoidentifymodeldevelopersas
theprimaryaudienceforTDAexplanationsandmodeldebuggingasthekeyusecase.
5.1.2 RQ2:WhatdousersneedfromTDAexplanations? Toanswerthisquestion,wedesignedasurveystudythat
extractsuserpreferencesfortheinformationrepresentedbyTDA(¬ß4.4).Ourstudyrevealsthatusersneeddifferent
typesofinformationtounderstandmodelbehaviour,dependingontheirhypothesesofwhythemodelerrsduring
development.ThisnecessitatesTDAexplanationsthatareflexibleandadaptabletoindividualneeds.Theseneedsvary
basedontheapplicationdomainandtheuser‚Äôslevelofexpertise.Experiencedusers,mayformhypothesesaboutmodel
errorsbasedontheirpastexperiences.Incontrast,lessexperiencedusersmayformhypothesesbasedonwhatthey
learntpreviouslyaboutmachinelearningmodels.Usershaveapreferenceforgroupattribution,asgroupsprovide
moreinformationthanindividualsamples.Additionally,usersneedTDAexplanationstobereliableconsideringhow
data-centricactionsmightaffectthemodelasawhole.Reliabilityentailstwomainaspects:First,theinformationneeds
tobereliableforittobeactionableandeffectiveforthetask(i.e.,modeldebugging).Second,TDAexplanationsshould
alsoaccountforanybroaderchangesinthemodel‚Äôsbehaviourthatmayaffecttheattributiontotrainingsamples.
5.1.3 RQ3:TowhatextentdoexistingTDAapproachesalignwithuserneeds? Toanswerthisquestion,wereflecton
existingTDAapproachesinlightoftheidentifiedneeds:TDAexplanationsneedtobeadaptabletotheuserandprovide
reliableandactionableinsightwhilemaintainingconsistencywiththeoverallmodelbehaviour.Fromtheseneeds,we
identifydifferentTDAtasksthatusersneed,nexttotheoverarchingneedforreliability(seeTable5).
TraditionalTDAmeasurestheinfluenceofatrainingsampleonmodelpredictionsbyanalysingtheimpactofits
removalthroughleave-one-outretraining[30].Thismethodessentiallyevaluatesmodelpredictionsinthecontextofa
counterfactualchangeinthetrainingdata.Ithasbeenstudiedacrossdifferenttasks,suchasidentifyingmislabelleddata,
understandingadversarialvulnerabilities,anddetectingdomainmismatches[41].Mislabelidentification,inparticular,
isacommonevaluationstrategyemployedinseveralstudies[54,61,66].Consequently,traditionalTDApartially
addressestheneedforadaptabilitytodifferentusecases.However,sinceTDAquantifiestherelevanceofatraining
samplebyitsremoval,itisparticularlysuitedforscenarioswheredataeliminationisnecessary,suchasmalicious
Preprint.Underreview.18 Nguyen,etal.
Table5. OverviewofthetypesofTDAidentifiedinourstudyandhowoftentheywerementionedinthesurveystudy,definedby
theirspecificationintheTDAdesignspace,whereAttributingerrorswasmainlymentionedintheadditionalcomments.Citedworks
addressthistypeofTDA.
Attributiontype Action Metric |Ztrain| |Ztest| Timeschosen
Influenceattribution(e.g.,[24,27,41,54,61,66]) Removal Sampleloss 1 1 0
Groupinfluenceattribution(e.g.,[7,42,46,54]) Removal Sampleloss >1 1 11
Attributingerrors(e.g.[34]) Any Any >1 >1 4
Lackingdataattribution Addition Any >1 >1 26
Decisionboundaryattribution Labelchange Any >1 >1 14
samples.Itremainsanopenquestionwhetheralternativeactions,suchaschanginglabelsorupsamplingadataregion,
mightprovideimprovedexplanationsintermsofactionability.Ourstudyindicatesthatusersmayhavediverseideas
regardingtherootcausesoferrors,andtraditionalTDAonlyaddressesoneoftheseperspectives.
Regardingtheneedforreliable,actionable,andeffectiveinformation,existingTDAmethodshavebeencriticisedfor
theirlowreliabilityindeeplearning[5,6,52].Inaddition,ourstudyintroducesadifferentaspectofreliabilitythat
onlybecomesapparentwhenconsideringthefullcontextoftheusecase(asweassesseduserswithinthecontextofa
specifictask).Whenadatasetismodified,theoverallmodelbehaviourcanbeaffectedandmustbeconsidered.For
TDA,thismeansthatwhenmodifyingthedatasettoaddressingaparticularerror,usersrequireexplanationsthatnot
onlysuggestaneffectivemodificationbutalsoensurethemodel‚Äôsperformanceremainsratherconsistent.
Ouranalysisunderscorestheimportanceofincorporatinguserperspectivestoidentifyneedscriticaltothereal-
world application of this technology. Traditional TDA explanations only partially meet these needs, and further
interdisciplinaryeffortsarerequiredtodevelopmethodswithimprovedactionability.
5.2 Overlookedresearchtopicsforuser-focusedtrainingdataattribution
Thisworkaddstoacollectionofhuman-centredexplainableAI(HCXAI)workscallingtocentreXAIresearcharound
theuser(e.g.,[10,19,38,46,48,65]).ByfocusingonTDAexplanationsspecifically,weidentifyseveralresearchareas
thatarenecessarytostudytoadvanceTDAresearchtowardsafocusonusers.
‚Ä¢ MentalmodelsandTDA:Ourstudysupportspreviouswork[38,65]thatthemostusefulexplanationsdepend
ontheuser‚Äôsmentalmodelofwhythemodelerrs:Wefindthatwhatinformationisactionabletousersdepends
intheirhypothesisforreasonsofmodelbehaviour(Themearea:Actiondependsonuser‚Äôshypothesis).
Therefore,futureresearchshouldexplorehowTDAinfluencesandisinfluencedbymentalmodels,aswellas
howTDAcanbeadaptedtoreflectmentalmodels(e.g.bydefiningrelevancethroughtheactionofupweighting
asopposedtoremoval),potentiallyleadingtomorealignedandactionableexplanationsthatarewell-defined.
‚Ä¢ User-centredgroupattribution:Thesurveyfindingsrevealaclearneedforattributingmodelbehaviour
togroupsoftrainingsamples,asitprovidesmoreinformativeinsights(Themearea:Groupattribution
preference).Whileexistingapproaches[7,42,54]addressthis,ourfindingshighlighttheneedforcreating
groupingsthatmakesensetousers(e.g.,basedongroundtruthorpredictedclass),anaspectnotyetwidely
exploredinTDAresearch.
‚Ä¢ Holisticunderstandingofmodelerrors:Ourthematicanalysisofsurveyresponseshighlightstheimportance
ofunderstandingthemodelerroritselfbeforeattemptingtofixit(Theme:Groupingerroneoustestsamples).
Iftherootcauseisaspuriouscorrelation,theerrorlikelyextendsbeyondthecurrenttestsampleandmay
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 19
notfullyrepresenttheissue.Werecommendfutureresearchfocusonunderstandingerrortypesratherthan
isolatedinstances(e.g.,slicediscovery[77])andonattributingmodelbehaviourongroupsoftestsamplesto
trainingdata(e.g.,[34]).
‚Ä¢ ReliabilityofTDA:TDAquantifiestheimpactoftrainingsamplesonmodelerrorsbypredictingchangesin
modelbehaviour,servingasanexplanationtotheuser.Fortheexplanationstobeinformative,theattribution
mustbereliable.Itisessentialtounderstandhowoverallmodelbehaviourwillbeaffectedasmentionedbyour
participants(Themearea:Reliabilityofexplanations).Werecommendfutureresearchtoextendexisting
workonthefragility,reliability,andstabilityofTDA[5,6,21,52]toaddresstheseneeds.
‚Ä¢ TDAandfeatureattribution:CombiningfeatureattributionwithTDAcouldcreateTDAexplanationsfamiliar
tomodeldeveloperswhoalreadyusefeatureattributionmethodslikeSHAP[47].Whileourparticipants
indicatedtheyfrequentlyusefeatureattribution,thereisaknownriskofmisinterpretationandoverreliance[38,
39].Providingfeatureattributionexplanationswithcontext,suchasrelevanttrainingdataidentifiedthrough
TDA,couldhelpincheckingwhethersimilarfeaturesintrainingandtestdatamightmisleadthemodel.
5.3 Limitations
Thisstudyhasseverallimitations.First,theuseofpurposiveandsnowballsamplingtechniquesinparticipantrecruitment
mayhaveintroducedselectionbias.Consequently,thesamplemaynotbefullyrepresentativeofthebroaderpopulation
ofprofessionalsworkingwithmachinelearningormodeldevelopersingeneral.Second,therelativelysmallsample
sizeinourstudieslimitstherobustnessofthequantitativeanalyses,sotheresultsshouldbeinterpretedwithcaution
andleadustofocusmorestronglyonthequalitativeanalysis.Third,wesimulatedtheuseofTDAexplanationsina
modeldebugginginterfacewhicharelab-likeconditionsforthesurveystudy.Hence,theneedfindinganalysisisnot
rootedintherealworkflowsandisboundtoourstudyconditions,includingtheinterfacedesign.
6 CONCLUSION
Thispaperproposesatop-downapproachtoconductingexplainableAI(XAI)researchwhichisdrivenbyuserneedsas
opposedtotechno-centricsolutions.Weillustratethisapproachwiththeemergingsubfieldoftrainingdataattribution
(TDA)andpresentaneedfindingstudywithAIpractitioners.Thestudyconsistsoftwostages:First,weconduct
semi-structuredinterviewswithprofessionalswhoalreadyworkwithAIsystems(N=10)togainanimpressionof
commonusecasesandchallenges.WefindthatTDAcouldespeciallybenefitmodeldevelopers,astheirworkflowsare
stronglydata-centric.WederiveadesignspaceofTDAexplanatoryinformationthatrepresentswhatrelevantdatafor
modeldebuggingcouldlooklike.Second,wedevelopaninteractiveinterfacetoextractuserpreferencesinthedesign
spaceandintegrateitintoasurveystudy(N=31)targetedatmodeldevelopers.Themixed-methodsanalysisshowsthat
theexplanatoryinformationneededfromTDAformodeldebuggingishighlydependentnotonlyontheusecasebut
alsoontheuserandtheirintuitions.Finally,wehighlightseveralresearchdirectionsinuser-focusedTDAthatare
largelyoverlookedinthecurrentlandscape.
ACKNOWLEDGMENTS
Wefirstandforemostthankallstudyparticipantswhogaveustheirtimeandinput.WealsothankAlbertCatal√°n,
NikitaKister,andArnasUselisforparticipatinginthepilotstudyandhelpingusimprovethestudydesign.Wethank
DustinTheobaldforsharinghissurveywebsitecodebasewhichweusedasabasis.WethankKristinaKapanova
forhelpingushostthesurveysecurely,andeveryonewhohelpedspreadthesurveystudy.Theauthorsthankthe
Preprint.Underreview.20 Nguyen,etal.
InternationalMaxPlanckResearchSchoolforIntelligentSystems(IMPRS-IS)forsupportingElisaNguyen.Thiswork
wassupportedbytheT√ºbingenAICenter.
REFERENCES
[1] JuliusAdebayo,JustinGilmer,MichaelMuelly,IanGoodfellow,MoritzHardt,andBeenKim.2018.Sanitychecksforsaliencymaps.Advancesin
neuralinformationprocessingsystems31(2018).
[2] EkinAky√ºrek,TolgaBolukbasi,FrederickLiu,BinbinXiong,IanTenney,JacobAndreas,andKelvinGuu.2022.TowardsTracingKnowledgein
LanguageModelsBacktotheTrainingData.FindingsoftheAssociationforComputationalLinguistics:EMNLP2022(2022),2429‚Äì2446.
[3] JamalAlsakran,XiaokeHuang,YeZhao,JingYang,andKarlFast.2014.Usingentropy-relatedmeasuresincategoricaldatavisualization.In2014
IEEEPacificVisualizationSymposium.IEEE,81‚Äì88.
[4] JuhanBae,WuLin,JonathanLorraine,andRogerGrosse.2024.TrainingDataAttributionviaApproximateUnrolledDifferentation.arXivpreprint
arXiv:2405.12186(2024).
[5] JuhanBae,NathanNg,AlstonLo,MarzyehGhassemi,andRogerBGrosse.2022. IfInfluenceFunctionsaretheAnswer,ThenWhatisthe
Question?.InAdvancesinNeuralInformationProcessingSystems,S.Koyejo,S.Mohamed,A.Agarwal,D.Belgrave,K.Cho,andA.Oh(Eds.),Vol.35.
CurranAssociates,Inc.,17953‚Äì17967. https://proceedings.neurips.cc/paper_files/paper/2022/file/7234e0c36fdbcb23e7bd56b68838999b-Paper-
Conference.pdf
[6] SamyadeepBasu,PhilPope,andSoheilFeizi.2021. InfluenceFunctionsinDeepLearningAreFragile.InInternationalConferenceonLearning
Representations. https://openreview.net/forum?id=xHKVVHGDOEk
[7] SamyadeepBasu,XuchenYou,andSoheilFeizi.2020. Onsecond-ordergroupinfluencefunctionsforblack-boxpredictions.InInternational
ConferenceonMachineLearning.PMLR,715‚Äì724.
[8] BlairBilodeau,NatashaJaques,PangWeiKoh,andBeenKim.2024.Impossibilitytheoremsforfeatureattribution.ProceedingsoftheNational
AcademyofSciences121,2(2024),e2304406120.
[9] VirginiaBraunandVictoriaClarke.2012.Thematicanalysis.AmericanPsychologicalAssociation.
[10] AndreaBrennen.2020.WhatDoPeopleReallyWantWhenTheySayTheyWant"ExplainableAI?"WeAsked60Stakeholders..InExtendedAbstracts
ofthe2020CHIConferenceonHumanFactorsinComputingSystems(Honolulu,HI,USA)(CHIEA‚Äô20).AssociationforComputingMachinery,New
York,NY,USA,1‚Äì7. https://doi.org/10.1145/3334480.3383047
[11] Marc-EtienneBrunet,ColleenAlkalay-Houlihan,AshtonAnderson,andRichardZemel.2019.Understandingtheoriginsofbiasinwordembeddings.
InInternationalconferenceonmachinelearning.PMLR,803‚Äì811.
[12] JohnM.Carroll(Ed.).1995.Scenario-baseddesign:envisioningworkandtechnologyinsystemdevelopment.JohnWiley&Sons,Inc.,USA.
[13] GuillaumeCharpiat,NicolasGirard,LorisFelardos,andYuliyaTarabalka.2019.InputSimilarityfromtheNeuralNetworkPerspective.InAdvances
inNeuralInformationProcessingSystems,H.Wallach,H.Larochelle,A.Beygelzimer,F.d'Alch√©-Buc,E.Fox,andR.Garnett(Eds.),Vol.32.Curran
Associates,Inc. https://proceedings.neurips.cc/paper_files/paper/2019/file/c61f571dbd2fb949d3fe5ae1608dd48b-Paper.pdf
[14] SangKeunChoe,HwijeenAhn,JuhanBae,KewenZhao,MinsooKang,YoungseogChung,AdithyaPratapa,WillieNeiswanger,EmmaStrubell,
TerukoMitamura,etal.2024.WhatisYourDataWorthtoGPT?LLM-ScaleDataValuationwithInfluenceFunctions.arXivpreprintarXiv:2405.13954
(2024).
[15] FinaleDoshi-VelezandBeenKim.2017.Towardsarigorousscienceofinterpretablemachinelearning.arXivpreprintarXiv:1702.08608(2017).
[16] RudreshDwivedi,DevamDave,HetNaik,SmitiSinghal,RanaOmer,PankeshPatel,BinQian,ZhenyuWen,TejalShah,GrahamMorgan,etal.2023.
ExplainableAI(XAI):Coreideas,techniques,andsolutions.Comput.Surveys55,9(2023),1‚Äì33.
[17] AnthonyWFEdwards.2005.RAFischer,statisticalmethodsforresearchworkers,(1925).InLandmarkwritingsinwesternmathematics1640-1940.
Elsevier,856‚Äì870.
[18] UpolEhsan,QVeraLiao,MichaelMuller,MarkORiedl,andJustinDWeisz.2021.Expandingexplainability:Towardssocialtransparencyinai
systems.InProceedingsofthe2021CHIconferenceonhumanfactorsincomputingsystems.1‚Äì19.
[19] UpolEhsan,SamirPassi,Q.VeraLiao,LarryChan,I-HsiangLee,MichaelMuller,andMarkORiedl.2024.TheWhoinXAI:HowAIBackground
ShapesPerceptionsofAIExplanations.InProceedingsoftheCHIConferenceonHumanFactorsinComputingSystems(Honolulu,HI,USA)(CHI‚Äô24).
AssociationforComputingMachinery,NewYork,NY,USA,Article316,32pages. https://doi.org/10.1145/3613904.3642474
[20] UpolEhsanandMarkO.Riedl.2020.Human-CenteredExplainableAI:TowardsaReflectiveSociotechnicalApproach.InHCIInternational2020-
LateBreakingPapers:MultimodalityandIntelligence,ConstantineStephanidis,MasaakiKurosu,HelmutDegen,andLaurenReinerman-Jones(Eds.).
SpringerInternationalPublishing,Cham,449‚Äì466.
[21] JacobEpifano,RavichandranRamachandran,AaronJ.Masino,andGhulamRasool.2023.RevisitingtheFragilityofInfluenceFunctions.Neural
networks:theofficialjournaloftheInternationalNeuralNetworkSociety162(2023),581‚Äì588.
[22] VitalyFeldmanandChiyuanZhang.2020.Whatneuralnetworksmemorizeandwhy:Discoveringthelongtailviainfluenceestimation.Advances
inNeuralInformationProcessingSystems33(2020),2881‚Äì2891.
[23] RaymondFokandDanielSWeld.2023.Insearchofverifiability:ExplanationsrarelyenablecomplementaryperformanceinAI-adviseddecision
making.AIMagazine(2023).
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 21
[24] RogerGrosse,JuhanBae,CemAnil,NelsonElhage,AlexTamkin,AmirhosseinTajdini,BenoitSteiner,DustinLi,EsinDurmus,EthanPerez,etal.
2023.Studyinglargelanguagemodelgeneralizationwithinfluencefunctions.arXivpreprintarXiv:2308.03296(2023).
[25] GregGuest,EmilyE.Namey,andMarilynL.Mitchell.2023.CollectingQualitativeData:AFieldManualforAppliedResearch.SAGEPublications,
Ltd,55CityRoad. https://doi.org/10.4135/9781506374680
[26] RiccardoGuidotti,AnnaMonreale,SalvatoreRuggieri,FrancoTurini,FoscaGiannotti,andDinoPedreschi.2018.ASurveyofMethodsforExplaining
BlackBoxModels.ACMComput.Surv.51,5,Article93(2018),42pages. https://doi.org/10.1145/3236009
[27] HanGuo,NazneenRajani,PeterHase,MohitBansal,andCaimingXiong.2021.FastIF:ScalableInfluenceFunctionsforEfficientModelInterpretation
andDebugging.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.AssociationforComputationalLinguistics,
OnlineandPuntaCana,DominicanRepublic,10333‚Äì10350. https://doi.org/10.18653/v1/2021.emnlp-main.808
[28] SophiaHadash,MartijnC.Willemsen,ChrisSnijders,andWijnandA.IJsselsteijn.2022.Improvingunderstandabilityoffeaturecontributionsin
model-agnosticexplainableAItools.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems(NewOrleans,LA,USA)
(CHI‚Äô22).AssociationforComputingMachinery,NewYork,NY,USA,Article487,9pages. https://doi.org/10.1145/3491102.3517650
[29] ZaydHammoudehandDanielLowd.2024.Trainingdatainfluenceanalysisandestimation:Asurvey.MachineLearning113,5(2024),2351‚Äì2403.
[30] FrankR.Hampel.1974.TheInfluenceCurveanditsRoleinRobustEstimation.J.Amer.Statist.Assoc.69,346(1974),383‚Äì393. https://doi.org/10.
1080/01621459.1974.10482962
[31] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016.Deepresiduallearningforimagerecognition.InProceedingsoftheIEEEconference
oncomputervisionandpatternrecognition.770‚Äì778.
[32] HansHofmann.1994.Statlog(GermanCreditData).UCIMachineLearningRepository. DOI:https://doi.org/10.24432/C5NC77.
[33] AndrewIlyas,SungMinPark,LoganEngstrom,GuillaumeLeclerc,andAleksanderMadry.2022.Datamodels:PredictingPredictionsfromTraining
Data.InProceedingsofthe39thInternationalConferenceonMachineLearning.
[34] SaachiJain,KimiaHamidieh,KristianGeorgiev,AndrewIlyas,MarzyehGhassemi,andAleksanderMadry.2024.DataDebiasingwithDatamodels
(D3M):ImprovingSubgroupRobustnessviaDataSelection.arXivpreprintarXiv:2406.16846(2024).
[35] WeinaJin,JianyuFan,DianeGromala,PhilippePasquier,andGhassanHamarneh.2023.Invisibleusers:Uncoveringend-users‚Äôrequirementsfor
explainableaiviaexplanationformsandgoals.arXivpreprintarXiv:2302.06609(2023).
[36] WeiJin,HaohanWang,DaochenZha,QiaoyuTan,YaoMa,SharonLi,andSu-InLee.2024.DCAI:Data-centricArtificialIntelligence.InCompanion
ProceedingsoftheACMWebConference2024(Singapore,Singapore)(WWW‚Äô24).AssociationforComputingMachinery,NewYork,NY,USA,
1482‚Äì1485. https://doi.org/10.1145/3589335.3641297
[37] PrernaJuneja,WenjuanZhang,AlisonMarieSmith-Renner,HemankLamba,JoelTetreault,andAlexJaimes.2024.Dissectingusers‚Äôneedsfor
searchresultexplanations.InProceedingsoftheCHIConferenceonHumanFactorsinComputingSystems(Honolulu,HI,USA)(CHI‚Äô24).Association
forComputingMachinery,NewYork,NY,USA,Article841,17pages. https://doi.org/10.1145/3613904.3642059
[38] HarmanpreetKaur,HarshaNori,SamuelJenkins,RichCaruana,HannaWallach,andJenniferWortmanVaughan.2020.InterpretingInterpretability:
UnderstandingDataScientists‚ÄôUseofInterpretabilityToolsforMachineLearning.InProceedingsofthe2020CHIConferenceonHumanFactorsin
ComputingSystems(Honolulu,HI,USA)(CHI‚Äô20).AssociationforComputingMachinery,NewYork,NY,USA,1‚Äì14. https://doi.org/10.1145/
3313831.3376219
[39] SunnieSYKim,NicoleMeister,VikramVRamaswamy,RuthFong,andOlgaRussakovsky.2022.HIVE:Evaluatingthehumaninterpretabilityof
visualexplanations.InEuropeanConferenceonComputerVision.Springer,280‚Äì298.
[40] SunnieS.Y.Kim,ElizabethAnneWatkins,OlgaRussakovsky,RuthFong,andAndr√©sMonroy-Hern√°ndez.2023."HelpMeHelptheAI":Understanding
HowExplainabilityCanSupportHuman-AIInteraction.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems(Hamburg,
Germany)(CHI‚Äô23).AssociationforComputingMachinery,NewYork,NY,USA,Article250,17pages. https://doi.org/10.1145/3544548.3581001
[41] PangWeiKohandPercyLiang.2017. UnderstandingBlack-boxPredictionsviaInfluenceFunctions.InProceedingsofthe34thInternational
ConferenceonMachineLearning(ProceedingsofMachineLearningResearch,Vol.70),DoinaPrecupandYeeWhyeTeh(Eds.).PMLR,1885‚Äì1894.
https://proceedings.mlr.press/v70/koh17a.html
[42] PangWeiWKoh,Kai-SiangAng,HubertTeo,andPercySLiang.2019.Ontheaccuracyofinfluencefunctionsformeasuringgroupeffects.Advances
inneuralinformationprocessingsystems32(2019).
[43] YongchanKwon,EricWu,KevinWu,andJamesZou.2023.Datainf:Efficientlyestimatingdatainfluenceinlora-tunedllmsanddiffusionmodels.
arXivpreprintarXiv:2310.00902(2023).
[44] HimabinduLakkaraju,DylanSlack,YuxinChen,ChenhaoTan,andSameerSingh.2022.Rethinkingexplainabilityasadialogue:Apractitioner‚Äôs
perspective.arXivpreprintarXiv:2202.01875(2022).
[45] Q.VeraLiao,DanielGruen,andSarahMiller.2020. QuestioningtheAI:InformingDesignPracticesforExplainableAIUserExperiences.In
Proceedingsofthe2020CHIConferenceonHumanFactorsinComputingSystems(Honolulu,HI,USA)(CHI‚Äô20).AssociationforComputingMachinery,
NewYork,NY,USA,1‚Äì15. https://doi.org/10.1145/3313831.3376590
[46] ChrisLin,MingyuLu,ChanwooKim,andSu-InLee.2024.EfficientShapleyValuesforAttributingGlobalPropertiesofDiffusionModelstoData
Group.arXivpreprintarXiv:2407.03153(2024).
[47] ScottMLundbergandSu-InLee.2017.Aunifiedapproachtointerpretingmodelpredictions.Advancesinneuralinformationprocessingsystems30
(2017).
Preprint.Underreview.22 Nguyen,etal.
[48] AlexMei,MichaelSaxon,ShiyuChang,ZacharyCLipton,andWilliamYangWang.2023. Usersarethenorthstarforaitransparency. arXiv
preprintarXiv:2303.05500(2023).
[49] TimMiller.2019.Explanationinartificialintelligence:Insightsfromthesocialsciences.Artificialintelligence267(2019),1‚Äì38.
[50] MeikeNauta,JanTrienes,ShreyasiPathak,ElisaNguyen,MichellePeters,YasminSchmitt,J√∂rgSchl√∂tterer,MauricevanKeulen,andChristin
Seifert.2023.FromAnecdotalEvidencetoQuantitativeEvaluationMethods:ASystematicReviewonEvaluatingExplainableAI.ACMComput.
Surv.55,13s,Article295(jul2023),42pages. https://doi.org/10.1145/3583558
[51] HumzaNaveed,AsadUllahKhan,ShiQiu,MuhammadSaqib,SaeedAnwar,MuhammadUsman,NaveedAkhtar,NickBarnes,andAjmalMian.
2023.Acomprehensiveoverviewoflargelanguagemodels.arXivpreprintarXiv:2307.06435(2023).
[52] ElisaNguyen,MinjoonSeo,andSeongJoonOh.2023.ABayesianApproachToAnalysingTrainingDataAttributioninDeepLearning.InProceedings
ofthe2023ConferenceonNeuralInformationProcessingSystems.
[53] OpenAI.2022.ChatGPT-3.5. https://chat.openai.com
[54] SungMinPark,KristianGeorgiev,AndrewIlyas,GuillaumeLeclerc,andAleksanderMadry.2023.TRAK:AttributingModelBehavioratScale.In
InternationalConferenceonMachineLearning(ICML).
[55] EuropeanParliament.2023.AIAct,AnnexIII.
[56] AdamPaszke,SamGross,FranciscoMassa,AdamLerer,JamesBradbury,GregoryChanan,TrevorKilleen,ZemingLin,NataliaGimelshein,Luca
Antiga,AlbanDesmaison,AndreasKopf,EdwardYang,ZacharyDeVito,MartinRaison,AlykhanTejani,SasankChilamkurthy,BenoitSteiner,Lu
Fang,JunjieBai,andSoumithChintala.2019.PyTorch:AnImperativeStyle,High-PerformanceDeepLearningLibrary.InAdvancesinNeural
InformationProcessingSystems32.CurranAssociates,Inc.,8024‚Äì8035. http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-
performance-deep-learning-library.pdf
[57] DevPatnaikandRobertBecker.1999.Needfinding:TheWhyandHowofUncoveringPeople‚ÄôsNeeds.DesignManagementJournal(FormerSeries)10,
2(1999),37‚Äì43. https://doi.org/10.1111/j.1948-7169.1999.tb00250.xarXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1948-7169.1999.tb00250.x
[58] KarlPearson.1900.X.Onthecriterionthatagivensystemofdeviationsfromtheprobableinthecaseofacorrelatedsystemofvariablesissuch
thatitcanbereasonablysupposedtohavearisenfromrandomsampling.TheLondon,Edinburgh,andDublinPhilosophicalMagazineandJournalof
Science50,302(1900),157‚Äì175.
[59] F.Pedregosa,G.Varoquaux,A.Gramfort,V.Michel,B.Thirion,O.Grisel,M.Blondel,P.Prettenhofer,R.Weiss,V.Dubourg,J.Vanderplas,A.Passos,
D.Cournapeau,M.Brucher,M.Perrot,andE.Duchesnay.2011.Scikit-learn:MachineLearninginPython.JournalofMachineLearningResearch12
(2011),2825‚Äì2830.
[60] PouyaPezeshkpour,SarthakJain,SameerSingh,andByronWallace.2022. CombiningFeatureandInstanceAttributiontoDetectArtifacts.
InFindingsoftheAssociationforComputationalLinguistics:ACL2022.AssociationforComputationalLinguistics,Dublin,Ireland,1934‚Äì1946.
https://doi.org/10.18653/v1/2022.findings-acl.153
[61] GarimaPruthi,FrederickLiu,SatyenKale,andMukundSundararajan.2020.EstimatingTrainingDataInfluencebyTracingGradientDescent.In
AdvancesinNeuralInformationProcessingSystems,H.Larochelle,M.Ranzato,R.Hadsell,M.F.Balcan,andH.Lin(Eds.),Vol.33.CurranAssociates,
Inc.,19920‚Äì19930. https://proceedings.neurips.cc/paper_files/paper/2020/file/e6385d39ec9394f2f3a354d9d2b88eec-Paper.pdf
[62] AlecRadford,JongWookKim,TaoXu,GregBrockman,ChristineMcleavey,andIlyaSutskever.2023. RobustSpeechRecognitionviaLarge-
ScaleWeakSupervision.InProceedingsofthe40thInternationalConferenceonMachineLearning(ProceedingsofMachineLearningResearch,
Vol.202),AndreasKrause,EmmaBrunskill,KyunghyunCho,BarbaraEngelhardt,SivanSabato,andJonathanScarlett(Eds.).PMLR,28492‚Äì28518.
https://proceedings.mlr.press/v202/radford23a.html
[63] MarcoTulioRibeiro,SameerSingh,andCarlosGuestrin.2016."Whyshoulditrustyou?"Explainingthepredictionsofanyclassifier.InProceedings
ofthe22ndACMSIGKDDinternationalconferenceonknowledgediscoveryanddatamining.1135‚Äì1144.
[64] YaoRong,TobiasLeemann,Thai-TrangNguyen,LisaFiedler,PeizhuQian,VaibhavUnhelkar,TinaSeidel,GjergjiKasneci,andEnkelejdaKasneci.
2023.TowardsHuman-CenteredExplainableAI:ASurveyofUserStudiesforModelExplanations.IEEETrans.PatternAnal.Mach.Intell.46,4(nov
2023),2104‚Äì2122. https://doi.org/10.1109/TPAMI.2023.3331846
[65] HeleenRutjes,MartijnWillemsen,andWijnandIJsselsteijn.2019.ConsiderationsonexplainableAIandusers‚Äômentalmodels.InCHI2019Workshop:
Whereisthehuman?BridgingthegapbetweenAIandHCI.AssociationforComputingMachinery,Inc.
[66] AndreaSchioppa,PolinaZablotskaia,DavidVilar,andArtemSokolov.2022.ScalingUpInfluenceFunctions.ProceedingsoftheAAAIConferenceon
ArtificialIntelligence36,8(Jun.2022),8179‚Äì8186. https://doi.org/10.1609/aaai.v36i8.20791
[67] HuaShen,Chieh-YangHuang,TongshuangWu,andTing-HaoKennethHuang.2023.ConvXAI:DeliveringHeterogeneousAIExplanationsvia
ConversationstoSupportHuman-AIScientificWriting.InCompanionPublicationofthe2023ConferenceonComputerSupportedCooperativeWork
andSocialComputing(Minneapolis,MN,USA)(CSCW‚Äô23Companion).AssociationforComputingMachinery,NewYork,NY,USA,384‚Äì387.
https://doi.org/10.1145/3584931.3607492
[68] KarenSimonyan,AndreaVedaldi,andAndrewZisserman.2013.Deepinsideconvolutionalnetworks:Visualisingimageclassificationmodelsand
saliencymaps.arXivpreprintarXiv:1312.6034(2013).
[69] DanielSmilkov,NikhilThorat,BeenKim,FernandaVi√©gas,andMartinWattenberg.2017.Smoothgrad:removingnoisebyaddingnoise.arXiv
preprintarXiv:1706.03825(2017).
[70] MukundSundararajan,AnkurTaly,andQiqiYan.2017.Axiomaticattributionfordeepnetworks.InInternationalconferenceonmachinelearning.
PMLR,3319‚Äì3328.
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 23
[71] MohammadRezaTaesiri,GiangNguyen,andAnhNguyen.2022.Visualcorrespondence-basedexplanationsimproveAIrobustnessandhuman-AI
teamaccuracy.AdvancesinNeuralInformationProcessingSystems35(2022),34287‚Äì34301.
[72] StefanoTeso,AndreaBontempelli,FaustoGiunchiglia,andAndreaPasserini.2021.InteractiveLabelCleaningwithExample-basedExplanations.In
AdvancesinNeuralInformationProcessingSystems,A.Beygelzimer,Y.Dauphin,P.Liang,andJ.WortmanVaughan(Eds.). https://openreview.net/
forum?id=T6m9bNI7C__
[73] V.Turri,K.Morrison,K.Robinson,C.Abidi,J.Forlizzi,A.Perer,andR.Dzombak.2024.TransparencyintheWild:NavigatingTransparencyina
DeployedAISystemtoBroadenNeed-FindingApproaches.ACMConferenceonFairness,Accountability,andTransparency(ACMFAccT)(2024).
[74] JuliaP.A.vonThienen,WilliamJ.Clancey,andChristophMeinel.2019. TheoreticalFoundationsofDesignThinking. SpringerInternational
Publishing,Cham,13‚Äì38. https://doi.org/10.1007/978-3-319-97082-0_2
[75] C.Wah,S.Branson,P.Welinder,P.Perona,andS.Belongie.2011.TheCaltech-UCSDBirds-200-2011Dataset.TechnicalReportCNS-TR-2011-001.
CaliforniaInstituteofTechnology.
[76] DandingWang,QianYang,AshrafAbdul,andBrianYLim.2019.Designingtheory-drivenuser-centricexplainableAI.InProceedingsofthe2019
CHIconferenceonhumanfactorsincomputingsystems.1‚Äì15.
[77] FultonWang,JuliusAdebayo,SarahTan,DiegoGarcia-Olano,andNarineKokhlikyan.2024.Errordiscoverybyclusteringinfluenceembeddings.In
Proceedingsofthe37thInternationalConferenceonNeuralInformationProcessingSystems(NewOrleans,LA,USA)(NIPS‚Äô23).CurranAssociatesInc.,
RedHook,NY,USA,Article1809,13pages.
[78] Sheng-YuWang,AaronHertzmann,AlexeiAEfros,Jun-YanZhu,andRichardZhang.2024.DataAttributionforText-to-ImageModelsbyUnlearning
SynthesizedImages.arXivpreprintarXiv:2406.09408(2024).
[79] EricWWeisstein.2004.Bonferronicorrection.https://mathworld.wolfram.com/(2004).
[80] XiaosenZheng,TianyuPang,ChaoDu,JingJiang,andMinLin.2023.Intriguingpropertiesofdataattributionondiffusionmodels.arXivpreprint
arXiv:2311.00500(2023).
Preprint.Underreview.24 Nguyen,etal.
A INCLUSIONCRITERIA:HIGH-RISKAPPLICATIONAREAS
Werefertothedefinitionofhigh-riskapplicationareasaccordingtoAnnexIIIoftheEuropeanUnion‚ÄôsAIAct[55].For
readability,weincludeanoverview:
‚Ä¢ AIapplicationsinproductsthatrequireaspecificlevelofsafety:
‚Äì Toys,
‚Äì Aviation,
‚Äì Cars,
‚Äì Medicaldevices,
‚Äì Lifts.
‚Ä¢ Biometricidentificationandcategorisationofnaturalpersons.
‚Ä¢ Managementandoperationofcriticalinfrastructure.
‚Ä¢ Educationandvocationaltraining.
‚Ä¢ Employment,workermanagementandaccesstoself-employment.
‚Ä¢ Accesstoandenjoymentofessentialprivateservicesandpublicservicesandbenefits.
‚Ä¢ Lawenforcement.
‚Ä¢ Migration,asylumandbordercontrolmanagement.
‚Ä¢ Assistanceinlegalinterpretationandapplicationofthelaw.
B INTERVIEWSTUDYTHEMES
Thethematiccodinganalysisofthesurveystudy(N=10)yielded29themescorrespondingtosixthemeareasandfour
unexpectedthemes(¬ß4.2).Inthefollowing,wefurtherelaborateonthesethemes.
B.1 Themearea:RoleofMLsystems
Thethemearea‚ÄúRoleofMLsystems‚ÄùgroupsthreethemesthatrepresentwhatkindofroleMLsystemstakeinour
participant‚Äôswork:
‚Ä¢ Workassistant:MLsystemsactasworkassistantsastheytakeworkloadofftheparticipant.Chatbotsgenerally
filltheroleofaworkassistantthat‚Äú[takesworkoffoftheparticipant‚Äôshandsandmakestheirworkeasier]"
(P10)andis‚Äúavailablearoundtheclock"(P10).Participantsusechatbotsystemstoimprovetheirwritingin
English(P1,P11),tosearchforinformationwherepreviouslytheywould"[ask]Google"(P1),ortoideate
researchideas(P11).Moreover,P10truststheircompany-internalchatbotenoughtoredirectsimpleemployee
questionstothechatbot.
‚Ä¢ Decision support: As decision support systems, ML systems deliver information that acts as a basis for
decisionstakenbyend-users,e.g.diagnosissupport(P6).ThisisthemainroletakenbytheMLsystemsthat
thedeveloperparticipantsworkon(‚Äú[We]makepredictionsaboutwhereweshoulddoour[pharmaceutical]
studiesandourdevelopment."(P8),‚Äútrytoaccommodatethepolicymakerssothatthey‚Äôreabletodecide[where
morehealthservicesareneeded]"(P9)).P3usesMLsystemstoidentifyandexplainthecontributingfactors
toproductissues:‚ÄúIfwecanpredictit,wecanalsohaveanideawhatarethefactorsmostlycreatingthis
phenomenon."
‚Ä¢ Automation:Insomecases,MLsystemsaredeployedfortheautomationofsometasks,e.g.autonomous
driving(P2)orautomatedprocessingofcamerarecordings(P4).
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 25
B.2 Themearea:WorkflowwithMLsystems
Thethemearea‚ÄúWorkflowwithMLsystems‚Äùgroupsfourthemesthatemergedintheinterviewsrelatedtostandardor
often-occuringworkflows:
‚Ä¢ Collaborationwithdomainexperts:Developersandsystemuserscollaboratecloselyforbuildingand
evaluatingMLmodels,wherebugsarereportedtothedevelopersbytheend-users(P2,P3,P6,P4,P9).This
collaborationisespeciallystrongiftheMLsystemisdevelopedin-house,andlessstrongiftheMLsystemisa
productthecompanypurchased.
‚Ä¢ Standardmodelchoices:Developersrarelybuildtheirownmodelarchitecturesbutoptforstandardones
(‚Äú[If]it‚Äôsalreadyanestablishedproblem,you‚Äôreprobablynotgoingtodobetterthananalgorithmthat‚Äôsalready
beenlaidouttosolvethatproblemforyou."(P8)).
‚Ä¢ Data-focuseddebuggingprocess:Thedevelopmentworkinpracticeiscentredarounddata.Developer
participantsmentionthatmostoften,dataartefactsarethereasonforbugsinthemodel(P2,P3,P4,P7,P8,P9).
‚Ä¢ Dataqualitychecks:Dataqualitychecksareasetpartofthedatapreprocessingpipeline(P2,P3,P4,P8).
P2andP9reportedthattheyfirstassessdataqualitybeforeinspectingthemodelindebugging.Thisincludes
lookingforanypossibledataartefacts,especiallymissingdata.
B.3 Themearea:Roleoftrainingdata
Thethemearea‚ÄúRoleoftrainingdata‚Äùgroupsfivethemesstemmingfromparticipant‚Äôsresponseswhentalkingabout
theroleoftrainingdataintheinterviews:
‚Ä¢ Mostimportantvariableinamodel:Modeldeveloperparticipantsconsistentlyviewtrainingdataasthe
mostimportantvariableinamodel,e.g.‚Äú[we][...]believethat[...]themodelscanonlybeasgoodasthe[...]
datathatyoufeedin."(P4).Hence,thedebuggingprocessisfocusedarounddata(Theme:Data-focused
debuggingprocess).
‚Ä¢ Interestingbutnocapacity:Thisthemeappliestosystemuserparticipants,inparticularP6.Theymention
thattheywouldbecuriousabouttrainingdatatounderstandwhetherthemodellearnedfromhigh-quality
databut‚Äú[it]isaluxurythat[requirestime]",highlightingthepracticalconstraintoftimepressure.
‚Ä¢ Notinteresting:Thisthemeappliestosystemuserparticipants.Theywereunawareofwhichtrainingdata
mayhavebeenusedtotrainthemodels(P1,P10)andmentionedthatthisdoesnotmattertoomuchfortheir
workastheycannotchangeitanyhow.
‚Ä¢ Increasingtrainingdataasabugfix:Areoccuringthemeinourinterviewsisthattrainingdataisflexible‚Äì
thetrainingsetcanbeexpanded.Thisisoftendoneinpracticewhenencounteringabug,e.g.P2explainedthat
collectingmoredataisacommonwaytoovercomemodelshortcomingsinautonomousdriving.
‚Ä¢ Trainingdataartefactsasmainbugcauses:Inlinewithpreviousthemeshighlightingtheimportanceof
trainingdatatothedevelopmentprocess,participantsexplicitlymentionthatmostoften,trainingdataartefacts
arethecauseofbadmodelperformance.Hence,dataartefactsarealsothefirstthingthatdeveloperslookour
forwhenencounteringabug.
B.4 Themearea:ChallengesinworkingwithMLsystems
Thethemearea‚ÄúChallengesinworkingwithMLsystems‚Äùgroupssixthemesrelatedtothemainpainpointsthat
participantsmentioned
Preprint.Underreview.26 Nguyen,etal.
‚Ä¢ Trustcalibration:OurfindingsagreewithKimetal.[40]:Itisunclearhowmuchandwhenasystemcanbe
trusted.P1sometimesfindsthemselvesinadilemmainwhichtheywishtolearnsomethingfromthechatbot,
butareunabletocalibratetheirtrustintheresponseduetomissingknowledge:‚ÄúIdon‚Äôtknoweverything
regardingthistopic.I[don‚Äôteven]knowwhathe‚Äôsreplyingtome."(P1).
‚Ä¢ ValidationandEvaluation:P2mentionsthatthevalidationitselfisachallengeduetomultiplerequirements
thattheMLsystemshouldfulfil.Inpractice,thepredictiveperformanceofamodelmatters,alongwithother
objectivessuchasinferencespeed,whetherthemodelisbias-free,andmore.Inaddition,Adata-centricaspect
ofevaluationbeingchallengingisthedifficultyofevaluationwhenlabelsareabsent.
‚Ä¢ Dataqualityissues:DataqualityissuesareamajorchallengewhenworkingwithMLsystems.InTable2,we
detailthequalityissuesmentionedbythepariticipants.
‚Ä¢ Resource constraints: For developer participants, memory and compute constraints are relevant in the
developmentandevaluationprocessoftheirmodels,especiallytoP2andP4astheyworkwithMLsystemson
theedge.
‚Ä¢ StochasticnatureofMLmodels:ThestochasticnatureofMLmodelsposesaspecificchallengetodeep
modelsinthedevelopmentprocessanddebuggingtasks:‚Äú[The]samedataset,samemodel,youtrainmultiple
times,youcanget[different]results."(P2).Itisthereforedifficulttounderstandifabugwastrulyfixedorifit
isaconsequenceofrandomness.
‚Ä¢ Misuseduetolackingknow-how:P10mentionsinadequateknow-howinMLsystemusageasachallenge:
‚Äútheemployeesoftendon‚Äôtmanagetoaskthechatbottherightquestions".
B.5 Themearea:Useof(featureattribution)XAIinpractice
Thethemearea‚ÄúUseof(featureattribution)XAIinpractice‚ÄùgroupssixthemesrelatedtohowXAIisalreadybeing
usedbytheparticipants.
‚Ä¢ XAIisnotused:SomesystemuserparticipantswereunawareofXAIsinceexplanationsarenotapartofthe
MLtoolstheyuse(P1,P10,P11).
‚Ä¢ XAIislittleused:Thisthemeisrelatedtothesystemusers.P6reportsthatXAItoolstheyusedinradiology
imagessofar(i.e.heatmaps)donotdeliverafullanswertothewhyquestion,ascounterfactualinformationis
missing:‚Äú[If]Ijustgetanoverallhighlightinthesebasallungregionsandthepredictionthatisatelectasis,I
stilldon‚Äôtknowwhythisisatelectasisbutnotpleuraleffusionorconsolidation."Hence,theyonlyuseitwhen
theinformationisuseful.
‚Ä¢ Modeldevelopment:Fordeveloperparticipants,XAIismostcommonlyusedasatoolformodeldevelopment
(P2,P3,P8).Assuch,XAItools(withinourparticipants,theseareexclusivelyfeatureattributionexplanations,i.e.,
SHAP[47]orvisualisationofattention)offerexplanationsforper-exampledebuggingofe.g.wrongpredictions
(‚Äúweworkwithhands-onexamplesthatwethen[...]relatetheinputfeaturesthattakeapoororagood
prediction[to]."-P8).
‚Ä¢ Understand real-world phenomena: P3 described the use of XAI as a tool to understand phenomena
representedbytheMLmodel:‚Äú[Building]themodel,thewholepurposeistogetsomeexplainability.Because
[...]weknowthat[aproblemis]happeningandpredictingdoesn‚Äôtreallyaddvalue.Butifwecanpredictit,we
canalsohaveanideawhatarethefactorsmostlycreatingthisphenomenon."
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 27
‚Ä¢ Getcustomerbuy-in:P8statesthatXAItoolsareusefulingettingcustomerbuy-inandconvincingthe
customersofthemodel‚Äôsdecisionsuggestion:‚ÄúWill[thecustomers]behappywith[highaccuracy]?Probably.
Willtheybeconvinced?Willtheybe100%confidentthatthat‚Äôsthewaytheywanttodoit?Probablynot.So
it‚Äôsallaboutthebuy-inthatyouget,andSHAPdefinitelyhelps."
‚Ä¢ Sanitycheckformodelreasoning:OneparticularcaseofusingXAIformodeldevelopmentisasasanity
checkformodelreasoning(‚ÄúIfit‚Äôsmorelikeanideationproject,thenIwouldsaythattheexplainabilityanalysis
[isdone]tosee[...]whatisguidingthepredictionaswellas[...]howaremypredictionsonthetestset
explained?And[...]doesitalignwiththeactualvaluethatIhave?"-P8).
B.6 Themearea:UserperspectivesonTDA
Thethemearea‚ÄúUserperspectivesonTDA‚Äùgroupsfourthemesthatemergedintheparticipant‚Äôsanswerswhen
discussingTDA.
‚Ä¢ UsefulnessofXAIisuse-casedependent:SomeparticipantsfindXAIonlyusefulincertainuse-casesand
undercertainconditionssuchastimeavailability,intuitivenessoftheexplanation,andthepossibilityoftaking
actionbasedontheexplanation.Whenexplanationsareusedforcommunicationwithbusinessdepartments,
theydonotdeliverusefulinformationwhentheunderlyingmodelisnothigh-performingyet(P3,P8).
‚Ä¢ XAIisuseful:WhileparticipantsvoicedcertainconditionsfortheusefulnessofXAI,theoverallmajority
agreedthatexplanationsareusefulintheirwork(P1,P2,P3,P9,P11).
‚Ä¢ TDAcomplementarytofeatureattribution:ParticipantsareoverallpositivetowardsTDAexplanations.
TheymentionedthatTDAcouldbecomplementarytofeatureattributionexplanationsandprovidecontext,as
featureattributioninformationisratherlocal(e.g.,comparingfeatureattributionmapsbetweentrainingand
testsamplesthatarehighlyrelatedtoeachother).
‚Ä¢ Differentnotionsofinterestingtrainingsamples:Withinourparticipants,wefindthatthereareseveral
differentnotionsofwhataninterestingtrainingsampletoamodeloutputcouldbeamongtheparticipants.We
detailthecodesinthisthemeinTable2ofthemainpaper.
C DATAGENERATIONFORTHESURVEYSTUDY
Thesecondprobeofourstudypresentsaninteractivemock-upofamodeldevelopmentsuitewhereparticipantscan
customisewhatkindofdata-centricinformationisshown.Thisdataispre-computedusingrealmodelsandopenly
availabledatasetsforanimageclassificationandatabulardataclassificationusecase.Inthefollowing,wedescribethe
datagenerationprocess.
C.1 Usecase:Birdclassificationapp
Thesettingoftheimageclassificationusecaseisaboutacompanythatbuildsabirdclassificationapp.Thisbird
classificationappsettinghasbeenusedinpreviousHCXAIstudies,e.g.Kimetal.[40].Togeneratethedataforthisuse
case,wefinetunethepretrainedResNet18[31]checkpointinPyTorch[56]withtheCUBdataset[75].
Datapreprocessing. TheCUBdataset[75]isamulti-classimageclassificationwith200classes,and5994imagesin
trainingand5794imagesinthetestset.Whilethedatasetincludesfine-grainedannotations,weonlyutilisethetarget
labelsinthedatagenerationprocess.WesubsampleCUBtoincludeonly10classesforourapplicationtoensurethat
participantscanlearnandidentifythedifferentbirdspecieswithoutpriorknowledge.Werefertotheselectedclasses
Preprint.Underreview.28 Nguyen,etal.
astheirspeciesfamily(e.g.Grasshoppersparrow‚ÜíSparrow)forbrevity.Thetrainingsetincludes300images,andthe
testset277images.
Modeltraining. WefinetuneaResNet18modelpretrainedonImageNet(availableonthetorchvisionhub)withthe
CUBtrainingsubsetfor10epochsusingtheAdamWoptimizer,alearningrateof0.001withweightdecayfactor0.005for
thecross-entropyobjective.Sincethetrainingprocessofdeepmodelsisstochasticwhichaffectsanyretraining-based
effects[52],werecordthelastthreemodelcheckpointsforamodelensemble.Thefinalmodelachievesatestaccuracy
of0.57whichissuitableforthemodeldebuggingusecasesinthiswork.
C.2 Usecase:Loanapprovementrecommendationapp
Thesettingofthescenarioofthetabulardatausecaseisthemodeldevelopmentdepartmentofabankthatimplements
amachinelearningmodeltogiverecommendationsforloanapprovalsoftheirclients.Tobuildthisscenario,wetraina
logisticregressionmodelontheGermancreditdataset[32]whichisopenlyavailableontheUCIdatasetrepositoryand
islicensedbyCCBY4.0.
Datapreprocessing. TheGermancreditdataset[32]isamultivariatedatasetwith20featuresand1000entries.Itis
usedforbinaryclassificationandincludeslabelsofloanapprovalanddeclines.Wesplititintoatrainandtestsetusing
an80-20train-testsplit.Aswewishtodisplaythewholedataintheinterfacemock-up,wesubselectthefollowing
featuresforreadability:
(1) Thestatusofexistingcheckingaccountfeaturedescribeshowmuchmoneyisintheapplicant‚Äôschecking
accountandisacategoricalvariable.Possiblevaluesare:(a)lessthan$0,(b)lessthan$200,(c)morethan$200,
and(d)nocheckingaccount.
(2) Thedurationdescribestheloan‚Äôsdurationinmonthsandisanumericalvariable.
(3) Thecredithistorydescribestheapplicant‚Äôshistorywithloansfromthisandotherbanksasacategorical
variable.Possiblevaluesare:(a)nocreditstaken,(b)allcreditsatthisbankpaidbackduly,(c)existingcredits
paidbackdulytillnow,(d)delayinpayingoffinthepast,and(e)criticalaccount.
(4) Thecreditamountdescribesthesizeoftheloanin$andisanumericalvariable.
(5) Theinstallmentrateinpercentageoftheapplicant‚Äôsdisposableincomedescribeshowlargetheinstallment
paymentsoftheloanare.Itisanumericalfeature.
(6) Theageisanumericalfeatureanddescribestheageoftheloanapplicant.
Modeltraining. Wetrainedalogisticregressionmodelwithstochasticgradientdescentusingthescikit-learnlibrary
inPython[59].Indetail,themodelwastrainedin50epochswithL2regularisationweightedbyùõº =10ùëí‚àí4andthe
defaultadaptivelearningrateofthelibrary.Recordingthreecheckpointsalongthetrainingtrajectoryat30,40and50
epochsresultsinthemodelensembleweuseforcomputingthedata.Thefinalmodelaccuracyis0.68,leavingroomfor
improvementanddebugging.
C.3 Modelerrorselection
Inthesurveyprobe,theparticipantisaskedtoanalyseamodelerror,i.e.acommonmisclassification.Weselectthe
errorstoshowbyfirstunderstandingwhichtypeofmisclassificationismostcommon,i.e.whichclassAisoften
classifiedasanotherclassB.Todeterminethetesterrors,weclassifythetestsetusingthemodelensemble,grouptest
samplesaccordingtotrueandpredictedlabelsandselecttheerrorsrepresentedbythelargestgroups.Weselectthree
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 29
errortypesforthemulti-classprobleminthebirdclassificationusecase.Inthebinarytabularclassificationusecase,
onlytwoerrorsarepossible.Intheseerrorgroups,werandomlychoosethreeerroneoussampleseach,resultinginnine
andsixerroneoustestsamplesforthebirdclassificationandloanapprovalrecommendationusecases,respectively.
Thetestsamplesarerandomisedacrossparticipantsbydrawingfromauniformdistributiontopreventbiasinthe
analysisstemmingfromaspecificerrorortestsample.
C.4 Relevanttrainingsampleselection
Inthemock-upinterfaceusedinthesurveyprobe,wedisplaytheeffectofdifferenttrainingdata-basedactionsonthe
modelerrorathandandtheglobalmodelbehaviour.Weprecomputedthesevaluesusingthemodelspresentedinthe
above.Weelaborateontheprocedureofprecomputationbelow.
Determiningthetrainingsamples. Theinterfaceshowstrainingsamplesmostrelevanttothetestsamplegroupbased
ondifferentactions,i.e.removal,labelchangeandupweighting,measuredindifferentmetricsandfordifferentgroup
sizes.Todeterminewhichtrainingsamplestoshow,wewouldhavetoprecomputeallpossiblecombinationsofaction,
metricandgroupsize.Asthisiscomputationallyprohibitiveandrigorouscorrectnessisnotrequiredforourresearch
questions,weselecttherelevanttrainingsamplegroupstotheerroneoustestsamplesbasedonindividualrelevance.In
otherwords,wefirstiterativelyremove/changethelabel/upweigheachtrainingsampleandretrainthemodels(details
below).Then,werecordthedifferencesinloss/trueclassprobability/predictedclassprobabilityforeacherroneoustest
sampleexampleandcomputemean,varianceandp-valuesasin[52].Afterfilteringthetrainingsamplesthatexhibita
statisticallysignificanteffect(ùëù <0.05),wesortthetrainingsamplemeansfrommostpositivetomostnegativeeffect
whichdiffersacrossmetrics(e.g.anincreaseinlossisnegative,whileanincreaseintrueclassprobabilityispositive).
Thetop10trainingsamplesineachsettingaretherelevanttrainingsamplesweuseintheinterface.
Actionimplementation. Implementingandcomputingtheactionsrequireselaboration:
‚Ä¢ Removal:Theimplementationofremovalisratherstraightforward‚Äìweexcludethetrainingsamplefromthe
datasetandretrainusingthesametrainingpipeline.
‚Ä¢ Labelchange:Changingthelabelofatrainingsamplemakessensewhenanotherlabelmayfitthesample
better.Hence,weflipthelabelinthecaseofbinaryclassification.Inthecaseofmorethantwoclasses,we
considertwocases:(1)Thetrainingsamplewasmisclassified.Assumingthatthemodellearnsallclasseswell,a
misclassificationcouldoccurbecausethepredictedlabeldescribesthedatabetter.Therefore,inthesecases,the
newlabelisthepredictedlabel.(2)Thetrainingsamplewascorrectlyclassified.Wewouldonlywanttochange
thelabelifitwaswronglylabelled.Assumingthatthemodelgenerallylearnedtheclasseswell,wechangedthe
labeltothepredictedlabelwiththesecondhighestprobability.
‚Ä¢ Upweighting:Weimplementupweightingwithaweightfactorof10.
Computingfinaleffects. Intheinterface,weprovidesimulatedeffectsofcertaindata-centricactionsonthemodel
errors(e.g.removingcertaintrainingdatapointsleadstoanincreaseinloss).Individualeffectsdonotnecessarilyadd
uptothegroupeffect[7,42].Hence,wecomputethefinaleffectsusingtheactualremoval/labelchange/upweighting
oftrainingdatagroups.Thiscomputationisfeasiblesincethegroupsandthenumberoftimeswehavetoretrainthe
modelsarelimited.Wecomputeandshowthestandarddeviationofremoving/changingthelabel/upweightingacross
themodelcheckpointsrecorded.
Preprint.Underreview.30 Nguyen,etal.
D SURVEYSTUDYTHEMES
Thethematiccodinganalysisofthesurveystudy(N=31)yielded34themescorrespondingtofourthemeareasandfour
unexpectedthemes(¬ß4.5).Inthefollowing,wefurtherelaborateonthesethemes.
D.1 Themearea:Actiondependsonuser‚Äôshypothesis
Thethemearea‚ÄúActiondependsonuser‚Äôshypothesis‚Äùgroups21themeslinkedtothereasonsforparticipant‚Äôschoices
intheactionaxis.Wefindthattheproposeddebuggingactionsofparticipantsarehighlydependentontheirhypotheses
ofthemodelerror‚Äôsrootcause.
‚Ä¢ [Hypothesis]Mislabeleddata:Themodelmakesanerrorbecauseofmislabeleddatainthetrainingsetthat
ishighlyrelatedtotheerroneoustestsample.
‚Ä¢ [Hypothesis]Incompletetraining:Themodelmakesanerrorbecauseithasnotfinishedtraining,orwas
trainedusingnon-optimalhyperparametersandtrainingprocedures.
‚Ä¢ [Hypothesis]Spuriouscorrelation:Themodelmakesanerrorduetoaspuriouscorrelationbeingpresentin
thetestimage,thatthemodellearntfromthetrainingdata.
‚Ä¢ [Hypothesis]Similarclassfeatures:Themodelmakesanerrorbecausetheerroneoustestsampleissimilar
infeaturestoanotherclassinthedataset.
‚Ä¢ [Hypothesis]Lowdatasetdiversity:Themodelmakesanerrorbecauseitwasnotabletogeneralisefrom
trainingonadatasetwithlowdiversityinthesamples(i.e.,samplesofaclassareallsimilar,notshowingthe
breadthoftheclass).
‚Ä¢ [Hypothesis]Classoverlap:Themodelmakesanerrorbecausetheclassoftheerroneoustestsampleis
highlyoverlappingintermsofclass-relevantfeatureswithanotherclassanddistinctivefeaturesmaynotbe
presentinthedata.
‚Ä¢ [Hypothesis]Datasetimbalance:Themodelmakesanerrorbecauseitwasnotabletogeneralisefroman
imbalanceddataset(i.e.,classimbalance).
‚Ä¢ [Hypothesis]Smalldatasetsize:Themodelmakesanerrorbecauseitwasnotabletogeneralisefroma
smalldataset,insteaditoverfitit.
‚Ä¢ [Action]Removenoisydata:Toovercometheerror,noisydatasuchasmislabeleddata,isremovedfromthe
datasetandthemodelisretrained.
‚Ä¢ [Action]Changinglabeltocorrect:Toovercometheerror,incorrectlylabelledtrainingdataiscorrected
andthemodelisretrained.
‚Ä¢ [Action]Fixlabellingpipelineforfuturedata:Toovercometheerror,thelabellingandannotationpipeline
isinspectedtofindarootcauseforlabellingerrors.
‚Ä¢ [Action]Trainingprocessengineering:Toovercometheerror,hyperparametersandtrainingprocess
protocolsareadjustedandtunedbeforeretraining.
‚Ä¢ [Action]Modelarchitectureengineering:Toovercometheerror,themodelarchitectureisadjusted(e.g.
additionofanotherlayer,choosingadifferentfoundationalmodel).
‚Ä¢ [Action]Featureengineering:Toovercometheerror,thefeatureextractorsofthedatapreprocessingpipeline
areinspected.Thisthemewasmainlyfoundforthetabulardatausecase.
‚Ä¢ [Action]Upweighttofocusonspecificfeatures:Toovercometheerror,certaintrainingdatasamples
shouldbeupweightedsothatthemodellearnsthefeaturespresentinthesesamplesbetter.
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 31
‚Ä¢ [Action]Featureattributioninspection:Toovercometheerror,themisleadingfeaturesmustbeunderstood
first.Featureattributioncouldbeausefultool.
‚Ä¢ [Action]Manualinspection:Toovercometheerror,thetrainingdataismanuallyinspectedtofindanydata
artefacts.Participantsmentionedthattheyalreadydothisaspartoftheirmodeldevelopmentpipeline.
‚Ä¢ [Action]Collectspecificnewdata:Toovercometheerror,newdatarelatedtotheerroneoustrainingsample
shouldbecollectedandaddedtothetrainingdataset.Thiscanimprovedatasetdiversityandhelpthemodel
generalisebetter.
‚Ä¢ [Action]Synthesise/augmentdata:Toovercometheerror,newdatasamplesshouldbesynthesisedorexisting
datasamplesshouldbeaugmentedfurther,targetingthepartsoftrainingdatathatareunderrepresented.This
themewasmentionedoftenundertheassumptionthataddingcompletelynewdataisnotpossible.
‚Ä¢ [Action]Resample/reweightdata:Toovercometheerror,theexistingtrainingdatasetshouldberesampled,
potentiallywithaspecificweightingtoovercomeclassimbalances.
‚Ä¢ [Action]Collectanynewdata:Toovercometheerror,themodelneedstolearnfrommoredata.Hence,
expandingthedatasetoverallwilllikelyhelpthemodelperformance.
D.2 Themearea:Individualmetricpreferences
Thethemearea‚ÄúIndividualmetricpreferences‚Äùgroupsfourthemesandprovidesinsightintowhycertainmetricsare
preferred.
‚Ä¢ [Action/Metric]Labelchangeandprobabilityshowsdecisionboundary:Probabilitiesarethepreferred
metric,especiallyincombinationwiththelabelchangeaction,asitgivestheuseranintuitionaboutthedecision
boundarybetweenthepredictedandground-truthclass.
‚Ä¢ [Metric]Probabilitiesareintuitiveandshowdecisionboundaries:Probabilitiesarethepreferredmetric
becausetheyareanintuitivemetricboundedbetween0-100.Also,theygivetheuseranintuitionaboutthe
decisionboundarybetweenthepredictedandground-truthclass.
‚Ä¢ [Metric]Groundtruthprobabilityisthetarget:Theprobabilityofthegroundtruthclassofthetestsample
ispreferredbecausethisisthetargetmetrictooptimisewhendebuggingthiserroneoustestsample.
‚Ä¢ [Metric]Lossismostinformativeinthemulti-classcase:Thelossispreferredbecauseitentailsinformation
acrossmanyclassesandisadirectindicatorofhowwellthemodelisperformingoverall.Thisisparticularly
interestinginmulti-classclassificationcases.
D.3 Themearea:Reliabilityofexplanations
Thethemearea‚ÄúReliabilityofexplanations‚Äùgroupsthreethemesrelatedtotheoverarchingneedforreliabilityofthe
attributionscores.
‚Ä¢ [Action]Removalshowscausaleffect:Theremovalactionispreferredbecauserepresentsthecausaleffect
oftheinclusionofaspecifictrainingsample.Thiscausaleffectisassumedtobemeaningfulandtherefore
reliable.
‚Ä¢ [Numberofsamples]Groupsizeenoughforreliableattribution:Agroup(i.e.,morethanonetraining
sample)ispreferredfortrainingdataattributionbecauseconsideringtheeffectofagroupismorereliablethan
ofsingletrainingsamples.Thegroupsizeshouldbesufficientlylargefortheattributionscoretobemeaningful
andhence,reliable.
Preprint.Underreview.32 Nguyen,etal.
‚Ä¢ [Numberofsamples]Smallgrouptopreventreasoningchange:Whileagroupoftrainingsamplesis
preferred,thesizeofthegroupshouldbesufficientlysmallsothattheunderlyingmodelstaysratherconsistent
giventheproposedaction(e.g.,iftheattributioncorrespondstotheeffectofremovingùëÅ samples,thiswill
changethedatadistributionwhichaffectsthemodel‚Äôslearning,too).Iftheunderlyingmodelweretochange
toomuch,theattributionscorescouldbearbitraryanditisnotcertainwhetherthemodelbehaviourwillstay
similar,makingthesample-wisedebuggingprocessdifficult.
D.4 Themearea:Groupattributionpreferences
Thethemearea‚ÄúGroupattributionpreferences‚Äùgroupstwothemesthatelaborateondesiredsizesoftrainingdata
groupsasexplanations.Incontrasttotheotheraxesofactionandmetric,thereisaclearpreferencetowardstraining
datagroupattribution,emphasisinganeedformethodsthatservethistask.
‚Ä¢ [Numberofsamples]Groupforanoverviewoftheerror:Agroupoftrainingsamplesispreferredin
theexplanationofthemodelerrortogetabetteroverviewoftheerror,asitisexpectedthatthesamplesof
thegroupwiththehighestattributionarerelatedtothemodelerror.Onesampleistoolittlefortheuserto
understandtheerrorandproposeanactionforwardbasedontheexplanation.
‚Ä¢ [Numberofsamples]Balancebetweenvarietyandconciseness:Whileagroupoftrainingsamplesis
preferred,thegroupsizeshouldbelargeenoughtoshowavarietyofdifferenttrainingsamplesrelatedtothe
modelerror,whilebeingsmallenoughtobeconciseandnotoverwhelmtheuser.
D.5 Unexpectedthemes
Inadditiontothepreviousthemeareas,wefoundthreeadditionalthemeswhichwereunexpected.Theyprovide
contexttotheoverallanalysis,showtwopredominantmindsetsofdevelopersandpointtotheresearchdirectionof
groupingerroneoustestsamples,whichhaslargelybeenoverlooked.
‚Ä¢ Focusonthemodelerrorathand:Themainfocusoftheuserduringthedebuggingprocessliesinunder-
standingthemodelerrorathand,andidentifyingawaytofixtheerror.Thisisalocalfocus.
‚Ä¢ Focusontheoverallmodelperformance:Themainfocusoftheuserduringthedebuggingprocessisto
optimisetheoverallmodelperformance,i.e.,havingtheoverallmodelaccuracyinmind.Thisisaglobalfocus.
‚Ä¢ Groupingerroneoustestsamples:Inthedebuggingprocess,usersseektounderstandthereasonsbehindthe
modelerror.Asingletestsampleisunlikelytobetheonlyinstanceoferroneousmodelbehaviour,e.g.spurious
correlations.Thisthemedescribestheneedforpresentingtheuserwithmultipletestinstancesthatthemodel
errsonsimilarlysothattheuserwillhaveabetterunderstandingoftheerrorwhichwillenablethemtofixit.
‚Ä¢ Studyinterfaceunfamiliar:Inthecomments,weoccasionallyfoundremarksthattheparticipantswere
unsureaboutwhethertheyhadcorrectlyfulfilledthetask,indicatingtheoverallinfamiliaritywithsample-wise
debuggingwithTDAexplanations.
Preprint.Underreview.