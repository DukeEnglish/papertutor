Text-to-Vector Generation with Neural Path Representation
PEIYINGZHANG,CityUniversityofHongKong,China
NANXUANZHAO,AdobeResearch,USA
JINGLIAOâˆ—,CityUniversityofHongKong,China
Chocolate cake The Statue of Liberty A pirate with a parrot Fast Food A crown
with the face of an owl
A spaceship flying in the sky A pig wearing a backpack A torii gate An astronaut riding a horse A painting of the Mona Lisa
Fig.1. Examplesoftext-guidedvectorgraphicsgeneratedbyourframework,withclearandvalidlayer-wisevectorpaths.
1 INTRODUCTION
Vectorgraphicsarewidelyusedindigitalartandhighlyfavoredbydesigners
duetotheirscalabilityandlayer-wiseproperties.However,theprocessof Vectorgraphics,specificallyintheScalableVectorGraphics(SVG)
creatingandeditingvectorgraphicsrequirescreativityanddesignexpertise,
format,playanessentialroleindigitalartssuchasclipart,animation,
makingitatime-consumingtask.Recentadvancementsintext-to-vector
andgraphicdesign.Benefitingfromtheircompositionofgeomet-
(T2V)generationhaveaimedtomakethisprocessmoreaccessible.However,
ricshapes,vectorgraphicsarewidelyfavoredbydesignersdueto
existingT2Vmethodsdirectlyoptimizecontrolpointsofvectorgraphics
theeaseofmanipulation,withthenatureofresolutionindepen-
paths,oftenresultinginintersectingorjaggedpathsduetothelackof
geometryconstraints.Toovercometheselimitations,weproposeanovel denceandcompactfilesizes.However,craftinghigh-qualityvector
neuralpathrepresentationbydesigningadual-branchVariationalAutoen- graphicsrequiresbothprofessionalexpertiseandconsiderabletime
coder(VAE)thatlearnsthepathlatentspacefrombothsequenceandimage investment.Withthesuccessoftext-to-image(T2I)generationmod-
modalities.Byoptimizingthecombinationofneuralpaths,wecanincor- els[Rombachetal.2022;Ruizetal.2022],recentworkshavestarted
porategeometricconstraintswhilepreservingexpressivityingenerated toexploretext-to-vectorgraphicsgeneration(T2V),aimingtomake
SVGs.Furthermore,weintroduceatwo-stagepathoptimizationmethod thecreationmoreaccessibletouserswithtextprompts.
toimprovethevisualandtopologicalqualityofgeneratedSVGs.Inthe
OnecommonT2Vapproachisconductingexistingimagevector-
firststage,apre-trainedtext-to-imagediffusionmodelguidestheinitial
ization[Dominicietal.2020;Maetal.2022;Selinger2003]based
generationofcomplexvectorgraphicsthroughtheVariationalScoreDis-
onT2Iresults.However,T2Imodelsoftengeneraterasterimages
tillation(VSD)process.Inthesecondstage,werefinethegraphicsusing
withphotographicandrealisticstyles,withintricatetextures,and
alayer-wiseimagevectorizationstrategytoachieveclearerelementsand
structure.Wedemonstratetheeffectivenessofourmethodthroughexten- complexcolorvariations.Thisposesachallengewhentransition-
siveexperimentsandshowcasevariousapplications.Theprojectpageis ingtovectorgraphics,wherethegoalistoachievesmoothgeo-
https://intchous.github.io/T2V-NPR. metricshapesanduniformcolors.Theconversionprocessoften
resultsinexcessivelycomplexvectorelements,introducingcompli-
AdditionalKeyWordsandPhrases:VectorGraphics,SVG,DiffusionModel, cationsforsubsequentgraphicmanipulationsanddeviatingfrom
Text-GuidedGeneration
thesimplicityandclarityexpectedinvectorgraphics.Inrecent
developments,anewcategoryofT2Vmethodshasemerged(e.g.,
âˆ—Correspondingauthor CLIPDraw[Fransetal.2022]andVectorFusion[Jainetal.2022]).
Thesemethodsdirectlyoptimizevectorgraphicspathsusinglarge
pre-trainedvisual-textualmodels[Rombachetal.2022].Theyrep-
Authorsâ€™ addresses: Peiying Zhang, City University of Hong Kong, Hong Kong, resentvectorgraphicsthroughparametricshapeprimitives(e.g.,
China,zhangpeiying17@gmail.com;NanxuanZhao,AdobeResearch,SanJose,USA, cubicBÃ©ziercurves)andrefinepathparameters,suchascontrol
nanxuanzhao@gmail.com;JingLiao,CityUniversityofHongKong,HongKong,China,
points.However,directlyoptimizingcontrolpointsoftenleadsto
jingliao@cityu.edu.hk.
4202
yaM
61
]VC.sc[
1v71301.5042:viXra2 â€¢ PeiyingZhang,NanxuanZhao,andJingLiao
intersectingorjaggedpaths,duetotheirhighdegreesoffreedom â€¢ Weproposeadual-branchVAEforlearningneuralpathrepre-
andthelackofgeometryconstraints. sentationfrombothsequenceandimagemodalities.
Therefore,inadditiontorepresentingvectorsastheexplicitpara- â€¢ We develop a two-stage text-driven neural path optimization
metricpaths,itbecomesimperativetodevelopanefficientrepresen- methodtoguidethecreationofvectorgraphicswithvalidand
tationtocapturebothgeometricrelationshipandshapeperception. layer-wiseSVGpaths.
Previousworkshaveexploredlearningsuchlatentrepresentations â€¢ Wedemonstrateseveralpracticalapplicationsenabledbyour
basedonsequencesofSVGsusingdifferentnetworkarchitectures, pipeline.
suchasRecurrentNeuralNetworks(RNN)[HaandEck2017;Lopes
etal.2019;WangandLian2021]andTransformers[Carlieretal. 2 RELATEDWORK
2020;Wangetal.2023b].However,giventheinherentcomplexity
2.1 DiffusionModelsforT2IGeneration
anddiversenatureofSVGs,learningacomprehensiveglobalSVG-
levelrepresentationischallenging.Asaresult,previousmethods Recently,diffusionmodels(DM)havebecomestate-of-the-artinT2I
areoftenrestrictedtogeneratingSVGswithinspecificcategories, generation.Itisafamilyofgenerativemodels,involvingaforward
suchasfonts[Lopesetal.2019;WangandLian2021;Wangetal. processofperturbingthedatawithnoiseandareverseprocess
2023b],sketches[HaandEck2017;Ribeiroetal.2020],andsimple thatgraduallyaddsstructurefromnoise[Hoetal.2020;Nichol
icons[Caoetal.2023;Carlieretal.2020;Wuetal.2023]. etal.2021;Sohl-Dicksteinetal.2015].StableDiffusion[Rombach
Toovercometheabovelimitations,insteadoflearningglobalSVG etal.2022]furtherintroducesimagelatenttothediffusionmodel,
features,weproposeanovelneuralpathrepresentationthateffec- overcomingresolutionlimitationsandenablingthegenerationof
tivelylearnsvalidgeometricpropertiesofpaths.Thisismotivated amazinghigh-resolutionresults.Thediversetypeofuser-defined
bythefindingthatcomplexvectorgraphicsareoftencomposedof conditionmodalitiesenablenumerousdownstreamapplications,
simplepaths[Chenetal.2023;Liuetal.2023].Thiscompactrepre- suchassketch-guidedimagegeneration[Voynovetal.2023;Zhang
sentationensuresbothsimplicityandexpressivity.Tolearnaneural etal.2023b],multi-modalconditionsinimagesynthesis[Zhanetal.
pathrepresentation,wedesignadual-branchVariationalAutoen- 2023],andvariousimage-to-imagegenerationtasks[Sahariaetal.
coder(VAE)tolearnfrombothsequenceandimagemodalities.They 2022;Zhangetal.2023a].Diffusionmodelsalsosupportflexible
jointlyoptimizethesharedpathrepresentation,andthesequence text-guidedimageediting[Hertzetal.2023;Mengetal.2021]and
modalityprovidessupervisionforlearninggeometryproperties, customizationtasks[Kumarietal.2022;Ruizetal.2022].Togenerate
whiletheimagemodalityhelpstolearnrenderingvisualfeatures. personalizedimages,thepioneeringworkDreamBooth[Ruizetal.
Wefurtherproposeatwo-stagepathoptimizationmethodfor 2022]refinestheweightsofadiffusionmodelwithauniquetokento
conductingtext-to-vectorgenerationbasedonthelearnedpathla- capturedistinctivecharacteristicswithinasetofimages.Subsequent
tentspace.Theunderlyingmotivationisthatobtaininghigh-quality worksfocusonfine-tuningonlyparticularpartsofthenetwork,
vectorswithinonestagecanbehard.Inthefirststage,werelyon including low-rank weight residuals [Hu et al. 2021] and cross-
thegenerationpowerofalargepre-traineddiffusionmodel[Rom- attentionlayers[Kumarietal.2022].Ratherthanaimingatraster
bachetal.2022]forgeneratinganinitialSVG.Ratherthanusing imagegeneration,ourmethodleveragesthepowerfulpre-trained
ScoreDistillationSampling(SDS)loss[Pooleetal.2022]asinVec- T2Imodelaspriorstoguidethegenerationofvectorgraphics.
torFusion[Jainetal.2022],whichmaysufferfromover-saturated,
2.2 Text-to-VectorGeneration
over-smooth,andlow-diversityissues,weborrowtheideaofVari-
ationalScoreDistillation(VSD)[Wangetal.2023a]tooptimizea OneapproachinT2VgenerationcombinesT2Igenerationwith
combinationofneuralpathsgiventhetextprompt.Inthesecond imagevectorizationmethods.Traditionalvectorizationmethods
stage,tofurtherimprovethegeometryclarityandlayer-wisestruc- involvesegmentingimagesintoregionsbasedoncolorsimilarity
tureoftheinitiallygeneratedSVG,weapplyapathsimplification [KopfandLischinski2011]andfittingcurvestotheregionbound-
andlayer-wiseoptimizationstrategytohierarchicallyenhancethe aries[Dominicietal.2020;Favreauetal.2017;Hoshyarietal.2018;
paths. Selinger2003;Yangetal.2015].Theadventofdifferentiableren-
Weevaluateourapproachthroughextensiveexperimentsusing dering techniques [Li et al. 2020] enhances image vectorization
vector-level,image-level,andtext-levelmetrics.Theresultsdemon- by enabling the use of loss functions in image space. LIVE [Ma
stratetheeffectivenessofourmodelingeneratinghigh-qualityand etal.2022]optimizespathparametersguidedbythereconstruction
diversevectorgraphicswithvalidpathsandlayerproperties,given oftheinputimage.Recentdevelopmentshaveexploredtraining
theinputtextprompt.Fig.1showsexamplesoftext-to-vectorgener- end-to-endneuralnetworksforimagevectorization[Chenetal.
ationresultsproducedbyourframework.Ourmodelenablesvarious 2023;Reddyetal.2021;Rodriguezetal.2023].However,thiskind
applicationsexceptforT2Vgeneration,suchasvectorgraphicscus- ofmethodreliesonimagesgeneratedbypre-trainedT2Imodels,
tomization,image-to-SVGgeneration,andSVGanimation.Ourkey whichstruggletoproducehigh-qualitySVG-styleimagesfeaturing
contributionsare: cleargeometricprimitivesandflatcolors.Withthedevelopment
ofgenerativeAI,severalcommunity-madetoolsandcommercial
productssuchasAdobeIllustrator[Illustrator2023],Illustroke[Il-
â€¢ We introduce a novel T2V generation pipeline, innovated by lustroke2024],andKittl[Kittl2024],offercapabilitiestogenerate
theideaofoptimizinglocalneuralpathrepresentationforhigh- vectorgraphicsfromtextpromptsbyemployingvectorizationtech-
qualityvectorgraphicsgeneration. niqueswithT2Imethods.ToproducevisuallyappealingSVG-styleText-to-VectorGenerationwithNeuralPathRepresentation â€¢ 3
Input Reconstruction Optimization with VSD (Stage 1) Optimization with
Layer-wise
Vectorization (Stage 2)
Input Text Prompt
SE ğ’›ğ’”ğ’†ğ’’ SD V Pe ac tt hor ColorrT mra an ts iofo n "A tiger karate master" Diffusion â€¦
Vector Path Vector Path
ğ’›ğŸ ğ‘ªğŸ ğ‘»ğ’“ğŸ Model V Pe ac tt ho sr
Image
Rendered ğ’› Finetune Loss
Path
ğ’›ğŸ SD ğ‘ªğŸ ğ‘»ğ’“ğŸ
Guidance image
Latent LoRA Model
IE ğ’›ğ’Šğ’ğ’ˆ ID ğ’›ğ’ ğ‘ªğ’ ğ‘»ğ’“ğ’Œ Rendered image Add Noise D Miff ou ds eio ln
Path Image Path Image
Output SVG
(a)Neural Path Representation Learning (b) Text-driven Neural Path Optimization
Fig.2. Oursystempipelinestartswithlearninganeuralrepresentationofpathsbytrainingadual-branchVAE.Next,weoptimizetheSVG,representedwith
neuralpaths,toalignwiththeprovidedtextprompt,whichisachievedthroughatwo-stagepathoptimizationprocess.
images,itisessentialtofine-tunepre-trainedT2Imodels[Huetal. IconShop[Wuetal.2023]achievesT2Vgenerationbyrepresenting
2021;Ruizetal.2022].Thesefine-tuningmethodsheavilyrelyon SVGsastokensequencescombinedwithtexttokens.
thetrainingdataset,requiringalabor-intensivecollectionofimages PreviousworksfocusonlearningSVG-levellatentrepresentations
andtextualtags. fromSVGcommandsequences.However,thevastdiversityofpath
AnotherapproachforT2Vgenerationinvolvesdirectlyoptimiz- combinationsposesachallengeinlearningauniversalglobalSVG-
ingthegeometricandcolorparametersofSVGpathsunderthe levelrepresentation.Asaresult,existingmethodspredominantly
guidanceofpre-trainedvision-languagemodels,suchastheCLIP generateSVGsinspecificcategorieslikefonts[Lopesetal.2019;
model[Radfordetal.2021]orthediffusionmodel[Rombachetal. WangandLian2021;Wangetal.2023b],sketches[HaandEck2017;
2022].CLIP-basedmethods[Fransetal.2022;Schaldenbrandetal. Ribeiroetal.2020],andsimpleicons[Caoetal.2023;Carlieretal.
2022;Songetal.2022]utilizetheimage-textsimilaritymetricwithin 2020;Wuetal.2023].Incontrast,ourneuralpathrepresentation
CLIPlatentspacetocreatevectorgraphicsfromtextprompts.Apart capturesvalidpathproperties,whileenablingthegenerationof
fromtheCLIPdistance,ScoreDistillationSampling(SDS)lossbased diverseandcomplexvectorgraphicsfromtextprompts.
onaT2IdiffusionmodelisusedforoptimizingSVGtoalignwithtext
promptsacrossvariousapplicationssuchasfonts[Iluzetal.2023], 3 OVERVIEW
vectorgraphics[Jainetal.2022;Xingetal.2023b],andsketches[Gal
Givenatextprompt,ourgoalistogenerateanSVGthataligns
etal.2023;Xingetal.2023a].However,thesemethodsoftenleadto
withthesemanticsofthetextpromptwhileexhibitingdesirable
SVGswithclutteredandirregularpaths,asthedirectoptimization
pathpropertiesandlayer-wisestructuresconsistentwithhuman
ofcontrolpointsinparametricpathslikecubicBÃ©ziercurveslacks
perception.SinceanSVGiscomposedofasetofpaths,denotedas
essentialgeometricrelationships.
ğ‘†ğ‘‰ğº ={ğ‘ƒğ‘ğ‘¡â„ 1,ğ‘ƒğ‘ğ‘¡â„ 2,...,ğ‘ƒğ‘ğ‘¡â„ ğ‘š},ourobjectiveistooptimizeaset
ofğ‘špathsbasedonatextpromptğ‘‡ through:
2.3 NeuralRepresentationforSVG
NeuralPathRepresentationLearning(Sec.4). Thepathgeometry
Previousworkshaveexploredlearningvariousrepresentationsof consistsofconnectedcubicBÃ©ziercurves.Ourobjectiveistolearn
SVG,anddesigningdifferentnetworkarchitecturestounderstand aneuralpathrepresentationbymappingeachpathintoalatent
thegeometricinformationandglobalperceptioninherentinSVG codedenotedasğ‘§,whichcapturesvalidgeometricproperties.To
data.SketchRNN[HaandEck2017]leveragesarecurrentneural achievethis,weproposeadual-branchVAEthatlearnsfromboth
network(RNN)togeneratevectorpathsforsketches.SVG-VAE theimageandsequencemodalitiesofpaths(refertoFig.2(a)).
[Lopesetal.2019]usesanimageautoencodertocapturefontstyle
featuresandemploysLSTMstogeneratevectorfonts.Sketchformer Text-drivenNeuralPathOptimization(Sec.5). Withthelearned
[Ribeiroetal.2020]usesaTransformertorecoversketchstrokes neural path representation, an SVG can be represented by a set
inavectorformbasedonrasterimages.Tomaintainhierarchical oflatentcodes,alongwithcolorandtransformationparameters
relationships in SVGs, DeepSVG [Carlier et al. 2020] employs a associatedwitheachpath,denotedasğ‘†ğ‘‰ğº ={ğœƒ 1,ğœƒ 2,...,ğœƒ ğ‘š},where
hierarchicalTransformer-basednetworktogeneratevectoricons ğœƒ ğ‘– =(ğ‘§ ğ‘–,ğ¶ ğ‘–,ğ‘‡ğ‘Ÿ ğ‘–).Here,ğ‘§ ğ‘–,ğ¶ ğ‘–,andğ‘‡ğ‘Ÿ ğ‘–representthelatentcode,color
composedofmultiplepaths.Dual-modalitylearningframework parameter,andtransformationparameterfortheğ‘–-path(ğ‘ƒğ‘ğ‘¡â„ ğ‘–),re-
[Liuetal.2023;WangandLian2021;Wangetal.2023b]utilizes spectively.Next,weusethetextpromptğ‘‡ tooptimizethecombina-
bothsequenceandimagefeaturestosynthesizeaccuratevector tionofğ‘špathsthroughtwostages.Inthefirststage,weutilizea
fonts. A Transformer-based framework is designed to vectorize pre-traineddiffusionmodelasapriortooptimizethecombination
linedrawingswithdual-modalsupervision[Liuetal.2022],butit ofneuralpathsalignedwithğ‘‡.Inthesecondstage,weapplyalayer-
lackssmoothinterpolationcharacteristicsinthelatentspace.While wisevectorizationstrategytooptimizepathhierarchy,ensuring
thesetechniqueshavenotyetsupportedtext-guidedSVGcreation, clearvisualelementsandlayerstructuresinthegeneratedSVG.
â€¦ â€¦ â€¦ â€¦
Render Diff4 â€¢ PeiyingZhang,NanxuanZhao,andJingLiao
Finally,afterdecodingtheoptimizedlatentcodesintoBÃ©ziercurves,
weobtaintheresultingSVG(refertoFig.2(b)). Chamfer
Distance
Loss
BÃ©zier Curve BÃ©zier Curve
4 NEURALPATHREPRESENTATIONLEARNING Sampling Points Sampling Points
PreviousT2Vapproachesdirectlyoptimizethecontrolpointsof ğ’‘ğŸ ğ’‘"ğŸ
parametricpaths.However,thisoftenleadstointersectingorjagged ğ’‘ğŸ ğ’‘"ğŸ
Dual-Branch
pathsduetothehighdegreesoffreedomandthelackofgeometric ğ’‘ğ’Œ Network ğ’‘"ğ’Œ
constraints.Toaddressthisissue,weproposeanovelapproachthat Vector Path C po on intr to sl C po on intr to sl Vector Path
learnsaneuralpathrepresentationwithinalatentspace,capturing Rendered
thevalidgeometricpropertiesofpathsandenablingtheoptimiza-
tionofpathswhileensuringgeometricregularity.Forthispurpose, L1
+ Perceptual
wedesignandtrainadual-branchVAEtolearnalatentspacefor Loss
Path Image Path Image
pathrepresentation. (a)Input (b)Reconstruction
Fig.3. Traininglossofthedual-branchVAE.
4.1 Dual-branchVAE
Aparametricpath(ignoringthecolorparameter)canbedefined
Modality Fusion. We fuse the sequence and image features to
asaseriesofcubicBÃ©ziercurvesconnectedend-to-end,denoted
ğ‘˜as cğ‘ƒ oğ‘ nğ‘¡ tâ„ ro= lp( oğ‘ i1 n, tğ‘ s2 u,. se.. d,ğ‘ toğ‘˜) d, ew fih ne er te hğ‘ eğ‘— cf uo br icğ‘— B= Ã©z1 iet ro cğ‘˜ urr vep esr .es Be ynt us tit lh ize
-
c sere qa ut ee na ceco fem atp ur re eh se ğ‘§n ğ‘ s ğ‘’i ğ‘ve anre dp ir mes ae gn eta feti ao tn uro ef sp ğ‘§a ğ‘–ğ‘šth ğ‘”s a. rS epe coci nfi cc aa tl ely n, at th ede
andpassedthroughalinearprojectionlayer,obtainingalatentcode
ingthedifferentiablerasterizerR [Lietal.2020],wecanrender
thevectorpathandobtaintherasterizedpathimageğ¼ =R(ğ‘ƒğ‘ğ‘¡â„). ğ‘§ âˆˆRğ‘‘ğ¹,whereğ‘‘ ğ¹ =24,thatissharedwithbothmodalities.
Thesequencerepresentationofapathcontainsrichgeometricin- Decoder. Thelatentcodeğ‘§ispassedthroughthetwodecoding
formation,suchastheorderingandconnectionsbetweenpoints branchestoreconstructthevectorpathandpathimage,respectively.
inthepath.TrainingaVAEbasedonthepointsequenceenables ThesequencedecoderhasasimilarTransformer-basedarchitec-
effectivelearningofgeometricproperties,butitstrugglestopre- turetothesequenceencoder.Ittakesğ‘§ asinputandoutputsthe
ciselyreconstructtherenderedshape.Ontheotherhand,theimage decodedpointssequenceğ‘ƒğ‘Ë†ğ‘¡â„ = (ğ‘Ë† 1,ğ‘Ë† 2,...,ğ‘Ë†ğ‘˜).Theimagede-
representationisbetteratcapturingvisualfeaturesafterrendering, coderisadeconvolutionalneuralnetworkthatutilizesğ‘§togenerate
butitcannotrepresenttherelationshipsbetweencontrolpoints,as thereconstructedpathimageğ¼Ë†.
differentsequencesofcontrolpointsmayresultinthesameren-
deredshape.Toaddressthesechallenges,weproposeadual-branch 4.2 Training
encoder-decoderVAEthatlearnsasharedlatentspacefrompath
LossFunction. Thedual-branchVAEistrainedend-to-endtore-
datainbothvectorandimagemodalities,asshowninFigure2(a).
constructtheinputusingdual-modalitylosses.However,simply
Thisapproachallowsfortheincorporationofbothgeometricand
usingmeansquarederror(MSE)lossbetweentheinputandoutput
visualinformation,enablingamorecomprehensiveandaccurate
controlpointsequencesforsequencereconstructioncanleadto
learningofpaths.
overfitting,asdifferentcontrolpointsequencescanproducesimilar
shapes.Toaddressthis,weintroduceashape-levellosstocapture
Encoders. Theencoderofourdual-branchVAEiscomposedofa shapefeatures.AsdepictedinFig.3,wefirstsampleğ‘› auxiliary
sequenceencoderandanimageencoder.Thesequenceencoder points(inourimplementation,ğ‘›=4)fromeachcubicBÃ©ziercurveof
takesthecontrolpointsequenceasinputandemploysatransformer avectorpath,resultingintheauxiliarypointssetğ‘ƒ ğ‘ğ‘¢ğ‘¥.Next,wecal-
architecturewithanattentionmechanismtoexploitthegeometric culatetheChamferDistancebetweentheauxiliarypointssetofthe
relationshipsbetweencontrolpoints.First,wenormalizethecon- inputpathğ‘ƒğ‘ğ‘¡â„andthatofthereconstructedpathğ‘ƒğ‘Ë†ğ‘¡â„bysumming
trolpointssequencetotherangeof[0,1]andthenusealearnable
thedistancesbetweenthenearestcorrespondencesofthetwopoint
embeddinglayertoprojecteachnormalizedcontrolpointintoa sets.ThiscalculationyieldstheChamferlossLğ‘ğ‘“ğ‘Ÿ(ğ‘ƒğ‘ğ‘¡â„,ğ‘ƒğ‘Ë†ğ‘¡â„).The
ğ‘‘ â„-dimensionalvector.SimilartoDeepSVG[Carlieretal.2020],we image-levellosscombinestheğ¿ 1lossandperceptuallossbetween
usepositionalencodingtoembedtheindexofeachpointinthe theinputimageğ¼ andreconstructedimagesğ¼Ë†.Specifically,itcan
sequence.Thesequenceembeddingğ‘’ ğ‘ ğ‘’ğ‘ âˆˆRğ‘‘â„Ã—ğ‘˜ isthenfedinto beexpressedasLğ‘–ğ‘šğ‘” = |ğ¼ âˆ’ğ¼Ë†| 1+Lğ‘ğ‘’ğ‘Ÿğ‘ğ‘’ğ‘(ğ¼,ğ¼Ë†).Inadditiontothe
thesixtransformerlayers.Eachlayerconsistsofmaskedmulti-head
reconstructionlossesinbothmodalities,thelatentspaceisalso
attention and feed-forward layers [Vaswani et al. 2017]. Finally, regularizedbytheKLdivergencelossLğ‘˜ğ‘™,whichencouragesthe
alinearprojectionisappliedtoobtaintheaggregatedoutputse- latentcodeğ‘§tofollowaGaussiandistributionN(0,ğ¼).
quencefeaturesğ‘§
ğ‘ ğ‘’ğ‘
âˆˆRğ‘‘ğ‘†.Tofurtherlearntheshapeperception
Theoveralllossfunctionis:
of the path, we also adopt an image encoder composed of six
convolutionallayers.Ittakestherasterizedpathimageğ¼ asinput L=ğœ† ğ‘ğ‘“ğ‘ŸLğ‘ğ‘“ğ‘Ÿ +ğœ† ğ‘–ğ‘šğ‘”Lğ‘–ğ‘šğ‘”+ğœ† ğ‘˜ğ‘™Lğ‘˜ğ‘™, (1)
andoutputsthefeatureğ‘§ ğ‘–ğ‘šğ‘” âˆˆRğ‘‘ğ¼.Inourimplementation,weset whereğœ† ğ‘ğ‘“ğ‘Ÿ,ğœ† ğ‘–ğ‘šğ‘”,ğœ† ğ‘˜ğ‘™ are the weights of each loss term. We set
ğ‘‘ â„ =64,ğ‘‘ ğ‘† =32,andğ‘‘ ğ¼ =64. ğœ† ğ‘ğ‘“ğ‘Ÿ =1,ğœ† ğ‘–ğ‘šğ‘” =0.1,ğœ† ğ‘˜ğ‘™ =0.01inourimplementation.
â€¦ â€¦Text-to-VectorGenerationwithNeuralPathRepresentation â€¢ 5
tohierarchicallyoptimizepathcombinations,ensuringclearvisual
elementsandwell-definedlayer-wisestructuresintheresultSVG.
Next,weintroducethesetwostages.
(a) Path samples from dataset
5.1 OptimizationwithVariationalScoreDistillation
Inthisstage,weoptimizeaninitialSVGguidedbythetextprompt
ğ‘‡.WedrawinspirationfromVectorFusion[Jainetal.2022],which
(b) Random samples in the latent space (c) Latent Interpolations
leveragesapre-trainedtext-to-imagediffusionmodelasapriorto
optimizepathparametersthroughaScoreDistillationSampling
Fig.4. Pathsamplesandlatentinterpolations.(a)Pathexamplesfromthe
(SDS) process. The process begins with anğ‘†ğ‘‰ğº with randomly
dataset.(b)Pathsamplesdecodedfromrandomvectorsinthelatentspace.
(c)Latentinterpolationsamongfourgivensamples(markedinred).
initializedpathparametersğœƒ,andineachiteration,theğ‘†ğ‘‰ğºisren-
deredusingthedifferentiablerasterizerRtoobtainarasterimage
ğ¼ ğ‘†ğ‘‰ğº = R(ğ‘†ğ‘‰ğº).Thepre-trainedencoderofthediffusionmodel
encodesğ¼ ğ‘†ğ‘‰ğº intolatentfeaturesx = E(ğ¼ ğ‘†ğ‘‰ğº),andaGaussian
TrainingDetails. Wetrainourdual-branchVAEontheFIGR-8- noiseğœ– âˆˆN(0,ğ¼)isaddedtox,obtainingxğ‘¡ attimeğ‘¡oftheforward
SVGdataset[ClouÃ¢treandDemers2019],whichconsistsofblack-
diffusionprocess.Finally,theSDSlossisdefinedasthedistance
and-whitevectoricons.Topreprocessthedata,wefollowthesame betweentheaddednoiseğœ– andthepredictednoiseğœ– ğœ™ usingthe
stepsasIconShop[Wuetal.2023]toobtainvalidSVGdata.We pre-traineddiffusionmodel,anditsgradienttooptimizeğœƒ canbe
extractpathsfromtheSVGsandremoveduplicateshapes.InFig.4,
estimatedasfollows:
weshowcaseseveralexamplesofpathsfromthedataset.Forthe
rawinput,sincethecontrolpointsequencesineachpathcanhave âˆ‡ğœƒL SDS â‰œE ğ‘¡,ğœ–
(cid:20) ğ‘¤(ğ‘¡)(cid:16)
ğœ– ğœ™
(xğ‘¡;ğ‘‡,ğ‘¡)âˆ’ğœ–(cid:17) ğœ• ğœ•ğœƒx(cid:21)
(2)
variablelengths,wepadthepointsequenceswithzerostoafixed
length(inourimplementation,ğ‘˜ = 50)andfilteroutthosewith whereğ‘¤(ğ‘¡)isatime-dependentweightingfunction.
longerlengths.Thisresultsin200,000samplesformodeltraining. Despiteitssuccess,empiricalobservationshaverevealedthatre-
TheimageresolutionfortrainingVAEis64Ã—64.Totrainthemodel,
sultsoptimizedfromSDSsufferfromissuessuchasover-saturation,
weusetheAdamoptimizerwithaninitiallearningrateof0.001. over-smoothing,andalackofdiversity.TheseissuesstemfromSDS
Weincorporatelinearwarmupanddecaytechniques.Thedropout treatingparameterğœƒ asasinglepointandusingasinglepointto
rateinalltransformerlayersissetto0.1.Wetrainthedual-branch approximateadistributionoutputbythediffusionmodel.Inlightof
networkfor100epochs. this,weleveragetheVSDlossproposedbyProlificDreamer[Wang
Uponcompletionoftraining,weobtainasmoothlatentspace etal.2023a]toreplaceSDSinouroptimization.UnlikeSDS,VSD
sharedbybothmodalities.InFig.4,wepresentpathsdecodedfrom modelstheparameterğœƒ asadistribution,andconsequently,the
randomsamplesinthelearnedlatentspace,alongwithsmoothpath imagesrenderedbyğ‘†ğ‘‰ğºwithparameterğœƒ arealsoadistribution.
interpolations. FollowingProlificDreamer,weemployLoRA(Low-rankadaptation)
[Huetal.2021]ofthepre-traineddiffusionmodeltomodelthedis-
5 TEXT-DRIVENNEURALPATHOPTIMIZATION
tributionoftherenderedimages.Therefore,theVSDlossisdefined
Withthelearnedneuralpathrepresentation,anSVGcanberep- as the distance between the noises predicted by the pre-trained
resentedbyacombinationofğ‘špathsinthelatentspace,denoted diffusionmodelandtheLoRAmodel.Itsgradienttooptimizeğœƒ can
asğ‘†ğ‘‰ğº = {ğœƒ 1,ğœƒ 2,...,ğœƒ ğ‘š},whereğœƒ ğ‘– = (ğ‘§ ğ‘–,ğ¶ ğ‘–,ğ‘‡ğ‘Ÿ ğ‘–).Here,thelatent beformulatedasfollows:
codeğ‘§ ğ‘– definestheshape,ğ¶ ğ‘– definesthecolor,andğ‘‡ğ‘Ÿ ğ‘– definesthe
affinetransformationoftheğ‘ğ‘ğ‘¡â„ ğ‘–.Weinitializethelatentcodesby (cid:20) (cid:16) (cid:17) ğœ•x(cid:21)
randomlydrawingfromazero-meanGaussiandistribution.Our âˆ‡ğœƒL VSD â‰œE ğ‘¡,ğœ– ğ‘¤(ğ‘¡) ğœ– ğœ™ (xğ‘¡;ğ‘‡,ğ‘¡)âˆ’ğœ– LoRA(xğ‘¡;ğ‘‡,ğ‘¡) ğœ•ğœƒ (3)
aimistooptimizetheseparametersbasedonthegiventextprompt
ğ‘‡.Unlikepreviousmethods[Jainetal.2022;Xingetal.2023b]that TheuseofVSDhelpsgenerateSVGswithhigherqualityand
optimizecontrolpointsexplicitly,weoptimizethelatentcodeğ‘§ diversity.WedenotetheSVGoptimizedfromthisstageasğ‘†ğ‘‰ğº0,
withinthelearnedspacetoguaranteetheregularityofeachpath whichwillguidethelayer-wiserefinementinthenextstage.
intheresult.Afteroptimization,wecanobtaincontrolpointsofa
5.2 OptimizationwithLayer-wiseVectorization
pathbydecodingğ‘§ ğ‘– withoursequencedecoderandtransforming
pointswithğ‘‡ğ‘Ÿ ğ‘–,asğ‘ƒğ‘ğ‘¡â„ ğ‘– =ğ‘‡ğ‘Ÿ ğ‘– Â·ğ‘†ğ‘’ğ‘ğ·ğ‘’ğ‘(ğ‘§ ğ‘–). AlthoughVSDoptimizationiseffectiveinaligningSVGswithtext
Moreover,previousworks[Fransetal.2022;Jainetal.2022]simul- prompts,itoftenresultsinclutteredandstackedpaths.Thiscan
taneouslyoptimizeallpathsofanSVGinasinglestage,resultingin introduceartifactsandleadtoapoorlyorganizedlayerstructure
clutteredpathsandamessylayerstructure.Totacklethischallenge, withintheSVG,complicatingsubsequenteditingandmodification.
wehavedevelopedatwo-stageneuralpathoptimizationprocess,as Toenhancetheclarityofvectorelementsandthehierarchicalstruc-
showninFig.2(b).Inthefirststage,weemployVSDdefinedona tureofthegeneratedSVG,weintroduceasecond-stageoptimization
pre-trainedtext-to-imagediffusionmodeltooptimizepaths,result- basedonğ‘†ğ‘‰ğº0obtainedfromthepreviousstage.Thisstageincor-
inginaninitialSVGthatalignswithğ‘‡.Inthesecondstage,starting poratesapathsimplificationsteptoobtainasimplifiedpathset,and
fromtheinitialSVG,weapplyalayer-wisevectorizationstrategy alayer-wisevectorizationstrategytohierarchicallyoptimizepath6 â€¢ PeiyingZhang,NanxuanZhao,andJingLiao
numberofpathstocoverthecontentoftheguidanceimageasmuch
"A tiger karate master " ğ’›ğŸ ğ’›ğŸ ğ’›ğŸ ğ’›ğŸâ€¦ ğ’›ğ’Š ğ’›ğŸâ€¦ ğ’›ğ’ aspossible,weapplytheintersection-over-union(IoU)lossbetween
Sequence Sequence Sequence Sequence therenderedsilhouetteofğ‘†ğ‘‰ğºğ‘˜ andtheforegroundregionofğ¼ ğ‘”.
Decoder Decoder Decoder Decoder Theoveralllossfunctionisdefinedasğ¿ ğ‘™ğ‘¦ğ‘Ÿ = ğ¿ ğ¶ğ¿ğ¼ğ‘ƒ +ğœ† ğ¼ğ‘œğ‘ˆğ¿ ğ¼ğ‘œğ‘ˆ,
â€¦ â€¦ whereğœ† ğ¼ğ‘œğ‘ˆ issetto0.01.
â€¦
SVGVSD
ğ‘ªğŸ ğ‘ªğŸ ğ‘ªğŸ ğ‘ªğŸ â€¦ ğ‘ªğ’Š ğ‘ªğŸ â€¦ ğ‘ªğ’ Vector
Astheiterationsprogress,morepathsareinvolvedintheop-
Diffusion ğ‘»ğ’“ğŸ ğ‘»ğ’“ğŸ ğ‘»ğ’“ğŸ ğ‘»ğ’“ğŸâ€¦ ğ‘»ğ’“ğ’Š ğ‘»ğ’“ğŸâ€¦ğ‘»ğ’“ğ’ Paths timizationprocess,andtheSVGgraduallyaddsdetails.Whenall
Model pathsareoptimized,weobtainthefinalresult,ğ‘†ğ‘‰ğºğ‘› withğ‘›paths.
6 EXPERIMENTS
â€¦
ExperimentSetup. Toevaluateourmethod,wecollect160text
Guidance image Output SVG promptsfromtheStableDiffusionPromptsdataset[Dehoucheand
Neural Paths Optimization
Kullathida2023],includingadiverserangeofcharacters,actions,
Fig.5. Layer-wiseoptimizationstrategy. andscenes.Foreachprompt,wegenerate5SVGs,culminatingina
totalof800vectorgraphics.Toencouragethegenerationtowards
aflatvectorstyle,weappendthephrase"minimalflat2dvector"
combinationswiththeassistanceofaguidanceimage.Thisstage toeachprompt.InVSDoptimizationprocess,weutilizetheofficial
canimprovetheoverallqualityandorganizationoftheresulting "SD-v1-5"checkpoint1 withaguidancescaleof10,andtimestep
SVG,makingiteasiertoeditandreuse. ğ‘¡ âˆ¼U(50,950)isuniformlysampled.
PathSimplification. Weremovepathsinğ‘†ğ‘‰ğº0withanopacity 6.1 EvaluationMetrics
below0.05oranareasmallerthan10pixels,andmergeoverlapping
pathsthatexhibitthesamecolorintoasinglepathusinganoverlap Weevaluatethequalityofourresultsfromvector-level,image-level,
thresholdof5pixels.Thesestepsreducethenumberofpathsfrom andtext-levelperspectives.
ğ‘š toğ‘›. The simplified path set with sequence representation is Vector-level. Drawing upon criteria from prior perception re-
theninverselytransformedintothelatentspaceusingoursequence searchinvectorgraphics[Dominicietal.2020;Favreauetal.2017],
encoder,obtaininganewsetoflatentcodesandresultinginanew agoodSVGshouldminimizeredundantpathstopreservecompact-
SVG,ğ‘†ğ‘‰Ëœğº0.
nessandeditability.Basedonthisguideline,weassessvectorization
qualityusingthefollowingmetrics:(a)Smoothness:Inverseof
Layer-wiseOptimizationStrategy. Aftersimplification,wefurther
theaveragecurvaturevariationofthepathsingeneratedSVGs.
refinetheğ‘†ğ‘‰Ëœğº0withenhancedperceptualclarityandabetterlayer-
(b)Simplicity:Theaveragenumberofpathsingeneratedvector
wisestructurewiththeassistanceofaguidanceimage.Theguidance
graphics.(c)Layer-wisesemantics:Thesemanticsofpathsare
imageisobtainedbyfirstrenderingğ‘†ğ‘‰Ëœğº0intotheimageğ¼ ğ‘†0 ğ‘‰ğº.Then, evaluatedbycomparingthedecreaseinCLIPsimilaritybetween
weperturbğ¼ ğ‘†0 ğ‘‰ğº withGaussiannoise,settingthenoisestrengthto theSVGrenderresultsandcorrespondingtextpromptsbeforeand
0.4,andgraduallyremovethenoiseusingapre-traineddiffusion afterrandomlyremoving30%oftheSVGpaths.Alargerdecrease
model.ThisprocesshelpsreduceartifactsintheinitialSVGand indicatesthateachpathhasmorespecificsemantics.
yieldsaguidanceimageğ¼ ğ‘” withclearerandmoreprecisevisual
Image-level. Toevaluatethevisualqualityanddiversityofvector
elements.
Withthehelpofğ¼ ğ‘”,weintroducealayer-wiseoptimizationstrat- graphics,wecollectedadatasetof800well-designedvectorgraphics
egy.Specifically,wesortthepathsinğ‘†ğ‘‰Ëœğº0
byareaandthenop-
fromiconfont2,encompassingvariouscategoriesincludingcharac-
ters,animals,andscenes.Thesesamplesserveasthegroundtruth
timizethetopğ‘˜ pathswiththelargestareasineachiteration.A
forcalculatingtheFIDmetricsonrenderedimagesofSVGs.
recursivepipelineprogressivelyaddspathsaccordingtoapathnum-
berschedule,thusoptimizingtheSVGfromcoarsetofine,asshown Text-level. To compute whether the generated SVG is aligned
inFig.5. withtheinputtextprompt,wedefinethetext-levelsimilarityby
Ineachiteration,weoptimizetheparametersofthetopğ‘˜paths calculatingtheCLIPcosinesimilarity[Radfordetal.2021]between
inğœƒËœ0,denotedasğ‘†ğ‘‰ğºğ‘˜ ={ğœƒ 1,ğœƒ 2,...,ğœƒ ğ‘˜}.Theoptimizationisbased thetextpromptandrenderedSVG.
onCLIPlossandIoUlossdefinedbetweenğ‘†ğ‘‰ğºğ‘˜
andtheguidance
6.2 Baselines
imageğ¼ ğ‘”.TheCLIPlossiscomputedbysummingtheğ¿ 2distances
betweentheintermediate-levelactivationsoftheCLIPmodelas WecompareourproposedpipelinewithtwotypesofT2Vpipelines.
follows:
VectorizationwithT2I. Wefirstgenerateimagesfromtextprompts
ğ¿ ğ¶ğ¿ğ¼ğ‘ƒ =âˆ‘ï¸ âˆ¥ğ¶ğ¿ğ¼ğ‘ƒ ğ‘™(Iğ‘”)âˆ’ğ¶ğ¿ğ¼ğ‘ƒ ğ‘™(R(ğ‘†ğ‘‰ğºğ‘˜ ))âˆ¥2 2, (4) usingadiffusionmodelandthenconverttheimagesintoSVGsusing
ğ‘™ twodistinctvectorizationmethods:(a)Potrace[Selinger2003]:A
ğ¶ğ¿ğ¼ğ‘ƒ
ğ‘™
denotestheCLIPencoderactivationatlayerğ‘™.Itevaluatesthe traditionalvectorizationmethodinvolvesimagesegmentationand
image-levelsimilarityandencouragestherenderingofğ‘†ğ‘‰ğºğ‘˜
tobe 1https://huggingface.co/runwayml/stable-diffusion-v1-5
faithfultotheguidanceimageğ¼ ğ‘”.Moreover,toencouragealimited 2https://iconfont.cnText-to-VectorGenerationwithNeuralPathRepresentation â€¢ 7
Table1. Quantitativecomparisonwithexistingmethods.
"An astronaut walking
"An erupting volcano" "Vincent Van Gogh"
across a desert"
Methods Smoothâ†‘ Simpâ†“ Layerâ†‘ FIDâ†“ CLIPâ†‘
T2I+Potrace 0.7846 430 0.0226 104.92 0.2732 (a) Potrace
T2I+LIVE 0.5797 40 0.0119 97.82 0.2519
T2I+LoRA+Potrace 0.7882 160 0.0395 45.16 0.2729
CLIPDraw 0.4711 128 0.0317 123.55 0.2832
Diffsketcher 0.4829 128 0.0105 92.36 0.2607
Vectorfusion(fromscratch) 0.6322 128 0.0139 65.71 0.2675 (b) LIVE
Vectorfusion(fromLIVE) 0.5025 128 0.0258 76.45 0.2880
Ours 0.8012 40 0.0591 52.30 0.3015
(c) Lora +
curvefittingtotransformrasterimagesintoSVGs.(b)LIVE[Maetal. Potrace
2022]:AdeeplearningmethodthatgeneratesSVGsbyoptimizing
pathsusinglossfunctionsdefinedintheimagespace.Weusethe
samenumberofpathsasourmethod.
(d) Ours
Text-guided SVG optimization. We compare our method with
CLIP-basedanddiffusion-basedoptimizationapproaches:(c)CLIP-
Draw[Fransetal.2022]:Amethodthatleveragestheimage-text Fig.6. QualitativecomparisontovectorizationwithT2Imethods.
similaritymetricofCLIPtooptimizeSVGsfromprompts.(d)Diffs-
ketcher[Xingetal.2023a]:Amethodincorporatesbothimage-level
CLIPlossandSDSlossfortext-guidedsketchgeneration.(e)Vec- weutilizethe"VectorIllustration"LoRA3 fine-tunedonthebase
torFusion[Jainetal.2022]:ThisapproachemploysSDSlossto diffusionmodel"SD-v1-5",andthenconvertthegeneratedimagesto
optimizeSVGstoalignwithgiventextprompts.Itofferstwoopti- vectorgraphicsusingPotrace.SincethisLoRAmodelisspecifically
mizationroutes:startingfromscratchorrefiningvectorizedresults fine-tunedonwell-designedvectorgraphicsimagessimilartothe
producedbyLIVE.Weuse128pathsfortext-guidedSVGoptimiza- iconfontdatasetweusedforevaluation,thegeneratedresultsexhibit
tionmethods,consistentwiththedefaultsettinginVectorFusion. lower FID scores. However, as demonstrated in Fig. 6 (c), while
thisbaselineachievespleasingvisualresults,itstillstruggleswith
6.3 Comparisons overcomplicatedanddisorganizedpaths,asthisisacommonissue
intraditionalimagevectorizationmethods.Incontrast,ourmethods
Weevaluatetheperformanceofourmethodbycomparingitwith
producevisuallyappealingSVGswithsmoothpathsandlayer-wise
baselinesqualitativelyandquantitatively.Thequantitativeresults
structures.
areprovidedinTab.1andthequalitativeresultsareshowninFig.6
and Fig. 17. As shown in Tab. 1, our method outperforms other ComparisonswithText-guidedSVGOptimizationMethods. These
approachesfromacomprehensiveperspective. methodsdirectlyoptimizethecontrolpointsofparametricpaths.
However, due to their high degrees of freedom and the lack of
ComparisonswithVectorizationwithT2IMethods. Thoughwitha
geometryconstraints,thecontrolpointsoftenundergocomplex
vectorstylepromptsuffix,T2Imodelsstilloftengeneraterasterim-
transformationstogenerateSVGsthatalignwiththetextprompts.
ageswithintricatetexturesandcomplexcolorvariations.Itposesa
This results in low path smoothness, as indicated by the lower
challengewhenconvertingtovectorgraphicswithsmoothgeomet-
SmoothscoreinTab.1.Zoom-inillustrationsinFig.17highlightthe
ricshapesanduniformcolors.AsshowninFig.6,thevectorization
issuesofintersectingandjaggedpaths,leadingtovisuallyunappeal-
resultsusingPotraceexhibitoverlycomplexvectorelements.This
ingoutcomes.Moreover,theresultingSVGsoftencontaincomplex
leadstoahighnumberofpaths(indicatedbyahighsimplicityscore
andredundantshapes,makingthemdifficulttoedit.Incontrast,
inTab.1)andalackoflayerorganizationamongthesepaths,re-
ourneuralpathrepresentationeffectivelycapturesvalidgeometric
sultingindiminishedpathsemantics(reflectedbyalowlayer-wise
propertiesofpaths.Byenablingtext-guidedoptimizationwithina
semanticsscoreinTab.1).Furthermore,suchvectorizationresults
constrainedlatentspace,ourapproachfacilitatesthegenerationof
oftendeviatefromthestyleofwell-designedSVGs,asevidencedby
SVGswithsmoothpaths.
thelowFIDscoresinTab.1.LIVEfacessimilarchallenges.When
Additionally,VectorFusion,whichsimultaneouslyoptimizesall
thepathnumberissetthesameasourmethod,LIVEobtainssub-
pathsinasinglestage,oftenleadstoclutteredpathsandadisorga-
optimalvectorizationoutcomesastheconstrainedpathnumberis
nizedlayerstructure.Incontrast,ourpipelineadoptsatwo-stage
ofteninsufficientforaccuratelyreconstructingtheimagesgener-
text-drivenneuralpathoptimizationmethod,resultinginvector
atedbytheT2Imodel.Furthermore,theSVGsproducedbyLIVE
graphicswithclearandvalidlayer-wisevectorpaths.Despiteusing
exhibitnumerousirregularandbrokenpaths,asindicatedbythe
fewerpaths,ourmethodstillproducesSVGsthatmaintainsemantic
lowsmoothnessscoreinTab.1.
alignmentwiththetextprompts.Thisindicatesthatourpathshave
LoRA[Huetal.2021]isapopulartechniquetofine-tuneapre-
trainedT2Imodelforspecificstyles.ToproduceSVG-styleimages, 3https://civitai.com/models/60132/vector-illustration8 â€¢ PeiyingZhang,NanxuanZhao,andJingLiao
SVG Quality
"A smiling
sloth wearing
Text Alignment a jacket and
cowboy hat"
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Ours Potrace DiffSketcher CLIPDraw VectorFusion
Fig.7. UserStudy.Weshowthehumanpreferencesin%.
"A Japanese
sakura tree
on a hill"
Table2. Ablationstudyonneuralpathrepresentationlearningandtext-
drivenneuralpathoptimizationmodules.
Text (a) w/o NPR (b) Sequence Modality (c) Ours
Methods Smoothâ†‘ Simpâ†“ ğ‘†ğ‘–ğ‘šğ‘”â†‘ Fig.8. AblationonNeuralPathRepresentationLearning.
w/oNPR 0.5271 40 0.9941
NeuralPathRepresentation(NPR)
Sequence 0.8116 40 0.9910
w/oVSD 0.7896 380 -
SDS 0.8070 40 0.9932
NeuralPathOptimization
VSDOnly 0.8194 40 -
w/oLayer-wise 0.7924 40 0.9929 "A boat"
Ours 0.8012 40 0.9926
bettersemanticmeaning,whichisfurthersupportedbythehigher
layer-wisesemanticsscoreinTab.1. "A city
intersection"
6.4 UserStudy
Weconductedaperceptualstudytoevaluateourtext-to-vectorgen- Text (a) w/o VSD (b) SDS (c) Ours
erationfromtwoperspectives:overallSVGqualityandalignment
Fig.9. AblationonOptimizationwithVariationalScoreDistillation.
withthetextprompt.Werandomlyselected20textpromptsfrom
ourtestsetandgeneratedSVGsusingboththebaselinemethods
described in Sec. 6.2 and our approach. To gather feedback, we
recruited32participants(17malesand15females)throughuni-
versity mailing lists. The participants had diverse ages, with an "A Ming
Dynasty vase"
averageageof24,andvariedlevelsofdesignexperience.Eachques-
tionpresentedtheresultsofdifferentmethodsinarandomorder,
andparticipantsweregivenunlimitedtimetoselectthebestre-
sultamongfiveoptionsforeachevaluationmetric.Asshownin
Fig.7,ourmethoddemonstratedsuperiorperformancebyachieving "An espresso
machine"
thehighestpreferenceinbothevaluationmetrics.Specifically,our
methodreceived81.1%ofvotesforoverallSVGqualityand69.2%
fortextalignment.Theseresultsdemonstratetheeffectivenessof Text (a) VSD Only (b) w/o Layer-wise (c) Ours
ourmethodingeneratinghigh-qualitySVGsfromtextpromptsthat
Fig.10. AblationonOptimizationwithLayer-wiseVectorization.
alignmorecloselywithhumanperception.
6.5 AblationStudy
Inanotherbaseline,wereplaceourdual-branchVAEbyase-
Weconductedablationstudiestovalidatetheeffectivenessofkey
quenceVAEwithsingle-modalityrepresentation(Sequence).How-
componentsinourpipeline.
ever,relyingsolelyonasequencerepresentationprovestobein-
6.5.1 AblationonNeuralPathRepresentationLearning. Toillustrate sufficientincapturingthevisualfeaturesnecessaryforaccurately
theeffectivenessofourneuralpathrepresentationlearningmodule reconstructingtherenderedshape.Fig.8(b)visualizestheresulting
andthedesignchoiceofourdual-branchVAE,wecomparethem challengesinreconstruction.Toevaluatethereconstructionaccu-
withtwobaselines. racy,wecomputetheimagesimilarityğ‘†ğ‘–ğ‘š ğ‘”betweentheguidance
Thefirstbaselinedirectlyoptimizesthecontrolpointsofpara- imageandtherenderedSVGinRGBspace.Theresultsindicatethat
metricpathsusingourtext-drivenoptimizationmodule(w/oNPR). thesequenceVAEachievesalowerğ‘†ğ‘–ğ‘š ğ‘” scorecomparedtoour
Withouttheneuralpathrepresentation,optimizedpathsoftensuf- dual-branchVAE(Tab.2).
ferfromintersectionsandabruptcurvaturechanges.Consequently, Ourneuralpathrepresentationprovestobemoreeffectivefor
thisapproachgeneratesSVGpathsofpoorqualitycharacterizedby pathoptimization,resultinginmoreaccuratepathsandbettervisual
lowsmoothnessscoreinTab.2,asshowninFig.8(a). qualityoftheSVGs.Text-to-VectorGenerationwithNeuralPathRepresentation â€¢ 9
6.5.2 Ablation on Text-driven Neural Path Optimization. In this
subsection,weinvestigatetheeffectivenessofourtext-drivenneural
pathoptimizationmodule.
"Delicious
WefirstexploretheeffectsofVSDoptimization(Stage1).We hamburger"
generateimagesusingT2Imodelsandemploythelayer-wiseopti-
mizationstrategytotransformtherasterimageintoSVGsusingour
neuralpathrepresentation(w/oVSD).However,T2Imodelsoften
generaterasterimageswithphotographicandrealisticstylesthat
donotalignwiththedesiredSVGstylecharacterizedbysmooth "A castle stands
in mountains"
geometricshapesandflatcolors.TheabsenceofStage1intheopti-
mizationprocessresultsinSVGsthatareoverlycomplex(Fig.9).
WealsocomparetheVSDlosswiththeSDSlossusedinStage
1.WhileSDSoftenleadstooversmoothingandalackofdiversity,
VSDgeneratesSVGswithclearerdetailsandhighervisualquality, "Watercolor
painting of
asshowninFig.9.
villages"
Weevaluatetheimpactofoptimizationwithlayer-wisevector-
izationbyremovingStage2(VSDOnly).Withoutthisstage,we
Text Prompt (a) 20 Paths (b) 40 Paths (c) 80 Paths
observedthatSVGstendtohaveclutteredandstackedpaths.This
notonlycreatesvisualartifactsbutalsoresultsinadisorganized
Fig.11. Controllabletext-to-vectorwithdifferentlevelsofdetails.
layerstructurewithintheSVGs,makingthemdifficulttoeditand
modify,asshowninFig.10.
Finally,wecompareourlayer-wisevectorizationstrategywith
theglobalvectorizationstrategy,whichinvolvesoptimizingallpaths
togetherinStage2(w/oLayer-wise).Whileglobalvectorization
caneffectivelyfitimages,itoftenfailstopreservethetopological
integrityofSVGs.Incontrast,ourlayer-wisevectorizationstrategy A shark,
A cat, Watercolor A girl with sunglasses, A gamepad, Monochrome Girl with a Pearl
capturesthehierarchicallayerstructureofSVGs,resultinginclearer painting Pop art style Flat 2D icon icon Earring
andwell-structuredvectorgraphics,asshowninFig.10.
7 APPLICATIONS
Wedemonstratetheeffectivenessofourmethodwithvariousappli- A man with hat,
cations,includingSVGgenerationwithadjustablelevelsofdetails Crâ€¦ os, sA inn gim sa tyl le Crâ€¦ os, sA inn gim sa tyl le mA is nt ir maw ab l e icrr oy n, Mono icc oh nrome A cat
anddifferentstyles,SVGcustomization,image-to-SVGgeneration,
andSVGanimation.
A bottle of beer,
7.1 SVGGenerationwithAdjustableLevelsofDetails Acamera, Monochrome A castle stands in
â€¦, Anime style â€¦, Japanism style minimal icon icon mountains
Ourmethodcangeneratevectorgraphicswithvaryinglevelsof (a) Clipart (b) Icon (c) Line art
abstractionbyadjustingthenumberofpaths.Fig.11illustratesthe
resultsofgeneratingvectorgraphicswith20,40,and80paths.Using Fig.12. Text-to-vectorgenerationwithdiversestyles.
fewerpathsproducesSVGswithasimplerandflatterstyle,while
increasingthenumberofpathsaddsmoredetailandcomplexity.
7.3 SVGCustomization
GivenanexemplarSVG,ourmethodcancustomizetheSVGbased
7.2 SVGGenerationwithDifferentStyles
ontextpromptswhilepreservingthevisualidentityoftheexemplar.
Ourmethodcangeneratevectorgraphicswithdiversestylesby Toachievethis,wefollowtheapproachoutlinedin[Kumarietal.
modifyingstyle-relatedkeywordsinthetextprompts(e.g.,water- 2022]tofine-tuneapre-trainedDiffusionmodelonanexemplar
colorpainting"or"Animestyle"),orbyconstrainingpathparameters image(renderedfromexemplarSVG)andatextpromptcontaining
suchasfillcolorsandthenumberofpaths.AsillustratedinFig.12, aspecialtokenğ‘‰âˆ—.Thistokenlearnstheconceptfromtheexemplar
weappenddifferentsuffixestothepromptstoproduceclipartsand image.Subsequently,weapplyourmethodtooptimizetheSVG
icons that align with the desired aesthetics. To further enhance basedonanewprompt,suchas"ğ‘‰âˆ—holdingalaptop"or"Treesin
supportforlinearts,wefine-tuneourpathVAEonadatasetof ğ‘‰âˆ—style,"resultinginacustomizedSVGthatreflectsthedesired
cleanedsketches[Yanetal.2020]featuringopen-formpaths.Then, customizationinobjectorstyle.FigureFig.13showcasesthere-
byutilizingblackcolorandincorporating"linedrawings"intothe sultsofcustomizingtheexemplarSVGwithdifferenttextprompts,
textprompts,ourmethodcaneffectivelygeneratelinearts. demonstratingtheflexibilityandcreativityofourmethod.10 â€¢ PeiyingZhang,NanxuanZhao,andJingLiao
â€œThe
runner
runsâ€
"V* holding a laptop" "V* wearing a hat" "V* holding a bag"
"A
woman
dances"
Fig.15. SVGanimationalignedwiththedescribedmotions.
Exemplar "Trees in V* style" "Mountainsin V* style" "Leaves in V* style"
Fig.13. Text-guidedSVGcustomization.ExemplarSVGs:the1ğ‘ ğ‘¡ rowis
fromEnvatoElementscreatorÂ©Telllu;the2ğ‘›ğ‘‘ rowisfromÂ©Freepik.
Realistic Image Iconified SVG Realistic Image Iconified SVG
"a f oid nd l ae pn ie nx gt pto o na g b ta as bk lee "tball "a b wo itt htl e a o hf a b lfe -se mr n oe kext d t co i ga an r ea ts th e"tray Raster Image SVG
(a)InaccurateGeneration (b)Over-smooth Vectorization
Fig.16. Failurecases.
"A dog" "An alarm clock"
represented asğ‘‰ğ‘–ğ‘‘ğ‘’ğ‘œ = {ğ‘†ğ‘‰ğº1,ğ‘†ğ‘‰ğº2,...,ğ‘†ğ‘‰ğºğ‘˜} = (cid:110) ğ‘ƒğ‘ğ‘¡â„ ğ‘–ğ‘—(cid:111) ğ‘–ğ‘— âˆˆâˆˆ ğ‘šğ‘˜ ,
aligningwiththemotiondescribedinthetextprompt.Specifically,
weemployasimilartwo-stageoptimizationprocess.IntheVSD
optimizationstage,weleverageapre-trainedtext-to-videodiffusion
modelModelScope[Wangetal.2023c]toreplacethetext-to-image
"A fox playing the cello" "A margarita"
model.Inthelayer-wisevectorizationstage,wegenerateaguidance
videobasedontheinitialSVGsequence[Geyeretal.2023],which
containsğ‘˜guidanceimages.AsdemonstratedinFig.15,ourmethod
animatesSVGswithsmoothmotions,showcasingtheeffectiveness
ofourneuralpathrepresentation.
"The Alamo with clouds" "The titanic" 8 CONCLUSION
Fig.14. Image-to-SVGgeneration. Inthispaper,weproposeanoveltext-to-vectorpipelinetogenerate
vectorgraphicsthatalignwiththesemanticsofgiventextprompts.
Ourframeworklearnsaneuralpathrepresentationwithinthelatent
7.4 Image-to-SVGGeneration spacetocapturevalidgeometricpropertiesofpaths.Byemploying
thetwo-stagetext-drivenneuralpathoptimization,ourmethod
Ourframeworkenablesflexiblecontrolbeyondtextprompts,which
effectivelygeneratesvectorgraphicswithdesirablepathproperties
isparticularlyusefulfordesignersseekinginspirationfromnatural
andlayer-wisestructures.
imagesforSVG-styledesigns.Forexample,asshowninFigure14,
Whileourmethodachieveshigh-qualitySVGresults,itstillhas
ourmethodcangeneratevectoriconsfromnaturalimages.Thisis
somelimitations,asshowninFig.16.First,ourmethodreliesonthe
achievedbyintegratingtheControlNet[Zhangetal.2023b]intothe
generativecapabilitiesofthediffusionmodel;thus,overlydetailed
VSDoptimizationprocess,whichensuresanoptimizationdirection
textpromptsmayleadtoinaccurateSVGresults.Forexample,as
thatrespectsboththeoriginalstructureoftheimageandtheinput
depictedinFig.16(a),semanticelementslikethe"pingpongtable"
textprompt.
and"ashtray"aremissing.Second,ourmethodtendstosimplify
shapeswithintricateboundariesintosmootherpaths,astheyexceed
7.5 SVGAnimation
therepresentationalcapacityofourpathlatentspace.Forinstance,
OurframeworkcanbeextendedtoSVGanimationbyanimatingan thedetailededgesofthebearâ€™sbodyinFig.16(b)aresmoothed
initialSVGaccordingtoatextpromptdescribingthedesiredmotion. out,resultinginthelossoftheoriginalcomplexity.Thiscanbeim-
WefirstgenerateastaticSVGusingourpipelineandthenanimate provedbycollectingalargerpathdatasetcontainingmorecomplex
itbyoptimizingatemporalsequenceofğ‘špathsintoğ‘˜videoframes, paths,whichweleaveasfuturework.Third,ourmethod,similarText-to-VectorGenerationwithNeuralPathRepresentation â€¢ 11
toothertext-guidedSVGoptimizationmethodssuchasCLIPDraw JohannesKopfandDaniLischinski.2011.Depixelizingpixelart.InACMSIGGRAPH
andVectorFusion,isgenerallyslowduetotheiterativeoptimization 2011papers.1â€“8.
NupurKumari,BingliangZhang,RichardZhang,EliShechtman,andJun-YanZhu.
process.Ittakesapproximately13minutestooptimize128pathson
2022. Multi-ConceptCustomizationofText-to-ImageDiffusion. arXivpreprint
anNVIDIA-3090,whereasvectorizationwithT2Imethodscanbe arXiv:2212.04488(2022).
completedwithinafewseconds.Despitethecurrentslowness,our Tzu-MaoLi,MichalLukÃ¡Ä,MichaÃ«lGharbi,andJonathanRagan-Kelley.2020.Differen-
tiablevectorgraphicsrasterizationforeditingandlearning.ACMTransactionson
neuralpathrepresentationlaysthegroundworkfortrainingfast Graphics(TOG)39,6(2020),1â€“15.
feed-forwardT2Vnetworkstoreplaceiterativeoptimizationinfu- HanyuanLiu,ChengzeLi,XuetingLiu,andTien-TsinWong.2022. End-to-endline
drawingvectorization.InProceedingsoftheAAAIConferenceonArtificialIntelligence,
turework.Thisapproachcouldalsobringbenefitstothegeneration
Vol.36.4559â€“4566.
ofgraphiclayouts,fonts,andCADmodels. Ying-TianLiu,ZhifeiZhang,Yuan-ChenGuo,MatthewFisher,ZhaowenWang,and
Song-HaiZhang.2023.DualVector:UnsupervisedVectorFontSynthesiswithDual-
PartRepresentation.InProceedingsoftheIEEE/CVFConferenceonComputerVision
ACKNOWLEDGMENTS andPatternRecognition.14193â€“14202.
RaphaelGontijoLopes,DavidHa,DouglasEck,andJonathonShlens.2019.Alearned
Theworkdescribedinthispaperwassubstantiallysupportedby representationforscalablevectorgraphics.InProceedingsoftheIEEE/CVFInterna-
aGRFgrantfromtheResearchGrantsCouncil(RGC)oftheHong tionalConferenceonComputerVision.7930â€“7939.
XuMa,YuqianZhou,XingqianXu,BinSun,ValeriiFilev,NikitaOrlov,YunFu,and
Kong Special Administrative Region, China [Project No. CityU
HumphreyShi.2022.Towardslayer-wiseimagevectorization.InProceedingsofthe
11216122]. IEEE/CVFConferenceonComputerVisionandPatternRecognition.16314â€“16323.
ChenlinMeng,YutongHe,YangSong,JiamingSong,JiajunWu,Jun-YanZhu,and
StefanoErmon.2021.Sdedit:Guidedimagesynthesisandeditingwithstochastic
REFERENCES differentialequations.arXivpreprintarXiv:2108.01073(2021).
AlexNichol,PrafullaDhariwal,AdityaRamesh,PranavShyam,PamelaMishkin,Bob
DefuCao,ZhaowenWang,JoseEchevarria,andYanLiu.2023.SVGformer:Representa- McGrew,IlyaSutskever,andMarkChen.2021. Glide:Towardsphotorealistic
tionLearningforContinuousVectorGraphicsusingTransformers.InProceedingsof imagegenerationandeditingwithtext-guideddiffusionmodels. arXivpreprint
theIEEE/CVFConferenceonComputerVisionandPatternRecognition.10093â€“10102. arXiv:2112.10741(2021).
AlexandreCarlier,MartinDanelljan,AlexandreAlahi,andRaduTimofte.2020.Deepsvg: BenPoole,AjayJain,JonathanTBarron,andBenMildenhall.2022. Dreamfusion:
Ahierarchicalgenerativenetworkforvectorgraphicsanimation.AdvancesinNeural Text-to-3dusing2ddiffusion.arXivpreprintarXiv:2209.14988(2022).
InformationProcessingSystems33(2020),16351â€“16361. AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,Sandhini
YeChen,BingbingNi,XuanhongChen,andZhangliHu.2023.EditableImageGeo- Agarwal,GirishSastry,AmandaAskell,PamelaMishkin,JackClark,etal.2021.
metricAbstractionviaNeuralPrimitiveAssembly.InProceedingsoftheIEEE/CVF Learningtransferablevisualmodelsfromnaturallanguagesupervision.InInterna-
InternationalConferenceonComputerVision.23514â€“23523. tionalconferenceonmachinelearning.PMLR,8748â€“8763.
LouisClouÃ¢treandMarcDemers.2019.Figr:Few-shotimagegenerationwithreptile. PradyumnaReddy,MichaelGharbi,MichalLukac,andNiloyJMitra.2021. Im2vec:
arXivpreprintarXiv:1901.02199(2019). Synthesizingvectorgraphicswithoutvectorsupervision.InProceedingsofthe
NassimDehoucheandKullathida.2023. WhatisinaText-to-ImagePrompt:The IEEE/CVFConferenceonComputerVisionandPatternRecognition.7342â€“7351.
PotentialofStableDiffusioninVisualArtsEducation.arXivpreprintarXiv:2301.01902 LeoSampaioFerrazRibeiro,TuBui,JohnCollomosse,andMoacirPonti.2020.Sketch-
(2023). former:Transformer-basedrepresentationforsketchedstructure.InProceedingsof
EdoardoAlbertoDominici,NicoSchertler,JonathanGriffin,ShayanHoshyari,Leonid theIEEE/CVFconferenceoncomputervisionandpatternrecognition.14153â€“14162.
Sigal,andAllaSheffer.2020. Polyfit:Perception-alignedvectorizationofraster JuanARodriguez,ShubhamAgarwal,IssamHLaradji,PauRodriguez,DavidVazquez,
clip-artviaintermediatepolygonalfitting.ACMTransactionsonGraphics(TOG)39, ChristopherPal,andMarcoPedersoli.2023.StarVector:GeneratingScalableVector
4(2020),77â€“1. GraphicsCodefromImages.arXivpreprintarXiv:2312.11556(2023).
Jean-DominiqueFavreau,FlorentLafarge,andAdrienBousseau.2017.Photo2clipart: RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBjÃ¶rnOmmer.
Imageabstractionandvectorizationusinglayeredlineargradients.ACMTransac- 2022.High-resolutionimagesynthesiswithlatentdiffusionmodels.InProceedingsof
tionsonGraphics(TOG)36,6(2017),1â€“11. theIEEE/CVFConferenceonComputerVisionandPatternRecognition.10684â€“10695.
KevinFrans,LisaSoros,andOlafWitkowski.2022.Clipdraw:Exploringtext-to-drawing NatanielRuiz,YuanzhenLi,VarunJampani,YaelPritch,MichaelRubinstein,andKfir
synthesisthroughlanguage-imageencoders.AdvancesinNeuralInformationPro- Aberman.2022.Dreambooth:Finetuningtext-to-imagediffusionmodelsforsubject-
cessingSystems35(2022),5207â€“5218. drivengeneration.arXivpreprintarXiv:2208.12242(2022).
RinonGal,YaelVinker,YuvalAlaluf,AmitHBermano,DanielCohen-Or,ArielShamir, ChitwanSaharia,WilliamChan,HuiwenChang,ChrisLee,JonathanHo,TimSalimans,
andGalChechik.2023. BreathingLifeIntoSketchesUsingText-to-VideoPriors. DavidFleet,andMohammadNorouzi.2022. Palette:Image-to-imagediffusion
arXivpreprintarXiv:2311.13608(2023). models.InACMSIGGRAPH2022ConferenceProceedings.1â€“10.
MichalGeyer,OmerBar-Tal,ShaiBagon,andTaliDekel.2023.Tokenflow:Consistent PeterSchaldenbrand,ZhixuanLiu,andJeanOh.2022.Styleclipdraw:Couplingcontent
diffusionfeaturesforconsistentvideoediting. arXivpreprintarXiv:2307.10373 andstyleintext-to-drawingtranslation.arXivpreprintarXiv:2202.12362(2022).
(2023). PeterSelinger.2003.Potrace:apolygon-basedtracingalgorithm.
DavidHaandDouglasEck.2017.Aneuralrepresentationofsketchdrawings.arXiv JaschaSohl-Dickstein,EricWeiss,NiruMaheswaranathan,andSuryaGanguli.2015.
preprintarXiv:1704.03477(2017). Deepunsupervisedlearningusingnonequilibriumthermodynamics.InInternational
AmirHertz,KfirAberman,andDanielCohen-Or.2023. Deltadenoisingscore.In conferenceonmachinelearning.PMLR,2256â€“2265.
ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.2328â€“ YirenSong,XningShao,KangChen,WeidongZhang,MinzheLi,andZhongliang
2337. Jing.2022.CLIPVG:Text-GuidedImageManipulationUsingDifferentiableVector
JonathanHo,AjayJain,andPieterAbbeel.2020. Denoisingdiffusionprobabilistic Graphics.arXivpreprintarXiv:2212.02122(2022).
models.Advancesinneuralinformationprocessingsystems33(2020),6840â€“6851. AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanN
ShayanHoshyari,EdoardoAlbertoDominici,AllaSheffer,NathanCarr,Zhaowen Gomez,ÅukaszKaiser,andIlliaPolosukhin.2017.Attentionisallyouneed.Advances
Wang,DuyguCeylan,andI-ChaoShen.2018.Perception-drivensemi-structured inneuralinformationprocessingsystems30(2017).
boundaryvectorization.ACMTransactionsonGraphics(TOG)37,4(2018),1â€“14. AndreyVoynov,KfirAberman,andDanielCohen-Or.2023.Sketch-guidedtext-to-image
EdwardJHu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang, diffusionmodels.InACMSIGGRAPH2023ConferenceProceedings.1â€“11.
LuWang,andWeizhuChen.2021.Lora:Low-rankadaptationoflargelanguage JiuniuWang,HangjieYuan,DayouChen,YingyaZhang,XiangWang,andShiweiZhang.
models.arXivpreprintarXiv:2106.09685(2021). 2023c.Modelscopetext-to-videotechnicalreport.arXivpreprintarXiv:2308.06571
AdobeIllustrator.2023. TurnideasintoillustrationswithTexttoVectorGraphic. (2023).
https://www.adobe.com/products/illustrator/text-to-vector-graphic.html. YizhiWangandZhouhuiLian.2021.DeepVecFont:Synthesizinghigh-qualityvector
Illustroke.2024.Stunningvectorillustrationsfromtextprompts.https://illustroke.com/. fontsviadual-modalitylearning.ACMTransactionsonGraphics(TOG)40,6(2021),
ShirIluz,YaelVinker,AmirHertz,DanielBerio,DanielCohen-Or,andArielShamir. 1â€“15.
2023. Word-as-imageforsemantictypography. arXivpreprintarXiv:2303.01818 YuqingWang,YizhiWang,LonghuiYu,YueshengZhu,andZhouhuiLian.2023b.
(2023). DeepVecFont-v2:ExploitingTransformerstoSynthesizeVectorFontswithHigher
AjayJain,AmberXie,andPieterAbbeel.2022.VectorFusion:Text-to-SVGbyAbstract- Quality.InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPattern
ingPixel-BasedDiffusionModels.arXivpreprintarXiv:2211.11319(2022). Recognition.18320â€“18328.
Kittl.2024.AIVectorGenerator. https://www.kittl.com/feature/ai-text-to-vector.12 â€¢ PeiyingZhang,NanxuanZhao,andJingLiao
ZhengyiWang,ChengLu,YikaiWang,FanBao,ChongxuanLi,HangSu,andJun MingYang,HongyangChao,ChiZhang,JunGuo,LuYuan,andJianSun.2015. Ef-
Zhu.2023a.ProlificDreamer:High-FidelityandDiverseText-to-3DGenerationwith fectiveclipartimagevectorizationthroughdirectoptimizationofbezigons.IEEE
VariationalScoreDistillation.arXivpreprintarXiv:2305.16213(2023). transactionsonvisualizationandcomputergraphics22,2(2015),1063â€“1075.
RonghuanWu,WanchaoSu,KedeMa,andJingLiao.2023. IconShop:Text-Guided FangnengZhan,YingchenYu,RongliangWu,JiahuiZhang,ShijianLu,LingjieLiu,
VectorIconSynthesiswithAutoregressiveTransformers. ACMTransactionson AdamKortylewski,ChristianTheobalt,andEricXing.2023. Multimodalimage
Graphics(TOG)42,6(2023),1â€“14. synthesisandediting:Asurveyandtaxonomy.IEEETransactionsonPatternAnalysis
XimingXing,ChuangWang,HaitaoZhou,JingZhang,QianYu,andDongXu.2023a. andMachineIntelligence(2023).
DiffSketcher:TextGuidedVectorSketchSynthesisthroughLatentDiffusionModels. LvminZhang,AnyiRao,andManeeshAgrawala.2023b.Addingconditionalcontrol
arXivpreprintarXiv:2306.14685(2023). totext-to-imagediffusionmodels.InProceedingsoftheIEEE/CVFInternational
XimingXing,HaitaoZhou,ChuangWang,JingZhang,DongXu,andQianYu.2023b. ConferenceonComputerVision.3836â€“3847.
SVGDreamer:TextGuidedSVGGenerationwithDiffusionModel.arXivpreprint YuxinZhang,NishaHuang,FanTang,HaibinHuang,ChongyangMa,WeimingDong,
arXiv:2312.16476(2023). andChangshengXu.2023a.Inversion-basedstyletransferwithdiffusionmodels.In
ChuanYan,DavidVanderhaeghe,andYotamGingold.2020.Abenchmarkforrough ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.
sketchcleanup.ACMTransactionsonGraphics(TOG)39,6(2020),1â€“14. 10146â€“10156.Text-to-VectorGenerationwithNeuralPathRepresentation â€¢ 13
"An
astronaut,
Van Gogh
style"
"The
headquart
er of
Google"
"A cruise
ship"
"A giraffe
in street"
"A dog
driving a
truck"
"A picture
of Tokyo"
"A dragon-
cat hybrid"
"A Starbucks
coffee cup"
Text (a) CLIPDraw (b) DiffSketcher (c) Vectorfusion (d) LIVE+ Vectorfusion (e) Ours
Fig.17. Qualitativecomparisonwithtext-guidedSVGoptimizationmethods.