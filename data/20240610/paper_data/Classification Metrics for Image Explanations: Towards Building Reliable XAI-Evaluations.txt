ClassificationMetricsforImageExplanations
TowardsBuildingReliableXAI-Evaluations
BENJAMINFRESZâˆ—,
FraunhoferInstituteforManufacturingEngineeringandAutomationIPA,Germany,andInsti-
tuteofIndustrialManufacturingandManagementIFF,UniversityofStuttgart,Germany
LENALOERCHERâˆ—,
FraunhoferInstituteforManufacturingEngineeringandAutomationIPA,Germany
MARCOF.HUBER,
FraunhoferInstituteforManufacturingEngineeringandAutomationIPA,Germany,andInsti-
tuteofIndustrialManufacturingandManagementIFF,UniversityofStuttgart,Germany
Decisionprocessesofcomputervisionmodelsâ€”especiallydeepneuralnetworksâ€”areopaqueinnature,meaningthatthesedecisions
cannotbeunderstoodbyhumans.Thus,overthelastyears,manymethodstoprovidehuman-understandableexplanationshave
beenproposed.Forimageclassification,themostcommongrouparesaliencymethods,whichprovide(super-)pixelwisefeature
attributionscoresforinputimages.Buttheirevaluationstillposesaproblem,astheirresultscannotbesimplycomparedtothe
unknowngroundtruth.Toovercomethis,aslewofdifferentproxymetricshavebeendefined,whichareâ€”astheexplainabilitymethods
themselvesâ€”oftenbuiltonintuitionandthus,arepossiblyunreliable.Inthispaper,newevaluationmetricsforsaliencymethodsare
developedandcommonsaliencymethodsarebenchmarkedonImageNet.Inaddition,aschemeforreliabilityevaluationofsuch
metricsisproposedthatisbasedonconceptsfrompsychometrictesting.Theusedcodecanbefoundatthislink.
CCSConcepts:â€¢Computingmethodologiesâ†’Interestpointandsalientregiondetections;Machinelearning;Computervision;
â€¢Human-centeredcomputingâ†’Humancomputerinteraction(HCI);â€¢Generalandreferenceâ†’Metrics.
AdditionalKeyWordsandPhrases:eXplainableAI,XAI,saliencymaps,saliencymetrics,heatmaps,quantitativeevaluation,psycho-
metrictesting,validity,reliability,objectiveXAIevaluation
ACMReferenceFormat:
BenjaminFresz,LenaLoercher,andMarcoF.Huber.2024.ClassificationMetricsforImageExplanations:TowardsBuildingReliable
XAI-Evaluations.InThe2024ACMConferenceonFairness,Accountability,andTransparency(FAccTâ€™24),June3â€“6,2024,RiodeJaneiro,
Brazil.ACM,NewYork,NY,USA,25pages.https://doi.org/10.1145/3630106.3658537
1 INTRODUCTION
Inrecentyears,eXplainableArtificialIntelligence(XAI)hasgainedsignificantattentionasameanstoaddressthe
black-boxnatureofmanyMachineLearning(ML)models.XAImethodsaimtoprovidetransparencyandinterpretability,
allowinguserstounderstandthedecision-makingprocessofMLmodels.WhilevariousXAItechniqueshavebeen
developed,theirevaluationremainschallenging,particularlyincomputervisiontasks.Acommonapproachofexplaining
imageclassificationandobjectdetectiondecisionsareso-calledsaliencymapsthathighlightimageregionsdeemed
particularlyimportantfortheprediction.Theevaluationofsuchmethodsforimageclassificationisessentialtoassess
theireffectivenessandcomparedifferentapproaches.However,thisisstillanopenproblemdespitevariousapproaches
toassessthepropertiesofthesaliencymethod,mainlyduetothesubjectivenatureofevaluations[28],thefallibilityof
âˆ—Bothauthorscontributedequallytothisresearch.
Permissiontomakedigitalorhardcopiesofpartorallofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenot
madeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirstpage.Copyrightsforthird-party
componentsofthisworkmustbehonored.Forallotheruses,contacttheowner/author(s).
Â©2024Copyrightheldbytheowner/author(s).
ManuscriptsubmittedtoACM
1
4202
nuJ
7
]VC.sc[
1v86050.6042:viXraFAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
userstudies[13],andthedifferentconceptsusedtoevaluatesuchmetrics[39].Itisparticularlydifficulttocompare
andassesssaliencyexplanationsbeyondanecdotalevidence,asbydefinitiontheyonlyprovidelocalexplanations,
i.e.,explanationsforindividualdatapoints.Aremedyforthiscanbewaystoevaluatelocalexplanationsoverentire
datasetsasin[6],resultinginaglobalassessmentofexplanationproperties.
ForXAImethodsingeneral,thelackofground-truthexplanationscomplicatestheirrobustassessment,sometimes
attemptedtobesolvedviacreatingspecificdatasetswithground-truthexplanations[4,7].Additionaltousingsuch
datasets,conceptsfromotherdisciplineswithsimilarproblemsâ€”lackofgroundtruthandtestswithpossiblydiffering
underlyingconceptsâ€”suchaspsychometrictestingcanbeused[36].
TheaimofthisworkistofurtherdeveloptheideasofArias-Duartetal.[5,6],whichprovideasetofmetricsfor
saliencymethods.Thissetisextendedtoacomprehensivelistofmetricsthatmimiccommonmetricsforclassification
evaluationbasedonthedefinitionofcorrectandincorrectfeatureimportance(FI)inimages.Additionally,itisshown
howthereliability(aspartofvalidity)oftheproposedmetricscanbeassessed,basedon[36].Assuch,ourcontributions
are:
â€¢ Weextendthelistofsaliencymetrics.While[5]introducessomeofthem,othersareoverlooked.Theadditional
metricsinparticularprovideinterestingadditionalinformation,asshowninSection5.
â€¢ Weshowhowsuchmetricscanbeassessedregardingreliability(asaprecursortovalidity)inordertotestthem
fortheirpracticaluse.
â€¢ WiththefullsetofsaliencymetricsandbyaddingB-cosnetworks[10]andthepopularSHAP[21],weprovidea
morecompletebenchmarkofXAImethods.
â€¢ Weprovideanin-depthdiscussionofthesaliencymetricsandshowwhichpropertiesofXAImethods(asgiven
byNautaetal.[24])theyaddress.
Inthefollowingchapter,theFocusscoreofArias-Duartetal.[6]isbrieflyintroduced,thesaliencymethodsusedinthis
paperandfurtherworksrelatedtoXAI-evaluationarediscussed,withtheproposedmethodologybeingpresentedin
Section3,includingthedefinitionof(in)correctFIandthepsychometricevaluationapproachusedhere.Theexperiment
setupandspecificallycreateddatasetsaredescribedinSection4,followedbyaselectionoftheresultsfortheproposed
metricsinSection5,accompaniedbyadiscussionofthelimitationsoftheapproachinSection6.Thepaperisclosed
withasummaryinSection7.
2 RELATEDWORK
ThisworkbuildsontheideaofArias-Duartetal.[6],whereametricforevaluatingXAImethodsisproposed.Since
thereisnogroundtruthforindividualimagepixelsastowhichclasstheycanbeassignedto,theauthorshaveproposed
adifferentwayofevaluatingexplanationsofsaliencymethods:theycreatemosaicsfromfourimagesofvariousclasses
andassumethattheevidencetowardsaclassismoreprevalentinimageslabelledwiththatclass.Theexplanations,
whichareprovidedasFIbytheexaminedXAImethods,arethenevaluatedbycomparingpositivefeatureattributionon
imagesbelongingtothecorrectclasswithpositivefeatureattributionontheentiremosaic.Positivefeatureattribution
herereferstothesummedupfeatureattributionvaluesofeachpixelintherespectivepartofthemosaic.
InSection2.1thesaliencymethodsconsideredintheoriginalpaper[6]aswellassomeadditionalmethodsexamined
inthispaperarebrieflypresented.Section2.2addressesthestateoftheartwithregardtoXAIevaluation.
2ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
2.1 SaliencyMethods
ThesaliencymethodsforwhichtheFocusscorewasdeterminedandanalyzedin[6]willbedescribedshortlyin
the following. Linear Interpretable Model-Agnostic Explanations (LIME) was one of the first methods to provide
model-agnostic explanations in the form of feature attribution. The feature attribution is calculated by sampling
aroundadata-pointandfittingasimplerlinearmodeltotheweightedsamples[27].Forimages,LIMEcancreate
class-specificexplanationsbyhighlightingimageregionsâ€”so-calledsuperpixelsâ€”thataredeemedespeciallyrelevant
forthetargetclass.Layer-wiseRelevancePropagation(LRP),ontheotherhand,usesfirst-orderTaylorexpansionsfor
localrenormalizationlayerstogeneratesaliencymaps[8].IntegratedGradients(IntGrad),whichwasproposedin[34],
calculatesthefeatureimportanceofanimagebyformingthegradientofthemodeloutputwithrespecttothemodel
inputandintegratingthisgradientoverabaselineimage(â€œneutralâ€input,e.g.,greyimage).Gradient-weightedClass
ActivationMapping(Grad-CAM)producesclass-specificsaliencymapsbycomputinggradientinformationinthelast
convolutionallayerofaneuralnetwork[29].AmodificationofGrad-CAM,namelyGrad-CAM++,usesaweighted
combinationofthepositivepartialderivativesinthelastconvolutionallayer,improvingtheperformanceofGrad-CAM
formultipleobjectsofthesameclassinasingleimageandobjectlocalization[12].Lastly,SmoothGraddescribesthe
exchangeoftheoftennoisygradient-basedexplanationsbyaweightedlocalaverage,thuspossiblyimprovingthe
visualqualityandinformativeness[31].
Inthiswork,therangeofexaminedsaliencymethodsisextendedtoalsoincludeSHapleyAdditiveexPlanations
(SHAP)andB-cos.SHAPisnotanexplanationmethoditselfbutaunifyingframeworkforfeatureattributionmethods,
especiallyShapleyRegression,ShapleySampling,QuantitativeInputInfluenceFeatureAttributions,LIME,DeepLIFT,
andLRP[21].Thegame-theoreticinterpretationofthesemethods,whichareusedtoapproximateShapleyValues(given
certainhyperparameterchoices),providesthepossibilityofreceivingfeatureattributionswiththreedesiredcriteria:
Localaccuracy,missingness,andconsistency.KernelSHAPwaschosentoapproximateShapleyValueshere,dueto
itscomparativelylowruntime.Incontrasttoallthepost-hocexplanationmethodsdescribedbefore,B-cosnetworks
[10]generatemodel-inherentsaliencymapsbychangingtheactivationfunctionsofneuralnetworks.Thisforcesthe
networkweightstoalignwiththenetwork-inputandrequiresthenetworkstobetrainedwiththeB-costransformas
activationfunctions.
2.2 XAIEvaluation
Inrecentyears,severalapproacheshavebeenproposedforevaluatingXAImethods.Anoverviewofthemethods
publishedbytheendof2020canbefoundin[24].TheauthorslisttwelvepropertiesofXAImethodsthatcanbetested,
oftenwithvariousautomatedchecksassessing(partof)aspecificproperty.Theygroupthesepropertiesintouser-,
presentation-,andcontent-properties,withsixofthembelongingtothelastclassandthreetoeachoftheprevious
ones.Thecontent-propertiesarethemostlikelyonestobeobjectivelymeasurable,althoughtheauthorsofthispaper
expectthatsinglemetricswillmostlikelyonlyassessasmallsubsetoftheavailablepropertiesatonce,asmostofthem
arequitedisjointintheirinterpretation,e.g.,covariatecomplexityâ€”denotinghowcomplexthe(interactionsof)features
intheexplanationareâ€”andconsistencyâ€”denotinghowdeterministicandimplementation-invariantanexplanation
isâ€”probablyrequirequitedifferentassessmentmethods.Themetricsinthispaperarethereforelimitedtoassessing
twooftheseproperties:Thecontrastivityofsaliencyexplanations,denotinghowstronglyanexplanationdiscriminates
betweendifferentoutcomesoftheMLmodel.Anexplanationthatdoesnotdiscriminatewellwouldprobablyhighlight
generalinformationsuchasedgesinthemosaicimages,thusresultinginbadsaliencymetrics.Additionally,withthe
3FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
assumptionfulfilledthattheusedmodelsareabletodistinguishbetweentherelevantclassesandevidencecanmainly
befoundwithinimagesofthecorrespondingclass,thecorrectnessofsaliencymethodscanbeassessed(asdescribedin
thebeginningofthischapter).
Theexplanationtypeandthus,theevaluationusuallydependsonthetypeofinputdataforwhichpredictionsor
modelsneedtobeexplained.Becauseofthis,availabletoolboxesarelimitedtocertaindatatypeswhilestillproviding
multipleevaluationmetrics,e.g.,[3]fortabularexplanationsand[17]forimageexplanations.Doshi-VelezandKim
[15]proposedthreedifferentstagesofXAIevaluation,eachwithincreasingeffortandcost:functionally-grounded,
human-grounded,andapplication-grounded.Aspartofthefunctionally-groundedevaluationandthus,earlyoninthe
developmentandimplementationofXAImethods,metricssuchastheonepresentedherecanbeused.
Userstudiesareoftenviewedasthegold-standardofXAIevaluation,althoughtheirresultshavetobetakenwith
cautionasuserstendtooverestimatetheirunderstandingoftheMLmodel[13,37],whichdistortsthestudyresults.
Inadditiontouserstudiesandmetricsthatcanbeevaluatedonaspecificuse-case,moregeneraldocumentation
approacheshavebeensuggested,forinstanceExplanationFactSheets[32],whichcontaininformationonrelevant
aspectsofXAImethods.Asimilarapproach,althoughmoreanecdotalanduse-casespecific,canbefoundin[9],which
aimsatprovidingastandardizedformattoassessanddiscusstrade-offswhenevaluatingsaliencymethods.
IntheabsenceofestablishedwaystocompareXAImethodsonanon-task-specificbasis,so-calledsanitychecks
canbeused.Thesecantestsaliencymethodsforimageclassificationfordesideratasuchasmodel-invarianceand
input-invariance[2,19].Eventhoughasuccessfulcheckdoesnotprovideenoughinformationtofullytrustamodel,
anunsuccessfulonedoesshowproblematicbehavior.Suchsanitycheckscanalsobeformulatedforobjectdetection
models[25],althoughtheideaofgeneralsanitychecksandtheoneswhicharenottask-specificcanbecriticizeddueto
possiblyintroducingaselectionbias[40].Othersanitychecksinvolvethecreationofâ€œground-truthâ€saliencymaps
thatarecomparedwiththegeneratedexplanations[18].
Raoetal.[26]proposeametricsimilartoFocus[6],whichalsoonlyusespositivefeatureattributions,butlimitall
classestoappearinthemosaicatmostonce.Theauthorsguaranteethebasicassumptionofclass-specificfeatures
occurringexclusivelyinthetargetclassbyconstrainingtheclassifiertousetheinformationfromonepartofthemosaic
only.Thisisdonebybuildingoneseparatemodelheadforeveryimageinthemosaic.Thisensuresthatnovisual
informationbetweenimagesisexchanged,limitingtheclassifierinitsdecisiontorelyonsingleimages.Theauthors
thendefinetheirmetricbasedonwhetherthesaliencymethodsstillhighlightotherpartsofthemosaic.Moreover,they
evaluatethemosaicsvisuallybyhumansviaasystematicassessmentapproachthatentailsclusteringthemwiththeir
previouslydefinedscores.
In[38]abenchmarkofcommonsaliencymethodsandevaluationmetricsisprovided.Theworkconcludesthatthe
evaluationresultsareinconclusiveandthemetricsinpartcontradicteachother.
Finally,Tomsettetal.[36]investigateXAIevaluationmetricsandpresentanapproachfrompsychometrictestingto
assessthem.Apartfrom[36],however,thereislittleresearchthataddressesthetopicofXAImetricsevaluation.
3 METHODOLOGY
ThissectionextendstheFocusscoreforevaluatingXAImethodsfromArias-Duartetal.[6]byincorporatingnegative
FI.First,theconstructionofmosaicsisexplained,followedbythedefinitionoftruepositivesandnegatives,andfalse
positivesandnegativeswithrespecttoFIinthemosaics.Thesearethenusedtodefineadditionalevaluationmetrics.In
thesecondpart,anapproachfrompsychometrictestingisintroducedtoexaminethesuitabilityofthesemetricsfor
evaluatingXAImethods.
4ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
Fig.1. Onesamplemosaicforeachoftheregardeddatasets(cf.Section4).OntheleftthemosaiccomprisestheImageNetclasses
â€œtabbyâ€andâ€œsportscarâ€,inthemiddleâ€œBerneseMountainDogâ€andâ€œGreaterSwissMountainDogâ€,andontherighttheclasses
â€œlorikeetâ€,â€œmashedpotatoâ€,andâ€œAmericanchameleonâ€.
3.1 ProposedMetrics
Tocalculatethesaliencymetrics,so-calledmosaicsareused.Theyconsistofa2Ã—2gridofimagesofdifferentclasses
fromtheoriginaldataset.Theideabehindthemisthatâ€”givenamodelthatisabletodistinguishbetweentherelevant
classesâ€”FIforagivenclassğ¶shouldbeattributedtothepartofthemosaicthatbelongstoclassğ¶(asdenotedbythe
labelsintheoriginaldataset).Thisthenallowstocalculatedmetricsakintoclassicalmetricsforclassificationtasks,as
describedinthefollowing.
3.1.1 Mosaics. TheproposedapproachadaptstheprocedurefromtheoriginalFocuspaper[6].Themosaicsusedto
testandevaluatevarioussaliencymethodsareconstructedoffourimages:twofromtheassignedtargetclassandtwo
fromdifferentclasseswithinthesamedataset.Allimagesareselectedrandomlyfromtheirspecificclasses.Theimages
arearrangedinrandompositionsinthe2Ã—2gridwithoutoverlap.Tomaintainconsistencyofvisualpatternsbetween
mosaicsandthetrainingdata,theindividualimagesarescaledtoauniformsizeof224Ã—224pixels.Accordingly,the
mosaicshavearesolutionof448Ã—448pixels.Becausetheindividualimagesofthemosaicsarepartofthetrainingdata,
thenoiseintroducedbythemisensuredtofallwithinthedistributionofthetrainingdata.Figure1showsanexample
mosaicforeachdatasetconsideredinthispaper.Thedatasetsusedformosaicconstructionfortheexperimentsare
describedindetailinSection4.
3.1.2 TrueandFalseFeatureImportance. ForamoreholisticevaluationofXAImethods,furthermetricsaredefinedin
additiontotheFocusscoreâ€”theprecisionforFIâ€”byconsideringnegativeFI.Ingeneral,pixelswithapositivefeature
attributionvaluecontributetothepredictionofthetargetclassandpixelswithanegativefeatureattributionvalue
contributetothepredictionoftheotherclasses.Here,botharetakenintoaccountforthespecificationoftruepositives
andnegativesaswellasfalsepositivesandnegativesrelatedtotheFIonthemosaics.However,trueandfalseFIcan
onlybeapproximated,becausethepixel-wisegroundtruthisunknown.Thisisdoneasfollows:
â€¢ truepositive(ğ‘¡ğ‘):positiveFIontheimagesofthetargetclass
âˆ‘ï¸
ğ‘¡ğ‘ = FI(ğ‘ img(ğ‘¥,ğ‘¦)=ğ‘ targetâˆ§FI>0)
ğ‘¥,ğ‘¦
5FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
Table1. XAIevaluationmetricsproposedinthiswork.Allofthemcanbecalculatedwiththetruepositives,truenegatives,false
positives,andfalsenegativesdefinedinSection3.1.2.
EvaluationMetrics Formula
ğ‘¡ğ‘
Precision(Focusscore)
ğ‘¡ğ‘+ğ‘“ğ‘
ğ‘¡ğ‘
Sensitivity(Recall)
ğ‘¡ğ‘+ğ‘“ğ‘›
ğ‘¡ğ‘›
Specificity
ğ‘¡ğ‘›+ğ‘“ğ‘
ğ‘“ğ‘›
False-Negative-Rate
ğ‘¡ğ‘+ğ‘“ğ‘›
ğ‘“ğ‘
False-Positive-Rate
ğ‘¡ğ‘›+ğ‘“ğ‘
ğ‘¡ğ‘+ğ‘¡ğ‘›
Accuracy
ğ‘¡ğ‘+ğ‘¡ğ‘›+ğ‘“ğ‘+ğ‘“ğ‘›
2Â·precisionÂ·sensitivity
F1-Score
precision+sensitivity
whereğ‘¥,ğ‘¦ âˆˆ{0,1}aretheimagecoordinates,i.e.,(0,0)istheimageonthebottomleft,(0,1)isbottomright,
(1,0)istopleft,and(1,1)istopright.FIisthefeatureimportanceintheentiremosaic,ğ‘ imgistheclasslabelat
position(ğ‘¥,ğ‘¦),basedonthefourimagesusedtocreatethemosaicandğ‘ targetisthetargetclassfortheFI.The
computationoftheFIdependsonthesaliencymethodunderinvestigation.
â€¢ falsepositive(ğ‘“ğ‘):positiveFIontheimagesthatdonotbelongtothetargetclass
âˆ‘ï¸
ğ‘“ğ‘ = FI(ğ‘ img(ğ‘¥,ğ‘¦)=Â¬ğ‘ targetâˆ§FI>0)
ğ‘¥,ğ‘¦
â€¢ falsenegative(ğ‘“ğ‘›):negativeFIontheimagesofthetargetclass
âˆ‘ï¸
ğ‘“ğ‘›= FI(ğ‘ img(ğ‘¥,ğ‘¦)=ğ‘ targetâˆ§FI<0)
ğ‘¥,ğ‘¦
â€¢ truenegative(ğ‘¡ğ‘›):negativeFIontheimagesofotherclasses
âˆ‘ï¸
ğ‘¡ğ‘›= FI(ğ‘ img(ğ‘¥,ğ‘¦)=Â¬ğ‘ targetâˆ§FI<0)
ğ‘¥,ğ‘¦
Thus,byalsoconsideringnegativeFI,trueandfalsenegativescanbecalculatedinadditiontotrueandfalsepositives,
sothatafullconfusionmatrixcanbedefined.Thisenablesthecomputationofmetricscommonlyappliedinclassification
tasks,specificallyforassessingsaliencymethods(cf.Table1).Withtheadditionalmetrics,XAImethodscantherefore
beevaluatedmorecomprehensively.
PleasenotethatnotallXAImethodsprovidenegativeFI.Accordingly,theadditionalmetricscanonlybecalculated
forB-cos,IntGrad,LRPandSHAP.TheotherXAImethodscanonlybeevaluatedusingtheprecisionmetric.An
approachtoexaminethesuitabilityofthemetricsforevaluatingtheXAImethodsisexplainedinthenextsection.
3.2 EvaluationApproach
Despitetheabsenceofgroundtruthforevaluatingtheexplanationmethodsand,consequently,thesaliencymetrics,
theevaluationofcertainpropertiesofsuchmetricscanstillbeconducted.Giventheanalogouschallengesoflacking
groundtruthinpsychometricapproaches,correspondingevaluationprocedurescanbeadaptedtosaliencymaps,as
proposedin[36].Twofundamentalconceptsarevalidity,i.e.,theextenttowhichatestorvariablemeasureswhat
itisintendedtomeasure,andreliability,i.e,theconsistencyofresultsatestproduces.Whileareliabletestdoesnot
6ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
guaranteevalidity,reliabilityisanecessaryconditionforvalidity[22].Inpsychometrictesting,thescenarioisusually
describedbyraters(e.g.,psychologists)administeringteststoapatient,wheredifferenttypesofreliabilitycanbe
evaluatedtoassesswhetherametricproducesreliableandthus,possiblyvalidresults.Inthispaper,twoadapted
reliabilitytestsfrom[36]areconsidered.
3.2.1 Inter-raterReliability. Forthepurposeofselectingametrictochoosebetweenvarioussaliencymethods,this
metricideallyyieldsthesamerankingofsaliencymethodsacrossallimagesofadataset.Whentherankingofsaliency
methodsremainsconsistentacrossall(ormost)testimages,itishighlylikelythattherankingfornewimageswillbe
thesameaswell.Thismakesiteasiertoidentifythebestperformingsaliencymethodforfuturetasks.Thisparadigm
canbecomparedtointer-raterreliability,wheretheimagescanberegardedasdifferentratersadministeringabattery
ofteststobescoredbythesaliencymethods[36].Intuitively,eachimage(rater)producesarankingofsaliencymethods
viatherespectivemetric.Thisrankingcanthenbecheckedforagreementoverallimages(raters)acrossadataset.
Krippendorffâ€™sğ›¼ âˆˆ [âˆ’1,1] isacommonstatisticusedtoassessagreementbetweenraters[20].Itiscalculatedas
ğ›¼ =1âˆ’ ğ· ğ·ğ‘œ
ğ‘’
,whereğ· ğ‘œ denotesthedisagreementobservedandğ· ğ‘’ denotesthedisagreementbychance.Avalueof
ğ›¼ =1signifiesperfectagreementintherankingofsaliencymethods,ğ›¼closeto0indicatesrandomrankings,andğ›¼ <0
indicatessystematicdisagreement.TheimplementationusedistheonebyCastro[11].
3.2.2 Inter-methodReliability. Thesaliencyprecisioncanalsobeusedtoidentifyimagesorclassesthatareparticularly
challengingtoclassifywithinagivendataset[6].Inordertoutilizeanevaluationmetricforthisobjective,difficultclasses
andimagesshouldbefoundconsistently.Thisconsistencyshouldbeindependentofthesaliencymethodemployed,asthe
modelusedremainsthesameacrossallmethods.Suchadesideratumcanbecomparedtointer-methodreliability,which
canbequantifiedusingSpearmanâ€™sğœŒ[36],whichmeasureswhethertherelationoftwovariablesğ‘‹,ğ‘Œ canbedescribed
viaamonotonicfunction(i.e.,anincreaseinğ‘‹ alsoresultsinanincreaseinğ‘Œ [33]).Spearmanâ€™sğœŒcanbecalculatedas
thePearsoncorrelationğ‘betweentheranksofğ‘‹ andğ‘Œ,resultinginğœŒ =ğ‘ ğ‘…(ğ‘‹),ğ‘…(ğ‘Œ) = co ğœv ğ‘…(ğ‘… (ğ‘‹(ğ‘‹ )Â·ğœ), ğ‘…ğ‘… (( ğ‘Œğ‘Œ ))) ,whereğœ ğ‘…(ğ‘‹)
andğœ
ğ‘…(ğ‘Œ)
denotethestandarddeviationsoftherankvariablesğ‘…(ğ‘‹)andğ‘…(ğ‘Œ),respectively,andcov(ğ‘…(ğ‘‹),ğ‘…(ğ‘Œ))the
covarianceoftherankvariables[23].AhighvalueofğœŒindicatesthatthesaliencymethodsexhibitagreementintheir
variationsacrossdifferentimages.Consequently,imageswithhigh(low)saliencymetricscoresforonemethodwill
consistentlyreceivesimilarlyhigh(low)scoresacrossallsaliencymethods.
4 DATASETS
Inthefollowing,generalinformationabouttheexperimentsetupisgiven,beforetheusedmosaicdatasetsaredescribed
inmoredetail.
Tocomputethemetricscores,therelativemagnitudeoftheFIisused.Forvisualisationsake,thesaliencymaps
arenormalizedviamax-scaling,mappingthemtotheinterval [âˆ’1,1].Thisisthestraightforwardextensionofthe
normalizationusedbyArias-Duartetal.[6]toalsoworkforsaliencymethodswithnegativeFI.Thisnormalization
preservesthe0-pointofthesaliencymapsandleavestheproposedmetricsunchanged.
Weevaluatethemetricsontwodifferentneuralnetworkarchitectures,withthecomparativelysmallVGGarchitecture
withadepthof11layers[30]andthelargerResNetarchitecturewithadepthof50layers[16].SincetheVGGarchitecture
containsbatchnormalization,itsimplementationdiffersslightlybetweentheB-cos-versionandtheconventionalone.
Toremoveallbiastermsintheirnetworks,theauthorsofB-coschangethebatchnormalizationtonotcontaina
centeringoperation,resultinginaso-calledâ€œuncenteredâ€batchnormalization[10].
7FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
Ingeneral,itisdifficulttodisentangletheperformanceofthemodelandtheperformanceoftheexplanationmethods.
Specifically,incorrectlydistributedFIandthus,alowsaliencymetricscore,couldindicateeitherahighperforming
modelwithalow-fidelityexplanationmethod(withfeatureattributiondistributedevenlyacrossamosaic)orabad
modelandahigh-fidelityexplanationmethod.Todistinguishbetweenthesecases,thesaliencyscoresandthemodel
performancemustalwaysbeconsideredincombination.
Totestthereliabilityoverdifferentdatasetsandmodelsandtheamountofinformationprovidedbythesaliency
metrics,thescenariosdescribedinthefollowingsubsectionsaretested.ThehyperparametersusedfortheXAImethods
canbefoundinAppendixB.1.
4.1 CornerCaseswithSmallDatasets
Toestablishtheoverallbehavioroftheproposedmetrics,theirperformanceandcoherencewithexpectationcanbe
testedinsimplecornercases,forwhichclearexpectationscanbeformulated.Ascornercases,forwhichthemetric
behaviorcanbepredicted,twodatasetsareusedwithtwoclassesand100mosaicsperclasseach.Forthesedatasets,the
classesarechosenfromtheonesrepresentedinImageNet,withimagesforthemosaicschosenfromallclassimagesat
random.AsallmodelsarepretrainedonImageNetandabenchmarkoftheirperformanceismostinformativewithout
anychanges,themodelsarenotfine-tunedonthespecificdatasets.Thisevaluationapproachlimitsoptionsregarding
datasets,asonlyonesbuiltfromImageNet(oratleastwiththesameclasses)canbeused.Otherwise,fine-tuningof
modelsorrelabelingofclasseswouldbenecessary.ThisiscontrarytoArias-Duartetal.[6],whoadaptthenetwork
architecturetothenumberofclassesinthedatasetunderconsiderationandthus,needtofine-tunetheirmodels.Our
approachprovidesanunbiasedassessmentofpopularmodelsbutalsocomplicatesthereportingofaccuracy,asmodels
trainedonImageNetmighthavelearnedhigh-levelfeatureslikethedifferencebetweencatsanddogsbutnotthe
specificdifferencebetweencertaindogbreeds,resultinginalowtop-1accuracybutinahightop-kaccuracyfork>1.
Thus,bothtop-1andtop-5accuracyneedtobeconsideredtomakesurethattheusedmodelshavelearnedrelevant
featurestoclassifythedatasetscorrectly.
Afurtherdifferenceto[6]isthecreationofthemosaics:ForthecornercasesinSections4.1.1and4.1.2,samples
fromthetrainingsetoftheImageNetsubset[1]areusedforthemosaicconstruction,insteadofonlytestdatasamples
(whereâ€˜trainingâ€™andâ€˜testâ€™refertothecorrespondingpartitionsofthisdataset).Sincetheaimofthisworkistotest
theproposedmetricsfortheevaluationofdifferentXAImethods(incontrasttoe.g.performanceevaluationofthe
networks),norelevanteffectsofleakageareexpected.Thisassumptionwasconfirmedinexperimentswithunseen
datapointsofthesamedataset.
4.1.1 EasytoDistinguishClasses. Inthefirstcornercase,themosaicsforthesaliencymetricsarecreatedwithtwo
ImageNet-classes,whichareexpectedtoconsistofverydissimilarfeaturesandthus,shouldbeeasilydistinguishable
bythepre-trainedmodels.Thetargetclassesâ€œtabbyâ€andâ€œsportscarâ€areusedandthedatasetisreferredtoasthe
Cars/Catsdatasetinthefollowing.Sincethereshouldbe(nearly)nooverlapbetweentherelevantfeaturesforboth
classes,nexttoperfectsaliencymetricscoresaretobeexpected.Onesamplemosaicforthisdatasetcanbeseenin
Figure1ontheleft.
4.1.2 DifficulttoDistinguishClasses. Theseconddatasetconsistsofmosaicsbuiltfromtwoclassesthatlooksimilarto
laypeopleandhavestronglyoverlappingfeatures.Theclasseschosenforthisdatasetareâ€œGreaterSwissMountainDogâ€
andâ€œBerneseMountainDogâ€.ThedatasetisreferredtoastheMountainDogsdataset.Forthesemosaics,itisexpected
8ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
Fig.2. OnesampleheatmapbyeachsaliencymethodforthefirstmosaicshowninFigure1oftheCars/Catsdataset.Theexplanations
arecreatedforResNet50forthetargetclassâ€œtabbyâ€.TheupperrowshowsheatmapsformethodsprovidingpositiveandnegativeFI,
theloweroneformethodswithonlypositiveFI.LIMEusesabinarymasktohighlightrelevantimagepieces,thusabinarymasking
oftheoriginalimageisshownhere.SimilarresultsforVGG11arepresentedinFigure5intheappendix.
thatthemodelswillnotbeabletoseparatetheseclasses,resultinginnear-randomperformanceandsaliencymetrics.
OnesamplemosaicforthisdatasetcanbeseeninFigure1inthemiddle.
4.2 ImageNet
Aftertestingthesaliencymetricbehaviorforcornercases,thethirddatasetusesallclassesoftheImageNetdataset
[14]asdescribedin[6].ThemosaicsconstructedbyArias-Duartetal.[6]areavailableonlineandwereusedhere.
Comparedtotheotherdatasets,thisdatasetbetterrepresentsmostreal-worldcomputervisiontasks.Forallofthe
1,000ImageNet-classes,mosaicsarecreated,butduetohardwareandruntimeconstraints,onlytenmosaicspertarget
classarefeasible,resultingin10,000mosaicsoverall.Thehardwareusedfortheexperimentsandresultingruntimefor
thisdatasetisdescribedinAppendixA.1.FortheImageNetdataset,themosaicsonceagaincontaintwotargetclass
images,withtheothertwoimagesbeingchosenatrandomfromallotherpossibleclasses,ascanbeseenontheright
sideofFigure1.
5 RESULTS
Inthischapter,theresultsandfindingsoftheproposedsaliencymetricsarediscussed.Atfirst,theresultsforinter-rater
andinter-methodreliabilityaresummarized,followedbysomegeneralfindingswiththesaliencymethodsandmetrics
inSection5.3.Togiveabetterintuitionfortheseresults,Figure2providesanexampleofhowthesaliencymapsdiffer
betweenthesaliencymethodsforResNet50.ThesamecanbeseenforVGG11inFigure5intheappendix.Amore
detailedviewanddiscussionoftheresultscanbefoundintheAppendixB.
9FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
5.1 Inter-raterReliability
Krippendorffâ€™sğ›¼ canbeusedasametricforinter-raterreliability,indicatingwhethertherankingofXAImethodsbya
saliencymetricisstableoverall(ormost)oftheimagesinadataset.DetailedresultscanbefoundinappendixB.4.In
these,sometendenciesemerge:Theconsistencyofthesaliencymethodrankingdependsonthemodeltype.Inthe
experiments,ResNet50almostalwaysreceiveshigherğ›¼-valuesthantheVGG11-model.
SmoothGrad,LIME,Grad-CAM,andGrad-CAM++provideonlypositiveFI,thusonlytheprecision-reliability(the
reliabilityoftheoriginalFocusmetric[6])canbeevaluatedforallusedsaliencymethods.Forthedatasets,theeasierthe
modelscandistinguishbetweenclasses,themorereliabletheprecisionrankingbecomes,withthehighestvaluesfor
ResNet50fortheCars/Catsdatasetwithğ›¼ =0.88andforImageNetwithğ›¼ =0.71.Thehighestğ›¼-valuesforVGG11are
below0.6,thusunderpinningthatthesaliencymethodperformance(andmetricreliability)dependsonthemodeltype.
Whentheprecision-reliabilityisevaluatedforonlyB-cos,LRP,IntGradandSHAP,theresultsaresimilar,butfor
thesemethods,additionalsaliencymetricscanbecalculatedwithnegativeFI.Theyfollowsimilartrends:Theeasier
thedataset,thehigherthereliability,andingeneralhigherreliabilityforResNet50thanforVGG11,exceptforthe
false-positive-rateandspecificityonImageNet.Althoughnotperfect,theinter-raterreliabilityforallclassesofImageNet
(withvaluesbetween0.49and0.85)showsthatthesaliencymetricsproduceconsistentresults,thusenablingauserto
choosebetweendifferentsaliencymethods.Overall,thereliabilityofsensitivity,false-negative-rate,false-positive-rate,
specificity,accuracy,andF1-scoreishigherthanforprecision,showingtheaddedbenefitsofthesemetrics.
5.2 Inter-methodReliability
Spearmanâ€™sğœŒ correlationbetweentheresultsofthemetricsfordifferentsaliencymethodscanbeusedtoexamine
whethermosaicsareconsistentlydifficulttoexplaincorrectlyforallmethods.ForğœŒ,somedependenciesemerge:The
correlationvaluesforonemetricdifferbetweenmodelsonthesamedataset,betweendifferentdatasetsforthesame
modelandbetweenthedifferentmetrics.Formoredetailedresults,seeSectionB.2andFigure11intheappendix.While
mostcorrelationvaluesareratherlow(<0.8),insomecasesforcertainmethods,correlationscloseto1canbeseen,
especiallyforthedatasetsforwhichtheusedclasseswereexpectedtobedifficulttodistinguish(especiallyonthe
MountainDogsdatasetforGrad-CAM,Grad-CAM++andSHAP).Onthesedatasets,allXAImethodsdonotperform
wellbasedonthesaliencymetrics,thuspossiblyindicatingajointfailureofcertainsaliencymethods.Fortheother
datasets,noclearcorrelationpatternemerges,withcorrelations<0.8.Overall,theperformancesoftheXAImethods
canbehighlycorrelatedbetweensomeofthem,giventhatthemodelisnotabletodistinguishwellbetweendifferent
classes,whileformorediversedatasets,theperformancesoftheXAImethodsarenotstronglycorrelated.Thiscould
beparaphrasedas:â€œThesaliencymethodstendtoworkindividuallybutsomeofthemfailjointly.â€
5.3 GeneralFindings
Additionaltothemorespecificfindingsabove,somegeneraltendenciesforthesaliencymethodscanbeidentified.
B-coshighlightstheupperleftcornerofimages,possiblybecausethebiaswasremovedinthenetworkarchitecture,
forcingthenetworktoâ€œcreateitsownbiasâ€viamostlyirrelevantbutstablefeatureslikeimageedges[10](seeFigure2
foranexample).
IntGraddoesseemtoyieldmostlyrandomperformancesinthemetrics.Togetherwithagoodbalancebetween
positiveandnegativeFI,thisresultsinmetricscloseto0.5(seeFigures3cand3d).AscanbeseeninFigure3a,the
precisionfortheCars/CatsdatasetforIntGradisabove0.5,showingaperformancebetterthanrandomguessingas
10ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
(a) Precision for all saliency methods on the Cars/Cats (b)PrecisionforallsaliencymethodsontheMountainDogs
dataset. dataset.
(c)SpecificityforsaliencymethodswithnegativeFIonthe (d)SpecificityforsaliencymethodswithnegativeFIonthe
Cars/Catsdataset. MountainDogsdataset.
Fig.3. ExemplaryresultsforprecisionandspecificityforResNet50onthedatasetswitheasierandmoredifficulttodistinguish
classes.Highervaluesarebetter.NotethatspecificitycanonlybecalculatedformethodswhichprovidenegativeFI.
indicatedbytheothermetrics.Visually,IntGradexplanationsdomainlylooklikenoisethatseemstobestrongeron
therelevantimageparts.
WhilesomemethodsintheoryprovidenegativeFI,themagnitudeoftheirpositiveimportanceishigherthanthe
negativeone,thusyieldingmisleadinginterpretationsforsomeofthemetricswheninspectedontheirown.Thisis
illustrated,forexample,bytheprecisionandspecificityinFigure3:B-cosprovidesahighprecision,butalowspecificity,
becauseitbarelyprovidesanynegativeFI-valuesandistailoredtowardsthecorrectattributionofpositiveFI.This
imbalancetowardspositiveFIisespeciallyprevalentwhentheclassesinthemosaicsaremoredifficulttodistinguish
(seeFigures3cand3d).
Underpinning the initial intuition in creating the datasets in Section 4, the precision is significantly lower for
MountainDogsthanforCars/Cats(Figure3),withtheprecisionforImageNetsomewhereinbetween.
11FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
Noneofthetestedmethodsprovidegoodresultsinallofthemetricsoverdifferentdatasets,despiteasufficiently
highclassificationaccuracyforalldatasets,showingthatthemodelshavelearnedrelevantfeatures(seeAppendixA.2).
WhileB-cosforexamplefaredwellinmeanandmedian-performanceforprecisionforalldatasets,itsspecificity
consistentlyproducedvaluescloseto0(duetothehigherprevalenceofpositiveFI,seeaboveandFigure3acompared
toFigure3c).Here,itisimportanttonotethattheinter-raterreliabilityonlymeasurestheagreementoverthesaliency
methodrankingwithinagivenmetricbutdoesnotindicatethatthedifferentmetricsleadtothesamerankingof
saliencymethods.Complementarytotheâ€œeye-checkâ€forB-cosandothermethodsasabove,thisaspectcouldbe
exploredviaKrippendorffâ€™sğ›¼ betweendifferentmetricsonthesamedatasetandmodel.Sincetheâ€œeye-checkâ€ofthe
saliencymethodrankingbetweenthemetricsalreadyshowedthatmetricsusuallyproducedifferentrankingsandno
saliencymethodperformswellinallofthem,thisaspectwasnotexploredfurther(AppendixB.3).Anadditionalaspect
ofreliability-evaluationcouldbetheagreementovermeanandmedianperformancesofthesaliencymethodsover
differentdatasets,asthiswouldshowwhethersomemethodsconsistentlyproducebetterperformancesondifferent
datasets.AsananalysisofthistypeofreliabilityjustunderpinnedthepreviousresultsofResNet50providingmore
reliableresultsandmethodrankingsmostlydifferingbetweendatasets,adetaileddiscussionisommittedhere.For
allofthedatasets,largevariancesinthemetricscanbediscerned,thusindicatingthatsomeimagesproducedalmost
perfectscoreswhileothersreceivedscorestowardstheotherendofthescale.
Inclassicalliterature,ithasbeenlongknownthatasinglemetricisnotsufficientandmultiplemetricsarenecessary
toobtainareliableassessmentofamethod,especiallywhensomesortofunbalanceddatasetisused[35].Inthispaper,
theexistenceofsuchanimbalanceinthesaliencymethodswasshown.
ForImageNet,theexplanationmethodsrecommendedâ€”atleastforthepropertiesofcorrectnessandcontrastivityâ€”are
LRPandSHAP,althoughbothshowclearweaknesses(seeappendixB.3).LRPperformsslightlybetterinsomecases,
butoveralltheperformanceofSHAPismoreconsistentforResNet50comparedtoLRP,especiallyforspecificityand
false-positive-rate.ForVGG11,thevarianceofLRPislowerthanforResNet50,thusrenderingLRPthebestexplanation
methodforthismodelfortheImageNet-mosaics.Whilearecommendationforsaliencymethodsforaspecificmodeland
use-casecanbemadewiththeproposedmetrics,themetricvaluesandvariancesalsoshowthatnomethodperformsto
completesatisfaction(as,forinstance,thehighestmean-specificityforResNet50ontheImageNet-datasetisbelow0.6),
promptingmoreresearchforimprovedsaliencymethods.
Overall,theXAImethodsperformdifferentlyindifferentscenarios,possiblybecausetheirunderlyingconcepts
ofwhatconstitutesimportantfeaturesdiffer[39].Thereliabilityassessmentofthesaliencymetricsshowsthatthe
proposedmetricscanhelptochoosebetweensaliencymethods,althoughitshouldbenotedthatasinglesaliency
metricdoesnotyieldsufficientinformationforthischoiceforagivenuse-case.Instead,thecombinationofdataset,
model,andXAImethodneedstobeevaluatedtoreceiveameaningfulassessmentofthepropertiesofsaliencymethods.
6 DISCUSSION
Thispaperexaminedthequestionwhethertherelevantfeatures(i.e.,thepositivefeatureimportance)foraclassare
actuallylocatedontheimagesofthisclassandifthisfactcanbeutilizedtodefinesensiblemetricsforevaluating
saliencymethods.Overall,thisassumptionholds,however,theintroducedmetricsarenotexactlyintuitive.Theyrange
between0and1,where1canusuallynotbereachedand0.5correspondstorandomguessing.Additionally,ifimages
ofclasseswithverysimilarfeaturesarepresentinthemosaic(cf.MountainDogsdataset),theassumptionislikelyto
beviolated.
12ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
Anotherchallengeforthemetricsariseswhen,forexample,allimagesofoneclasshavethesamebackgroundand
thisbackgroundisonlypresentinthisclassinthedatasetunderconsideration.Insuchacase,themetricsprovide
high(resp.low)scoresforthegeneratedexplanations,buttheexplanationswouldshowsomesortofbiaswithinthe
modelwheninspectedbyhumans.Itisimportanttonotethatthesaliencymetricsdonotcontaininformationaboutthe
visualqualityofexplanationsandrathercorrespondtoasanitycheck.Forthesaliencymethodsexamined,higher(resp.
lower)scoresarealwaysconsideredbetter,nevertheless,themetricscouldbeoutsmarted:forinstance,anexplanation
methodthatonlyattributesrelevancetoasingleimagepixelwouldleadtoperfectscoresbutdoesnotprovidehelpful
informationatall.
Therearealsosomelimitationsofthemethodologythatneedtobeaddressed:therandomchoiceofimagesusedfor
creatingmosaicsmayintroducebias,e.g.,byselectingimagesthataretoo(dis)similarandespeciallyeasyordifficultto
distinguish.Tomitigatethis,theexperiments,includingmosaiccreation,canberepeatedmultipletimesorthenumber
ofgeneratedmosaicscanbeincreased.However,withthegivennumberofmosaics,sucheffectsareexpectedtobalance
outwithinthedatasetsusedinthispaperwithoutexceedingruntimelimits.Additionally,itisworthemphasizingthat
theB-cosmethodusesdifferentmodelweightsandactivationfunctionsthantheotherXAImethods,whichcouldraise
concernsaboutthedirectcomparabilityofexplanationresults.
Viewedfromtheoutside,thereisalsothemeta-levelproblem:saliencymethodsareusedtounderstandandevaluate
blackboxMLmodels.Saliencymetricsarethenusedtoevaluatethesaliencymethodsandthesemetricsarethen
checkedforreliability,etc.Fromapracticalviewpoint,low-levelinformationaboutwhichXAImethodstochoose
needstobeavailablewithoutexcessiveamountsofworkforevaluatingdifferentXAIapproaches.Butsincethereisno
groundtruththatcanbeusedtoverifystatementsatanylevel,theentireframeworkremainsshaky.Ontheotherhand,
astherecanprobablynotbeafullgroundtruthexplanationofablack-box-modelthatisdifferentfromjustthemodel
itself,itisnecessarytoemploythemethodsathandtoilluminatetheunderlyingcomplexitiesatleasttosomeextent.
Therefore,itiscrucialtoalwaysexplicitlystatethemainassumptionsofXAImethodsandpossiblebiasthatmayoccur
whenusingthem,astheseaspectsarefundamentalforselectingasuitablemethodfortherespectivemodelanddataset.
Forfutureresearch,itwouldbeinterestingtoextendthelistofmetricstoaddressfurtherXAIpropertieslistedin
[24].Inaddition,theproposedmetricscouldbeappliedtoXAImethodsonspecificbenchmarkdatasetstoanalyzeand
evaluatetheresultingexplanations.
7 SUMMARY
Inthispaper,newobjectiveevaluationmetricsforsaliencymethodsweredevelopedbasedonthedefinitionoftrue
(false)positiveandnegativeFIinimagemosaics.Thisdefinitionrequiredtheassumptionthatevidencetowardsacertain
classwouldbemoreprevalentinimagesofthisclassthaninothers,enablingthesaliencymetricstouseimagemosaics
asthebasisoftheircalculation,mimickingcommonclassificationevaluationmetrics.Totestthesemetrics,datasets
withmosaicimageswerecreated,smallonestoevaluatecornercaseswithespeciallyeasyordifficulttodistinguish
classesandalargeronebasedonallclassesofImageNet.
Forthepracticaluseofameasurement,itsvalidityâ€”withitsnecessaryconditionofreliabilityâ€”iscrucial.Viainter-
raterandinter-methodreliability,theproposedmetricswereestablishedtobereliableinmostcases,withtheoverall
resultsshowingthattheperformanceofcommonsaliencymethodsdependsontheMLmodelanduseddataset.As
noclearcorrelationbetweenthedifferentsaliencymethodresultscouldbefound,itseemsthatthesaliencymethod
performancealsodependsonthespecificimagebeingexplainedandgoesbeyondjustsingleimagesbeingeasyor
difficulttoexplain.Duetotheirhighinter-raterreliability,theproposedsaliencymetricscanbeusedtochoosebetween
13FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
differentsaliencymethodsforaspecificuse-case,although,duetothemethodâ€™sfocusonpositiveFI,morethanasingle
metricneedstobetakenintoaccountwherepossible.Asthesemethodsonlyassessthecontrastivityandcorrectnessof
saliencymetrics,welookforwardtoproposalsofobjective,reliable,andvalidevaluationmetricsforotherpropertiesof
XAImethodsandfurtherreliabilityevaluationsofothersaliencymetrics.
ACKNOWLEDGMENTS
Partsofthispaperwerecreatedwiththehelpofacompany-specificimplementationofChatGPT(3.5turbo).Itwas
usedtocreateLaTeX-codefortablesandfiguresandtorefinethedraftsofsomesections.
WethankthereviewersoftheFAccT2024conference,whohelpedtoimprovethispaperwiththeirvaluablefeedback.
ThispaperisfundedinpartsbytheGermanFederalMinistryforEconomicAffairsandClimateActionundergrant
no.19A21040B(project"veoPipe")andbytheFraunhoferGesellschaftundergrantno.PREPARE40-02702(project
"ML4Safety").
REFERENCES
[1] WendyKanAddisonHoward,EunbyungPark.2018.ImageNetObjectLocalizationChallenge. https://kaggle.com/competitions/imagenet-object-
localization-challenge
[2] JuliusAdebayo,JustinGilmer,MichaelMuelly,IanGoodfellow,MoritzHardt,andBeenKim.2018.Sanitychecksforsaliencymaps.InProceedingsof
the32ndInternationalConferenceonNeuralInformationProcessingSystems(MontrÃ©al,Canada)(NIPSâ€™18).CurranAssociatesInc.,RedHook,NY,
USA,9525â€“9536.
[3] ChiragAgarwal,SatyapriyaKrishna,EshikaSaxena,MartinPawelczyk,NariJohnson,IshaPuri,MarinkaZitnik,andHimabinduLakkaraju.2023.
OpenXAI:TowardsaTransparentEvaluationofModelExplanations. arXiv:2206.11104[cs.LG]
[4] ShidehShamsAmiri,RosinaO.Weber,PrateekGoel,OwenBrooks,ArcherGandley,BrianKitchell,andAaronZehm.2020.DataRepresenting
Ground-TruthExplanationstoEvaluateXAIMethods. arXiv:2011.09892[cs.LG]
[5] AnnaArias-Duart,EttoreMariotti,DarÃ­oGarcÃ­a-Gasulla,andJoseMariaAlonso-Moral.2023. AConfusionMatrixforEvaluatingFeature
AttributionMethods. 2023IEEE/CVFConferenceonComputerVisionandPatternRecognitionWorkshops(CVPRW)(2023),3709â€“3714. https:
//api.semanticscholar.org/CorpusID:260910875
[6] AnnaArias-Duart,FerranParÃ©s,DarioGarcia-Gasulla,andVictorGimÃ©nez-Ãbalos.2022.Focus!RatingXAIMethodsandFindingBiases.In2022
IEEEInternationalConferenceonFuzzySystems(FUZZ-IEEE)(Padua,Italy).IEEEPress,1â€“8. https://doi.org/10.1109/FUZZ-IEEE55066.2022.9882821
[7] LeilaArras,AhmedOsman,andWojciechSamek.2022. CLEVR-XAI:Abenchmarkdatasetforthegroundtruthevaluationofneuralnetwork
explanations.InformationFusion81(2022),14â€“40. https://doi.org/10.1016/j.inffus.2021.11.008
[8] AlexanderBinder,GrÃ©goireMontavon,SebastianLapuschkin,Klaus-RobertMÃ¼ller,andWojciechSamek.2016.Layer-WiseRelevancePropagation
forNeuralNetworkswithLocalRenormalizationLayers.InArtificialNeuralNetworksandMachineLearningâ€“ICANN2016,AlessandroE.P.Villa,
PaoloMasulli,andAntonioJavierPonsRivero(Eds.).SpringerInternationalPublishing,Cham,63â€“71.
[9] AngieBoggust,HariniSuresh,HendrikStrobelt,JohnGuttag,andArvindSatyanarayan.2023.SaliencyCards:AFrameworktoCharacterizeand
CompareSaliencyMethods.InProceedingsofthe2023ACMConferenceonFairness,Accountability,andTransparency(Chicago,IL,USA)(FAccTâ€™23).
AssociationforComputingMachinery,NewYork,NY,USA,285â€“296. https://doi.org/10.1145/3593013.3593997
[10] MoritzBÃ¶hle,NavdeeppalSingh,MarioFritz,andBerntSchiele.2023.B-cosAlignmentforInherentlyInterpretableCNNsandVisionTransformers.
arXiv:2306.10898[cs.CV]
[11] SantiagoCastro.2017.FastKrippendorff:FastcomputationofKrippendorffâ€™salphaagreementmeasure.https://github.com/pln-fing-udelar/fast-
krippendorff.
[12] AdityaChattopadhay,AnirbanSarkar,PrantikHowlader,andVineethNBalasubramanian.2018. Grad-CAM++:GeneralizedGradient-Based
VisualExplanationsforDeepConvolutionalNetworks.In2018IEEEWinterConferenceonApplicationsofComputerVision(WACV).IEEE. https:
//doi.org/10.1109/wacv.2018.00097
[13] MichaelChromik,MalinEiband,FelicitasBuchner,AdrianKrÃ¼ger,andAndreasButz.2021.IThinkIGetYourPoint,AI!TheIllusionofExplanatory
DepthinExplainableAI.In26thInternationalConferenceonIntelligentUserInterfaces(CollegeStation,TX,USA)(IUIâ€™21).AssociationforComputing
Machinery,NewYork,NY,USA,307â€“317. https://doi.org/10.1145/3397481.3450644
[14] J.Deng,W.Dong,R.Socher,L.-J.Li,K.Li,andL.Fei-Fei.2009.ImageNet:ALarge-ScaleHierarchicalImageDatabase.InCVPR09.
[15] FinaleDoshi-VelezandBeenKim.2017.TowardsARigorousScienceofInterpretableMachineLearning. arXiv:1702.08608[stat.ML]
[16] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016.DeepResidualLearningforImageRecognition.In2016IEEEConferenceonComputer
VisionandPatternRecognition(CVPR).770â€“778. https://doi.org/10.1109/CVPR.2016.90
14ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
[17] AnnaHedstrÃ¶m,LeanderWeber,DanielKrakowczyk,DilyaraBareeva,FranzMotzkus,WojciechSamek,SebastianLapuschkin,andMarinaM.-C.
HÃ¶hne.2023.Quantus:AnExplainableAIToolkitforResponsibleEvaluationofNeuralNetworkExplanationsandBeyond.JournalofMachine
LearningResearch24,34(2023),1â€“11. http://jmlr.org/papers/v24/22-0142.html
[18] JoonSikKim,GregoryPlumb,andAmeetTalwalkar.2021.SanitySimulationsforSaliencyMethods.CoRRabs/2105.06506(2021).arXiv:2105.06506
[19] Pieter-JanKindermans,SaraHooker,JuliusAdebayo,MaximilianAlber,KristofT.SchÃ¼tt,SvenDÃ¤hne,DumitruErhan,andBeenKim.2017.The
(Un)reliabilityofsaliencymethods. arXiv:1711.00867[stat.ML]
[20] KlausKrippendorff.2004.ReliabilityinContentAnalysis.HumanCommunicationResearch30,3(2004),411â€“433. https://doi.org/10.1111/j.1468-
2958.2004.tb00738.x
[21] ScottM.LundbergandSu-InLee.2017.Aunifiedapproachtointerpretingmodelpredictions.CoRRabs/1705.07874(2017).arXiv:1705.07874
[22] KevinMurphyandCharlesDavidshofer.2004.Psychologicaltesting:Principlesandapplications(6thed.).Pearson.
[23] JeromeL.Myers,ArnoldD.Well,andRobertF.LorchJr.2013. ResearchDesignandStatisticalAnalysis. Routledge. https://doi.org/10.4324/
9780203726631
[24] MeikeNauta,JanTrienes,ShreyasiPathak,ElisaNguyen,MichellePeters,YasminSchmitt,JÃ¶rgSchlÃ¶tterer,MauricevanKeulen,andChristin
Seifert.2023.FromAnecdotalEvidencetoQuantitativeEvaluationMethods:ASystematicReviewonEvaluatingExplainableAI.ACMComput.Surv.
(feb2023). https://doi.org/10.1145/3583558
[25] DeepanChakravarthiPadmanabhan,PaulG.PlÃ¶ger,OctavioArriaga,andMatiasValdenegro-Toro.2023. SanityChecksforSaliencyMethods
ExplainingObjectDetectors. arXiv:2306.02424[cs.CV]
[26] SukrutRao,MoritzBÃ¶hle,andBerntSchiele.2022.TowardsBetterUnderstandingAttributionMethods.In2022IEEE/CVFConferenceonComputer
VisionandPatternRecognition(CVPR).10213â€“10222. https://doi.org/10.1109/CVPR52688.2022.00998
[27] MarcoTÃºlioRibeiro,SameerSingh,andCarlosGuestrin.2016."WhyShouldITrustYou?":ExplainingthePredictionsofAnyClassifier.CoRR
abs/1602.04938(2016).arXiv:1602.04938
[28] YaoRong,TobiasLeemann,ThaitrangNguyen,LisaFiedler,PeizhuQian,VaibhavUnhelkar,TinaSeidel,GjergjiKasneci,andEnkelejdaKasneci.
2023.TowardsHuman-centeredExplainableAI:ASurveyofUserStudiesforModelExplanations. arXiv:2210.11584[cs.AI]
[29] RamprasaathR.Selvaraju,AbhishekDas,RamakrishnaVedantam,MichaelCogswell,DeviParikh,andDhruvBatra.2016.Grad-CAM:Whydidyou
saythat?VisualExplanationsfromDeepNetworksviaGradient-basedLocalization.CoRRabs/1610.02391(2016).arXiv:1610.02391
[30] KarenSimonyanandAndrewZisserman.2015.VeryDeepConvolutionalNetworksforLarge-ScaleImageRecognition. arXiv:1409.1556[cs.CV]
[31] DanielSmilkov,NikhilThorat,BeenKim,FernandaB.ViÃ©gas,andMartinWattenberg.2017.SmoothGrad:removingnoisebyaddingnoise.CoRR
abs/1706.03825(2017).arXiv:1706.03825
[32] KacperSokolandPeterFlach.2020.Explainabilityfactsheets.InProceedingsofthe2020ConferenceonFairness,Accountability,andTransparency.
ACM. https://doi.org/10.1145/3351095.3372870
[33] C.Spearman.1904. TheProofandMeasurementofAssociationbetweenTwoThings. TheAmericanJournalofPsychology15,1(1904),72.
https://doi.org/10.2307/1412159
[34] MukundSundararajan,AnkurTaly,andQiqiYan.2017.AxiomaticAttributionforDeepNetworks.CoRRabs/1703.01365(2017).arXiv:1703.01365
[35] AlaaTharwat.2021.Classificationassessmentmethods.AppliedComputingandInformatics17,1(2021),168â€“192. https://doi.org/10.1016/j.aci.2018.
08.003
[36] Richard Tomsett, Dan Harborne, Supriyo Chakraborty, Prudhvi Gurram, and Alun Preece. 2019. Sanity Checks for Saliency Metrics.
arXiv:1912.01451[cs.LG]
[37] JaspervanderWaa,ElisabethNieuwburg,AnitaCremers,andMarkNeerincx.2021.EvaluatingXAI:Acomparisonofrule-basedandexample-based
explanations.ArtificialIntelligence291(2021),103404. https://doi.org/10.1016/j.artint.2020.103404
[38] BenjaminVandersmissenandJoseOramas.2023.OnTheCoherenceofQuantitativeEvaluationofVisualExplanations. arXiv:2302.10764[cs.CV]
[39] DavidWatson.2020.ConceptualChallengesforInterpretableMachineLearning.SSRNElectronicJournal(012020),508. https://doi.org/10.2139/
ssrn.3668444
[40] GalYonaandDanielGreenfeld.2021.RevisitingSanityChecksforSaliencyMaps.CoRRabs/2110.14297(2021).arXiv:2110.14297
15FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
A MODELANALYSIS
A.1 Runtime
ADGXA100systemwith40GBofRAM-MemorywasusedtocarryouttheexperimentsdescribedinSection4.The
codeforgeneratingsaliencymapswithvaryingsaliencymethodswasexecutedona20GBMIGsliceofanNVIDIA
A10040GBGPU.TheruntimesforgeneratingheatmapsfortheImageNetdatasetfromSubsection4.2withrespectto
differentsaliencymethodscanbeseeninFigure4.Theseruntimeshighlighttheperformancebenefitsofgradient-based
methodscomparedtothesample-basedmethodsofLIMEandSHAP.
A.2 Accuracy
Forthemodelaccuracyformosaicdatasets,seeTable2forResNet50andTable3forVGG11.Theaccuracyiscalculated
foreachclassseparately,withtop-1accuracydenotingwhetherclass1orclass2ofamosaicispredictedasthemost
likelyclass,top-5accuracydenotingwhetherclass1orclass2arepredictedinthefivemostlikelyclasses.Asthe
performanceofthesemodelsismeasuredonthemosaicdatasets,notruenegativesnorfalsepositivesaretobeexpected,
asallmosaicsdocontainimagesoftherelevantclasses.Becauseofthis,onlytheaccuracycanbecalculatedasa
meaningfulperformancemeasure.Theseresultsshowthatbothmodelspredicttherelevantclassesforthemosaics
oftenenoughtoexpectthemtohavelearnedtherelevantfeaturesfortheseclasses.Thisaidsintheassessmentwhether
theassumptionisfulfilledthatmodelsshouldhighlighttheimagesinamosaicthatcorrespondtothetargetofan
explanation.TheaccuracyfortheMountainDogsdatasetishigherthanfortheothers,possiblybecausealloftheimages
inthesemosaicscontributetothesametargetclasses.Thisexplanationisunderpinnedbytheimbalancebetween
positiveandnegativeFI,asdescribedinSection5.3.
Fig.4. Visualizationoftheexecutiontimeofthedifferentsaliencymethodsinseconds.Thetimerequiredtogeneratethesaliency
mapsofeverymosaicintheImageNetdataset(cf.Subsection4.2)wasmeasured.
16ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
Table2. Top-1andTop-5AccuracyforResNet50onthemosaicdatasets,forthestandardandfortheB-cosmodel.Notethatonlythe
ImageNet-mosaicscontainmorethantwoclasses.
top-1, top-5, top-1, top-5, top-1, top-5,
ResNet50
class1 class1 class2 class2 class3 class3
Cars/Catsdataset 0.27 0.73 0.175 0.765 - -
Cars/Catsdataset,B-cos 0.435 0.875 0.385 0.845 - -
MountainDogsdataset 0.42 0.995 0.49 0.995 - -
MountainDogsdataset,B-cos 0.345 1.0 0.41 0.995 - -
ImageNet 0.6256 0.8683 0.0423 0.1971 0.0447 0.2148
ImageNet,B-cos 0.476 0.8095 0.1548 0.4727 0.1701 0.496
Table3. Top-1andTop-5AccuracyforVGG11onthedatasetsforeachoftheclassesrepresentedinthemosaics,forthestandardand
fortheB-cosmodel.NotethatonlytheImageNet-mosaicscontainmorethantwoclasses.
top-1, top-5, top-1, top-5, top-1, top-5,
VGG11
class1 class1 class2 class2 class3 class3
Cars/Catsdataset 0.32 0.52 0.28 0.535 - -
Cars/Catsdataset,B-cos 0.375 0.805 0.435 0.86 - -
MountainDogsdataset 0.405 0.995 0.42 0.985 - -
MountainDogsdataset,B-cos 0.31 0.99 0.325 0.98 - -
ImageNet 0.3451 0.5933 0.0468 0.133 0.0447 0.1384
ImageNet,B-cos 0.3996 0.685 0.1265 0.328 0.1386 0.3408
Table4. ListofhyperparametersusedwhenexecutingtheXAI-methodsduringtheexperiments.
SaliencyMethod Hyperparameters
LIME ğ‘›ğ‘¢ğ‘š_ğ‘ ğ‘ğ‘šğ‘ğ‘™ğ‘’ğ‘  =1000
SHAP ğ‘›ğ‘¢ğ‘š_ğ‘ ğ‘ğ‘šğ‘ğ‘™ğ‘’ğ‘  =1500,ğ‘ ğ‘¢ğ‘ğ‘’ğ‘Ÿ_ğ‘ğ‘–ğ‘¥ğ‘’ğ‘™_ğ‘ ğ‘–ğ‘§ğ‘’ =56(equals8Ã—8=64superpixelspermosaic)
B EXPERIMENTS
B.1 Hyperparameters
Table4liststhehyperparametersusedwhenexecutingtheXAImethodsintheexperiments.Thisisdonetoensure
reproducibilityoftheresults.Hyperparametersthatequalthedefaultvalueandmethodsthatwereusedonlywith
defaulthyperparametersarenotincludedinthelisting.
B.2 Results
ForadditionalsaliencymapsforImageNetmosaicsseeFigure6andfordifficulttodistinguishclassesseeFigure7.Note
thatinthesecondcase,thesaliencyismoreevenlydistributedacrossthedifferentimagesinthemosaics.Forboth
datasets,differencesbetweentheexplanationsforthemodeltypescanbeseen.ComparedtoFigure2,thedistinction
betweenclassesislessclearinthesaliencymapsforImageNetandevenlessfortheMountainDogsdataset,resulting
inworsesaliencymetricperformance.
17FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
Fig.5. OnesampleheatmapbyeachsaliencymethodforthefirstmosaicshowninFigure1oftheCars/Catsdataset,hereforVGG11.
TheupperrowshowsheatmapsformethodswithpositiveandnegativeFI,theloweroneformethodswithonlypositiveFI.LIME
usesabinarymasktohighlightrelevantimagepieces,thusabinarymaskingoftheoriginalimageisshownhere.Notethedifferences
totheexplanationsforthesameimageforResNet50inFigure2.
B.3 MetricsforImageNet
Inthefollowing,adiscussionoftheresultsforthesaliencymetricsonImageNetcanbefound.Figure8showsmost
metricsforResNet50forB-cos,IntGrad,LRPandSHAP,Figure9displaysthesamemetricsforVGG11andFigure10
showstheF1-scoreforthesemethodsandtheprecisionforallconsideredsaliencymethods.Forbothmodels,some
similaritiescanbeobserved:ThesaliencymetricresultsofIntGradarecloseto0.5withalowvarianceforallmetricsbut
precisionandF1-score.Overall,therangeofsaliencymetricvaluesiswide(sometimesspanningfrom0to1),although
withthevaluesusuallyconcentratedonasmallerrange.Thiscanbeexplainedbysomemosaicsbeingeasierandsome
moredifficulttoexplainforeachofthemethods,whichisexpectedwhenusingrandomimagesfromadatasetas
diverseasImageNet.WhiletheB-cosmodelsdoperformwellinsomemetrics(precision,sensitivity,false-negative-rate,
accuracyandF1-score),theyconsistentlyperformbadinspecificityandfalse-positive-rate(withvaluescloseto0and1
respectively),showingtheirfailuretoattributenegativeFIcorrectlyandastrongbiastowardspositiveFIasdiscussed
inSection5.3.Overall,basedonthemedianperformances,LRPandSHAPseemtobethebestmethods,withSHAP
beatingoutLRPregardingthevarianceofspecificityandfalse-positive-rateforResNet50,whilethedistributionof
saliencyresultsforthosemetricsisbetterforLRPthanforSHAPwithVGG11.Thisbehaviourdoesnotshowinthe
F1-score,whichisaharmonizedmeanofprecisionandrecall.ButduetothehighermagnitudesforpositiveFI,the
F1-scoremainlyshowshowwellthepositiveFIisdistributed.ThisisnotsurprisinggiventhattheF1-scorecanbe
2ğ‘¡ğ‘
rewrittento .Thisshowsthatâ€”ifcorrectdistributionofnegativeFImattersforause-caseâ€”specificityand
2ğ‘¡ğ‘+ğ‘“ğ‘+ğ‘“ğ‘›
false-positive-rateshouldbeconsideredalongwithoneoftheothermetrics.
18ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
(a)SaliencymapsforResNet50onanImageNetmosaic.
(b)SaliencymapsforVGG11onanImageNetmosaic.
Fig.6. SaliencymapsfortheImageNetmosaicshownasthefirstimageinFigure6a.Thesaliencywascalculatedregardingthetarget
classâ€œear,spike,capitulumâ€,towhichtherighttwoimagesinthemosaicbelong.
19FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
(a)SaliencymapsforResNet50onamosaicoftheMountainDogsdataset.
(b)SaliencymapsforVGG11onamosaicoftheMountainDogsdataset.
Fig.7. SaliencymapsforthemosaicshownasthefirstimageinFigure7a.Thesaliencywascalculatedregardingthetargetclass
â€œBerneseMountainDogâ€,towhichthelowertwoimagesinthemosaicbelong.
20ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
Table5. Krippendorffâ€™sğ›¼forB-cos,IntGrad,LRPandSHAPforallmetricsforResNet50.
False- False-
Precision Sensitivity Negative- Positive- Specificity Accuracy F1-Score
Rate Rate
Cars/Catsdataset 0.81 0.89 0.89 0.82 0.82 0.83 0.85
MountainDogsdataset 0.24 0.98 0.98 0.96 0.96 0.35 0.67
ImageNet 0.61 0.85 0.85 0.49 0.49 0.69 0.74
Table6. Krippendorffâ€™sğ›¼forB-cos,IntGrad,LRPandSHAPforallmetricsforVGG11.
False- False-
Precision Sensitivity Negative- Positive- Specificity Accuracy F1-Score
Rate Rate
Cars/Catsdataset 0.56 0.59 0.59 0.79 0.79 0.64 0.56
MountainDogsdataset 0.15 0.72 0.72 0.67 0.67 0.14 0.52
ImageNet 0.52 0.58 0.58 0.67 0.67 0.62 0.57
Table7. Krippendorffâ€™sğ›¼forB-cos,IntGrad,LRP,SHAP,LIME,Grad-CAM,Grad-CAM++andSmoothGradforprecisionforResNet50
andVGG11.
ResNet50 VGG11
Cars/Catsdataset 0.88 0.56
MountainDogsdataset 0.25 0.14
ImageNet 0.71 0.56
ForthemethodswithonlypositiveFI,solelytheprecisioncanbecalculated.TheresultsinFigure10showthatthe
rankingofsaliencymethodsdiffersbetweenthetwomodels,aneffectespeciallyprominentforLIME,whichprovides
thebestmeanprecisionforResNet50,butonlythefifth-bestforVGG11.Basedontheprecision,LIMEseemstobethe
best-performingmethodforResNet50(althoughwithahighervariancethantheothermethods)andGrad-CAMfor
VGG11.Forbothdatasets,theyarecloselyfollowedbyB-cos,LRPandSHAP.
B.4 Inter-raterReliability
Fordetailedresultsforinter-raterreliabilityforResNet50,seeTable5,forVGG11,seeTable6.Notethatsomeofthe
usedsaliencymethodsonlyprovidepositiveFI,thusonlytheprecisionreliabilitycanbecalculatedforthem.These
resultscanbefoundinTable7.Thefindingsfortheinter-raterreliabilityarediscussedinSection5.1.
B.5 Inter-methodReliability
DetailedresultsforSpearmanâ€™sğœŒ correlationcanbefoundinFigure11forResNet50ontheCars/Catsdatasetand
ontheMountainDogsdataset.Thesecorrelationvaluesdifferbetweenthetwodatasets,asforthemoredifficultto
distinguishclasses(MountainDogs,Figure11a),somemethodsyieldhighlycorrelatedprecisionvalues,showingthat
thesemethodstendtoperformsimilarlyonthesameimages.Thiscouldbeduetomostimagesbeingdifficultto
distinguishandsomeshowingcleardifferences(ornoneatall)betweenthedogbreeds,thuseffectivelyproducing
21FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
(a)Precision (b)Sensitivity
(c)Specificity (d)False-Negative-Rate
(e)False-Positive-Rate (f)Accuracy
Fig.8. ResultsofthesaliencymetricsontheImageNetmosaicsfortheResNet50model.
22ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
(a)Precision (b)Sensitivity
(c)Specificity (d)False-Negative-Rate
(e)False-Positive-Rate (f)Accuracy
Fig.9. ResultsofthesaliencymetricsontheImageNetmosaicsfortheVGG11model.
23FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil BenjaminFresz,LenaLoercher,andMarcoF.Huber
(a)F1-scoreforResNet50. (b)F1-ScoreforVGG11.
(c)PrecisionforallmethodsforResNet50. (d)PrecisionforallmethodsforVGG11.
Fig.10. F1-ScoreandprecisionforbothmodelsontheImageNetmosaics.
good(bad)performancesonthesameimages.Fortheeasiertodistinguishclasses(Cars/Cats,Figure11b),noclear
correlationtendenciesexist,withthehighestvaluebelow0.6andmostbeingcloseto0,withsomeevenbelow0.This
showsthatthesaliencymethodsdonotconsistentlyagreeonwhichofthemosaicsinthisdatasetiseasierormore
difficulttoattributecorrectly.Sincethisdatasetapproximatesreal-worlduse-casesbetterthantheMountainDogs
dataset,itcanbeconcludedthatforreal-worldapplications,saliencymethodswilllikelystrugglewithdifferentimages
andthedifficultyofexplainingadecisionisnotinherenttoimagesbutrelatedtotheusedsaliencymethod.InSection5,
thiswassummarizedasâ€œThesaliencymethodstendtoworkindividuallybutsomeofthemfailjointlyâ€.
Received22January2024
24ClassificationMetricsforImageExplanations FAccTâ€™24,June3â€“6,2024,RiodeJaneiro,Brazil
(a)Spearmanâ€™sğœŒontheMountainDogsdatasetfortheprecisionmetricforResNet50.
(b)Spearmanâ€™sğœŒontheCars/CatsdatasetfortheprecisionmetricforResNet50.
Fig.11. Spearmanâ€™sğœŒfortheprecisionmetricondifferentdatasets.Whilethedatasetwithdifficulttodistinguishclassesproduces
highcorrelationvalues(nearing1forGrad-CAM/Grad-CAM++),thedatasetwitheasytodistinguishclassesproducesmostlyrandom
correlations,withthehighestonebetweenGrad-CAM/Grad-CAM++andGrad-CAM/LRPwith0.54.
25