The Last JITAI?
The Unreasonable Effectiveness of Large Language Models in Issuing Just-in-Time
Adaptive Interventions: Fostering Physical Activity in a Prospective Cardiac
Rehabilitation Setting
David Haag1,2,3, Devender Kumar1, Sebastian Gruber4,5, Mahdi Sareban1,6, Gunnar Treff1,6,
Josef Niebauer1,6, Christopher Bull7, Jan David Smeddinck1,7,8
1. Ludwig Boltzmann Institute for Digital Health and Prevention, Ludwig Boltzmann
Gesellschaft, Salzburg, Austria
2. Department of Psychology, Paris-Lodron-University of Salzburg, Salzburg, Austria
3. Digital Health Information Systems, Center for Health & Bioresources, AIT Austrian
Institute of Technology GmbH, Graz, Austria
4. Institute of Business Informatics - Data & Knowledge Engineering, Johannes Kepler
University Linz, Linz, Austria
5. Human Motion Analytics, Salzburg Research Forschungsgesellschaft, Salzburg, Austria
6. University Institute for Sports Medicine, Prevention and Rehabilitation, Paracelsus Medical
University, Salzburg, Austria
7. Open Lab, School of Computing, Newcastle University, Newcastle upon Tyne, UK
8. Human-Centered Ubiquitous Media, LMU Munich, Munich, Austria
Corresponding author:
David Haag, Ludwig Boltzmann Institute for Digital Health and Prevention, Lindhofstr. 22,
5020 Salzburg, Austria. E-mail: david.haag@dhp.lbg.ac.at
1 / 28Abstract
We explored the viability of Large Language Models (LLMs) for triggering and personalizing
content for Just-in-Time Adaptive Interventions (JITAIs) in digital health. JITAIs are being
explored as a key mechanism for sustainable behavior change, adapting interventions to an
individual‚Äôs current context and needs. However, traditional rule-based and machine learning
models for JITAI implementation face scalability and reliability limitations, such as lack of
personalization, difficulty in managing multi-parametric systems, and issues with data
sparsity. To investigate JITAI implementation via LLMs, we tested the contemporary overall
performance-leading model ‚ÄòGPT-4‚Äô with examples grounded in the use case of fostering
heart-healthy physical activity in outpatient cardiac rehabilitation. Three personas and five
sets of context information per persona were used as a basis of triggering and personalizing
JITAIs. Subsequently, we generated a total of 450 proposed JITAI decisions and message
content, divided equally into JITAIs generated by 10 iterations with GPT-4, a baseline
provided by 10 laypersons (LayPs), and a gold standard set by 10 healthcare professionals
(HCPs). Ratings from 27 LayPs indicated that JITAIs generated by GPT-4 were superior to
those by HCPs and LayPs over all assessed scales: i.e., appropriateness (M|SD =
GPT-4
5.47|1.26; M|SD = 4.60|1.67; M|SD = 4.47|1.53), engagement (M|SD = 5.94|0.90;
HCP LayP GPT-4
M|SD = 4.58|1.66; M|SD = 4.35|1.54), effectiveness (M|SD = 5.85|0.96; M|SD =
HCP LayP GPT-4 HCP
4.58|1.58; M|SD = 4.36|1.51), and professionality (M|SD = 5.86|0.91; M|SD =
LayP GPT-4 HCP
4.74|1.55; M|SD = 4.54|1.37). This study indicates that LLMs have significant potential for
LayP
implementing JITAIs as a building block of personalized or ‚Äúprecision‚Äù health, offering
scalability, effective personalization based on opportunistically sampled information, and
good acceptability.
2 / 28Introduction
Retaining adherence after transitioning back from settings with intensive in-person support is
a major challenge in promoting long-term health behavior change. E.g., patients going
through cardiac rehabilitation typically transition through different phases from initial clinical
to ambulatory settings with more sparse healthcare professional (HCP) support, and
eventually should return to living fully independent everyday lives1. However, health
behaviors like regular physical activity (PA), which is a central part of a successful cardiac
rehabilitation program2, are strongly determined by contextual influences such as the social
environment, structural opportunities for integrating PA, or momentary affect3,4. That means,
when support fades out after patients transition back to living their regular lives, many
people quickly fall back into their old, often sedentary habits5. This is the point where digital
health tools such as Just-in-Time Adaptive Interventions (JITAIs) can support the
maintenance and perpetual habitualization of health behavior change introduced during the
first rehabilitation phases6.
JITAIs are a concept that has many use cases across a broad range of digital health
interventions7. Nahum-Shani et al.8 conceptualized that JITAIs are designed to adjust to the
dynamic needs and contexts of individuals, harnessing technological advancements to
provide personalized health interventions when they are needed most. As opposed to
common ‚Äúone-size-fits-all‚Äù models in healthcare, JITAIs have potential as a valuable tool
offering more ‚Äúprecise‚Äù, context-sensitive, and time-relevant health interventions that
consider the individual‚Äôs unique circumstances. JITAIs can have many use cases, especially in
digitally accompanying people outside of stationary or in-practice routine care, e.g. in
offering support with achieving PA or other health behavior change goals throughout daily
living.
However, the two main approaches currently used to implement JITAIs ‚Äì rule-based
systems9 and machine learning models (MLM) ‚Äì are lacking behind visions of what JITAIs
could be ‚Äì a ‚Äúpersonal coach in your pocket‚Äù. Rule-based JITAIs function based on a pre-
established set of rules or algorithms. They often implement, clear-cut intervention
guidelines that can be conveniently modified when needed. However, appropriate models
describing the contextual dependencies of the respective health behaviors are not yet
available3,12. Therefore, setting up an effective set of rules requires time- and cost-intensive
optimization processes, such as micro-randomized trials (MRTs)13. Additionally, these systems
become exponentially more complex with rising numbers of tailoring variables. This makes
them hard to manage and potentially leads to error-prone outputs. Rule-based systems also
lack the ability to personalize interventions in the sense of tailoring to an individual's unique
needs and preferences as they dynamically change over time14.
While such personalization could be achieved through MLMs, e.g., using
reinforcement learning (RL)10,11, such models face extensive requirements regarding the
amount of data they need to start working effectively, also referred to as the "cold start"
3 / 28problem15. This can quickly leave users annoyed by ill-placed interventions, which might
cause them to abandon the use of their digital health tool, entirely14. Additionally, both rule-
based and MLM-based JITAIs face limitations in effectively dealing with missing or sparse
data or with not firmly pre-defined types of data16, which are very common in real-world
applications.
Additionally, the concerns above are only considering JITAI tailoring in terms of
whether a message should be sent in a given moment, not the content of messages, which is
also a core intervention element with JITAIs. Currently, most state-of-the-art systems merely
aim to support choosing the most appropriate option for a given situation out of a static list
of intervention options with only pre-structured or no personalization. This limits variability
in personalization and contextualization and can quickly lead to JITAIs being repetitive,
potentially disrupting the user‚Äôs impression of receiving personalized support and possibly
leading to reduced efficacy and increasing disengagement21. Overcoming this limitation
requires a different approach that offers the opportunity to generate flexible, personalized,
context-aware, and ever-unique health interventions in real-time. Such qualities might be
offered by generative artificial intelligence (GenAI), including large-language models
(LLMs)22‚Äì24 that have seen a ubiquitous rise over the last year and have reached prominent
public discourse25. This begs the question if these models might present a viable solution for
the challenges named above and thus be the next step in JITAI evolution.
LLMs such as OpenAI's GPT series can generate meaningful responses when faced
with opportunistically sampled, very high-dimensional information with many sparse or
temporarily unavailable parameters. The adaptability, scalability, and potential for
personalization31 of LLMs could move JITAI systems closer to the envisioned "personal coach
in your pocket" concept. Figure 1 illustrates the role that LLMs could potentially take over in
terms of the original JITAI conceptualization8. In the original concept, decision rules are
evaluated at predefined decision points. This means that based on the values of one or more
tailoring variables, a decision is made on whether one of the predefined intervention options
should be triggered. These interventions aim to improve on a certain proximal outcome (e.g.,
step count within 30 minutes after intervention), which should, in turn, lead to
improvements in a distal outcome (e.g., overall PA level). We propose that LLMs could (1)
replace the decision rules in this classic JITAI conceptualization, offering more flexibility in the
tailoring of interventions, and (2) augment the intervention options with custom-generated
or more strongly adapted content.
4 / 28Figure 1: The conceptual change from rule-based (left) to LLM-based (right) JITAI
implementations. Original figure (top) adapted from Nahum-Shani et al.8: In their original
concept, decision rules are evaluated at predefined decision points, decision rules are
evaluated. This means that based on the values of one or more tailoring variables, a decision
is made on whether one of the predefined intervention options should be triggered. These
interventions aim to improve on a certain proximal outcome (e.g., step count within 30
minutes after intervention), which should, in turn, lead to improvements in a distal outcome
(e.g., overall PA level).
Therefore, our main goal with this study was to explore the viability of employing
LLMs, specifically GPT-4, to trigger and generate JITAIs to support engagement with heart-
healthy PA in an outpatient cardiac rehabilitation setting. For that purpose, we presented the
model with semi-structured information about a persona in outpatient cardiac rehabilitation
together with a parameterization of their current context (see Supplement 1 for details). For
any respective combination of persona and context, the model was tasked with (1) deciding
whether the situation indicates a good opportunity for triggering a JITAI and, if so, (2)
proposing a fitting motivational text for the potential use case of a push-message
intervention. With this task, we aimed to investigate our guiding research question: ‚ÄúCan
5 / 28LLMs be utilized as a decision-making and personalized message tailoring mechanism in
JITAIs for fostering physical activity support messaging in prospective cardiac rehabilitation
contexts?‚Äù
In order to ground the performance of the LLM in relative terms, we compared the quality of
GPT-4 (below abbreviated as GPT) generated JITAI decisions and message content to
decisions and intervention messages generated by (1) laypersons (LayPs; as a ‚Äúbaseline‚Äù of
human performance without domain-specific training and since laypersons could arguably be
employed for crowdsourced or ‚Äúhuman computation‚Äù solutions for JITAI decision-making and
generation in limited use cases), and (2) HCPs (as a ‚Äúgold standard‚Äù ‚Äì which we would not
consider a practical alternative for solving the challenges of personalized JITAIs at scale, but
can arguably provide valid anchoring of the LLM performance). To assess the decision and
message quality of these three groups of ‚Äúgenerators‚Äù, we collected ratings on the
dimensions of assumed appropriateness, engagement, effectiveness, and professionality of
LayPs acting as ‚Äúassessors‚Äù (see Figure 2 for a visualization of study flow).
Figure 2: Study Procedure Flowchart. The term ‚ÄòJITAI response‚Äô refers to (1) a decision on
whether a JITAI should be triggered in the given moment, (2) generating the content of a
short smartphone notification (max. 75 characters) if a JITAI should be triggered, and (3)
generating the content of a slightly longer message (100 to 300 characters) to display in the
JITAI app. CVD = cardiovascular disease; HCP = healthcare professional; LayP = layperson;
JITAI = Just-in-Time Adaptive Intervention. Step 3 resulted in a total of 1350 JITAI assessments
from LayP. To allow for modeling the assessor as random effect, each of the assessments was
entered separately into the linear mixed model.
6 / 28Results
Study Participants
For the second step in our study procedure, as depicted in Figure 2 ‚Äì the JITAI
generation step ‚Äì we sampled 10 JITAI responses from each generator group (GPT, LayP, HCP)
for all 15 combined contexts (3 personas with 5 contexts each). This resulted in 3 x 150 = 450
unique responses, which constituted the generator outputs sample for the study. Generally,
we recruited HCP generators with the inclusion criteria of working as HCP in the UK (for
language consistency), having regular contact with patients, and having regular professional
experience with giving PA recommendations, e.g., in the form of creating exercise plans. Out
of the 10 HCPs who generated the JITAI responses (6 female, 4 male, M = 34.9 years, SD
Age Age
= 5.67 years), 6 reported to work as clinical exercise physiologists, and 1 each as nurse,
cardiologist, physical therapist, and sport scientist. The legitimacy of their professional
backgrounds was checked by the study team. None of the LayP JITAI generators (7 female, 3
male, M = 32, SD = 12.73 years, recruited from the UK adult population) reported to
Age Age
have previous experience with giving PA recommendations. For the LLM-based JITAI
generation, we used ChatGPT with the GPT-4 model35. JITAI response generation was done
between the 14th and the 21st of June 2023. Due to the continuous changes that are
implemented with these models36, our results refer to the model's capabilities at that time.
To generate the GPT-4 responses, given the non-deterministic nature of GPT-4 chat instances
when presented with identical prompts, we started 10 separate chats with ChatGPT and
provided the same instructions as for the human generators (see Supplement 2).
For the evaluation of the JITAI prompts, we recruited 27 additional laypersons (UK
adults, 18 female, 9 male, M = 36.3 years, SD = 12.07 years) to act as raters (assessors).
Age Age
Two of the 27 raters reported previous experience with giving PA recommendations
(regularly giving PA advice to friends). Each rater was responsible for assessing 50 responses,
ensuring that every generated JITAI received three independent evaluations. The raters
served to provide the primary and most secondary outcome measures of the study, with
additional auxiliary outcomes being provided by some of the question items that response
generators were asked to respond to. Table 1 summarizes the descriptive outcomes for
ratings provided for proposed JITAIs by each generator group, and Figure 3 provides an
according chart.
Table 1. Descriptive statistics for LayP assessor ratings (on 7-point Likert scales) per generator group.
Rating scale Generator group M SD Min Max
Considering persona and context, the decision and message are...
GPT 5.47 1.26 1.33 7.00
Appropriate HCP 4.60 1.67 1.00 7.00
LayP 4.47 1.53 1.00 7.00
GPT 5.94 0.90 2.33 7.00
Engaging HCP 4.58 1.66 1.00 7.00
LayP 4.35 1.54 1.00 7.00
7 / 28GPT 5.85 0.96 2.67 7.00
Effective HCP 4.58 1.58 1.00 7.00
LayP 4.36 1.51 1.00 6.67
GPT 5.86 0.91 3.00 7.00
Professional HCP 4.74 1.55 1.00 7.00
LayP 4.54 1.37 1.33 7.00
Considering persona and context, the decision and message would leave the recipient ...
GPT 1.71 0.80 1.00 5.67
Angry HCP 2.19 1.26 1.00 6.33
LayP 2.09 1.15 1.00 6.00
GPT 2.09 1.04 1.00 6.67
Annoyed HCP 2.77 1.49 1.00 7.00
LayP 2.56 1.34 1.00 6.33
GPT 2.08 1.05 1.00 6.33
Frustrated HCP 2.68 1.44 1.00 6.67
LayP 2.53 1.28 1.00 6.67
GPT 4.23 1.24 1.00 7.00
Happy HCP 3.51 1.49 1.00 7.00
LayP 3.38 1.28 1.00 6.67
GPT 1.74 0.72 1.00 3.67
Sad HCP 2.11 0.98 1.00 5.00
LayP 2.10 0.99 1.00 5.00
GPT 1.60 0.69 1.00 4.33
Scared HCP 1.85 0.90 1.00 6.00
LayP 1.78 0.79 1.00 4.67
GPT 2.34 0.88 1.00 4.67
Surprised HCP 2.71 1.13 1.00 7.00
LayP 2.68 1.12 1.00 5.67
Note. M = Mean; SD = Standard Deviation; Min = Minimum; Max = Maximum; HCP = Healthcare
Professional; LayP = Layperson
Differences in Response Quality Between Generator Groups
To analyze the differences in response quality as measured by the respective scales
(see Table 5), we used linear mixed models (LMMs), with rating on one of the scales (e.g.,
appropriateness) as outcome, generator group as fixed, and rater as random effect. The first
model, which analyzed the central outcome of a JITAI‚Äôs appropriateness to the given persona
in their current context, revealed that ratings differed significantly by group. Thus, we ran a
post-hoc test, which revealed that both lay-person responses (ùõΩ = -1.02, 95% CI = -1.32 ‚Äì -
0.71, p<.001) and HCP-generated responses (ùõΩ = -0.88, 95% CI = -1.18 ‚Äì -0.57, p<.001) were
rated significantly less appropriate than the GPT-generated responses. LayP and HCP did not
differ significantly regarding prospectively assessed appropriateness. We repeated this
analysis for all our scales, with the same directionality to the results throughout. Figure 3
summarizes how JITAIs generated by laypersons were prospectively assessed to be less
8 / 28engaging (ùõΩ = -1.57, 95% CI = -1.90 ‚Äì -1.24, p <.001), less effective for fostering PA (ùõΩ = -1.47,
95% CI = -1.81 ‚Äì -1.13, p <.001), and less professional (ùõΩ = -1.29, 95% CI = -1.61 ‚Äì -0.97, p
<.001) than the GPT-4 generated responses. The same applies to the HCP-generatedJITAIs,
which were also rated less engaging (ùõΩ = -1.36, 95% CI = -1.66 ‚Äì -1.05, p <.001), less effective
for fostering PA (ùõΩ = -1.26, 95% CI = -1.58 ‚Äì -0.95, p <.001), and less professional (ùõΩ = -1.12,
95% CI = -1.41 ‚Äì -0.82, p <.001) than the GPT-4 generated responses. Between lay-person and
HCP-generated JITAIs, while minor differences slightly but reliably favored the HCP responses
(see Table 1), we neither found significant differences in engagement, effectiveness, or
professionalism.
In the same way as we analyzed the previously mentioned scales, we also investigated
how LayP assessors thought the personas would feel after receiving the given ‚Äì or not
receiving any ‚Äì JITAI. These analyses, also visualized in Figure 3, revealed the same results,
with GPT-generated JITAIs consistently being rated more positively than those from HCPs or
laypersons (see Table 2 for detailed comparisons).
Figure 3: Mean and 95% confidence interval indicators for ratings of JITAI quality and
expected affective responses by generator groups.
9 / 28Table 2. Tukey-HSD post-hoc test results for differences in expected affective responses to JITAIs
from different generator groups.
Emotion Comparison Estimate (ùõΩ) 95% CI p
HCP - GPT 0.49 [0.27, 0.71] < .001*
Angry LayP - GPT 0.39 [0.18, 0.61] < .001*
LayP - HCP -0.10 [-0.32, 0.12] .533
HCP - GPT -0.72 [-0.99, -0.44] < .001*
Happy LayP - GPT -0.86 [-1.13, -0.58] < .001*
LayP - HCP -0.14 [-0.42, 0.14] .459
HCP - GPT 0.38 [0.19, 0.57] < .001*
Sad LayP - GPT 0.37 [0.18, 0.56] < .001*
LayP - HCP -0.01 [-0.20, 0.18] .987
HCP - GPT 0.25 [0.09, 0.42] < .001*
Scared LayP - GPT 0.18 [0.01, 0.34] < .05*
LayP - HCP -0.07 [-0.24, 0.09] .541
HCP - GPT 0.39 [0.16, 0.61] < .001*
Surprised LayP - GPT 0.36 [0.13, 0.59] < .001*
LayP - HCP -0.03 [-0.26, 0.20] .957
HCP - GPT 0.69 [0.43, 0.95] < .001*
Annoyed LayP - GPT 0.48 [0.22, 0.74] < .001*
LayP - HCP -0.21 [-0.47, 0.06] .152
HCP - GPT 0.61 [0.36, 0.87] < .001*
Frustrated LayP - GPT 0.46 [0.21, 0.71] < .001*
LayP - HCP -0.15 [-0.40, 0.10] .345
Note. CI = Confidence Interval; HCP = Healthcare Professional; LayP = Layperson; *p < .05
Consistency of Ratings Across Raters Overall and by Assessed Generator Group
To check the consistency of our response ratings over different raters, we calculated
inter-rater reliabilities and compared if they differed between generator groups. Since we
had three raters (LayP assessors) per JITAI response, we calculated and averaged Cohen‚Äôs
Kappa between each of the rater pairs. This resulted in an overall average of ùúÖ = .53
indicating a moderate agreement between raters over all our responses. Analyzing this
separately for the three different response generators revealed a good level of agreement
between raters for GPT-4 generated responses (ùúÖ = .64) and a moderate level of inter-rater
reliability for responses from HCPs (ùúÖ = .50) and laypersons (ùúÖ = .42).
Possible Interaction Effects with Persona
To investigate whether the persona ‚Äì and thus, the approximate degree of aspects
either easing or increasing concerns around the extent, intensity and further nature of PA
10 / 28that is safe and appropriate to propose ‚Äì moderates the differences in response ratings
between the generator groups, we ran a modified LMM, this time including the interaction
between the generator group and persona as predictor. We did not find statistically
significant interactions between any level of generator group and any level of persona.
Instead, the effects observed above hold in the same directionality and separation across
dependent variables across the different personas. Hence, there does not appear to be any
persona for which the ordering of the relative performance qualities of any rater group
changes, which might be assumed, e.g., for a higher-risk persona, or perhaps also for a
‚Äúmiddle-ground‚Äù persona, as their description and situation leaves more room for
interpretation.
To explore this notion, we also analyzed if there were differences between the three
personas when comparing how difficult the JITAI generation was perceived to be by the
different generators. Using a Kruskal-Wallis test to compare these difficulty ratings over all
generators yielded a chi-squared value of 0.07 with 2 degrees of freedom, culminating in a p-
value of 0.966. This result suggests a lack of statistically significant differences in the difficulty
ratings assigned to the three personas. We found the same result in conducting this analysis
separately for the three generator groups: GPT (chi-squared = 1.95, df = 2, p-value = 0.378),
HCP (chi-squared = 0.61, df = 2, p-value = 0.736), and LayP (chi-squared = 0.22, df = 2, p-value
= 0.895).
Qualitative Feedback Analysis
We also analyzed the qualitative feedback that assessors could optionally give for
each JITAI response. We received 228 qualitative feedback statements for GPT-generated
responses, 203 statements for HCP-generated JITAIs, and 170 statements for JITAIs from
LayPs. The first author categorized this feedback into positive, neutral, or negative sentiment.
Table 3 shows the counts and respective percentages by category. Comparing the three
generator groups by their positive to negative feedback ratio clearly shows that GPT-4
responses received the best feedback, with 4.5 times more positive than negative feedback.
HCP responses received 0.2 times more positive than negative feedback, and laypersons
received even less positive than negative feedback (P/N ratio:0.74). This is in line with the
inferential statistics significantly setting GPT apart from LayP and HCP, as well as with the
descriptive statistics indicating slightly but consistently higher response quality for HCP than
for LayP within our obtained sample.
Table 3. Valence of feedback on JITAIs by generator group
Positive Neutral Negative
GPT 170 (75%) 27 (12%) 31 (14%)
HCP 96 (47%) 27 (13%) 80 (39%)
LayP 61 (36%) 26 (15%) 83 (49%)
11 / 28Note. HCP = Healthcare Professional; LayP = Layperson
In an inductive thematic analysis of the qualitative feedback, the first author
systematically identified emergent themes by iteratively categorizing the responses into
distinct groups. Thereby, we identified reoccurring themes around JITAI timing, content,
verbal representation, and affective responses towards JITAIs. Regarding JITAI content,
several sub-themes emerged, such as positive reinforcement (e.g., praising users after they
adhered to their exercise plan), planning (e.g., incentivizing replanning of a missed activity),
offering alternative PA options (e.g., when an outdoor activity is planned, but the weather is
bad), encouraging spontaneous PA for mood improvements (e.g., recommending users to go
for a short walk to relieve stress), contextualization (i.e. feedback on how well the JITAI was
adjusted to a users current context), personalization (i.e. feedback on how well the JITAI was
adjusted to the respective user), as well as quality, actionability, correctness, and safety of
advice. Notably, regarding the JITAI content sub-themes, positive reinforcement, offering
alternative PA options, and encouraging spontaneous PA for mood improvements were
perceived as positive over JITAIs from all generator groups. All other content sub-themes
contained both positive and negative feedback, with differing distributions over different
generator groups.
As mentioned above, GPT-4 JITAIs generally received the most positive feedback.
Splitting this up into different themes only corroborated this impression, especially regarding
contextualization and personalization. For these central aspects of JITAIs, we received
feedback such as: ‚ÄúIt came at a good time, Markus was awake and ready to go for a walk, he
wouldn‚Äôt feel angered because he is in a good mood and on his day off, perfect for a walk
with his wife‚Äù (LayP Rater-14 for GPT-4 JITAI iteration 6, Persona 2, Context 3).HCP-generated
JITAIs, on the other hand, received largely negative feedback on the level of personalization
and context-sensitivity, e.g., ‚ÄúHe has a walk planned so I think this would feel impersonal and
not encouraging as it does not relate to the planned activity, and I would think it was
automated and not relevant‚Äù (LayP Rater-12 for HCP 1, Persona 2, Context 3). The same goes
for layperson JITAIs with feedback like, ‚ÄúAs the app can see the 'work' location it should not
send anything at 9 pm at night. It would be inappropriate and annoying. Sending exercise
reminders that late at night should never happen‚Äù (LayP Rater-2 for LayP 9, Persona 1,
Context 1).
Another interesting insight, we can draw from this feedback is that while all the
generator groups received about the same amount of negative feedback on the timing of
JITAIs ‚Äì 24 for GPT-4, 24 for HCPs, and 37 for laypersons ‚Äì these feedbacks contained fewer
considerations around negative affect being evoked by bad timing for GPT-4 based JITAIs ‚Äì 6
(25%) for GPT-4, 10 (42%) for HCPs, and 18 (49%) for laypersons. This could be related to
GPT-4 based JITAIs being generally phrased in a more friendly and engaging manner, which
was also indicated by feedback such as: ‚ÄúI might be a bit frustrated and groggy because of
how early it is but the message would motivate me!‚Äù (LayP Rater-6 for GPT-4 JITAI iteration 5,
12 / 28Persona 3, Context 1). Meanwhile, HCPs and laypersons received largely negative feedback
on the verbal representation of their JITAIs, e.g. for HCPs: ‚ÄúThe message could be more
encouraging rather than factual. The feeling of anxiety may be made much worse if made to
feel that not doing at least 30 minutes of exercise will put them at risk of another heart
attack.‚Äù (LayP Rater-7 for HCP 5, Persona 2, Context 1) or for laypersons: ‚ÄúI don't like the
message of this one, it doesn't tell me what to do except for move. It's not very encouraging
but I would probably need the reminder.. maybe the wording needs to be different.‚Äù (LayP
Rater-13 for LayP 5, Persona 3, Context 1).
Guessing the Generator
Before presenting the last six responses that each assessor was asked to evaluate, we
revealed that there were three different groups responsible for generating these JITAIs. This
gave us the opportunity to additionally ask the raters for a guess on who generated the
respective response. The confusion matrix of ‚Äòguessed generator‚Äô by ‚Äòactual generator‚Äô in
Table 4 indicates how well LayP assessors were able to distinguish between the different
generators. We found that only the GPT-4 responses were recognized with an above-chance
probability. For the other groups‚Äô JITAIs, the recognition rate was slightly below chance, with
a tendency to confuse them for GPT-4 responses. GPT-4 responses, however, were mistaken
for being HCP-generated in half of the cases and were very rarely taken for being generated
by LayPs. Additionally, we asked the raters how many of the six responses they expected
themselves to guess correctly. The ratio of expected to actually correct guesses was 1.74,
which means that raters in the sample overestimated their ability to distinguish between the
different types of generator groups.
Table 4. Confusion matrix of guesses to actual JITAI generator
Guessed Generator
GPT HCP LayP
GPT 23 (43%) 27 (50%) 4 (7%)
Actual Generator HCP 25 (46%) 16 (30%) 13 (24%)
LayP 31 (57%) 8 (15%) 15 (28%)
Note. HCP = Healthcare Professional; LayP = Layperson
Differences in Ratings When the Generator is Known
Lastly, we analyzed how the response ratings differed when raters knew who
generated the respective responses. Using a Wilcoxon signed rank test to compare
appropriateness ratings provided by LayP for known and unknown conditions, we found no
significant differences for GPT-4 generated responses (M = 5.09, M =
generator known generator unknown
4.85, Wilcoxon‚Äôs V = 64.5, p = .47), but trend-level differences for HCP (M = 5.45,
generator known
13 / 28M = 4.75, Wilcoxon‚Äôs V = 100, p = .1) and layperson generated responses
generator unknown
(M = 3.44, M = 4.2, Wilcoxon‚Äôs V = 31.5, p = .06). Thus, for GPT-4
generator known generator unknown
JITAIs the primary appropriateness rating seems to be unaffected by raters‚Äô knowledge about
the generator, while slight biases might improve HCP JITAI ratings and worsen layperson JITAI
ratings. Figure 4 visualizes this outcome using the difference score between the unknown
and the known condition.
Figure 4: Differences between blind and unblinded JITAI ratings by generator group.
Discussion
The results indicate several key insights regarding the potential effectiveness of LLMs
as a particular type of generative AI foundation models in generating JITAIs to motivate
heart-healthy PA in the prospective setting of cardiovascular rehabilitation: Firstly, JITAIs
generated by GPT-4 consistently benchmarked positively compared to those created by HCPs
and LayPs in terms of appropriateness, engagement, effectiveness, and professional
appropriateness. This finding extends to prospective affective impacts, with GPT-4 JITAIs
being assessed as more likely to provoke positive emotions and less likely to elicit negative
ones.
Additionally, our analysis showed a higher inter-rater reliability for GPT-4 responses
than for responses from HCPs and LayPs, underscoring a more uniform perception of their
qualities. Furthermore, GPT-4 demonstrated a consistently high performance across various
personas placed on a low-to-high CVD-risk continuum, showcasing its adaptability and
reliability of response qualities in diverse contexts. This finding is crucial for the scalability of
14 / 28JITAI personalization to heterogeneous interests, abilities and needs of the stakeholders,
which will also change dynamically over time14.
Notably, our raters experienced great difficulties in correctly identifying the source of
JITAIs and being made aware of the response generator did not significantly influence the
perception of GPT-generated JITAIs by LayPs, formatively representing the target stakeholder
group for many nonmedical use-cases. This outcome is noteworthy as it shows that, at least
in this aspect, there seems to be no general bias towards AI-generated content or negative
suspicion around the capacity of generative AI to inform decision-making and content
production in this setting in an automated fashion. For HCP and LayP-generated responses,
we observed trend-level biases. As one might assume based on socially learned expectations,
we found better ratings for HCP responses and worse ratings for JITAIs from LayPs as
compared to blindly labeled persona-context pairings.
Overall, our formative outcomes underscore the considerable potential of LLMs as a
form of generative AI for the implementation of effective JITAIs.
Contextualization in Related Work
It is important to stress that the task of generating JITAIs to motivate PA in cardiac
rehabilitation patients, as assessed in this study, is not within the typical scope of
responsibilities of HCPs. A large-scale deployment of JITAIs that are custom-generated for
every user by HCPs ‚Äì or even by LayPs ‚Äì following a crowdsourcing38 or human
computation39,40 paradigm is not reasonably possible due to scalability limitations and
privacy concerns. However, the JITAI implementation through LLMs opens completely new
possibilities, and traditional JITAI approaches cannot reasonably compete with the
interpretation of complex parameter spaces as they are employed in this study in order to
represent broad categories of information that modern multi-device context sensing systems
can be expected to integrate during daily living. Thus, we argue that HCP-generated JITAIs are
the most appropriate "gold standard" comparison, since we expected that training and
experience should allow the HCPs to excel at this task. Even though it is not part of everyday
work for HCPs, giving motivational guidance and feedback in a contextualized manner is an
occasional part of the work of many HCPs who are regularly involved in issuing PA
recommendations or exercise plans. Yet, our results explicitly do not reflect an assessment of
LLM capabilities to take over tasks that are currently being handled by HCPs. This formative
work to assess the viability of LLMs in the context of JITAIs was also not designed to contrast
differences in the ability to offer support in fostering PA between HCP and LayP in a nuanced
manner. When considering the integration of JITAIs in healthcare, the role of HCPs might be
more aligned with overseeing or validating the content rather than directly creating it. The
findings of our study suggest that while HCPs are highly skilled in their traditional roles,
crafting digital interventions like JITAIs requires a set of competencies in which generative AI
like GPT-4 can offer substantial advantages in terms of personalization based on
15 / 28opportunistically sampled possibly sparse but broadly sampled information inputs, scalability
to high-frequency or even continuous support, and adaptability to stakeholder groups of very
heterogeneous interests, abilities, and needs, as well as to a broad range of contexts.
Our outcomes indicatively corroborate results from related work on the potential of
LLMs. For instance, Kosinski33 found that GPT-4 displayed strong 'Theory of Mind'-like
abilities, being able to solve 95% of the presented false-belief tasks. These are commonly
used to measure Theory of Mind34, which refers to the human ability to infer and simulate
others‚Äô cognitive states and processes32. Arguably, this ability is essential to the LLM‚Äôs ability
to make empathetic decisions on whether to send a JITAI in a given moment, approximating
a ‚Äúpersonal coach in your pocket‚Äù.
The ability of LLMs to make meaningful recommendations has already been
determined in the context of recommender systems41. To foster PA, such recommender
systems could, for instance, be used to recommend PAs that fit a person‚Äôs preferences42. Shin
et al.43 explored a similar direction, indicating their GPT-4-based AI assistant‚Äôs potential to
support users in creating an individualized exercise plan based on their exercise goals,
availability, and possible obstacles.
However, to apply such systems to medical contexts, it is extremely important that
they adhere to high safety standards and do not pose a risk to patients. In this regard, LLMs
have demonstrated the ability to pass various professional qualification tests, including
health-relevant ones like the United States Medical Licensing Exam (USMLE)44 or the
MultiMedQA45,46. However, Lee et al.47 also found that GPT-4 produced responses of
unreliable quality when asked to answer medical questions and reported an overall relatively
low accuracy of GPT-4 in answering these medical questions, and 7% of the responses were
even deemed harmful by HCPs. This indicates the need for continued critical debate,
consolidation of conflicting outcomes being reported by different research teams, and
rigorous empirical testing of LLM outputs‚Äô efficacy and safety for each use case47.
Given the context of our study within the sensitive realm of health, broader
challenges associated with LLMs would, of course, need to be considered and addressed for
potential practical use beyond the formative exploration of viability. Issues of privacy,
security, inherent biases, and regulatory compliance52, notably under frameworks like the EU
AI Act53, which will particularly regulate AI development and use in sensitive settings,
including health, are paramount. Additionally, ensuring accuracy, transparency, fairness, and
explainability54 in these models is critical. Ethical considerations and accessibility also play
crucial roles, as highlighted by frameworks such as the European Patients Forum's 2023
principles for AI regulation in healthcare55. These challenges underscore the complex
landscape of deploying LLMs in healthcare settings and emphasize the necessity for a
cautious, well-regulated approach.
From a technical point of view, our findings further corroborate one of the arguably
most valuable use cases of generative AI, and particularly LLMs, in fostering transitions
between highly structured, possibly well-defined data and rich but not well-defined natural
16 / 28language representations (see, e.g., emerging databases56). As such, in our study, we
provided the persona and context information (model input) as the foundation for triggering
JITAIs and generating their content (model output). This model input represents, e.g.,
human- and machine-readable data that might be exchanged from various information
collection mechanisms to a central decision-making mechanism in JSON or following other
data exchange format specifications. In a digital health context, this can function both ways,
e.g., isolating relevant key terms and relations from a subjective expression of self-perceived
symptoms, or ‚Äì as in the case of this study ‚Äì generating language expressions that feel
natural and can serve functions that include human communication nuances. Thus, the
encouragement to adhere to planned PA behavior change, as generated in our study, can be
seen as an example of computational outputs that are viable to fulfill the principles of reality-
based interaction57. Similar principles are concurrently being explored in many other
application areas, such as robotics and AI-enabled human-robot interaction58‚Äì62.
Limitations
This study is formative and exploratory, and it is therefore crucial to address
limitations that frame our findings. Firstly, the generation and assessment of JITAIs were
executed based on personas and viable ‚Äì but artificially composed ‚Äì context information and
the JITAIs were not experienced as part of situated daily living as they would be during an
actual deployment. Furthermore, at the current state, our results exclusively display how
LayPs perceived the quality of JITAIs generated in our study. Professional perspectives for
HCPs are being collected and will be included in the final peer-reviewed publication and
updated pre-print versions. Currently, however, the absence of professional perspectives
limits the depth and breadth of our evaluation. Especially the professionality ratings should
be treated with caution since they were provided by LayPs without specific medical training
and experience with making recommendations for exercise activities in the prospective
setting of cardiac rehabilitation patients. Thus, the results presented herein require further
validation from professional perspectives and based on practical ‚Äúreal-world‚Äù deployments.
While our study strongly indicates the viability of using LLMs like GPT-4 for creating
JITAIs, this should not be confused with proven effectiveness. The transition from feasibility
to real-world efficacy remains an uncharted territory that eventually necessitates rigorous
evaluation in practical healthcare settings. Our research lays the groundwork for future
studies to explore the actual impact of these AI-generated interventions on health outcomes
and can arguably serve to justify a certain degree of efforts, costs and minor inherent
dangers in further investigations, e.g., in settings with CVD patients from an ethical
perspective.
Based on the comparison with human-generated proposed decisions and content, we
also cannot draw conclusions as to how these AI-generated JITAIs compare to current JITAIs
implemented via, e.g., rule-based solutions or parameter prediction based on more
17 / 28traditional machine learning approaches, such as supervised learning from labeled datasets.
However, as we lay out above, especially the LLMs‚Äô ability to handle sparse and varying
contextual variables and transform between structured data and natural language can
change the way we think about JITAIs fundamentally, which makes a comparison to rule-
based implementations almost impossible. Equally important is the scope of LLMs explored
in our study. Focusing solely on GPT-4, we did not evaluate other state-of-the-art LLMs.
Particularly, open-source models such as the LLaMA/LLaMA2 model series27 could be
interesting candidates. But also models that are being tailored for local execution ‚Äúon the
edge‚Äù and can fully respect crucial privacy sandboxes with federated learning (e.g., MPT-7B28
or Phi-263) or models trained specifically for the medical context (e.g., Med-PaLM29) should
be considered.
Lastly, although related work is beginning to show that prompting can have a
considerable impact on LLM performance64, we did not experiment with prompting
strategies beyond providing factual and outcome-oriented instructions that were designed to
make for meaningful inputs to the LLM and human generators and assessors alike and
running feasibility checks with different LLMs and human study participant testers.
Implications and Future Research
Alternative generative AI models could present better solutions in terms of data
privacy and could lead to even more precise and effective interventions. Thus, future works
should compare these options more closely. Particularly, considering smaller, more domain-
specific, and multi-modal models that can more flexibly ingest and produce various input or
output data formats, lead to energy savings, and importantly, be reliably and entirely privacy-
preserving, e.g., by running on user-dedicated HIPAA and GDPR-conforming secure cloud
instances, or even on a user‚Äôs smartphone65. Future studies should also focus on
implementing generative AI-enabled JITAIs in practical healthcare settings, allowing for an
evaluation of their effectiveness in real-world environments. In settings that potentially
involve more severe consequences for triggering flawed JITAIs than fostering PA, it could also
be an interesting approach to combine pre-defined rules (e.g., HCPs defining values of
tailoring variables in which no JITAIs should be triggered) with the LLMs ability to produce
personalized and contextualized JITAI content.
Another intriguing aspect for future research is the exploration of the extent to which
personalization and contextualization contribute to the effectiveness of JITAIs. Understanding
the relative importance of personalization, e.g., as compared to viable pre-produced building
blocks and content of JITAIs could significantly influence how JITAIs are structured and
delivered, potentially leading to more efficient health interventions.
Moreover, the concept of incorporating a reinforcement-learning-like mechanism to
enhance personalization in JITAIs presents an exciting avenue for research. Such a
mechanism could involve feedback loops where patient responses to JITAIs are fed back to
18 / 28the LLM to continually refine and adapt the interventions based on what works for the
individual. Looking beyond contributing personal preferences and feedback as part of an
online RL or RL from human feedback66 loop, further building up and considering user
models offers exciting perspectives both for further improved acceptance and effectiveness
of interventions. This could, e.g., be enabled by personal health knowledge graphs67 that a
generative AI model can rely on, contribute to, and expand upon. Additionally, this might
even allow for scaling research into understanding the complex interplay of the high-
dimensional parameter spaces that make up the composition of complex, dynamically
evolving personalized interventions14. Further viable technical steps would include
experimentation with LLMs that are fine-tuned based on the scenarios and feedback data
collected from this study. For example, our qualitative findings on themes of ‚Äúpositive
reinforcement‚Äù, ‚Äúoffering alternative PA options‚Äù, and ‚Äúencouraging spontaneous PA for
mood improvements‚Äù, which received very positive feedback over all generator groups, could
inform instruction prompts for JITAI generation. Such refinements should arguably further
improve the produced JITAI decision-making and proposed content, moving beyond zero-
shot performance in a self-supervised/agentic or weakly supervised manner68.
Conclusion
In this formative study, we explored the potential of LLMs - such as GPT-4 - in creating
JITAIs for cardiac rehabilitation. Our findings indicate that LLM-generated JITAIs not only
surpassed human-generated interventions in terms of appropriateness, engagement, and
effectiveness based on layperson assessments, but also demonstrated significant adaptability
across various patient personas. Furthermore, the response assessment by laypersons did
not differ significantly if the LLM was clearly identified as the producer of the JITAI, indicating
an absence of critical biases regarding the potential and viability of AI systems to be the key
driver in a JITAI mechanism in the sampled population. Together, these points indicate the
relevant potential of generative AI with foundation models in delivering scalable,
personalized and contextualized digital health interventions. Despite the identified
advantages, the transition from viability to efficacy and acceptability in real-world healthcare
settings remains a vital area for future research. In conclusion, this study underlines the
transformative potential of LLMs in digital health, particularly in creating effective and
personalized JITAIs for fostering behavioral change, clearly warranting investment into
further study of the effectiveness of situated and longer-term deployments.
19 / 28Methods
Procedure
As the first step of the study procedure depicted in Fig. 2, we created three different
detailed personas of cardiac rehabilitation patients. With these three personas, we aimed to
approximate the spectrum of cardiac health risks commonly found in outpatient CVD
rehabilitation, from rather low to rather high. Each persona was crafted with a
comprehensive set of variables, including demographics, health metrics, and lifestyle factors,
as they may typically be available in healthcare settings. For each persona, we produced five
distinct contexts, aiming to vary the advisability of a PA intervention. The contextual
variables representing these contexts were selected based on tailoring variables typically
used according to JITAI literature69,70, previous work from our institute on momentary
determinants of PA71, and the aktivplan application72, in which this exploratory work is
grounded for motivation and which produced the original personas that were adapted for
this work. Both the personas and contexts were then subjected to a validation process by
two HCPs ‚Äî a cardiologist and a sports scientist ‚Äî to ensure they depicted a realistic and
progressive range of symptom severity.
To generate the JITAI responses we presented, our three generator groups‚ÄîGPT-4,
LayPs, and HCPs‚Äîwith the detailed information on persona and context. We always
presented the contexts nested within personas, permuting the order for both, personas, and
contexts within each persona. Based on this information, we asked the generators to decide
whether a JITAI should be sent in the given situation and to compose two text messages ‚Äì a
short notification (max. 75 characters) and a slightly longer text to display in an exemplary
app for physical activity planning and reporting (100 to 300 characters) ‚Äì if they deemed the
situation appropriate for sending a JITAI. If a generator decided against sending a JITAI, they
were asked to articulate their rationale. To assess the complexity, effort, and mental load
perceived by generators, we also asked for feedback on the difficulty of deciding on and
crafting a JITAI. Ensuring a standardized task representation across groups, we initially
presented instructions that delineated the concept of JITAIs, the functioning of the JITAI-App,
and its role in supporting outpatient rehabilitation before starting the JITAI generation. The
study materials are available online as supplementary material, and Figure 5 shows an
example of a GPT-4 output for this task.
20 / 28Figure 5: Screenshot of a JITAI that GPT-4 would have generated for the persona ‚ÄúEmily
Thompson‚Äù. The response was based on contextual data representing the following situation:
‚ÄúIt's Thursday evening, and Emily is sitting in her living room, knitting a new scarf. She‚Äôs been
watching TV for the last couple of hours and has barely moved from her chair." (See online
prompt materials: Persona: Emily Thompson, Scenario: 2 for full details.).
To assess the quality of the generated JITAI decisions and content, we asked all three
groups of generators to rate the responses on multiple scales described below. We presented
the assessors with instructions similar to the generating task, explaining the concept of JITAIs
and how their quality should be assessed. For each rating task, instructions contained the
same detailed information on personas and their contexts as before, but we additionally
included a description of the situation in natural language to ensure the assessors were
provided with an accurate representation of the situation as an actual JITAI recipient would
have as well. We currently report on the preliminary outcomes based on responses by LayP
assessors. The final publication of this study will also contain response ratings from HCPs,
which are currently being collected and analyzed. This will allow us to derive more reliable
implications driven by multi-stakeholder views, especially regarding the professionality of
generated JITAIs, which LayPs can only assess to a limited degree. However, since the main
users of such applications would most likely be akin in their assessments to LayP, it is already
possible to draw first indications regarding viability of the approach. Therefore, this study can
act as an appropriate exploratory step before experimentation in applied health or medical
use cases.
21 / 28Measures
The JITAIs were primarily assessed using four key dimensions presented as 7-point Likert
scales. Table 5 shows the scales and the items.
Table 5. Dimensions and items assessed via 7-point Likert scales and their respective items
Dimension Item (What do you think ‚Ä¶)
‚Ä¶how appropriate is it to send this JITAI to
appropriateness the given persona under the given
circumstances?
engagement ‚Ä¶how engaging are the messages?
‚Ä¶how effective will this JITAI be in
effectiveness
supporting the user to reach their PA goals?
‚Ä¶how professionally appropriate is the
professional appropriateness
content of this JITAI?
In addition to the dimensions listed in Table 5, raters gauged the assumed emotional
impact of the JITAIs, providing their assessment of how the recipient would feel upon reading
the given message under the given circumstances. This assessment included single-item
scales for five basic emotions73 (happiness, sadness, anger, surprise, fear) and additionally for
annoyance and frustration, which we considered especially relevant to the JITAI context as
they are often related to intervention fatigue21 and users discontinuing the use of digital
health tools8. Given the formative and prospective nature of this work and the assessment
task, we did not employ validated psychometric questionnaires ‚Äì which would be firmly
implied for possible future practically validating work of this approach ‚Äì given their
complexity and their lack of validity for prospective scenarios.
An optional qualitative feedback section was provided for raters to express their
thoughts on the JITAI content and its presentation within the application, which was
described as part of the overarching context and framing of the study provided to
participants.
The primary outcomes of the study were captured as part of a blinded rating phase.
Afterward, raters were informed about the three JITAI-producing parties and asked to guess
the generator group in a selected subsample of responses. This was followed by a final phase,
in which the generator of the JITAI was disclosed before asking for assessment following the
scheme as described above on a further subsample of responses. Thus, we were able to
analyze whether the evaluations regarding response quality provided by the raters were
influenced by their knowledge of the generator group, offering formative insights into
potential biases towards AI-generated versus human-generated interventions.
22 / 28Participant Recruitment
LayP participants for both generation and rating tasks were recruited via Prolific,
targeting UK participants to reduce the impact of language barriers. For their contribution,
human JITAI generators were compensated with 10 GBP, with an additional 5 GBP bonus
awarded for responses deemed to have satisfactory quality. This bonus incentive was aimed
at ensuring the collection of thoughtful and relevant JITAIs. LayP raters were offered a higher
compensation of 15 GBP, reflecting the longer engagement time of approximately 90 minutes
required to complete the ratings. Healthcare professionals were recruited from professional
networks within the UK that specialize in physical activity-related fields, as well as via social
media and the networks of the study team. Considering their professional expertise as
relevant to the context of the study and the nature of their contribution, HCPs were
compensated with a 30 GBP Amazon voucher, reflecting approximately twice the monetary
value. We selected GPT-4 as the LLM for our study because of its general state-of-the-art
performance on most relevant benchmarks74 and argue that outcomes remain relevant even
in comparison to models targeting the medical and health domain, since GPT-4 has been
shown to outperform domain-specific models like MedPALM 248 when using case-oriented
prompting64. We also performed a sanity check comparing the GPT-4 responses to JITAIs
generated by Google Bard and BING models available in August 2023 but found GPT-4
responses to display the highest response quality in an informal assessment, providing
reasoning to proceed with GPT-4 only for this exploratory work.
Data analysis
The principal analysis of the JITAI response ratings employed LMMs to accommodate
the nested structure of our data: multiple, but not all JITAIs evaluated by each rater. Each
LMM accounted for the fixed effect of the generator group (GPT-4, LayPs, HCPs) on the
ratings, while treating the rater as a random effect to control for inter-rater variability. This
approach allowed us to discern the impact of the generator group on the perceived
appropriateness, engagement, effectiveness, and professional suitability of the JITAIs. After
fitting the LMMs, Tukey's HSD post-hoc tests were conducted for multiple comparisons to
determine the significance of the differences between the generator groups. In an additional
analysis, we included the interaction between generator group and persona in the model to
investigate if any generator groups would show advantages or shortcomings for different
levels of symptom severity. To check if the stability of ratings differed between different
generator groups, we calculated and compared average Cohen‚Äôs Kappa values for responses
produced by each of the groups.
23 / 28Acknowledgments
We thank all our study participants. We also thank Dr. Daniela Wurhofer and Dr.
Stefan Tino Kulnik, as well as the wider teams behind the iterative development process of
the aktivplan application in which this exploratory work is grounded for motivation and
which produced the original personas that were adapted for this work. We also thank various
participants of the Generative AI for Digital Health Interventions workshop held in Salzburg in
February 2023 for early discussion around the research aim of this work.
Author Contributions
DH acted as the lead author of the study and implemented and executed most of the
study. JS acted as the senior author, together with DK providing mentorship and guidance
throughout the project. DK and JS developed the original research concept and collaborated
on iterating it throughout the study duration. SG contributed to starting and closing
discussions of the project. DH, DK, SG, MS, GT, JN, CB and JS all contributed to drafting and
improving the writing of this article. MS and GT contributed to checking the fidelity of
personas and scenarios and ‚Äì together with JN supported writing the medical / health-
relevant sections of the draft.
Data Availability
Personas, context descriptions / scenarios, JITAI instructions, analysis scripts, and
anonymized outcome data at raw and various processing stages are available online at:
10.5281/zenodo.10649386
24 / 28References
1. Leon, A. S. et al. Cardiac Rehabilitation and Secondary Prevention of Coronary Heart
Disease: An American Heart Association Scientific Statement From the Council on Clinical
Cardiology (Subcommittee on Exercise, Cardiac Rehabilitation, and Prevention) and the
Council on Nutrition, Physical Activity, and Metabolism (Subcommittee on Physical
Activity), in Collaboration With the American Association of Cardiovascular and Pulmonary
Rehabilitation. Circulation 111, 369‚Äì376 (2005).
2. Warburton, D. E. R., Nicol, C. W. & Bredin, S. S. D. Health benefits of physical
activity: the evidence. Can. Med. Assoc. J. 174, 801‚Äì809 (2006).
3. Dunton, G. F. Ecological Momentary Assessment in Physical Activity Research.
Exerc. Sport Sci. Rev. 45, 48‚Äì54 (2017).
4. Giles-Corti, B. & Donovan, R. J. The relative influence of individual, social and
physical environment determinants of physical activity. Soc. Sci. Med. 54, 1793‚Äì1812 (2002).
5. Sanches, E. E. et al. Barriers and Facilitators in Rehabilitation in Chronic Diseases and
After Surgery: Is It a Matter of Adherence? Cureus (2021) doi:10.7759/cureus.20173.
6. Piette, J. D. et al. Mobile Health Devices as Tools for Worldwide Cardiovascular Risk
Reduction and Disease Management. Circulation 132, 2012‚Äì2027 (2015).
7. WHO Digital Health and Innovation. Classification of digital interventions, services
and applications in health: A shared language to describe the uses of digital technology for
health. (2023).
8. Nahum-Shani, I. et al. Just-in-Time Adaptive Interventions (JITAIs) in Mobile Health:
Key Components and Design Principles for Ongoing Health Behavior Support. Ann. Behav.
Med. 52, 446‚Äì462 (2018).
9. Ding, X. et al. WalkMore: promoting walking with just-in-time context-aware
prompts. in 2016 IEEE Wireless Health (WH) 1‚Äì8 (IEEE, 2016).
doi:10.1109/WH.2016.7764558.
10. G√∂n√ºl, S., Namlƒ±, T., Co≈üar, A. & Toroslu, ƒ∞. H. A reinforcement learning based
algorithm for personalization of digital, just-in-time, adaptive interventions. Artif. Intell. Med.
115, 102062 (2021).
11. Liao, P., Greenewald, K., Klasnja, P. & Murphy, S. Personalized HeartSteps: A
Reinforcement Learning Algorithm for Optimizing Physical Activity. Proc. ACM Interact.
Mob. Wearable Ubiquitous Technol. 4, 1‚Äì22 (2020).
12. Hekler, E. B. et al. Advancing Models and Theories for Digital Behavior Change
Interventions. Am. J. Prev. Med. 51, 825‚Äì832 (2016).
13. Klasnja, P. et al. Microrandomized trials: An experimental design for developing just-
in-time adaptive interventions. Health Psychol. 34, 1220‚Äì1228 (2015).
14. Streicher, A. & Smeddinck, J. D. Personalized and Adaptive Serious Games. in
Entertainment Computing and Serious Games (eds. D√∂rner, R., G√∂bel, S., Kickmeier-Rust,
M., Masuch, M. & Zweig, K.) vol. 9970 332‚Äì377 (Springer International Publishing, 2016).
15. Sutton, R. S. & Barto, A. G. Reinforcement learning: an introduction. (MIT Press,
2018).
16. Awan, S. E., Bennamoun, M., Sohel, F., Sanfilippo, F. & Dwivedi, G. A
reinforcement learning-based approach for imputing missing data. Neural Comput. Appl. 34,
9701‚Äì9716 (2022).
17. Yom-Tov, E. et al. Encouraging Physical Activity in Patients With Diabetes:
Intervention Using a Reinforcement Learning System. J. Med. Internet Res. 19, e338 (2017).
18. d3center. Intervention Designs. https://d3c.isr.umich.edu/intervention-designs/ (2023).
19. Wang, S., Zhang, C., Kr√∂se, B. & van Hoof, H. Optimizing Adaptive Notifications in
25 / 28Mobile Health Interventions Systems: Reinforcement Learning from a Data-driven Behavioral
Simulator. J. Med. Syst. 45, 102 (2021).
20. Schmidhuber, J. Deep learning in neural networks: An overview. Neural Netw. 61,
85‚Äì117 (2015).
21. Heckman, B. W., Mathew, A. R. & Carpenter, M. J. Treatment burden and treatment
fatigue as barriers to health. Curr. Opin. Psychol. 5, 31‚Äì36 (2015).
22. Floridi, L. & Chiriatti, M. GPT-3: Its Nature, Scope, Limits, and Consequences. Minds
Mach. 30, 681‚Äì694 (2020).
23. Radford, A., Narasimhan, K., Salimans, T. & Sutskever, I. Improving Language
Understanding by Generative Pre-Training. Preprint at (2018).
24. Vaswani, A. et al. Attention Is All You Need. Preprint at
https://doi.org/10.48550/arXiv.1706.03762 (2023).
25. Hadi, M. U. et al. Large Language Models: A Comprehensive Survey of its
Applications, Challenges, Limitations, and Future Prospects. (2023).
doi:10.36227/techrxiv.23589741.
26. Vaswani, A. et al. Attention Is All You Need. ArXiv170603762 Cs (2017).
27. Touvron, H. et al. LLaMA: Open and Efficient Foundation Language Models. (2023).
28. MosaicML NLP Team. Introducing MPT-7B: A New Standard for Open-Source,
Commercially Usable LLMs. www.mosaicml.com/blog/mpt-7b (2023).
29. Tu, T. et al. Towards Generalist Biomedical AI. Preprint at
http://arxiv.org/abs/2307.14334 (2023).
30. Touvron, H. et al. Llama 2: Open Foundation and Fine-Tuned Chat Models. Preprint
at http://arxiv.org/abs/2307.09288 (2023).
31. Lyu, H., Jiang, S., Zeng, H., Xia, Y. & Luo, J. LLM-Rec: Personalized
Recommendation via Prompting Large Language Models. Preprint at
https://doi.org/10.48550/arXiv.2307.15780 (2023).
32. Heyes, C. M. & Frith, C. D. The cultural evolution of mind reading. Science 344,
1243091 (2014).
33. Kosinski, M. Theory of Mind May Have Spontaneously Emerged in Large Language
Models. Preprint at https://doi.org/10.48550/ARXIV.2302.02083 (2023).
34. Fu, I.-N. et al. A systematic review of measures of theory of mind for children. Dev.
Rev. 67, 101061 (2023).
35. OpenAI. GPT-4 Technical Report. Preprint at http://arxiv.org/abs/2303.08774 (2023).
36. Chen, L., Zaharia, M. & Zou, J. How is ChatGPT‚Äôs behavior changing over time?
Preprint at http://arxiv.org/abs/2307.09009 (2023).
37. Pelliccia, A. et al. 2020 ESC Guidelines on sports cardiology and exercise in patients
with cardiovascular disease. Eur. Heart J. 42, 17‚Äì96 (2021).
38. Malone, T. W., Laubacher, R. & Dellarocas, C. N. Harnessing Crowds: Mapping the
Genome of Collective Intelligence. SSRN Electron. J. (2009) doi:10.2139/ssrn.1381502.
39. Quinn, A. J. & Bederson, B. B. Human computation: a survey and taxonomy of a
growing field. in Proceedings of the SIGCHI Conference on Human Factors in Computing
Systems 1403‚Äì1412 (ACM, 2011). doi:10.1145/1978942.1979148.
40. Von Ahn, L. Human computation. in Proceedings of the 4th international conference
on Knowledge capture 5‚Äì6 (ACM, 2007). doi:10.1145/1298406.1298408.
41. Geng, S., Liu, S., Fu, Z., Ge, Y. & Zhang, Y. Recommendation as Language
Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5). Preprint
at http://arxiv.org/abs/2203.13366 (2023).
42. Bhimavarapu, U., Sreedevi, M., Chintalapudi, N. & Battineni, G. Physical Activity
Recommendation System Based on Deep Learning to Prevent Respiratory Diseases.
26 / 28Computers 11, 150 (2022).
43. Shin, D., Hsieh, G. & Kim, Y.-H. PlanFitting: Tailoring Personalized Exercise Plans
with Large Language Models. Preprint at http://arxiv.org/abs/2309.12555 (2023).
44. Kung, T. H. et al. Performance of ChatGPT on USMLE: Potential for AI-assisted
medical education using large language models. PLOS Digit. Health 2, e0000198 (2023).
45. Nori, H., King, N., McKinney, S. M., Carignan, D. & Horvitz, E. Capabilities of GPT-
4 on Medical Challenge Problems. Preprint at https://doi.org/10.48550/arXiv.2303.13375
(2023).
46. Singhal, K. et al. Large Language Models Encode Clinical Knowledge. Preprint at
http://arxiv.org/abs/2212.13138 (2022).
47. Lee, P., Bubeck, S. & Petro, J. Benefits, Limits, and Risks of GPT-4 as an AI Chatbot
for Medicine. N. Engl. J. Med. 388, 1233‚Äì1239 (2023).
48. Singhal, K. et al. Towards Expert-Level Medical Question Answering with Large
Language Models. Preprint at http://arxiv.org/abs/2305.09617 (2023).
49. McDuff, D. et al. Towards Accurate Differential Diagnosis with Large Language
Models. Preprint at https://doi.org/10.48550/arXiv.2312.00164 (2023).
50. Liu, Q. et al. Exploring the Boundaries of GPT-4 in Radiology. in (2023).
51. Wang, X. et al. ChatGPT: promise and challenges for deployment in low- and middle-
income countries. Lancet Reg. Health ‚Äì West. Pac. 41, (2023).
52. Rajpurkar, P., Chen, E., Banerjee, O. & Topol, E. J. AI in health and medicine. Nat.
Med. 28, 31‚Äì38 (2022).
53. Cohen, I. G., Evgeniou, T., Gerke, S. & Minssen, T. The European artificial
intelligence strategy: implications and challenges for digital health. Lancet Digit. Health 2,
e376‚Äìe379 (2020).
54. Schrills, T. & Franke, T. How Do Users Experience Traceability of AI Systems?
Examining Subjective Information Processing Awareness in Automated Insulin Delivery
(AID) Systems. ACM Trans Interact Intell Syst (2023) doi:10.1145/3588594.
55. European Patients Forum. Artificial Intelligence in Health Care: Advancing Patient-
Centric Care through Co-design and Responsible Implementation. https://www.eu-
patient.eu/globalassets/policy/artificial-intelligence-applications-in-healthcare-epf.pdf (2023).
56. Perez, C. E. Large language models (LLMs) and knowledge graphs (KGs) are
complementary technologies that balance each other‚Äôs strengths and weaknesses when
combined: - LLMs have a strong capability for understanding and generating natural language,
but can sometimes hallucinate facts. -‚Ä¶. @IntuitMachine
https://twitter.com/IntuitMachine/status/1721275064803336483 (2023).
57. Jacob, R. J. K. et al. Reality-based interaction: a framework for post-WIMP interfaces.
in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems 201‚Äì210
(ACM, 2008). doi:10.1145/1357054.1357089.
58. Huang, W., Abbeel, P., Pathak, D. & Mordatch, I. Language Models as Zero-Shot
Planners: Extracting Actionable Knowledge for Embodied Agents.
59. Pan, J. Z. et al. Large Language Models and Knowledge Graphs: Opportunities and
Challenges. Preprint at http://arxiv.org/abs/2308.06374 (2023).
60. Yang, L., Chen, H., Li, Z., Ding, X. & Wu, X. ChatGPT is not Enough: Enhancing
Large Language Models with Knowledge Graphs for Fact-aware Language Modeling.
Preprint at http://arxiv.org/abs/2306.11489 (2023).
61. Yasunaga, M., Ren, H., Bosselut, A., Liang, P. & Leskovec, J. QA-GNN: Reasoning
with Language Models and Knowledge Graphs for Question Answering. Preprint at
http://arxiv.org/abs/2104.06378 (2022).
62. Zhang, B. & Soh, H. Large Language Models as Zero-Shot Human Models for
27 / 28Human-Robot Interaction. Preprint at http://arxiv.org/abs/2303.03548 (2023).
63. Javaheripi, M. & Bubeck, S. Phi-2: The surprising power of small language models.
Microsoft Research Blog https://www.microsoft.com/en-us/research/blog/phi-2-the-
surprising-power-of-small-language-models/ (2023).
64. Nori, H. et al. Can Generalist Foundation Models Outcompete Special-Purpose
Tuning? Case Study in Medicine. Preprint at http://arxiv.org/abs/2311.16452 (2023).
65. Jiang, A. Q. et al. Mistral 7B. Preprint at https://doi.org/10.48550/arXiv.2310.06825
(2023).
66. Ouyang, L. et al. Training language models to follow instructions with human
feedback. Adv. Neural Inf. Process. Syst. 35, 27730‚Äì27744 (2022).
67. Gyrard, A., Gaur, M., Shekarpour, S., Thirunarayan, K. & Sheth, A. Personalized
Health Knowledge Graph. (2021).
68. Smith, R., Fries, J. A., Hancock, B. & Bach, S. H. Language Models in the Loop:
Incorporating Prompting into Weak Supervision. Preprint at
https://doi.org/10.48550/arXiv.2205.02318 (2022).
69. Golbus, J. R., Dempsey, W., Jackson, E. A., Nallamothu, B. K. & Klasnja, P.
Microrandomized Trial Design for Evaluating Just-in-Time Adaptive Interventions Through
Mobile Health Technologies for Cardiovascular Disease. Circ. Cardiovasc. Qual. Outcomes
14, e006760 (2021).
70. Hardeman, W., Houghton, J., Lane, K., Jones, A. & Naughton, F. A systematic review
of just-in-time adaptive interventions (JITAIs) to promote physical activity. Int. J. Behav.
Nutr. Phys. Act. 16, 31 (2019).
71. Haag, D., Carrozzo, E., Pannicke, B., Niebauer, J. & Blechert, J. Within-person
association of volitional factors and physical activity: Insights from an ecological momentary
assessment study. Psychol. Sport Exerc. 68, 102445 (2023).
72. Wurhofer, D. aktivplan - rehabilitation activity planning and reporting tool. LBI for
Digital Health and Prevention https://dhp.lbg.ac.at/app-development-aktivplan/?lang=en
(2021).
73. Ekman, P. Are there basic emotions? Psychol. Rev. 99, 550‚Äì553 (1992).
74. Naveed, H. et al. A Comprehensive Overview of Large Language Models. Preprint at
http://arxiv.org/abs/2307.06435 (2023).
28 / 28