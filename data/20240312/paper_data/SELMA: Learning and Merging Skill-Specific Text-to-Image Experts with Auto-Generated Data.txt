SELMA: Learning and Merging Skill-Specific
Text-to-Image Experts with Auto-Generated Data
JialuLi‚àó JaeminCho‚àó Yi-LinSung JaehongYoon MohitBansal
UNCChapelHill
{jialuli, jmincho, ylsung, jhyoon, mbansal}@cs.unc.edu
https://selma-t2i.github.io
Abstract
Recenttext-to-image(T2I)generationmodelshavedemonstratedimpressivecapa-
bilitiesincreatingimagesfromtextdescriptions. However,theseT2Igeneration
modelsoftenfallshortofgeneratingimagesthatpreciselymatchthedetailsof
thetextinputs, suchasincorrectspatialrelationshipormissingobjects. Inthis
paper,weintroduceSELMA:Skill-SpecificExpertLearningandMergingwith
Auto-GeneratedData,anovelparadigmtoimprovethefaithfulnessofT2Imodels
byfine-tuningmodelsonautomaticallygenerated,multi-skillimage-textdatasets,
withskill-specificexpertlearningandmerging. First,SELMAleveragesanLLM‚Äôs
in-contextlearningcapabilitytogeneratemultipledatasetsoftextpromptsthatcan
teachdifferentskills,andthengeneratestheimageswithaT2Imodelbasedonthe
prompts. Next,SELMAadaptstheT2Imodeltothenewskillsbylearningmulti-
plesingle-skillLoRA(low-rankadaptation)expertsfollowedbyexpertmerging.
Ourindependentexpertfine-tuningspecializesmultiplemodelsfordifferentskills,
and expert merging helps build a joint multi-skill T2I model that can generate
faithfulimagesgivendiversetextprompts,whilemitigatingtheknowledgeconflict
fromdifferentdatasets. Weempiricallydemonstratethat SELMA significantly
improvesthesemanticalignmentandtextfaithfulnessofstate-of-the-artT2Idif-
fusion models on multiple benchmarks (+2.1% on TIFA and +6.9% on DSG),
humanpreferencemetrics(PickScore,ImageReward,andHPS),aswellashuman
evaluation.Moreover,fine-tuningwithimage-textpairsauto-collectedviaSELMA
showscomparableperformancetofine-tuningwithgroundtruthdata. Lastly,we
showthatfine-tuningwithimagesfromaweakerT2Imodelcanhelpimprovethe
generationqualityofastrongerT2Imodel,suggestingpromisingweak-to-strong
generalizationinT2Imodels.
1 Introduction
Text-to-Image (T2I) generation models have shown impressive development in recent years [58;
56;47;27;54;81;8]. Althoughtheseapproachescangeneratehigh-quality,diverseimageswith
the unseen composition of objects (e.g., Eiffel Tower under water) based on textual inputs, they
still struggle to capture and reflect all semantics in the given textual prompts. In particular, the
state-of-the-artT2Imodelsareknowntooftenfailtogeneratemultiplesubjects[81;20;38],spatial
relationshipsbetweenentities[45],andtextrendering[39;71](e.g.,anartboardwith‚ÄúSELMA‚Äù
writtenonit)intheprompts.
Manyrecentworkshavebeenproposedtotacklethesechallengesintext-to-imagegeneration,aiming
toenhancethefaithfulnessofT2Imodelstotextualinputs.Onelineofresearchfocusesonsupervised
‚àóequalcontribution
4202
raM
11
]VC.sc[
1v25960.3042:viXra1. Auto-Generate Image-Text Pairs Teaching Different Skills
‚ÄúA very sunny day at the state
park for a motorcycle ride.‚Äù
Image-Text Skill 1 Skill 2 ‚Ä¶ Skill N common objects
Datasets ‚ÄúA playful puppy chases its
Text-to-Image Model toy in a backyard.‚Äù
Large Language Model
long text prompts
Text-to-Image Model ‚ÄúAn elegant room with floor-
to-ceiling bookshelves, filled
with an impressive collection
of books of all genres. The
cozy reading nook by the
‚Ä¶ window invites anyone to curl
(a) SupervisedFine-tuning (SFT) up with a good book.‚Äù
Auto-Generated Image-Text Pairs
‚ÄúAn adorable critter‚Äù commonsense-defying
Human Preference ‚ÄúA cat with wings flying over
a field of donuts.‚Äù
Text-to-Image Model
2. Learn Skill-Specific Experts 3. Merge Skill-Specific Experts
‚Ä¶
Scoring / Ranking Skill 1 FT T2I Model T2I Model T2I Model T2I Model
Merge
Skill 2 FT T2I Model
Generate
Feedback ‚Ä¶ T2I Model
(b) Fine-tuning with Human Preference (c) SELMA: Skill-Specific Expert Learning & Merging with Auto-Generated Data
Figure1: Comparisonofdifferentfine-tuningparadigmsfortext-to-image(T2I)generationmodels.
(a)SupervisedFine-tuning(SFT):aT2Imodelistrainedwithimage-textpairsfromexistingdatasets.
(b)Fine-tuningwithHumanPreference(e.g.,RL/DPO):humansannotatetheirpreferenceson
imagesbyranking/scoringintermsoftextalignments,andaT2Imodelistrainedtomaximizethe
humanpreferencescores. (c)SELMA:insteadofcollectingimage-textpairsorhumanpreference
annotations,weautomaticallycollectimage-textpairsfordesiredskillswithLLMandT2Imodel,
andcreateamulti-skillT2Imodelbylearningandmergingskill-specificexpertmodels.
fine-tuningonhigh-qualityimage-textdatasetswithhumanannotations[16]orimage-textpairswith
re-captionedtextprompts[61;3],asshowninFig.1(a). Anotherlineofresearchisbasedonaligning
T2Imodelswithhumanpreferenceannotations[78;49;19;31;73],asshowninFig.1(b). Other
worksfocusonintroducingadditionallayoutsorobjectgroundingboxestoguidethegeneration
process[35;77;80;20;14;85]. Despiteachievingsignificantimprovementsinaligninggenerated
imageswithinputtextualprompts,thesuccessoftheseapproachesreliesonthequalityofthelayouts
createdfromthetextualprompts,thecollectionofhigh-qualityannotationswithhumanefforts,or
theexistenceoflarge-scalegroundtruthdata,whichinvolvesexpensivehumanannotation.
Motivated by LLMs‚Äô impressive text generation capability (given open-ended task instructions
andin-contextexamples),andrecentT2Imodels‚Äôcapabilityingeneratinghighlyrealisticphotos
(basedontextprompts),weinvestigateaninterestingquestiontofurtherimprovethefaithfulness
ofstate-of-the-artT2Imodels: ‚ÄúCanweautomaticallygeneratemulti-skillimage-textdatasetswith
LLMsandT2Imodels, toeffectivelyandefficientlyteachdifferentimagegenerationskillstoT2I
models?‚Äù Inthispaper,wepropose SELMA:Skill-SpecificExpertLearningandMergingwith
Auto-GeneratedData,anovelparadigmforelicitingthepre-trainedknowledgeinT2Imodelsfor
improvedfaithfulnessbasedonskill-specificlearningandmergingofexperts. SELMAconsistsof
fourstages:(1)collectingskill-specificpromptswithin-contextlearningofLLMs,(2)self-generating
image-textsamplesfordiverseskillswithouttheneedofhumanannotationnorfeedbackfromreward
models,(3)fine-tuningtheexpertT2Imodelsonthesedatasetsseparately,and(4)obtainingthefinal
modelbymergingexpertsofeachdatasetforefficientadaptationtodifferentskillsandmitigationof
knowledgeconflictinjointtraining. WeillustratetheSELMApipelineinFig.1(c).
Inthefirstandsecondstages,weusetheLLMandtheT2Imodeltogenerateskill-specificimage-
textdata(whichwillbeusedforfine-tuningT2Imodelsinlaterstages). Weaimtoteachdiverse
generationskillstothesameT2Imodel(i.e.,self-learning),sothattheycanhandledifferenttypesof
prompts. Forexample,somepromptsrequireobjectcountingcapabilityofT2Imodels(e.g.,‚ÄúTwo
leavesandtwowallets‚Äù),whileotherpromptsspecifyalistofdesiredattributesinthegeneratedimage
(e.g.,‚Äúhighpriestesstarotcard,blackbackground,moontheme,witchery,greatdetail,sketchartwith
intricatebackground,dynamicpose,closeup‚Äù). Togenerateimage-textpairsfordifferentskills,we
firstqueryGPT-3.5[43]forpromptgenerationbyusingonlythreeskill-specificpromptsasin-context
2examples,andfilterthegeneratedpromptswithROUGE-Lscoretomaximizepromptdiversityto
collect1Kpromptsintotal(Sec.3.1). ThenweuseStableDiffusionmodels[56;47]themselvesto
generatecorrespondingimagesfromtheprompts(Sec.3.2). Wefindthatourskill-specifictraining
canhelpmitigateknowledgeconflictwhenjointlylearningmultipleskills(seeTable2).
Inthethirdandfourthstages,wefine-tuneaT2Imodelwiththecollectedimage-textpairstoteach
differentskills. However,updatingtheentiremodelweightscanbeinefficient;knowledgeconflicts
withinmixeddatasetsmayalsoleadtosuboptimalperformance[40]. Thus,inthethirdstage,wefine-
tuneT2Imodelsontheseself-generatedimage-textpairswithparameter-efficientLoRA(low-rank
adaptation)modules[24]tocreateskill-specificexpertT2Imodels(Sec.3.3). Inthefourthstage,to
buildajointmulti-skillT2Imodelthatcanhavefaithfulgenerationsacrossdifferentskills,wemerge
theskill-specificexpertsbasedonLoRAmerging[62;86](Sec.3.4). Wefindthatourinference-time
mergingofskill-specificLoRAexpertsiseffectiveinmitigatingskillconflictsthantrainingamixture
ofLoRAexpertmodel[76]whilealsobeingmoreefficient(seeTable4).
WevalidatetheusefulnessofSELMAwithpublicstate-of-the-artT2Imodels‚ÄìafamilyofStable
Diffusion‚Äìv1.4[56],v2[56],andXL[47]ontwotextfaithfulnessevaluationbenchmarks(DSG[12]
andTIFA[25]),threehumanpreferencemetrics(Pick-a-Pic[29],ImageReward[78],andHPS[75]),
and human evaluation. Empirical results demonstrate that SELMA significantly improves T2I
models‚Äôfaithfulnesstoinputtextpromptsandachieveshigherhumanpreferencemetrics. Ourfinal
LoRA-Mergingmodelachieves6.9%improvementsonDSG,2.1%improvementsonTIFA,and
improves the human preference metrics by 0.4 on Pick-a-Pic, 0.39 on ImageReward, and 3.7 on
HPS.Furthermore,weempiricallyshowthattheT2Imodelslearnedfromtheself-generatedimages
achieveaperformancesimilartothatoflearningfromground-truthimages(seeFig.3). Lastly,we
furthershowthatfine-tuningwithimagesfromaweakerT2Imodel(i.e.,SDv2)canhelpimprovethe
faithfulnessofastrongerT2Imodel(i.e.,SDXL),suggestingpromisingweak-to-stronggeneralization
intext-to-imagemodels(seeTable3).
2 RelatedWork
TrainingVision-LanguageModelswithSyntheticImages. Asrecentdenoisingdiffusionmod-
els[65;22]haveachievedphotorealisticimagesynthesiscapabilities,manyworkshavestudiedusing
their synthetic images for training different models. Azizi et al. [2], Sariyildiz et al. [60], Lei et
al. [32], inter alia, study training image classification models with synthetic images. For image
captioning,Caffagnietal.[7]usediffusionmodelstogenerateimagesonthecaptioningdata. For
trainingCLIP[50]models, severalworksusediffusionmodelstogenerateimagesfromexisting
captions[70]ortextgeneratedwithlanguagemodels[21]. Thereisarecentresearchdirectionusing
syntheticimagestotrainimagegenerationmodelsthemselves,andwediscussmoredetailsinthe
followingparagraph.
TrainingText-to-ImageGenerationModelswithSyntheticImages. Alineofrecentworkstrain
text-to-image(T2I)generationmodelswithsyntheticimagesgeneratedbythesameorothermodels
annotatedwithhumanpreferencescoresusingreinforcementlearning[31;78;75;18;15;19]ordirect
preferenceoptimization(DPO)[52;73]. Whiletheseworksshowpromisingresultsinimproving
model behavior with human preferences, they require expensive human preference annotations.
SPIN-Diffusion[83]proposesusingself-play[59;69],whichwassuccessfullyadoptedinAlphago
Zero [63] and language models [11; 84], where the model itself becomes a judge and iteratively
comparesitselfwithpreviousiterations. However,self-playalgorithmstillreliesonasetofground
truthimage-textpairsaspositiveexamplesforsupervision. Concurrent/independenttoourwork,
DreamSync[66]trainsaT2ImodelbyfirstcreatingtextpromptswithLLMs,samplingmultiple
imagesbytheT2Imodelitself,filteringoutimageswithoff-the-shelfscorers,andfine-tuningthe
modelontheresultingsyntheticimage-textpairs[66]. UnlikeDreamSyncthatdependsonimage
filtering(generating8imagesandtakingatmostoneofthemforeachtextprompt,SELMAgenerates
1imageforeachprompt,significantlyimprovingdatagenerationefficiencybyusingonly2%of
image-textpairscomparedwithDreamSync. Furthermore,wefocusonlearningmultipleskillswith
T2Imodelsbylearningandmergingskill-specificLoRAexpertstomitigateknowledgeinterference
acrossdifferentskills,andweshowthisapproachattainsmuchstrongerperformancewithoutadding
anyadditionalinferencecost(seeTable2).
3Skill Descrip7on Generated Prompts Skill 1 Skill 2 Skill N LoRA 1
+ Examples
Prompts Prompts Prompts LoRA 2
‚Ä¶ Merge LoRA
LLM Text-to-Image Images Images Images LoRA N
Model ‚Ä¶
Text Diversity Filter
T2I Model T2I Model T2I Model Final T2I Model
Mul7-skill
Generated Prompts Generated Images LoRA 1üî• LoRA 2üî• LoRA Nüî• Model LoRA
(a) Prompt Genera.on (b) Image Genera.on (c) Skill-Specific Expert Learning (d) Merging Expert Models
Figure2: Illustrationofthefour-stagepipelineofSELMA.(a)PromptGeneration: Givenashort
skilldescriptionandafew(i.e.,three)seedexamplesaboutaspecificskill,wegeneratepromptsto
teachtheskillwithanLLM,whilemaintainingpromptdiversityviatext-similaritybasedfiltering.
(b)ImageGeneration: GiventheLLM-generatedtextprompts,wegeneratetrainingimageswitha
T2Imodel. (c)Skill-SpecificExpertLearning: Welearnskill-specificexpertT2Imodelsbasedon
LoRAfine-tuning. (d)MergingExpertModels: Weobtainamulti-skillT2Imodelbymergingthe
skill-specificLoRAparameters.
3 SELMA:LearningandMergingText-to-ImageSkill-SpecificExpertswith
Auto-GeneratedData
WeintroduceSELMA,anovelframeworktoteachdifferentskillstoaT2Igenerationmodelbased
onauto-generateddataandmodelmerging. AsillustratedinFig.2,SELMAconsistsoffourstages:
(1) skill-specific prompt generation with LLM (Sec. 3.1), (2) image generation with T2I Model
(Sec.3.2),(3)skill-specificexpertlearning(Sec.3.3),and(4)mergingexpertmodels(Sec.3.4).
3.1 AutomaticSkill-SpecificPromptGenerationwithLLM
As shown in Fig. 2 (a), we automatically collect skill-specific prompts (that will be paired with
imagesinSec.3.2)tofine-tuneT2Imodelsintwosteps: (1)usinglargelanguagemodels(LLMs)
togeneratepromptswithbriefskilldescriptionsandafewexamplepromptsand(2)filteringthe
generatedpromptstoensuretheirdiversity. Inthefollowing,weexplainthetwostepsindetail.
PromptGeneration. Weleveragethein-contextlearningabilityofLLMstogenerateadditionaltext
promptsthatfollowsimilarwritingstyles(e.g.,paragraphstyle)oracquiremodels‚Äôknowledgeinthe
samedomain(e.g.,countcapability). Wemanuallycollectthreeseedpromptswithsimilarwriting
stylesoracquiresimilarskills(e.g.,spatialreasoning)tothetargettextprompts. Next,weusethese
seedpromptsasin-contextlearningexamplestoqueryGPT-3.5(GPT3.5-turbo-instruct)[43].
Weprovideadditionalinstructionsthatencouragediversityingeneratedprompts,includingobject
occurrences,sentencepatterns,andrequiredskillsfortheT2Imodeltogenerateaccurateprompts.
ThedetailedprompttemplatecanbefoundintheAppendix. Duringpromptgeneration,wekeep
expandingtheseedpromptswiththegeneratedprompts,andalwaysrandomlysamplethreeprompts
asin-contextlearningexamplesfromtheseedprompts.
PromptFiltering. Toimprovethediversityofthecollectedtextprompts,wefilteroutpromptsthat
aresimilartoalreadygeneratedones. AsTaorietal.[68]demonstratethatinstructiondiversityis
crucialforimprovingtheinstructionfollowingcapabilityoflargelanguagemodels,wefollowthe
sameintuitiontocreatediversetextprompts. Toensurethediversityofgeneratedprompts,wefirst
receiveanewlygeneratedtextpromptfromthepreviousstep. Then,wecalculateitshighestROUGE-
L[36]scorewithallthepreviouslygeneratedandfilteredprompts. FollowingTaorietal.[68],we
discardtextpromptswithROUGE-L>0.8tomaximizethediversityofgeneratedprompts.
3.2 AutomaticImageGenerationwithText-to-ImageModels
AsillustratedinFig.2(b),wegeneratecorrespondingimagesforeachgeneratedtextpromptusing
theT2Imodel. Wefindthatexistingdiffusion-basedT2Imodelsarehighlyeffectiveinlearning
fromtheirself-generatedimages,andevenbenefitfromlearningfromimagesgeneratedwithweaker
T2Imodels(Table3). ItisimportanttoleveragetheknowledgethatalreadyexistsinsidetheT2I
models(learnedfromwebdataduringpre-training),andhenceweaimtoextractthisknowledgefor
4creatingtheskill-specificimage-textpairs,whichinturnwillbeusedtofine-tunetheT2Imodelsfor
improvingfaithfulness(Sec.3.3).
3.3 Fine-tuningwithMultipleSkill-SpecificLoRAExperts
Afterconstructingtheself-trainingtext-imagepairsfordifferentskillsfromprevioussteps,SELMA
fine-tunes the T2I model on them to equip the model with these skills. We adopt Low-Rank
Adaptation(LoRA)[24]toefficientlyadaptthemodeltodifferentskillsbylearningskill-specific
LoRAexperts,whichenablestheT2Imodeltolearnwithouthavingconflictswiththedatainother
skills[9]. LoRAalsogreatlyreducesthefine-tuningcostwhenlearningalargenumberofexperts.
TheLoRAfine-tuningoptimizestherank-decompositionmatricesofdenselayersinT2Imodels,
making it more parameter-efficient compared to updating entire parameters of large T2I models.
Specifically,theupdatestotheweightsW ‚ààRd√ódinthepre-trainedT2Imodelscanberepresented
0
as: W +‚àÜW =W +BA,whereB ‚ààRd√ór andA‚ààRr√ódarelowrankdecompositionmatrics.
0 0
Inpractice,rankrisselectedtobemuchsmaller(thuslow-rank)thanthehiddendimensiondfor
efficientfine-tuning.
Fine-tuning T2I models on collected self-training data with skill-specific LoRA modules boosts
T2Imodels‚Äôalignmentonthespecifictextstyleordesiredskillsneededforfaithfulnessgeneration.
Concretely,foreachnewdatasett‚ààT,wefine-tunetheT2ImodelwithLoRAindependentlyand
thisintroduces|T|skill-specificLoRAmodulesafterfine-tuningonalldatasets(asshowninFig.2
(c)). InSec.5.2,weobservethatlearningandmergingskill-specificexpertsismoreeffectivethan
learningasingleLoRAacrossalldatasets,byhelpingtheT2Imodelmitigateknowledgeconflicts
betweendifferentskills[40].
However,usingmultipleskill-specificexpertsrequiresthemodeltoknowwhichexperttousefora
giveninput,andthisusuallyrequiresuserannotationsontheskillcategoryofinputs. Anoptionisto
learnaroutertodeterminewhichexperttouseinthetesttime[76;9],buttrainingrouterisinefficient
asitrequirestheroutertobetrainedonalldatasetssimultaneouslyoritmaysufferfromserious
catastrophicforgetting[28]. Inthenextsection,weproposetoutilizemodelmergingtoefficiently
constructasinglefinalmulti-skillmodel.
3.4 MergingLoRAExpertModelstoObtainaMulti-SkillModel
Recentworkofmodelmerging[26;64;1;67;79]proposesmethodsthatmergemultipletask-specific
weightsintoone,whilemostlyretainingtheoriginaltask-specificperformances. Moreover,model
mergingcanhelpmitigatetheknowledgeconflictsbetweendatasetsbecauseweonlyneedtoadjust
themergingratioswithoutre-trainingthetask-specificmodels[82;53]. Duetothesebenefits,we
thenextendmodelmergingtolearnafinalT2Imodelthatcanhandlemultipleskillswithoutmuch
knowledgeconflicts. Concretely,given|T|LoRAexpertslearnedfromSec.3.3,wemergeallLoRA
expertsintooneLoRAexpert(Am = 1 (cid:80) AtandBm = 1 (cid:80) Bt)andthissingleexpert
|T| t‚ààT |T| t‚ààT
can handle all skills simultaneously (as shown in Fig. 2 (d)). With this approach, we can reach
superiorperformanceoverstandardmulti-taskLoRAtrainingandevenMoE-LoRA(learningarouter
with LoRA experts), as shown in Tables 2 and 4, and also eliminate the need to know the skill
categoriesbeforehand. NotethatwhileZipLoRA[62]hasdemonstratedtheuseofLoRAmerging
(merging2LoRAmodules)indiffusionmodels,tothebestofourknowledge,wearethefirsttoshow
theeffectivenessofLoRAmergingonmultiplediverseskills(from5datasets)indiffusionmodels.
4 ExperimentalSetup
4.1 EvaluationBenchmarks
Weevaluatemodelsontwoevaluationbenchmarksthatmeasurethealignmentbetweentextprompts
andgeneratedimages: DSG[12]andTIFA[25]. Bothbenchmarksconsistofpromptsfromdifferent
sources,coveringdiversetextpromptstylesandgenerationskills.
DSGconsistsof1060promptsfrom10differentsources(160promptsfromTIFA[25],and100
promptsfromeachofLocalizedNarratives[48],DiffusionDB[74],CountBench[44],Whoops[4],
DrawText[39],Midjourney[72],StanfordParagraph[30],VRD[41],PoseScript[17]). Amongthe
tenDSGpromptsources,wemainlyexperimentwithtextpromptsfromfivepromptsourcesthathave
5(1)ground-truthimage-textpairs(tocomparetheusefulnessofauto-generateddatawithground-truth
data)and(2)measuringdifferentskillsrequiredinT2Igeneration(e.g., followinglongcaptions,
composinginfrequentobjects). Specifically,weuseCOCO[37]forshortpromptswithcommon
objectsindailylife,LocalizedNarratives[48]forparagraph-stylelongcaptions,DiffusionDB[74]
forhuman-writtenpromptsthatspecifymanyattributedetails,CountBench[44]forevaluatingobject
counting,andWhoops[4]forcommonsense-defyingtextprompts.
TIFAconsistsof4,081promptsfromfoursources,includingCOCO[37]forshortpromptswith
commonobjects,PartiPrompts[81]/DrawBench[58]forchallengingimagegenerationskills,and
PaintSkills[13]forcompositionalvisualreasoningskills.
4.2 EvaluationMetrics
WequantitativelyevaluatetheperformanceofT2Igenerationmodelsintextfaithfulnessandhuman
preferencemetrics. SeealsoSec.5.5forhumanevaluation.
Textfaithfulness. ToevaluateT2Imodel‚Äôsfaithfulnessingeneration,weuseVQAaccuracyfrom
TIFAandDSG.Specifically,TIFAandDSGutilizeLLMstogeneratequestionsgivenatextprompt
andutilizetheVQAmodeltocheckwhetheritcananswerthequestionscorrectlygiventhegenerated
image. TheimageisconsideredtohavebetterfaithfulnesstotextpromptsiftheVQAmodelcan
answerthequestionmorecorrectly. ForTIFA,weuseBLIP-2astheVQAmodelfollowingSunet
al. [66], For DSG, we use mPLUG-large [33] as the VQA model, as PaLI [10] is not publicly
accecssible,andHuetal.[25]showsthatmPLUGachieveshigherhumancorrelationthanBLIP-2.
Humanpreferencemetrics. Toevaluatehowthegeneratedimagesalignwithhumanpreference,we
usethePickScore[29],ImageReward[78],andHPS[75].PickScoreandHPSarebasedonCLIP[51]
trainedonthePick-a-Picdataset[29]andHumanPreferenceScoredataset[75]respectively,which
bothhaveannotationsofhumanpreferenceoverimages. ImageRewardisaBLIP[34]basedreward
model fine-tuned on human preference data collected on DiffusionDB. We calculate PickScore,
ImageReward,andHPSonthe1060DSGprompts. WealsoprovidetheevaluationresultsonHPS
promptsintheappendix.
4.3 ImplementationDetails
In the prompt generation stage (Sec. 3.1), we use gpt-3.5-turbo-instruct [43] to generate
text prompts by providing three prompts for each skill as in-context examples. For each of the
five datasets (COCO [37], Localized Narratives [48], DiffusionDB [74], CountBench [44], and
Whoops [4]), we collect 1K prompts starting with three prompts randomly sampled from them,
ensuring the prompts are not included in the DSG test prompts (i.e., 5K prompts in total). We
refer to the resulting auto-generated datasets as Localized NarrativeSELMA, CountBenchSELMA,
DiffusionDBSELMA,WhoopsSELMA,andCOCOSELMA. Werefertotheresultingcombinationof5K
auto-generateddatasetasDSGSELMA-5K.
Intheimagegenerationstage(Sec.3.2),weusethedefaultdenoisingsteps50forallmodels,andthe
Classifier-FreeGuidance(CFG)[23]of7.5. IntheLoRAfine-tuningstage(Sec.3.3),weuse128as
theLoRArank. Wefine-tuneLoRAinmixedprecision(i.e.,FP16)withaconstantlearningrateof
3e-4andabatchsizeof64. Wefine-tuneLoRAmodulesfor5000steps,whichisapproximately313
epochs. Duringinference,weuniformlymergethespecializedLoRAexpertsintoonemulti-skill
expert(Sec.3.4). Weevaluatemodelcheckpointsevery1000stepsandpickthemodelwiththebest
textfaithfulnessonDSGbenchmark. Fine-tuningLoRAforSDv1.4,SDv2,andSDXLtakes6
hours,6hours,and12hoursonasingleNVIDIAL40GPU,respectively. WeuseDiffusers[46]for
ourexperiments.
5 ResultsandAnalysis
WedemonstratetheusefulnessofSELMAwithcomprehensiveexperimentsandanalysis. Wefirst
compareourproposedapproachwithmultipleT2Imethodsthataimtoimprovethealignmentoftext
andimage(Sec.5.1). ThenweshowtheeffectivenessofourproposedLoRAmerginginmitigating
knowledgeconflictacrossdifferentdatasets(Sec.5.2),andtheeffectivenessofauto-generateddata
bycomparingitwithgroundtruthdata(Sec.5.3). Furthermore,weshowpromisingweak-to-strong
6Table1: ComparisonofSELMAanddifferenttext-to-imagealignmentmethodsontextfaithfulness
andhumanpreference(seeSec.5.1fordiscussion). SELMAachievesthebestperformanceinall
fivemetricswhenadaptedondifferentbasemodels(i.e.,SDv1.4,SDv2,andSDXL).Bestscores
foreachmodelareinbold.
TextFaithfulness HumanPreferenceonDSGprompts
BaseModel Methods
DSGmPLUG‚Üë TIFABLIP2‚Üë PickScore‚Üë ImageReward‚Üë HPS‚Üë
Basemodel 67.3 76.6 20.3 -0.22 23.0
(Training-free)
SynGen[55] 66.2 76.8 20.4 -0.24 24.5
StructureDiffusion[20] 67.1 76.5 20.3 -0.14 23.5
SDv1.4[56]
(RL)
DPOK[19] - 76.4 - -0.26 -
DDPO[5] - 76.7 - -0.08 -
(Automaticdatageneration)
DreamSync[66] - 77.6 - -0.05 -
SELMA(Ours) 71.3 79.5 20.5 0.36 25.5
Basemodel 70.3 79.2 20.8 0.17 24.0
SDv2[56]
SELMA(Ours) 77.7 83.2 21.3 0.72 27.5
Basemodel 73.3 83.5 21.6 0.70 26.2
SDXL[47] DreamSync[66] - 85.2 - 0.84 -
SELMA(Ours) 80.2 85.6 22.0 1.09 29.9
generalizationofT2Imodels(Sec.5.4),humanevaluationresults(Sec.5.5),andablationoftraining
methods(Sec.5.6). Lastly,wepresentqualitativeexamples(Sec.5.7).
5.1 ComparisonwithDifferentAlignmentMethodsforText-to-ImageGeneration
WecompareSELMAwithdifferentalignmentmethodsforT2Igeneration,includingtraining-free
methods(SynGen[55],StructureDiffusion[20]),RL-basedmethods(DPOK[19],DDPO[5]),and
DreamSync[66],aconcurrentmethodbasedonautomaticdatageneration. Weexperimentwiththree
diffusion-basedT2Imodels(i.e.,SDv1.4,SDv2,andSDXL).
SELMA outperforms other alignment methods for T2I generation. As shown in Table 1,
SELMAconsistentlyimprovesfaithfulnessandhumanpreferencemetricsforallthreebackbones.
Specifically,onSDv1.4,SELMAimprovesthebaselineby2.9%inTIFA,4.0%inDSG,0.2in
PickScore,0.58inImageReward,and2.5inHPSscore. Furthermore,SELMAachievessignificantly
higherperformancethanotherbaselines,includingtheRL-basedmethods(DPOK/DDPO),which
requireannotatedhumanpreferencedata,andDreamSync,aconcurrent/independentworkbasedona
largerauto-generateddataset(i.e.,28Ktextprompts;SELMAuses5Ktexttrainingpromptsintotal),
andimagefiltering(i.e.,generating8imagesandtakingatmostoneofthemforeachtextprompt;
SELMAonlygenerates1imageforeachprompt). Besides,onSDv2andSDXL,SELMAshows
largerimprovementintextfaithfulness(i.e.,7.4%improvementonDSGforSDv2,and6.9%on
DSGforSDXL),demonstratingtheeffectivenessofSELMA.
5.2 EffectivenessofLearning&MergingSkill-SpecificExperts
We compare (1) separately learning multiple LoRA experts on different auto-generated datasets
followedbymergingand(2)trainingasingleLoRAonamixtureofdatasets. Forthis,weexperi-
mentwithourfiveauto-generatedimage-textpairs: LocalizedNarrativeSELMA,CountBenchSELMA,
DiffusionDBSELMA,WhoopsSELMA,andCOCOSELMA (seeSec.4.3fordetails).
Learning and merging skill-specific LoRA experts is more effective than single LoRA on
multipledatasets. AsshowninTable2,theLoRAmodelstrainedseparatelyoneachofthefive
automaticallygenerateddatasets(No.1. toNo.5.) canimprovetheoverallmetricoverthebaseline
SD v2 ‚Äì 70.3%, while the degree of improvements is different for each metric (e.g., 76.4% for
fine-tuning with Localized NarrativeSELMA, and 73.0% for fine-tuning with DiffusionDBSELMA).
However, training multiple skills simultaneously with a single LoRA (No.6. to No.7.) tends to
degradeperformanceasmoredatasetsareincorporated. ThisindicatesthattheT2Imodelstruggles
with LoRA to accommodate distinct skills and writing styles from different datasets. A similar
7Table2: ComparisonofsingleLoRAandLoRAMergingintextfaithfulnessandhumanpreference
(seeSec.5.2fordiscussion).WeuseSDv2asourbasemodelandtrainmodelswithourautomatically
generatedimage-textpairs.DATASELMA:auto-generatedimage-textpairswherepromptsaregenerated
withLLMswiththreepromptexamplesfromDATAthatarenotincludedinDSGtestprompts(see
Sec.4.3fordetails). LN:LocalizedNarratives;CB:CountBench;DDB:DiffusionDB.Best/2ndbest
scoresarebolded/underlined.
Auto-GeneratedTrainingDataset TextFaithfulness HumanPreferenceonDSG
No. Model LNSELMA CBSELMA DDBSELMA WhoopsSELMA COCOSELMA
(Paragraph) (Count)
(Real (Counter- (Common DSGmPLUG TIFABLIP2 PickScore ImageReward HPS
Users) Factual) Objects)
0. SDv2 70.3 79.2 20.8 0.17 24.0
1. ‚úì 76.4 81.4 20.9 0.56 26.2
2. ‚úì 76.0 81.4 20.8 0.46 25.7
3. ‚úì 73.0 81.2 20.9 0.46 25.8
4. +SingleLoRA ‚úì 73.0 80.7 20.8 0.44 25.3
5. ‚úì 76.0 81.3 20.9 0.47 25.6
6. ‚úì ‚úì ‚úì 75.1 81.5 20.7 0.37 24.8
7. ‚úì ‚úì ‚úì ‚úì ‚úì 74.4 80.2 20.6 0.35 24.9
8. ‚úì ‚úì ‚úì 76.9 82.9 21.2 0.65 27.3
9. +LoRAMerging ‚úì ‚úì ‚úì ‚úì ‚úì 77.7 83.2 21.3 0.72 27.5
GT vs. Auto-Generated Data for Fine-tuning
80.0
77.477.7
77 57 .. 05 75.776.4 75.075.276.0
75.3
74.7
73.9
75.175.676.0 76.8
73.0 73.0 72.4
72.5
71.1
70.0
67.5
65.0 SD v2
SD v2 FT w/ GT Prompts + GT Images
62.5 SD v2 FT w/ GT Prompts + SDv2-Generated Images
SD v2 FT w/ LLM-Generated Prompts + SDv2-Generated Images (Ours)
60.0
Localized CountBenchDiffusionDB Whoops COCO Five Datasets
Narratives (LoRA Merging)
Fine-tuning Datasets
Figure3: DSGaccuracyofSDv2fine-tunedwithdifferentimage-textpairs.
phenomenonhasbeenreportedinLLaVA-MoLE[9],wheretheknowledgeconflictbetweendatasets
can degrade the performance of multi-task training. We find that merging multiple skill-specific
LoRAexperts(No.8. andNo.9.) achievesthebestperformanceinbothtextfaithfulnessandhuman
preference, demonstrating that merging LoRA experts can help mitigate the knowledge conflict
betweenmultipleskills.
5.3 EffectivenessofAuto-GeneratedData
Inthissection,weinvestigatetheeffectivenessofourautomaticallygenerateddatabycomparing
themwithgroundtruthdata. Wefine-tuneSDv2modelusinggroundtruthdatafromLocalized
Narratives,CountBench,DiffusionDB,Whoops,andCOCO,sampling1Kimage-textpairsfrom
eachdatasetandfine-tuningspecializedLoRAexpertsaccordingly.
Fine-tuningwithauto-generateddatacanachievecomparableperformancetofine-tuningwith
groundtruthdata. AsshowninFig.3,weobservethatfine-tuningwitheitherauto-generatedor
groundtruthdataimprovesfrombaselineSDv2performance‚Äì70.3%,whenevaluatedontheDSG
benchmark. Surprisingly,fine-tuningwiththegenerateddataviaSELMAoutperformstheuseof
groundtruthdatainmostcases,leadingtoaDSGaccuracyimprovementof4.0%withLocalized
Narrativestyleprompts,1.0%withCountBenchstyleprompts,1.9%withDiffusionDBstyleprompts,
and0.9%withCOCOstyleprompts. Inshort,ourapproachresultsinanaverageimprovementof
1.2%broughtbyfine-tuningonlyauto-generateddatawithoutanyneedforhuman-collectedground
truthtext-imagepairs,suggestingthatdiffusion-basedtext-to-imagemodelsmaybenefitfromthe
8
)%(
ycaruccA
GSDTable3: Comparisonofdifferentimagegeneratorsforcreatingtrainingimages. Inadditiontousing
thesamemodelbeingtrainedasanimagegenerator,wealsoexperimentwithusingasmallermodel
asanimagegenerator(No. 4.). SDXLisabiggerandstrongermodelthanSDv2. SeeSec.5.4for
discussion.
TextFaithfulness HumanPreferenceonDSG
No. BaseModel TrainingImageGenerator
DSGmPLUG‚Üë TIFABLIP2‚Üë PickScore‚Üë ImageReward‚Üë HPS‚Üë
1. SDv2 - 70.3 79.2 20.8 0.17 24.0
2. SDXL - 73.3 83.5 21.6 0.70 26.2
3. SDv2 SDv2 77.7 83.2 21.3 0.72 27.5
4. SDXL SDv2 81.3 83.8 21.5 0.78 28.8
5. SDXL SDXL 80.2 85.6 22.0 1.09 29.9
Human Evaluation
All 67.9% 32.1%
Localized 79.2% 21.8%
Narratives
DiffusionDB 54.5% 45.5%
CountBench 70.3% 29.7%
COCO 94.6% 5.4%
SDXL+SELMA (Ours)
Whoops SDXL 67.7% 32.3%
0 20 40 60 80 100
Preference [%]
Figure4: HumanEvaluationon200sampledtextpromptsfromDSG,whereweshowthewinvs.
losepercentagesofSDXLandSDXL+SELMA(Ours).
diversityofself-generatedimages. Furthermore,weinvestigatewhethertheimprovementisbrought
bytextpromptorimagequality. WegenerateimageswithSDv2basedon1Kgroundtruthcaptions,
andfine-tunespecializedLoRAexpertsaccordingly. Weobservethatinmostofthecases,using
generatedimagesworksbetterthangroundtruthimages(e.g.,LocalizedNarrative),suggestingT2I
modelscangenerateimageswithcomparablealignmentasgroundtruthimages. Besides,learning
fromourLLM-generatedcaptionsachievescomparableperformancewithlearningfromgroundtruth
captions,suggestingtheeffectivenessofourtextpromptcollectionprocess.
5.4 Weak-to-StrongGeneralization
Inpreviousexperiments,wedemonstratetheinterestingself-improvingcapabilitiesofT2Imodels,
wherethetrainingimagesweregeneratedbythesameT2Imodel. Here,wedelveintothefollowing
research question: ‚ÄúCan a T2I model benefit from learning with images generated by a weaker
model?‚Äù. The problem of weak-to-strong generalization was initially explored in the context of
LLMs[6;57],referredtoassuperalignment,whichinvolvedtrainingGPT-4[42]usingresponses
generatedbyaweakeragent,suchasGPT-2.
WeakerT2ImodelscanhelpstrongerT2Imodels. AsshowninTable3,fine-tuningSDXLwith
generatedimagesfromSDv2(No.4.) remarkablyenhancesperformanceovertheSDXLbaseline
(No.2.)inbothtextfaithfulnessandhumanpreference.Inaddition,thisapproachachievescompetitive
performancecomparedwithfine-tuningSDXLwithSDXL-generatedimages(No.5.),indicatinga
promisingpotentialforweak-to-stronggeneralizationindiffusion-basedT2Igenerationmodels. To
thebestofourknowledge,thisisthefirstworktofindpromisingimprovementsintheweak-to-strong
generalizationfortext-to-imagediffusionmodels.
5.5 HumanEvaluation
Inadditiontoautomaticevaluationusingtextfaithfulnessbenchmarks(DSGandTIFA)andhuman
preferencemetrics(PickScore,ImageReward,andHPS),wefurtherperformahumanevaluationto
9Table4: Comparisonwithdifferentfine-tuningmethodsonSDv2withourauto-generateddata,in
textfaithfulnessandhumanpreference. SeeSec.5.6fordiscussion.
TextFaithfulness HumanPreferenceonDSG
No. Methods
DSGmPLUG‚Üë TIFABLIP2‚Üë PickScore‚Üë ImageReward‚Üë HPS‚Üë
0. SDv2 70.3 79.2 20.8 0.17 24.0
1. +LoRAMerging(SELMA) 77.7 83.2 21.3 0.72 27.5
2. +LoRAMerging+DPO 75.1 81.4 20.8 0.44 26.0
3. +MoE-LoRA 77.2 83.0 21.3 0.68 27.2
(cid:54)(cid:39)(cid:59)(cid:47) (cid:54)(cid:39)(cid:59)(cid:47)(cid:14)(cid:54)(cid:40)(cid:47)(cid:48)(cid:36) (cid:54)(cid:39)(cid:59)(cid:47) (cid:54)(cid:39)(cid:59)(cid:47)(cid:14)(cid:54)(cid:40)(cid:47)(cid:48)(cid:36)
(cid:36)(cid:3)(cid:70)(cid:88)(cid:69)(cid:72)(cid:3)(cid:80)(cid:68)(cid:71)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:71)(cid:72)(cid:81)(cid:76)(cid:80)(cid:17)(cid:3)(cid:36)(cid:3)(cid:70)(cid:88)(cid:69)(cid:72)(cid:3)(cid:90)(cid:76)(cid:87)(cid:75)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:87)(cid:72)(cid:91)(cid:87)(cid:88)(cid:85)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:71)(cid:72)(cid:81)(cid:76)(cid:80)(cid:17) (cid:36)(cid:3)(cid:87)(cid:68)(cid:79)(cid:79)(cid:3)(cid:69)(cid:85)(cid:82)(cid:90)(cid:81)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:90)(cid:75)(cid:76)(cid:87)(cid:72)(cid:3)(cid:70)(cid:68)(cid:78)(cid:72)(cid:3)(cid:76)(cid:86)(cid:3)(cid:86)(cid:76)(cid:87)(cid:87)(cid:76)(cid:81)(cid:74)(cid:3)(cid:82)(cid:81)(cid:3)(cid:68)(cid:3)(cid:87)(cid:68)(cid:69)(cid:79)(cid:72)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:85)(cid:72)(cid:3)(cid:68)(cid:85)(cid:72)(cid:3)(cid:85)(cid:72)(cid:71)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:92)(cid:72)(cid:79)(cid:79)(cid:82)(cid:90)(cid:3)(cid:73)(cid:79)(cid:82)(cid:90)(cid:72)(cid:85)(cid:3)
(cid:83)(cid:72)(cid:87)(cid:68)(cid:79)(cid:86)(cid:3)(cid:68)(cid:85)(cid:82)(cid:88)(cid:81)(cid:71)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:70)(cid:68)(cid:78)(cid:72)(cid:17)(cid:55)(cid:75)(cid:72)(cid:85)(cid:72)(cid:3)(cid:76)(cid:86)(cid:3)(cid:68)(cid:3)(cid:90)(cid:75)(cid:76)(cid:87)(cid:72)(cid:3)(cid:83)(cid:79)(cid:68)(cid:87)(cid:72)(cid:3)(cid:82)(cid:81)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:87)(cid:68)(cid:69)(cid:79)(cid:72)(cid:3)(cid:90)(cid:76)(cid:87)(cid:75)(cid:3)(cid:68)(cid:3)(cid:73)(cid:82)(cid:85)(cid:78)(cid:3)(cid:82)(cid:81)(cid:3)(cid:87)(cid:82)(cid:83)(cid:3)(cid:82)(cid:73)(cid:3)(cid:76)(cid:87)(cid:17)
(cid:36)(cid:3)(cid:87)(cid:85)(cid:68)(cid:76)(cid:81)(cid:3)(cid:76)(cid:86)(cid:3)(cid:82)(cid:83)(cid:72)(cid:81)(cid:76)(cid:81)(cid:74)(cid:3)(cid:76)(cid:87)(cid:86)(cid:3)(cid:71)(cid:82)(cid:82)(cid:85)(cid:86)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:87)(cid:85)(cid:68)(cid:76)(cid:81)(cid:3)(cid:76)(cid:86)(cid:3)(cid:70)(cid:88)(cid:85)(cid:85)(cid:72)(cid:81)(cid:87)(cid:79)(cid:92)(cid:3)(cid:83)(cid:68)(cid:85)(cid:78)(cid:72)(cid:71)(cid:3)(cid:68)(cid:87)(cid:3)(cid:68)(cid:3)(cid:87)(cid:85)(cid:68)(cid:76)(cid:81)(cid:3)(cid:86)(cid:87)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:17)(cid:3)
(cid:36)(cid:81)(cid:3)(cid:82)(cid:79)(cid:71)(cid:3)(cid:80)(cid:68)(cid:81)(cid:3)(cid:79)(cid:76)(cid:73)(cid:87)(cid:86)(cid:3)(cid:68)(cid:3)(cid:69)(cid:68)(cid:85)(cid:69)(cid:72)(cid:79)(cid:79)(cid:3)(cid:68)(cid:69)(cid:82)(cid:89)(cid:72)(cid:3)(cid:75)(cid:76)(cid:86)(cid:3)(cid:75)(cid:72)(cid:68)(cid:71)(cid:17)
(cid:55)(cid:75)(cid:72)(cid:3)(cid:87)(cid:85)(cid:68)(cid:76)(cid:81)(cid:3)(cid:76)(cid:86)(cid:3)(cid:69)(cid:79)(cid:88)(cid:72)(cid:15)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:71)(cid:82)(cid:82)(cid:85)(cid:86)(cid:3)(cid:68)(cid:85)(cid:72)(cid:3)(cid:85)(cid:72)(cid:71)(cid:15)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:76)(cid:87)(cid:3)(cid:75)(cid:68)(cid:86)(cid:3)(cid:90)(cid:75)(cid:76)(cid:87)(cid:72)(cid:3)(cid:86)(cid:87)(cid:85)(cid:76)(cid:83)(cid:72)(cid:86)(cid:3)(cid:82)(cid:81)(cid:3)(cid:76)(cid:87)(cid:17)(cid:55)(cid:75)(cid:72)(cid:85)(cid:72)(cid:3)(cid:76)(cid:86)(cid:3)(cid:68)(cid:3)
(cid:79)(cid:82)(cid:81)(cid:74)(cid:3)(cid:92)(cid:72)(cid:79)(cid:79)(cid:82)(cid:90)(cid:3)(cid:79)(cid:76)(cid:81)(cid:72)(cid:3)(cid:81)(cid:72)(cid:68)(cid:85)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:87)(cid:85)(cid:68)(cid:76)(cid:81)(cid:3)(cid:68)(cid:85)(cid:72)(cid:68)(cid:17)
Figure 5: Example images generated with SDXL and SDXL+SELMA. SELMA shows better
performanceinobjectcomposition,attributebinding,andlongtextpromptfollowing. Wehighlight
thepartsofthepromptsinredwhereSDXLmakeserrorswhileSDXL+SELMAgeneratescorrectly.
comparetheperformanceofSDXLandSDXLfine-tunedwithSELMAonDSGSELMA-5K(details
in Sec. 4.3). We randomly select 200 prompts from DSG and ask three annotators to determine
‚ÄúWhichimagealignswiththecaptionbetter?‚Äù giventhetextpromptandgeneratedimagesfromboth
SDXLandSDXL+SELMA.Weprovidewin/tie/loseoptionstotheannotators,andwereportthe
winvs.losepercentageinthefollowing. Theuserinterface,instructions,andthedetailedstatistics
areprovidedinappendix.
SDXL+SELMAispreferredthanSDXLintermsoftextalignment. Fig.4showsthatonallfive
DSGsplits,imagesgeneratedwithSDXL+SELMAarepreferred67.9%ofthetime,comparedto
32.1%forthebaselineSDXL.Furthermore,onthefivedatasetsfine-tunedwithsimilartextprompts,
SDXL+SELMA achieve a preference rate of 94.6% on COCO split and 79.2% on Localized
Narratives. Thissubstantialpreferenceoverthebaselinemodeldemonstratestheeffectivenessof
SELMAinenhancingT2Imodels.
5.6 TrainingMethodAblations
WeexperimentwithvarioustrainingconfigurationsforSELMAtovalidateourdesignchoicesfor
fine-tuning. Asourcurrentexperimentsarebasedonsupervisedfine-tuningwithLoRAMerging,we
additionallyexploreDirectPreferenceOptimization(DPO)[52;73]asanalternativetosupervised
fine-tuningandemployingMixtureofLoraExperts(MoE-LoRA)[76]insteadofLoRAMerging.
SeetheAppendixfortheimplementationdetails. Table4demonstratesthatwhilefine-tuningwith
DPOandMoE-LoRAsignificantlyimprovestheT2Imodels‚Äôtextfaithfulnessandhumanpreference
(No.2&3. vs.No.0.),simpleinference-timeLoRAmergingachievesthebestoverallperformance. In
10theend,weadoptLoRAmergingandsupervisedfine-tuningasthedefaultconfigurationinSELMA
foritssimplicityandefficiency.
5.7 QualitativeExamples
We show some qualitative examples of images generated with SDXL fine-tuned with SELMA
paradigminFig.5. Wefindthatfine-tuningwithSELMAimprovesSDXL‚Äôscapabilityincomposing
infrequently co-occurred attributes (i.e., ‚Äúcube‚Äù and ‚Äúdenim‚Äù in the top-left image), composing
multipleobjectsmentionedinthetextprompts(i.e.,‚Äúbrownandwhitecake‚Äù,‚Äútable‚Äù,‚Äúredandyellow
flower‚Äù,and‚Äúfork‚Äùinthetop-rightimage),followingdetailsinthelongparagraph-styletextprompts
(i.e.,‚Äúbluetrainwithwhitestripes‚Äùand‚Äúlongyellowlineneartrainarea‚Äùinthebottom-leftimage),
andgeneratingimagesthatchallengecommonsense(i.e.,‚ÄúOldmanliftsabarbell‚Äùinbottom-right
image). These qualitative examples demonstrate the effectiveness of SELMA in improving T2I
models‚Äôtextfaithfulnessandhumanpreference.
6 Conclusion
We propose SELMA, an novel paradigm to improve state-of-the-art T2I models‚Äô faithfulness in
generationandhumanpreferencebyelicitingthepre-trainedknowledgeofT2Imodels. SELMAfirst
collectsself-generatedimagesgivendiversegeneratedtextpromptswithouttheneedforadditional
humanannotation. Then,SELMAfine-tunesseparateLoRAmodelsondifferentdatasetsandmerges
themduringinferencetomitigateknowledgeconflictbetweendatasets. SELMAdemonstratesstrong
empiricalresultsinimprovingT2Imodels‚Äôfaithfulnessandalignmentstohumanpreferenceand
suggestspotentialweak-to-stronggeneralizationfordiffusion-basedT2Imodels.
7 Acknowledgement
WethankEliasStengel-EskinandPrateekYadavforthethoughtfuldiscussion. Thisworkwassup-
portedbyDARPAECOLEProgramNo. HR00112390060,NSF-AIEngageInstituteDRL-2112635,
DARPAMachineCommonsense(MCS)GrantN66001-19-2-4031,AROAwardW911NF2110220,
ONR Grant N00014-23-1-2356, and a Bloomberg Data Science Ph.D. Fellowship. The views
containedinthisarticlearethoseoftheauthorsandnotofthefundingagency.
References
[1] Ainsworth,S.K.,Hayase,J.,Srinivasa,S.S.: Gitre-basin: Mergingmodelsmodulopermutation
symmetries.TheInternationalConferenceonLearningRepresentations(ICLR)(2023),https:
//api.semanticscholar.org/CorpusID:252199400
[2] Azizi,S.,Kornblith,S.,Saharia,C.,Norouzi,M.,Fleet,D.J.: SyntheticDatafromDiffusion
ModelsImprovesImageNetClassification.TMLR(2023), http://arxiv.org/abs/2304.
08466
[3] Betker, J., Goh, G., Jing, L., Brooks, T., Wang, J., Li, L., Ouyang, L., Zhuang, J., Lee, J.,
Guo,Y.,etal.: Improvingimagegenerationwithbettercaptions.ComputerScience.https://cdn.
openai.com/papers/dall-e-3.pdf2(3), 8(2023)
[4] Bitton-Guetta, N., Bitton, Y., Hessel, J., Schmidt, L., Elovici, Y., Stanovsky, G., Schwartz,
R.: Breaking common sense: Whoops! a vision-and-language benchmark of synthetic and
compositionalimages.In: ProceedingsoftheIEEE/CVFInternationalConferenceonComputer
Vision.pp.2616‚Äì2627(2023)
[5] Black, K., Janner, M., Du, Y., Kostrikov, I., Levine, S.: Training diffusion models with
reinforcement learning. The International Conference on Learning Representations (ICLR)
(2024)
[6] Burns,C.,Izmailov,P.,Kirchner,J.H.,Baker,B.,Gao,L.,Aschenbrenner,L.,Chen,Y.,Ecoffet,
A.,Joglekar,M.,Leike,J.,etal.: Weak-to-stronggeneralization: Elicitingstrongcapabilities
withweaksupervision.arXivpreprintarXiv:2312.09390(2023)
11[7] Caffagni, D., Barraco, M., Cornia, M., Baraldi, L., Cucchiara, R.: Synthcap: Augmenting
transformerswithsyntheticdataforimagecaptioning.In:Foresti,G.L.,Fusiello,A.,Hancock,E.
(eds.)ImageAnalysisandProcessing‚ÄìICIAP2023.pp.112‚Äì123.SpringerNatureSwitzerland,
Cham(2023)
[8] Chang,H.,Zhang,H.,Barber,J.,Maschinot,A.,Lezama,J.,Jiang,L.,Yang,M.H.,Murphy,K.,
Freeman,W.T.,Rubinstein,M.,etal.: Muse: Text-to-imagegenerationviamaskedgenerative
transformers.ICML(2023)
[9] Chen,S.,Jie,Z.,Ma,L.:Llava-mole:Sparsemixtureofloraexpertsformitigatingdataconflicts
ininstructionfinetuningmllms.arXivpreprintarXiv:2401.15947(2024)
[10] Chen,X.,Wang,X.,Changpinyo,S.,Piergiovanni,A.,Padlewski,P.,Salz,D.,Goodman,S.,
Grycner,A.,Mustafa,B.,Beyer,L.,etal.: Pali: Ajointly-scaledmultilinguallanguage-image
model.ICLR(2023)
[11] Chen,Z.,Deng,Y.,Yuan,H.,Ji,K.,Gu,Q.: Self-PlayFine-TuningConvertsWeakLanguage
ModelstoStrongLanguageModels(2024),http://arxiv.org/abs/2401.01335
[12] Cho, J., Hu, Y., Garg, R., Anderson, P., Krishna, R., Baldridge, J., Bansal, M., Pont-Tuset,
J., Wang, S.: Davidsonian scene graph: Improving reliability in fine-grained evaluation for
text-imagegeneration.ICLR(2024)
[13] Cho, J., Zala, A., Bansal, M.: Dall-eval: Probing the reasoning skills and social biases of
text-to-imagegenerationmodels.In: ICCV(2023)
[14] Cho,J.,Zala,A.,Bansal,M.: Visualprogrammingfortext-to-imagegenerationandevaluation.
In: NeurIPS(2023)
[15] Clark, K., Vicol, P., Swersky, K., Fleet, D.J.: Directly Fine-Tuning Diffusion Models on
DifferentiableRewards.In: ICLR(2024),http://arxiv.org/abs/2309.17400
[16] Dai,X.,Hou,J.,Ma,C.Y.,Tsai,S.,Wang,J.,Wang,R.,Zhang,P.,Vandenhende,S.,Wang,
X.,Dubey,A.,etal.: Emu: Enhancingimagegenerationmodelsusingphotogenicneedlesina
haystack.arXivpreprintarXiv:2309.15807(2023)
[17] Delmas,G.,Weinzaepfel,P.,Lucas,T.,Moreno-Noguer,F.,Rogez,G.: Posescript: 3dhuman
poses from natural language. In: European Conference on Computer Vision. pp. 346‚Äì362.
Springer(2022)
[18] Dong,H.,Xiong,W.,Goyal,D.,Zhang,Y.,Chow,W.,Pan,R.,Diao,S.,Zhang,J.,Shum,K.,
Zhang,T.: RAFT:RewardrAnkedFineTuningforGenerativeFoundationModelAlignment.
TMLR(2023),http://arxiv.org/abs/2304.06767
[19] Fan,Y.,Watkins,O.,Du,Y.,Liu,H.,Ryu,M.,Boutilier,C.,Abbeel,P.,Ghavamzadeh,M.,Lee,
K.,Lee,K.: Dpok: Reinforcementlearningforfine-tuningtext-to-imagediffusionmodels.In:
NeurIPS(2023)
[20] Feng,W.,He,X.,Fu,T.J.,Jampani,V.,Akula,A.,Narayana,P.,Basu,S.,Wang,X.E.,Wang,
W.Y.: Training-freestructureddiffusionguidanceforcompositionaltext-to-imagesynthesis.
ICLR(2023)
[21] Hammoud,H.A.A.K.,Itani,H.,Pizzati,F.,Torr,P.,Bibi,A.,Ghanem,B.: SynthCLIP:AreWe
ReadyforaFullySyntheticCLIPTraining? (2024),http://arxiv.org/abs/2402.01832
[22] Ho,J.,Jain,A.,Abbeel,P.: DenoisingDiffusionProbabilisticModels.In: NeurIPS.pp.1‚Äì25
(2020),http://arxiv.org/abs/2006.11239
[23] Ho, J., Salimans, T.: Classifier-free diffusion guidance. In: NeurIPS 2021 Workshop on
DeepGenerativeModelsandDownstreamApplications(2021),https://openreview.net/
forum?id=qw8AKxfYbI
[24] Hu, E.J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., Chen, W.: Lora:
Low-rankadaptationoflargelanguagemodels.ICLR(2022)
12[25] Hu,Y.,Liu,B.,Kasai,J.,Wang,Y.,Ostendorf,M.,Krishna,R.,Smith,N.A.: Tifa: Accurate
andinterpretabletext-to-imagefaithfulnessevaluationwithquestionanswering.ICCV(2023)
[26] Ilharco,G.,Ribeiro,M.T.,Wortsman,M.,Gururangan,S.,Schmidt,L.,Hajishirzi,H.,Farhadi,
A.: Editingmodelswithtaskarithmetic.TheInternationalConferenceonLearningRepresenta-
tions(ICLR)(2023),https://api.semanticscholar.org/CorpusID:254408495
[27] Kang,M.,Zhu,J.Y.,Zhang,R.,Park,J.,Shechtman,E.,Paris,S.,Park,T.: Scalingupgansfor
text-to-imagesynthesis.2023IEEE/CVFConferenceonComputerVisionandPatternRecog-
nition(CVPR)pp.10124‚Äì10134(2023),https://api.semanticscholar.org/CorpusID:
257427461
[28] Kirkpatrick,J.,Pascanu,R.,Rabinowitz,N.C.,Veness,J.,Desjardins,G.,Rusu,A.A.,Milan,
K., Quan, J., Ramalho, T., Grabska-Barwinska, A., Hassabis, D., Clopath, C., Kumaran,
D.,Hadsell,R.: Overcomingcatastrophicforgettinginneuralnetworks.Proceedingsofthe
NationalAcademyofSciences114,3521‚Äì3526(2016),https://api.semanticscholar.
org/CorpusID:4704285
[29] Kirstain,Y.,Polyak,A.,Singer,U.,Matiana,S.,Penna,J.,Levy,O.:Pick-a-pic:Anopendataset
ofuserpreferencesfortext-to-imagegeneration.AdvancesinNeuralInformationProcessing
Systems36(2023)
[30] Krause, J., Johnson, J., Krishna, R., Fei-Fei, L.: A hierarchical approach for generating
descriptiveimageparagraphs.In: ProceedingsoftheIEEEconferenceoncomputervisionand
patternrecognition.pp.317‚Äì325(2017)
[31] Lee,K.,Liu,H.,Ryu,M.,Watkins,O.,Du,Y.,Boutilier,C.,Abbeel,P.,Ghavamzadeh,M.,Gu,
S.S.: Aligningtext-to-imagemodelsusinghumanfeedback.arXivpreprintarXiv:2302.12192
(2023)
[32] Lei, S., Chen, H., Zhang, S., Zhao, B., Tao, D.: Image Captions are Natural Prompts for
Text-to-ImageModels(2023),http://arxiv.org/abs/2307.08526
[33] Li,C.,Xu,H.,Tian,J.,Wang,W.,Yan,M.,Bi,B.,Ye,J.,Chen,H.,Xu,G.,Cao,Z.,etal.:
mplug: Effectiveandefficientvision-languagelearningbycross-modalskip-connections.ACL
(2022)
[34] Li, J., Li, D., Xiong, C., Hoi, S.: Blip: Bootstrapping language-image pre-training for uni-
fiedvision-languageunderstandingandgeneration.In: InternationalConferenceonMachine
Learning.pp.12888‚Äì12900.PMLR(2022)
[35] Li,Y.,Liu,H.,Wu,Q.,Mu,F.,Yang,J.,Gao,J.,Li,C.,Lee,Y.J.: Gligen: Open-setgrounded
text-to-imagegeneration.In: ProceedingsoftheIEEE/CVFConferenceonComputerVision
andPatternRecognition.pp.22511‚Äì22521(2023)
[36] Lin,C.Y.: Rouge: Apackageforautomaticevaluationofsummaries.In: Textsummarization
branchesout.pp.74‚Äì81(2004)
[37] Lin,T.Y.,Maire,M.,Belongie,S.,Hays,J.,Perona,P.,Ramanan,D.,Doll√°r,P.,Zitnick,C.L.:
Microsoftcoco: Commonobjectsincontext.In: ComputerVision‚ÄìECCV2014: 13thEuropean
Conference,Zurich,Switzerland,September6-12,2014,Proceedings,PartV13.pp.740‚Äì755.
Springer(2014)
[38] Liu,N.,Li,S.,Du,Y.,Torralba,A.,Tenenbaum,J.B.: Compositionalvisualgenerationwith
composable diffusion models. In: European Conference on Computer Vision. pp. 423‚Äì439.
Springer(2022)
[39] Liu,R.,Garrette,D.,Saharia,C.,Chan,W.,Roberts,A.,Narang,S.,Blok,I.,Mical,R.,Norouzi,
M.,Constant,N.: Character-awaremodelsimprovevisualtextrendering.ACL(2023)
[40] Liu, S., Liang, Y., Gitter, A.: Loss-balanced task weighting to reduce negative transfer in
multi-tasklearning.In: AAAIConferenceonArtificialIntelligence(AAAI)(2019),https:
//api.semanticscholar.org/CorpusID:84836014
13[41] Lu,C.,Krishna,R.,Bernstein,M.,Fei-Fei,L.:Visualrelationshipdetectionwithlanguagepriors.
In: ComputerVision‚ÄìECCV2016: 14thEuropeanConference,Amsterdam,TheNetherlands,
October11‚Äì14,2016,Proceedings,PartI14.pp.852‚Äì869.Springer(2016)
[42] OpenAI:Gpt-4technicalreport(2023),https://api.semanticscholar.org/CorpusID:
257532815
[43] OpenAI:Openaimodels(2023),https://platform.openai.com/docs/models
[44] Paiss,R.,Ephrat,A.,Tov,O.,Zada,S.,Mosseri,I.,Irani,M.,Dekel,T.: Teachingcliptocount
toten.ICCV(2023)
[45] Phung,Q.,Ge,S.,Huang,J.B.: Groundedtext-to-imagesynthesiswithattentionrefocusing.
arXivpreprintarXiv:2306.05427(2023)
[46] von Platen, P., Patil, S., Lozhkov, A., Cuenca, P., Lambert, N., Rasul, K., Davaadorj, M.,
Wolf,T.: Diffusers: State-of-the-artdiffusionmodels.https://github.com/huggingface/
diffusers(2022)
[47] Podell,D.,English,Z.,Lacey,K.,Blattmann,A.,Dockhorn,T.,M√ºller,J.,Penna,J.,Rombach,
R.: Sdxl: Improvinglatentdiffusionmodelsforhigh-resolutionimagesynthesis.ICLR(2024)
[48] Pont-Tuset,J.,Uijlings,J.,Changpinyo,S.,Soricut,R.,Ferrari,V.: Connectingvisionandlan-
guagewithlocalizednarratives.In: ComputerVision‚ÄìECCV2020: 16thEuropeanConference,
Glasgow,UK,August23‚Äì28,2020,Proceedings,PartV16.pp.647‚Äì664.Springer(2020)
[49] Prabhudesai, M., Goyal, A., Pathak, D., Fragkiadaki, K.: Aligning text-to-image diffusion
modelswithrewardbackpropagation.arXivpreprintarXiv:2310.03739(2023)
[50] Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell,
A.,Mishkin,P.,Clark,J.,Krueger,G.,Sutskever,I.,Wook,J.,Chris,K.,Aditya,H.,Gabriel,
R., Sandhini, G., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., Sutskever, I.:
LearningTransferableVisualModelsFromNaturalLanguageSupervision.In: ICML(2021),
http://arxiv.org/abs/2103.00020
[51] Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell,
A.,Mishkin,P.,Clark,J.,etal.: Learningtransferablevisualmodelsfromnaturallanguage
supervision.In: Internationalconferenceonmachinelearning.pp.8748‚Äì8763.PMLR(2021)
[52] Rafailov,R.,Sharma,A.,Mitchell,E.,Ermon,S.,Manning,C.D.,Finn,C.: DirectPreference
Optimization: YourLanguageModelisSecretlyaRewardModel.In: NeurIPS(2023),http:
//arxiv.org/abs/2305.18290
[53] Ram√©, A., Couairon, G., Shukor, M., Dancette, C., Gaya, J.B., Soulier, L., Cord, M.: Re-
warded soups: towards pareto-optimal alignment by interpolating weights fine-tuned on
diverse rewards. Conference on Neural Information Processing Systems (NeurIPS) (2023),
https://api.semanticscholar.org/CorpusID:259096117
[54] Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.:
Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp.
8821‚Äì8831.PMLR(2021)
[55] Rassin,R.,Hirsch,E.,Glickman,D.,Ravfogel,S.,Goldberg,Y.,Chechik,G.:Linguisticbinding
in diffusion models: Enhancing attribute correspondence through attention map alignment.
AdvancesinNeuralInformationProcessingSystems36(2024)
[56] Rombach,R.,Blattmann,A.,Lorenz,D.,Esser,P.,Ommer,B.:High-resolutionimagesynthesis
withlatentdiffusionmodels.In: ProceedingsoftheIEEE/CVFconferenceoncomputervision
andpatternrecognition.pp.10684‚Äì10695(2022)
[57] Saha,S.,Hase,P.,Bansal,M.: Canlanguagemodelsteachweakeragents? teacherexplanations
improvestudentsviapersonalization.In: Advancesinneuralinformationprocessingsystems
(NeurIPS)(2023)
14[58] Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E.L., Ghasemipour, K., Gon-
tijoLopes,R.,KaragolAyan,B.,Salimans,T.,etal.: Photorealistictext-to-imagediffusion
modelswithdeeplanguageunderstanding.AdvancesinNeuralInformationProcessingSystems
35,36479‚Äì36494(2022)
[59] Samuel,A.L.: Somestudiesinmachinelearningusingthegameofcheckers.IBMJournalof
ResearchandDevelopment3(3),210‚Äì229(1959).https://doi.org/10.1147/rd.33.0210
[60] Sariyildiz, M.B., Alahari, K., Larlus, D., Kalantidis, Y.: Fake it Till You Make it: Learn-
ing Transferable Representations from Synthetic ImageNet Clones. In: CVPR (2023).
https://doi.org/10.1109/cvpr52729.2023.00774
[61] Segalis,E.,Valevski,D.,Lumen,D.,Matias,Y.,Leviathan,Y.: Apictureisworthathousand
words: Principledrecaptioningimprovesimagegeneration.arXivpreprintarXiv:2310.16656
(2023)
[62] Shah, V., Ruiz, N., Cole, F., Lu, E., Lazebnik, S., Li, Y., Jampani, V.: Ziplora: Any
subject in any style by effectively merging loras. ArXiv abs/2311.13600 (2023), https:
//api.semanticscholar.org/CorpusID:265351656
[63] Silver,D.,Huang,A.,Maddison,C.J.,Guez,A.,Sifre,L.,vandenDriessche,G.,Schrittwieser,
J., Antonoglou, I., Panneershelvam, V., Lanctot, M., Dieleman, S., Grewe, D., Nham, J.,
Kalchbrenner,N.,Sutskever,I.,Lillicrap,T.,Leach,M.,Kavukcuoglu,K.,Graepel,T.,Hassabis,
D.: MasteringthegameofGowithdeepneuralnetworksandtreesearch.Nature529(7587),
484‚Äì489(jan2016).https://doi.org/10.1038/nature16961
[64] Singh,S.P.,Jaggi,M.: Modelfusionviaoptimaltransport.ConferenceonNeuralInformation
Processing Systems (NeurIPS) (2020), https://api.semanticscholar.org/CorpusID:
204512191
[65] Sohl-Dickstein,J.,Weiss,E.A.,Maheswaranathan,N.,Ganguli,S.: Deepunsupervisedlearning
usingnonequilibriumthermodynamics.In: ICML(2015)
[66] Sun,J.,Fu,D.,Hu,Y.,Wang,S.,Rassin,R.,Juan,D.C.,Alon,D.,Herrmann,C.,vanSteenkiste,
S.,Krishna,R.,etal.: Dreamsync: Aligningtext-to-imagegenerationwithimageunderstanding
feedback.arXivpreprintarXiv:2311.17946(2023)
[67] Sung,Y.L.,Li,L.,Lin,K.,Gan,Z.,Bansal,M.,Wang,L.: Anempiricalstudyofmultimodal
modelmerging.EmpiricalMethodsinNaturalLanguageProcessing(Findings)(2023)
[68] Taori,R.,Gulrajani,I.,Zhang,T.,Dubois,Y.,Li,X.,Guestrin,C.,Liang,P.,Hashimoto,T.B.:
Stanfordalpaca: Aninstruction-followingllamamodel.https://github.com/tatsu-lab/
stanford_alpaca(2023)
[69] Tesauro, G.: Temporal difference learning and td-gammon. Commun. ACM 38(3), 58‚Äì68
(mar1995).https://doi.org/10.1145/203330.203343, https://doi.org/10.1145/203330.
203343
[70] Tian, Y., Fan, L., Isola, P., Chang, H., Krishnan, D.: StableRep: Synthetic Images from
Text-to-Image Models Make Strong Visual Representation Learners. In: NeurIPS (2023),
http://arxiv.org/abs/2306.00984
[71] Tuo,Y.,Xiang,W.,He,J.Y.,Geng,Y.,Xie,X.: Anytext: Multilingualvisualtextgeneration
andediting.ICLR(2024)
[72] Turc,I.,Nemade,G.: Midjourneyuserprompts&generatedimages(250k)(2023)
[73] Wallace,B.,Dang,M.,Rafailov,R.,Zhou,L.,Lou,A.,Purushwalkam,S.,Ermon,S.,Xiong,
C.,Joty,S.,Naik,N.: Diffusionmodelalignmentusingdirectpreferenceoptimization.arXiv
preprintarXiv:2311.12908(2023)
[74] Wang,Z.J.,Montoya,E.,Munechika,D.,Yang,H.,Hoover,B.,Chau,D.H.: Diffusiondb: A
large-scalepromptgallerydatasetfortext-to-imagegenerativemodels.ACL(2023)
15[75] Wu, X., Sun, K., Zhu, F., Zhao, R., Li, H.: Human Preference Score: Bet-
ter Aligning Text-to-image Models with Human Preference. In: ICCV (2023).
https://doi.org/10.1109/iccv51070.2023.00200,http://arxiv.org/abs/2303.14420
[76] Wu, X., Huang, S., Wei, F.: Mole: Mixture of lora experts. In: The Twelfth International
ConferenceonLearningRepresentations(2023)
[77] Xie, J., Li, Y., Huang, Y., Liu, H., Zhang, W., Zheng, Y., Shou, M.Z.: Boxdiff: Text-to-
imagesynthesiswithtraining-freebox-constraineddiffusion.In: ProceedingsoftheIEEE/CVF
InternationalConferenceonComputerVision.pp.7452‚Äì7461(2023)
[78] Xu,J.,Liu,X.,Wu,Y.,Tong,Y.,Li,Q.,Ding,M.,Tang,J.,Dong,Y.: Imagereward: Learning
andevaluatinghumanpreferencesfortext-to-imagegeneration.NeurIPS(2023)
[79] Yadav,P.,Tam,D.,Choshen,L.,Raffel,C.,Bansal,M.: Ties-merging: Resolvinginterference
when merging models. In: Advances in Neural Information Processing Systems (NeurIPS)
(2023)
[80] Yang, Z., Wang, J., Gan, Z., Li, L., Lin, K., Wu, C., Duan, N., Liu, Z., Liu, C., Zeng, M.,
etal.: Reco: Region-controlledtext-to-imagegeneration.In: ProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecognition.pp.14246‚Äì14255(2023)
[81] Yu,J.,Xu,Y.,Koh,J.Y.,Luong,T.,Baid,G.,Wang,Z.,Vasudevan,V.,Ku,A.,Yang,Y.,Ayan,
B.K.,etal.: Scalingautoregressivemodelsforcontent-richtext-to-imagegeneration.TMLR
2(3), 5(2023)
[82] Yu,L.,Bowen,Y.,Yu,H.,Huang,F.,Li,Y.: Languagemodelsaresupermario: Absorbing
abilities from homologous models as a free lunch. ArXiv abs/2311.03099 (2023), https:
//api.semanticscholar.org/CorpusID:265034087
[83] Yuan,H.,Chen,Z.,Ji,K.,Gu,Q.:Self-PlayFine-TuningofDiffusionModelsforText-to-Image
Generation(2024),http://arxiv.org/abs/2402.10210
[84] Yuan, W., Pang, R.Y., Cho, K., Li, X., Sukhbaatar, S., Xu, J., Weston, J.: Self-Rewarding
LanguageModels(2024),http://arxiv.org/abs/2401.10020
[85] Zhang,L.,Rao,A.,Agrawala,M.:Addingconditionalcontroltotext-to-imagediffusionmodels.
In:ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.pp.3836‚Äì3847
(2023)
[86] Zhong,M.,Shen,Y.,Wang,S.,Lu,Y.,Jiao,Y.,Ouyang,S.,Yu,D.,Han,J.,Chen,W.:Multi-lora
compositionforimagegeneration.arXivpreprintarXiv:2402.16843(2024)
16Appendix
Inthisappendix,wepresentthefollowing:
‚Ä¢ EvaluationonHPSv2.1benchmark(AppendixA).
‚Ä¢ AdditionalqualitativeexampleswithSELMAonSDXLbackbone(AppendixB).
‚Ä¢ Skill-specificVQAaccuracyonbothTIFAandDSGbenchmarks(AppendixC)
‚Ä¢ Humanevaluationdetails(AppendixD).
‚Ä¢ Implementationdetailsoftwotrainingconfigurationvariants: DPOandMoE-LoRA(Ap-
pendixE).
‚Ä¢ PromptsweusedtoqueryLLMtogeneratenewtextdata(AppendixF).
‚Ä¢ LimitationsofSELMAapproach(AppendixG).
A EvaluationonHPSv2.1Benchmark
In the main paper, we calculate HPS score [75] on text prompts on DSG benchmark, following
DreamSync[66]. Inthissection,weadditionallyshowtheHPSscoreonthepromptsfromHPSv2.1
benchmark. HPSbenchmarkcontains3200uniquepromptsfromfourdifferentcategories: anime,
concept-art,paintings,andphoto. WecalculatetheHPSscorebasedonitsHPSv2.1modeltrained
onhigherqualitydatasets. AsshowninTable5,whenadaptingSELMAtodifferentstablediffusion
basemodel,ourapproachsignificantlyimprovesthebaselineperformance(i.e.2.5forSDv1.4,4.3
forSDv2,and1.4forSDXL),achievingbetterperformancethanallthereleasedmodelontheHPS
benchmark2.
Table5: EvaluationonHPSv2.1evaluationbenchmark. SELMAachievessignifiantlybetterscores
on HPS evaluation benchmark compared with baselines, and outperforming all other baselines
reportedinHPSv2.1benchmark.
HPSv2.1EvaluationBenchmark
Method
Anime Concept-Art Paintings Photo Average
SDv1.4[56] 26.0 24.9 24.8 25.7 25.4
+SELMA 28.2 27.6 27.8 28.0 27.9
SDv2[56] 27.1 26.0 25.7 26.7 26.4
+SELMA 32.0 30.3 30.0 30.4 30.7
SDXL[47] 33.3 32.1 31.6 28.4 31.3
+SELMA 34.7 32.7 32.6 30.8 32.7
B AdditionalQualitativeExmaples
InFig.6,weshowadditionalqualitativeexamplesofSDXLandSDXL+SELMAfromDSG[12]
testpromptsrequiringdifferentskills. SELMA helpsimproveSDXLinvariousskills,including
counting, text rendering, spatial relationships, and attribute binding. For counting skill prompts,
SDXL+SELMAgenerates‚Äúfourbees‚Äùand‚Äúsevengroomsmen‚Äùcorrectlyfollowingthetextprompts.
Fortextrenderingskillprompts,SDXL+SELMAcanrenderthetext(‚Äúknowledgeispower‚Äùand‚ÄúFall
ishere‚Äù)moreaccurately,whileitstilllacksthecapabilitytorenderthetextinthetextureofvinesor
autumnleaves. Forentityskill(placingcorrectobjects)prompts,theSDXLsometimesmissessome
entitiesmentionedinthetextprompt(i.e.,‚ÄúAchild‚Äù,and‚ÄúAroadsign‚Äù),whileSDXL+SELMA
cansuccessfullygeneratethem. Forspatialrelationshipskillprompts,SDXL+SELMAgenerated
images(i.e.,‚Äúholdingastickinitsmouth‚Äù,and‚Äústopsignlefttodog‚Äù). Lastly,forattributeskill
prompts,SDXL+SELMAbindsobjectswiththeircorrespondingattributes(i.e.,‚Äúcottoncandytrees‚Äù
and‚ÄúAmaninblacksuit‚Äù)moreaccuratelythanSDXL.Thesequalitativeresultsdemonstratethe
effectivenessofSELMA.
2Benchmarkperformancecanbefound:https://github.com/tgxs002/HPSv2
17(cid:54)(cid:39)(cid:59)(cid:47) (cid:54)(cid:39)(cid:59)(cid:47)(cid:14)(cid:54)(cid:40)(cid:47)(cid:48)(cid:36) (cid:54)(cid:39)(cid:59)(cid:47) (cid:54)(cid:39)(cid:59)(cid:47)(cid:14)(cid:54)(cid:40)(cid:47)(cid:48)(cid:36)
(cid:38)(cid:82)(cid:88)(cid:81)(cid:87)(cid:76)(cid:81)(cid:74)
(cid:36)(cid:3)(cid:70)(cid:68)(cid:85)(cid:87)(cid:82)(cid:82)(cid:81)(cid:3)(cid:89)(cid:72)(cid:70)(cid:87)(cid:82)(cid:85)(cid:3)(cid:76)(cid:79)(cid:79)(cid:88)(cid:86)(cid:87)(cid:85)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:86)(cid:72)(cid:87)(cid:3)(cid:82)(cid:73)(cid:3)(cid:73)(cid:82)(cid:88)(cid:85)(cid:3)(cid:70)(cid:88)(cid:87)(cid:72)(cid:3)(cid:69)(cid:88)(cid:80)(cid:69)(cid:79)(cid:72)(cid:3)(cid:69)(cid:72)(cid:72)(cid:17) (cid:54)(cid:72)(cid:89)(cid:72)(cid:81)(cid:3)(cid:74)(cid:85)(cid:82)(cid:82)(cid:80)(cid:86)(cid:80)(cid:72)(cid:81)(cid:3)(cid:68)(cid:87)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:70)(cid:72)(cid:85)(cid:72)(cid:80)(cid:82)(cid:81)(cid:92)(cid:17)
(cid:55)(cid:72)(cid:91)(cid:87)(cid:3)(cid:53)(cid:72)(cid:81)(cid:71)(cid:72)(cid:85)(cid:76)(cid:81)(cid:74)
(cid:54)(cid:87)(cid:88)(cid:71)(cid:76)(cid:82)(cid:3)(cid:86)(cid:75)(cid:82)(cid:87)(cid:3)(cid:82)(cid:73)(cid:3)(cid:89)(cid:76)(cid:81)(cid:72)(cid:86)(cid:3)(cid:76)(cid:81)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:86)(cid:75)(cid:68)(cid:83)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:72)(cid:91)(cid:87)(cid:3)(cid:3) (cid:10)(cid:41)(cid:68)(cid:79)(cid:79)(cid:3)(cid:76)(cid:86)(cid:3)(cid:75)(cid:72)(cid:85)(cid:72)(cid:10)(cid:3)(cid:90)(cid:85)(cid:76)(cid:87)(cid:87)(cid:72)(cid:81)(cid:3)(cid:76)(cid:81)(cid:3)(cid:68)(cid:88)(cid:87)(cid:88)(cid:80)(cid:81)(cid:3)(cid:79)(cid:72)(cid:68)(cid:89)(cid:72)(cid:86)(cid:3)
(cid:78)(cid:81)(cid:82)(cid:90)(cid:79)(cid:72)(cid:71)(cid:74)(cid:72)(cid:3)(cid:76)(cid:86)(cid:3)(cid:83)(cid:82)(cid:90)(cid:72)(cid:85)(cid:3)(cid:86)(cid:83)(cid:85)(cid:82)(cid:88)(cid:87)(cid:76)(cid:81)(cid:74)(cid:15)(cid:3)(cid:70)(cid:72)(cid:81)(cid:87)(cid:72)(cid:85)(cid:72)(cid:71)(cid:17) (cid:73)(cid:79)(cid:82)(cid:68)(cid:87)(cid:76)(cid:81)(cid:74)(cid:3)(cid:82)(cid:81)(cid:3)(cid:68)(cid:3)(cid:79)(cid:68)(cid:78)(cid:72)(cid:17)
(cid:40)(cid:81)(cid:87)(cid:76)(cid:87)(cid:92)
(cid:36)(cid:3)(cid:70)(cid:75)(cid:76)(cid:79)(cid:71)(cid:3)(cid:71)(cid:85)(cid:68)(cid:90)(cid:86)(cid:3)(cid:68)(cid:3)(cid:69)(cid:79)(cid:88)(cid:72)(cid:3)(cid:73)(cid:79)(cid:82)(cid:90)(cid:72)(cid:85)(cid:3)(cid:90)(cid:76)(cid:87)(cid:75)(cid:3)(cid:68)(cid:3)(cid:85)(cid:72)(cid:71)(cid:3)(cid:83)(cid:72)(cid:81)(cid:70)(cid:76)(cid:79)(cid:17) (cid:36)(cid:3)(cid:85)(cid:82)(cid:68)(cid:71)(cid:3)(cid:86)(cid:76)(cid:74)(cid:81)(cid:3)(cid:76)(cid:81)(cid:71)(cid:76)(cid:70)(cid:68)(cid:87)(cid:72)(cid:86)(cid:3)(cid:68)(cid:3)(cid:71)(cid:76)(cid:81)(cid:82)(cid:86)(cid:68)(cid:88)(cid:85)(cid:3)(cid:70)(cid:85)(cid:82)(cid:86)(cid:86)(cid:76)(cid:81)(cid:74)(cid:17)
(cid:54)(cid:83)(cid:68)(cid:87)(cid:76)(cid:68)(cid:79)(cid:3)(cid:53)(cid:72)(cid:79)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:75)(cid:76)(cid:83)
(cid:44)(cid:81)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:83)(cid:76)(cid:70)(cid:87)(cid:88)(cid:85)(cid:72)(cid:3)(cid:90)(cid:72)(cid:3)(cid:70)(cid:68)(cid:81)(cid:3)(cid:86)(cid:72)(cid:72)(cid:3)(cid:68)(cid:3)(cid:71)(cid:82)(cid:74)(cid:3)(cid:85)(cid:88)(cid:81)(cid:81)(cid:76)(cid:81)(cid:74)(cid:15)(cid:3)(cid:75)(cid:82)(cid:79)(cid:71)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:3)(cid:86)(cid:87)(cid:76)(cid:70)(cid:78)(cid:3)(cid:76)(cid:81)(cid:3)(cid:76)(cid:87)(cid:86)(cid:3) (cid:36)(cid:3)(cid:83)(cid:75)(cid:82)(cid:87)(cid:82)(cid:3)(cid:82)(cid:73)(cid:3)(cid:71)(cid:82)(cid:74)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:86)(cid:87)(cid:82)(cid:83)(cid:3)(cid:86)(cid:76)(cid:74)(cid:81)(cid:30)(cid:3)(cid:86)(cid:87)(cid:82)(cid:83)(cid:3)(cid:86)(cid:76)(cid:74)(cid:81)(cid:3)(cid:76)(cid:86)(cid:3)(cid:79)(cid:72)(cid:73)(cid:87)(cid:3)(cid:87)(cid:82)(cid:3)(cid:71)(cid:82)(cid:74)(cid:17)
(cid:80)(cid:82)(cid:88)(cid:87)(cid:75)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:69)(cid:68)(cid:70)(cid:78)(cid:74)(cid:85)(cid:82)(cid:88)(cid:81)(cid:71)(cid:3)(cid:76)(cid:86)(cid:3)(cid:81)(cid:82)(cid:87)(cid:3)(cid:70)(cid:79)(cid:72)(cid:68)(cid:85)(cid:79)(cid:92)(cid:3)(cid:89)(cid:76)(cid:86)(cid:76)(cid:69)(cid:79)(cid:72)(cid:17)
(cid:36)(cid:87)(cid:87)(cid:85)(cid:76)(cid:69)(cid:88)(cid:87)(cid:72)
(cid:43)(cid:88)(cid:71)(cid:86)(cid:82)(cid:81)(cid:3)(cid:85)(cid:76)(cid:89)(cid:72)(cid:85)(cid:3)(cid:86)(cid:70)(cid:75)(cid:82)(cid:82)(cid:79)(cid:3)(cid:76)(cid:70)(cid:72)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:80)(cid:3)(cid:79)(cid:68)(cid:81)(cid:71)(cid:86)(cid:70)(cid:68)(cid:83)(cid:72)(cid:3)(cid:70)(cid:75)(cid:82)(cid:70)(cid:82)(cid:79)(cid:68)(cid:87)(cid:72)(cid:3) (cid:36)(cid:3)(cid:80)(cid:68)(cid:81)(cid:3)(cid:76)(cid:81)(cid:3)(cid:68)(cid:3)(cid:69)(cid:79)(cid:68)(cid:70)(cid:78)(cid:3)(cid:86)(cid:88)(cid:76)(cid:87)(cid:3)(cid:86)(cid:88)(cid:85)(cid:73)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:3)(cid:79)(cid:68)(cid:85)(cid:74)(cid:72)(cid:3)(cid:90)(cid:68)(cid:89)(cid:72)(cid:17)
(cid:85)(cid:76)(cid:89)(cid:72)(cid:85)(cid:3)(cid:76)(cid:70)(cid:72)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:80)(cid:3)(cid:80)(cid:82)(cid:88)(cid:81)(cid:87)(cid:68)(cid:76)(cid:81)(cid:86)(cid:3)(cid:70)(cid:82)(cid:87)(cid:87)(cid:82)(cid:81)(cid:3)(cid:70)(cid:68)(cid:81)(cid:71)(cid:92)(cid:3)(cid:87)(cid:85)(cid:72)(cid:72)(cid:86)(cid:17)
Figure 6: Qualitative example images generated with SDXL and SDXL+SELMA (Ours) from
DSG[12]testpromptsrequiringdifferentskills. SELMAhelpsimproveSDXLinvariousskills,
includingcounting,textrendering,spatialrelationships,andattributebinding. Wehighlighttheparts
ofthepromptsinredwhereSDXLmakeserrorswhileSDXL+SELMAgeneratescorrectly.
18Table6: Detailedskill-specificcomparisonofSDmodelsvs.SDmodels+SELMAonTIFAbench-
mark.
TIFAskills
Method
Animal/Human Object Location Activity Color Spatial Attribute Food Counting Material Other Shape Average
SDv1.4[56] 83.7 78.3 80.3 71.7 73.0 58.9 74.5 81.8 63.3 76.6 47.3 65.2 75.8
+SELMA 87.1 83.0 84.8 75.9 74.4 62.3 76.0 88.1 66.2 78.5 52.2 59.4 79.5
SDv2[56] 86.5 82.6 83.8 75.6 76.8 62.4 75.4 85.2 66.5 82.2 55.4 75.0 79.2
+SELMA 89.7 88.0 87.6 80.3 80.3 66.0 77.2 91.0 65.8 81.3 63.2 68.1 83.2
SDXL[47] 90.3 86.4 86.6 80.0 78.6 67.7 78.3 90.6 67.4 84.2 67.7 62.3 82.9
+SELMA 93.4 90.4 89.5 83.6 81.1 69.6 78.5 92.1 68.8 83.7 68.7 60.9 85.6
Table7: Detailedskill-specificcomparisonofSDmodelsvs.SDmodels+SELMAonDSGbench-
mark. Weshowtheskillcategoriesthathavemorethan50questions.
DSGskills
Method
Whole Color Shape Spatial Part State Count Action Global Material Type TextRendering Average
SDv1.4[56] 78.6 62.5 46.0 61.1 68.1 58.2 62.4 59.9 59.4 42.3 73.0 52.7 67.2
+SELMA 83.7 62.5 52.0 66.2 72.1 63.3 66.1 72.1 57.1 59.7 67.6 50.9 71.3
SDv2[56] 80.8 68.6 50.0 63.6 72.3 63.6 69.3 62.9 61.9 55.7 66.8 60.9 70.3
+SELMA 88.0 80.8 65.4 71.0 78.7 71.5 66.3 78.4 61.0 69.2 81.4 67.4 77.7
SDXL[47] 84.8 74.7 58.0 69.4 71.1 60.7 59.8 71.7 61.5 63.9 71.7 60.0 73.3
+SELMA 90.4 81.3 64.0 77.4 83.3 68.2 73.0 79.4 60.2 77.3 75.4 76.4 80.2
C Skill-specificVQAAccuracyonTIFAandDSG
In this section, we show the detailed VQA accuracy for each skill category on TIFA and DSG
benchmarks. SinceDreamSync[66]doesnotprovidetheskill-specificscores,wereporttheskill-
specificscoresofSDmodelsonTIFAandDSGandbasedonourexperimentsinTable6andTable7;
weobservetherearelessthan1%scoredifferencesofSD/SDXLmodelsinTIFAaverageaccuracy
betweentheresultsinSunetal.andours.
As shown in Table 6 and Table 7, on both TIFA and DSG benchmarks, SELMA improves the
generation faithfulness in most of the categories. Comparing SDXL and SDXL+SELMA, the
SDXLfinetunedwithSELMAapproachshowslargeimprovementespeciallyinentity(i.e.3.1%on
animal/humanonTIFAcomparedwithSDXL,5.6%inwholeonDSG,12.2%inpartonDSG),as
wellasspatialrelationship(i.e.1.9%onTIFA,and8.0%onDSG),andcountingskills(i.e.1.4%on
TIFA,and13.2%onDSG).Besides,wealsoobservethatSELMAsignificantlyimprovesthetext
renderingforSDv2andSDXL(i.e.16.4%comparedwithSDXL,and6.5%comparedwithSDv2
onDSG),butnotSDv1.4(i.e.1.8%decreasecomparedwithSDv1.4onDSG).
D HumanEvaluationDetails
Weconductthehumanevaluation(describedinthemain Table8: HumanEvaluationon200sam-
paperSec.5.5)on200randomlysampledpromptsfrom pledtextpromptsfromDSG.Weshow
DSG,withthreeexternalannotators. Weshowtheannota- the detailed win/lose/tie counts on all
tioninterfaceinFig.7. Theimageorderbetweenthetwo samplesandsamplesfromeachdataset.
modelsisrandomizedtoavoidtheleakageofinformation
aboutwhichimageisgeneratedwithwhichmodel. EvalDataset Win Lose Tie
In Table 8, we show the detailed annotator votes for All 241 114 245
LocalizedNarratives 19 5 12
win, lose, and tie for SDXL and SDXL+SELMA.
DiffusionDB 6 5 34
SDXL+SELMAhassignificantlyhigherwinvotescom-
CountBench 26 11 17
paredwithSDXLonallthe200sampledtextprompts(i.e., COCO 35 2 47
241winvs.114lose),demonstratingtheeffectivenessof Whoops 21 10 26
SELMA.
E ImplementationDetailsofDPOandMoE-LoRA
Inthissection,weprovidetheimplementationdetailsoftwotrainingapproachesweexperimentwith
(describedinSec.5.6inthemainpaper).
19Figure7: ExampleuserinterfaceforhumanevaluationonDSGprompts.
DirectPreferenceOptimization(DPO).Wefine-tuneLoRAmodelswithDPOproposedin[73].
Specifically,wesampletwoimageswithT2Imodelsandcalculatetheimage-textalignmentwith
CLIPscore[51]. WeusetheimagewithahigherCLIPscoreasthepositiveexampleandtheimage
withalowerCLIPscoreasthenegativeexample. Wefine-tunetheLoRAmodelstolearntogenerate
imagesclosertothepositiveimagedistributionandpushawayfromgeneratingimagessimilarto
thenegativeimagedistribution. Similarly, wefine-tunewithDPOonfivedatasetswithdifferent
textstylesandskillsandmergeLoRAexpertmodelsduringinferencetimebyaveragingtheLoRA
weights. InDPOtraining,weuseaconstantlearningrate3e-4andfine-tuneLoRAfor5Ksteps. We
evaluatethemodelonDSGevery1Kstepsandpickthebestcheckpoint.
Mixture of Lora Experts (MoE-LoRA). MoE-LoRA [76] utilizes a gating function (router) to
decidewhichexpertstouseduringtrainingandinference. Thegatingfunctionpredictsweightsfor
eachexpertbasedonlayerinputsandpicksthetopK expertstouseateachlayer. Specifically,the
gatingfunctionweuseisasimplelinearmappingfunction,where{w }K =W x. xistheinputto
i i=1 g
eachlayer,W isthelearnablegatingweights,and{w }K arethepredictedweights. Theoutputsof
g i i=1
eachexpertareaddedtogetherwiththenormalizedweightsfromthegatingfunction. InMoE-LoRA,
weinitializefiveLoRAexpertsfine-tunedondifferentdatasetscontainingdifferenttextstylesand
skills. WefreezethelearnedLoRAweightsandonlyfine-tunethegatingfunctiononthecollected
fivedatasets. Weactivateallfiveexpertsduringtrainingandinference(i.e.,K =5). InMoE-LoRA
training, weuseaconstantlearningrate1e-5andfine-tuneLoRAfor5Ksteps. Weevaluatethe
modelonDSGevery1Kstepsandpickthemodelwithhighesttextfaithfulnessscore.
F Skill-SpecificPromptGenerationDetails
WeshowthepromptsweusetoqueryGPT3.5togenerate1Kpromptsforeachskill. Asshownin
Fig.8, weusedifferentpromptstogenerate SELMA data. Forexample, wespecify‚Äúparagraph
captions‚Äùtogeneratetextpromptsthatcanbeusedtoteachmodeltofollowlongtextprompts,and
specifying‚Äúevaluatemodel‚Äôscapabilitytocountobjects‚Äùtocollectasetofpromptsforimproving
model‚Äôscountingcapability. Besides, inallthepromptgeneration, weemphasizethattheimage
should‚Äúmentiondiverseobjects‚Äùtomaximizethesemanticdiversityingeneratedprompts.
20(cid:47)(cid:82)(cid:70)(cid:68)(cid:79)(cid:76)(cid:93)(cid:72)(cid:71)(cid:3)(cid:49)(cid:68)(cid:85)(cid:85)(cid:68)(cid:87)(cid:76)(cid:89)(cid:72)(cid:86)(cid:29)
(cid:51)(cid:79)(cid:72)(cid:68)(cid:86)(cid:72)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:87)(cid:72)(cid:3)(cid:21)(cid:19)(cid:3)(cid:80)(cid:82)(cid:85)(cid:72)(cid:3)(cid:71)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:17)(cid:3)(cid:43)(cid:72)(cid:85)(cid:72)(cid:3)(cid:68)(cid:85)(cid:72)(cid:3)(cid:86)(cid:72)(cid:89)(cid:72)(cid:85)(cid:68)(cid:79)(cid:3)(cid:85)(cid:88)(cid:79)(cid:72)(cid:86)(cid:3)(cid:73)(cid:82)(cid:85)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:87)(cid:76)(cid:81)(cid:74)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)
(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:29)
(cid:20)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:88)(cid:86)(cid:72)(cid:71)(cid:3)(cid:87)(cid:82)(cid:3)(cid:72)(cid:89)(cid:68)(cid:79)(cid:88)(cid:68)(cid:87)(cid:72)(cid:3)(cid:82)(cid:81)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:86)(cid:78)(cid:76)(cid:79)(cid:79)(cid:86)(cid:3)(cid:82)(cid:73)(cid:3)(cid:68)(cid:81)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:74)(cid:72)(cid:81)(cid:72)(cid:85)(cid:68)(cid:87)(cid:82)(cid:85)(cid:29)(cid:3)(cid:86)(cid:83)(cid:68)(cid:87)(cid:76)(cid:68)(cid:79)(cid:15)(cid:3)(cid:70)(cid:82)(cid:88)(cid:81)(cid:87)(cid:15)(cid:3)
(cid:68)(cid:81)(cid:76)(cid:80)(cid:68)(cid:79)(cid:15)(cid:3)(cid:75)(cid:88)(cid:80)(cid:68)(cid:81)(cid:15)(cid:3)(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)(cid:15)(cid:3)(cid:79)(cid:82)(cid:70)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:15)(cid:3)(cid:68)(cid:70)(cid:87)(cid:76)(cid:89)(cid:76)(cid:87)(cid:92)(cid:15)(cid:3)(cid:70)(cid:82)(cid:79)(cid:82)(cid:85)(cid:15)(cid:3)(cid:68)(cid:87)(cid:87)(cid:85)(cid:76)(cid:69)(cid:88)(cid:87)(cid:72)(cid:15)(cid:3)(cid:73)(cid:82)(cid:82)(cid:71)(cid:15)(cid:3)(cid:80)(cid:68)(cid:87)(cid:72)(cid:85)(cid:76)(cid:68)(cid:79)(cid:15)(cid:3)(cid:86)(cid:75)(cid:68)(cid:83)(cid:72)(cid:17)
(cid:22)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:81)(cid:72)(cid:72)(cid:71)(cid:3)(cid:87)(cid:82)(cid:3)(cid:80)(cid:72)(cid:81)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:71)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:72)(cid:3)(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)(cid:86)(cid:3)(cid:87)(cid:75)(cid:68)(cid:87)(cid:3)(cid:73)(cid:85)(cid:72)(cid:84)(cid:88)(cid:72)(cid:81)(cid:87)(cid:79)(cid:92)(cid:3)(cid:68)(cid:83)(cid:83)(cid:72)(cid:68)(cid:85)(cid:3)(cid:76)(cid:81)(cid:3)(cid:71)(cid:68)(cid:76)(cid:79)(cid:92)(cid:3)(cid:79)(cid:76)(cid:73)(cid:72)(cid:17)
(cid:23)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:79)(cid:72)(cid:86)(cid:86)(cid:3)(cid:87)(cid:75)(cid:68)(cid:81)(cid:3)(cid:24)(cid:19)(cid:3)(cid:90)(cid:82)(cid:85)(cid:71)(cid:86)(cid:17)
(cid:24)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:87)(cid:72)(cid:91)(cid:87)(cid:3)(cid:86)(cid:87)(cid:92)(cid:79)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:71)(cid:76)(cid:73)(cid:73)(cid:72)(cid:85)(cid:72)(cid:81)(cid:87)(cid:3)(cid:73)(cid:85)(cid:82)(cid:80)(cid:3)(cid:72)(cid:68)(cid:70)(cid:75)(cid:3)(cid:82)(cid:87)(cid:75)(cid:72)(cid:85)(cid:15)(cid:3)(cid:69)(cid:88)(cid:87)(cid:3)(cid:74)(cid:72)(cid:81)(cid:72)(cid:85)(cid:68)(cid:79)(cid:79)(cid:92)(cid:3)(cid:76)(cid:81)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)
(cid:86)(cid:87)(cid:92)(cid:79)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:83)(cid:68)(cid:85)(cid:68)(cid:74)(cid:85)(cid:68)(cid:83)(cid:75)(cid:3)(cid:70)(cid:68)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:17)
(cid:43)(cid:72)(cid:85)(cid:72)(cid:10)(cid:85)(cid:72)(cid:3)(cid:86)(cid:82)(cid:80)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:72)(cid:91)(cid:68)(cid:80)(cid:83)(cid:79)(cid:72)(cid:86)(cid:29)
(cid:38)(cid:82)(cid:88)(cid:81)(cid:87)(cid:37)(cid:72)(cid:81)(cid:70)(cid:75)(cid:29)
(cid:51)(cid:79)(cid:72)(cid:68)(cid:86)(cid:72)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:87)(cid:72)(cid:3)(cid:21)(cid:19)(cid:3)(cid:80)(cid:82)(cid:85)(cid:72)(cid:3)(cid:71)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:17)(cid:3)(cid:43)(cid:72)(cid:85)(cid:72)(cid:3)(cid:68)(cid:85)(cid:72)(cid:3)(cid:86)(cid:72)(cid:89)(cid:72)(cid:85)(cid:68)(cid:79)(cid:3)(cid:85)(cid:88)(cid:79)(cid:72)(cid:86)(cid:3)(cid:73)(cid:82)(cid:85)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:87)(cid:76)(cid:81)(cid:74)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)
(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:29)
(cid:20)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:68)(cid:69)(cid:79)(cid:72)(cid:3)(cid:87)(cid:82)(cid:3)(cid:72)(cid:89)(cid:68)(cid:79)(cid:88)(cid:68)(cid:87)(cid:72)(cid:3)(cid:80)(cid:82)(cid:71)(cid:72)(cid:79)(cid:10)(cid:86)(cid:3)(cid:70)(cid:68)(cid:83)(cid:68)(cid:69)(cid:76)(cid:79)(cid:76)(cid:87)(cid:92)(cid:3)(cid:87)(cid:82)(cid:3)(cid:70)(cid:82)(cid:88)(cid:81)(cid:87)(cid:3)(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)(cid:86)(cid:17)
(cid:21)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:70)(cid:82)(cid:88)(cid:81)(cid:87)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:81)(cid:82)(cid:87)(cid:3)(cid:69)(cid:72)(cid:3)(cid:79)(cid:68)(cid:85)(cid:74)(cid:72)(cid:85)(cid:3)(cid:87)(cid:75)(cid:68)(cid:81)(cid:3)(cid:22)(cid:17)
(cid:22)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:81)(cid:72)(cid:72)(cid:71)(cid:3)(cid:87)(cid:82)(cid:3)(cid:80)(cid:72)(cid:81)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:71)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:72)(cid:3)(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)(cid:86)(cid:3)(cid:87)(cid:75)(cid:68)(cid:87)(cid:3)(cid:73)(cid:85)(cid:72)(cid:84)(cid:88)(cid:72)(cid:81)(cid:87)(cid:79)(cid:92)(cid:3)(cid:68)(cid:83)(cid:83)(cid:72)(cid:68)(cid:85)(cid:3)(cid:76)(cid:81)(cid:3)(cid:71)(cid:68)(cid:76)(cid:79)(cid:92)(cid:3)(cid:79)(cid:76)(cid:73)(cid:72)(cid:17)
(cid:23)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:79)(cid:72)(cid:86)(cid:86)(cid:3)(cid:87)(cid:75)(cid:68)(cid:81)(cid:3)(cid:22)(cid:19)(cid:3)(cid:90)(cid:82)(cid:85)(cid:71)(cid:86)(cid:17)
(cid:24)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:87)(cid:72)(cid:91)(cid:87)(cid:3)(cid:86)(cid:87)(cid:92)(cid:79)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:71)(cid:76)(cid:73)(cid:73)(cid:72)(cid:85)(cid:72)(cid:81)(cid:87)(cid:3)(cid:73)(cid:85)(cid:82)(cid:80)(cid:3)(cid:72)(cid:68)(cid:70)(cid:75)(cid:3)(cid:82)(cid:87)(cid:75)(cid:72)(cid:85)(cid:17)(cid:3)
(cid:43)(cid:72)(cid:85)(cid:72)(cid:10)(cid:85)(cid:72)(cid:3)(cid:86)(cid:82)(cid:80)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:72)(cid:91)(cid:68)(cid:80)(cid:83)(cid:79)(cid:72)(cid:86)(cid:29)
(cid:39)(cid:76)(cid:73)(cid:73)(cid:88)(cid:86)(cid:76)(cid:82)(cid:81)(cid:39)(cid:37)(cid:29)
(cid:51)(cid:79)(cid:72)(cid:68)(cid:86)(cid:72)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:87)(cid:72)(cid:3)(cid:21)(cid:19)(cid:3)(cid:80)(cid:82)(cid:85)(cid:72)(cid:3)(cid:71)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:17)(cid:3)(cid:43)(cid:72)(cid:85)(cid:72)(cid:3)(cid:68)(cid:85)(cid:72)(cid:3)(cid:86)(cid:72)(cid:89)(cid:72)(cid:85)(cid:68)(cid:79)(cid:3)(cid:85)(cid:88)(cid:79)(cid:72)(cid:86)(cid:3)(cid:73)(cid:82)(cid:85)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:87)(cid:76)(cid:81)(cid:74)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)
(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:29)
(cid:20)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:88)(cid:86)(cid:72)(cid:71)(cid:3)(cid:87)(cid:82)(cid:3)(cid:72)(cid:89)(cid:68)(cid:79)(cid:88)(cid:68)(cid:87)(cid:72)(cid:3)(cid:82)(cid:81)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:86)(cid:78)(cid:76)(cid:79)(cid:79)(cid:86)(cid:3)(cid:82)(cid:73)(cid:3)(cid:68)(cid:81)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:74)(cid:72)(cid:81)(cid:72)(cid:85)(cid:68)(cid:87)(cid:82)(cid:85)(cid:29)(cid:3)(cid:86)(cid:83)(cid:68)(cid:87)(cid:76)(cid:68)(cid:79)(cid:15)(cid:3)(cid:70)(cid:82)(cid:88)(cid:81)(cid:87)(cid:15)(cid:3)
(cid:68)(cid:81)(cid:76)(cid:80)(cid:68)(cid:79)(cid:15)(cid:3)(cid:75)(cid:88)(cid:80)(cid:68)(cid:81)(cid:15)(cid:3)(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)(cid:15)(cid:3)(cid:79)(cid:82)(cid:70)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:15)(cid:3)(cid:68)(cid:70)(cid:87)(cid:76)(cid:89)(cid:76)(cid:87)(cid:92)(cid:15)(cid:3)(cid:70)(cid:82)(cid:79)(cid:82)(cid:85)(cid:15)(cid:3)(cid:68)(cid:87)(cid:87)(cid:85)(cid:76)(cid:69)(cid:88)(cid:87)(cid:72)(cid:15)(cid:3)(cid:73)(cid:82)(cid:82)(cid:71)(cid:15)(cid:3)(cid:80)(cid:68)(cid:87)(cid:72)(cid:85)(cid:76)(cid:68)(cid:79)(cid:15)(cid:3)(cid:86)(cid:75)(cid:68)(cid:83)(cid:72)(cid:17)
(cid:22)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:81)(cid:72)(cid:72)(cid:71)(cid:3)(cid:87)(cid:82)(cid:3)(cid:80)(cid:72)(cid:81)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:71)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:72)(cid:3)(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)(cid:86)(cid:3)(cid:87)(cid:75)(cid:68)(cid:87)(cid:3)(cid:73)(cid:85)(cid:72)(cid:84)(cid:88)(cid:72)(cid:81)(cid:87)(cid:79)(cid:92)(cid:3)(cid:68)(cid:83)(cid:83)(cid:72)(cid:68)(cid:85)(cid:3)(cid:76)(cid:81)(cid:3)(cid:71)(cid:68)(cid:76)(cid:79)(cid:92)(cid:3)(cid:79)(cid:76)(cid:73)(cid:72)(cid:17)
(cid:23)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:79)(cid:72)(cid:86)(cid:86)(cid:3)(cid:87)(cid:75)(cid:68)(cid:81)(cid:3)(cid:24)(cid:19)(cid:3)(cid:90)(cid:82)(cid:85)(cid:71)(cid:86)(cid:17)
(cid:24)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:87)(cid:72)(cid:91)(cid:87)(cid:3)(cid:86)(cid:87)(cid:92)(cid:79)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:71)(cid:76)(cid:73)(cid:73)(cid:72)(cid:85)(cid:72)(cid:81)(cid:87)(cid:3)(cid:73)(cid:85)(cid:82)(cid:80)(cid:3)(cid:72)(cid:68)(cid:70)(cid:75)(cid:3)(cid:82)(cid:87)(cid:75)(cid:72)(cid:85)(cid:15)(cid:3)(cid:69)(cid:88)(cid:87)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:69)(cid:72)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)
(cid:76)(cid:81)(cid:3)(cid:71)(cid:72)(cid:87)(cid:68)(cid:76)(cid:79)(cid:86)(cid:17)
(cid:43)(cid:72)(cid:85)(cid:72)(cid:10)(cid:85)(cid:72)(cid:3)(cid:86)(cid:82)(cid:80)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:72)(cid:91)(cid:68)(cid:80)(cid:83)(cid:79)(cid:72)(cid:86)(cid:29)
(cid:38)(cid:50)(cid:38)(cid:50)(cid:29)
(cid:51)(cid:79)(cid:72)(cid:68)(cid:86)(cid:72)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:87)(cid:72)(cid:3)(cid:21)(cid:19)(cid:3)(cid:80)(cid:82)(cid:85)(cid:72)(cid:3)(cid:71)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:17)(cid:3)(cid:43)(cid:72)(cid:85)(cid:72)(cid:3)(cid:68)(cid:85)(cid:72)(cid:3)(cid:86)(cid:72)(cid:89)(cid:72)(cid:85)(cid:68)(cid:79)(cid:3)(cid:85)(cid:88)(cid:79)(cid:72)(cid:86)(cid:3)(cid:73)(cid:82)(cid:85)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:87)(cid:76)(cid:81)(cid:74)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)
(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:29)
(cid:20)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:88)(cid:86)(cid:72)(cid:71)(cid:3)(cid:87)(cid:82)(cid:3)(cid:72)(cid:89)(cid:68)(cid:79)(cid:88)(cid:68)(cid:87)(cid:72)(cid:3)(cid:82)(cid:81)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:86)(cid:78)(cid:76)(cid:79)(cid:79)(cid:86)(cid:3)(cid:82)(cid:73)(cid:3)(cid:68)(cid:81)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:74)(cid:72)(cid:81)(cid:72)(cid:85)(cid:68)(cid:87)(cid:82)(cid:85)(cid:29)(cid:3)(cid:86)(cid:83)(cid:68)(cid:87)(cid:76)(cid:68)(cid:79)(cid:15)(cid:3)(cid:70)(cid:82)(cid:88)(cid:81)(cid:87)(cid:15)(cid:3)
(cid:68)(cid:81)(cid:76)(cid:80)(cid:68)(cid:79)(cid:15)(cid:3)(cid:75)(cid:88)(cid:80)(cid:68)(cid:81)(cid:15)(cid:3)(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)(cid:15)(cid:3)(cid:79)(cid:82)(cid:70)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:15)(cid:3)(cid:68)(cid:70)(cid:87)(cid:76)(cid:89)(cid:76)(cid:87)(cid:92)(cid:15)(cid:3)(cid:70)(cid:82)(cid:79)(cid:82)(cid:85)(cid:15)(cid:3)(cid:68)(cid:87)(cid:87)(cid:85)(cid:76)(cid:69)(cid:88)(cid:87)(cid:72)(cid:15)(cid:3)(cid:73)(cid:82)(cid:82)(cid:71)(cid:15)(cid:3)(cid:80)(cid:68)(cid:87)(cid:72)(cid:85)(cid:76)(cid:68)(cid:79)(cid:15)(cid:3)(cid:86)(cid:75)(cid:68)(cid:83)(cid:72)(cid:17)
(cid:22)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:81)(cid:72)(cid:72)(cid:71)(cid:3)(cid:87)(cid:82)(cid:3)(cid:80)(cid:72)(cid:81)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:71)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:72)(cid:3)(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)(cid:86)(cid:3)(cid:87)(cid:75)(cid:68)(cid:87)(cid:3)(cid:73)(cid:85)(cid:72)(cid:84)(cid:88)(cid:72)(cid:81)(cid:87)(cid:79)(cid:92)(cid:3)(cid:68)(cid:83)(cid:83)(cid:72)(cid:68)(cid:85)(cid:3)(cid:76)(cid:81)(cid:3)(cid:71)(cid:68)(cid:76)(cid:79)(cid:92)(cid:3)(cid:79)(cid:76)(cid:73)(cid:72)(cid:17)
(cid:23)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:79)(cid:72)(cid:86)(cid:86)(cid:3)(cid:87)(cid:75)(cid:68)(cid:81)(cid:3)(cid:22)(cid:19)(cid:3)(cid:90)(cid:82)(cid:85)(cid:71)(cid:86)(cid:17)
(cid:24)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:87)(cid:72)(cid:91)(cid:87)(cid:3)(cid:86)(cid:87)(cid:92)(cid:79)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:71)(cid:76)(cid:73)(cid:73)(cid:72)(cid:85)(cid:72)(cid:81)(cid:87)(cid:3)(cid:73)(cid:85)(cid:82)(cid:80)(cid:3)(cid:72)(cid:68)(cid:70)(cid:75)(cid:3)(cid:82)(cid:87)(cid:75)(cid:72)(cid:85)(cid:17)
(cid:43)(cid:72)(cid:85)(cid:72)(cid:10)(cid:85)(cid:72)(cid:3)(cid:86)(cid:82)(cid:80)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:72)(cid:91)(cid:68)(cid:80)(cid:83)(cid:79)(cid:72)(cid:86)(cid:29)
(cid:58)(cid:75)(cid:82)(cid:82)(cid:83)(cid:86)(cid:29)
(cid:51)(cid:79)(cid:72)(cid:68)(cid:86)(cid:72)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:87)(cid:72)(cid:3)(cid:21)(cid:19)(cid:3)(cid:80)(cid:82)(cid:85)(cid:72)(cid:3)(cid:71)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:17)(cid:3)(cid:43)(cid:72)(cid:85)(cid:72)(cid:3)(cid:68)(cid:85)(cid:72)(cid:3)(cid:86)(cid:72)(cid:89)(cid:72)(cid:85)(cid:68)(cid:79)(cid:3)(cid:85)(cid:88)(cid:79)(cid:72)(cid:86)(cid:3)(cid:73)(cid:82)(cid:85)(cid:3)(cid:70)(cid:85)(cid:72)(cid:68)(cid:87)(cid:76)(cid:81)(cid:74)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)
(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:29)
(cid:20)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:88)(cid:86)(cid:72)(cid:71)(cid:3)(cid:87)(cid:82)(cid:3)(cid:72)(cid:89)(cid:68)(cid:79)(cid:88)(cid:68)(cid:87)(cid:72)(cid:3)(cid:82)(cid:81)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:86)(cid:78)(cid:76)(cid:79)(cid:79)(cid:86)(cid:3)(cid:82)(cid:73)(cid:3)(cid:68)(cid:81)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:74)(cid:72)(cid:81)(cid:72)(cid:85)(cid:68)(cid:87)(cid:82)(cid:85)(cid:29)(cid:3)(cid:86)(cid:83)(cid:68)(cid:87)(cid:76)(cid:68)(cid:79)(cid:15)(cid:3)(cid:70)(cid:82)(cid:88)(cid:81)(cid:87)(cid:15)(cid:3)
(cid:68)(cid:81)(cid:76)(cid:80)(cid:68)(cid:79)(cid:15)(cid:3)(cid:75)(cid:88)(cid:80)(cid:68)(cid:81)(cid:15)(cid:3)(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)(cid:15)(cid:3)(cid:79)(cid:82)(cid:70)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:15)(cid:3)(cid:68)(cid:70)(cid:87)(cid:76)(cid:89)(cid:76)(cid:87)(cid:92)(cid:15)(cid:3)(cid:70)(cid:82)(cid:79)(cid:82)(cid:85)(cid:15)(cid:3)(cid:68)(cid:87)(cid:87)(cid:85)(cid:76)(cid:69)(cid:88)(cid:87)(cid:72)(cid:15)(cid:3)(cid:73)(cid:82)(cid:82)(cid:71)(cid:15)(cid:3)(cid:80)(cid:68)(cid:87)(cid:72)(cid:85)(cid:76)(cid:68)(cid:79)(cid:15)(cid:3)(cid:86)(cid:75)(cid:68)(cid:83)(cid:72)(cid:17)
(cid:22)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:81)(cid:72)(cid:72)(cid:71)(cid:3)(cid:87)(cid:82)(cid:3)(cid:80)(cid:72)(cid:81)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:71)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:72)(cid:3)(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)(cid:86)(cid:3)(cid:87)(cid:75)(cid:68)(cid:87)(cid:3)(cid:73)(cid:85)(cid:72)(cid:84)(cid:88)(cid:72)(cid:81)(cid:87)(cid:79)(cid:92)(cid:3)(cid:68)(cid:83)(cid:83)(cid:72)(cid:68)(cid:85)(cid:3)(cid:76)(cid:81)(cid:3)(cid:71)(cid:68)(cid:76)(cid:79)(cid:92)(cid:3)(cid:79)(cid:76)(cid:73)(cid:72)(cid:15)(cid:3)(cid:69)(cid:88)(cid:87)(cid:3)(cid:75)(cid:68)(cid:89)(cid:72)(cid:3)
(cid:86)(cid:82)(cid:80)(cid:72)(cid:3)(cid:70)(cid:82)(cid:80)(cid:80)(cid:82)(cid:81)(cid:86)(cid:72)(cid:81)(cid:86)(cid:72)(cid:16)(cid:71)(cid:72)(cid:73)(cid:92)(cid:76)(cid:81)(cid:74)(cid:3)(cid:70)(cid:82)(cid:80)(cid:69)(cid:76)(cid:81)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:17)
(cid:23)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:79)(cid:72)(cid:86)(cid:86)(cid:3)(cid:87)(cid:75)(cid:68)(cid:81)(cid:3)(cid:22)(cid:19)(cid:3)(cid:90)(cid:82)(cid:85)(cid:71)(cid:86)(cid:17)
(cid:24)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:87)(cid:72)(cid:91)(cid:87)(cid:3)(cid:86)(cid:87)(cid:92)(cid:79)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:3)(cid:86)(cid:75)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:69)(cid:72)(cid:3)(cid:71)(cid:76)(cid:73)(cid:73)(cid:72)(cid:85)(cid:72)(cid:81)(cid:87)(cid:3)(cid:73)(cid:85)(cid:82)(cid:80)(cid:3)(cid:72)(cid:68)(cid:70)(cid:75)(cid:3)(cid:82)(cid:87)(cid:75)(cid:72)(cid:85)(cid:17)
(cid:43)(cid:72)(cid:85)(cid:72)(cid:10)(cid:85)(cid:72)(cid:3)(cid:86)(cid:82)(cid:80)(cid:72)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:3)(cid:71)(cid:72)(cid:86)(cid:70)(cid:85)(cid:76)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:72)(cid:91)(cid:68)(cid:80)(cid:83)(cid:79)(cid:72)(cid:86)(cid:29)
Figure8: PromptsusedtoqueryGPT-3.5auto-generatenewpromptstargetingdifferentskills.
G Limitations
SELMAreliesonastrongimagegeneratorandaninstruction-followingLLM.NotethatSELMA
ismodel-agnosticandcanbeimplementedwithpubliclyaccessiblemodels(GPT-3.5andStable
Diffusionmodels). Also,sinceourfine-tuningworkswellwithasmallnumberofimage-textpairs
(i.e.,foreachskill,weonlygenerate1Ktextpromptsandgeneratingoneimagepereachtextprompt),
the cost of LLM inference (i.e., $27.78 for querying GPT-3.5 for generating prompts in all the
21experimentsincludingablationstudies)andimagegeneration(8sperimageforimagegeneration
with SDXL on a single NVIDIA L40 GPU with 48GB memory) is minimal. Second, although
SELMAhelpsboostT2Imodels‚Äôperformancesignificantlyinbothtextfaithfulnessandalignment
tohumanpreference,fine-tuningwith SELMA doesnotguaranteetheresultingmodeltofollow
thetextpromptsineverydetail. TouseT2ImodelstrainedwithSELMA,researchersshouldfirst
carefullystudytheircapabilitiesinrelationtothespecificcontexttheyarebeingappliedwithin.
22