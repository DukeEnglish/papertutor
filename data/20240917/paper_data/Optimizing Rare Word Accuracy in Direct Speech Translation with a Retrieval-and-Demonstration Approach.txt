Optimizing Rare Word Accuracy in Direct Speech Translation with a
Retrieval-and-Demonstration Approach
SiqiLi‚àó DanniLiu‚àó JanNiehues
KarlsruheInstituteofTechnology,Germany
siqi.li@student.kit.edu,{danni.liu, jan.niehues}@kit.edu
Abstract Despite the advancements, accurately translating
rarewordslikepersonnames(Gaidoetal.,2021,
Direct speech translation (ST) models often
2023) remains a significant challenge for ST sys-
strugglewithrarewords. Incorrecttranslation
tems. While infrequent, incorrect translations of
ofthesewordscanhavesevereconsequences,
rarewordscanseverelydegradeoveralltranslation
impacting translation quality and user trust.
qualityandevenusers‚Äôtrustinthedeployedmod-
Whilerarewordtranslationisinherentlychal-
lengingforneuralmodelsduetosparselearn- els. Rarewordtranslationisinherentlydifficultfor
ingsignals,real-worldscenariosoftenallowac- STmodelsduetolimitedorabsentlearningsignals.
cesstotranslationsofpastrecordingsonsimilar Practically, however, valuable external resources
topics. To leverage these valuable resources, holdthepotentialtoaddressthisissue. Real-world
weproposearetrieval-and-demonstrationap-
scenarios often allow access to translations from
proachtoenhancerarewordtranslationaccu-
pastrecordingsonsimilartopics,sometimeseven
racy in direct ST models. First, we adapt ex-
fromthesamespeaker. Similarly,humantransla-
isting ST models to incorporate retrieved ex-
amplesforrarewordtranslation,whichallows tors often leverage existing translations (Bowker,
themodeltobenefitfromprependedexamples, 2005),especiallyforspecialterminologies(Brkic¬¥
similar to in-context learning. We then de- et al., 2009). Inspired by these observations, we
velopacross-modal(speech-to-speech,speech- ask the question: How can we improve the rare
to-text,text-to-text)retrievertolocatesuitable
wordtranslationperformanceofdirectSTmodels
examples. We demonstrate that standard ST
byleveraginganexamplepoolthatcontainssimilar
modelscanbeeffectivelyadaptedtoleverage
translations?
examplesforrarewordtranslation,improving
The envisioned approach faces challenges in
rare word translation accuracy over the base-
line by 17.6% with gold examples and 8.5% both the retrieval and translation components.
withretrievedexamples. Moreover,ourspeech- First,theretrievaltaskiscomplicatedbythevari-
to-speechretrievalapproachoutperformsother abilityofspeechandthelocalityofrarewords. As
modalitiesandexhibitshigherrobustnesstoun- thespeakingconditionforthesamerareworddif-
seenspeakers. Ourcodeispubliclyavailable1.
fersineveryutterance,source-sidefeaturematch-
ingasoftendoneintexttranslation(Zhangetal.,
1 Introduction 2018;BulteandTezcan,2019;Xuetal.,2020;Cai
et al., 2021; Hao et al., 2023) is not sufficient to
Speechtranslation(ST)traditionallyinvolvescas-
handlethepronunciationvariations. Moreover,as
cading automatic speech recognition (ASR) and
rare words only constitute a small portion of the
machine translation (MT) (Stentiford and Steer,
queryandcandidateutterances,theretrievermust
1988; Waibel et al., 1991) to convert spoken lan-
be able to locate the relevant information in long
guage into text ina different language. However,
speechutterances. Forthetranslationmodel,inte-
recent years have witnessed rapid progress in di-
gratingretrievedutterance-translationpairsisalso
rectSTmodels(Anastasopoulosetal.,2021,2022;
non-trivial. Standardmodelstrainedonsentence-
Agarwaletal.,2023)thatbypassintermediatetext
leveldatarequireadaptationtoingesttheexamples.
representationsforlowerinferencelatencyandre-
Besidesprocessinglongerinputs,theyalsoneedto
ducederrorpropagation(SperberandPaulik,2020).
pinpointboththeacousticfeaturesandcorrespond-
1':SiqiLii/Retrieve-and-Demonstration-ST ingtextualtranslationsofrarewords.
*Equalcontribution Addressingtheabovechallenges,weintroducea
4202
peS
31
]LC.sc[
1v90090.9042:viXraST Model Training Retriever Training
Parameters are frozen
Example sentence Parameters are finetuned from pre-trained model
Original sentence
ùë¢!: ùë¢: ùë¢!:
ùë¶ um!: T ‚Ä¶ ipA peu rf .hebens ùë¶ H" yb# r: i d‚Ä¶ a d ue tos s K ua nu dfs von Text ino pr ut Query Input Candidate Input that contains
the same rare word as query
Latent Representation of
Transformer Query Input
Encoder (ST) ùë¢": L Ca at ne dn it d R ae tp er Ie ns pe un ttation of ‚úïM
or
Transformer Text input
Decoder (ST)
‚úïN
Inference
ùë¢!: ùë¢:
ùë¶!: ‚Ä¶ Aufhebens ùë¶: ‚Ä¶ des Kaufs von ùë¢!:
um Tipper. H ùë¶yb "r #idautos u ùë¶n #d Tipper. Retriever ùë¶ Te! c:
h
n‚Ä¶
o
sg plo hb √§a rl ee
.
ùë¶ Te! c:
h
‚Ä¶
no
g slo pb ha √§l re
e .
}Prefix
No LosP s r Ce ofi mx puted Cross Entropy Loss Query ùë¢: ùë¶ ga: n‚Ä¶ zd ea Tr eu cn ht ner o sh pa htt √§e rn e .wir die }Prediction
Figure 1: Proposed retrieval-and-demonstration framework: At the ST model training stage (¬ß2.1), example-
prependedtrainingdataisusedtoinstillin-contextlearningabilitiesintheS2Tmodel. Attheretrievertraining
stage(¬ß2.2),SONARencodersarefine-tunedwithintheDPRarchitectureforourrarewordtask. Attheinference
stage(¬ß2.3),retrievedexamplesareusedasdemonstrationstofacilitatethetranslationofrarewords.
retrieval-and-demonstrationframework(Figure1) 2 ProposedFramework
effectiveforimprovingrarewordtranslationaccu-
Ourretrieval-and-demonstrationframeworkisillus-
racyofSTmodels. Specifically,weadaptstandard
tratedinFigure1. First,atraineddirectSTmodel
STmodelstobenefitfromprependedexamplesin
isfinetunedtoingestexamples(¬ß2.1),whichserve
awaysimilartoin-contextlearning(Brownetal.,
asdemonstrationsofcorrectlytranslatingtherare
2020),andthenbuildaretrievertofindsuitableex-
wordsinquestion. Duringinference,givenanut-
amples. Buildingonrecentmulti-modalencoders
terancecontainingrarewords,weretrieve(¬ß2.2)a
(Duquenneetal.,2023),theretrieversupportsmul-
relevant utterance and its translation as a demon-
tiple modalities (speech‚Üíspeech, speech‚Üítext,
strationtoguidetheinference(¬ß2.3).
text‚Üítext). Second, we propose an evaluation
methodologytoadaptstandardSTcorpora,MuST-
2.1 AdaptingSTModelstoIngestExamples
C(DiGangietal.,2019)inthiscase,fortargeted
Motivation Humantranslatorsoftenleverageex-
assessment of rare words translation (¬ß3.1). Our
ampletranslationsalsoknownastranslationmem-
mainfindingsare:
ory(Bowker,2005),especiallyfordomain-specific
‚Ä¢ StandarddirectSTmodelscanbeeasilyadapted
translationwithterminologies(Brkic¬¥ etal.,2009).
tobenefitfromprependedexamplesforrareword
We aim to apply a similar approach to direct ST
translation,inawaysimilartoin-contextlearn-
models. The underlying idea mirrors that of in-
ing(¬ß4.1). Thisimprovesrarewordtranslation
contextlearning(ICL)(Brownetal.,2020),where
accuracy over the baseline by 17.6% with gold
providingmodelswithtask-specificexamplesdur-
examplesand8.5%withretrievedexamples.
inginferenceimprovesthequalityofthegenerated
‚Ä¢ Text-to-text information retrieval architectures
output. WhileICLhasbeenprimarilyobservedon
(Karpukhin et al., 2020) can be effectively
text-based LLMs (Brown et al., 2020; Min et al.,
adapted for speech-based rare word retrieval,
2022;Vilaretal.,2023),weexplorewhethersmall-
yielding33.3%to46.6%top-1retrievalaccuracy
or medium-sized encoder-decoder-based speech
underdifferentmodalities(¬ß4.2).
translationmodelscanalsoexhibitthiscapability.
‚Ä¢ Comparedtoothermodalities,speech-to-speech
retrievalleadstohigheroveralltranslationquality Training ToadaptstandardSTmodelstoingest
andrarewordtranslationaccuracy(¬ß4.3),aswell examples, the example utterance and translation
asmorerobustnesstounseenspeakers(¬ß5.1). must be included as context for training and in-
!
Frontend
Frontend
Encoder
Encoder
Speech/Text
Speech/Text
Sonar
Sonar
Encoder
Encoder
Speech/Text
Speech/Text
Sonar
Sonar
representation
representation
Candidate
Query
‚úïM
Encoder
(ST)
Transformer
Similarity Dot-Product
‚úïN
Decoder
(ST)
Transformerference. An intuitive approach is to include the whererelevantanswersareretrievedgivenaques-
example as prefix in both input and output, as tion, we take inspiration from IR approaches for
shownintheleftsideofFigure1,Thisallowsthe our retriever. In text-to-text IR, a prominent ar-
outputgenerationtobeconditionedontheexam- chitecture is the Dense Passage Retriever (DPR)
pleutteranceandtranslationascontext. Formally, (Karpukhin et al., 2020). It has a dual-encoder
givenanutteranceu,letyÀÜbethetargettranslation architecture,whereoneencoderencodestheques-
and y the predicted translation. Let (ue,ye) be tions, and the other encodes the passages poten-
an example utterance-translation pair. We aim to tiallycontaininganswerstothequestions. There-
adapt an ST model so that the model maximizes trievalmodelistrainedwithacontrastiveobjective,
the probability of generating the correct transla- mapping question-passage (positive) pairs closer
tion yÀÜ, given the input utterance u and example to each other in the latent space while pushing
(ue,ye) : y = argmax P(yÀÜ|ue,ye,u). The dif- irrelevant(negative)pairsfurtherapart. Duringin-
yÀÜ
ferencetothestandardtrainingisthattheexample ference,passagesclosertotheencodedquestionby
(ue,ye)isincludedascontextwhengeneratingthe thedot-productsimilarityarereturnedasanswers.
target translation. For the training data, for the i- Inourcase,theutterancescontainingthesamerare
th training utterance u , an example utterance ue words are considered positive pairs, while those
i i
is prepended to it, forming a concatenated input notsharingthesamerarewordsarenegativepairs.
ue + u .2 The targets are also concatenated as
i i
ye +<SEP>+y , where <SEP> is a special token Speech-to-Speech/Text Retrieval We propose
i i
indicating the separator between sentences. Dur- toextendtheDPRmodeltosupportqueryingfrom
ing training, the loss is only calculated on y to speech. Astheexampleutterancestoberetrieved
i
prioritizethetranslationoftheutteranceafterthe oftenalsohavetexttranscriptsavailable,wecon-
example.3 Indoingso,weencouragethemodelto siderthefollowingretrievalmodalities:
predict its outputs based on the context provided ‚Ä¢ Speech‚Üíspeech retrieval: we retrieve ue in
bythedemonstrationexample. speechusingaudioqueryu.
‚Ä¢ Speech‚Üítext retrieval: we retrieve ye directly
2.2 ExampleRetrieval
usingaudioqueryu. Thisrequirestheretriever
FormalizationandChallenge Givenaqueryut-
tosupportbothmodalities(textandspeech).
terance u containing a rare word w, we aim to
‚Ä¢ Na√Øvetext‚Üítextretrieval: firsttranscribingthe
retrievearelevantexample(ue,ye)fromanexam-
queryutteranceuandthentext-to-textretrieval
plepoolD = {(u1,y1),...,(um,ym)}withare- for ye. As discussed before, the risk of ASR
trievalmodelr,suchthattherarewordwisspoken
errors especially on rare words renders this ap-
inutteranceue. Hereui indicatesthei-thutterance
proachsuboptimal. Theadditionalinferencetime
and yi its translation. As the query u is only in
forrunningASRmakesitfurtherunpractical.
speech,wefaceadditionalcomplexitiescompared
Given these requirements, instead of initializing
to text-based retrieval. First, speech is versatile,
thedualencoderswithpre-trainedBERT(Devlin
unliketext,whichoftenhasastandardwritingsys-
et al., 2019) as in DPR (Karpukhin et al., 2020),
tem. The speaking condition for the same word
weleveragerecentspeech-textjointrepresentation
varies in every recording, requiring a robust re-
modelsincludingSONAR(Duquenneetal.,2023)
trieverthataccountsforpronunciationvariations.
andSpeechT5(Aoetal.,2022).
Second, speech sequences are magnitudes longer
thantext. Theretrievermustfindfine-grainedlo-
2.3 IntegratingExamplesintoSTModel
calfeaturescorrespondingtothekeywordsinlong
sequences. Third,transcribingthequeryutterance InferencewithRetrievedExamples Duringin-
firstandthenusingtext-basedretrievalissubopti- ference, the model is provided with a test input
malduetoASRerrors,especiallyonrarewords. u and a retrieved example (ue,ye). The example
is prepended to test input in the same way as in
Architecture As the nature of our example re-
training. The example input-output pairs are in-
trieval task resembles information retrieval (IR)
tegrated by forced decoding. After the separator
2Detailsonconstructingthedatasetisin¬ß3.1.
token(<SEP>),themodelstartstoautoregressively
3Includingthelossontheprefixleadsthefinetuningstep
generate the output translation, conditioned addi-
toendprematurelyinpreliminaryexperiments.Thelosscal-
culationisformallydescribedinAppendixA. tionallybytheexampleutteranceandtranslations.PracticalConsiderations Anadvantageofour jointdev/tstsetrespectively,whichcreatesazero-
frameworkisitsmodularity. Theseparationofthe shotconditionwheretherarewordisneverseenin
STandretrievalmodulesenablesstraightforward training. For rare words occurring thrice, we fol-
upgrades to newer models in either component. lowthesamestrategyfortwooccurrences. There-
Moreover,theretrievalmodulecanbeimplemented mainingthirdoccurrenceisretainedinthereduced
usinghighlyoptimizedtoolkitslikeFAISS(John- trainingsettocreateaone-shotlearningscenario,
sonetal.,2021),whichensuresefficientretrieval where the rare word is seen once in the training
withoutcompromisinginferencespeed. Prepend- set. Finally,theaggregateddev/tstsetissplitinto
ingexampleshoweverleadstoincreasedinference individualdevelopmentandtestsetsforstandard
latencyasdiscussedin¬ß5.5. evaluation. Weanalyzetherarewordtypesintst-
rare-word by a named entity recognition (NER)
Avg.utt. Avg.# #unique model4 with results in Table 2. A more detailed
Split #utt.
duration(s) tokens rarewords categorizationofthewordsisinAppendixB.
train(original) 250942 6.5 27.1 9512
tst-COMMON 2580 5.8 25.3 157
tst-rare-word Person Location Tech Food Company
rare-wordpool 9821 9.7 43.1 8679
2358 130 72 29 27 25
dev-rare-word 6932 9.9 42.8 6244
tst-rare-word 2500 9.9 43.1 2358
train-reduced 231689 6.2 25.8 3164 Table2:NERresultsonrarewordsintst-rare-wordwith
thenumberofuniquewordsineachcategory.
Table1: Datasetstatistics. Wesplittheoriginaltraining
set into the example pool with rare words (rare-word
Training Data with Prepended Examples To
pool),dev/testsetsforrarewords(dev/tst-rare-word),
adapt the ST model and to train the retriever, we
andareducedtrainingset(train-reduced). Theexample
poolsimulatesexistingresourcesforquerying. need training data with prepended examples. As
mostutteranceslackrarewordsbythepreviously
used corpus-level frequency (3164 rare words in
3 ExperimentalSetup 231kutterancesinTable1),wetraintheretriever
onsimulateddatabytreatingwordsthathavethe
3.1 DatasetConstruction
lowestcorpus-levelfrequencyineachsentenceas
Forevaluation,weusetheEnglish-to-Germansub- simulated rare words. Specifically, we propose
setoftheMuST-Cdataset(DiGangietal.,2019), to use sentence-level rare words to choose the
wherethetaskistotranslatefromEnglish-public prepended examples. For each piece of the train-
speakingaudiotoGermantext. Tocreateatargeted ingdata(ui,si,yi),weidentifythewordw s insi
testconditionforrarewords,weextractsentences thathastheleastcorpus-levelfrequencyamongall
containing rare words from the original training words in its transcript. We then sample another
set to create dedicated sets. The statistics of the traininginstance(uj,sj,yj)wheresj containsthe
originaldatasetandthenewlycreatedsplitsarein samesentence-levelrarewordw s asexample. In
Table 1. The rare-word sets have higher average short, the retriever is trained without rare word
tokencountsdueto: 1)longerutteranceduration retrievaldata. Inthiszero-shottrainingsetup,the
and2)therarewordsbeingsegmentedintofiner- retrievalaccuracyislimitedbythestrongmismatch
grained subwords. Note that we only re-split the betweenthetrainandtestconditions.
trainingset,leavingtheofficialvalidationandtest
TestSetwithGoldExamples Wealsoconstruct
sets (tst-COMMON) unmodified. Below we de-
avariantoftst-rare-wordsetwithgoldexamples,
scribethedatasetconstructionprocessindetail.
wheretherarewordinthetestutteranceisalways
present in the example. This serves as an oracle
Rare Word Sets Our data partition step is in-
conditionforevaluatingtheSTmodel‚Äôsabilityto
spiredbyNiehues(2021),whichre-splitsparallel
learn from perfect demonstrations. As our data
databasedonwordfrequencies. Specifically,from
splittingprocedureensuresthattherarewordsalso
theEnglishtranscript,wefindrarewordsbytheir
occur in the example pool, we select sentences
corpus-levelfrequency,choosingthoseappearing
fromtherare-wordpoolcontainingthesamerare
twoorthreetimesintheoriginaltrainingset. For
wordsasthoseinthetst-rare-wordsettoserveas
rare words occurring twice, we move their corre-
spondingutterancestotherare-wordpoolandthe 4HuggingfacemodelbyZaratianaetal.(2023)example sentences. The example sentences are (Reietal.,2020)6. Fortheaccuracyofrareword
thenprependedtotestsentencesinawayidentical translation,weevaluatehowmanyuniquelemma-
tothatinthetrainingsetwithprependedexamples. tizedrarewordsinthetestsetaretranslated. We
use the spaCy toolkit (Honnibal et al., 2020) for
3.2 ModelConfiguration
wordlemmatizationandusedAWESoMEAligner
STModel WeusetheTransformerarchitecture (DouandNeubig,2021)foren-deword-levelalign-
S2T_TRANSFORMER_S in FAIRSEQ S2T (Wang ment. For rare word accuracy, we further distin-
et al., 2020) for all our ST models. To prevent guishbetweenrarewordsappearingonceornever
thetokenizerfromseeingtherarewordsduringits appearinthetrainingset(¬ß3.1),whichcorresponds
training,whichwillcauseanunfairtestcondition, to the one-shot and zero-shot accuracy. For the
wetraintheSentencePiece(KudoandRichardson, retriever, we use top-1 retrieval accuracy to eval-
2018) tokenizer on the reduced train set after the uate the retriever‚Äôs performance. Only the first
utterancescontainingrarewordsaremovedtoded- retrievedexamplesareusedasdemonstrationsin
icated splits (Table 1). Based on this vocabulary, theSTmodel.
we train the base model on the train-reduced set,
EvaluationDifficulty Asdescribedin¬ß3.1,our
closelyfollowingthehyperparametersfromWang
rare word sets are based on rare words from the
et al. (2020). We then adapt the base model to
source-sideEnglishtranscripts.7 Duetotheflexi-
ingestexamplesasdescribedin¬ß2.1usingthere-
bilityoftranslation,evenwithgoldexamples,some
ducedtrainingsetwithprependedexamples(¬ß3.1).
rarewordsaretranslateddifferentlyintheexample
Astheprefixtokensdonotcontributetotheoverall
translation versus the reference translation of the
loss(Figure1),wedoubletheeffectivebatchsize
actualtestsentence. Only845ofthe2500unique
tokeepthelossscalecomparabletobefore. Further
wordsaretranslatedtoidenticaltargetwordswhen
detailsontrainingandinferenceareinAppendixC.
usinggoldexamples. Therefore,thehighestpossi-
Retriever We use the DPR (Karpukhin et al., bleaccuracyis33.8%giventhisstrictevaluation.8
2020)architecturefortheretriever. Theencoders
4 MainResults
areinitializedwitheitherSONAR(Duquenneetal.,
2023) or SpeechT5 (Ao et al., 2022). For both
Beforepresentingtheresultsofourproposedframe-
models, we use the encoder only and discard the
work,weconfirmthatourbaselinemodelperforms
decoder. DPRrequiresfixed-sizeembeddingsfrom
on par with those reported in the literature. The
its encoders. For SpeechT5, we mean-pool over
detailsareinAppendixE.
thesequencelength. ForSONAR,weusethebuilt-
in attention-pooling for the speech encoder and 4.1 ImpactofDemonstration
mean-pooling for the text encoder. The dual en-
Direct ST models can effectively learn from
codersinDPRaretrainedonthereducedtraining
demonstration at inference time. To indepen-
setwithprependedexamples. Eachsentence‚Äôsex-
dentlyanalyzetheSTmodel‚Äôsabilitytolearnfrom
ampleservesasapositiveexample,whileexamples
theprependedexamples,wefirstassumeanoracle
fromothersentencesinthebatcharein-batchnega-
retrievalmodelbyusinggoldexampleswhichal-
tives. Onlythetoplayeroftheencodersistrained,
wayscontaintherarewordsinquestion. Theresults
as the lower layers of the encoders are likely re-
areinrow(2)ofTable3. Comparedtothebaseline
sponsibleforextractinglow-levelacousticfeatures.
inrow(1),thismodelachievessubstantiallyhigher
Thesefeaturesareconsideredlessrelevantforour
overall rare word translation accuracy (+17.6%
retrieval task, which focuses on word-level infor-
abs.),withalargergaininzero-shot(+18.8%)than
mation. Another reason is memory efficiency in
one-shot accuracy (+15.3%). Nonetheless, this
training. Furtherdetailsontrainingandinference
gaincomesatthecostofoveralltranslationquality
areinAppendixD.
6with Unbabel/wmt22-comet-da; √ó100 for readability.
3.3 Evaluation TheCOMETmodelstaketexttranscriptsassource.
7Constructingthesesetsbasedontarget-siderarewords
Metrics We evaluate speech translation quality
wouldbeunrealisticsincethetargetisunavailableinpractice.
withBLEU(Papinenietal.,2002)5 andCOMET 8Ideally,beyondlexicalmatches,synonymsandotheral-
ternativetranslationsshouldalsobeconsidered.Astheeval-
5sacreBLEU(Post,2018)signature: uationofthesecasesisnon-straightforward,wechoosethe
nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2 strictlexicalevaluation.Overall 0-shot 1-shot
STModel BLEU COMET
acc(%) acc(%) acc(%)
(1)baselinemodel(ontrain-reduced) 17.2 57.9 11.8 11.0 13.3
(2)adapted+goldexample 17.0 55.6 29.4 29.8 28.6
(3)adapted+randomexample 15.7 53.2 8.8 8.4 9.7
(4)trainon{train-reduced+rare-wordpool}(moredata) 17.9 59.0 15.5 14.7 17.2
Usingretrievedexamples
(5)adapted+text(goldtranscript)‚Üítext 15.2 54.4 20.1 19.6 21.2
(6)adapted+speech‚Üítext 15.3 54.0 18.8 18.2 20.2
(7)adapted+speech‚Üíspeech 16.2 55.3 20.3 20.3 20.2
Table 3: Translation quality (BLEU‚Üë, COMET‚Üë) and rare word accuracy‚Üë (overall, 0- and 1-shot) of different
modelsonthetst-rare-wordsplit. Thelowersectionusesretrievedexamplesfromtheretriever(¬ß4.3).
(‚àí0.2BLEU,‚àí2.3COMET).Apotentialreason RetrievalModel T‚ÜíT S‚ÜíT S‚ÜíS
isthattheprependedexamplesentencesmakethe
(1)Orig.DPRw/BERT(pretrained) 2.0 ‚àí ‚àí
inputsequencesmuchlongerandthereforecreate (2)Orig.DPRw/BERT(finetuned) 55.8 ‚àí ‚àí
(3)DPRw/SpeechT5(finetuned) 0.1 0.0 0.0
more difficulty for learning. Nonetheless, since
(4)DPRw/SONAR(pretrained) 28.7 22.3 20.6
rarewordsareoftenimportantnamedentities,cap- (5)DPRw/SONAR(finetuned) 46.6 33.3 41.3
turingthemcorrectlyisascrucialifnotmorethan
theoveralltranslationqualityscores. Overall,the Table4:Top-1retrievalaccuracy(%)ofdifferentretriev-
results suggest that task-specific demonstrations erson3modalitiesoftext-to-text(T‚ÜíT),speech-to-text
(S‚ÜíT), and speech-to-speech (S‚ÜíS) on the tst-rare-
providedatinferencetimecaneffectivelyenhance
wordsplit.T‚ÜíTretrievalusesgoldtranscriptsasquery.
rarewordtranslationaccuracyofdirectSTmodels.
Quality of the given demonstration matters. 4.2 RetrievalPerformance
Next, we study the impact of the demonstration
BeforeintegratingretrievedexamplesintotheST
quality. In contrast to the gold examples before,
model,weanalyzetheretrievalperformancealone
wenowuserandomexamplesthatdonotcontain
with results in Table 4. To establish the upper
rarewordsrelevanttothesentencetobetranslated.
bounds of retrieval performance, we first use the
The results are in row (3) of Table 3. This led to
originalDPRmodelfortext-to-textretrievalwith
adeclineintranslationquality(‚àí1.3BLEU,‚àí2.4
goldtranscriptsofthequeryutterancesandexam-
COMET) and rare word accuracy. These results
ples. Asshowninrow(1)ofTable4,directlyusing
indicatethatirrelevantdemonstrationsareharmful.
thepretrainedDPRforQAisnotsufficientforour
taskofrarewordretrieval. Fine-tuningDPR‚Äôsen-
Seeingrarewordsonlyintrainingdoesnotsuffi-
coders(row(2))onourtaskenableseffectiverare
cientlyimprovetheirtranslationaccuracy. In-
wordretrievalinatext-to-textsetting(55.8%).
steadofretrievingdatafromtherare-wordpoolas
demonstration,asimplealternativeistoaddthese Encoderchoiceiscrucialforsuccessfulretrieval.
dataintraining. Here,weaddtherare-wordpool We proceed by adapting the original DPR to re-
intothetrainingsetandtrainanidenticalmodelto trieval from speech. Overall, we notice that the
thebaseline. Theresultsareinrow(4)ofTable3. choiceoftheencoderheavilyimpactstheretrieval
Overall,therarewordaccuracyonlyseesaslight performance. WithSONAR,usingthepretrained
increasecomparedtorow(1),withanabsoluteac- encodersalreadyachievespartialsuccessinfulfill-
curacyimprovementof3.7%,whichisfarlessthan ing the task (row (4) in Table 4), with finetuning
using gold example sentences (+17.6% overall). furtherimprovingtheresults(row(5)). However,
Thisindicatesthattrainingwithrarewordsalone finetuningSpeechT5provesinsufficientforlearn-
isinsufficientforimprovingtheirtranslationaccu- ing the task (row (3)). We believe that the dis-
racy. Thisislikelybecauseofthelimitedtraining crepancyprimarilyarisesfromthemodels‚Äôability
signal for rare words, as each appears only once toaggregateinformationoverthesentencelength:
or twice. Note that the translation quality scores SONAR is explicitly trained to aggregate it into
underthisdataconditionalsoimproved,whichis fixed-sizeembeddingswhileSpeechT5lackssuch
likelyaresultoftheadditionaltrainingdata. amechanism. Na√Øvemean-poolingoversequencelengthfailstocreatemeaningfulembeddingsover tation(Saonetal.,2013),wherethemodelbenefits
long sequences like speech, as well as character- fromadaptingtothespecificspeaker‚Äôsvoicechar-
leveltextrepresentationsusedinSpeechT5. acteristics. Totestthis,weanalyzetheproportion
ofretrievedsentencesfromthesamespeakeracross
Speech‚Üíspeech outperforms speech‚Üítext re-
differentretrievalmodalities. TheresultsinTable5
trieval. While we initially expected speech-to-
show similar percentages for all three scenarios,
speechretrievaltobemorechallengingthanspeech-
indicating that the gains by speech-to-speech re-
to-textretrievalduetothehighvariabilityofspeech,
trievaldonotstemfromspeakeradaptation.
the finetuned retriever in (5) of Table 4 shows
strongerperformanceonspeech‚Üíspeechretrieval
DRP+SONARfinetuned T‚ÜíT S‚ÜíT S‚ÜíS
thanspeech‚Üítext(41.3%vs. 33.3%). Wesuppose
Examplesfromsamespeaker(%) 50.3 53.4 50.2
that the reason is the modality gap between text
and speech, which makes it more challenging to
Table5:Proportionofretrievedexamplesfromthesame
bridgethetwodifferenttypesofdata.
speaker as the utterance to be translated for the three
retrievalmodalitiesontst-rare-word.
4.3 STPerformancewithRetrievedExamples
Correlation between retrieval accuracy and
translation quality: As the retriever based on 5 FurtherAnalysesandDiscussions
finetunedSONARshowedthemostpromisingre-
5.1 EffectsonUnseenSpeakers
trievalresults(Table4),weusetheretrievedexam-
Nowwepushtheapproachfurtherunderthechal-
plesfromthismodeltoguidetheST.Theresults
lenging scenario of unseen speakers, i.e., the ex-
areinrows(5),(6),and(7)ofTable3. Whencom-
ample pool does not contain any utterance from
paringtheperformanceofthethreeretrievalmodal-
thespeakerofthetestutterance. Specifically,dur-
ities, retrievalaccuracydoesnotalways translate
ingretrieval,weignoreutterancesfromthesame
toimprovedoveralltranslationqualityorrareword
speaker as the query utterance. As shown in Ta-
accuracy. Althoughtext-to-textretrievalusinggold
ble 6, this harms retrieval accuracy substantially,
transcriptshadthehighestretrievalaccuracy(Ta-
losing 14.9% to 23.4% compared to Table 4 for
ble 4), its integration into the ST model resulted
thethreemodalities. Thisismainlyduetothelim-
in lower translation quality compared to speech-
itedcoverageoftherare-wordpool,whichcontains
to-speechretrieval. Moreover,inpractice,westill
onlyonesentenceformostrarewords. Excluding
need an ASR model to derive the transcripts that
thespeakeralsoexcludestherareword. However,
likelycontainerrors,especiallyonrarewords. This
theBLEUscoresandoverallrarewordtranslation
introducesadditionallimitationstothetext-to-text
accuracychangeonlyslightlycomparedtoTable3:
retrievalapproach. Overall,theseresultsshowthat
T‚ÜíT(‚àí0.6BLEU,‚àí1.5%),S‚ÜíT(‚àí0.3BLEU,
speech-speechretrievalismoreeffectivethanthe
‚àí3.2%),S‚ÜíS(+0.2BLEU,‚àí1.0%). Thisdemon-
othermodalitiesinimprovingrarewordtranslation
strates that our approach, especially when using
accuracy. Despite the improvement in rare word
speech‚Üíspeechretrieval,isrelativelyrobusttoun-
translationaccuracy,wealsonotethedropintrans-
seenspeakers.
lation quality compared to the baseline (row (7)
vs. (1); ‚àí1.0 BLEU and ‚àí2.6 COMET). We ex-
Retrieval Retrieval Overall 0-shot 1-shot
pectthatincreasingtherobustnessoftheSTmodel BLEU
modality acc(%) acc(%) acc(%) acc(%)
to examples containing incorrect rare words, for
(5)T‚ÜíT 23.2 14.6 18.6 18.5 18.7
instance by including such examples in training,
(6)S‚ÜíT 18.4 15.0 15.6 15.6 15.7
couldmitigatethisnegativeimpact. (7)S‚ÜíS 23.5 16.4 19.3 18.8 20.2
Doesspeech‚Üíspeechretrievalhelpbyimplicit
Table6:RetrievalandSTperformanceonunseenspeak-
speakeradaptation? Speech-to-speechretrieval ers. ComparedtoTable3,S‚ÜíSretrievalhastheleast
could be particularly effective in finding same- decreaseintranslationqualityandrarewordaccuracy.
speaker utterances due to the access to acoustic
information. This raises the hypothesis that if
5.2 QualitativeExample
the prepended example originates from the same
speakerastheutterancetobetranslated,translation Table7showsanexamplewhereourapproachcre-
qualitycouldbeimprovedbyimplicitspeakeradap- atespartiallycorrecttranslationforthenameden-tities‚ÄúPatriceandPatee‚Äù. Toavoidcherry-picked isstillnotsubstantialcomparedtothetop-1result.
results, we include more examples where our ap- Includingmultipleexamplesalsomakesinputse-
proachsucceedsandfailsinAppendixF. quences significantly longer, especially as audio
inputs are factors longer than text. This not only
Source(transcript):PatriceandPateesetoutmostdaysto posesachallengeforthemodelbutwouldalsosig-
goouthuntingintheforestaroundtheirhomes.
nificantlyslowdowntheinferencespeed,whichwe
Baseline(Table3row(1)):DieB√§umeundPetes(Trees
aimtoavoid. Forthesereasons,wedonotfurther
and Petes) setzten die meisten Tage hinaus, um in den
W√§ldernumihreH√§userzupumpen. explorethepotentialofusingmoreexamples.
Addingrare-wordpooltotraining(Table3row(4)):
Patrizinpathie(Patrizinpathie)setztesichindenmeisten
TagenumdieJagdindenW√§ldernumihreH√§user. DPR+SONARft. T‚ÜíT S‚ÜíT S‚ÜíS
Speech‚Üíspeechexample(Table4row(5)):Siehei√üen
Top1 46.6 33.3 41.3
PatriceundPatee(TheirnamesarePatriceandPatee.).
Top5 60.4 48.0 56.2
AdaptedST+speech‚Üíspeech(Table3row(7)):Patrice
Top10 64.6 53.1 61.1
undPateeteesetztendiemeistenTage,umindenW√§ldern
umihreH√§userherumjagenzuk√∂nnen.
Target: PatriceundPatee(PatriceandPatee)gehenfast Table 8: Top-10 retrieval performance (%) of the
jedenTagjagenindemWaldrundumihrHeim. SONAR-basedretrieveronthetst-rare-wordset.
Table7: Anexampleofourretrieval-and-demonstration
approachimprovingthetranslationofrarewords. 5.5 InferenceLatencyofIncludingExamples
Adownsideofourapproachistheadditionalinfer-
encelatencyduetolongerprefixes,asinherentin
5.3 AnalysesofRetrievalPerformance
other vanilla in-context learning approaches. On
Inourmainexperiments,wepartiallyfinetunedthe the same GPU (NVIDIA Titan RTX) with batch
DPRencoders. Wenowinvestigatetheimpactof size 1, the average inference time is 0.35s per
different numbers of trainable parameters in the sentence (system in Row 1, Table 3) and 0.82s
retriever. As shown in Figure 2, the retrieval per- after adding examples (average of the systems
formanceoftheSONAR-basedretrieverisstable in Row 2-7, Table 3). The main contributor of
across100to500Mtrainableparametersoutofa the additional latency is the roughly doubled in-
totalofover1.3Bparameters. Thisindicatesthat put sequence length. The text prefixes from the
theretrievercanmaintainnearlyconsistentperfor- prepended examples are incorporated by forced
mancedespitechangesinmodelcapacity. decodinganddonotincurmuchlatency.
5.6 PotentialofUsingChunk-BasedExamples
100 text-text retrieval Our in-context examples are in the form of par-
speech-text retreival speech-speech retrieval allel data. An alternative is to use chunks in-
80
text-text retrieval(original DPR)
stead of unprocessed parallel data. In this case,
60 55.8 as the source and target of the in-context exam-
43.9 pleshavetobealigned,creatingthechunk-based
40 38.0 40.4 41.3 46.6 example pool requires two additional alignment
33.0 33.3
28.9 29.9 steps: audio-transcript alignment and transcript-
20
translation alignment. While both steps have es-
0 tablishedoff-the-shelftools,thissignificantlycom-
0 100 200 300 400 500 600
Trainable Parameters (Millions)
plicates the workflow. Increasing the number of
Figure2: RetrievalperformanceoftheSONAR-based retrievalcandidatesmayalsoincreasethedifficulty
retrieverfordifferentnumbersoftrainableparameters. of the retrieval task. A main advantage of using
chunksisthereducedinferencelatencyasthepre-
fixesareshorter. Moreover,shortercontextmaybe
5.4 PotentialofUsingMoreExamples
easierforthemodeltolocateandutilize. Weleave
Few-shot learning is more often performant than theexplorationofthisalternativeforfuturework.
one-shot learning because it provides the model
5.7 ReusingSTEncoderforRetrieval
withabroadercontextandmorevariedexamples.
However, asshowninTable8, theincreaseinre- In our main experiments, we use SONAR for re-
trieval accuracy with additional top-10 examples trieval. An attractive alternative is to use the en-
)%(
)tes
drow-erar-tst(
egatnecreP
deveirteRcoderofpretrainedSTmodelsforretrieval,which 2023),andcontextenhancementbyanadditional
woulddramaticallyreducethetotalmodelsizeat memorymodule(Bruguieretal.,2019;Jainetal.,
inference. However, based on our comparison to 2020;Changetal.,2021;Huberetal.,2021;Qiu
usingtheSpeechT5encoderforretrieval(Row3, etal.,2022;HuberandWaibel,2024). InMT,rare
Table4)andinterpretations,modelsthatdonotex- wordtranslationhasbeentackledby,amongother
plicitlyshrinkthesequencelengthdimensioninto techniques,constraineddecoding(Chatterjeeetal.,
morecompactrepresentationsarelikelyunableto 2017;Hasleretal.,2018;Ailemetal.,2021;Zhang
perform the retrieval task. Therefore, we believe etal.,2023),copyingbysourceannotations(Dinu
theencodersofexistingSTmodelswouldneedto etal.,2019;Songetal.,2019;BergmanisandPin-
learnanaggregationmechanismlikeinSONARto nis,2021)orpointingmechanisms(Gulcehreetal.,
bereadyfortheretrievaltask. 2016; Pham et al., 2018; Gu et al., 2019; Zhang
et al., 2021), and retrieval-augmented translation
6 RelatedWork
(Martins et al., 2023; Liu et al., 2023). In direct
ST,translatingrarewordsisasignificantchallenge
Retrieval-Augmented Translation Our work
duetothecombinedcomplexitiesofASRandMT.
falls within the paradigm of retrieval-augmented
Theamountofpriorworkisalsorelativelysparse.
translation (RAT) (Simard and Langlais, 2001;
Gaidoetal.(2022)usemultilingualmodelstoim-
KoehnandSenellart,2010;Tuetal.,2018;Khan-
provetheaccuracyofnon-Englishnames. Gaido
delwal et al., 2021), which augments a transla-
etal.(2023)proposetofirstdetectnamedentities
tion model with results retrieved from a transla-
(NEs)inthesourceaudiothatarepresentinagiven
tionmemory. PriorworksonRATprimarilyfocus
contextualdictionaryandtheninjecttheseNEsin
ontext-to-texttranslation(Zhangetal.,2018;Gu
textformintothedecoder. Ourapproachdoesnot
et al., 2018; Bulte and Tezcan, 2019; Xu et al.,
assume a readily available contextual dictionary,
2020; Cai et al., 2021; Hoang et al., 2023; Hao
butcaninsteadleverageunprocessedparalleldata.
etal.,2023),whereretrievalreliesontextualfea-
turematchingsuchasn-gramoverlap. Thesemeth-
7 Conclusion
odsarethereforenotreadilyapplicabletodirectST
duetothecontinuousnatureofspeechandmuch We introduced a retrieval-and-demonstration ap-
longer input lengths. In ST, Du et al. (2022) use proachtoimproverarewordtranslationaccuracy
kNN-MT (Khandelwal et al., 2021) for domain indirectST.Forreal-worldapplications,e.g.,trans-
adaption. Thisapproachrequiresajointmodelfor lating scientific talks, we recommend adding ut-
speechandtextinput,withafullytext-baseddatas- terances from the same speaker to the example
tore. OurworkdoesnotrequiremodifyingtheST poolandusingspeech-to-speechretrievaltoiden-
model to support speech and text inputs, and en- tifyexamples. Whenfeasible,oneshouldconsider
ablestheretrievertoqueryfromspeechtospeech incorporatinganadditionalverificationsteptoen-
or text. Our retrieval module is related to the re- sure the relevance of the retrieved sentences, by
cent work by Lin et al. (2024) as both are based human-in-the-looporautomatedtechniques.
onDPR.Themaindifferenceisthattheirmodelis
Limitations
forquestionansweringanddoesnotsupportcross-
modalretrieval. Chenetal.(2024)showthatLLMs Robustness to Irrelevant Examples Our ap-
adaptedforspeechcouldleveragein-contextexam- proach effectively improves the accuracy of rare
ples for speech recognition and translation. Our wordtranslation. However,aselaboratedinthere-
work is orthogonal to theirs in that we show that sultdiscussions,wealsoobservedthatincorrectly
conventional encoder-decoder ST models can be retrievedexamplestendtoharmtranslationquality.
trainedtoexhibitin-contextlearningabilities. Asanextstep,wehopetoincreasetherobustness
oftheSTmodelstoirrelevantexamples. Thiscould
Rare Words in ASR, MT, and direct ST In
forinstancebeachievedbyincorporatingincorrect
ASR, some representative approaches to handle
rarewordsduringtrainingtoenhancethemodel‚Äôs
rare words include language model rescoring or
resiliencetosucherrors.
fusion(Rajuetal.,2019;Yangetal.,2021;Huang
et al., 2022; Weiran et al., 2022; Mathur et al., Targeted Solution for Rare Word Translation
2023),dataaugmentationbytext-to-speech(TTS) Ourapproachisatargetedsolutionfortheuse-case
(Guo et al., 2019; Zheng et al., 2021; Qu et al., of rare word translation. When there is no rarewordinthetestsentence,theexampleswillharm Turchi,AlexWaibel,MingxuanWang,ShinjiWatan-
translationquality,asseeninthecaseofusingir- abe, and Rodolfo Zevallos. 2023. FINDINGS OF
THEIWSLT2023EVALUATIONCAMPAIGN. In
relevantexamples. Whetherrarewordsexistinthe
Proceedingsofthe20thInternationalConferenceon
test sentences could be determined by ST model
SpokenLanguageTranslation(IWSLT2023),pages
confidence(decodingprobability)orretrieverdis- 1‚Äì61,Toronto,Canada(in-personandonline).Asso-
tancestotheclosestneighborintheexamplepool. ciationforComputationalLinguistics.
Weleavethisexplorationtofuturework.
MelissaAilem,JingshuLiu,andRaheelQader.2021.
LanguageCoverage Ourexperimentswerelim- Encouragingneuralmachinetranslationtosatisfyter-
minologyconstraints. InFindingsoftheAssociation
ited to the English-to-German language pair due
forComputationalLinguistics: ACL-IJCNLP2021,
toresourceconstraints. Experimentsonadditional
pages1450‚Äì1455,Online.AssociationforComputa-
languagepairs,especiallydistantones,wouldfur- tionalLinguistics.
thersubstantiatethefindings.
Antonios Anastasopoulos, Lo√Øc Barrault, Luisa Ben-
ExtensiontootherAudioTasks Thisworkfo- tivogli,MarcelyZanonBoito,OndÀárejBojar,Roldano
Cattoni,AnnaCurrey,GeorgianaDinu,KevinDuh,
cused on rare words in direct speech translation.
Maha Elbayad, Clara Emmanuel, Yannick Est√®ve,
An extension to other audio tasks would enlarge
Marcello Federico, Christian Federmann, Souhir
theimpactoftheproposedapproach. Asapartial Gahbiche, Hongyu Gong, Roman Grundkiewicz,
remedy,weperformedpreliminaryexperimentson Barry Haddow, Benjamin Hsu, D√°vid Javorsk√Ω,
VeÀòraKloudov√°,SurafelLakew,XutaiMa,Prashant
rarewordASRinAppendixGandfoundthatthe
Mathur, Paul McNamee, Kenton Murray, Maria
resultssupportthemainfindingsinthiswork.
NaÀádejde, Satoshi Nakamura, Matteo Negri, Jan
Niehues, Xing Niu, John Ortega, Juan Pino, Eliz-
Acknowledgments abeth Salesky, Jiatong Shi, Matthias Sperber, Se-
bastianSt√ºker,KatsuhitoSudoh,MarcoTurchi,Yo-
We thank the anonymous reviewers for their in- gesh Virkar, Alexander Waibel, Changhan Wang,
sightfulfeedback. WealsothankPapietal.(2024) andShinjiWatanabe.2022. FindingsoftheIWSLT
2022 evaluation campaign. In Proceedings of the
for reporting Conformer bugs which led to unex-
19thInternationalConferenceonSpokenLanguage
plainableresultsinourinitialexperiments. Partof
Translation (IWSLT 2022), pages 98‚Äì157, Dublin,
thisworkwasperformedontheHoreKasupercom- Ireland(in-personandonline).AssociationforCom-
puterfundedbytheMinistryofScience,Research putationalLinguistics.
andtheArtsBaden-W√ºrttembergandbytheFed-
AntoniosAnastasopoulos,OndÀárejBojar,JacobBremer-
eral Ministryof Educationand Research. Part of
man,RoldanoCattoni,MahaElbayad,MarcelloFed-
thisworkwassupportedbyfundingfromthepilot
erico, XutaiMa, SatoshiNakamura, MatteoNegri,
programCore-InformaticsoftheHelmholtzAsso- Jan Niehues, Juan Pino, Elizabeth Salesky, Sebas-
ciation(HGF). tianSt√ºker,KatsuhitoSudoh,MarcoTurchi,Alexan-
derWaibel,ChanghanWang,andMatthewWiesner.
2021. FINDINGS OF THE IWSLT 2021 EVAL-
UATIONCAMPAIGN. InProceedingsofthe18th
References
InternationalConferenceonSpokenLanguageTrans-
lation(IWSLT2021),pages1‚Äì29,Bangkok,Thailand
Milind Agarwal, Sweta Agrawal, Antonios Anasta-
(online).AssociationforComputationalLinguistics.
sopoulos, Luisa Bentivogli, OndÀárej Bojar, Claudia
Borg,MarineCarpuat,RoldanoCattoni,MauroCet-
tolo,MingdaChen,WilliamChen,KhalidChoukri, JunyiAo,RuiWang,LongZhou,ChengyiWang,Shuo
AlexandraChronopoulou,AnnaCurrey,ThierryDe- Ren,YuWu,ShujieLiu,TomKo,QingLi,YuZhang,
clerck, Qianqian Dong, Kevin Duh, Yannick Es- Zhihua Wei, Yao Qian, Jinyu Li, and Furu Wei.
t√®ve, Marcello Federico, Souhir Gahbiche, Barry 2022. SpeechT5: Unified-modal encoder-decoder
Haddow, Benjamin Hsu, Phu Mon Htut, Hirofumi pre-trainingforspokenlanguageprocessing. InPro-
Inaguma, D√°vid Javorsk√Ω, John Judge, Yasumasa ceedingsofthe60thAnnualMeetingoftheAssocia-
Kano,TomKo,RishuKumar,PengweiLi,XutaiMa, tionforComputationalLinguistics(Volume1: Long
PrashantMathur,EvgenyMatusov,PaulMcNamee, Papers),pages5723‚Äì5738,Dublin,Ireland.Associa-
John P. McCrae, Kenton Murray, Maria Nadejde, tionforComputationalLinguistics.
SatoshiNakamura, MatteoNegri, HaNguyen, Jan
Niehues, XingNiu, AtulKr.Ojha, JohnE.Ortega, AlexeiBaevski,YuhaoZhou,AbdelrahmanMohamed,
ProyagPal,JuanPino,LonnekevanderPlas,Peter andMichaelAuli.2020. wav2vec2.0: Aframework
Pol√°k,ElijahRippeth,ElizabethSalesky,JiatongShi, forself-supervisedlearningofspeechrepresentations.
Matthias Sperber, Sebastian St√ºker, Katsuhito Su- Advancesinneuralinformationprocessingsystems,
doh,YunTang,BrianThompson,KevinTran,Marco 33:12449‚Äì12460.TomsBergmanisandMa¬ØrcisPinnis.2021. Facilitating ConferenceonAcoustics,SpeechandSignalProcess-
terminology translation with target lemma annota- ing(ICASSP),pages13521‚Äì13525.
tions. InProceedingsofthe16thConferenceofthe
EuropeanChapteroftheAssociationforComputa- Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
tionalLinguistics: MainVolume,pages3105‚Äì3111, Kristina Toutanova. 2019. BERT: Pre-training of
Online.AssociationforComputationalLinguistics. deepbidirectionaltransformersforlanguageunder-
standing. InProceedingsofthe2019Conferenceof
LynneBowker.2005. Productivityvsquality? apilot theNorthAmericanChapteroftheAssociationfor
studyontheimpactoftranslationmemorysystems. ComputationalLinguistics: HumanLanguageTech-
nologies,Volume1(LongandShortPapers),pages
MarijaBrkic¬¥,SanjaSeljan,andBozenaBasicMikulic.
4171‚Äì4186,Minneapolis,Minnesota.Associationfor
2009. Usingtranslationmemorytospeeduptransla-
ComputationalLinguistics.
tionprocess.
MattiaA.DiGangi,RoldanoCattoni,LuisaBentivogli,
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
MatteoNegri,andMarcoTurchi.2019. MuST-C:a
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
MultilingualSpeechTranslationCorpus. InProceed-
Neelakantan,PranavShyam,GirishSastry,Amanda
ingsofthe2019ConferenceoftheNorthAmerican
Askell,etal.2020. Languagemodelsarefew-shot
Chapter of the Association for Computational Lin-
learners. Advancesinneuralinformationprocessing
guistics: HumanLanguageTechnologies,Volume1
systems,33:1877‚Äì1901.
(Long and Short Papers), pages 2012‚Äì2017, Min-
neapolis,Minnesota.AssociationforComputational
AntoineBruguier,RohitPrabhavalkar,GolanPundak,
Linguistics.
andTaraN.Sainath.2019. Phoebe: Pronunciation-
awarecontextualizationforend-to-endspeechrecog-
GeorgianaDinu,PrashantMathur,MarcelloFederico,
nition. InICASSP2019-2019IEEEInternational
and Yaser Al-Onaizan. 2019. Training neural ma-
ConferenceonAcoustics,SpeechandSignalProcess-
chinetranslationtoapplyterminologyconstraints. In
ing(ICASSP),pages6171‚Äì6175.
Proceedingsofthe57thAnnualMeetingoftheAsso-
BramBulteandArdaTezcan.2019. Neuralfuzzyre-
ciationforComputationalLinguistics,pages3063‚Äì
pair: Integratingfuzzymatchesintoneuralmachine 3068,Florence,Italy.AssociationforComputational
translation. InProceedingsofthe57thAnnualMeet- Linguistics.
ingoftheAssociationforComputationalLinguistics,
Zi-YiDouandGrahamNeubig.2021. Wordalignment
pages 1800‚Äì1809, Florence, Italy. Association for
by fine-tuning embeddings on parallel corpora. In
ComputationalLinguistics.
Proceedingsofthe16thConferenceoftheEuropean
Deng Cai, Yan Wang, Huayang Li, Wai Lam, and Chapter of the Association for Computational Lin-
LemaoLiu.2021. Neuralmachinetranslationwith guistics: Main Volume, pages 2112‚Äì2128, Online.
monolingual translation memory. In Proceedings AssociationforComputationalLinguistics.
of the 59th Annual Meeting of the Association for
ComputationalLinguisticsandthe11thInternational YichaoDu,WeizhiWang,ZhiruiZhang,BoxingChen,
JointConferenceonNaturalLanguageProcessing Tong Xu, Jun Xie, and Enhong Chen. 2022. Non-
(Volume1: LongPapers),pages7307‚Äì7318,Online. parametricdomainadaptationforend-to-endspeech
translation. InProceedingsofthe2022Conference
AssociationforComputationalLinguistics.
onEmpiricalMethodsinNaturalLanguageProcess-
Feng-Ju Chang, Jing Liu, Martin Radfar, Athanasios ing,pages306‚Äì320,AbuDhabi,UnitedArabEmi-
Mouchtaris,MaurizioOmologo,AriyaRastrow,and rates.AssociationforComputationalLinguistics.
Siegfried Kunzmann. 2021. Context-aware trans-
formertransducerforspeechrecognition. InIEEE Paul-AmbroiseDuquenne,HolgerSchwenk,andBeno√Æt
Automatic Speech Recognition and Understanding Sagot. 2023. SONAR: sentence-level multimodal
Workshop, ASRU 2021, Cartagena, Colombia, De- and language-agnostic representations. CoRR,
cember13-17,2021,pages503‚Äì510.IEEE. abs/2308.11466.
RajenChatterjee,MatteoNegri,MarcoTurchi,Marcello MarcoGaido,MatteoNegri,andMarcoTurchi.2022.
Federico, Lucia Specia, and Fr√©d√©ric Blain. 2017. Whoarewetalkingabout? handlingpersonnamesin
Guiding neural machine translation decoding with speechtranslation. InProceedingsofthe19thInter-
externalknowledge. InProceedingsoftheSecond nationalConferenceonSpokenLanguageTransla-
ConferenceonMachineTranslation,pages157‚Äì168, tion(IWSLT2022),pages62‚Äì73,Dublin,Ireland(in-
Copenhagen, Denmark. Association for Computa- personandonline).AssociationforComputational
tionalLinguistics. Linguistics.
ZhehuaiChen,HeHuang,AndreiAndrusenko,Oleksii MarcoGaido,SusanaRodr√≠guez,MatteoNegri,Luisa
Hrinchuk,KrishnaC.Puvvada,JasonLi,Subhankar Bentivogli,andMarcoTurchi.2021. Is‚Äúmobydick‚Äù
Ghosh,JagadeeshBalam,andBorisGinsburg.2024. awhaleorabird? namedentitiesandterminology
Salm: Speech-augmented language model with in- in speech translation. In Proceedings of the 2021
contextlearningforspeechrecognitionandtransla- Conference on Empirical Methods in Natural Lan-
tion. In ICASSP 2024 - 2024 IEEE International guage Processing, pages 1707‚Äì1716, Online andPunta Cana, Dominican Republic. Association for W.RonnyHuang,CalPeyser,TaraSainath,Ruoming
ComputationalLinguistics. Pang,TrevorD.Strohman,andShankarKumar.2022.
Sentence-Select: Large-ScaleLanguageModelData
MarcoGaido,YunTang,IliaKulikov,RongqingHuang,
Selection for Rare-Word Speech Recognition. In
HongyuGong,andHirofumiInaguma.2023. Named
Proc.Interspeech2022,pages689‚Äì693.
entitydetectionandinjectionfordirectspeechtrans-
lation. InICASSP2023-2023IEEEInternational ChristianHuber,JuanHussain,SebastianSt√ºker,and
ConferenceonAcoustics,SpeechandSignalProcess- Alexander Waibel. 2021. Instant one-shot word-
ing(ICASSP),pages1‚Äì5. learning for context-specific neural sequence-to-
sequence speech recognition. In IEEE Automatic
JeticGu,HassanS.Shavarani,andAnoopSarkar.2019.
Speech Recognition and Understanding Workshop,
Pointer-basedfusionofbilinguallexiconsintoneural
ASRU2021,Cartagena,Colombia,December13-17,
machinetranslation. CoRR,abs/1909.07907.
2021,pages1‚Äì7.IEEE.
Jiatao Gu, Yong Wang, Kyunghyun Cho, and Victor
Christian Huber and Alexander Waibel. 2024. Con-
O.K.Li.2018. Searchengineguidedneuralmachine
tinuously learning new words in automatic speech
translation. In Proceedings of the Thirty-Second
recognition. CoRR,abs/2401.04482.
AAAI Conference on Artificial Intelligence, (AAAI-
18), the 30th innovative Applications of Artificial
MahaveerJain,GilKeren,JayMahadeokar,Geoffrey
Intelligence(IAAI-18),andthe8thAAAISymposium
Zweig, Florian Metze, and Yatharth Saraf. 2020.
on Educational Advances in Artificial Intelligence
ContextualRNN-TforOpenDomainASR. InProc.
(EAAI-18),NewOrleans,Louisiana,USA,February
Interspeech2020,pages11‚Äì15.
2-7,2018,pages5133‚Äì5140.AAAIPress.
JeffJohnson,MatthijsDouze,andHerv√©J√©gou.2021.
Caglar Gulcehre, Sungjin Ahn, Ramesh Nallapati,
Billion-scale similarity search with gpus. IEEE
Bowen Zhou, and Yoshua Bengio. 2016. Pointing
Trans.BigData,7(3):535‚Äì547.
theunknownwords. InProceedingsofthe54thAn-
nualMeetingoftheAssociationforComputational
VladimirKarpukhin,BarlasOguz,SewonMin,Patrick
Linguistics(Volume1:LongPapers),pages140‚Äì149,
Lewis,LedellWu,SergeyEdunov,DanqiChen,and
Berlin,Germany.AssociationforComputationalLin-
Wen-tauYih.2020. Densepassageretrievalforopen-
guistics.
domainquestionanswering. InProceedingsofthe
2020ConferenceonEmpiricalMethodsinNatural
Jinxi Guo, Tara N. Sainath, and Ron J. Weiss. 2019.
LanguageProcessing(EMNLP),pages6769‚Äì6781,
A spelling correction model for end-to-end speech
Online.AssociationforComputationalLinguistics.
recognition. InICASSP2019-2019IEEEInterna-
tionalConferenceonAcoustics,SpeechandSignal
UrvashiKhandelwal,AngelaFan,DanJurafsky,Luke
Processing(ICASSP),pages5651‚Äì5655.
Zettlemoyer,andMikeLewis.2021. Nearestneigh-
Hongkun Hao, Guoping Huang, Lemao Liu, Zhirui bormachinetranslation. In9thInternationalConfer-
Zhang,ShumingShi,andRuiWang.2023. Rethink- enceonLearningRepresentations,ICLR2021,Vir-
ingtranslationmemoryaugmentedneuralmachine tualEvent,Austria,May3-7,2021.OpenReview.net.
translation. InFindingsoftheAssociationforCom-
PhilippKoehnandJeanSenellart.2010. Convergence
putationalLinguistics: ACL2023,pages2589‚Äì2605,
oftranslationmemoryandstatisticalmachinetransla-
Toronto,Canada.AssociationforComputationalLin-
tion. InProceedingsoftheSecondJointEM+/CNGL
guistics.
Workshop: Bringing MT to the User: Research on
Eva Hasler, Adri√† de Gispert, Gonzalo Iglesias, and IntegratingMTintheTranslationIndustry,pages21‚Äì
BillByrne.2018. Neuralmachinetranslationdecod- 32,Denver,Colorado,USA.AssociationforMachine
ingwithterminologyconstraints. InProceedingsof TranslationintheAmericas.
the2018ConferenceoftheNorthAmericanChap-
teroftheAssociationforComputationalLinguistics: TakuKudoandJohnRichardson.2018. SentencePiece:
HumanLanguageTechnologies,Volume2(ShortPa- A simple and language independent subword tok-
pers),pages506‚Äì512,NewOrleans,Louisiana.As- enizeranddetokenizerforneuraltextprocessing. In
Proceedings of the 2018 Conference on Empirical
sociationforComputationalLinguistics.
Methods in Natural Language Processing: System
Cuong Hoang, Devendra Sachan, Prashant Mathur, Demonstrations, pages 66‚Äì71, Brussels, Belgium.
BrianThompson,andMarcelloFederico.2023. Im- AssociationforComputationalLinguistics.
proving retrieval augmented neural machine trans-
lationbycontrollingsourceandfuzzy-matchinter- Chyi-Jiunn Lin, Guan-Ting Lin, Yung-Sung Chuang,
actions. InFindingsoftheAssociationforCompu- Wei-Lun Wu, Shang-Wen Li, Abdelrahman Mo-
tational Linguistics: EACL 2023, pages 289‚Äì295, hamed, Hung-yi Lee, and Lin-Shan Lee. 2024.
Dubrovnik,Croatia.AssociationforComputational Speechdpr: End-to-endspokenpassageretrievalfor
Linguistics. open-domain spoken question answering. CoRR,
abs/2401.13463.
Matthew Honnibal, Ines Montani, Sofie Van Lan-
deghem,andAdrianeBoyd.2020. spaCy: Industrial- Danni Liu, Thai Binh Nguyen, Sai Koneru, Enes
strengthNaturalLanguageProcessinginPython. YavuzUgan,Ngoc-QuanPham,TuanNamNguyen,TuAnhDinh,CarlosMullov,AlexanderWaibel,and MattPost.2018. AcallforclarityinreportingBLEU
JanNiehues.2023. KIT‚Äôsmultilingualspeechtrans- scores. InProceedingsoftheThirdConferenceon
lation system for IWSLT 2023. In Proceedings of MachineTranslation: ResearchPapers,pages186‚Äì
the 20th International Conference on Spoken Lan- 191, Brussels, Belgium. Association for Computa-
guage Translation (IWSLT 2023), pages 113‚Äì122, tionalLinguistics.
Toronto,Canada(in-personandonline).Association
DavidQiu,TsendsurenMunkhdalai,YanzhangHe,and
forComputationalLinguistics.
Khe Chai Sim. 2022. Context-aware neural confi-
Pedro Henrique Martins, Jo√£o Alves, T√¢nia Vaz, dence estimation for rare word speech recognition.
Madalena Gon√ßalves, Beatriz Silva, Marianna In IEEE Spoken Language Technology Workshop,
Buchicchio, Jos√© G. C. de Souza, and Andr√© F. T. SLT2022,Doha,Qatar,January9-12,2023,pages
Martins. 2023. Empirical assessment of kNN-MT 31‚Äì37.IEEE.
forreal-worldtranslationscenarios. InProceedings
LeyuanQu,CorneliusWeber,andStefanWermter.2023.
ofthe24thAnnualConferenceoftheEuropeanAs-
Emphasizingunseenwords: Newvocabularyacqui-
sociationforMachineTranslation,pages115‚Äì124,
sitionforend-to-endspeechrecognition. NeuralNet-
Tampere,Finland.EuropeanAssociationforMachine
works,161:494‚Äì504.
Translation.
AnirudhRaju,DenisFilimonov,GautamTiwari,Gui-
PuneetMathur,ZheLiu,KeLi,YingyiMa,GilKeren,
tangLan,andAriyaRastrow.2019. ScalableMulti
Zeeshan Ahmed, Dinesh Manocha, and Xuedong
CorporaNeuralLanguageModelsforASR. InProc.
Zhang. 2023. PersonaLM: Language model per-
Interspeech2019,pages3910‚Äì3914.
sonalizationviadomain-distributedspanaggregated
k-nearest n-gram retrieval augmentation. In Find-
RicardoRei,CraigStewart,AnaCFarinha,andAlon
ingsoftheAssociationforComputationalLinguis-
Lavie.2020. COMET:AneuralframeworkforMT
tics: EMNLP2023,pages11314‚Äì11328,Singapore.
evaluation. InProceedingsofthe2020Conference
AssociationforComputationalLinguistics.
onEmpiricalMethodsinNaturalLanguageProcess-
ing(EMNLP),pages2685‚Äì2702,Online.Association
SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,
forComputationalLinguistics.
MikeLewis,HannanehHajishirzi,andLukeZettle-
moyer.2022. Rethinkingtheroleofdemonstrations:
George Saon, Hagen Soltau, David Nahamoo, and
Whatmakesin-contextlearningwork? InProceed-
MichaelPicheny.2013. Speakeradaptationofneural
ingsofthe2022ConferenceonEmpiricalMethodsin
network acoustic models using i-vectors. In 2013
NaturalLanguageProcessing,pages11048‚Äì11064,
IEEE Workshop on Automatic Speech Recognition
AbuDhabi,UnitedArabEmirates.Associationfor
andUnderstanding,Olomouc,CzechRepublic,De-
ComputationalLinguistics.
cember8-12,2013,pages55‚Äì59.IEEE.
JanNiehues.2021. Continuouslearninginneuralma-
Michel Simard and Philippe Langlais. 2001. Sub-
chinetranslationusingbilingualdictionaries. InPro-
sentential exploitation of translation memories. In
ceedings of the 16th Conference of the European
Proceedings of Machine Translation Summit VIII,
Chapter of the Association for Computational Lin-
SantiagodeCompostela,Spain.
guistics: MainVolume,pages830‚Äì840,Online.As-
sociationforComputationalLinguistics. Kai Song, Yue Zhang, Heng Yu, Weihua Luo, Kun
Wang, and Min Zhang. 2019. Code-switching for
SaraPapi,MarcoGaido,AndreaPilzer,andMatteoNe-
enhancing NMT with pre-specified translation. In
gri.2024. Whengoodandreproducibleresultsarea
Proceedings of the 2019 Conference of the North
giantwithfeetofclay: Theimportanceofsoftware
AmericanChapteroftheAssociationforComputa-
qualityinNLP. InProceedingsofthe62ndAnnual
tionalLinguistics: HumanLanguageTechnologies,
Meeting of the Association for Computational Lin-
Volume1(LongandShortPapers),pages449‚Äì459,
guistics(Volume1: LongPapers),pages3657‚Äì3672,
Minneapolis,Minnesota.AssociationforComputa-
Bangkok,Thailand.AssociationforComputational
tionalLinguistics.
Linguistics.
Matthias Sperber and Matthias Paulik. 2020. Speech
KishorePapineni,SalimRoukos,ToddWard,andWei-
translationandtheend-to-endpromise: Takingstock
JingZhu.2002. Bleu: amethodforautomaticevalu-
ofwhereweare. InProceedingsofthe58thAnnual
ationofmachinetranslation. InProceedingsofthe
Meeting of the Association for Computational Lin-
40thAnnualMeetingoftheAssociationforCompu-
guistics,pages7409‚Äì7421,Online.Associationfor
tational Linguistics, pages 311‚Äì318, Philadelphia,
ComputationalLinguistics.
Pennsylvania,USA.AssociationforComputational
Linguistics. FredWMStentifordandMartinGSteer.1988. Machine
translation of speech. British Telecom technology
Ngoc-QuanPham,JanNiehues,andAlexanderWaibel. journal,6(2):116‚Äì122.
2018. Towardsone-shotlearningforrare-wordtrans-
lationwithexternalexperts. InProceedingsofthe ZhaopengTu,YangLiu,ShumingShi,andTongZhang.
2ndWorkshoponNeuralMachineTranslationand 2018. Learningtoremembertranslationhistorywith
Generation, pages 100‚Äì109, Melbourne, Australia. acontinuouscache. TransactionsoftheAssociation
AssociationforComputationalLinguistics. forComputationalLinguistics,6:407‚Äì420.DavidVilar,MarkusFreitag,ColinCherry,JiamingLuo, neuralmachinetranslationwithretrievedtranslation
VireshRatnakar,andGeorgeFoster.2023. Prompt- pieces. In Proceedings of the 2018 Conference of
ingPaLMfortranslation: Assessingstrategiesand theNorthAmericanChapteroftheAssociationfor
performance. In Proceedings of the 61st Annual ComputationalLinguistics: HumanLanguageTech-
Meeting of the Association for Computational Lin- nologies,Volume1(LongPapers),pages1325‚Äì1335,
guistics (Volume 1: Long Papers), pages 15406‚Äì NewOrleans,Louisiana.AssociationforComputa-
15427,Toronto,Canada.AssociationforComputa- tionalLinguistics.
tionalLinguistics.
Tong Zhang, Long Zhang, Wei Ye, Bo Li, Jinan Sun,
AlexWaibel,AjayNJain,ArthurEMcNair,Hiroaki Xiaoyu Zhu, Wen Zhao, and Shikun Zhang. 2021.
Saito,AlexanderGHauptmann,andJoeTebelskis. Point, disambiguate and copy: Incorporating bilin-
1991. Janus: aspeech-to-speechtranslationsystem gualdictionariesforneuralmachinetranslation. In
usingconnectionistandsymbolicprocessingstrate- Proceedingsofthe59thAnnualMeetingoftheAsso-
gies. In Acoustics, speech, and signal processing, ciationforComputationalLinguisticsandthe11th
IEEE international conference on, pages 793‚Äì796. InternationalJointConferenceonNaturalLanguage
IEEEComputerSociety. Processing (Volume 1: Long Papers), pages 3970‚Äì
3979, Online. Association for Computational Lin-
Changhan Wang, Yun Tang, Xutai Ma, Anne Wu,
guistics.
Dmytro Okhonko, and Juan Pino. 2020. Fairseq
S2T:Fastspeech-to-textmodelingwithfairseq. In XianruiZheng,YulanLiu,DenizGunceler,andDaniel
Proceedingsofthe1stConferenceoftheAsia-Pacific Willett.2021. Usingsyntheticaudiotoimprovethe
Chapter of the Association for Computational Lin- recognitionofout-of-vocabularywordsinend-to-end
guisticsandthe10thInternationalJointConference asrsystems. InICASSP2021-2021IEEEInterna-
on Natural Language Processing: System Demon- tionalConferenceonAcoustics,SpeechandSignal
strations,pages33‚Äì39,Suzhou,China.Association Processing(ICASSP),pages5674‚Äì5678.
forComputationalLinguistics.
A DetailsonMaskedLoss
WangWeiran,TongzhouChen,TaraSainath,EhsanVar-
iani,RohitPrabhavalkar,W.RonnyHuang,Bhuvana
DuringthetrainingofouradaptedSTmodel, ex-
Ramabhadran,NeerajGaur,SepandMavandadi,Cal
Peyser,TrevorStrohman,YanzhangHe,andDavid amplesentencesareprependedtosentencesinthe
Rybach.2022. ImprovingRareWordRecognition reducedtrainingset. Thetranslationoftheexam-
with LM-aware MWER Training. In Proc. Inter-
plesentenceisusedasaprefixandmaskedduring
speech2022,pages1031‚Äì1035.
loss calculation. The cross-entropy loss function
JitaoXu,JosepCrego,andJeanSenellart.2020. Boost- weusefortrainingcanbeexpressedasEquation1:
ingneuralmachinetranslationwithsimilartransla-
tions. InProceedingsofthe58thAnnualMeetingof T
(cid:88)
theAssociationforComputationalLinguistics,pages L = ‚àí M logP(y |y ,ue,ye,u) (1)
t t <t
1580‚Äì1590,Online.AssociationforComputational
t=1
Linguistics.
WithM asamaskfunctionEquation2:
Chao-HanHuckYang,LindaLiu,AnkurGandhe,Yile t
Gu,AnirudhRaju,DenisFilimonov,andIvanBulyko.
(cid:40)
2021. Multi-tasklanguagemodelingforimproving 0 ifpositiontispartofye
M = (2)
speechrecognitionofrarewords. InIEEEAutomatic t
1 ifpositiontispartofy
Speech Recognition and Understanding Workshop,
ASRU2021,Cartagena,Colombia,December13-17,
2021,pages1087‚Äì1093.IEEE. B DetailsofRareWordTypes
Urchade Zaratiana, Nadi Tomeh, Pierre Holat, and ThedetailedrarewordanalysisresultsforTable2
ThierryCharnois.2023. Gliner:Generalistmodelfor areinTable9.
named entity recognition using bidirectional trans-
former. CoRR,abs/2311.08526.
C STTrainingandInferenceDetails
HuaaoZhang,QiangWang,BoQin,ZelinShi,Haibo
C.1 TrainingDetails
Wang, and Ming Chen. 2023. Understanding and
improvingtherobustnessofterminologyconstraints We use the Transformer architecture
inneuralmachinetranslation. InProceedingsofthe
S2T_TRANSFORMER_S in FAIRSEQ S2T
61stAnnualMeetingoftheAssociationforCompu-
tationalLinguistics(Volume1: LongPapers),pages (Wang et al., 2020) For all our ST models, the
6029‚Äì6042,Toronto,Canada.AssociationforCom- encoder-decoder architecture consists of 12
putationalLinguistics. transformer encoder blocks and 6 transformer
decoder blocks, with a model dimension of 256
Jingyi Zhang, Masao Utiyama, Eiichro Sumita, Gra-
hamNeubig,andSatoshiNakamura.2018. Guiding andaninnerdimension(FFN)of2,048.RareWordType Frequency a search in {0.1, 0.2, 0.3} based on the dev loss
duringthetrainingoftheadaptedSTmodel. The
Person 130
Location 72 training was stopped after the validation perfor-
Technology 29
mancedidnotimprovefor30consecutiveepochs
Food 27
Company 25 (patience30). Forevaluation,weaveragedthelast
Biology 23 10checkpoints.
Organization 18
Health 18 C.2 InferenceDetails
Culture 14
Transport 14 The inference uses a beam size of 5. Since the
Religion 14
rare-word-tstdatasetincludesexample-prepended
Fashion 13
Medicine 12 sentences, the sentences are longer than typical
Science 12 translationsentences. Tokeepallutterancesinthe
Geography 11
rare-word-tstset,wesetalargeallowedsourcesize
Chemics 11
Language 11 with ‚Äìmax-source-positions 30000. This ensures
History 10 that even the longest utterances are not excluded
Politics 9
fromtherare-word-tstset.
Architecture 9
Military 9
Environment 8 D RetrieverTrainingandInference
Education 7 Details
Sport 7
Law 6
D.1 TrainingDetails
Society 4
Data 4 OurretrieverisbasedontheDPR(Karpukhinetal.,
Book 4
2020)architecture,whereadensepassageencoder
Physics 4
Game 3 E P and a question encoder E Q is constructed to
Economy 3 mapcandidateinputcandqueryinputq tolatent
Literature 2
representationvectorsrespectively. Thesimilarity
Art 2
Music 1 betweenthecandidaterepresentationandthequery
Entertainment 1
representationisdefinedasthedot-productoftheir
Award 1
vectorsasshowninEquation3:
Table9: DetailedNERresultsonrarewordsintst-rare-
sim(q,c) = E (q)TE (c) (3)
wordwiththenumberofuniquewordsineachcategory. Q P
The encoders E and E of DPR are initialized
P Q
withSpeechT5encoder(Aoetal.,2022)orSONAR
WeinitializedtheSTmodelfromapre-trained
encoder(Duquenneetal.,2023).
ASRmodel9. Subsequently,wefine-tunedthepre-
trainedmodelfortheSTtaskwithhyperparameters Speech T5 The SpeechT5 speech/text encoder
following(Wangetal.,2020),specifically,weset transforms speech or text input into a 768-
dropoutrate0.1andlabelsmoothing0.1. TheST dimensional embedding vector. It comprises 12
trainingusedatokenizerwithavocabularysizeof Transformerencoderblocks,eachwithamodeldi-
8,000. Topreventthetokenizerfromseeingtherare mensionof768andaninnerfeed-forwardnetwork
wordsduringitstraining,whichwillcauseanunfair (FFN) dimension of 3,072. Before the encoder,
test condition, we train the SentencePiece (Kudo aspeech/text-encoderpre-netpreprocessesthein-
and Richardson, 2018) tokenizer on the reduced put. Thespeech-encoderpre-netincludesthecon-
trainsetaftertheutterancescontainingrarewords volutional feature extractor of wav2vec (Baevski
aremovedtoothersplitsasdiscussedin¬ß3.1. et al., 2020) for waveform downsampling. The
DuringthetrainingoftheadaptedSTmodelwith text-encoder pre-net applies positional encoding
examples, we doubled the effective batch size to to convert character-level tokenized indices into
maintainacomparablelossscalesincetheprefix embeddingvectors.
tokens do not contribute to the overall loss. Ad-
SONAR The SONAR speech/text encoder en-
ditionally, we set dropout rate to 0.2 after doing
codes speech/text input to an embedding vector
of1,024. Theencoderconsistsof24transformer
9https://dl.fbaipublicfiles.com/fairseq/s2t/
mustc_de_asr_transformer_s.pt encoderblockswithamodeldimensionof1,024and an inner dimension (FFN) of 8,192. The BLEU
speechencoder-frontendappliesthewav2vecfea-
FAIRSEQS2T(Wangetal.,2020) 22.7
tureextractor(Baevskietal.,2020),whilethetext Ourbaselinemodel 23.6
encoder-frontendusesapositionencoder.
Table 10: The performance of our baseline model on
Training ThedualencodersinDPRaretrained the tst-COMMON split of MuST-C is comparable to
onareducedtrainingsetwithprependedexamples. existingbaselines. Bothmodelshavetheidenticalarchi-
Each sentence‚Äôs example works as a positive ex-
tectureusingS2T_TRANSFORMER_S.
ample,whileexamplesfromothersentencesinthe
source (transcript): Murali Krishna (Murali Krishna)
batchserveasin-batchnegatives. Wesetabatch
comesfromoneofthosevillages.
sizeof4andalearningrateof2e-5fortraining. baseline model (on train-reduced) (Table 3 row
GiventhelargesizeoftheSONARencoder,for (1)):Moralische Christen (Moral Christians) sind aus
einemdieserD√∂rfer.
memory efficiency, only the top layer of the en-
trainon{train-reduced+rare-wordpool}(Table3row
coder is trained. This approach is not only for (4)): DasMarateKrishna(MarateKrishna)kommtaus
memoryefficiencybutalsobecausethelowerlay- einemdieserD√∂rfer.
speech‚Üíspeechexample(Table4row(5)):Siearbeitet
erslikelyextractlow-levelacousticfeatures,which
mitLeutenwieMuraliKrishna. (Sheworkswithpeople
are less relevant for our retrieval task focused on likeMuraliKrishna.).
adapted + speech‚Üíspeech (Table 3 row (7)): Murali
word-levelinformation. Wefurtherinvestigatethe
Krishna(MuraliKrishna)kommtauseinemdieserD√∂rfer.
retrievalaccuracyunderdifferentnumbersoftrain-
target:MuraliKrishna(MuraliKrishna)kommtauseiner
ableparameters. AsshowninFigure2. Weusethe dieserD√∂rfer.
settingswiththebestretrievalaccuracyforourST source(transcript):TheMcLaren(McLaren)justpopped
task. whichare: offandscratchedthesidepanel.
baselinemodel(ontrain-reduced)(Table3row(1)):Und
‚Ä¢ Forthespeech-to-speechretriever, thetop2
der Klient (client) stoppte ab und kratzte die Seite des
layers of both speech encoders are trained, Paddels.
trainon{train-reduced+rare-wordpool}(Table3row
resultingin205milliontrainableparameters.
(4)):UndderSpieler(player)st√ºrzteeinfachabundkratzte
‚Ä¢ Forthespeech-to-textretriever,thetop8lay-
aufdenB√ºrgersteig.
ers of both the text and speech encoders are speech‚Üíspeech example (Table 4 row (5)): Aber als
NebeneffektsammelterKornette. (Butasasideline,he
trained,with422milliontrainableparameters.
happenstocollectcornets.)
‚Ä¢ Forthetext-to-textretriever,thetop8layers adapted+speech‚Üíspeech(Table3row(7)): Alsder
of both text encoders are trainable, totaling Klairner(Klairner)geradeankam,stopfteereinNebenpan-
del.
335milliontrainableparameters.
target: DerMcLaren(McLaren)bekameineBeuleund
einenKratzeranderSeitenkarosserie.
D.2 InferenceDetails
Table 11: Additional examples of our retrieval-and-
During inference time, we apply the passage en-
demonstrationapproach.
coder E to all the candidates in the rare-word
P
pool. Given a question q, we can derive its em-
bedding v q = E Q(q) and then retrieve the top-1 fectly. In the second example, we demonstrate a
candidate whose embedding is the closest to v q casewhereourapproachdoesnotperformwell.
fromtherare-wordpool.
G PreliminaryASRResults
E ComparisontoExistingResults
Totestthegeneralizabilityofourapproach,wead-
We confirm that our baseline model performs on ditionallyranrarewordASRexperimentsonthe
par with those reported in the literature with the same data splits following the data construction
resultsinTable10. steps in ¬ß3.1. The results are in Table 12. Here
we directly used all hyperparameters for the ST
F AdditionalExamples models. Thescoresthereforemaybenotoptimal.
However,pirmainfindingsstillholdgiventhead-
Herewepresenttwoadditionaltranslationexam-
ditionalresults:
plesforcomparisonamongthebaselinemodel,the
model trained with an additional rare-word pool, 1. ASR models can also effectively learn from
and our approach. In the first example, our ap- demonstration at inference time: Rare word
proachsuccessfullytranslatesazero-shotwordper- recognition accuracy in line (2) vs. (1) im-Overall 0-shot 1-shot
ASRModel WER
acc(%) acc(%) acc(%)
(1)baselinemodel(ontrain-reduced) 14.8 31.2 27.0 40.3
(2)adapted+goldexample 22.0 72.1 71.4 73.8
(3)adapted+randomexample 25.3 19.8 18.6 22.4
(4)trainon{train-reduced+rare-wordpool}(moredata) 13.9 42.8 38.7 51.7
Usingretrievedexamples
(5)adapted+text(goldtranscript)‚Üítext 28.0 46.2 45.0 48.8
(6)adapted+speech‚Üítext 28.1 40.1 39.3 41.7
(7)adapted+speech‚Üíspeech 21.7 46.8 46.2 48.1
Table 12: ASR quality (WER‚Üì) and rare word accuracy‚Üë (overall, 0- and 1-shot) of different models on the
tst-rare-wordsplit. Thelowersectionusesretrievedexamplesfromtheretriever(¬ß4.3).
provesfrom31.2to72.1%.
2. Seeing rare words only in training does not
sufficiently improve their recognition accu-
racy: Rare word accuracy does not improve
asmuchinline(4)vs. (1)comparedto(2)vs.
(1).
3. Speech‚Üíspeechoutperformsspeech‚Üítextre-
trieval: In systems with retrieved examples,
line(7)hasthebestperformance.