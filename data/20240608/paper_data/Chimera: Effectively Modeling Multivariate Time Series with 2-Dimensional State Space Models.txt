Chimera: Effectively Modeling Multivariate Time Series with
2-Dimensional State Space Models
AliBehrouzâ˜…,MicheleSantacatterinaâ€ ,andRaminZabihâ˜…
â˜…DepartmentofComputerScience,CornellUniversity
â€ NYUGrossmanSchoolofMedicine
, ,
ab2947@cornell.edu santam13@nyu.edu rdz@cs.cornell.edu
Abstract
Modelingmultivariatetimeseriesisawell-establishedproblemwithawiderangeofapplicationsfromhealthcare
tofinancialmarkets.It,however,isextremelychallengingasitrequiresmethodsto(1)havehighexpressivepowerof
representingcomplicateddependenciesalongthetimeaxistocapturebothlong-termprogressionandseasonalpatterns,(2)
capturetheinter-variatedependencieswhenitisinformative,(3)dynamicallymodelthedependenciesofvariateandtime
dimensions,and(4)haveefficienttrainingandinferenceforverylongsequences.TraditionalStateSpaceModels(SSMs)
areclassicalapproachesforunivariatetimeseriesmodelingduetotheirsimplicityandexpressivepowertorepresentlinear
dependencies.They,however,havefundamentallylimitedexpressivepowertocapturenon-lineardependencies,areslow
inpractice,andfailtomodeltheinter-variateinformationflow.Despiterecentattemptstoimprovetheexpressivepower
ofSSMsbyusingdeepstructuredSSMs,theexistingmethodsareeitherlimitedtounivariatetimeseries,failtomodel
complexpatterns(e.g.,seasonalpatterns),failtodynamicallymodelthedependenciesofvariateandtimedimensions,
and/orareinput-independent.WepresentChimera,anexpressivevariationofthe2-dimensionalSSMswithcarefuldesign
ofparameterstomaintainhighexpressivepowerwhilekeepingthetrainingcomplexitylinear.UsingtwoSSMheadswith
differentdiscretizationprocessesandinput-dependentparameters,Chimeraisprovablyabletolearnlong-termprogression,
seasonalpatterns,anddesirabledynamicautoregressiveprocesses.Toimprovetheefficiencyofcomplex2Drecurrence,
wepresentafasttrainingusinganew2-dimensionalparallelselectivescan.Wefurtherpresentanddiscuss2-dimensional
MambaandMamba-2asthespacialcasesofour2DSSM.Ourexperimentalevaluationshowsthesuperiorperformance
ofChimeraonextensiveanddiversebenchmarks,includingECGandspeechtimeseriesclassification,long-termand
short-termtimeseriesforecasting,andtimeseriesanomalydetection.
1 Introduction
Modelingtimeseriesisawell-establishedproblemwithawiderangeofapplicationsfromhealthcare(Behrouz,Delavari,
andHashemi2024;Ivanovetal.1999)tofinancialmarkets(Gajamannage,Park,andJayathilake2023;PincusandKalman
2004) and energy management (H. Zhou et al. 2021). The complex nature of time series data, its diverse domains of
applicability,anditsbroadrangeoftasks(e.g.,classification(Behrouz,Delavari,andHashemi2024;Wagneretal.2020),
imputation(LuoandX.Wang2024;H.Wu,Hu,etal.2023),anomalydetection(Behrouz,Delavari,andHashemi2024;
Su et al. 2019), and forecasting (H. Zhou et al. 2021)), however, raise fundamental challenges to design effective and
generalizablemodels:(1)Thehigher-order,seasonal,andlong-termpatternsintimeseriesrequireaneffectivemodeltobe
abletoexpressivelycapturecomplexandautoregressivedependencies;(2)Inthepresenceofmultiplevariatesoftime
series,aneffectivemodelneedtocapturethecomplexdynamicsofthedependenciesbetweentimeandvariateaxes.More
specifically,mostexistingmultivariatemodelsseemtosufferfromoverfittingespeciallywhenthetargettimeseriesisnot
correlatedwithothercovariates(Zengetal.2023a).Accordingly,aneffectivemodelneedstoadaptivelylearntoselect
(resp.filter)informative(resp.irrelevant)variates;(3)Thediversesetofdomainsandtasksrequireseffectivemodelstobe
freeofmanualpre-processinganddomainknowledgeandinsteadadaptivelylearnthem;and(4)Duetotheprocessingof
verylongsequences,effectivemethodsneedefficienttrainingandinference.
Classicalmethods(e.g.,StateSpaceModels(Aoki2013;Harvey1990),ARIMA(Bartholomew1971),SARIMA(Benderand
Simonovic1994),ExponentialSmoothing(ETS)(Winters1960))requiremanualdatapreprocessingandmodelselection,
1
4202
nuJ
6
]GL.sc[
1v02340.6042:viXraFigure1: TheOverviewofContributionsandArchitectureofChimera. Wepresenta2-dimensionalSSMwithcarefuland
expressiveparameterization.Itusesdifferentlearnablediscretizationprocessestolearnseasonalandlong-termprogressionpatterns,
andleveragesaparallelizableandfasttrainingprocessbyre-formulatingthe2Dinputdependentrecurrenceasa2Dprefixsumproblem.
andoftenarenotabletocapturecomplexnon-linear dynamics.Theraiseofdeeplearningmethodsandmorespecifically
Transformers(Vaswanietal.2017)hasledtosignificantresearcheffortstoaddressthelimitationofclassicalmethods
anddevelopeffectivedeepmodels(Z.Chenetal.2023;Kitaev,Kaiser,andLevskaya2020;LimandZohren2021;S.Liu
etal.2021;YongLiu,Hu,etal.2024;Wooetal.2022;H.Wu,J.Wu,etal.2022;H.Wu,Xu,etal.2021;Y.ZhangandYan
2023;T.Zhou,Z.Ma,Wen,X.Wang,etal.2022). Unfortunately,mostexistingdeepmodelsstruggletoachieveallthe
abovefourcriteria.Themainbodyofresearchinthisdirectionhasfocusedondesigningattentionmodulesthatusethe
specialtraitsoftimeseries(Wooetal.2022;H.Wu,Xu,etal.2021).However,theinherentpermutationequivarianceof
attentionscontradictsthecausalnatureoftimeseriesandoftenresultsinsuboptimalperformancecomparedtosimple
linearmethods(Zengetal.2023a).Moreover,theyofteneitheroverlookdifferenceofseasonalandlong-termtrendoruse
non-learnablemethodstohandlethem(Wooetal.2022).
Aconsiderablesubsetofdeepmodelsoverlooktheimportanceofmodelingthedependenciesofvariates(Nieetal.2023;
Zengetal.2023a;M.Zhangetal.2023).Thesedependencies,however,arenotalwaysuseful;specificallywhenthetarget
timeseriesisnotcorrelatedwithothercovariates(S.-A.Chenetal.2023).Despiteseveralstudiesexploringtheimportance
oflearningcrossvariatedependencies(S.-A.Chenetal.2023;YongLiu,Hu,etal.2024;Y.ZhangandYan2023),therehas
beennouniversalstandardandtheconclusionhasbeendifferentdependingonthedomainandbenchmarks.Accordingly,
wearguethataneffectivemodelneedtoadaptively learntocapturethedependenciesofvariatesinadata-dependent
manner.Inthisdirection,recently,YongLiu,Hu,etal.(2024)arguethatattentionmechanismsaremoreeffectivewhen
theyareusedacrossvariates,showingtheimportanceofmodelingcomplexnon-lineardependenciesacrossthevariate
axisinadata-dependentmanner.However,thequadraticcomplexityofTransformerschallengesthemodelonmultivariate
timeserieswithalargenumberofvariates(e.g.,brainactivitysignals(Behrouz,Delavari,andHashemi2024)ortraffic
forecasting(H.Zhouetal.2021)),limitingtheefficienttrainingandinference(seeTable3,andTable5).
Theobjectiveofthisstudyistodevelopaprovablyexpressivemodelformultivariatetimeseriesthatnotonlycanmodel
thedynamicsofthedepenendenciesalongbothtimeandvariates,butitalsotakesadvantageoffasttrainingandinference.
To this end, we present a Chimera, a three-headed two-dimensional State Space Model (SSM) that is based on linear
layers along (i) time, (ii) variates, (iii) timeâ†’variate, and (iv) variateâ†’time. Chimera has a careful parameterization
based on the pair of companion and diagonal matrices (see Figure 1), which is provably expressive to recover both
2classicalmethods(Bartholomew1971;BenderandSimonovic1994;Winters1960),linearattentions,andrecentSSM-based
models(Behrouz,Santacatterina,andZabih2024;Nguyenetal.2022).Itfurtherusesanadaptivemodulebasedona2DSSM
withanespeciallydesigneddiscretizationprocesstocaptureseasonalpatterns.Whileourtheoreticalresultsanddesign
ofChimeraguaranteethefirstthreecriteriaofaneffectivemodel,duetoits2Drecurrence,thenaiveimplementation
ofChimeraresultsinslowtraining. Toaddressthisissue,wereformulateits2Drecurrenceastheprefixsumproblem
with a 2-dimensional associative operators. This new formulation can be done in parallel and has hardware-friendly
implementation,resultinginmuchfastertrainingandinference.
Wediscussnewvariantsofour2DSSMinSection3.2bylimitingitstransitionmatrices.Theresultedmodelscanbeseen
asthegeneralizationofMamba(GuandDao2023)andMamba-2(DaoandGu2024)to2-dimensionaldata.Whilethemain
focusofthispaperisontimeseriesdata,thesepresentedmodelsduetotheir2Dinductivebiasarepotentiallysuitablefor
otherhighdimensionaldatamodalitiessuchasimages,videos,andmulti-channelaudio.
Inourexperimentalevaluation,weexploretheperformanceofChimerainawiderangeoftasks:ECGandaudiospeechtime
seriesclassification,long-andshort-termtimeseriesforecasting,andanomalydetectiontasks.WefindthatChimeraachieve
superiororonparperformancewithstate-of-the-artmethods,whilehavingfastertrainingandlessmemoryconsumption.
We perform a case study on the human brain activity signals (Behrouz, Delavari, and Hashemi 2024) to show (1) the
effectivenessofChimeraand(2)evaluatetheimportanceofmodelingthedynamicsofthevariatesdependencies.
2 Preliminaries
Notations.Inthispaperwemainlyfocusonclassificationandforecastingtasks.Notethatanomalydetectioncanbeseen
asabinaryclassificationtask,where0meansâ€œnormallâ€and1meansâ€œanomalyâ€.WeletX= {x1,...,xğ‘} âˆˆRğ‘Ã—ğ‘‡ bethe
inputsequences,whereğ‘ isthenumberofvariatesandğ‘‡ isthetimesteps.Weusexğ‘£,ğ‘¡ torefertothevalueoftheseriesğ‘£
attimeğ‘¡.Inclassification(anomalydetection)tasks,weaimtoclassifyinputsequencesandforforecastingtasks,givenan
inputsequencexğ‘–,weaimtopredictxËœ
ğ‘–
âˆˆR1Ã—ğ»,i.e.,thenextğ» timestepsforvariatexğ‘–,whereğ» iscalledhorizon.In2D
SSMsformulation,fora2-dimensionalvectorğ‘¥ âˆˆC1,weuseğ‘¥(1) andğ‘¥(2) torefertoitsrealandimaginarycomponents,
respectively.
Multi-DimensionalStateSpaceModels.WebuildourapproachonthecontinuousStateSpaceModel(SSM)butlater
wemakeeachcomponentofChimeradiscretebyadesigneddiscretizationprocess.Foradditionaldiscussionon1DSSMs
seeAppendixA.GivenparametersAğœ1 âˆˆRğ‘(ğœ1)Ã—ğ‘(ğœ1),Bğœ2 âˆˆCğ‘(ğœ2)Ã—1,andCâˆˆCğ‘1Ã—ğ‘2 forğœ 1 âˆˆ {1,...,4}andğœ 2 âˆˆ {1,2},the
generalformofthetime-invariant2DSSMisthemapxâˆˆC1 â†¦â†’yâˆˆC1definedbythelinearPartialDifferentialEquation
(PDE)withinitialconditionâ„(0,0) =0:
ğœ• (cid:16) (cid:17) (cid:16) (cid:16) (cid:17) (cid:16) (cid:17)(cid:17) (cid:16) (cid:17)
â„ ğ‘¡(1),ğ‘¡(2) = A1â„(1) ğ‘¡(1),ğ‘¡(2) ,A2â„(2) ğ‘¡(1),ğ‘¡(2) +B1x ğ‘¡(1),ğ‘¡(2) , (1)
ğœ•ğ‘¡(1)
ğœ• (cid:16) (cid:17) (cid:16) (cid:16) (cid:17) (cid:16) (cid:17)(cid:17) (cid:16) (cid:17)
â„ ğ‘¡(1),ğ‘¡(2) = A3â„(1) ğ‘¡(1),ğ‘¡(2) ,A4â„(2) ğ‘¡(1),ğ‘¡(2) +B2x ğ‘¡(1),ğ‘¡(2) , (2)
ğœ•ğ‘¡(2)
(cid:16) (cid:17) (cid:16) (cid:17)
y ğ‘¡(1),ğ‘¡(2) = âŸ¨C,x ğ‘¡(1),ğ‘¡(2) âŸ©. (3)
Contrarytothemulti-dimensionalSSMsdiscussedbyGuandDao(2023)andGu,Goel,andRe(2022),inwhichmulti-
dimensionreferstothedimensionoftheinputbutwithonetimevariable, theaboveformulationusestwovariables,
meaningthatthemappingisfroma2Dgridtoa2Dgrid.
(Seasonal)AutoregressiveProcess. Autoregressiveprocessisabasicyetessentialpremisefortimeseriesmodeling,
whichmodelsthecausalnatureoftimeseries.Givenğ‘ âˆˆN,xğ‘˜ âˆˆRğ‘‘,thesimplelinearautoregressiverelationshipsbetween
xğ‘˜ anditspastsamplesxğ‘˜âˆ’1,xğ‘˜âˆ’2,...,xğ‘˜âˆ’ğ‘ canbemodeledasxğ‘˜ =ğœ™ 1xğ‘˜âˆ’1+ğœ™ 2xğ‘˜âˆ’2+...,ğœ™ ğ‘xğ‘˜âˆ’ğ‘,whereğœ™ 1,...,ğœ™ ğ‘ are
coefficients. ThisiscalledAR(ğ‘). Similarly,inthepresenceofseasonalpatterns,theseasonalautoregressiveprocess,
SAR(ğ‘,ğ‘,ğ‘ ),is:
xğ‘˜ =ğœ™ 1xğ‘˜âˆ’1+ğœ™ 2xğ‘˜âˆ’2+...,ğœ™ ğ‘xğ‘˜âˆ’ğ‘+ğœ‚ 1xğ‘˜âˆ’ğ‘  +ğœ‚ 2xğ‘˜âˆ’2ğ‘  +Â·Â·Â·+ğœ‚ ğ‘xğ‘˜âˆ’ğ‘ğ‘ , (4)
whereğ‘  isthefrequencyofseasonality,andğœ™ ,...,ğœ™ andğœ‚ ,...,ğœ‚ arecoefficients.Notethatonecansimplyextendthe
1 ğ‘ 1 ğ‘
aboveformulationtomultivariatetimeseriesbylettingcoefficientstobevectorsandreplacetheproductwithelement-wise
product.
33 Chimera: A Three-headed 2-Dimensional State Space Model
Inthissection,wefirstpresentamathematicalmodelformultivariatetimeseriesdataandthenbasedonthismodel,we
presentaneuralarchitecturethatcansatisfyallthecriteriadiscussedinÂ§1.
3.1 Motivations&ChimeraModel
SSMshavebeenlong-standingmethodsformodelingtimeseries(Aoki2013;Harvey1990),mainlyduetotheirsimplicity
andexpressivepowertorepresentcomplicatedandautoregressivedependencies.Theirstates,however,arethefunctionof
asingle-variable(e.g.,time).Multivariatetimeseries,ontheotherhand,requirecapturingdependenciesalongbothtime
andvariatedimensions,requiringthecurrentstateofthemodeltobethefunctionofbothtimeandvariate.Classical2D
SSMs(Eising1978;FornasiniandMarchesini1978;Hinamoto1980;Kungetal.1977),however,struggletoachievegood
performancecomparedtorecentadvanceddeeplearningmethodsastheyare:(1)onlyabletocapturelineardependencies,
(2)discretebydesign, havingapre-determinedresolution, andsocannotsimplymodelseasonalpatterns, (3)slowin
practiceforlargedatasets,(4)theirupdateparametersarestaticandcannotcapturethedynamicsofdependencies.Deep
learning-basedmethods(S.-A.Chenetal.2023;YongLiu,Hu,etal.2024;H.Zhouetal.2021),ontheotherhand,potentially
areabletoaddressasubsetoftheabovelimitations,whilehavingtheirowndrawbacks(discussedinÂ§1).Inthissection,
westartwithcontinuousSSMsduetotheirconnectiontobothclassicalmethods(Aoki2013;Harvey1990)andrecent
breakthroughindeeplearning(GuandDao2023;Gu,Goel,andRe2022).Wethendiscussourcontributionsonhowto
taketheadvantagesofthebestofbothworlds,addressingalltheabovementionedlimitations.
Discrete2DSSM.Weuse2-dimensionalSSMs,introducedinEquation1-3,tomodelmultivariatetimeseries,wherethe
firstaxiscorrespondstothetimedimensionandthesecondaxisisthevariates.Accordingly,eachstateisafunctionofboth
timeandvariates.Thefirststageistotransformthecontinuousformof2DSSMstodiscreteform.GiventhestepsizeÎ”
1
andÎ” 2,whichrepresenttheresolutionoftheinputalongtheaxes,discreteformoftheinputisdefinedasxğ‘˜,â„“ =x(ğ‘˜Î” 1,â„“Î” 2).
UsingZero-OrderHold(ZOH)method,wecandiscretizetheinputas(seeAppendixCfordetails):
(cid:32) â„ â„ğ‘˜ ğ‘˜( (1 2, +â„“)
)
1+ ,1 â„“(cid:33) = (cid:18) AA Â¯Â¯ 31 AA Â¯Â¯ 42(cid:19) (cid:32) â„ â„ğ‘˜ ğ‘˜( (1 2, ,â„“ â„“) )(cid:33) + (cid:18) B BÂ¯ Â¯1 2(cid:19) âŠ— (cid:18) x xÂ¯ Â¯ğ‘˜ ğ‘˜, +â„“ 1+ ,1 â„“(cid:19) , (5)
whereAÂ¯ ğ‘– =exp(cid:16) Î” âŒŠğ‘–+ 21âŒ‹Ağ‘–(cid:17) forğ‘– =1,2,3,4,BÂ¯ 1 = (cid:34) AA 21 âˆ’âˆ’ 11 (cid:0)(cid:0) AA Â¯Â¯ 21 âˆ’âˆ’ II (cid:1)(cid:1) BB 11 (( 21 ))(cid:35) ,andBÂ¯ 2 = (cid:34) AA 43 âˆ’âˆ’ 11 (cid:0)(cid:0) AA Â¯Â¯ 43 âˆ’âˆ’ II (cid:1)(cid:1) BB 22 (( 21 ))(cid:35) .
NotethatthisformulationcanalsobeviewedasthemodificationofthediscreteRoesserâ€™sSSMmodel(Kungetal.1977)
whenweaddalagof1intheinputs(cid:18) xÂ¯ ğ‘–,ğ‘—(cid:19)
.Thismodification,however,missesthediscretizationstep,whichisanimportant
xÂ¯
ğ‘–,ğ‘—
stepinourmodel. Welaterusethediscretizationstepto(1)empowerthemodeltoselect(resp. filter)relevant(resp.
irrelevant)information,(2)adaptivelyadjusttheresolutionofthemethod,capturingseasonalpatterns.
Fromnowon,weuseğ‘¡ (resp.ğ‘£)torefertotheindexalongthetime(resp.variate)dimension.Therefore,forthesakeof
simplicity,wereformulateEquation5asfollows:
â„ ğ‘£( ,1 ğ‘¡)
+1
=AÂ¯ 1â„ ğ‘£( ,1 ğ‘¡) +AÂ¯ 2â„ ğ‘£( ,2 ğ‘¡) +BÂ¯ 1xğ‘£,ğ‘¡+1, (6)
â„ ğ‘£(2 +)
1,ğ‘¡
=AÂ¯ 3â„ ğ‘£( ,1 ğ‘¡) +AÂ¯ 4â„ ğ‘£( ,2 ğ‘¡) +BÂ¯ 2xğ‘£+1,ğ‘¡, (7)
yğ‘£,ğ‘¡ =C1â„ ğ‘£( ,1 ğ‘¡) +C2â„ ğ‘£( ,2 ğ‘¡), (8)
where AÂ¯ 1,AÂ¯ 2,AÂ¯ 3,AÂ¯ 4 âˆˆ Rğ‘Ã—ğ‘, BÂ¯ 1,BÂ¯ 2 âˆˆ Rğ‘Ã—1, and C1,C2 âˆˆ R1Ã—ğ‘ are parameters of the model,â„ ğ‘£( ,1 ğ‘¡),â„ ğ‘£( ,2 ğ‘¡) âˆˆ Rğ‘Ã—ğ‘‘ are
hiddenstates,andxğ‘£,ğ‘¡ âˆˆR1Ã—ğ‘‘ istheinput.Inthisformulation,intuitively,â„ ğ‘£( ,1 ğ‘¡) isthehiddenstatethatcarriescross-time
information(eachstatedependsonitsprevioustimestampbutwithinthesamevariate),whereAÂ¯
1
andAÂ¯
2
controlthe
emphasisonpastcross-timeandcross-variateinformation,respectively. Similarly,â„(2) isthehiddenstatethatcarries
ğ‘£,ğ‘¡
cross-variateinformation(eachstatedependsonothervariatesbutwiththesametimestamp).Laterinthissection,we
discusstomodifythemodeltobi-directionalsettingalongthevariatedimension,toenhanceinformationflowalongthis
non-causaldimension.
4Figure2: DifferentformsofChimera.(Top-Left)Chimerahasarecurrenceform(bi-directionalalongthevariates),whichalsocan
becomputedasaglobalconvolutionintraining.(Top-Right)Inforecasting,wepresentthemultivariateclosed-looptoimprovethe
performanceforlonghorizons.(Bottom)Usingdata-dependentparameters,Chimeratrainingcanbedoneasaparallel2Dscan.
InterpretationofDiscretization.Timeseriesdataareoftensampledfromanunderlyingcontinuousprocess(Hebartetal.
2023;Warden2018).Inthesecases,variableÎ” inthediscretizationofthetimeaxiscanbeinterpretedasresolutionorthe
1
samplingratefromtheunderlyingcontinuousdata.However,discretizationalongthevariateaxis,whichisdiscretebyits
nature,orwhenworkingdirectlywithdiscretedata(A.E.Johnsonetal.2023)isanunintuitiveprocess,andraisequestions
aboutitssignificance.Thediscretizationstepin1DSSMshasdeepconnectionstogatingmechanismsofRNNs(Guand
Dao2023;TallecandOllivier2018),automaticallyensuresthatthemodelisnormalized(Gu,I.Johnson,Timalsina,etal.
2023),andresultsindesirablepropertiessuchasresolutioninvariance(Nguyenetal.2022).
Proposition3.1. The2DdiscreteSSMintroducedinEquation6-8withparameters({AÂ¯ ğ‘–},{BÂ¯ ğ‘–},{CÂ¯ ğ‘–},ğ‘˜Î” 1,â„“Î” 2)evolvesatarate
ğ‘˜ (resp.â„“)timesasfastasthe2DdiscreteSSMwithparameters({AÂ¯ ğ‘–},{BÂ¯ ğ‘–},{CÂ¯ ğ‘–},Î” 1,â„“Î” 2)(resp. ({AÂ¯ ğ‘–},{BÂ¯ ğ‘–},{CÂ¯ ğ‘–},ğ‘˜Î” 1,Î” 2)).
Accordingly,parametersÎ” canbeviewedasthecontrollerofthelengthofdependenciesthatthemodelcaptures.Thatis,
1
basedontheaboveresult,weseethediscretizationalongthetimeaxisasthesettingoftheresolutionorsamplingrate:
whilesmallÎ” cancapturelong-termprogression,largerÎ” capturesseasonalpatterns.Fornow,weseethediscretization
1 1
alongthevariateaxisasamechanismsimilartogatinginRNNs(GuandDao2023;Gu,Gulcehre,etal.2020),whereÎ”
2
controlsthelengthofthemodelcontext.LargervaluesofÎ” meanslesscontextwindow,ignoringothervariates,while
2
smallervaluesofÎ” meansmoreemphesisonthedependenciesofvariates. Later,inspiredbyGuandDao(2023),we
2
discussmakingÎ” asthefunctionoftheinput,resultinginaselectionmechanismthatfiltersirrelevantvariates.
2
StructureofTransitionMatrices.ForChimeratobeexpressiveandabletorecoverautoregressiveprocess,hiddenstates
â„ ğ‘£( ,1 ğ‘¡) shouldcarryinformationaboutpast timestamps.WhilemakingalltheparametersinAğ‘– learnableallowsthemodel
tolearnanyarbitrarystructureforAğ‘–,previousstudiesshowthatthisisnotpossibleunlessthestructureoftransition
matricesarerestricted(Gu,Goel,Gupta,etal.2022;Gu,I.Johnson,Goel,etal.2021).Tothisend,inspiredbyM.Zhang
etal.(2023)thatarguethatcompanionmatricesareeffectivetocapturethedependenciesalongthetimedimension,we
restrictA1andA2matricestohavecompanionstructure:
0 0 ... 0 ğ‘(ğ‘–) 0 0 ... 0 0 0 0 ... 0 ğ‘(ğ‘–)
1 1
Ağ‘– =(cid:169) (cid:173) (cid:173) (cid:173) (cid:173) (cid:173) (cid:173) (cid:173)1 0 0. . . 0 1 0. . . . . .... . ... .
.
0 0 1. . . ğ‘ ğ‘ ğ‘2 3( ( (. . .ğ‘– ğ‘– ğ‘–) ) )(cid:170) (cid:174) (cid:174) (cid:174) (cid:174) (cid:174) (cid:174) (cid:174)=(cid:169) (cid:173) (cid:173) (cid:173) (cid:173) (cid:173) (cid:173)1 0 0. . . 0 1 0. . . . . .... . ... .
.
0 0 1. . . 0 0 0. . .(cid:170) (cid:174) (cid:174) (cid:174) (cid:174) (cid:174) (cid:174)+(cid:169) (cid:173) (cid:173) (cid:173) (cid:173) (cid:173) (cid:173) (cid:173)0 0 0. . . 0 0 0. . . . . .... . ... .
.
0 0 0. . . ğ‘ ğ‘ ğ‘2 3( ( (. . .ğ‘– ğ‘– ğ‘–) ) )(cid:170) (cid:174) (cid:174) (cid:174) (cid:174) (cid:174) (cid:174) (cid:174), (9)
(cid:171) ğ‘ (cid:172) (cid:171) (cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:123)(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:125)(cid:172) (cid:171)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ğ‘ (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:172)
(cid:124) (cid:123)(cid:122) (cid:125)
ShiftMatrix
Low-rankMatrix
5forğ‘– =1,2.Notethatthesetwomatricesareresponsibletofusetheinformationalongthetimeaxis(seeFigure2).Notonly
thisformulationisshowntobeeffectiveforcapturingdependenciesalongthetimedimension(M.Zhangetal.2023)(also
seeTheorem3.4),butitalsocanhelpustocomputethepowerofA1andA2fasterintheconvolutionalform,asdiscussed
byM.Zhangetal.(2023).Also,forA3andA4,weobservethatevenasimplerstructureofdiagonalmatricesiseffectiveto
fuseinformationalongthevariatedimension.Notonlythesesimplestructuredmatricesmakethetrainingofthemodel
faster,buttheyalsoareproventobeeffective(Gu,Goel,Gupta,etal.2022).
Bi-Directionality. Thecausalnatureofthe2DSSMresultinlimitedinformationflowalongthevariatedimensionas
variatearenotordered.Toovercomethischallenge,inspiredbythebi-directional1DSSMs(J.Wangetal.2023),weuse
twodifferentmodulesforforwardandbackwardpassalongthevariatedimension:
â„ ğ‘£( ,1 ğ‘¡) +ğ‘“
1
=AÂ¯ 1ğ‘“â„ ğ‘£( ,1 ğ‘¡) +AÂ¯ 2ğ‘“â„ ğ‘£( ,2 ğ‘¡)ğ‘“ +BÂ¯ 1ğ‘“ xğ‘£,ğ‘¡+1,
â„ ğ‘£( ,1 ğ‘¡) +ğ‘
1
=AÂ¯ğ‘ 1â„ ğ‘£( ,1 ğ‘¡) +AÂ¯ğ‘ 2â„ ğ‘£( ,2 ğ‘¡) +BÂ¯ğ‘ 1xğ‘£,ğ‘¡+1, (10)
â„ ğ‘£(2 +) 1ğ‘“
,ğ‘¡
=AÂ¯ 3ğ‘“â„ ğ‘£( ,1 ğ‘¡) +AÂ¯ 4ğ‘“â„ ğ‘£( ,2 ğ‘¡)ğ‘“ +BÂ¯ 2ğ‘“ xğ‘£+1,ğ‘¡,
â„ ğ‘£(2 âˆ’) 1ğ‘
,ğ‘¡
=AÂ¯ğ‘ 3â„ ğ‘£( ,1 ğ‘¡)ğ‘ +AÂ¯ğ‘ 4â„ ğ‘£( ,2 ğ‘¡)ğ‘ +BÂ¯ğ‘ 2xğ‘£âˆ’1,ğ‘¡, (11)
yğ‘“ =Cğ‘“â„(1)ğ‘“ +Cğ‘“â„(2)ğ‘“ , (12)
ğ‘£,ğ‘¡ 1 ğ‘£,ğ‘¡ 2 ğ‘£,ğ‘¡
yğ‘
ğ‘£,ğ‘¡
=Cğ‘ 1â„ ğ‘£( ,1 ğ‘¡)ğ‘ +Cğ‘ 2â„ ğ‘£( ,2 ğ‘¡)ğ‘ , (13)
yğ‘£,ğ‘¡ =y ğ‘£ğ‘“
,ğ‘¡
+yğ‘ ğ‘£,ğ‘¡, (14)
whereAÂ¯ğœ,AÂ¯ğœ,AÂ¯ğœ,AÂ¯ğœ âˆˆ Rğ‘Ã—ğ‘,BÂ¯ğœ,BÂ¯ğœ âˆˆ Rğ‘Ã—1,andCğœ,Cğœ âˆˆ R1Ã—ğ‘ areparametersofthemodel,â„(1)ğœ ,â„(2)ğœ âˆˆ Rğ‘Ã—ğ‘‘ are
1 2 3 4 1 2 1 2 ğ‘£,ğ‘¡ ğ‘£,ğ‘¡
hiddenstates,xğ‘£,ğ‘¡ âˆˆR1Ã—ğ‘‘ istheinput,andğœ âˆˆ {ğ‘“,ğ‘}.Figure2illustratesthebi-directionalrecurrenceprocessinChimera.
Forthesakeofsimplicity,wecontinuewithunidirectionalpass,butadaptingthemforbi-directionalsettingissimpleas
weusetwoseparateblocks,eachofwhichforadirection.
ConvolutionForm. Similarto1DSSMs(Gu,Goel,andRe2022),ourdata-independent formulationcanbeviewedas
aconvolutionwithakernelK. Thisformulationnotonlyresultsinfastertrainingbyprovidingtheabilityofparallel
processing, but it also connect Chimera with very recent studies of modern convolution-based architecture for time
series(LuoandX.Wang2024).ApplyingtherecurrentrulesinEquation6-8,wecanwritetheoutputas:
yğ‘£,ğ‘¡ = âˆ‘ï¸ âˆ‘ï¸ (cid:16) C1K ğ‘£( Ë†,1 ğ‘¡Ë†) +C2K ğ‘£( Ë†,2 ğ‘¡Ë†)(cid:17) xğ‘£Ë†,ğ‘¡Ë†, (15)
1â‰¤ğ‘£Ë†â‰¤ğ‘£1â‰¤ğ‘¡Ë†â‰¤ğ‘¡
wherekernelsK ğ‘£( Ë†ğœ ,ğ‘¡Ë†) =(cid:205) (ğ‘§1,...,ğ‘§5)âˆˆP(ğœ)ğ‘
ğ‘–
AÂ¯ğ‘ 11AÂ¯ğ‘ 22AÂ¯ğ‘ 33AÂ¯ğ‘ 44BÂ¯ ğ‘5,andP(ğœ) isthepartitioningofthepathsfromthestartingpoint
to (ğ‘£Ë†,ğ‘¡Ë†) forğœ âˆˆ {1,2}. As discussed by Baron, Zimerman, and Wolf (2024), if the power of AÂ¯ ğ‘–s are given and cached,
calculatingthepartitioningofallpathscanbedoneveryefficiently(near-linearly)asitthegeneralizationofpascaltriangle.
TocalculatethepowerofAÂ¯ ğ‘–,notethatweusediagonalmatricesasthestructureofAÂ¯ 3,andAÂ¯ 4,andsocomputingtheir
powersisveryfast.Ontheotherhand,forAÂ¯ 1andAÂ¯ 2withcompanionstructures,wecanusesparsematrixmultiplication,
whichresultsinlinearcomplexityintermsofthesequencelength.
Data-DependentParameters. Asdiscussedearlier,parametersAÂ¯ 1 andAÂ¯ 2 controlstheemphasisonpastcross-time
andcross-variateinformation.Similarly,parametersÎ” 1andBÂ¯ 1controlstheemphasisonthecurrentinputandhistorical
data.Sincetheseparametersaredata-independent,onecaninterpretthemasaglobalfeatureofthesystem.Incomplex
systems(e.g.,humanneuralactivity),however,theemphasisdependsonthecurrentinput,requiringtheseparametersto
bethefunctionoftheinput(seeÂ§4.1).Theinput-dependencyofparametersallowsthemodeltoselectrelevantandfilter
irrelevantinformationforeachinputdata,providingasimilarmechanismastransformers(GuandDao2023).Additionally,
asweargueearlier,dependingonthedata,themodelneedstoadaptivelylearnifmixinginformationalongthevariates
isuseful.Makingparametersinput-dependentfurtherovercomesthischallengeandletsourmodeltomixrelevantand
filterirrelevantvariatesforthemodelingofavariateofinterest.OneofourmaintechnicalcontributionsistoletBÂ¯ ğ‘–,CÂ¯ ğ‘–,
andÎ” ğ‘– forğ‘– âˆˆ {1,2}bethefunctionoftheinputxğ‘£,ğ‘¡. Thisinput-dependent2DSSM,unfortunately,doesnothavethe
convolutionform,limitingthescalabilityandefficiencyofthetraining.Weovercomethischallengebycomputingthe
modelrecurrentlywithanew2Dscan.
62DSelectiveScan.Inspiredbythescanningin1DSSMs(GuandDao2023;Smith,Warrington,andLinderman2023),we
presentanalgorithmtodecreasethesequentialstepsthatarerequiredtocalculatehiddenstates.Givenğ‘,ğ‘,eachofwhich
with6elements,wefirstdefineoperationâ‹‡as:(âŠ™ismatrix-matrixandâŠ—ismatrix-vectormultiplication)
ğ‘â‹‡ğ‘ =
(cid:18)ğ‘
1
ğ‘
2
ğ‘ 3(cid:19)
â‹‡
(cid:18)ğ‘
1
ğ‘
2
ğ‘ 3(cid:19)
=
(cid:18)ğ‘
1
âŠ™ğ‘
1
ğ‘
2
âŠ™ğ‘
2
ğ‘
1
âŠ—ğ‘ 3+ğ‘
2
âŠ—ğ‘ 6+ğ‘ 3(cid:19)
ğ‘
4
ğ‘
5
ğ‘
6
ğ‘
4
ğ‘
5
ğ‘
6
ğ‘
4
âŠ™ğ‘
4
ğ‘
5
âŠ™ğ‘
5
ğ‘
4
âŠ—ğ‘ 3+ğ‘
5
âŠ—ğ‘ 6+ğ‘
6
TheproofsofthenexttwotheoremsareinAppendixE.
Theorem3.2. Operatorâ‹‡isassociative:Givenğ‘,ğ‘,andğ‘Ÿ,wehave: (ğ‘â‹‡ğ‘)â‹‡ğ‘Ÿ =ğ‘â‹‡(ğ‘â‹‡ğ‘Ÿ).
Theorem3.3. 2DSSMrecurrencecanbedoneinparallelusingparallelprefixsumalgorithmswithassociativeoperatorâ‹‡.
3.2 NewVariantsof2DSSM:2DMambaand2DMamba-2
Figure2(Top-Left)showstherecurrenceformofour2DSSM.Eachsmallsquareisastateofthesystem,i.e.,thestateofa
variateatacertaintimestamp.2DSSMconsiderstwohiddenstatesforeachstate(representedbytwocolors:lightredand
blue),encodingtheinformationalongthetime(red)andvariate(blue),respectively.Furthermore,eacharrowrepresentsa
transitionmatrixAğ‘– thatdecidestohowinformationneedtobefused.Inthissection,wediscussdifferentvariantsofour
2DSSMbylimitingitsparameters.
2DMamba.WeletA2 =A3 =0intheformulationofour2DSSM.Theresultingmodelisequivalentto:
â„ ğ‘£( ,1 ğ‘¡)
+1
=AÂ¯ 1â„ ğ‘£( ,1 ğ‘¡) +BÂ¯ 1xğ‘£,ğ‘¡+1, (16)
â„ ğ‘£(2 +)
1,ğ‘¡
=AÂ¯ 4â„ ğ‘£( ,2 ğ‘¡) +BÂ¯ 2xğ‘£+1,ğ‘¡, (17)
yğ‘£,ğ‘¡ =C1â„ ğ‘£( ,1 ğ‘¡) +C2â„ ğ‘£( ,2 ğ‘¡), (18)
whereAÂ¯ 1 =exp(Î” 1A1),AÂ¯ 2 =exp(Î” 2A2),BÂ¯ 1 = (cid:20) A 1âˆ’1(cid:0) AÂ¯ 1 0âˆ’I(cid:1) B 1(1)(cid:21) ,andBÂ¯ 2 = (cid:20)
A
4âˆ’1(cid:0) AÂ¯ 40 âˆ’I(cid:1)
B
2(2)(cid:21) .Thisformulationwith
data-dependentparameters,isequivalenttousingtwoS6blocks(GuandDao2023)eachofwhichalongadimension.
Notably,thesetwoS6blocksarenotseparateastheoutputyğ‘£,ğ‘¡ isbasedonbothhiddenstatesâ„ ğ‘£( ,1 ğ‘¡) andâ„ ğ‘£( ,2 ğ‘¡),capturing2D
inductivebias.
2DMamba-2.Recently,DaoandGu(2024)presentMamba-2thatre-formulatesS6blockusingstructuredsemi-separable
matrices,resultinginmoreefficienttrainingandabilityofhavinglargerrecurrentstatesizes. Althoughweleavethe
explorationofhowgeneric2DSSMscanbere-formulatedbytensors(seeSection5forfurtherdiscussion),thespecialcase
ofA2 =A3 =0,similartotheaboveformulation,canbere-formulatedastwoSSDblocks(DaoandGu2024)eachofwhich
alongadimension.Furthermore,forbi-directionalityalongthevariates,onecanusequasi-separablestructuredmatrices,
whichinherentlycapturesbi-directionalityasdiscussedbyBehrouz,Santacatterina,andZabih(2024):
yğ‘£,ğ‘¡
=(cid:169)
(cid:173) (cid:173)
(cid:173)
C1C ğ‘£,21 Ağ‘£,1
1 . .
.BÂ¯ ğ‘£,21 Bğ‘£Â¯,1
1ğ‘£,1
C1ğ‘£,20
. .
.BÂ¯
1ğ‘£,2
. . ... . .. . 0 0
. .
.
(cid:170)
(cid:174) (cid:174) (cid:174)xğ‘£,: (19)
(cid:173) (cid:174)
(cid:171)C (cid:32)(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)(cid:32)ğ‘£(cid:32)(cid:32),(cid:32)ğ‘¡(cid:32)(cid:32)(cid:32)(cid:32)(cid:0) (cid:32)(cid:32)(cid:206) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ğ‘–ğ‘¡ (cid:32)(cid:32)=(cid:32)(cid:32)(cid:32)2 (cid:32)(cid:32)(cid:32)(cid:32)A (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)ğ‘£(cid:32)(cid:32),(cid:32)ğ‘–(cid:32)(cid:32)(cid:32)(cid:1) (cid:32)(cid:32)(cid:32)B (cid:32)Â¯ (cid:32)(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)ğ‘£(cid:32)(cid:32),(cid:32)1(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)C (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)ğ‘£(cid:32)(cid:32),(cid:32)ğ‘¡(cid:32)(cid:32)(cid:32)(cid:32)(cid:0) (cid:32)(cid:206) ğ‘–ğ‘¡ (cid:32)(cid:32)=(cid:32)(cid:32)(cid:32)3 (cid:32)(cid:32)(cid:32)(cid:32)A (cid:32)(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)(cid:32)ğ‘£(cid:32)(cid:32),(cid:32)ğ‘–(cid:32)(cid:32)(cid:1) (cid:32)(cid:32)(cid:32)(cid:32)BÂ¯ (cid:32)(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)ğ‘£(cid:32)(cid:32),(cid:32)2(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32). (cid:32)(cid:32)(cid:32). (cid:32)(cid:32)(cid:32). (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)C (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)ğ‘£(cid:32)(cid:32),(cid:32)ğ‘¡(cid:32)(cid:32)(cid:32)BÂ¯ (cid:32)(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)ğ‘£(cid:32)(cid:32),(cid:32)ğ‘¡(cid:32)(cid:172)
(cid:124) (cid:123)(cid:122) (cid:125)
SSDBlock
(cid:169)
ğ›¾ 1 C 2â€² ğ‘£âˆ’1,ğ‘¡A 4â€² ğ‘£âˆ’1,ğ‘¡BÂ¯ 2â€²
ğ‘£,ğ‘¡
... C 2â€²
ğ‘£,ğ‘¡
(cid:16) (cid:206) ğ‘–ğ‘£ =âˆ’ 11 A 4â€² ğ‘–,ğ‘¡(cid:17) BÂ¯ 2â€²
1,ğ‘¡ (cid:170)
+(cid:173) (cid:173) (cid:173) C22,ğ‘¡A42,ğ‘¡BÂ¯ 21,ğ‘¡ ğ›¾ 2 ... C 2â€² ğ‘£âˆ’1,ğ‘¡ (cid:16) (cid:206) ğ‘–ğ‘£ =âˆ’ 21 A 4â€² ğ‘–,ğ‘¡(cid:17) BÂ¯ 2â€² 2,ğ‘¡(cid:174) (cid:174) (cid:174)x:,ğ‘¡, (20)
(cid:173)
(cid:173)
. .
.
. .
.
... . .
.
(cid:174)
(cid:174)
(cid:173) (cid:174)
(cid:171)C (cid:32)(cid:32)(cid:32)(cid:32)2 (cid:32)(cid:32)(cid:32)ğ‘£(cid:32)(cid:32),ğ‘¡(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:0) (cid:32)(cid:32)(cid:206) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ğ‘– (cid:32)ğ‘£ (cid:32)=(cid:32)(cid:32)(cid:32)2 (cid:32)(cid:32)(cid:32)(cid:32)A (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)4 (cid:32)(cid:32)ğ‘–(cid:32)(cid:32),ğ‘¡(cid:32)(cid:32)(cid:32)(cid:1) (cid:32)(cid:32)(cid:32)(cid:32)B (cid:32)Â¯ (cid:32)(cid:32)(cid:32)2 (cid:32)(cid:32)(cid:32)1(cid:32),(cid:32)ğ‘¡(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)C (cid:32)(cid:32)(cid:32)(cid:32)2 (cid:32)(cid:32)(cid:32)ğ‘£(cid:32)(cid:32),ğ‘¡(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:0) (cid:32)(cid:32)(cid:206) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ğ‘–ğ‘£ (cid:32)(cid:32)=(cid:32)(cid:32)(cid:32)3 (cid:32)(cid:32)(cid:32)(cid:32)A (cid:32)(cid:32)(cid:32)(cid:32)4ğ‘–,ğ‘¡(cid:1) (cid:32)(cid:32)(cid:32)(cid:32)B (cid:32)Â¯ (cid:32)(cid:32)(cid:32)2 (cid:32)(cid:32)2(cid:32)(cid:32),(cid:32)ğ‘¡(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32). (cid:32)(cid:32). (cid:32)(cid:32)(cid:32). (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)ğ›¾ (cid:32)(cid:32)(cid:32)(cid:32)ğ‘£
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:172)
(cid:124) (cid:123)(cid:122) (cid:125)
Quasi-SeparableBlock
wherexğ‘£,:andx:,ğ‘¡ arethevectorswhenwefixğ‘£ andğ‘¡ ininputx,respectively.
73.3 ChimeraNeuralArchitecture
In this section, we use a stack of our 2D SSMs, with non-linearity in between, to enhance the expressive power and
capabilitiesoftheabovementioned2DSSM.Tothisend,similartodeepSSMmodels(M.Zhangetal.2023),weallowall
parameterstobelearnableandineachlayerweusemultiple2DSSMs,eachofwhichwithitsownresponsibility.Also,in
thedata-dependentvariantofChimera,weletparametersBğ‘–,Cğ‘–,andÎ” ğ‘– forğ‘– âˆˆ {1,2}bethefunctionoftheinputx:
Bğ‘– =Linear Bğ‘–(ğ‘¥), Cğ‘– =Linear Cğ‘–(ğ‘¥), Î” ğ‘– =Softplus(cid:0) LinearÎ”ğ‘–(ğ‘¥)(cid:1). (21)
Chimerafollowsthecommonlyuseddecompositionoftimeseries,anddecomposesthemintotrendcomponentsand
seasonalpatterns.it,however,usesspecialtraitsof2DSSMtocapturetheseterms.
SeasonalPatterns.Tocapturethemulti-resolutionseasonalpatterns,wetakeadvantageofthediscretizationprocess.
Proposition 3.1 states that if x(ğ‘£,ğ‘¡) â†¦â†’ y(ğ‘£,ğ‘¡) with parameters ({AÂ¯ ğ‘–},{BÂ¯ ğ‘–},{CÂ¯ ğ‘–},Î” 1,Î” 2) then x(ğ‘£,ğ‘˜ğ‘¡) â†¦â†’ y(ğ‘£,ğ‘˜ğ‘¡) with
({AÂ¯ ğ‘–},{BÂ¯ ğ‘–},{CÂ¯ ğ‘–},ğ‘˜Î” 1,Î” 2).Accordingly,weuse2D-SSM(.)modulewithaseparatelearnableÎ”
ğ‘ 
thatisresponsibletolearn
thebestresolutiontocaptureseasonalpatterns.AnotherinterpretationforthismoduleisbasedonSAR(ğ‘,ğ‘,ğ‘ )(Equation4).
Inthiscase,Î” aimstolearnaproperparameterğ‘  tocaptureseasonalpatterns.Sinceweexpecttheresolutionbeforeand
ğ‘ 
afterthismodulematches,weaddadditionalre-discretizationmodule(asimplelinearlayer),afterthismodule.
TrendComponents.ThesecondmoduleofChimera,2D-SSMğ‘¡ (.)simplyusesasequenceofmultiple2DSSMstolearn
trendcomponents. Propercombinationoftheoutputsofthisandthepreviousmodulescancapturebothseasonaland
trendcomponents.
Both Modules Together. We followed previous studies (Toner and Darlow 2024) and consider residual connection
modelingforlearningtrendandseasonalpatterns.GiveninputdataXËœ
0
=X,andâ„“ =0,...,L,wehave:
XË† â„“+1 =2D-SSMğ‘¡ (cid:16) XËœ â„“(cid:17) , (22)
XËœ â„“+1 =Re-Discretization(cid:16) 2D-SSMğ‘  (cid:16) XËœ â„“ âˆ’XË† â„“+1(cid:17)(cid:17) . (23)
Figure1illustratethearchitectureofChimera. Duetotheabilityofour2DSSMtorecoversmoothingtechniques(see
Theorem3.4),thiscombinationofmodulesfortrendandseasonalpatternscanbeviewedasageneralizationoftraditional
methodsthatusemovingaveragewithresidualconnectiontomodelseasonality(TonerandDarlow2024).
GatingwithLinearMapping.InspiredbythesuccessofgatedrecurrentandSSM-basedmodels(GuandDao2023;Qin,
Yang,andZhong2023),weuseaheadofafullyconnectedlayerwithSwish(Ramachandran,Zoph,andLe2017),resulting
inSwiGLUvariant(Touvronetal.2023).Whilewevalidatethesignificanceofthishead,this
Closed-Loop2DSSMDecoder. Toenhancethegeneralizabilityandtheabilityofourmodelforlonger-horizon,we
extendtheclosed-loopdecodermodule(M.Zhangetal.2023),whichissimilartoautoregression,tomultivariatetime
series.Weusedistinctprocessesfortheinputsandoutputs,usingadditionalmatricesD1andD2ineachdecoder2DSSM,
wemodelfutureinputtime-stepsexplicitly:
yğ‘£,ğ‘¡ =C1â„ ğ‘£( ,1 ğ‘¡) +C2â„ ğ‘£( ,2 ğ‘¡), (24)
uğ‘£,ğ‘¡ =D1â„ ğ‘£( ,1 ğ‘¡) +D2â„ ğ‘£( ,2 ğ‘¡), (25)
whereuğ‘£,ğ‘¡ isthenextinputandyğ‘£,ğ‘¡ istheoutput.Notethattheotherparts(recurrence)arethesameasEquation6.Figure2
illustratethearchitectureofclosed-loop2DSSM.
3.4 TheoreticalJustification
Inthissection,weprovidesometheoreticalevidencesfortheperformanceofChimera.Theseresultsaremostlyrevisiting
the theorems by M. Zhang et al. (2023) and Baron, Zimerman, and Wolf (2024), and extending them for Chimera. In
thefirsttheorem, weshowthatChimerarecoversseveralclassicmethods, andpre-processingstepsasitcanrecover
SpaceTime(M.Zhangetal.2023)andadditionallybecauseofitsdesign,itcanrecoverSARIMA(BenderandSimonovic
1994):
8Theorem3.4. Chimeracanrepresentseasonalautoregressiveprocess,SARIMA(BenderandSimonovic1994),SpaceTime(M.
Zhang et al. 2023), and so ARIMA (Bartholomew 1971), exponential smoothing (Winters 1960), and controllable linear
timeâ€“invariantsystems(C.-T.Chen1984).
Theorem 3.5. Chimera can represent S4nd (Nguyen et al. 2022), TSM2 (Behrouz, Santacatterina, and Zabih 2024), and
TSMixer(S.-A.Chenetal.2023).
NexttheoremcomparestheexpressivenessofChimerawithsomeexisting2DdeepSSMs. SinceChimeracanrecover
2DSSM(Baron,Zimerman,andWolf2024),itcanexpressfull-rankkernelswithaconstantnumberofparameters:
Theorem 3.6. Similar to 2DSSM (Baron, Zimerman, and Wolf 2024), Chimera can express full-rank kernels with O(1)
parameters,whileexistingdeepSSMs(Behrouz,Santacatterina,andZabih2024;Nguyenetal.2022)requireO(ğ‘)parameters
toexpressğ‘-rankkernels.
4 Experiments
GoalsandBaselines.WeevaluateChimeraonawiderangeoftimeseriestasks.InÂ§4.1wecompareChimerawiththe
state-of-the-artgeneralmultivariatetimeseriesmodels(Behrouz,Santacatterina,andZabih2024;Dasetal.2023;Limand
Zohren2021;M.Liuetal.2022;YongLiu,Hu,etal.2024;LuoandX.Wang2024;BadriN.PatroandVijayS.Agneeswaran
2024;Wooetal.2022;H.Wu,Hu,etal.2023;H.Wu,Xu,etal.2021;Y.ZhangandYan2023;T.Zhou,Z.Ma,Wen,X.Wang,
etal.2022)onlong-termforecastingandclassificationtasks. Inthenextpart,wetesttheperformanceofChimerain
short-termforecasting.InÂ§4.1weperformacasestudyonhumanneuralactivitytoclassifyseenimages,whichrequires
capturingcomplexdynamicdependenciesofvariates,totesttheabilityofChimeraincapturingcross-variateinformation
andthesignificanceofdata-dependency.InÂ§4.2,weevaluatethesignificanceoftheChimeraâ€™scomponentsbyperforming
ablationstudies.InÂ§4.2,weevaluatewhetherthesuperiorperformanceofChimeracoincidewithitsefficiency.Finally,
wetesttheChimeraâ€™sgeneralizabilityonunseenvariatesandfurtherevaluateitsabilitytofilterirrelevantcontextinÂ§4.3.
ThedetailsandadditionalexperimentsareinAppendixG.
Table1: AveragePerformanceonlong-termforecastingtask.Thefirstandsecondresultsarehighlightedinred(bold)andorange
(underline).FullresultsarereportedinAppendixG.
Chimera TSM2 Simba TCN iTransformer RLinear PatchTST Crossformer TiDE TimesNet DLinear
(ours) 2024 2024 2024 2024 2023 2023 2023 2023 2023 2023
MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE
ETTm1 0.3450.377 0.361 - 0.3830.396 0.351 0.381 0.407 0.410 0.4140.4070.3870.4000.513 0.496 0.4190.4190.4000.4060.4030.407
ETTm2 0.250 0.316 0.267 - 0.2710.327 0.253 0.3140.288 0.332 0.2860.3270.2810.3260.757 0.610 0.3580.4040.2910.3330.3500.401
ETTh1 0.405 0.424 0.403 - 0.4410.432 0.404 0.4200.454 0.447 0.4460.4340.4690.4540.529 0.522 0.5410.5070.4580.4500.4560.452
ETTh2 0.3180.375 0.333 - 0.3610.391 0.322 0.379 0.383 0.407 0.3740.3980.3870.4070.942 0.684 0.6110.5500.4140.4270.5590.515
ECL 0.1540.249 0.169 - 0.1850.274 0.156 0.253 0.178 0.270 0.2190.2980.2050.2900.244 0.334 0.2510.3440.1920.2950.2120.300
Exchange 0.311 0.358 0.443 - - - 0.302 0.366 0.360 0.403 0.3780.4170.3670.4040.940 0.707 0.3700.4130.4160.4430.3540.414
Traffic 0.403 0.286 0.420 - 0.4930.2910.3980.2700.428 0.282 0.6260.3780.4810.3040.550 0.304 0.7600.4730.6200.3360.6250.383
Weather 0.2190.258 0.239 - 0.2550.280 0.224 0.264 0.258 0.278 0.2720.2910.2590.2810.259 0.315 0.2710.3200.2590.2870.2650.317
1stCount 5 5 1 - 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0
4.1 MainResults: ClassificationandForecasting
Long-TermForecasting.Weperformexperimentsinlong-termforecastingtaskonbenchmarkdatasets(H.Zhouetal.
2021).Table1reportstheaverageofresultsoverdifferenthorizons(fortheresultsofeachseeTable8).Chimerashows
outstandingperformance,achievingthebestorthesecondbestresultsinallthedatasetsandoutperformsbaselinesin5
outof8benchmarks. Notably,itsurpassesextensivelystudiedMLP-basedandTransformer-basedmodelswhilebeing
moreefficient(seeTable3,Figure4,andAppendixG),providingabetterbalanceofperformanceandefficiency.Itfurther
significantlyoutperformsrecurrentmodels,includingveryrecentMamba-basedarchitectures(Behrouz,Santacatterina,
9andZabih2024;BadriN.PatroandVijayS.Agneeswaran2024),unleashingthepotentialofclassicalmodels,SSMs,when
arecarefullydesignedindeeplearningsettings.
ClassificationandAnomalyDetection. WeevaluatetheperformanceofChimerainECGclassificationonPTB-XL
dataset (Wagner et al. 2020) (see Table 2), speech classification (Warden 2018)(Table 3), 10 multivariate datasets from
UEATimeSeriesClassificationArchive(Bagnalletal.2018)(seeFigure3andTable10),andanomalydetectiontasks
onfivewidely-usedbenchmarks: SMD(Suetal.2019),SWaT(MathurandTippenhauer2016),PSM(Abdulaal,Z.Liu,
andLancewicki2021)andSMAP(Hundmanetal.2018)(seeFigure3andTable11). Foreachbenchmark, weusethe
state-of-the-artmethodsthatareapplicabletothetaskasthebaselines.Table2reportstheperformanceofChimeraand
baselinesonECGclassificationtasks.Chimeraoutperformsallthebaselinesin4/6tasks,whileachievingthesecondbest
resultsontheremainingtasks.Sincethesetasksareunivariatetimeseries,weattributetheoutstandingperformanceof
Chimera,specificallycomparedtoSpaceTime(M.Zhangetal.2023),toitsabilityofcapturingseasonalpatternsandits
input-dependentparameters,resultingindynamicallylearndependencies.
Table3reportstheresultsonspeechaudioclassificationtask,whichrequirelong-rangemodelingoftimeseries.Dueto
thelengthofthesequence(16K),LSSL(Gu,Goel,andRe2022)andTransformer(Vaswanietal.2017)hasoutofmemory
(OOM)issue,showingtheefficiencyofChimeracomparedtoalternativebackbones.
Finally,wereportthesummaryoftheresultsinmultivariatetimeseriesclassificationandanomalydetectiontasksin
Figure3.ThefulllistofresultscanbefoundinTable10andTable11.Chimerashowsoutstandingperformance,achieving
highestaverageaccuracyandF1scoreinclassificationandanomalydetectiontasksevencomparedtoveryrecentand
state-of-the-artmethods(LuoandX.Wang2024;H.Wu,Hu,etal.2023).
Table2:ECGstatementclassificationonPTB-XL(100Hzversion). Table3:Speechclassification.
Tasks All Diag Sub-diag Super-diag Form Rhythm Method Acc.(%)
Chimera 0.941 0.947 0.935 0.930 0.901 0.975 Chimera 98.40
SpaceTime(M.Zhangetal.2023) 0.936 0.941 0.933 0.929 0.883 0.967
SpaceTime 97.29
S4(Gu,Goel,andRe2022) 0.938 0.939 0.929 0.931 0.895 0.977
S4 98.32
Inception 0.925 0.931 0.930 0.921 0.899 0.953
LSSL OOM
xRN-101 0.925 0.937 0.929 0.928 0.896 0.957
LSTM 0.907 0.927 0.928 0.927 0.851 0.953 WaveGan-D 96.25
Transformer 0.857 0.876 0.882 0.887 0.771 0.831 Transformer OOM
Short-Term Forecasting. Our evaluation on short-term forecasting tasks on M4 benchmark datasets (Godahewa et
al.2021)reportsinTable4(FulllistinTable9), whichalsoshowsthesuperiorperformanceofChimeracomparedto
baselines.
Table4:Short-termforecastingtaskontheM4dataset.FullresultsarereportedinAppendixG.
Models
ChimeraModernTCNPatchTSTTimesNetN-HiTSN-BEATSâˆ— ETSâˆ— LightTSDLinearFEDâˆ—StationaryAutoâˆ—Pyraâˆ— Inâˆ— Reâˆ— LSTM
(ours) 2024 2023 2023 2022 2019 2022 2022 2023 2022 2022 2021 2021 2021 2020 1997
SMAPE 11.618 11.698 11.807 11.829 11.927 11.851 14.718 13.525 13.639 12.840 12.780 12.90916.98714.08618.200160.031
MASE 1.528 1.556 1.590 1.585 1.613 1.599 2.408 2.111 2.095 1.701 1.756 1.771 3.265 2.718 4.223 25.788
OWA 0.827 0.838 0.851 0.851 0.861 0.855 1.172 1.051 1.051 0.918 0.930 0.939 1.480 1.230 1.775 12.642
CaseStudyofBrainActivity.Inputdependencyisamusttocapturethedynamicofdependencies.Tosupportthisclaim,
weuseBVFC(Behrouz,Delavari,andHashemi2024)(multivariatetimeseriesonly),whichaimtoclassifyseenimages
byitscorrespondingbrainactivityresponse. Thistask,requiresfocusingmoreonthedependenciesofbrainunitsand
theirresponsesratherthantheactualtimeseries. Also,sinceeachwindowcorrespondstoaspecificimage,themodel
needstocapturethedependenciesbasedonthecurrentwindow,requiringtobeinput-dependent.Resultsarereportedin
Table5.ChimerasignificantlyoutperformsallthebaselinesincludingourChimerabutwithoutdata-dependentparameters
(convolutionform).Duetothelargenumberofbrainunits,i.e.,9K,inthefirstdataset,transformer-basedmethodsface
OOMissue.However,theyarealsodata-dependentandsoshowsthesecondbestresultsinsecondandthirddatasets.This
resultssupportthesignificanceofdata-dependencyinChimera.
10
dethgieW egarevA4.2 AblationStudyandEfficiency
ToevaluatethesignificanceoftheChimeraâ€™sdesign,weperformablationstudiesandremoveoneofthecomponentsat
eachtime,keepingotherpartsunchanged.Table6reportstheresults.ThefirstrowreportstheChimeraâ€™sperformance,
whilerow2usesunidirectionalrecurrencealongthevariatedimension,row3removesthegatingmechanism,row4uses
convolutionform(data-independent),androw5removesthemoduleforseasonalpatterns.Theresultsshowthatallthe
componentsofChimeracontributestoitsperformance.
Table6:AblationstudyontheChimeraâ€™sdesign.
Table5:Imageclassificationbybrainactivity(Acc.%).
ETTh1 ETTm1 ETTh2
Method
Chimera Chimera(ind.) SpaceTime S4 iTrans. Trans. DLinear MSE MAE MSE MAE MSE MAE
Method
(ours) (ours) 2023 2022 2024 2017 2023
Chimera 0.405 0.424 0.345 0.377 0.318 0.375
BVFC(9K) 69.41 62.36 41.20 40.89 OOM OOM 39.74 Uni.-directional 0.409 0.429 0.354 0.385 0.326 0.381
BVFC(1K) 58.99 50.25 34.31 35.19 54.18 43.60 33.09 w/oGating 0.418 0.433 0.351 0.384 0.321 0.379
BVFC(400) 51.08 45.17 33.58 33.76 48.22 38.05 32.73 Input-independent 0.471 0.498 0.361 0.389 0.372 0.401
w/oseasonal 0.426 0.431 0.357 0.382 0.331 0.386
Figure3: Classificationandanomalydetectionperformance. Fulllistwithadditional
Figure4:Wall-clockscaling.
baselinesisinAppendixG.
Length of Time Series. We perform experiments on the effect of the sequence length on the efficiency of Chimera
andbaselines.TheresultsarereportedinFigure4.Chimerascaleslinearlywithrespecttothesequencelengthandhas
smootherscalingthanS4(Gu,Goel,andRe2022)andTransformers(Vaswanietal.2017). Theseresultsalsohighlight
thesignificanceofouralgorithmthatuses2DparallelscansfortrainingChimera.Thisalgorithmresultsinâ‰ˆÃ—4faster
training,whichisveryclosedtotheconvolutionalformatwithout datadependency.Chimeraalsohasacloserunningtime
toSpaceTime(M.Zhangetal.2023),whichhas1Drecurrent.
4.3 SelectionMechanismAlongTimeandVariate
VariateGeneralization.Wearguethatthedata-dependencywithdiscretizationallowsthemodeltofiltertheirrelevant
contextbasedontheinput,resultinginmoregeneralizability.InspiredbyYongLiu,Hu,etal.(2024),wetrainourmodel
(andbaseline)on20%ofvariatesandevaluateitsgeneralizabilitytounseenvariates.TheresultsarereportedinFigure5.
ChimerahasonpargeneralizabilitycomparedtoTransformers(whenappliedalongthevariatedimension),whichwe
attributestoitsdata-dependentparametersasChimerawithconvolutionformperformspoorlyonunseenvariates.
ContextFiltering.IncreasingthelookbacklengthdoesnotnecessarilyresultinbetterperformanceforTransformers(Yong
Liu, Hu, et al. 2024). Due to the selection mechanism of Chimera, we expect it to filter irrelevant information and
monotonicallyperformsbetter.Figure6reportstheChimeraâ€™sperformance(w/andw/odata-dependency)andtransformer-
basedbaselines(H.Wu,J.Wu,etal.2022;H.Zhouetal.2021)whilevaryingthelookbacklength. Chimeraduetoits
selectionmechanismmonotonicallyperformsbetterwithincreasingthelookback.
11Figure6:Effectoflookbacklength.
Figure5:Selectionresultsingeneralizationtounseenvariates.
5 Conclusion and Future Work
ThispaperpresentsChimera,athree-headed2-dimensionalSSMmodelwithprovablyhighexpressivepower.Chimera
is based on 2D SSMs with careful design of parameters that allows it to dynamically and simultaneously capture the
dependenciesalongbothtimeandvariatedimensions.Weprovidedifferentviewsofour2DSSMforefficienttraining,and
presentadata-dependentformulationwithafastimplementationusing2Dscans.Chimerausestwodifferentmodulesto
capturetrendandseasonalpatternsanditsdiscretizationprocessallowsthesemodulestoadjusttheresolutionateachtime
stampandforeachvariate.OurexperimentalandtheoreticalresultssupporttheeffectivenessandefficiencyofChimerain
awiderangeoftasks.
OtherDataModalities.WhiletheparameterizationofChimeraisdesignedtoexpressivelymodeltimeseriesdata,the
overallarchitectureofChimeraandourdata-dependent2DSSMwithits2Dscanformintrainingarepotentiallyapplicable
forotherhigherdimensionaldatatypes,e.g.,images,videos,multi-channelspeech,etc.Despiterecentattemptstodesign
effectiveSSM-basedvisionmodels(BadriNarayanaPatroandVijaySrinivasAgneeswaran2024),theexistingmodels
sufferfromthelackof2Dspatialinductivebias.Our2DSSM,however,isabletoprovide2Dinductivebias,potentially
beingmoreeffectivethanexisting1DselectiveSSMs.Accordingly,apromisingdirectionistoexplorethepotentialof2D
selectiveSSMsforotherhighdimensionaldatamodalitiesanddifferenttasks.
VariantsofChimera.AsdiscussedinSection3.2,differentvariantsofChimeraresultintheextensionofwell-known
architectureslikeMamba(GuandDao2023)to2-dimensionaldata,orextensionofmethodslikeS4ND(Nguyenetal.2022),
and2DSSM(Baron,Zimerman,andWolf2024)tohavedata-dependentweights.Despitethefactthatourformulationof
the2DSSMwithdiscretizationanddatadependentparametersprovidesamoregeneralframeworktoextendSSMsto
higher-dimensionaldata,itdoesnotnecessarilymeanthatforanydatamodalitiesandnetworksize,itsgenericformcan
achievethebestresult.Whileourexperimentalevaluationislimitedtothegenericformofour2DSSMandChimera,it
isapromisingfuturedirectiontoseeiflimitingtransitionmatrixAğ‘– (i.e.,2DMamba,2DMamba-2)canresultinmore
powerfulmodels.Weleavetheexperimentalevaluationsofthesespacialcasesofour2DSSMforfuturework.
Efficiency.Whileour2Dscandecreasesthenumberofrequiredrecurrencetocomputethehiddenstates,itsstillbasedon
anaiveimplementationofparallelscan.Thereisapotentialforfurtherimprovementof2Dparallelscanâ€™sefficiencyby
usingmorehardware-awareimplementationssimilartoselectivescanbyGuandDao(2023).
References
[1] AhmedAbdulaal,ZhuanghuaLiu,andTomerLancewicki.â€œPracticalapproachtoasynchronousmultivariatetime
seriesanomalydetectionandlocalizationâ€.In:Proceedingsofthe27thACMSIGKDDconferenceonknowledgediscovery
&datamining.2021,pp.2485â€“2494.
[2] MasanaoAoki.Statespacemodelingoftimeseries.SpringerScience&BusinessMedia,2013.
[3] AnthonyBagnall,HoangAnhDau,JasonLines,MichaelFlynn,JamesLarge,AaronBostrom,PaulSoutham,and
EamonnKeogh.â€œTheUEAmultivariatetimeseriesclassificationarchive,2018â€.In:arXivpreprintarXiv:1811.00075
(2018).
[4] EthanBaron,ItamarZimerman,andLiorWolf.â€œA2-DimensionalStateSpaceLayerforSpatialInductiveBiasâ€.In:
TheTwelfthInternationalConferenceonLearningRepresentations.2024.url:https://openreview.net/forum?id=
BGkqypmGvm.
[5] DavidJBartholomew.TimeSeriesAnalysisForecastingandControl.1971.
12[6] AliBehrouz,ParsaDelavari,andFarnooshHashemi.â€œUnsupervisedRepresentationLearningofBrainActivityvia
BridgingVoxelActivityandFunctionalConnectivityâ€.In:Internationalconferenceonmachinelearning(ICML).2024.
[7] AliBehrouzandFarnooshHashemi.â€œGraphMamba:TowardsLearningonGraphswithStateSpaceModelsâ€.In:
arXivpreprintarXiv:2402.08678(2024).
[8] AliBehrouz,MicheleSantacatterina,andRaminZabih.â€œMambamixer:Efficientselectivestatespacemodelswith
dualtokenandchannelselectionâ€.In:arXivpreprintarXiv:2403.19888(2024).
[9] MichaelBenderandSlobodanSimonovic.â€œTime-seriesmodelingforlong-rangestream-flowforecastingâ€.In:Journal
ofWaterResourcesPlanningandManagement 120.6(1994),pp.857â€“870.
[10] GeorgeEPBoxandGwilymMJenkins.â€œSomerecentadvancesinforecastingandcontrolâ€.In:JournaloftheRoyal
StatisticalSociety.SeriesC(AppliedStatistics)17.2(1968),pp.91â€“109.
[11] CristianChallu,KinGOlivares,BorisNOreshkin,FedericoGarza,MaxMergenthaler,andArturDubrawski.â€œN-HiTS:
NeuralHierarchicalInterpolationforTimeSeriesForecastingâ€.In:arXivpreprintarXiv:2201.12886(2022).
[12] Si-AnChen,Chun-LiangLi,NateYoder,SercanOArik,andTomasPfister.â€œTsmixer:Anall-mlparchitecturefor
timeseriesforecastingâ€.In:arXivpreprintarXiv:2303.06053(2023).
[13] Chi-TsongChen.Linearsystemtheoryanddesign.Saunderscollegepublishing,1984.
[14] ZongleiChen,MinboMa,TianruiLi,HongjunWang,andChongshouLi.â€œLongsequencetime-seriesforecasting
withdeeplearning:Asurveyâ€.In:InformationFusion97(2023),p.101819.
[15] JunyoungChung,CaglarGulcehre,KyungHyunCho,andYoshuaBengio.â€œEmpiricalevaluationofgatedrecurrent
neuralnetworksonsequencemodelingâ€.In:arXivpreprintarXiv:1412.3555(2014).
[16] TriDaoandAlbertGu.â€œTransformersareSSMs:GeneralizedModelsandEfficientAlgorithmsThroughStructured
StateSpaceDualityâ€.In:InternationalConferenceonMachineLearning(ICML).2024.
[17] AbhimanyuDas,WeihaoKong,AndrewLeach,ShaanKMathur,RajatSen,andRoseYu.â€œLong-termForecasting
withTiDE:Time-seriesDenseEncoderâ€.In:TransactionsonMachineLearningResearch(2023).issn:2835-8856.url:
https://openreview.net/forum?id=pCbC3aQB5W.
[18] RikusEising.â€œRealizationandstabilizationof2-Dsystemsâ€.In:IEEETransactionsonAutomaticControl23.5(1978),
pp.793â€“799.
[19] EttoreFornasiniandGiovanniMarchesini.â€œDoubly-indexeddynamicalsystems:State-spacemodelsandstructural
propertiesâ€.In:Mathematicalsystemstheory12.1(1978),pp.59â€“72.
[20] Jean-YvesFranceschi,AymericDieuleveut,andMartinJaggi.â€œUnsupervisedScalableRepresentationLearningfor
MultivariateTimeSeriesâ€.In:NeurIPS.2019.
[21] Kelum Gajamannage, Yonggi Park, and Dilhani I Jayathilake. â€œReal-time forecasting of time series in financial
marketsusingsequentiallytraineddual-LSTMsâ€.In:ExpertSystemswithApplications223(2023),p.119879.
[22] RakshithaGodahewa,ChristophBergmeir,GeoffreyIWebb,RobJHyndman,andPabloMontero-Manso.â€œMonash
timeseriesforecastingarchiveâ€.In:arXivpreprintarXiv:2105.06643(2021).
[23] AlbertGuandTriDao.â€œMamba:Linear-timesequencemodelingwithselectivestatespacesâ€.In:arXivpreprint
arXiv:2312.00752(2023).
[24] Albert Gu, Tri Dao, Stefano Ermon, Atri Rudra, and Christopher RÃ©. â€œHippo: Recurrent memory with optimal
polynomialprojectionsâ€.In:Advancesinneuralinformationprocessingsystems33(2020),pp.1474â€“1487.
[25] AlbertGu,KaranGoel,AnkitGupta,andChristopherRÃ©.â€œOntheParameterizationandInitializationofDiagonal
StateSpaceModelsâ€.In:AdvancesinNeuralInformationProcessingSystems.Ed.byAliceH.Oh,AlekhAgarwal,
DanielleBelgrave,andKyunghyunCho.2022.url:https://openreview.net/forum?id=yJE7iQSAep.
[26] AlbertGu,KaranGoel,andChristopherRe.â€œEfficientlyModelingLongSequenceswithStructuredStateSpacesâ€.
In: International Conference on Learning Representations. 2022. url: https://openreview.net/forum?id=
uYLFoz1vlAC.
[27] AlbertGu,CaglarGulcehre,ThomasPaine,MattHoffman,andRazvanPascanu.â€œImprovingthegatingmechanism
ofrecurrentneuralnetworksâ€.In:InternationalConferenceonMachineLearning.PMLR.2020,pp.3800â€“3809.
[28] AlbertGu,IsysJohnson,KaranGoel,KhaledSaab,TriDao,AtriRudra,andChristopherRÃ©.â€œCombiningrecurrent,
convolutional, and continuous-time models with linear state space layersâ€. In: Advances in neural information
processingsystems34(2021),pp.572â€“585.
[29] AlbertGu,IsysJohnson,AmanTimalsina,AtriRudra,andChristopherRe.â€œHowtoTrainyourHIPPO:StateSpace
ModelswithGeneralizedOrthogonalBasisProjectionsâ€.In:InternationalConferenceonLearningRepresentations.
2023.url:https://openreview.net/forum?id=klK17OQ3KB.
[30] AndrewCHarvey.â€œForecasting,structuraltimeseriesmodelsandtheKalmanfilterâ€.In:Cambridgeuniversitypress
(1990).
13[31] MartinNHebart,OliverContier,LinaTeichmann,AdamHRockter,CharlesYZheng,AlexisKidder,AnnaCorriveau,
Maryam Vaziri-Pashkam, and Chris I Baker. â€œTHINGS-data, a multimodal collection of large-scale datasets for
investigatingobjectrepresentationsinhumanbrainandbehaviorâ€.In:Elife12(2023),e82580.
[32] TsHinamoto.â€œRealizationsofastate-spacemodelfromtwo-dimensionalinput-outputmapâ€.In:IEEETransactions
onCircuitsandSystems27.1(1980),pp.36â€“44.
[33] S.HochreiterandJ.Schmidhuber.â€œLongShort-TermMemoryâ€.In:NeuralComput.(1997).
[34] KyleHundman,ValentinoConstantinou,ChristopherLaporte,IanColwell,andTomSoderstrom.â€œDetectingspace-
craftanomaliesusinglstmsandnonparametricdynamicthresholdingâ€.In:Proceedingsofthe24thACMSIGKDD
internationalconferenceonknowledgediscovery&datamining.2018,pp.387â€“395.
[35] RomainIlbert,AmbroiseOdonnat,VasiliiFeofanov,AladinVirmaux,GiuseppePaolo,ThemisPalpanas,andIevgen
Redko.â€œUnlockingthePotentialofTransformersinTimeSeriesForecastingwithSharpness-AwareMinimization
andChannel-WiseAttentionâ€.In:arXivpreprintarXiv:2402.10198(2024).
[36] PlamenChIvanov,LuisANunesAmaral,AryLGoldberger,ShlomoHavlin,MichaelGRosenblum,ZbigniewR
Struzik,andHEugeneStanley.â€œMultifractalityinhumanheartbeatdynamicsâ€.In:Nature399.6735(1999),pp.461â€“
465.
[37] AlistairEWJohnson,LucasBulgarelli,LuShen,AlvinGayles,AyadShammout,StevenHorng,TomJPollard,Sicheng
Hao,BenjaminMoody,BrianGow,etal.â€œMIMIC-IV,afreelyaccessibleelectronichealthrecorddatasetâ€.In:Scientific
data10.1(2023),p.1.
[38] Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and FranÃ§ois Fleuret. â€œTransformers are rnns: Fast au-
toregressive transformers with linear attentionâ€. In: International conference on machine learning. PMLR. 2020,
pp.5156â€“5165.
[39] NikitaKitaev,LukaszKaiser,andAnselmLevskaya.â€œReformer:TheEfficientTransformerâ€.In:ICLR.2020.
[40] Sun-YuanKung,BernardCLevy,MartinMorf,andThomasKailath.â€œNewresultsin2-Dsystemstheory,PartII:2-D
state-spacemodelsâ€”realizationandthenotionsofcontrollability,observability,andminimalityâ€.In:Proceedingsof
theIEEE65.6(1977),pp.945â€“961.
[41] GuokunLai,Wei-ChengChang,YimingYang,andHanxiaoLiu.â€œModelinglong-andshort-termtemporalpatterns
withdeepneuralnetworksâ€.In:SIGIR.2018.
[42] ShiyangLi,XiaoyongJin,YaoXuan,XiyouZhou,WenhuChen,Yu-XiangWang,andXifengYan.â€œEnhancingthe
LocalityandBreakingtheMemoryBottleneckofTransformeronTimeSeriesForecastingâ€.In:NeurIPS.2019.
[43] ZheLi,ShiyiQi,YiduoLi,andZenglinXu.â€œRevisitinglong-termtimeseriesforecasting:Aninvestigationonlinear
mappingâ€.In:arXivpreprintarXiv:2305.10721(2023).
[44] BryanLimandStefanZohren.â€œTime-seriesforecastingwithdeeplearning:asurveyâ€.In:PhilosophicalTransactions
oftheRoyalSocietyA379.2194(2021),p.20200209.
[45] MinhaoLiu,AilingZeng,MuxiChen,ZhijianXu,QiuxiaLai,LingnaMa,andQiangXu.â€œScinet:Timeseriesmodeling
andforecastingwithsampleconvolutionandinteractionâ€.In:AdvancesinNeuralInformationProcessingSystems35
(2022),pp.5816â€“5828.
[46] ShizhanLiu,HangYu,CongLiao,JianguoLi,WeiyaoLin,AlexXLiu,andSchahramDustdar.â€œPyraformer:Low-
complexitypyramidalattentionforlong-rangetimeseriesmodelingandforecastingâ€.In:Internationalconferenceon
learningrepresentations.2021.
[47] YongLiu,TenggeHu,HaoranZhang,HaixuWu,ShiyuWang,LintaoMa,andMingshengLong.â€œiTransformer:
InvertedTransformersAreEffectiveforTimeSeriesForecastingâ€.In:TheTwelfthInternationalConferenceonLearning
Representations.2024.url:https://openreview.net/forum?id=JePfAI8fah.
[48] YongLiu,HaixuWu,JianminWang,andMingshengLong.â€œNon-stationarytransformers:Exploringthestationarity
intimeseriesforecastingâ€.In:AdvancesinNeuralInformationProcessingSystems35(2022),pp.9881â€“9893.
[49] YongLiu,HaixuWu,JianminWang,andMingshengLong.â€œNon-stationaryTransformers:RethinkingtheStationarity
inTimeSeriesForecastingâ€.In:NeurIPS.2022.
[50] YueLiu,YunjieTian,YuzhongZhao,HongtianYu,LingxiXie,YaoweiWang,QixiangYe,andYunfanLiu.â€œVmamba:
Visualstatespacemodelâ€.In:arXivpreprintarXiv:2401.10166(2024).
[51] DonghaoLuoandXueWang.â€œModernTCN:AModernPureConvolutionStructureforGeneralTimeSeriesAnalysisâ€.
In:TheTwelfthInternationalConferenceonLearningRepresentations.2024.url:https://openreview.net/forum?
id=vpJMJerXHU.
[52] JunMa,FeifeiLi,andBoWang.â€œU-Mamba:EnhancingLong-rangeDependencyforBiomedicalImageSegmentationâ€.
In:arXivpreprintarXiv:2401.04722(2024).
14[53] EricMartinandChrisCundy.â€œParallelizingLinearRecurrentNeuralNetsOverSequenceLengthâ€.In:International
ConferenceonLearningRepresentations.2018.url:https://openreview.net/forum?id=HyUNwulC-.
[54] AdityaPMathurandNilsOleTippenhauer.â€œSWaT:AwatertreatmenttestbedforresearchandtrainingonICS
securityâ€.In:2016internationalworkshoponcyber-physicalsystemsforsmartwaternetworks(CySWater).IEEE.2016,
pp.31â€“36.
[55] EricNguyen,KaranGoel,AlbertGu,GordonDowns,PreeyShah,TriDao,StephenBaccus,andChristopherRÃ©.
â€œS4nd:Modelingimagesandvideosasmultidimensionalsignalswithstatespacesâ€.In:Advancesinneuralinformation
processingsystems35(2022),pp.2846â€“2861.
[56] YuqiNie,NamHNguyen,PhanwadeeSinthong,andJayantKalagnanam.â€œATimeSeriesisWorth64Words:Long-
termForecastingwithTransformersâ€.In:TheEleventhInternationalConferenceonLearningRepresentations.2023.
url:https://openreview.net/forum?id=Jbdc0vTOcol.
[57] BorisNOreshkin,DmitriCarpov,NicolasChapados,andYoshuaBengio.â€œN-BEATS:Neuralbasisexpansionanalysis
forinterpretabletimeseriesforecastingâ€.In:ICLR(2019).
[58] BadriN.PatroandVijayS.Agneeswaran.SiMBA:SimplifiedMamba-BasedArchitectureforVisionandMultivariate
Timeseries.2024.arXiv:2403.15360[cs.CV].
[59] BadriNarayanaPatroandVijaySrinivasAgneeswaran.â€œMamba-360:SurveyofStateSpaceModelsasTransformer
AlternativeforLongSequenceModelling:Methods,Applications,andChallengesâ€.In:arXivpreprintarXiv:2404.16112
(2024).
[60] StevePincusandRudolfEKalman.â€œIrregularity,volatility,risk,andfinancialmarkettimeseriesâ€.In:Proceedingsof
theNationalAcademyofSciences101.38(2004),pp.13709â€“13714.
[61] ZhenQin,SonglinYang,andYiranZhong.â€œHierarchicallygatedrecurrentneuralnetworkforsequencemodelingâ€.
In:AdvancesinNeuralInformationProcessingSystems36(2023).
[62] PrajitRamachandran,BarretZoph,andQuocVLe.â€œSearchingforactivationfunctionsâ€.In:arXivpreprintarXiv:1710.05941
(2017).
[63] DavidSalinas,ValentinFlunkert,JanGasthaus,andTimJanuschowski.â€œDeepAR:Probabilisticforecastingwith
autoregressiverecurrentnetworksâ€.In:Internationaljournalofforecasting36.3(2020),pp.1181â€“1191.
[64] YairSchiff,Chia-HsiangKao,AaronGokaslan,TriDao,AlbertGu,andVolodymyrKuleshov.â€œCaduceus:Bi-directional
equivariantlong-rangednasequencemodelingâ€.In:arXivpreprintarXiv:2403.03234(2024).
[65] ImanolSchlag,KazukiIrie,andJÃ¼rgenSchmidhuber.â€œLineartransformersaresecretlyfastweightprogrammersâ€.In:
InternationalConferenceonMachineLearning.PMLR.2021,pp.9355â€“9366.
[66] JimmyT.H.Smith,AndrewWarrington,andScottLinderman.â€œSimplifiedStateSpaceLayersforSequenceModelingâ€.
In:TheEleventhInternationalConferenceonLearningRepresentations.2023.url:https://openreview.net/forum?
id=Ai8Hw3AXqks.
[67] YaSu,YoujianZhao,ChenhaoNiu,RongLiu,WeiSun,andDanPei.â€œRobustanomalydetectionformultivariate
timeseriesthroughstochasticrecurrentneuralnetworkâ€.In:Proceedingsofthe25thACMSIGKDDinternational
conferenceonknowledgediscovery&datamining.2019,pp.2828â€“2837.
[68] CorentinTallecandYannOllivier.â€œCanrecurrentneuralnetworkswarptime?â€In:InternationalConferenceon
LearningRepresentations.2018.url:https://openreview.net/forum?id=SJcKhk-Ab.
[69] WilliamTonerandLukeDarlow.â€œAnAnalysisofLinearTimeSeriesForecastingModelsâ€.In:Internationalconference
onmachinelearning(ICML)(2024).
[70] HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,TimothÃ©eLacroix,Baptiste
RoziÃ¨re,NamanGoyal,EricHambro,FaisalAzhar,etal.â€œLlama:Openandefficientfoundationlanguagemodelsâ€.In:
arXivpreprintarXiv:2302.13971(2023).
[71] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,ÅukaszKaiser,and
IlliaPolosukhin.â€œAttentionisallyouneedâ€.In:Advancesinneuralinformationprocessingsystems30(2017).
[72] Patrick Wagner, Nils Strodthoff, Ralf-Dieter Bousseljot, Dieter Kreiseler, Fatima I Lunze, Wojciech Samek, and
TobiasSchaeffter.â€œPTB-XL,alargepubliclyavailableelectrocardiographydatasetâ€.In:Scientificdata7.1(2020),
pp.1â€“15.
[73] JunxiongWang,JingNathanYan,AlbertGu,andAlexanderRush.â€œPretrainingWithoutAttentionâ€.In:Findingsofthe
AssociationforComputationalLinguistics:EMNLP2023.Ed.byHoudaBouamor,JuanPino,andKalikaBali.Singapore:
AssociationforComputationalLinguistics,Dec.2023,pp.58â€“69.doi:10.18653/v1/2023.findings-emnlp.5.url:
https://aclanthology.org/2023.findings-emnlp.5.
[74] PeteWarden.â€œSpeechcommands:Adatasetforlimited-vocabularyspeechrecognitionâ€.In:arXivpreprintarXiv:1804.03209
(2018).
15[75] PeterRWinters.â€œForecastingsalesbyexponentiallyweightedmovingaveragesâ€.In:Managementscience6.3(1960),
pp.324â€“342.
[76] GeraldWoo,ChenghaoLiu,DoyenSahoo,AkshatKumar,andStevenC.H.Hoi.â€œETSformer:ExponentialSmoothing
TransformersforTime-seriesForecastingâ€.In:arXivpreprintarXiv:2202.01381(2022).
[77] HaixuWu,TenggeHu,YongLiu,HangZhou,JianminWang,andMingshengLong.â€œTimesNet:Temporal2D-Variation
ModelingforGeneralTimeSeriesAnalysisâ€.In:TheEleventhInternationalConferenceonLearningRepresentations.
2023.url:https://openreview.net/forum?id=ju_Uqw384Oq.
[78] HaixuWu,JialongWu,JiehuiXu,JianminWang,andMingshengLong.â€œFlowformer:LinearizingTransformers
withConservationFlowsâ€.In:ICML.2022.
[79] HaixuWu,JiehuiXu,JianminWang,andMingshengLong.â€œAutoformer:Decompositiontransformerswithauto-
correlationforlong-termseriesforecastingâ€.In:Advancesinneuralinformationprocessingsystems34(2021),pp.22419â€“
22430.
[80] JiehuiXu,HaixuWu,JianminWang,andMingshengLong.â€œAnomalyTransformer:TimeSeriesAnomalyDetection
withAssociationDiscrepancyâ€.In:ICLR.2021.
[81] SonglinYang,BailinWang,YikangShen,RameswarPanda,andYoonKim.â€œGatedlinearattentiontransformers
withhardware-efficienttrainingâ€.In:Internationalconferenceonmachinelearning(ICML).2024.
[82] AilingZeng,MuxiChen,LeiZhang,andQiangXu.â€œAreTransformersEffectiveforTimeSeriesForecasting?â€In:
AAAI.2023.
[83] AilingZeng,MuxiChen,LeiZhang,andQiangXu.â€œAretransformerseffectivefortimeseriesforecasting?â€In:
ProceedingsoftheAAAIconferenceonartificialintelligence.Vol.37.2023,pp.11121â€“11128.
[84] MichaelZhang,KhaledKamalSaab,MichaelPoli,TriDao,KaranGoel,andChristopherRe.â€œEffectivelyModeling
TimeSerieswithSimpleDiscreteStateSpacesâ€.In:TheEleventhInternationalConferenceonLearningRepresentations.
2023.url:https://openreview.net/forum?id=2EpjkjzdCAa.
[85] T.Zhang,YizhuoZhang,WeiCao,J.Bian,XiaohanYi,ShunZheng,andJianLi.â€œLessIsMore:FastMultivariate
TimeSeriesForecastingwithLightSampling-orientedMLPStructuresâ€.In:arXivpreprintarXiv:2207.01186(2022).
[86] YunhaoZhangandJunchiYan.â€œCrossformer:Transformerutilizingcross-dimensiondependencyformultivariate
timeseriesforecastingâ€.In:Theeleventhinternationalconferenceonlearningrepresentations.2023.
[87] HaoyiZhou,ShanghangZhang,JieqiPeng,ShuaiZhang,JianxinLi,HuiXiong,andWancaiZhang.â€œInformer:
Beyondefficienttransformerforlongsequencetime-seriesforecastingâ€.In:ProceedingsoftheAAAIconferenceon
artificialintelligence.Vol.35.2021,pp.11106â€“11115.
[88] TianZhou,ZiqingMa,QingsongWen,LiangSun,TaoYao,WotaoYin,RongJin,etal.â€œFilm:Frequencyimproved
legendrememorymodelforlong-termtimeseriesforecastingâ€.In:AdvancesinNeuralInformationProcessingSystems
35(2022),pp.12677â€“12690.
[89] Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin. â€œFedformer: Frequency enhanced
decomposedtransformerforlong-termseriesforecastingâ€.In:Internationalconferenceonmachinelearning.PMLR.
2022,pp.27268â€“27286.
16A Background
A.1 1DSpaceStateModels
1DSpaceStateModels(SSMs)arelineartime-invariantsystemsthatmapinputsequenceğ‘¥(ğ‘¡) âˆˆRğ¿ â†¦â†’ğ‘¦(ğ‘¡) âˆˆRğ¿ (Aoki
2013).SSMsusealatentstateâ„(ğ‘¡) âˆˆRğ‘Ã—ğ¿,transitionparameterAâˆˆRğ‘Ã—ğ‘,andprojectionparametersBâˆˆRğ‘Ã—1,CâˆˆR1Ã—ğ‘
tomodeltheinputandoutputas:
â„â€²(ğ‘¡) =Aâ„(ğ‘¡)+Bğ‘¥(ğ‘¡), ğ‘¦(ğ‘¡) =Câ„(ğ‘¡). (26)
MostexistingSSMs(Behrouz,Santacatterina,andZabih2024;GuandDao2023;Gu,Goel,andRe2022),firstdiscretizethe
signalsA,B,andC.Thatis,usingaparameterğš«andzero-orderhold,thediscretizedformulationisdefinedas:
â„
ğ‘¡
=AÂ¯ â„ ğ‘¡âˆ’1+BÂ¯ ğ‘¥ ğ‘¡, ğ‘¦
ğ‘¡
=Câ„ ğ‘¡, (27)
whereAÂ¯ =exp(ğš«A)andBÂ¯ = (ğš«A)âˆ’1 (exp(ğš«Aâˆ’ğ¼)) .ğš«B.(Gu,Dao,etal.2020)showthatdiscreteSSMscanbeinterpreted
asbothconvolutionsandrecurrentnetworks:i.e.,
KÂ¯ = (cid:16) CBÂ¯,CAÂ¯ BÂ¯,...,CAÂ¯ğ¿âˆ’1 BÂ¯(cid:17) ,
ğ‘¦ =ğ‘¥ âˆ—KÂ¯, (28)
whichmakestheirtrainingandinferenceveryefficientasaconvolutionandrecurrentmodel,respectively.
A.2 DataDependency
AbovediscreteSSMsarebasedondata-independentparameters.Thatis,parametersğš«,AÂ¯,BÂ¯,andCaretimeinvariantand
arethesameforanyinput.GuandDao(2023)arguethatthistimeinvariancehasthecostoflimitingSSMseffectivenessin
compressingcontextintoasmallerstate(GuandDao2023).Toovercomethischallenge,theypresentaselectiveSSMs
(S6)blockthateffectivelyselectsrelevantcontextbyenablingdependenceoftheparametersBÂ¯,CÂ¯,andğš«ontheinputğ‘¥ ğ‘¡,
i.e.:
BÂ¯ ğ‘¡ =Linear B(ğ‘¥ ğ‘¡) (29)
CÂ¯ ğ‘¡ =Linear C(ğ‘¥ ğ‘¡) (30)
ğš«
ğ‘¡
=Softplus(Linearğš«(ğ‘¥ ğ‘¡)), (31)
whereLinear(.) isalinearprojectionandSoftplus(.) = log(1+exp(.)). Thisdatadependencycomesatthecostof
efficiencyasthemodelcannotbetrainedasaconvolution.Toovercomethischallenge,GuandDao(2023)showthatthe
linearrecurrenceinEquation1canbeformulatedasanassociativescan(MartinandCundy2018),whichacceptsefficient
parallelalgorithms.
B Additional Related Work
ClassicalApproach.Modelingtimeseriesdataisalong-standingproblemandhasattractedmuchattentionduringthepast
60years.Therehavebeenseveralmathematicalmodelstocapturethetimeseriestraitslikeexponentialsmoothing(Winters
1960),autoregressiveintegratedmovingaverage(ARIMA)(Bartholomew1971),SARIMA(BenderandSimonovic1994),
Box-Jenkinsmethod(BoxandJenkins1968),andmorerecentlystate-spacemodels(Aoki2013;Harvey1990). Despite
theirmoreinterpretability,thesemethodsusuallyfailtocapturenon-lineardependenciesandalsooftenrequiremanually
analyzingtimeseriesfeatures(e.g.,trendorseasonality),resultinginlackofgeneralizability.
Recurrent and Deep State Space Models. Another group of relevant studies to ours is deep sequence models. A
commonclassofarchitecturesforsequencemodelingarerecurrentneuralnetworkssuchaslikeGRUs(Chungetal.2014),
DeepAR(Salinasetal.2020),LSTMs(HochreiterandJ.Schmidhuber1997).ThemaindrawbackofRNNsistheirpotential
for vanishing/exploding gradients and also their slow training. Recently, linear attention methods with fast training
attractedattention(Katharopoulosetal.2020;Schlag,Irie,andJÃ¼rgenSchmidhuber2021;Yangetal.2024).Katharopoulos
etal.(2020)showthatthesemethodshaverecurrentformulationandcanbefastininference.
17Recently,deepstatespacemodelshaveattractedmuchattentionasthealternativeofTransformers(Vaswanietal.2017),
duetotheirfasttrainingandinference(Gu,Dao,etal.2020).ThesemethodsarethecombinationoftraditionalSSMswith
deepneuralnetworksbydirectlyparameterizingthelayersofaneuralnetworkwithmultiplelinearSSMs,andovercome
commonrecurrenttrainingdrawbacksbyleveragingtheconvolutionalviewofSSMs(Gu,Dao,etal.2020;Gu,Goel,Gupta,
etal.2022;Gu,Goel,andRe2022;Gu,I.Johnson,Goel,etal.2021;Smith,Warrington,andLinderman2023).Recently,Gu
andDao(2023)presentanewformulationofdeepSSMsbyallowingtheparameterstobethefunctionofinputs. This
architectureshowspromissingpotentialinvariousdomainslikeNLP(GuandDao2023),vision(Behrouz,Santacatterina,
andZabih2024;YueLiuetal.2024;J.Ma,F.Li,andB.Wang2024),graphs(BehrouzandHashemi2024),DNAmodeling(Gu
andDao2023;Schiffetal.2024).
Alltheabovemethodsaredesignfor1Ddata,meaningthatthestatesdependsononevariable.Thereare,however,afew
studiesthatuses2DSSMsindeeplearningsettings.S4ND(Nguyenetal.2022)usescontinuoussignalstomodelimages.
ThesemethodsnotonlyconsidertwoseparateSSMfortheaxes, butitalsodirectlytreatthesystemasacontinuous
systemwithoutdiscretizationstep.Furthermore,S4NDhasdata-independentparameters.Anothersimilarapproachis
2DSSM(Baron,Zimerman,andWolf2024),thatmodelsimagesasdiscretesignals.Thatis,theinitialSSMmodelisdiscrete
andagainthereisalackofdiscretizationstep,whichisimportantfortimeseriesaswediscussedearlier.Also,theirmethod
againisbasedondata-independentparameters.BothS4NDand2DSSMcanbecomputedasaconvolution.We,however,
presentanewscanningtechniqueforfasttrainingof2DSSMs,evenwithinput-dependentparameters.
Othermethods.Transformer-basedmodelshaveattractedmuchattentionoverrecentyearsformultivariatetimeseries
forecasting,whenmodelingthecomplexrelationshipsofco-variatesoralongthetimedimensionisrequired(Ilbertetal.
2024;Kitaev,Kaiser,andLevskaya2020;S.Liuetal.2021;Nieetal.2023;H.Wu,Xu,etal.2021;Zengetal.2023a;Y.Zhang
andYan2023;H.Zhouetal.2021;T.Zhou,Z.Ma,Wen,X.Wang,etal.2022).Severalstudieshavefocusedondesigning
moreefficientandeffectiveattentionswithusingspecialtraitsoftimeseries(Wooetal.2022).Someotherstudieshave
focusedonextractinglong-terminformationforbetterforecasting(Nieetal.2023;T.Zhou,Z.Ma,Wen,Sun,etal.2022).
Inadditiontotransformers,linearmodelsalsohaveshownpromisingresults(S.-A.Chenetal.2023;H.Wu,Hu,etal.2023).
Forexample,S.-A.Chenetal.(2023)presentTSMixer,anall-MLParchitecturefortimeseriesforecasting,withpromising
performance.Duetotheexpressivepowerofour2DSSM,theselinearmethodssometimescanbeviewedasaspecialcase
of2DSSMs.Recently,convolution-basedmodelsfortimeserieshaveshownpromisingresults(LuoandX.Wang2024).
Thesemethodsbyusingglobalkernelsenhancetheglobalreceptivefield.Ourdata-independentformulationofChimerais
connectedtothislineofworkasitcanbewrittenasaglobalconvolution.
C Details of the Discretization
GivenPDEwithinitialconditionâ„(0,0) =0:
ğœ• (cid:16) (cid:17) (cid:16) (cid:16) (cid:17) (cid:16) (cid:17)(cid:17) (cid:16) (cid:17)
â„(1) ğ‘¡(1),ğ‘¡(2) = A1â„(1) ğ‘¡(1),ğ‘¡(2) ,A2â„(2) ğ‘¡(1),ğ‘¡(2) +B1x ğ‘¡(1),ğ‘¡(2) , (32)
ğœ•ğ‘¡(1)
ğœ• (cid:16) (cid:17) (cid:16) (cid:16) (cid:17) (cid:16) (cid:17)(cid:17) (cid:16) (cid:17)
â„(2) ğ‘¡(1),ğ‘¡(2) = A1â„(1) ğ‘¡(1),ğ‘¡(2) ,A2â„(2) ğ‘¡(1),ğ‘¡(2) +B1x ğ‘¡(1),ğ‘¡(2) , (33)
ğœ•ğ‘¡(1)
ğœ• (cid:16) (cid:17) (cid:16) (cid:16) (cid:17) (cid:16) (cid:17)(cid:17) (cid:16) (cid:17)
â„(1) ğ‘¡(1),ğ‘¡(2) = A3â„(1) ğ‘¡(1),ğ‘¡(2) ,A4â„(2) ğ‘¡(1),ğ‘¡(2) +B2x ğ‘¡(1),ğ‘¡(2) , (34)
ğœ•ğ‘¡(2)
ğœ• (cid:16) (cid:17) (cid:16) (cid:16) (cid:17) (cid:16) (cid:17)(cid:17) (cid:16) (cid:17)
â„(2) ğ‘¡(1),ğ‘¡(2) = A3â„(1) ğ‘¡(1),ğ‘¡(2) ,A4â„(2) ğ‘¡(1),ğ‘¡(2) +B2x ğ‘¡(1),ğ‘¡(2) , (35)
ğœ•ğ‘¡(2)
overthesamplingintervals [ğ‘˜Î”ğ‘¡(1),(ğ‘˜+1)Î”ğ‘¡(1)] and [â„“Î”ğ‘¡(2),(â„“ +1)Î”ğ‘¡(2)] wehave:
âˆ« (ğ‘˜+1)Î”ğ‘¡(1) ğœ• (cid:16) (cid:17)
â„(1) ğ‘¡(1),ğ‘¡(2) ğ‘‘ğ‘¡(1)
ğ‘˜Î”ğ‘¡(1)
ğœ•ğ‘¡(1)
= âˆ« (ğ‘˜+1)Î”ğ‘¡(1) (cid:16) A1â„(1) (cid:16) ğ‘¡(1),ğ‘¡(2)(cid:17) +B 1(1) x(1) (cid:16) ğ‘¡(1),ğ‘¡(2)(cid:17)(cid:17) ğ‘‘ğ‘¡(1) (36)
ğ‘˜Î”ğ‘¡(1)
18andso:
âˆ« (ğ‘˜+1)Î”ğ‘¡(1) ğœ• (cid:16) (cid:17)
â„(2) ğ‘¡(1),ğ‘¡(2) ğ‘‘ğ‘¡(1)
ğ‘˜Î”ğ‘¡(1)
ğœ•ğ‘¡(1)
= âˆ« (ğ‘˜+1)Î”ğ‘¡(1) (cid:16) A2â„(2) (cid:16) ğ‘¡(1),ğ‘¡(2)(cid:17) +B 1(2) x(2) (cid:16) ğ‘¡(1),ğ‘¡(2)(cid:17)(cid:17) ğ‘‘ğ‘¡(1) (37)
ğ‘˜Î”ğ‘¡(1)
Similarly,forthesecondequationwehave:
âˆ« (â„“+1)Î”ğ‘¡(2) ğœ• (cid:16) (cid:17)
â„(1) ğ‘¡(1),ğ‘¡(2) ğ‘‘ğ‘¡(2)
â„“Î”ğ‘¡(2)
ğœ•ğ‘¡(2)
= âˆ« (â„“+1)Î”ğ‘¡(2) (cid:16) A3â„(1) (cid:16) ğ‘¡(1),ğ‘¡(2)(cid:17) +B 2(1) x(1) (cid:16) ğ‘¡(1),ğ‘¡(2)(cid:17)(cid:17) ğ‘‘ğ‘¡(2) (38)
â„“Î”ğ‘¡(2)
andso:
âˆ« (â„“+1)Î”ğ‘¡(2) ğœ• (cid:16) (cid:17)
â„(2) ğ‘¡(1),ğ‘¡(2) ğ‘‘ğ‘¡(2)
â„“Î”ğ‘¡(2)
ğœ•ğ‘¡(2)
= âˆ« (â„“+1)Î”ğ‘¡(2) (cid:16) A4â„(2) (cid:16) ğ‘¡(1),ğ‘¡(2)(cid:17) +B 2(2) x(2) (cid:16) ğ‘¡(1),ğ‘¡(2)(cid:17)(cid:17) ğ‘‘ğ‘¡(2) (39)
â„“Î”ğ‘¡(2)
Next,theintegralscanbesimplifiedas:
(cid:16) (cid:17)
â„(1) (ğ‘˜+1)Î”ğ‘¡(1),ğ‘¡(2)
=ğ‘’A1Î”ğ‘¡(1)â„(1) (cid:16) ğ‘˜Î”ğ‘¡(1),ğ‘¡(2)(cid:17) +âˆ« (ğ‘˜+1)Î”ğ‘¡(1) ğ‘’A1(ğ‘¡(1)âˆ’ğ‘˜Î”ğ‘¡(1))B(1) x(1) (cid:16) ğ‘¡(1),ğ‘¡(2)(cid:17) ğ‘‘ğ‘¡(1), (40)
1
ğ‘˜Î”ğ‘¡(1)
and
(cid:16) (cid:17)
â„(2) (ğ‘˜+1)Î”ğ‘¡(1),ğ‘¡(2)
=ğ‘’A2Î”ğ‘¡(1)â„(2) (cid:16) ğ‘˜Î”ğ‘¡(1),ğ‘¡(2)(cid:17) +âˆ« (ğ‘˜+1)Î”ğ‘¡(1) ğ‘’A2(ğ‘¡(1)âˆ’ğ‘˜Î”ğ‘¡(1))B(2) x(2) (cid:16) ğ‘¡(1),ğ‘¡(2)(cid:17) ğ‘‘ğ‘¡(1), (41)
1
ğ‘˜Î”ğ‘¡(1)
andsimilarlyforthethirdandfourthequationswehave:
(cid:16) (cid:17)
â„(1) ğ‘¡(1),(â„“ +1)Î”ğ‘¡(2)
=ğ‘’A3Î”ğ‘¡(2)â„(1) (cid:16) ğ‘¡(1),â„“Î”ğ‘¡(2)(cid:17) +âˆ« (â„“+1)Î”ğ‘¡(2) ğ‘’A3(ğ‘¡(2)âˆ’â„“Î”ğ‘¡(2))B(1) x(1) (cid:16) ğ‘¡(2),ğ‘¡(1)(cid:17) ğ‘‘ğ‘¡(2) (42)
2
â„“Î”ğ‘¡(2)
and
(cid:16) (cid:17)
â„(2) ğ‘¡(1),(â„“ +1)Î”ğ‘¡(2)
=ğ‘’A4Î”ğ‘¡(2)â„(2) (cid:16) ğ‘¡(1),â„“Î”ğ‘¡(2)(cid:17) +âˆ« (â„“+1)Î”ğ‘¡(2) ğ‘’A4(ğ‘¡(2)âˆ’â„“Î”ğ‘¡(2))B(2) x(2) (cid:16) ğ‘¡(2),ğ‘¡(1)(cid:17) ğ‘‘ğ‘¡(2) (43)
2
â„“Î”ğ‘¡(2)
UsingZOHassumption,wehave:
19âˆ« Î”ğ‘¡(1) ğ‘’A1ğ‘ ğ‘‘ğ‘  =A(1)âˆ’1 (cid:16) ğ‘’A1Î”ğ‘¡(1) âˆ’I(cid:17)
0
âˆ« Î”ğ‘¡(1) ğ‘’A2ğ‘ ğ‘‘ğ‘  =A(2)âˆ’1 (cid:16) ğ‘’A2Î”ğ‘¡(1) âˆ’I(cid:17) (44)
0
âˆ« Î”ğ‘¡(2) ğ‘’A3ğ‘ ğ‘‘ğ‘  =A(3)âˆ’1 (cid:16) ğ‘’A3Î”ğ‘¡(2) âˆ’I(cid:17) (45)
0
âˆ« Î”ğ‘¡(2) ğ‘’A4ğ‘ ğ‘‘ğ‘  =A(4)âˆ’1 (cid:16) ğ‘’A4Î”ğ‘¡(2) âˆ’I(cid:17) (46)
0
Accordingly,thediscretizedformisasfollows:
â„(1) =ğ‘’A1Î”ğ‘¡(1)â„(1) +A(1)âˆ’1 (cid:16) ğ‘’A1Î”ğ‘¡(1) âˆ’I(cid:17) B(1) x(1) (47)
ğ‘˜+1,â„“ ğ‘˜,â„“ 1 ğ‘˜+1,â„“
â„(2) =ğ‘’A2Î”ğ‘¡(1)â„(2) +A(2)âˆ’1 (cid:16) ğ‘’A2Î”ğ‘¡(1) âˆ’I(cid:17) B(2) x(2) (48)
ğ‘˜+1,â„“ ğ‘˜,â„“ 1 ğ‘˜+1,â„“
â„(1) =ğ‘’A3Î”ğ‘¡(2)â„(1) +A(3)âˆ’1 (cid:16) ğ‘’A3Î”ğ‘¡(2) âˆ’I(cid:17) B(1) x(1) (49)
ğ‘˜,â„“+1 ğ‘˜,â„“ 2 ğ‘˜,â„“+1
â„(2) =ğ‘’A4Î”ğ‘¡(2)â„(2) +A(4)âˆ’1 (cid:16) ğ‘’A4Î”ğ‘¡(2) âˆ’I(cid:17) B(2) x(2) , (50)
ğ‘˜,â„“+1 ğ‘˜,â„“ 2 ğ‘˜,â„“+1
whichmeansthat:
AÂ¯
1
=exp(A1Î” 1), (51)
AÂ¯
2
=exp(A2Î” 1), (52)
AÂ¯
3
=exp(A3Î” 2), (53)
AÂ¯
4
=exp(A4Î” 2), (54)
(55)
and
BÂ¯ 1 = (cid:34) A A( (1 2) )âˆ’ âˆ’1 1 (cid:0) (cid:0)ğ‘’ ğ‘’A A1 2Î” Î”1
1
âˆ’ âˆ’I I(cid:1) (cid:1)B B1( (1 2) )(cid:35) , (56)
1
BÂ¯ 2 = (cid:34) A A( (3 4) )âˆ’ âˆ’1 1 (cid:0) (cid:0)ğ‘’ ğ‘’A A3 4Î” Î”2
2
âˆ’ âˆ’I I(cid:1) (cid:1)B B2( (1 2) )(cid:35) . (57)
2
D Details of the Structure of Transition Matrices
DefinitionD.1(CompanionMatrix). Amatrixğ´ âˆˆRğ‘Ã—ğ‘ hascompanionformifitcanbewrittenas:
0 0 ... 0 ğ‘
1
(cid:169)1 0 ... 0 ğ‘ (cid:170)
(cid:173) 2 (cid:174)
(cid:173)0 1 ... 0 ğ‘ (cid:174)
ğ´=(cid:173) (cid:173) (cid:173). .
.
. .
.
... . .
.
. . .3 (cid:174) (cid:174) (cid:174). (58)
(cid:173) (cid:174)
(cid:173)0 0 ... 0 ğ‘ (cid:174)
(cid:173) ğ‘1(cid:174)
0 0 ... 1 ğ‘
ğ‘
(cid:171) (cid:172)
20Thesematricescanbedecomposeintoashiftandalow-rankmatrix.Thatis:
0 0 ... 0 ğ‘ 0 0 ... 0 0 0 0 ... 0 ğ‘
1 1
(cid:169)1 0 ... 0 ğ‘ (cid:170) (cid:169)1 0 ... 0 0(cid:170) (cid:169)0 0 ... 0 ğ‘ (cid:170)
(cid:173) 2 (cid:174) (cid:173) (cid:174) (cid:173) 2 (cid:174)
(cid:173)0 1 ... 0 ğ‘ (cid:174) (cid:173)0 1 ... 0 0(cid:174) (cid:173)0 0 ... 0 ğ‘ (cid:174)
ğ´=(cid:173) (cid:173) (cid:173). .
.
. .
.
... . .
.
. . .3 (cid:174) (cid:174) (cid:174)=(cid:173) (cid:173) (cid:173). .
.
. .
.
... . .
.
. . .(cid:174) (cid:174) (cid:174)+(cid:173) (cid:173) (cid:173). .
.
. .
.
... . .
.
. . .3 (cid:174) (cid:174) (cid:174). (59)
(cid:173) (cid:174) (cid:173) (cid:174) (cid:173) (cid:174)
(cid:173)0 0 ... 0 ğ‘ (cid:174) (cid:173)0 0 ... 0 0(cid:174) (cid:173)0 0 ... 0 ğ‘ (cid:174)
(cid:173) ğ‘1(cid:174) (cid:173) (cid:174) (cid:173) ğ‘1(cid:174)
0 0 ... 1 ğ‘ 0 0 ... 1 0 0 0 ... 0 ğ‘
ğ‘ ğ‘
(cid:171) (cid:172) (cid:171)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:172) (cid:171)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:172)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
ShiftMatrix Low-rankMatrix
Thisformulationcanhelpustocomputethepowerofğ´fasterintheconvolutionalform,asdiscussedbyM.Zhangetal.
(2023).
E Theoretical Results
E.1 ProofofTheorem3.2
Inthispart,wewanttoprovethatâ‹‡isassociative.Thisoperatorisdefinedas:
ğ‘â‹‡ğ‘ =
(cid:18)ğ‘
1
ğ‘
2
ğ‘ 3(cid:19)
â‹‡
(cid:18)ğ‘
1
ğ‘
2
ğ‘ 3(cid:19)
=
(cid:18)ğ‘
1
âŠ™ğ‘
1
ğ‘
2
âŠ™ğ‘
2
ğ‘
1
âŠ—ğ‘ 3+ğ‘
2
âŠ—ğ‘ 6+ğ‘ 3(cid:19)
ğ‘
4
ğ‘
5
ğ‘
6
ğ‘
4
ğ‘
5
ğ‘
6
ğ‘
4
âŠ™ğ‘
4
ğ‘
5
âŠ™ğ‘
5
ğ‘
4
âŠ—ğ‘ 3+ğ‘
5
âŠ—ğ‘ 6+ğ‘
6
Accordingly,wehave:
(ğ‘â‹‡ğ‘)â‹‡ğ‘Ÿ =
(cid:18)ğ‘
1
âŠ™ğ‘
1
ğ‘
2
âŠ™ğ‘
2
ğ‘
1
âŠ—ğ‘ 3+ğ‘
2
âŠ—ğ‘ 6+ğ‘ 3(cid:19)
â‹‡
(cid:18)ğ‘Ÿ
1
ğ‘Ÿ
2
ğ‘Ÿ 3(cid:19)
, (60)
ğ‘
4
âŠ™ğ‘
4
ğ‘
5
âŠ™ğ‘
5
ğ‘
4
âŠ—ğ‘ 3+ğ‘
5
âŠ—ğ‘ 6+ğ‘
6
ğ‘Ÿ
4
ğ‘Ÿ
5
ğ‘Ÿ
6
re-usingthedefinitionofâ‹‡,wehave:
(ğ‘â‹‡ğ‘)â‹‡ğ‘Ÿ =
(cid:18)ğ‘
1
âŠ™ğ‘
1
ğ‘
2
âŠ™ğ‘
2
ğ‘
1
âŠ—ğ‘ 3+ğ‘
2
âŠ—ğ‘ 6+ğ‘ 3(cid:19)
â‹‡
(cid:18)ğ‘Ÿ
1
ğ‘Ÿ
2
ğ‘Ÿ 3(cid:19)
(61)
ğ‘
4
âŠ™ğ‘
4
ğ‘
5
âŠ™ğ‘
5
ğ‘
4
âŠ—ğ‘ 3+ğ‘
5
âŠ—ğ‘ 6+ğ‘
6
ğ‘Ÿ
4
ğ‘Ÿ
5
ğ‘Ÿ
6
= (cid:18)ğ‘Ÿ 1 âŠ™ (ğ‘ 1 âŠ™ğ‘ 1) ğ‘Ÿ 2 âŠ™ (ğ‘ 2 âŠ™ğ‘ 2) ğ‘Ÿ 1 âŠ— (ğ‘ 1 âŠ—ğ‘ 3+ğ‘ 2 âŠ—ğ‘ 6+ğ‘ 3)+ğ‘Ÿ 2 âŠ™ (ğ‘ 4 âŠ—ğ‘ 3+ğ‘ 5 âŠ—ğ‘ 6+ğ‘ 6)+ğ‘Ÿ 3(cid:19) (62)
ğ‘Ÿ 4 âŠ™ (ğ‘ 4 âŠ™ğ‘ 4) ğ‘Ÿ 5 âŠ™ (ğ‘ 5 âŠ™ğ‘ 5) ğ‘Ÿ 4 âŠ— (ğ‘ 1 âŠ—ğ‘ 3+ğ‘ 2 âŠ—ğ‘ 6+ğ‘ 3)+ğ‘Ÿ 4 âŠ— (ğ‘ 4 âŠ—ğ‘ 3+ğ‘ 5 âŠ—ğ‘ 6+ğ‘ 6)+ğ‘Ÿ 6
UsingthefactthatâŠ™andâŠ—areassociative,wehave:
(ğ‘â‹‡ğ‘)â‹‡ğ‘Ÿ =
(cid:18)ğ‘
1
âŠ™ğ‘
1
ğ‘
2
âŠ™ğ‘
2
ğ‘
1
âŠ—ğ‘ 3+ğ‘
2
âŠ—ğ‘ 6+ğ‘ 3(cid:19)
â‹‡
(cid:18)ğ‘Ÿ
1
ğ‘Ÿ
2
ğ‘Ÿ 3(cid:19)
(63)
ğ‘
4
âŠ™ğ‘
4
ğ‘
5
âŠ™ğ‘
5
ğ‘
4
âŠ—ğ‘ 3+ğ‘
5
âŠ—ğ‘ 6+ğ‘
6
ğ‘Ÿ
4
ğ‘Ÿ
5
ğ‘Ÿ
6
= (cid:18)ğ‘Ÿ 1 âŠ™ (ğ‘ 1 âŠ™ğ‘ 1) ğ‘Ÿ 2 âŠ™ (ğ‘ 2 âŠ™ğ‘ 2) ğ‘Ÿ 1 âŠ— (ğ‘ 1 âŠ—ğ‘ 3+ğ‘ 2 âŠ—ğ‘ 6+ğ‘ 3)+ğ‘Ÿ 2 âŠ™ (ğ‘ 4 âŠ—ğ‘ 3+ğ‘ 5 âŠ—ğ‘ 6+ğ‘ 6)+ğ‘Ÿ 3(cid:19) (64)
ğ‘Ÿ 4 âŠ™ (ğ‘ 4 âŠ™ğ‘ 4) ğ‘Ÿ 5 âŠ™ (ğ‘ 5 âŠ™ğ‘ 5) ğ‘Ÿ 4 âŠ— (ğ‘ 1 âŠ—ğ‘ 3+ğ‘ 2 âŠ—ğ‘ 6+ğ‘ 3)+ğ‘Ÿ 4 âŠ— (ğ‘ 4 âŠ—ğ‘ 3+ğ‘ 5 âŠ—ğ‘ 6+ğ‘ 6)+ğ‘Ÿ 6
=
(cid:18)ğ‘
1
ğ‘
2
ğ‘ 3(cid:19)
â‹‡
(cid:18)ğ‘Ÿ
1
âŠ™ğ‘
1
ğ‘Ÿ
2
âŠ™ğ‘
2
ğ‘Ÿ
1
âŠ—ğ‘ 3+ğ‘Ÿ
2
âŠ—ğ‘ 6+ğ‘Ÿ 3(cid:19)
(65)
ğ‘
4
ğ‘
5
ğ‘
6
ğ‘Ÿ
4
âŠ™ğ‘
4
ğ‘Ÿ
5
âŠ™ğ‘
5
ğ‘Ÿ
4
âŠ—ğ‘ 3+ğ‘Ÿ
5
âŠ—ğ‘ 6+ğ‘Ÿ
6
=ğ‘â‹‡(ğ‘â‹‡ğ‘Ÿ), (66)
whichprovesthetheorem.
E.2 ProofofTheorem3.3
Foreachğ‘£,ğ‘¡,wecanpre-computeB1xğ‘£,ğ‘¡ andB2xğ‘£,ğ‘¡+1.Accordingly,allthefollowingparametersarepre-computed:
(cid:18) (cid:19)
ğ‘(ğ‘–,ğ‘—,ğ‘˜,â„“) = A1 A2 B1xğ‘£+ğ‘–,ğ‘¡+ğ‘— , (67)
ğ‘£,ğ‘¡ A3 A4 B2xğ‘£+ğ‘˜,ğ‘¡+â„“
21(cid:32) S(1)(cid:33) (cid:18)ğ¼ ğ¼ 0(cid:19)
forallinputsxğ‘£,ğ‘¡ andğ‘–,ğ‘—,ğ‘˜,â„“ âˆˆ {0,1}.Now,startingfrom 0 (, 20
)
=
ğ¼ ğ¼ 0
,wehave:
S
0,0
(cid:18) S0,1(cid:19)
=
(cid:18)ğ¼ ğ¼ 0(cid:19)
â‹‡
(cid:18) A1 A2 B1x0,1(cid:19)
(68)
S1,0 ğ¼ ğ¼ 0 A3 A4 B2x1,0
(cid:18) (cid:19)
=
A1 A2 B1x0,1
. (69)
A3 A4 B2x1,0
Re-usingoperatorâ‹‡,wehave:
(cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19)
S1,1
=
S0,1
â‹‡
A1 A2 B1x1,1
(70)
S1,1 S1,0 A3 A4 B2x1,1
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)
(cid:124) (cid:123)(cid:122) (cid:125)
Pre-computed
=
(cid:18) A2
1
A2
2
A1B1x0,1+A2B2x1,0+B1x1,1(cid:19)
(71)
A3 A2
4
A3B1x0,1+A4B2x1,0+B2x1,1
Lookingatthethirdelementofeachrow,theseelementsarecalculatingthehiddenstatesoftherecurrent(itcanbeshown
byastraightforwardinduction). Accordingly,usingthisoperation,wecanrecursivelycalculatethetheoutputsof2D
SSM.
However,usingTheorem3.2,weknowthatthisisanassociativeoperation,soinsteadofcalculatingintherecurrentform,
wecanuseparallelpre-fixsummakethiscomputationparallel,decreasingthesequentialoperationsrequiredtocalculate
thehiddenstates.Notethatsinceouraboveoperationcanmodeltheproblemasanparallelprefix,allthealgorithmsfor
thisproblemcanbeusedtoenhancetheefficiency.
E.3 ProofofTheorem3.4
Toprovethistheorem,weneedto(1)showthatChimeracanrecoverSpaceTime.Giventhis,sinceSpaceTimeiscapableof
recoveringARIMA(Bartholomew1971),exponentialsmoothing(Winters1960),andcontrollablelineartimeâ€“invariant
systems(C.-T.Chen1984),wecanconcludethatChimeracanalsorecoverthesemethods.Then,(2)weneedtoprovethat
ChimeracanrecoverSARIMA.ThisisthemodelthatSpaceTimeisnotcapableofrecoveringduetotheadditionalseasonal
terms.
NotethatusingA2 =A3 =A4 =0,resultsina1DSSM,withcompanionmatrixasthestructureofA1,whichisSpaceTime.
Accordingly,SpaceTimeisaspecialcaseofChimerawhentherecurrenceonlyhappenalongthetimedirection.
Note that as discussed in Proposition 3.1, multiplying the discretization parameter Î” results in multiplying the steps.
Accordingly,usingğ‘  astheÎ”inourseasonalmoduleandalsolettingA2 =A3 =A4 =0fortheseasonalmodule,wecan
modeltheseasonaltermsintheformulationofSAR(ğ‘,ğ‘,ğ‘ ),meaningthatChimeracanalsorecoverSARIMAwhichis
ARIMAwithseasonalterms. NotethatthereasonthatChimeraiscapableofsuchmodelingisthatitusestwoheads
separatelyfortrendandseasonalterms.Therefore,usingdifferentdiscretizationparameters,eachcanmodeltheirown
correspondingtermsinSAR(ğ‘,ğ‘,ğ‘ ).
E.4 ProofofTheorem3.5
Similartotheabove,usingA2 = A3 = 0,ourformulationisequivalenttoS4D,whileweusediagonalmatricesasthe
structureofA1.Similarly,asdiscussedbyBehrouz,Santacatterina,andZabih(2024),MambaMixerisequivalenttoS4ND
but on patched data. Using our Theorem 5, we can recover linear layers, resulting in recovering TSMixer by setting
A2 =A3 =0.
E.5 ProofofTheorem3.6
WeinfactwillshowthatrestrictingChimeraresultsinrecovering2DSSM(Baron,Zimerman,andWolf2024).Asdiscussed
earlier,thismethoddonotusediscretizationandinitiallystartsfromadiscretesystem.Also,itusesinput-independent
parameters. Therefore, we use LinearÎ”1(.) = LinearÎ”2(.) as broadcast function, and restrict Chimera to have input-
independentparameters,thenChimeracanrecover2DSSM(Baron,Zimerman,andWolf2024).
22F Experimental Settings
WeprovidethedescriptionofdatasetsinTable7.
Table7:Datasetdescriptions.Thedatasetsizeisorganizedin(Train,Validation,Test).
Tasks Dataset Dim SeriesLength DatasetSize Information(Frequency)
ETTm1,ETTm2 7 {96,192,336,720} (34465,11521,11521) Electricity(15mins)
ETTh1,ETTh2 7 {96,192,336,720} (8545,2881,2881) Electricity(15mins)
Forecasting Electricity 321 {96,192,336,720} (18317,2633,5261) Electricity(Hourly)
(Long-term) Traffic 862 {96,192,336,720} (12185,1757,3509) Transportation(Hourly)
Weather 21 {96,192,336,720} (36792,5271,10540) Weather(10mins)
Exchange 8 {96,192,336,720} (5120,665,1422) Exchangerate(Daily)
ILI 7 {24,36,48,60} (617,74,170) Illness(Weekly)
M4-Yearly 1 6 (23000,0,23000) Demographic
M4-Quarterly 1 8 (24000,0,24000) Finance
Forecasting M4-Monthly 1 18 (48000,0,48000) Industry
(short-term) M4-Weakly 1 13 (359,0,359) Macro
M4-Daily 1 14 (4227,0,4227) Micro
M4-Hourly 1 48 (414,0,414) Other
EthanolConcentration 3 1751 (261,0,263) AlcoholIndustry
FaceDetection 144 62 (5890,0,3524) Face(250Hz)
Handwriting 3 152 (150,0,850) Handwriting
Heartbeat 61 405 (204,0,205) HeartBeat
Classification JapaneseVowels 12 29 (270,0,370) Voice
(UEA) PEMS-SF 963 144 (267,0,173) Transportation(Daily)
SelfRegulationSCP1 6 896 (268,0,293) Health(256Hz)
SelfRegulationSCP2 7 1152 (200,0,180) Health(256Hz)
SpokenArabicDigits 13 93 (6599,0,2199) Voice(11025Hz)
UWaveGestureLibrary 3 315 (120,0,320) Gesture
SMD 38 100 (566724,141681,708420) ServerMachine
Anomaly MSL 55 100 (44653,11664,73729) Spacecraft
Detection SMAP 25 100 (108146,27037,427617) Spacecraft
SWaT 51 100 (396000,99000,449919) Infrastructure
PSM 25 100 (105984,26497,87841) ServerMachine
F.1 Baselines
Inourexperiments,weusethefollowingbaselines:
â€¢ Table8:TSM2(Behrouz,Santacatterina,andZabih2024),Simba(BadriN.PatroandVijayS.Agneeswaran2024),
TCN(LuoandX.Wang2024),iTransformer(YongLiu,Hu,etal.2024),RLinear(Z.Lietal.2023),PatchTST(Nieetal.
2023),Crossformer(Y.ZhangandYan2023),TiDE(Dasetal.2023),TimesNet(H.Wu,Hu,etal.2023),DLinear(Zeng
etal.2023b),SCINet(M.Liuetal.2022),FEDformer(T.Zhou,Z.Ma,Wen,X.Wang,etal.2022),Stationary(YongLiu,
H.Wu,etal.2022a),Autoformer(H.Wu,Xu,etal.2021)
23â€¢ Table 9: ModernTCN (Luo and X. Wang 2024), PatchTST (Nie et al. 2023), TimesNet (H. Wu, Hu, et al. 2023),
N-HiTS(Challuetal.2022),N-BEATSâˆ—(Oreshkinetal.2019),ETSformer(Wooetal.2022),LightTS(T.Zhangetal.
2022),DLinear(Zengetal.2023a),FEDformer(T.Zhou,Z.Ma,Wen,X.Wang,etal.2022),Stationary(YongLiu,
H.Wu,etal.2022b),Autoformer(H.Wu,Xu,etal.2021),Pyraformer(S.Liuetal.2021),Informer(H.Zhouetal.
2021),Reformer(Kitaev,Kaiser,andLevskaya2020),LSTM(HochreiterandJ.Schmidhuber1997)
â€¢ Table 10: LSTM (Hochreiter and J. Schmidhuber 1997), LSTNet (Lai et al. 2018), LSSL (Gu, Goel, and Re 2022),
Trans.former(Vaswanietal.2017),Reformer(Kitaev,Kaiser,andLevskaya2020),Informer(H.Zhouetal.2021),
Pyraformer (S. Liu et al. 2021), Autoformer (H. Wu, Xu, et al. 2021), Station. (Yong Liu, H. Wu, et al. 2022b),
FEDformer(T.Zhou,Z.Ma,Wen,X.Wang,etal.2022),ETSformer(Wooetal.2022),Flowformer(H.Wu,J.Wu,etal.
2022),DLinear(Zengetal.2023a),LightTS.(T.Zhangetal.2022),TimesNet(H.Wu,Hu,etal.2023),PatchTST(Nie
etal.2023),MTCN(LuoandX.Wang2024)
For the results of the baselines, we re-use the results reported by H. Wu, Hu, et al. (2023), or from the original cited
papers.
G Additional Experimental Results
G.1 LongTermForecastingFullResults
ThecompleteresultsoflongtermforecastingarereportedinTable8.
G.2 Short-TermForecasting
ThecompleteresultsofshorttermforecastingarereportedinTable9.
G.3 Classification
ThecompleteresultsoftimeseriesclassificationarereportedinTable10.
G.4 AnomalyDetection
ThecompleteresultsofanomalydetectiontasksarereportedinTable11.
24Table8:Long-termforecastingtaskwithdifferenthorizonsH.Thefirst,second,andthirdbestresultsarehighlightedinred(bold),
orange(underline),andpurple.
Chimera TSM2 Simba TCN iTransformer RLinear PatchTST Crossformer TiDE TimesNet DLinear SCINet FEDformerStationaryAutoformer
(ours) 2024 2024 2024 2024 2023 2023 2023 2023 2023 2023 2022 2022 2022 2021
MSE MAEMSEMAEMSEMAE MSE MAEMSE MAE MSEMAEMSEMAEMSE MAE MSEMAEMSEMAEMSEMAEMSEMAEMSEMAE MSEMAEMSE MAE
96 0.2930.3510.322 - 0.3240.360 0.2920.3460.334 0.368 0.3550.3760.3290.3670.404 0.426 0.3640.3870.3380.3750.3450.3720.4180.4380.3790.4190.3860.3980.505 0.475
192 0.3290.3620.349 - 0.3630.382 0.3320.3680.377 0.391 0.3910.3920.3670.3850.450 0.451 0.3980.4040.3740.3870.3800.3890.4390.4500.4260.4410.4590.4440.553 0.496
336 0.3520.3830.366 - 0.3950.405 0.3650.3910.426 0.420 0.4240.4150.3990.4100.532 0.515 0.4280.4250.4100.4110.4130.4130.4900.4850.4450.4590.4950.4640.621 0.537
720 0.4080.4120.407 - 0.4510.437 0.4160.4170.491 0.459 0.4870.4500.4540.4390.666 0.589 0.4870.4610.4780.4500.4740.4530.5950.5500.5430.4900.5850.5160.671 0.561
Avg 0.3450.3770.361 - 0.3830.396 0.3510.3810.407 0.410 0.4140.4070.3870.4000.513 0.496 0.4190.4190.4000.4060.4030.4070.4850.4810.4480.4520.4810.4560.588 0.517
96 0.1680.2610.173 - 0.1770.263 0.1660.2560.180 0.264 0.1820.2650.1750.2590.287 0.366 0.2070.3050.1870.2670.1930.2920.2860.3770.2030.2870.1920.2740.255 0.339
192 0.2150.2890.230 - 0.2450.306 0.2220.2930.250 0.309 0.2460.3040.2410.3020.414 0.492 0.2900.3640.2490.3090.2840.3620.3990.4450.2690.3280.2800.3390.281 0.340
336 0.2780.3370.279 - 0.3040.343 0.2720.3240.311 0.348 0.3070.3420.3050.3430.597 0.542 0.3770.4220.3210.3510.3690.4270.6370.5910.3250.3660.3340.3610.339 0.372
720 0.3410.3780.388 - 0.4000.399 0.3510.3810.412 0.407 0.4070.3980.4020.4001.730 1.042 0.5580.5240.4080.4030.5540.5220.9600.7350.4210.4150.4170.4130.433 0.432
Avg 0.2500.3160.267 - 0.2710.327 0.2530.3140.288 0.332 0.2860.3270.2810.3260.757 0.610 0.3580.4040.2910.3330.3500.4010.5710.5370.3050.3490.3060.3470.327 0.371
96 0.3620.3910.375 - 0.3790.395 0.3680.3940.386 0.405 0.3860.3950.4140.4190.423 0.448 0.4790.4640.3840.4020.3860.4000.6540.5990.3760.4190.5130.4910.449 0.459
192 0.3980.4150.398 - 0.4320.424 0.4050.4130.441 0.436 0.4370.4240.4600.4450.471 0.474 0.5250.4920.4360.4290.4370.4320.7190.6310.4200.4480.5340.5040.500 0.482
336 0.4020.4160.419 - 0.4730.443 0.3910.4120.487 0.458 0.4790.4460.5010.4660.570 0.546 0.5650.5150.4910.4690.4810.4590.7780.6590.4590.4650.5880.5350.521 0.496
720 0.4580.4770.422 - 0.4830.469 0.4500.4610.503 0.491 0.4810.4700.5000.4880.653 0.621 0.5940.5580.5210.5000.5190.5160.8360.6990.5060.5070.6430.6160.514 0.512
Avg 0.4050.4240.403 - 0.4410.432 0.4040.4200.454 0.447 0.4460.4340.4690.4540.529 0.522 0.5410.5070.4580.4500.4560.4520.7470.6470.4400.4600.5700.5370.496 0.487
96 0.2570.3250.253 - 0.2900.339 0.2630.3320.297 0.349 0.2880.3380.3020.3480.745 0.584 0.4000.4400.3400.3740.3330.3870.7070.6210.3580.3970.4760.4580.346 0.388
192 0.3140.3690.334 - 0.3730.390 0.3200.3740.380 0.400 0.3740.3900.3880.4000.877 0.656 0.5280.5090.4020.4140.4770.4760.8600.6890.4290.4390.5120.4930.456 0.452
336 0.3160.3810.347 - 0.3760.406 0.3130.3760.428 0.432 0.4150.4260.4260.4331.043 0.731 0.6430.5710.4520.4520.5940.5411.0000.7440.4960.4870.5520.5510.482 0.486
720 0.3880.4270.401 - 0.4070.431 0.3920.4330.427 0.445 0.4200.4400.4310.4461.104 0.763 0.8740.6790.4620.4680.8310.6571.2490.8380.4630.4740.5620.5600.515 0.511
Avg 0.3180.3750.333 - 0.3610.391 0.3220.3790.383 0.407 0.3740.3980.3870.4070.942 0.684 0.6110.5500.4140.4270.5590.5150.9540.7230.4370.4490.5260.5160.450 0.459
96 0.1320.2340.142 - 0.1650.253 0.1290.2260.148 0.240 0.2010.2810.1810.2700.219 0.314 0.2370.3290.1680.2720.1970.2820.2470.3450.1930.3080.1690.2730.201 0.317
192 0.1440.2230.153 - 0.1730.262 0.1430.2390.162 0.253 0.2010.2830.1880.2740.231 0.322 0.2360.3300.1840.2890.1960.2850.2570.3550.2010.3150.1820.2860.222 0.334
336 0.1560.2590.175 - 0.1880.277 0.1610.2590.178 0.269 0.2150.2980.2040.2930.246 0.337 0.2490.3440.1980.3000.2090.3010.2690.3690.2140.3290.2000.3040.231 0.338
720 0.1840.2800.209 - 0.2140.305 0.1910.2860.225 0.317 0.2570.3310.2460.3240.280 0.363 0.2840.3730.2200.3200.2450.3330.2990.3900.2460.3550.2220.3210.254 0.361
Avg 0.1540.2490.169 - 0.1850.274 0.1560.2530.178 0.270 0.2190.2980.2050.2900.244 0.334 0.2510.3440.1920.2950.2120.3000.2680.3650.2140.3270.1930.2960.227 0.338
96 0.0770.1980.163 - - - 0.0800.1960.086 0.206 0.0930.2170.0880.2050.256 0.367 0.0940.2180.1070.2340.0880.2180.2670.3960.1480.2780.1110.2370.197 0.323
192 0.1590.2700.229 - - - 0.1660.2880.177 0.299 0.1840.3070.1760.2990.470 0.509 0.1840.3070.2260.3440.1760.3150.3510.4590.2710.3150.2190.3350.300 0.369
336 0.3110.3440.383 - - - 0.3070.3980.331 0.417 0.3510.4320.3010.3971.268 0.883 0.3490.4310.3670.4480.3130.4271.3240.8530.4600.4270.4210.4760.509 0.524
720 0.6970.6230.999 - - - 0.6560.5820.847 0.691 0.8860.7140.9010.7141.767 1.068 0.8520.6980.9640.7460.8390.6951.0580.7971.1950.6951.0920.7691.447 0.941
Avg 0.3110.3580.443 - - - 0.3020.3660.360 0.403 0.3780.4170.3670.4040.940 0.707 0.3700.4130.4160.4430.3540.4140.7500.6260.5190.4290.4610.4540.613 0.539
96 0.3660.2480.396 - 0.4680.268 0.3680.2530.395 0.268 0.6490.3890.4620.2950.522 0.290 0.8050.4930.5930.3210.6500.3960.7880.4990.5870.3660.6120.3380.613 0.388
192 0.3940.2920.408 - 0.4130.317 0.3790.2610.417 0.276 0.6010.3660.4660.2960.530 0.293 0.7560.4740.6170.3360.5980.3700.7890.5050.6040.3730.6130.3400.616 0.382
336 0.4090.3110.427 - 0.5290.284 0.3970.2700.433 0.283 0.6090.3690.4820.3040.558 0.305 0.7620.4770.6290.3360.6050.3730.7970.5080.6210.3830.6180.3280.622 0.337
720 0.4430.2940.449 - 0.5640.297 0.4400.2960.467 0.302 0.6470.3870.5140.3220.589 0.328 0.7190.4490.6400.3500.6450.3940.8410.5230.6260.3820.6530.3550.660 0.408
Avg 0.4030.2860.420 - 0.4930.291 0.3980.2700.428 0.282 0.6260.3780.4810.3040.550 0.304 0.7600.4730.6200.3360.6250.3830.8040.5090.6100.3760.6240.3400.628 0.379
96 0.1460.2060.161 - 0.1760.219 0.1490.2000.174 0.214 0.1920.2320.1770.2180.158 0.230 0.2020.2610.1720.2200.1960.2550.2210.3060.2170.2960.1730.2230.266 0.336
192 0.1890.2390.208 - 0.2220.260 0.1960.2450.221 0.254 0.2400.2710.2250.2590.206 0.277 0.2420.2980.2190.2610.2370.2960.2610.3400.2760.3360.2450.2850.307 0.367
336 0.2440.2810.252 - 0.2750.297 0.2380.2770.278 0.296 0.2920.3070.2780.2970.272 0.335 0.2870.3350.2800.3060.2830.3350.3090.3780.3390.3800.3210.3380.359 0.395
720 0.2970.3090.337 - 0.3500.349 0.3140.3340.358 0.347 0.3640.3530.3540.3480.398 0.418 0.3510.3860.3650.3590.3450.3810.3770.4270.4030.4280.4140.4100.419 0.428
Avg 0.2190.2580.239 - 0.2550.280 0.2240.2640.258 0.278 0.2720.2910.2590.2810.259 0.315 0.2710.3200.2590.2870.2650.3170.2920.3630.3090.3600.2880.3140.338 0.382
25
1mTTE
2mTTE
1hTTE
2hTTE
LCE
egnahcxE
cffiarT
rehtaeWTable9: Fullresultsfortheshort-termforecastingtaskintheM4dataset. âˆ—.intheTransformersindicatesthenameof
âˆ—former.StationarymeanstheNon-stationaryTransformer.
Models
ChimeraModernTCNPatchTSTTimesNetN-HiTSN-BEATSâˆ— ETSâˆ— LightTSDLinearFEDâˆ—StationaryAutoâˆ—Pyraâˆ— Inâˆ— Reâˆ— LSTM
(ours) 2024 2023 2023 2022 2019 2022 2022 2023 2022 2022 2021 2021 2021 2020 1997
SMAPE 13.107 13.226 13.258 13.387 13.418 13.436 18.009 14.247 16.965 13.728 13.717 13.97415.53014.72716.169176.040
MASE 2.902 2.957 2.985 2.996 3.045 3.043 4.487 3.109 4.283 3.048 3.078 3.134 3.711 3.418 3.800 31.033
OWA 0.767 0.777 0.781 0.786 0.793 0.794 1.115 0.827 1.058 0.803 0.807 0.822 0.942 0.881 0.973 9.290
SMAPE 9.892 9.971 10.179 10.100 10.202 10.124 13.376 11.364 12.145 10.792 10.958 11.33815.44911.36013.313172.808
MASE 1.105 1.167 0.803 1.182 1.194 1.169 1.906 1.328 1.520 1.283 1.325 1.365 2.350 1.401 1.775 19.753
OWA 0.853 0.878 0.803 0.890 0.899 0.886 1.302 1.000 1.106 0.958 0.981 1.012 1.558 1.027 1.252 15.049
SMAPE 12.549 12.556 12.641 12.670 12.791 12.677 14.588 14.014 13.514 14.260 13.917 13.95817.64214.06220.128143.237
MASE 0.914 0.917 0.930 0.933 0.969 0.937 1.368 1.053 1.037 1.102 1.097 1.103 1.913 1.141 2.614 16.551
OWA 0.864 0.866 0.876 0.878 0.899 0.880 1.149 0.981 0.956 1.012 0.998 1.002 1.511 1.024 1.927 12.747
SMAPE 4.685 4.715 4.946 4.891 5.061 4.925 7.267 15.880 6.709 4.954 6.302 5.485 24.78624.46032.491186.282
MASE 3.007 3.107 2.985 3.302 3.216 3.391 5.240 11.434 4.953 3.264 4.064 3.865 18.58120.96033.355119.294
OWA 0.983 0.986 1.044 1.035 1.040 1.053 1.591 3.474 1.487 1.036 1.304 1.187 5.538 5.013 8.679 38.411
SMAPE 11.618 11.698 11.807 11.829 11.927 11.851 14.718 13.525 13.639 12.840 12.780 12.90916.98714.08618.200160.031
MASE 1.528 1.556 1.590 1.585 1.613 1.599 2.408 2.111 2.095 1.701 1.756 1.771 3.265 2.718 4.223 25.788
OWA 0.827 0.838 0.851 0.851 0.861 0.855 1.172 1.051 1.051 0.918 0.930 0.939 1.480 1.230 1.775 12.642
Table10: Fullresultsfortheclassificationtask(accuracy%). Weomitâ€œformerâ€fromthenamesofTransformer-based
methods.Forallmethods,thestandarddeviationislessthan0.1%.
LSTMLSTNetLSSLTrans.Re. In. Pyra.Auto.Station.FED./ETS./Flow./DLinear/LightTS./TimesNet/PatchTST/MTCN/Chimera
Datasets/Models
1997 2018 2022 2017 20202021 2021 2021 2022 2022 2022 2022 2023 2022 2023 2023 2024 (ours)
EthanolConcentration32.3 39.9 31.1 32.7 31.931.6 30.8 31.6 32.7 31.2 28.1 33.8 32.6 29.7 35.7 32.8 36.3 39.8
FaceDetection 57.7 65.7 66.7 67.3 68.667.0 65.7 68.4 68.0 66.0 66.3 67.6 68.0 67.5 68.6 68.3 70.8 70.4
Handwriting 15.2 25.8 24.6 32.0 27.432.8 29.4 36.7 31.6 28.0 32.5 33.8 27.0 26.1 32.1 29.6 30.6 32.9
Heartbeat 72.2 77.1 72.7 76.1 77.180.5 75.6 74.6 73.7 73.7 71.2 77.6 75.1 75.1 78.0 74.9 77.2 81.3
JapaneseVowels 79.7 98.1 98.4 98.7 97.898.9 98.4 96.2 99.2 98.4 95.9 98.9 96.2 96.2 98.4 97.5 98.8 99.1
PEMS-SF 39.9 86.7 86.1 82.1 82.781.5 83.2 82.7 87.3 80.9 86.0 83.8 75.1 88.4 89.6 89.3 89.1 89.5
SelfRegulationSCP1 68.9 84.0 90.8 92.2 90.490.1 88.1 84.0 89.4 88.7 89.6 92.5 87.3 89.8 91.8 90.7 93.4 93.7
SelfRegulationSCP2 46.6 52.8 52.2 53.9 56.753.3 53.3 50.6 57.2 54.4 55.0 56.1 50.5 51.1 57.2 57.8 60.3 59.9
SpokenArabicDigits 31.9100.0100.0 98.4 97.0100.099.6100.0 100.0 100.0100.0 98.8 81.4 100.0 99.0 98.3 98.7 100.0
UWaveGestureLibrary41.2 87.8 85.9 85.6 85.685.6 83.4 85.9 87.5 85.3 85.0 86.6 82.1 80.3 85.3 85.8 86.7 86.7
AverageAccuracy 48.6 71.8 70.9 71.9 71.572.1 70.8 71.1 72.7 70.7 71.0 73.0 67.5 70.4 73.6 72.5 74.2 75.3
26
dethgieW
ylraeY
ylretrauQ
ylhtnoM
srehtO
egarevATable11: Fullresultsfortheanomalydetectiontask. TheP,RandF1representtheprecision, recallandF1-score(%)
respectively.AhighervalueofP,RandF1indicatesabetterperformance.
Datasets SMD MSL SMAP SWaT PSM AvgF1
Metrics P R F1 P R F1 P R F1 P R F1 P R F1 (%)
LSTM 1997 78.5265.4771.41 78.0486.2281.93 91.0657.4970.48 78.0691.7284.34 69.2499.5381.67 77.97
Transformer 2017 83.5876.1379.56 71.5787.3778.68 89.3757.1269.70 68.8496.5380.37 62.7596.5676.07 76.88
LogTrans 2019 83.4670.1376.21 73.0587.3779.57 89.1557.5969.97 68.6797.3280.52 63.0698.0076.74 76.60
TCN 2019 84.0679.0781.49 75.1182.4478.60 86.9059.2370.45 76.5995.7185.09 54.5999.7770.57 77.24
Reformer 2020 82.5869.2475.32 85.5183.3184.40 90.9157.4470.40 72.5096.5382.80 59.9395.3873.61 77.31
Informer 2021 86.6077.2381.65 81.7786.4884.06 90.1157.1369.92 70.2996.7581.43 64.2796.3377.10 78.83
Anomalyâˆ— 2021 88.9182.2385.49 79.6187.3783.31 91.8558.1171.18 72.5197.3283.10 68.3594.7279.40 80.50
Pyraformer 2021 85.6180.6183.04 83.8185.9384.86 92.5457.7171.09 87.9296.0091.78 71.6796.0282.08 82.57
Autoformer 2021 88.0682.3585.11 77.2780.9279.05 90.4058.6271.12 89.8595.8192.74 99.0888.1593.29 84.26
LSSL 2022 78.5165.3271.31 77.5588.1882.53 89.4353.4366.90 79.0593.7285.76 66.0292.9377.20 76.74
Stationary 2022 88.3381.2184.62 68.5589.1477.50 89.3759.0271.09 68.0396.7579.88 97.8296.7697.29 82.08
DLinear 2023 83.6271.5277.10 84.3485.4284.88 92.3255.4169.26 80.9195.3087.52 98.2889.2693.55 82.46
ETSformer 2022 87.4479.2383.13 85.1384.9385.03 92.2555.7569.50 90.0280.3684.91 99.3185.2891.76 82.87
LightTS 2022 87.1078.4282.53 82.4075.7878.95 92.5855.2769.21 91.9894.7293.33 98.3795.9797.15 84.23
FEDformer 2022 87.9582.3985.08 77.1480.0778.57 90.4758.1070.76 90.1796.4293.19 97.3197.1697.23 84.97
TimesNet(I) 2023 87.7682.6385.12 82.9785.4284.18 91.5057.8070.85 88.3196.2492.10 98.2292.2195.21 85.49
TimesNet(R) 2023 88.6683.1485.81 83.9286.4285.15 92.5258.2971.52 86.7697.3291.74 98.1996.7697.47 86.34
CrossFormer 2023 83.6 76.6179.70 84.6883.7184.19 92.0455.3769.14 88.4993.4890.92 97.1689.7393.30 83.45
PatchTST 2023 87.4281.6584.44 84.0786.2385.14 92.4357.5170.91 80.7094.9387.24 98.8793.9996.37 84.82
ModernTCN 2024 87.8683.8585.81 83.9485.9384.92 93.1757.6971.26 91.8395.9893.86 98.0996.3897.23 86.62
Chimera (ours) 87.7483.2985.46 84.0186.8385.39 93.0558.1271.55 92.1895.9394.01 97.3096.1996.74 86.69
27