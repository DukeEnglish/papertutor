V2A-Mark: Versatile Deep Visual-Audio Watermarking for
Manipulation Localization and Copyright Protection
XuanyuZhang1,2,YouminXu1,RunyiLi1,JiwenYu1,WeiqiLi1,ZhipeiXu1,JianZhang1,2(cid:66)
1 SchoolofElectronicandComputerEngineering,PekingUniversity
2 PekingUniversityShenzhenGraduateSchool-RabbitpreAIGCJointResearchLaboratory
Video Frame Audio Video Frame Audio
(a)
(b)
(c)
(d)
2
Figure1:TwoapplicationinstancesofV A-Mark.(a):Originalvideo,(b):Watermarkedvideo,(c)Tamperedvideo,(d)Tampered
2
visualareasandaudioperiod.Weproposeaversatiledeepvisual-audioproactiveforensicsframework,dubbedV A-Mark.Our
methodcanembedaninvisiblecross-modalwatermarkintotheoriginalvideoframesandaudio(a),producingwatermarked
videoframesandaudio(b).Iftheyaretamperedbyobjectremoval,copy-and-paste,oranyeditingmethodsduringnetwork
transmission(c),wecanaccuratelygetthepredictedvisualtamperedareas,audiotamperedperiods,andthecopyright(d).
ABSTRACT KEYWORDS
AI-generatedvideohasrevolutionizedshortvideoproduction,film- ManipulationLocalization,CopyrightProtection,Watermarking
making,andpersonalizedmedia,makingvideolocaleditingan
essentialtool.However,thisprogressalsoblursthelinebetween 1 INTRODUCTION
realityandfiction,posingchallengesinmultimediaforensics.To 2024isregardedasaboomyearofAI-generatedvideo.Benefited
solvethisurgentissue,V2A-Markisproposedtoaddressthelimi-
fromdiffusionmodelsandtheinfluxofextensivevideodata,alarge
tationsofcurrentvideotamperingforensics,suchaspoorgeneral- amountofvideogenerationmodelsandeditingmethods[3,7,10,
izability,singularfunction,andsinglemodalityfocus.Combining 12,23,42,43,57]haveemerged,offeringconvenienceinthepro-
thefragilityofvideo-into-videosteganographywithdeeprobust ductionofshortvideos,film-making,advertising,andcustomized
watermarking,ourmethodcanembedinvisiblevisual-audiolocal- media. Specifically, local editing [41, 58, 61] has become a vital
izationwatermarksandcopyrightwatermarksintotheoriginal featureofAIvideogenerationtools.Forinstance,AIdubbingsoft-
videoframesandaudio,enablingprecisemanipulationlocalization ware,capableofalteringthefacialexpressions,lipmovements,and
andcopyrightprotection.Wealsodesignatemporalalignmentand voicesofcharactersinavideo,isextensivelyusedinsimultaneous
fusionmoduleanddegradationpromptlearningtoenhancethe interpretationandmoviedubbing.However,thispowerfulediting
localizationaccuracyanddecodingrobustness.Meanwhile,wein- capability is a double-edged sword. It not only facilitates video
troduceasample-levelaudiolocalizationmethodandacross-modal editorsandcreatorsbutalsoblurstheboundariesbetweenreality
copyrightextractionmechanismtocoupletheinformationofaudio andforgery,posingnewchallengesfortamperforensics.Therefore,
andvideoframes.TheeffectivenessofV2A-Markhasbeenverified
itisurgenttodevelopamethodforvisual-audiotamperlocaliza-
onavisual-audiotamperingdataset,emphasizingitssuperiority tionandcopyrightprotection,whichcanbewidelyusedincourt
inlocalizationprecisionandcopyrightaccuracy,crucialforthe evidence,rumorverification,andbeyond.
sustainabledevelopmentofvideoeditingintheAIGCvideoera. Mostvisual-audiomanipulationlocalizationmethods[28,29,33,
37,47,56]arepassive,whichmainlyrelyonexcavatingthetempo-
ralandspatialanomaloustracesfromthesuspectvideosthemselves
topredicttamperedregions.However,thesemethodsoftenprove
CCSCONCEPTS ineffectiveagainstAIGC-basedvideotampering,whichexhibits
â€¢Computingmethodologiesâ†’Computervision. fewerartifactsandmorerealistictexturedetails.Additionally,most
4202
rpA
52
]VC.sc[
1v42861.4042:viXraZhangetal.
passiveblack-boxlocalizationnetworkstypicallyrequiretheintro- generalizationabilities,andcopyrightprecisionwithoutanylabeled
ductionofspecifictypesofmanipulationduringtraining,rendering dataoradditionaltrainingrequiredforspecifictamperingtypes.
themineffectiveagainstpreviouslyunseeneditingmethods.There-
fore,thesemethodshaveobviousshortcomingsingeneralization
2 RELATEDWORKS
abilityandaccuracyofmanipulationlocalization.
Giventheinherentdrawbacksofpassivedetectionandlocaliza- 2.1 ManipulationLocalization
tion,visual-audiowatermarkinghasbecomeaconsensustechnol- Prevalentimageforensictechniqueshavefocusedonlocalizingspe-
ogyforproactiveforensics.However,existingvideowatermarking cifictypesofmanipulationsviaexploringartifactsandanomalies
methodsarefraughtwithsomeissues.1)PoorAccuracy:Although intamperedimages[6,14,20,22,24,29,44,48,50,54â€“56].Recently,
traditionalfragilewatermarkingmethods[13,26]canachieveblock- HiFi-Net[11]usedmulti-branchfeatureextractorandlocalization
wisemanipulationlocationviahashverification,theiraccuracyis modulesforAIGC-synthesizedandeditedimages.SAFL-Net[44]
unsatisfactoryanddifficulttoreachthepixel-wiselocalization.2) designedafeatureextractionapproachtolearnsemantic-agnostic
SingularFunction:Videomanipulationlocalizationandcopyright featureswithspecificmodulesandauxiliarytasks.IML-ViT[33]
protectiontendtobetreatedastwodistinctandseparatetasks.Tam- firstlyintroducedvisiontransformerforimagemanipulationlo-
peringforensicmethodslackthecapabilityforcopyrightprotection, calizationandmodifiedViTcomponentstoaddressthreeunique
limitingtheapplicativevalueoftheirpredictionresults.Simultane- challengesinhighresolution,multi-scale,andedgesupervision.
ously,robustdeepvideowatermarkingmethods[31,60]canonly MaLP[2]introducedalargenumberofforgeryimagestolearn
providecopyrightprotectionandareunabletopreciselypinpoint thematchedtemplateandlocalizationnetwork.Targetedatvideo
thelocationsoftamperingwithinvideos.3)SingleModality:Most tamperlocalization,[47]exploitedthespatialandtemporaltraces
currentforensicmethodsoftenonlyfocusonasinglevisual[62]or leftbyinpaintingandguidedtheextractionofinter-frameresid-
audiomodality[40]andhavenotestablishedeffectivecross-modal ualwithoptical-flow-basedframealignment.UVL[37]designeda
interactionmechanisms.Howtoeffectivelyutilizecross-modalin- novelhybridmulti-stagearchitecturethatcombinesCNNsandViTs
formationformanipulationlocalizationandcross-verificationof toeffectivelycapturebothlocalandglobalvideofeatures.However,
copyrightsisanurgentissue. theabove-mentionedpassivelocalizationmethodsareoftenlimited
Toaddresstheabove-mentionedissues,weproposeaninno- intermsofgeneralizationandlocalizationaccuracy,whichusually
vativemulti-functionalandmulti-modalwatermarkingmethod, workonknowntamperingtypesthathavebeentrained.
dubbedV2A-Mark.Inthevisualsection,integratingthefragility
ofvideo-into-videosteganographyandtherobustnessofbit-into-
videowatermarking,wesimultaneouslyembedbothlocalization 2.2 VideoWatermarkingandSteganography
andcopyrightwatermarksintothevideoframes,enablingthede- Videowatermarkingisawidelyacceptedforensicmethod,which
codingnetworktoindependentlyextracttamperedareasandcopy- canbebroadlyutilizedfortheverification,authenticity,andtrace-
rightinformation.Intheaudiosection,weinsertaversatilewater- abilityofimages.Intermsofrobustnesslevelsforextraction,video
markintothehostaudioanduseittoassistinthereconstruction watermarkingcanbedividedintofragileandrobustwatermark-
ofvisualcopyrightinformation,whileidentifyingthetampered ing[21,53,62].Althoughclassicalfragilewatermarking[13,15,18,
periodsintheaudio.Thus,ourcontributionsareasfollows. 26,27,35,36,45]canachieveblock-wisetamperlocalization,their
â‘(1)Wedesignaninnovativedeepversatile,cross-modalvideo localizationaccuracyandflexibilityareunsatisfactory.Therefore,
watermarking framework, dubbed V2 A-Mark, for visual-audio howtorealizejointpixel-leveltamperlocalizationandcopyright
manipulationlocalizationandcopyrightprotection.Itcanembed protectionhasstillalotofroomforresearch.
invisiblelocalizationandcopyrightwatermarksintovideoframes Thanks to the development of deep learning, learning-based
andaudiosamplessimultaneously,andthenobtainvisualtampered videowatermarkinghasattractedincreasedattention.Fordeep
area,audiotamperedperiod,andexactcopyrightinformationin robustvideowatermarking,anintuitiveapproachistoapplyimage
thedecodingend. watermarkingmethods[16,32,63]framebyframe.Forinstance,
HiDDeN[63]firstlydesignedadeepencoder-decodernetworkto
â‘(2)Inthevisualsection,wedevelopatemporalalignmentand
hideandrecoverbitstream.Moreover,manydifferentiabledistor-
fusionmodule(TAFM)andadegradationpromptlearning
tionlayerssuchasJPEGcompression,screen-shooting,andface
(DPL)mechanism,enablingthenetworktofullyleveragetemporal
swaping[1,8,30,49]wereincorporatedtoenhancetherobust-
informationforhigh-fidelityconcealmentandrobustpredictionof
nessoftheencoder-decoderwatermarkingframework.Meanwhile,
localizationandcopyrightresults.
CIN[32]andFIN[9]utilizedflow-basedmodelstofurtherimprove
â‘(3)Intheaudiosection,weembedsample-levelversatilewa- thefidelityofcontainerimages.However,thesedeepwatermarking
termarksintothepristineaudiotoidentifythetamperedsamples methodshaveasingularfunctionandcannotaccuratelylocalize
andextractthecopyrightinformation.Furthermore,across-modal thetamperedareas.Moreover,thereareotherexplorationstoad-
extractionmechanismisproposedtoobtainthefinalcopyright dressvideodegradationandtemporalcorrelations.Forinstance,
fromtheinformationofaudioandvideoframes. DVMark[31]usedanend-to-endtrainablemulti-scalenetwork
â‘(4)Theeffectivenessofourmethodhasbeenverifiedonour for robustwatermark embedding andextractionacross various
constructedvisual-audiotamperingdataset.Comparedtoother spatial-temporalclues.REVMark[60]focusedonimprovingthe
approaches,ourmethodhasnotablemeritsinlocalizationaccuracy, robustnessagainstH.264/AVCcompressionviathetemporalalign-
mentmoduleandDiffH264distortionlayer.LF-VSN[34]utilizedV2A-Mark:VersatileDeepVisual-AudioWatermarkingforManipulationLocalizationandCopyrightProtection
Pre-defined
watermark
Visual Localization Visual Tamper
Watermarking Visual Locator
Tampering
0 0 1 â€¦0 0 0 1 V Wisu aa tl e rC mop ay rkri ig nh gt Degradation Visu Ea xl t C rao cp ty or right 0 0 1 â€¦0 0 0 1
Audio Versatile Audio Audio Versatile
Watermarking Tampering Decoding
Figure2:OverallFrameworkofourproposedV2A-Mark.Weembedpre-definedvisuallocalizationwatermarkWğ‘™ğ‘œğ‘,copyright
watermarkwğ‘ğ‘œğ‘ andaudioversatilewatermarkwğ‘â€² ğ‘œğ‘ intotheoriginalvideoframesandaudiotoproduceVğ‘ğ‘œğ‘› andAğ‘ğ‘œğ‘›.If
undergoingmalicioustampering,wecanstillextractexactcopyrightwË† ğ‘ğ‘œğ‘,visualtamperedmasksMË† ğ‘£ğ‘–ğ‘  andaudiotampered
periodsmË† ğ‘ğ‘¢ğ‘‘.NotethatwË† ğ‘ğ‘œğ‘ isobtainedviaourcross-modalextractionmechanism,combiningwğ‘ğ‘ ğ‘œğ‘ andwğ‘ğ‘£ ğ‘œğ‘.
invertibleblocksandtheredundancypredictionmoduletorealize extractsthetamperedvideomasksMË†
ğ‘£ğ‘–ğ‘ 
andcopyrightinformation
large-capacityandflexiblevideosteganography. wğ‘ğ‘£ ğ‘œğ‘.Concurrently,asshowninFig.2,thetamperedperiodsmË†
ğ‘ğ‘¢ğ‘‘
andthecopyrightwğ‘ğ‘ ğ‘œğ‘intheaudiowillbeextractedfromtheaudio
3 METHODS versatiledecodingmodule.Thefinalrestoredcopyrightinformation
3.1 OverallFrameworkofV2 A-Mark ofthevideowË† ğ‘ğ‘œğ‘ willbeobtainedviacross-modalcombinationof
wğ‘ğ‘
ğ‘œğ‘
andwğ‘ğ‘£
ğ‘œğ‘
(Sec.3.5).Finally,thevisual-audiotamperforensics
Toachievemultimodal,versatile,andproactivemanipulationlocal-
process of V2A-Mark can be categorized into several scenarios,
izationandcopyrightprotection,asshowninFig.2,theproposed
V2A-Markconsistsoftwokeysections,namelythevisualhiding
whereâˆ§andâˆ¨respectivelydenotetheâ€œelement-wiseandâ€and
â€œelement-wiseorâ€.
anddecoding(Sec.3.3),andtheaudiohidinganddecoding(Sec.3.4).
Inthevisualhidingsection,wesequentiallyembedpre-defined â‘ (1) wË† ğ‘ğ‘œğ‘ (cid:48) wğ‘ğ‘œğ‘: Suspicious Vğ‘Ÿğ‘’ğ‘ was not processed via our
visuallocalizationwatermarksWğ‘™ğ‘œğ‘âˆˆRğ»Ã—ğ‘ŠÃ—ğ‘‡Ã—ğ¶ andthecopy- V2A-Mark,andwearealsounabletoascertaintheauthenticityof
rightwatermarkwğ‘ğ‘œğ‘âˆˆ{0,1}ğ‘˜ intotheoriginalvideosequences thecorrespondingaudioAğ‘Ÿğ‘’ğ‘.Theycannotbeusedasevidence.
Vğ‘œğ‘Ÿğ‘–âˆˆRğ»Ã—ğ‘ŠÃ—ğ‘‡Ã—ğ¶ togetthecontainervideoVğ‘ğ‘œğ‘›âˆˆRğ»Ã—ğ‘ŠÃ—ğ‘‡Ã—ğ¶.In â‘(2)wË† ğ‘ğ‘œğ‘ â‰ˆwğ‘ğ‘œğ‘ âˆ§(MË† ğ‘£ğ‘–ğ‘  (cid:48)0âˆ¨mË† ğ‘ğ‘¢ğ‘‘ (cid:48)0):SuspiciousVğ‘Ÿğ‘’ğ‘ or
theaudiohidingsection,weaddversatilewatermarkwğ‘â€² ğ‘œğ‘âˆˆ{0,1}ğ‘› Ağ‘Ÿğ‘’ğ‘ hasundergonetampering,disqualifyingitasvalidevidence.
totheoriginalaudioAğ‘œğ‘Ÿğ‘–âˆˆRğ¿ inasample-levelmannertoobtain â‘(3)wË† ğ‘ğ‘œğ‘ â‰ˆwğ‘ğ‘œğ‘ âˆ§MË† ğ‘£ğ‘–ğ‘  â‰ˆ0âˆ§mË† ğ‘ğ‘¢ğ‘‘ â‰ˆ0:SuspiciousVğ‘Ÿğ‘’ğ‘ and
theAğ‘ğ‘œğ‘›âˆˆRğ¿.Notethatğ‘‡ andğ¿denotethenumberofvideoframes Ağ‘Ÿğ‘’ğ‘arebothcredibleandhavenotbeentamperedwith.V2A-Mark
andlengthoftheaudio,respectively.â€œVersatileâ€meansthatthis ensurestheauthenticityandintegrityofthisvideo.
audiowatermarkinganddecodingmodulecanachieveaudioma-
nipulationlocalizationandcopyrightprotectionatthesametime.
3.2 PreliminariesandMotivations
Moreover,thepotentialimpactsoncontainervideosduringnetwork
PreviousworkEditGuard[59]hasalreadyvalidatedthefeasibility
transmissioncanbedividedintotwotypes,namelymalicioustam-
ofusingthefragilityandlocalityofimage-into-imagesteganogra-
peringandcommondegradation.Thus,thenetworktransmission
pipelineofvideoframesandaudioismodeledasfollows.
phyforproactiveimagetamperlocalization.Specifically,fragility
meansthedamagetothecontainerimageresultsincorrespond-
Vğ‘Ÿğ‘’ğ‘ =Dğ‘£(Vğ‘ğ‘œğ‘› âŠ™(1âˆ’M)+Tğ‘£(Vğ‘ğ‘œğ‘›)âŠ™M), (1) ingdamagetotherevealedsecretimage.Localityindicatesthat
damagetothecontainerimageandtherevealedsecretimageis
Ağ‘Ÿğ‘’ğ‘ =Dğ‘(Ağ‘ğ‘œğ‘› âŠ™(1âˆ’m)+Tğ‘(Ağ‘ğ‘œğ‘›)âŠ™m), (2)
essentiallypixel-levelanddirectlycorrelated.Thesetwoproper-
where Tğ‘£(Â·) and Tğ‘(Â·) respectively denote the video and audio tiescanalsobeeffectivelyappliedinproactivevideolocalization.
manipulationfunction.Dğ‘£(Â·)andDğ‘(Â·)respectivelydenotethe Meanwhile,EditGuard[59]adoptsaâ€œsequentialembeddingand
videoandaudiodegradationoperation.MâˆˆRğ»Ã—ğ‘ŠÃ—ğ‘‡ andmâˆˆRğ¿ paralleldecodingâ€structuretorealizeunitedtamperlocalization
respectivelydenotethetemperedvisualmasksandaudioperiods. andcopyrightprotection.Clearly,onedirectapproachistowa-
UponreceivingthevideoVğ‘Ÿğ‘’ğ‘ andaudioAğ‘Ÿğ‘’ğ‘,weattempttore- termarkeachvideoframeviaEditGuard.However,thismethod
coverthepreviouslyembeddedwatermarksondifferentrobustness overlookstheexploitationoftemporalcorrelation,makingitchal-
levelsandconductcorrespondingforensicsbasedontheextracted lengingtoensuretherobustnessofthereconstructedwatermarks
watermarks.Inthevisualdecodingsection,ourframeworkprecisely andthetemporalconsistencyofthewatermarkedvideos.Therefore,
ladom-ssorC noitcartxEZhangetal.
Video Hiding Module Video Revealing Module
â€¦ â€¦ â€¦ â€¦
DPL
Replicate
DPL
1 0 0 â€¦1 0 0 1 1 0 0 â€¦1 0 0 1
Bit Hiding Module Bit Recovery Module
2
Figure3:DetailsofthenetworkstructureandtrainingprocessoftheproposedV A-Mark.Wedesignthetemporalalignment
andfusionmodule(TAFM)anddegradationpromptlearning(DPL)toenhancetherobustnessandfidelityofourmethod.
thekeyissuesaddressedinthispaperare:1)Howtoutilizethe
auxiliaryinformationfromsupportingframesforwatermarkem-
beddinganddecodinginreferenceframes;2)Howtoimprovethe
robustnessofexistingframeworkstovideodegradation;3)Howto
employthewatermarksembeddedinvideoframesforaudiotamper
DWT DWT
localizationandcopyrightprotection.Toaddresstheaboveissues, s Sigmoid
wedesignthevisualhidingmodule(VHM),visualrevealingmodule T Transpose
(VRM),bithidingmodule(BHM),andbitrecoverymodule(BRM).
Meanwhile,wedesignanefficientcross-modalextractionmecha-
nismandintroducetheadvancedaudioversatilewatermarkingand Norm Norm
decodingmethod[40]toachievecross-modaltamperlocalization
Linear Linear Linear Linear
andcopyrightprotection.
T
3.3 VisualHidingandDecoding T
s s
3.3.1 InputandOutputDesignofVisualSection. Toachieve
memory-efficient hiding and decoding, our V2A-Mark employs
amulti-frameinput,single-frameoutputstructure.Asshownin
Fig.3,thevisualhidingisoperatedgroup-by-groupviaasliding
window,traversingeachvideoframefromheadtotail.Wesetthe
lengthofaslidingwindowto3.Giventheoriginalvideogroup
{I ğ‘œ(ğ‘– ğ‘Ÿ) ğ‘–}ğ‘˜ ğ‘˜+ âˆ’1 1andlocalizationwatermarkgroup{I ğ‘™( ğ‘œğ‘– ğ‘) }ğ‘˜ ğ‘˜+ âˆ’1 1,wefirstly Figure4:Detailsoftheproposedtemporalalignmentand
usetheTAFMtopreprocess{I ğ‘œ(ğ‘– ğ‘Ÿ) ğ‘–}ğ‘˜ ğ‘˜+ âˆ’1 1andadoptğ‘invertibleblocks fusionmodule(TAFM).ItalignsthesupportingframesI ğ‘œ(ğ‘˜ ğ‘Ÿğ‘–âˆ’1) ,
togenerateI ğ‘š(ğ‘˜ ğ‘’)
ğ‘‘
anditsby-productZğ‘£.Thecopyrightwatermark I ğ‘œ(ğ‘˜ ğ‘Ÿğ‘–+1) tothereferenceframeI ğ‘œ(ğ‘˜ ğ‘Ÿğ‘–) .
wğ‘ğ‘œğ‘ isthenembeddedintoI ğ‘š(ğ‘˜ ğ‘’)
ğ‘‘
viaaU-Net[49],producingthe
final container frame Iğ‘( ğ‘œğ‘˜ ğ‘›). For all video frames, we embed the namelyË† I ğ‘œ(ğ‘˜ ğ‘Ÿğ‘–) andË† I ğ‘™( ğ‘œğ‘˜ ğ‘).Notethatweintroducelearneddegradation
samecopyrightwatermark.Afternetworktransmission,V2A-Mark promptsPğ‘£,Pğ‘ invideorevealingandbitrecoverymodulesand
decodeseachreceivedvideoframeIğ‘Ÿ(ğ‘˜ ğ‘’ğ‘) individually.Ononehand, fusethemwithintrinsicfeaturestofurtherenhancetherobustness
ofourmethodagainstcommonvideoandaudiodegradations.
wË† ğ‘ğ‘œğ‘isextractedfromIğ‘Ÿ(ğ‘˜ ğ‘’ğ‘)viaaU-NetandanMLPextractor.Onthe
otherhand,wereplicateIğ‘Ÿ(ğ‘˜ ğ‘’ğ‘) threefoldandfeeditintotheresidual 3.3.2 TemporalAlignmentandFusionModule. Tofurther
predictionmodule(RPM)[34]toproducethemissingcomponentZË† ğ‘£. enhancethetemporalconsistencyofthecontainervideos,wede-
Then,ğ‘ invertibleblocksandtheTAFMareusedtoreconstructthe signatemporalalignmentandfusionmodule(TAFM)toalignthe
videogroupsandonlyselecttheintermediateframesastheresult, supportingframes{I ğ‘œ(ğ‘– ğ‘Ÿ) ğ‘–}ğ‘–â‰ ğ‘˜ tothereferenceframeI ğ‘œ(ğ‘˜ ğ‘Ÿğ‘–).Asshown
TAFM
Embedding
InvBlock-1 InvBlock-n InvBlock-N
Common
Visual
Degradation
RPM Fuse
InvBlock-N InvBlock-n
Fuse
InvBlock-1
Extraction
TAFMV2A-Mark:VersatileDeepVisual-AudioWatermarkingforManipulationLocalizationandCopyrightProtection
averagepooling(GAP)layer,a1Ã—1convolution,andasoftmax
operatortoproduceasetofdynamicweightcoefficientswğ‘£/wğ‘,
Prompt Components whichisinspiredby[39].Thesecoefficientsareusedtofuseeach
degradationprompt,resultingindegradation-enhancedfeatures.
Then,weutilizeconvolutionandconcatenationoperationstofuse
s * â†‘ thedegradation-enhancedfeatureswiththefeaturesextractedfrom
RPMortheU-NetinBRM.Notethatwelearnedtwodistinctsets
ofdegradationpromptsforvisualandbitdecoding,sinceweaim
fortheBRMtobeabsolutelyrobustagainstdegradation,whilethe
Globa Pl o oA lv ine grage * ComL bin ie na ar t ion s Softmax â†‘ Upsampling VRMshouldretainsomefragilityagainsttampering.
Figure5:Detailsoftheproposeddegradationpromptlearn- 3.4 AudioHidingandDecoding
ingmechanism.ItfusestheintrinsicimagefeaturesFğ‘£/Fğ‘
Consideringthatvideotamperingisoftenaccompaniedbycorre-
withthelearnablepromptcomponentsPğ‘£/Pğ‘ adaptively.
spondingchangesintheaudio,wetrytosimultaneouslyidentify
thetamperedareasoftheaudio,andutilizetheextractedaudiocopy-
inFig.4,weresorttobidirectionalcross-attentionmechanismsbe- righttocross-verifythecopyrightinthevideoframe.Toensurethe
tweenthesupportingframesandthereferenceframe.Specifically, correspondencebetweenvideoandaudio,wesettheaudioversatile
wedefinethescaleddotproductionoperationasfollows. copyrightwatermarkwğ‘â€²
ğ‘œğ‘
aspartofthecopyrightwğ‘ğ‘œğ‘ inthe
Attention(Q,K,V)=softmax(cid:16) QKğ‘‡ /âˆš ğ·(cid:17) V, (3) v thid ee fio rf sr ta 1m 6e bs i. tF so or fi wns ğ‘t ğ‘œa ğ‘n .c Ie n, sw piğ‘ rğ‘œ eğ‘ di bs ya t3 h2 e- ab dit vw ana cte er dm pa rr ok a, ca tin vd ew tağ‘â€² mğ‘œğ‘ peis
r
whereQâˆˆRğ»Ã—ğ‘ŠÃ—ğ· isthequerymatrixprojectedbythereference localizationtoolAudioseal[40],weintroduceanaudiowatermark
frameI(ğ‘˜),andK,VâˆˆRğ»Ã—ğ‘ŠÃ—ğ· arethekeyandvaluematrixpro- generatoranddetectortoachieveaudioversatilewatermarking
ğ‘œğ‘Ÿğ‘– anddecodingshowninFig.2.Specifically,weutilizethewatermark
ducedfromthesupportingframes{I ğ‘œ(ğ‘– ğ‘Ÿ) ğ‘–}ğ‘–â‰ ğ‘˜.Giventhereference generatortopredictanadditivewatermarkwaveformfromtheau-
featureFğ‘Ÿ andthesupportingfeatureFğ‘ ,theyarefirstlylayernor- dioinputAğ‘œğ‘Ÿğ‘–,anduseadetectortooutputtheprobabilitymË†
ğ‘ğ‘¢ğ‘‘
of
malizedintoFğ‘Ÿ=Norm(Fğ‘Ÿ)andFğ‘ =Norm(Fğ‘ ).Then,weuselinear thepresenceofawatermarkateachsampleofthecontaineraudio
layerstoprojectFğ‘Ÿ,Fğ‘  intoğ·-dimensionembeddingspaceandcal- Ağ‘ğ‘œğ‘›.Thedetectoristrainedwithmaskaugmentationstrategyto
culatethecross-attentionmapsbetweenreferenceandsupporting ensureitsaccuracyandrobustness.Meanwhile,weaddamessage
framesasfollows. embeddinglayer[40]inthemiddleofthewatermarkgenerator
Fğ‘Ÿâ†’ğ‘  =Attention(cid:16) Wğ‘Ÿ 1Fğ‘Ÿ,Wğ‘  1Fğ‘ ,Wğ‘  2Fğ‘ (cid:17) , (4) t ro obe um stb lyed dew cğ‘â€² rğ‘œ yğ‘ ptin wto
ğ‘ğ‘
ğ‘œA ğ‘,ğ‘œ wğ‘Ÿğ‘–. hI in chth we ild le bc eo ud si en dg te on cd o, mth be ind eet wec itt hor ww
ğ‘ğ‘£
ğ‘œi ğ‘ll
Fğ‘ â†’ğ‘Ÿ =Attention(cid:16) Wğ‘  1Fğ‘ ,Wğ‘Ÿ 1Fğ‘Ÿ,Wğ‘Ÿ 2Fğ‘Ÿ(cid:17) , (5) togetthefinalcopyrightwË† ğ‘ğ‘œğ‘.
where Wğ‘Ÿ 1, Wğ‘Ÿ 2, Wğ‘ 
1
and Wğ‘ 
2
respectively denote the projection
matrices.Finally,weperformtemporalfusionbetweentherefer- 3.5 TrainingandInferenceDetails
enceframeandsupportingframesviatheresidualconnectionand
Training:Thetrainingprocessofthevisualsectionoftheproposed
concatenationoperation. V2A-Markcanbedividedintotwosteps.Givenanarbitraryoriginal
FË†(ğ‘˜) =Concat(ğ›¾1Fğ‘ â†’ğ‘Ÿ +Fğ‘Ÿ,ğ›¾2Fğ‘Ÿâ†’ğ‘  +Fğ‘ ), (6) imageI ğ‘š(ğ‘˜ ğ‘’)
ğ‘‘
andwatermarkwğ‘ğ‘œğ‘,wefirsttrainthebithidingand
whereğ›¾1andğ›¾2respectivelydenotethelearnableparameters.With
recoverymoduleviatheâ„“2loss.
o acu hr iT eA viF nM g, mV o2 rA e- eM ffa er ck tic va en cb oe nt cte er ale mxp el no tit at ne dm mpo or ra el rc oo br ure sl ta dti eo cn os d, it nh gu .s â„“ ğ‘ğ‘œğ‘ =âˆ¥Iğ‘( ğ‘œğ‘˜ ğ‘›) âˆ’I ğ‘š(ğ‘˜ ğ‘’) ğ‘‘âˆ¥2 2+ğœ†âˆ¥wË† ğ‘ğ‘œğ‘ âˆ’wğ‘ğ‘œğ‘âˆ¥2 2, (7)
whereğœ†issetto10.Furthermore,wefreezetheweightsofBHM
3.3.3 DegradationPromptLearning. Tofurtherimprovethe andBRMandjointlytraintheVHMandVRM.Givenavideogroup
robustnessofV2A-Markindecodingbothvisuallocalizationand {I(ğ‘–) }ğ‘˜+1,localizationwatermarkgroup{I(ğ‘–) }ğ‘˜+1 andcopyright
copyrightwatermarks,weembedlearnabledegradationprompts ğ‘œğ‘Ÿğ‘– ğ‘˜âˆ’1 ğ‘™ğ‘œğ‘ ğ‘˜âˆ’1
Pğ‘£âˆˆRâ„1Ã—ğ‘¤1Ã—ğ‘1Ã—ğ‘’1,Pğ‘âˆˆRâ„2Ã—ğ‘¤2Ã—ğ‘2Ã—ğ‘’2 intofeaturesofthebitrecov-
watermarkwğ‘ğ‘œğ‘,thelossis:
eryandvideorevealingmodules,whereğ‘1,ğ‘2respectivelydenote â„“ ğ‘™ğ‘œğ‘ =âˆ¥Ë† I ğ‘œ(ğ‘˜ ğ‘Ÿğ‘–) âˆ’I ğ‘œ(ğ‘˜ ğ‘Ÿğ‘–) âˆ¥1+ğ›¼âˆ¥Iğ‘( ğ‘œğ‘˜ ğ‘›) âˆ’I ğ‘œ(ğ‘˜ ğ‘Ÿğ‘–) âˆ¥2 2+ğ›½âˆ¥Ë† I ğ‘™( ğ‘œğ‘˜ ğ‘) âˆ’I ğ‘™( ğ‘œğ‘˜ ğ‘) âˆ¥1, (8)
thechannelsofprompt,ğ‘’1,ğ‘’2respectivelydenotethenumberof
whereğ›¼andğ›½arerespectivelysetto100and1.Intheaudiosection,
degradation prompt. The degradation prompt pool comprises a
weuseapre-trainedaudiowatermarkingtool[40]torealizeaudio
seriesoflearnableembeddings,witheachcorrespondingtoatype
hidinganddecoding.
o of fp tho ete Rnt Pi Mald ineg tr ha eda vt ii do en o.S ru ep vp eo als ii nn gg mth oa dt uF lğ‘£ ea an nd dF tğ‘ ha ere U-th Ne etou intp tu ht es Inference:AsshowninFig.2and3,wecanconductforensics
viathepre-trainedcomponents.Toextracttamperedmasks,we
bit recovery module in Fig. 3 respectively, we utilize a channel
attentionmechanism(asshowninFig.5)tobetterencouragethe
comparethepre-definedwatermarkWğ‘™ğ‘œğ‘ withthedecodedone
interactionbetweentheinputfeaturesFğ‘£/Fğ‘ andthedegradation
WË†
ğ‘™ğ‘œğ‘
toobtainabinarymaskMË† ğ‘£ğ‘–ğ‘ âˆˆRğ»Ã—ğ‘ŠÃ—ğ‘‡:
promptPğ‘£/Pğ‘.Specifically,thefeaturesFğ‘£/Fğ‘arepassedtoaglobal MË† ğ‘£ğ‘–ğ‘ [ğ‘–,ğ‘—,ğ‘¡] =ğœƒ ğœ(max(|WË† ğ‘™ğ‘œğ‘[ğ‘–,ğ‘—,ğ‘¡,:]âˆ’Wğ‘™ğ‘œğ‘[ğ‘–,ğ‘—,ğ‘¡,:]|)), (9)
PAG
PAG vnoC vnoCZhangetal.
ProPainter[61] E2FGVI[25] VideoSlicing
Method
F1-Score AUC IoU BA(%) F1-Score AUC IoU BA(%) F1-Score AUC IoU BA(%)
OSN[48] 0.164 0.404 0.125 - 0.170 0.410 0.126 - 0.382 0.830 0.262 -
PSCC-Net[28] 0.275 0.757 0.186 - 0.273 0.742 0.174 - 0.559 0.876 0.419 -
HiFi-Net[11] 0.517 0.699 0.123 - 0.573 0.763 0.198 - 0.668 0.906 0.347 -
IML-ViT[33] 0.174 0.521 0.112 - 0.162 0.516 0.107 - 0.137 0.509 0.098 -
EditGuard[59] 0.924 0.950 0.866 99.41 0.923 0.950 0.865 99.43 0.922 0.949 0.861 99.73
V2A-Mark(Ours)
0.944 0.990 0.897 99.73 0.943 0.981 0.895 99.61 0.941 0.972 0.891 99.76
Table1:ComparisonwithothercompetitivetamperforensicsmethodsunderdifferentAIGC-basedvideoeditingmethods,such
2
asProPainter,E FGVI,andnaiveslicing.Clearly,ourmethodachievesthebestlocalizationandcopyrightrestorationaccuracy.
whereğ‘– âˆˆ [0,ğ»),ğ‘— âˆˆ [0,ğ‘Š)andğ‘¡ âˆˆ [0,ğ‘‡).ğœƒ ğœ(ğ‘§)=1(ğ‘§ â‰¥ğœ).ğœisset
Method Message PSNR(dB) SSIM NIQE(â†“)
to0.2.|Â·|isanabsolutevalueoperation.Theaudiotamperedperiod
MBRS[16] 30bits 26.57 0.908 6.473
m pË† rğ‘ eğ‘¢ cğ‘‘ iseis vd isir ue ac lt cly ope yxt rr igac ht te ,d wv ei ca ot nh de ua cu td bi io twve isr esa vt oil te ind gec oo nd te hr e.T coo pe yx rt ir ga hc tt CIN[32] 30bits 42.41 0.983 5.858
PIMoG[8] 30bits 37.71 0.971 8.129
extractedfromeachframeandselectthemostfrequentlyoccurring
0or1asthefinalresultwğ‘ğ‘£ ğ‘œğ‘.Meanwhile,weextractaudiocopy- SepMark[49] 30bits 34.86 0.914 5.321
HiNet[17] animage 36.46 0.940 6.271
rightwğ‘ğ‘ ğ‘œğ‘âˆˆ{0,1}ğ‘› anduseittocross-verifywithwğ‘ğ‘£ ğ‘œğ‘âˆˆ{0,1}ğ‘˜,
LF-VSN[34] animage 39.93 0.967 3.827
gettingthefinalresultwË† ğ‘ğ‘œğ‘âˆˆ{0,1}ğ‘˜.Consideringthattheaudio
EditGuard[59] animage 38.53 0.977 4.919
copyrightwatermarkcanoftenbeextractedmorerobustlyand V2A-Mark animage 40.83 0.983 3.484
isnoteasilydestroyed,wedirectlyuseitasthefirstğ‘›bitsinthe
finalmultimediacopyrightwË† ğ‘ğ‘œğ‘,whichtypicallyrepresentsthe Table2:Thecomparisonswithotherwatermarkingmethods
ownershipoftheentiremultimediaasset.Theremainingğ‘˜âˆ’ğ‘›bits onthevisualqualityofthecontainervideoVğ‘ğ‘œğ‘›.
aretakenfromtheextractedvisualwatermarkwğ‘ğ‘£ ğ‘œğ‘,whichwillbe
relyonimage-basedtamperlocalizationmethodsonaframe-by-
relatedtotheinformationofvideoframessuchasresolution,time frameprediction.Forvisualtamperlocalization,F1-score,AUC,
length,andframerate.Thecross-modalextractionprocessis: andIoUareusedtoevaluatelocalizationaccuracy.Forcopyright
wË†ğ‘ğ‘œğ‘ =Concat(wğ‘ğ‘ ğ‘œğ‘,wğ‘ğ‘£ ğ‘œğ‘[ğ‘›:]). (10) protection,bitaccuracy(BA)isusedtoassessthecopyrightrecov-
eryperformance.WeusetwoSOTAdeepvideoinpaintingmethods,
4 EXPERIMENTS
ProPainter[61]andE2FGVI[25],andanaiveslicingapproachto
simulatemalicioustampering.
4.1 ImplementationDetails AsreportedinTab.1,ourV2A-Markachievesimpressivelocal-
WetrainedourV2A-MarkintheVimeo-90K[52]withoutany
izationperformancewithanF1-Scoreofapproximately0.95,an
tampereddata.Wetestourmethodon30testingvideosofDavis AUCof0.99, andanIoUcloseto 0.9.Incontrast, otherpassive
dataset[38].Allvideoframeshavearesolutionof448Ã—256andcon- localizationmethods,whichrelysolelyontamperedvideoclues,
sistof50to100frames.Tosynthesizeaudio,wemanuallyextract performpoorlyinlocalizingunseentypesofmanipulation.Fur-
thevideocaptionsandusethemaspromptswiththeVALLE-E-X thermore,whenusingEditGuardtowatermarkeachvideoframe,
audiosynthesistool[46].TheAdam[19]isusedfortraining250ğ¾ althoughitachievessatisfactorylocalizationresults,itfallsshortin
iterationswithğ›½1=0.9andğ›½2=0.5.Thelearningrateisinitialized effectivelyutilizingtemporalinformation.Consequently,theIoU
to 1Ã—10âˆ’4 and decreases by half for every 30ğ¾ iterations, with ofthepredictedmasksinvarioustamperingmethodsisgenerally
thebatchsizesetto8.ğ‘ inVideohidingandrevealingmodule about0.03lowerthanthatachievedbyourV2A-Mark.Additionally,
issetto16.TheshapeoftwodegradationpromptsPğ‘£ andPğ‘ are our V2A-Mark achieves an over 99.5% bit accuracy across vari-
36Ã—36Ã—72Ã—2and36Ã—36Ã—16Ã—6.Weembed32-bitcopyrightwater- oustamperingmethods,whichisalsomarginallyhigherthanthat
markswğ‘ğ‘œğ‘ andpurebluevisuallocalizationwatermarksWğ‘™ğ‘œğ‘ ofEditGuard.Furthermore,asshowninFig.6,ourmethodhas
tooriginalvideos.Weusereplicationpaddingtoprocessthefirst veryobviousadvantagesoverSOTApassivelocalizationmethod
andlastframeoftheoriginalvideo.Meanwhile,wealsoembeda PSCC-Net[28],whichcanbeattributedtoourproactivetamper
versatilewatermarkwğ‘â€² ğ‘œğ‘ intotheoriginalaudio. localizationmechanism.Meanwhile,sinceweadoptedamoreef-
fectivetemporalalignmentandfusionmethod,wefoundthatin
4.2 ComparisonwithVisualTamper somesceneswhereEditGuardcanonlylocatetheroughoutline
LocalizationMethods ofthetamperingarea,ourV2A-Markcanstillclearlypredictthe
Toevaluatethevisuallocalizationandcopyrightrecoveryaccu- tamperedtraces.
racy,wecomparedourmethodwithsomeSOTApassivemethods
OSN[48],PSCC-Net[28],HiFi-Net[11],IML-ViT[33]andaproac- 4.3 ComparisonwithWatermarkingMethods
tiveforensicsmethodEditGuard[59].Despitepreviousresearchon To evaluate the visual quality of Vğ‘ğ‘œğ‘›, we compared our V2A-
videotamperlocalization[37],wecannotfindmethodswithpub- Markwithotherwatermarkingmethodson30testingvideosfrom
liclyavailablecode.Therefore,ourcomparativemethodsprimarily DAVIS[38].Forafaircomparison,wealsoretrainedourEditGuardV2A-Mark:VersatileDeepVisual-AudioWatermarkingforManipulationLocalizationandCopyrightProtection
2
Figure6:LocalizationaccuracycomparisonwithourV A-MarkandotherlocalizationmethodsPSCC-Net[28],EditGuard[59].
Ourmethodcanpredictmoreaccurateandclearertamperedmasks.Wealsopresentourcontainerandtamperedvideos.
on448Ã—256originalvideosand32bits.Ourcomparisonmethods ROC curve
includetheSOTAbit-hidingwatermarkingmethod[8,16,32,49], 1.0
large-capacitysteganographymethod[17,34],andaversatileimage
watermarkingmethod[59].AsshowninTab.2,thePSNRandSSIM 0.8
ofourcontainervideosfaroutperformmostwatermarkingmeth-
odssuchasMBRS,PIMoG,andSepMark,butiscloseorslightly
0.6
inferiortoCIN.Notethatthesemethodsonlyhide30bitsinthe
videos,butourV2A-MarkhidesbothanRGBimageand32bits.
0.4
Comparedwithhigh-capacitysteganographymethodsEditGuard, EditGuard
LF-VSN,andHiNet,ourmethodalsohasclearadvantagesinvisual LF-VSN
quality.Meanwhile,theperceptualquality(NIQE)ofourwater- 0.2 HiNet
V2A-Mark(Ours)
markedvideossurpassesallothermethods.Toverifythesecurityof
Reference
ourmethod,weperformanti-steganographydetectionviaStegEx- 0.0
0.0 0.2 0.4 0.6 0.8 1.0
pose[4]oncontainervideosofvarioussteganographymethods.
False Positive Rate
Allthemethodsconcealedpurebluevideosintotheoriginalvideos.
Figure7:ROCcurveofdifferentmethodsunderStegExpose.
Notethatthedetectionsetisbuiltbymixingcontainerandorig-
Thecloserthecurveistothereferencecentralaxis(which
inalvideoframeswithequalproportions.Wevarythedetection
meansrandomguess),themethodisbetterinsecurity.
thresholdsinawiderangeinStegExpose[4]anddrawtheROC
curveinFig.7.Theidealcaserepresentsthatthedetectorhasa50%
probabilityofdetectingcontainervideosfromanequallymixed
ofthetamperedaream.WeobservedfromTab.3thatthewater-
detectiontest,thesameasarandomguess.Evidently,thesecurity
markedaudiomaintainshighSNR/PESQon28.29dB/4.50with
of our method exhibits a significant advantage compared to all
theoriginalaudio,indicatingthatourV2A-Markhaslittleimpact
competitivemethods.
onthesemanticfidelityoftheaudio.Meanwhile,ourmethodcan
accuratelylocalizethetamperedareaswith99.63%AUCandobtain
4.4 AudioTamperLocalization
100%bitaccuracyunderâ€œCleanâ€degradation,whichshowsthat
ToevaluatetheaccuracyofV2A-Markforaudiotamperlocalization, ouraudiolocalizationwatermarkissensitiveenoughtomalicious
werandomlyinsert1s-2stamperedaudiointoourconstructed30 tampering.Furthermore,weadopttwoclassicaldegradationson
originalaudio.SNRandPESQareusedtoevaluatethequantitative thecontaineraudioAğ‘ğ‘œğ‘›,namelyResampleandLowpass.â€œResam-
andperceptualqualityofwatermarkedaudio.Bitaccuracyisused pleâ€denotesresamplingthecontaineraudioata90%samplingrate
toevaluatethebiterrorrateofthepre-definedwğ‘â€²
ğ‘œğ‘
andextracted (16000Hzâ†’14400Hz).â€œLowpassâ€meansapplyinglow-passfilterto
wğ‘ğ‘ ğ‘œğ‘.AUCisusedtocalculatethelocalizationaccuracybetween containeraudioAğ‘ğ‘œğ‘›,cuttingfrequenciesaboveacutofffrequency
thepredictedaudiotamperedperiodmğ‘ğ‘¢ğ‘‘ andthegroundtruth (1000Hz).AsplottedinTab.3,althoughthecontaineraudioAğ‘ğ‘œğ‘›
lanigirO
reniatnoC
derepmaT
teN-CCSP
drauGtidE
sruO
TG
etaR
evitisoP
eurTZhangetal.
Degradation SNR(dB) PESQ(â†‘) Bit.Acc. AUC Case DegradationDğ‘£(Â·) TAFM DPL F1 AUC IoU BA(%)
Clean 28.29 4.50 100% 99.63% (a) Clean âœ˜ âœ” 0.935 0.962 0.885 99.47
(b) RandomDegradations âœ” âœ˜ 0.901 0.961 0.832 98.45
Resample - - 100% 98.58%
Clean âœ” âœ” 0.944 0.990 0.897 99.73
Lowpass - - 99.72% 99.41% Ours
RandomDegradations âœ” âœ” 0.912 0.975 0.849 99.43
Table3:Watermarkedaudioqualityandaudiotamperlo- Table5:AbalationstudiesonthecorepartsofV2 A-Mark.
2
calizationperformanceofourV A-Markundercleanand
differentdegradationscenes.
4.7 Applications
GaussianNoise H.264 OurV2A-Markcanprovidefocusedprotectionforvideosbasedon
Methods Metrics Clean Poisson
ğœ=5 ğœ=10 QP=5 QP=10 user-definedareas.ThisallowsourV2A-Marktoapplytosome
F1 0.924 0.891 0.872 0.900 0.881 0.896
globaltamperingsuchasvisual-audiodeepfake.Specifically,weuse
AUC 0.950 0.945 0.922 0.946 0.941 0.947
EditGuard IoU 0.866 0.835 0.812 0.830 0.828 0.842 EfficientSAM[51]tosegmentthefacialregionsthatneedfocused
BA(%) 99.41 99.01 96.90 95.16 92.23 99.31 protection,andaddlocalizationwatermarksonlytotheseparts,
F1 0.944 0.904 0.900 0.915 0.909 0.913 whilestillembeddingaglobalcopyrightwatermark.Asshownin
V2A-Mark AUC 0.990 0.979 0.963 0.978 0.967 0.980 Fig.8,wemanipulatetheidentityinthecontainervideoframes
IoU 0.897 0.842 0.833 0.858 0.850 0.856
viaSimSwap[5],andalterthefirst0.5softhisaudiofrom"there
BA(%) 99.73 99.35 98.51 99.34 99.18 99.71
aremanyjobsforAmerican"to"therearefewjobsforAmerican."
Table4:Localizationandbitrecoveryperformanceofour Subsequently, our V2A-Mark is capable of effectively detecting
2
V A-MarkandEditGuardunderdifferentdegradations. tamperedareasinthefaceregionaswellasalterationsintheaudio.
Fortheaudioportion,wedeterminewhethereachsamplepoint
hasundergonedifferentdegradations,ourV2A-Markstillmain- hasbeentamperedwithbyevaluatingtheprobabilityofalteration.
tainsover98%localizationaccuracyandnearly100%bitaccuracy,
provingitsrobustnessagainstcommonaudiocorruptions. Video Frame Audio
4.5 RobustnessAnalysis
ToanalyzetherobustnessofourV2A-Mark,wecompareourmethod
withEditGuard,thebestcomparativemethodinthecleancase.We
selectedthreetypesofvideodegradation,includingGaussiannoise,
H.264videocoding,andPoissonnoise.AsreportedinTab.4,we
foundthatourV2A-Markhasonlyslightperformancedegrada-
tionundervariousdegradationscomparedtothecleanscene,and
bothsurpassEditGuardinlocalizationaccuracyandcopyrightre-
construction.Specifically,sinceweuseamulti-frameinput,single-
frameoutputstructure,whichbetterexplorestemporalinformation, Figure8:ApplicationsceneoftheproposedV2 A-Markon
ourmethodperformsbetterinhandlinginter-framedegradation theDeepfaketampering[5].OurV2 A-Markcanaccurately
(suchasH.264videocoding)thanEditGuardwhichaddswater- predictvisualtamperedmasksandthetamperedprobability
marks frame by frame. As reported in Tab. 4, the recovered bit ofaudiosamples.
accuracyofourmethodfarsurpassesEditGuardby4.18%and6.95%
inQP=5andQP=10.Meanwhile,ourV2A-Markalsooutperforms
EditGuardby0.028and0.022inlocalizationaccuracy(IoU),which 5 CONCLUSION
provesitssuperiorityindecodingrobustness. ToaddressthechallengesofAI-generatedvisual-audioforensics,
an innovative deep watermarking method with strong general-
4.6 AblationStudies izability, versatile function, and cross-modal properties dubbed
Toevaluatethecontributionofeachcomponent,wemainlycon- V2A-Markisproposed.Itembedsinvisiblevisual-audiolocalization
ductablationstudiesonthetemporalalignmentandfusionmodule andcopyrightwatermarksintotheoriginalvideoframesandaudio.
(TAFM)anddegradationpromptlearning(DPL).Ourresultsare Ifencounteringmalicioustamperingonvisualoraudioinformation,
reportedonTab.5,whereâ€œrandomdegradationâ€denotesthatwe wecangetaccuratetamperedvisualmasks,videocopyright,and
randomlyselectonedegradationfromGaussiannoise,H.264,and tamperedaudioperiodsinthedecodingendviaourV2A-Mark.
Poissonnoise.Comparingcase(a)andoursintheâ€œcleanâ€scene,it FacingtheimminentexplosivegrowthoftheAIGCvideoindus-
demonstratesthattheproposedTAFMcanenhancethelocaliza- try,ourV2A-Markhasthepotentialtosafeguardthesustainable
tionaccuracyandachieve0.012gainsinIoU,whichprovesthat developmentoftheAIGCindustry,andalsoestablishacleanand
theproposedTAFMcanboostthetemporalinteractionandrealize transparentinformationenvironment.
effectivetemporalalignment.Comparingcase(b)andoursinthe Limitations:Sincethereisacertaincontradictionbetweenthe
â€œrandomdegradationâ€scene,duetothelearneddegradationrepre- fidelityandrobustnessofvideowatermarking,wearestillcom-
sentations,wefindthatourmethodachievessignificantgainson mittedtodesigningadvancedmodulestoachievebettertradeoff.
localizationaccuracyandcopyrightprecision. Additionally,astherearefewvideodiffusion-basededitingmethods
lanigirO
reniatnoC
derepmaT
tluseR
TamperedV2A-Mark:VersatileDeepVisual-AudioWatermarkingforManipulationLocalizationandCopyrightProtection
available,wehavenotconductedexperimentsonlargervideoedit- conferenceoncomputervisionandpatternrecognition.
ingmodels.However,webelieveourmethodisrobustandeffective [22] HaodongLiandJiwuHuang.2019.Localizationofdeepinpaintingusinghigh-
againstallformsoflocalvisual-audiomanipulation.
passfullyconvolutionalnetwork.InProceedingsoftheIEEE/CVFInternational
ConferenceonComputerVision(ICCV).
[23] WeiqiLi,BinChen,andJianZhang.2022.D3c2-net:Dual-domaindeepconvolu-
REFERENCES
tionalcodingnetworkforcompressivesensing.arXivpreprintarXiv:2207.13560
(2022).
[1] MahdiAhmadi,AlirezaNorouzi,NaderKarimi,ShadrokhSamavi,andAliEmami. [24] YueLi,DongLiu,HouqiangLi,LiLi,ZhuLi,andFengWu.2018. Learninga
2020.ReDMark:Frameworkforresidualdiffusionwatermarkingbasedondeep convolutionalneuralnetworkforimagecompact-resolution.IEEETransactions
networks.ExpertSystemswithApplications146(2020),113157. onImageProcessing28,3(2018),1092â€“1107.
[2] VishalAsnani,XiYin,TalHassner,andXiaomingLiu.2023.Malp:Manipulation [25] ZhenLi,Cheng-ZeLu,JianhuaQin,Chun-LeGuo,andMing-MingCheng.2022.
localizationusingaproactivescheme.InProceedingsoftheIEEE/CVFConference Towardsanend-to-endframeworkforflow-guidedvideoinpainting.InPro-
onComputerVisionandPatternRecognition(CVPR). ceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.
[3] AndreasBlattmann,TimDockhorn,SumithKulal,DanielMendelevitch,Maciej 17562â€“17571.
Kilian,DominikLorenz,YamLevi,ZionEnglish,VikramVoleti,AdamLetts, [26] Siau-ChuinLiew,Siau-WayLiew,andJasniMohdZain.2013.Tamperlocaliza-
etal.2023.Stablevideodiffusion:Scalinglatentvideodiffusionmodelstolarge tionandlosslessrecoverywatermarkingschemewithROIsegmentationand
datasets.arXivpreprintarXiv:2311.15127(2023). multilevelauthentication.Journalofdigitalimaging26(2013),316â€“325.
[4] BenediktBoehm.2014. Stegexpose-AtoolfordetectingLSBsteganography. [27] Chia-ChenLin,Ting-LinLee,Ya-FenChang,Pei-FengShiu,andBohanZhang.
arXivpreprintarXiv:1410.6656(2014). 2023.FragileWatermarkingforTamperLocalizationandSelf-RecoveryBased
[5] RenwangChen,XuanhongChen,BingbingNi,andYanhaoGe.2020.Simswap: onAMBTCandVQ.Electronics12,2(2023),415.
Anefficientframeworkforhighfidelityfaceswapping.InProceedingsofthe28th [28] XiaohongLiu,YaojieLiu,JunChen,andXiaomingLiu.2022. PSCC-Net:Pro-
ACMinternationalconferenceonmultimedia.2003â€“2011. gressivespatio-channelcorrelationnetworkforimagemanipulationdetection
[6] XinruChen,ChengboDong,JiaqiJi,JuanCao,andXirongLi.2021. Image andlocalization.IEEETransactionsonCircuitsandSystemsforVideoTechnology
manipulationdetectionbymulti-viewmulti-scalesupervision.InProceedingsof 32,11(2022),7505â€“7517.
theIEEE/CVFInternationalConferenceonComputerVision(ICCV). [29] XuntaoLiu,YuzhouYang,QichaoYing,ZhenxingQian,XinpengZhang,and
[7] PatrickEsser,JohnathanChiu,ParmidaAtighehchian,JonathanGranskog,and ShengLi.2024.PROMPT-IML:ImageManipulationLocalizationwithPre-trained
AnastasisGermanidis.2023.Structureandcontent-guidedvideosynthesiswith FoundationModelsThroughPromptTuning. arXivpreprintarXiv:2401.00653
diffusionmodels.InProceedingsoftheIEEE/CVFInternationalConferenceon (2024).
ComputerVision.7346â€“7356. [30] YangLiu,MengxiGuo,JianZhang,YueshengZhu,andXiaodongXie.2019.
[8] HanFang,ZhaoyangJia,ZehuaMa,Ee-ChienChang,andWeimingZhang.2022. Anoveltwo-stageseparabledeeplearningframeworkforpracticalblindwa-
PIMoG:Aneffectivescreen-shootingnoise-layersimulationfordeep-learning- termarking.InProceedingsoftheACMInternationalConferenceonMultimedia
basedwatermarkingnetwork.InProceedingsofthe30thACMInternationalCon- (MM).
ferenceonMultimedia(MM). [31] XiyangLuo,YinxiaoLi,HuiwenChang,CeLiu,PeymanMilanfar,andFengYang.
[9] HanFang,YupengQiu,KejiangChen,JiyiZhang,WeimingZhang,andEe- 2023. DVMark:adeepmultiscaleframeworkforvideowatermarking. IEEE
ChienChang.2023.Flow-basedrobustwatermarkingwithinvertiblenoiselayer TransactionsonImageProcessing(2023).
forblack-boxdistortions.InProceedingsoftheAAAIConferenceonArtificial [32] RuiMa,MengxiGuo,YiHou,FanYang,YuanLi,HuizhuJia,andXiaodongXie.
Intelligence(AAAI). 2022.TowardsBlindWatermarking:CombiningInvertibleandNon-invertible
[10] RohitGirdhar,MannatSingh,AndrewBrown,QuentinDuval,SamanehAzadi, Mechanisms.InProceedingsoftheACMInternationalConferenceonMultimedia
SaiSakethRambhatla,AkbarShah,XiYin,DeviParikh,andIshanMisra.2023. (MM).
EmuVideo:FactorizingText-to-VideoGenerationbyExplicitImageConditioning. [33] XiaochenMa,BoDu,XianggenLiu,AhmedYAlHammadi,andJizheZhou.
arXivpreprintarXiv:2311.10709(2023). 2023.IML-ViT:ImageManipulationLocalizationbyVisionTransformer.arXiv
[11] XiaoGuo,XiaohongLiu,ZhiyuanRen,StevenGrosz,IacopoMasi,andXiaoming preprintarXiv:2307.14863(2023).
Liu.2023.Hierarchicalfine-grainedimageforgerydetectionandlocalization.In [34] ChongMou,YouminXu,JiechongSong,ChenZhao,BernardGhanem,andJian
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecogni- Zhang.2023. Large-capacityandflexiblevideosteganographyviainvertible
tion(CVPR). neuralnetwork.InProceedingsoftheIEEE/CVFConferenceonComputerVision
[12] YuweiGuo,CeyuanYang,AnyiRao,YaohuiWang,YuQiao,DahuaLin,and andPatternRecognition(CVPR).
BoDai.2023.Animatediff:Animateyourpersonalizedtext-to-imagediffusion [35] NeenaRajNRandRShreelekshmi.2022.Fragilewatermarkingschemefortamper
modelswithoutspecifictuning.arXivpreprintarXiv:2307.04725(2023). localizationinimagesusinglogisticmapandsingularvaluedecomposition.
[13] AmalHammami,AmalBenHamida,ChokriBenAmar,andHenriNicolas.2024. JournalofVisualCommunicationandImageRepresentation85(2022),103500.
BlindSemi-fragileHybridDomain-BasedDualWatermarkingSystemforVideo [36] RupaliDPatilandShilpaMetkar.2015.Fragilevideowatermarkingfortamper-
AuthenticationandTamperingLocalization.Circuits,Systems,andSignalPro- ingdetectionandlocalization.In2015InternationalConferenceonAdvancesin
cessing43,1(2024),264â€“301. Computing,CommunicationsandInformatics(ICACCI).1661â€“1666.
[14] XiaoxiaoHu,QichaoYing,ZhenxingQian,ShengLi,andXinpengZhang.2023. [37] PengfeiPei,XianfengZhao,JinchuanLi,andYunCao.2023. UVL:AUnified
DRAW:DefendingCamera-shootedRAWagainstImageManipulation.InPro- FrameworkforVideoTamperingLocalization.arXivpreprintarXiv:2309.16126
ceedingsoftheIEEE/CVFInternationalConferenceonComputerVision(ICCV). (2023).
[15] NasirNHurrah,ShabirAParah,NazirALoan,JavaidASheikh,Mohammad [38] FedericoPerazzi,JordiPont-Tuset,BrianMcWilliams,LucVanGool,Markus
Elhoseny,andKhanMuhammad.2019. Dualwatermarkingframeworkfor Gross,andAlexanderSorkine-Hornung.2016.Abenchmarkdatasetandeval-
privacyprotectionandcontentauthenticationofmultimedia.Futuregeneration uationmethodologyforvideoobjectsegmentation.InProceedingsoftheIEEE
computerSystems94(2019),654â€“673. conferenceoncomputervisionandpatternrecognition.724â€“732.
[16] ZhaoyangJia,HanFang,andWeimingZhang.2021.Mbrs:Enhancingrobustness [39] VaishnavPotlapalli,SyedWaqasZamir,SalmanKhan,andFahadShahbazKhan.
ofdnn-basedwatermarkingbymini-batchofrealandsimulatedjpegcompres- 2023. PromptIR:PromptingforAll-in-OneBlindImageRestoration. arXiv
sion.InProceedingsofthe29thACMInternationalConferenceonMultimedia preprintarXiv:2306.13090(2023).
(MM). [40] RobinSanRoman,PierreFernandez,AlexandreDÃ©fossez,TeddyFuron,Tuan
[17] JunpengJing,XinDeng,MaiXu,JianyiWang,andZhenyuGuan.2021.HiNet: Tran,andHadyElsahar.2024.ProactiveDetectionofVoiceCloningwithLocal-
DeepImageHidingbyInvertibleNetwork.InProceedingsoftheIEEE/CVFInter- izedWatermarking.arXivpreprintarXiv:2401.17264(2024).
nationalConferenceonComputerVision(ICCV). [41] ShellySheynin,AdamPolyak,UrielSinger,YuvalKirstain,AmitZohar,Oron
[18] AsraKamili,NasirNHurrah,ShabirAParah,GhulamMohiuddinBhat,and Ashual,DeviParikh,andYanivTaigman.2023.Emuedit:Preciseimageediting
KhanMuhammad.2020.DWFCAT:Dualwatermarkingframeworkforindustrial viarecognitionandgenerationtasks.arXivpreprintarXiv:2311.10089(2023).
imageauthenticationandtamperlocalization.IEEETransactionsonIndustrial [42] UrielSinger,AdamPolyak,ThomasHayes,XiYin,JieAn,SongyangZhang,
Informatics17,7(2020),5108â€“5117. QiyuanHu,HarryYang,OronAshual,OranGafni,etal.2022.Make-a-video:
[19] DiederikPKingmaandJimmyBa.2014.Adam:Amethodforstochasticopti- Text-to-videogenerationwithouttext-videodata.arXivpreprintarXiv:2209.14792
mization.arXivpreprintarXiv:1412.6980(2014). (2022).
[20] Myung-JoonKwon,In-JaeYu,Seung-HunNam,andHeung-KyuLee.2021.CAT- [43] XiaopengSun,WeiqiLi,ZhenyuZhang,QiufangMa,XuhanSheng,MingCheng,
Net:Compressionartifacttracingnetworkfordetectionandlocalizationofimage HaoyuMa,ShijieZhao,JianZhang,JunlinLi,etal.2023.OPDN:Omnidirectional
splicing.InProceedingsoftheIEEE/CVFWinterConferenceonApplicationsof position-awaredeformablenetworkforomnidirectionalimagesuper-resolution.
ComputerVision(WACV). InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecog-
[21] GuobiaoLi,ShengLi,ZicongLuo,ZhenxingQian,andXinpengZhang.2024. nition.1293â€“1301.
PurifiedandUnifiedSteganographicNetwork.InProceedingsoftheIEEE/CVFZhangetal.
[44] ZhihaoSun,HaoranJiang,DandingWang,XirongLi,andJuanCao.2023.SAFL- [54] QichaoYing,XiaoxiaoHu,XiangyuZhang,ZhenxingQian,ShengLi,andXin-
Net:Semantic-AgnosticFeatureLearningNetworkwithAuxiliaryPluginsfor pengZhang.2022.RWN:RobustWatermarkingNetworkforImageCropping
ImageManipulationDetection.InProceedingsoftheIEEE/CVFInternational Localization.InProceedingsoftheIEEEInternationalConferenceonImagePro-
ConferenceonComputerVision(ICCV). cessing(ICIP).
[45] YuliyaVybornova.2020. Anewwatermarkingmethodforvideoauthentica- [55] QichaoYing,ZhenxingQian,HangZhou,HaishengXu,XinpengZhang,and
tionwithtamperlocalization.InComputerVisionandGraphics:International SiyiLi.2021.Fromimagetoimuge:Immunizedimagegeneration.InProceedings
Conference,ICCVG2020,Warsaw,Poland,September14â€“16,2020,Proceedings. oftheACMinternationalconferenceonMultimedia(MM).
201â€“213. [56] QichaoYing,HangZhou,ZhenxingQian,ShengLi,andXinpengZhang.2023.
[46] ChengyiWang,SanyuanChen,YuWu,ZiqiangZhang,LongZhou,Shujie LearningtoImmunizeImagesforTamperLocalizationandSelf-Recovery.IEEE
Liu,ZhuoChen,YanqingLiu,HuamingWang,JinyuLi,etal.2023. Neural TransactionsonPatternAnalysisandMachineIntelligence(2023).
codeclanguagemodelsarezero-shottexttospeechsynthesizers.arXivpreprint [57] JiwenYu,XiaodongCun,ChenyangQi,YongZhang,XintaoWang,YingShan,
arXiv:2301.02111(2023). andJianZhang.2023. AnimateZero:VideoDiffusionModelsareZero-Shot
[47] ShujinWei,HaodongLi,andJiwuHuang.2022.DeepVideoInpaintingLocal- ImageAnimators.arXivpreprintarXiv:2312.03793(2023).
izationUsingSpatialandTemporalTraces.InIEEEInternationalConferenceon [58] YanhongZeng,JianlongFu,andHongyangChao.2020.Learningjointspatial-
Acoustics,SpeechandSignalProcessing(ICASSP).8957â€“8961. temporaltransformationsforvideoinpainting.InComputerVisionâ€“ECCV2020:
[48] HaiweiWu,JiantaoZhou,JinyuTian,andJunLiu.2022.Robustimageforgeryde- 16thEuropeanConference,Glasgow,UK,August23â€“28,2020,Proceedings,PartXVI
tectionoveronlinesocialnetworksharedimages.InProceedingsoftheIEEE/CVF 16.Springer,528â€“543.
ConferenceonComputerVisionandPatternRecognition(CVPR). [59] XuanyuZhang,RunyiLi,JiwenYu,YouminXu,WeiqiLi,andJianZhang.2024.
[49] XiaoshuaiWu,XinLiao,andBoOu.2023.SepMark:DeepSeparableWatermark- EditGuard:VersatileImageWatermarkingforTamperLocalizationandCopyright
ingforUnifiedSourceTracingandDeepfakeDetection.InProceedingsofthe Protection.InProceedingsoftheIEEE/CVFconferenceoncomputervisionand
ACMinternationalconferenceonMultimedia(MM). patternrecognition.
[50] YueWu,WaelAbdAlmageed,andPremkumarNatarajan.2019. Mantra-net: [60] YulinZhang,JiangqunNi,WenkangSu,andXinLiao.2023.ANovelDeepVideo
Manipulationtracingnetworkfordetectionandlocalizationofimageforgeries WatermarkingFrameworkwithEnhancedRobustnesstoH.264/AVCCompres-
withanomalousfeatures.InProceedingsoftheIEEE/CVFConferenceonComputer sion.InProceedingsofthe31stACMInternationalConferenceonMultimedia.
VisionandPatternRecognition(CVPR). 8095â€“8104.
[51] YunyangXiong,BalaVaradarajan,LemengWu,XiaoyuXiang,FanyiXiao, [61] ShangchenZhou,ChongyiLi,KelvinCKChan,andChenChangeLoy.2023.
ChenchenZhu,XiaoliangDai,DilinWang,FeiSun,ForrestIandola,etal.2023. ProPainter:Improvingpropagationandtransformerforvideoinpainting.In
Efficientsam:Leveragedmaskedimagepretrainingforefficientsegmentanything. ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.10477â€“
arXivpreprintarXiv:2312.00863(2023). 10486.
[52] TianfanXue,BaianChen,JiajunWu,DonglaiWei,andWilliamTFreeman.2019. [62] YangmingZhou,QichaoYing,YifeiWang,XiangyuZhang,ZhenxingQian,
Videoenhancementwithtask-orientedflow.InternationalJournalofComputer andXinpengZhang.2022.RobustWatermarkingforVideoForgeryDetection
Vision127(2019),1106â€“1125. withImprovedImperceptibilityandRobustness.In2022IEEE24thInternational
[53] GuanhuiYe,JiashiGao,YuchenWang,LiyanSong,andXuetaoWei.2023.ItoV: WorkshoponMultimediaSignalProcessing(MMSP).
EfficientlyAdaptingDeepLearning-basedImageWatermarkingtoVideoWater- [63] JirenZhu,RussellKaplan,JustinJohnson,andLiFei-Fei.2018.Hidden:Hiding
marking.arXivpreprintarXiv:2305.02781(2023). datawithdeepnetworks.InEuropeanConferenceonComputerVision(ECCV).