Amortized Bayesian Workflow (Extended Abstract)
MarvinSchmitt‚àó‚àó1,3 ChengkunLi‚àó2 AkiVehtari3 LuigiAcerbi2
Paul-ChristianBu¬®rkner4 StefanT.Radev5
1 Introduction
In statistics, we often reason about unknown parameters Œ∏ from observables y modeled as a joint
distributionp(Œ∏,y).Theposteriorp(Œ∏|y)isthestatisticallyoptimalsolutiontothisinverseproblem,
andtherearedifferentcomputationalapproachestoapproximatethiscostlydistribution.
Markov chain Monte Carlo (MCMC) methods constitute the most popular family of sampling al-
gorithmsduetotheirtheoreticalguaranteesandpowerfuldiagnostics[6,7]. MCMCmethodsyield
autocorrelateddrawsconditionalonafixeddatasety . Asaconsequence,theprobabilisticmodel
obs
has to be re-fit for each new data set, which necessitates repeating the entire MCMC procedure
fromscratch. Forsuchalgorithmsperformedconditionallyonafixeddataset,thewell-established
Bayesianworkflow[7]definesaniterativesequenceofstepsthatencompassesmodelspecification,
fitting,evaluation,addressingcomputationalissues,modifications,andmodelcomparison.
Differently,amortizedBayesianinferenceusesdeepneuralnetworkstolearnadirectmappingfrom
observablesy tothecorrespondingposteriorp(Œ∏|y). Amortizedinferencefollowsatwo-stageap-
proach: (i)atrainingstage,whereneuralnetworkslearntodistillinformationfromtheprobabilistic
modelbasedonsimulatedexamplesofobservationsandparameters(Œ∏,y) ‚àº p(Œ∏)p(y|Œ∏);and(ii)
an inference stage where the neural networks approximate the posterior distribution for an unseen
datasety innear-instanttimewithoutrepeatingthetrainingstage. TheBayesianworkflowisnot
obs
directlytransferabletoamortizedinferencebecausetheapproximationstepislearnedovertheprior
predictivespace(seeSection2)whileonlytheinferencestepisconditionalonafixeddataset.
InBayesianinference, bothMCMC(e.g., ChEES-HMC;[9])
ChEES-HMC
andamortizedinferencelieattheParetofrontofmethodsthat
have a favorable trade-off between accuracy and speed. In
thispaper,weproposeanadaptiveworkflowthatyieldshigh-
+ PSIS
quality posterior draws while minimizing the required com-
putetimebymovingalongtheParetofronttoaffordfast-and- Amortized
accurate inference when possible, and slow-but-guaranteed- inference
accurate inference when necessary (see Figure 1). Crucially,
slow instant
our workflow consistently yields high accuracy, as evaluated
Inference speed per data set
with tailored diagnostics in all steps. Furthermore, it re-uses
Figure1: Ourworkflowadaptively
computations for subsequent steps in the form of importance
moves along the Pareto front and
sampling proposals and initializations of many-short-chains
re-usespreviouscomputations.
MCMC.Thesoftwareimplementationencompassesanend-to-
endworkflowfeaturingmodelspecificationviaPyMC[15],amortizedinferencewithdeeplearning
viaBayesFlow[16],andGPU-enabledChEES-HMC[9]viaTensorflow Probability[5].
2 IntegratingAmortizedInferenceintotheBayesianWorkflow
Ouradaptiveworkflowstartswithneuralnetworktrainingtoenablesubsequentamortizedinference
onanynumberofunseendatasets. Whilethistrainingphaseisconceptuallyidenticaltostandalone
amortizedinferencetraining, theinferencephasefeaturesaprincipledcontrolflowthatguidesthe
analysisbasedontailoreddiagnosticsinordertoselecttheappropriateinferencealgorithmforeach
observeddatasetwhilere-usingcomputationsalongtheway.
‚àóEqualcontribution 1UniversityofStuttgart,GER2UniversityofHelsinki,FI3AaltoUniversity,FI
4TUDortmundUniversity,GER5RensselaerPolytechnicInstitute,US
1
4202
peS
6
]GL.sc[
1v23340.9042:viXra
seetnaraug
ycaruccA
gnorts
kaewStep 1 Step 2 Step 3
Amortized inference Pareto-smoothed importance sampling ChEES-HMC with amortized inits
re-use re-use
draws draws
One dataset Neural density ùëÜdraws Importance FitPareto Initialize ùëÜ Warmup and
ùë¶!( "% #) estimatorùëû‚Äô ùúÉ$ ((%),‚Ä¶,ùúÉ$ )(%) weights distribution superchains sampling
Example draws Diagnostics no Example draws Diagnostics no Example draws Diagnostics no Use NUTS or
OK? OK? OK? revise model
yes yes yes
Accept Accept Accept
draws draws draws
K=256 observed data sets PSIS on remaining 64 data sets ChESS-HMC on remaining 8 data sets
Accept amortized draws for 192/256 data sets Accept PSIS draws for 56/64 data sets Accept ChEES-HMC draws for 8/8 data sets
Figure2:Ouradaptiveworkflowleveragesnear-instantamortizedposteriorsamplingwhenpossible
andgraduallyresortstoslower‚Äìbutmoreaccurate‚Äìsamplingalgorithms. Asindicatedbytheblue
dashedarrows,were-usetheSdrawsfromtheamortizedposteriorinstep1forthesubsequentsteps
intheformofPSISproposals(step2)andinitialvaluesinChEES-HMC(step3).
2.1 Trainingphase: simulation-basedopt
SincemostBayesianmodelsaregenerativebydesign,wecanreadilysimulateM tuplesofparam-
etersandcorrespondingobservationsfromthejointmodel,
(Œ∏(m),y(m))‚àºp(Œ∏,y) ‚áî Œ∏(m) ‚àºp(Œ∏), y(m) ‚àºp(y|Œ∏) form=1,...,M (1)
which results in the training set {(Œ∏(m),y(m))}M .2 The total number M of example tuples is
m=1
calledthetrainingbudget,andthequalityoftheamortizedposteriorestimatorhingesonasufficient
trainingbudget. Inthecasestudy,weuseflowmatching[13]asaflexibleneuralestimators,butour
workflowisagnostictotheexactchoiceofneuralnetworkarchitecture.
Diagnostics. Atthispoint,therearenoobserveddatasetsyettoguidedata-conditionaldiagnos-
tics. However,wecaneasilysimulateasynthetictestset{(Œ∏(j),y(j))}J ofsizeJ fromthejoint
‚àó j=1
modelviaEq.1. Inthisclosed-world setting, weknowwhich‚Äútrue‚ÄùparametervectorŒ∏(j) gener-
‚àó
ated each simulated test data set y(j). We evaluate the amortized posterior‚Äôs bias and variance via
thenormalizedrootmean-squarederror(NRMSE)andperformsimulation-basedcalibration(SBC;
[19,21])checkingtoevaluatetheuncertaintycalibration.Theseevaluationsactasaconvergencedi-
agnostictoassertthattheneuralestimatoryieldsfaithfulposteriordrawsunderidealizedconditions
(seeAppendixAfordetails). Iftheseclosed-worldconvergencediagnosticsfail,weshouldtunethe
traininghyperparameters(e.g.,trainingduration,simulationbudget,neuralnetworkarchitecture).
2.2 Inferencephase: posteriorapproximationonobserveddatasets
We now use the pre-trained neural network to achieve rapid amortized posterior inference on a
total of K observed data sets {y(k)}K , which naturally do not come with known ground-truth
obs k=1
parameters. The diagnostics in this step are evaluated conditional on each observed data set to
determinewhetherthewholesetofamortizeddrawsisacceptableforeachspecificdataset.
2.2.1 Step1: Amortizedposteriordraws
Weaimtousetherapidsamplingcapabilitiesoftheamortizedposteriorapproximatorq whenever
œï
possible according to the diagnostics. Therefore, the natural first step for each observed data set
y(k) istoquerytheamortizedposteriorandsampleS posteriordrawsŒ∏ÀÜ(k),...,Œ∏ÀÜ(k) ‚àºq (Œ∏|y(k))
obs 1 S œï
innear-instanttime(seeFigure2,firstpanel).
Diagnostics. Amortized inference may yield unfaithful results under distribution shifts [11, 20,
23]. Therefore, we assess whether an observed data set is atypical under the data-generating pro-
cess of the joint model. We define atypical data as data sets that have a larger maximum mean
discrepancy(MMD;[8])tothetrainingsetthan95%ofthetrainingdatasetsthemselves(cf. [20];
seeAppendixBfordetails). Sincetheamortizedapproximatorhasnoaccuracyguaranteesfordata
outsideofthetypicalsetofthejointmodel,wepropagatesuchatypicaldatasetstothenextstep.
2Thisdatagenerationschemeisalsoknownaspriorpredictivesampling.
22.2.2 Step2: Pareto-smoothedimportancesampling
Asafirstpursuittoimprovethequalityoftheamortizedposteriordrawswithasmalloverheadin
computation time, we use a Pareto-smoothed sampling importance sampling (PSIS) scheme [22]
(seeFigure2,secondpanel). Basedontheamortizedposteriordrawsfromstep1,wecomputethe
importance weights w(k) =p(y(k)|Œ∏ÀÜ )p(Œ∏ÀÜ )/q (Œ∏ÀÜ |y(k)) conditional on each observed data set
s s s œï s
y(k) andsmooththetailoftheweightdistributionbasedonfittingageneralizedParetodistribution
(aka. Pareto-smoothing; [22]). These smoothed importance weights are then used for computing
posteriorexpectationsandforimprovingtheposteriordrawswiththesamplingimportanceresam-
pling (SIR) scheme [18]. While the utility of standard importance sampling for improving neural
posteriordrawshaspreviouslybeeninvestigated[4],wespecificallyusethePSISalgorithmwhich
isself-diagnosingandthereforebettersuitedforaprincipledworkflow.
Note. Commonneuralarchitecturesforamortizedinference(e.g.,normalizingflows,flowmatch-
ing) are mode covering.3 When the neural network training stage is insufficient (e.g., small simu-
lationbudgetorpoorlyoptimizednetwork),thismayleadtooverdispersedposteriors. Fortunately,
thiserrsintherightdirection,andPSIScangenerallymitigateoverdispersedmode-coveringdraws.
Diagnostics. We use the Pareto-kÀÜ diagnostic to gauge the fidelity of the PSIS-refined posterior
draws. Accordingtoestablishedguidelines[22,24],Pareto-kÀÜ ‚â§0.7indicatesgoodresults,whereas
kÀÜ >0.7impliesthatthedrawsshouldberejectedandtherespectivedatasetsproceedtostep3.
2.2.3 Step3: ChEES-HMCwithamortizedinitializations
If Pareto-smoothed importance sampling fails according
Amortized initializations
to the diagnostics, we resort to an MCMC sampling
ChEES-HMC samples
scheme which is augmented by re-using computations
Target posterior
fromtheprevioussteps. Concretely,weusetheChEES-
HMC algorithm [9] that affords to launch thousands of
parallelchainsonaGPU.Toaccelerateconvergence,we
usetheimportanceweightsfromstep2tosampleS(e.g.,
16) unique draws for initializing S ChEES-HMC super-
chains4,eachwithL(e.g.,128)subchainsforthenested-
R(cid:98)diagnosticbelow.ForthepurposeofChEES-HMCini-
1
tialization,itisalsodesirablethattheamortizedposterior
Figure 3: We initialize many ChEES-
drawsaregenerallymodecovering(cf.step2).
HMCchainswithamortizeddraws.
Diagnostics. Inthislaststep,weusethenestedR(cid:98)diagnostic[14]whichisspecificallydesignedto
assesstheconvergenceofthemany-but-shortMCMCchains. Ifthediagnosticsinthisstepindicate
unreliable inference, we recommend resorting to the overarching Bayesian workflow [7] and ad-
dressingthecomputationalissuesthatevenpersistwhenusingthe(ChEES-)HMCalgorithm. This
couldinvolveusingtheestablishedNUTS-HMCalgorithm([3,10])orrevisingtheBayesianmodel.
3 EmpiricalDemonstration: GeneralizedExtremeValueDistribution
In this section, we illustrate the application of the proposed workflow with Bayesian inference on
theparametersofageneralizedextremevalue(GEV)distribution. TheGEVdistributionischarac-
terizedbythreeparameters: alocationparameter¬µ ‚àà R,ascaleparameterœÉ ‚àà R ,andashape
>0
parameterŒæ ‚ààR,withacumulativedistributionfunctionG(y)=exp(‚àí(1+Œæ(y‚àí¬µ))‚àí1/Œæ). Given
œÉ
N = 65 i.i.d. observations y = (y ,...,y ) from the GEV distribution, we aim to compute a
1 65
posterior estimate for the data-generating parameters Œ∏ = (¬µ,œÉ,Œæ). We first train the amortized
posteriorapproximatoronsimulatedparametersandverifythatitsclosed-worldperformanceissat-
isfactory,asindexedbyhighparameterrecoveryandexcellentcalibration(seeAppendixC).
As summarized in Table 1, we perform inference on a total of K = 1000 test data sets which are
deliberatelysampledfromamodelwitha2√ówiderpriordistributiontoemulateout-of-distribution
3Conditional flow matching is mode covering [13]. Normalizing flows are mode covering because they
optimizetheforwardKLdivergence[17]. Incontrast,variationalinferencealgorithmstypicallyoptimizethe
reverseKLdivergence,whichleadstomodeseekingbehaviorthatislessfavorableforimportancesampling.
4IfimportancesamplingresamplingwithoutreplacementfailstoreturnS validdrawsforinitializingthe
chains(e.g.,duetolessthanSnon-zeroimportanceweights),wefallbacktorandominitializations.
3
2Accepteddatasets Time TPA1 MMDtoreference
Step1:Amortizedinference 678/1000 142 0.21 0.0082[4√ó10‚àí4,0.35]
Step2:Amortized+PSIS 228/322 124 0.54 0.0010[1√ó10‚àí4,0.02]
Step3:ChEES-HMCw/inits 66/94 398 6.03 0.0001[1√ó10‚àí5,0.05]
Total:aggregatedoversteps 972/1000 664 0.68 ‚Äî
1TPA:timeperaccepteddatasetinseconds,computedastheexpendedtimerelativetothenumberofaccepteddatasetsinthisstep.
Table1: MMD(median,95%CI)quantifiesthedistancebetweenapproximateandreferenceposte-
riordraws. Alltimesarewall-clocksecondsonanNVIDIAA100. Thetimeforstep1includesthe
training (120s), inference (10s), and diagnostics (12s) stages of the amortized approximator. Our
amortizedworkflowyieldedatotalof2millionposteriordrawsin11minutes,whereasusingNUTS
onalldatasetstakesapproximately16hours. WhiletheMMDinstep1isnumericallyhigherthan
insteps2and3,spotchecksindicatedthattheposteriorsarevisuallysimilartothereferencedraws.
settingsinrealapplications(seeAppendixCfordetails). Instep1,wedraw2000posteriorsamples
from the amortized approximator q , which takes 150 seconds for all 1000 data sets (2 million
œï
posteriordrawsintotal). Weconfirmthat678/1000observeddatasetsaretypicalunderthedata-
generatingprocessandaccepttheamortizeddraws. Theremaining322datasetsarepassedtostage
2,whereweapplythePSISalgorithm,takingatotalof130seconds.ThePareto-kÀÜdiagnosticsignals
acceptableresultsfor228ofthe322datasets,whichmeansthatwepropagatetheremaining94data
setstostage3. Here,weinitializetheparallelChEES-HMCsamplerwiththeamortizeddrawsand
observe that the nested R(cid:98) values lie below 1.01 for 66 of the data sets, leading to acceptance of
theChEESdraws. Thisleavesonly28datasetsforseparateinferencewithNUTS-HMC.Intotal,
ouramortizedBayesianworkflowtook‚âà10minutesandledtohigh-qualityposteriordrawsonall
steps, asindicatedbyasmallMMDtoareferenceposterior. Incontrast, runningNUTS-HMCon
all1000observedtestdatasetswouldhavetaken‚âà955minutes(16hours),whichunderscoresthe
efficiencygainsofourintegratedworkflow.
Amortized draws can be good ChEES-HMC inits. 101
Amortized
To further investigate whether the amortized posterior
100 Amortized + PSIS
estimates are indeed beneficial for initializing ChEES- Random Initialization
HMC chains, we randomly collect 20 test datasets that 10 1
are passed to step 3 in the workflow. This indicates
10 2
thatboththeamortizedposteriordrawsandtheirPareto-
smoothedrefinementaredeemedunacceptable,asquanti- 10 3
fiedbyPareto-kÀÜ >0.7instep2.WeinitializetheChEES- 1050100 200 300 500
Number of warmup iterations
HMCchainswiththreedifferentmethods: (1)Amortized
Figure 4: Using amortized posterior
posterior draws, (2) PSIS-refined amortized draws, and
draws as inits can reduce the required
(3)arandominitializationschemesimilartoStan[3].We
warmupinChEES-HMC,buttheextent
runthechainsfordifferentnumbersofwarmupiterations
of the benefit varies. The figure shows
followedbyasinglesamplingiteration. Asdescribedin
median¬±IQRacross20testdatasets.
Section2,weusethenestedR(cid:98)valuetogaugewhetherthe
chainsconvergedappropriatelyduringthewarmupstage(asquantifiedbycommonR(cid:98)‚àí1thresholds
of10‚àí1or10‚àí2). AsshowninFigure4,amortizedposteriordraws(andtheirPSIS-refinedcounter-
parts)cansignificantlyreducetherequirednumberofwarmupiterationstoachieveconvergenceof
ChEES-HMCchains,eventhoughthedrawsthemselveshavepreviouslybeenflaggedasunaccept-
able. This emphasizesthatour amortizedworkflow createssynergiesby re-usingcomputations in
subsequentsteps.However,itisnotevidentwhetherinitializingChEES-HMCwiththePSIS-refined
drawsfromstep2hasanadvantageoverusingtherawamortizeddrawsfromstep1,andwemainly
seethatPSISimprovestheworst-caseperformance(uppererrorboundaryinFigure4).
4 Conclusion
We presented an adaptive Bayesian workflow to combine the rapid speed of amortized inference
with the undisputed sampling quality of MCMC in the context of many observed data sets while
maintainingahighqualityofposteriordraws. Ourworkflowefficientlyusesresourcesby(i)using
fast(amortized)inferencewhentheresultsareaccurate;(ii)refiningdrawswithPSISwhenpossible;
and(iii)amortizedinitializationsofslow-but-guaranteed-accurateMCMCchainswhenneeded.
4
1
R
detseNAcknowledgments
MS and PB acknowledge support of Cyber Valley Project CyVy-RF- 2021-16, the DFG under
Germany‚Äôs Excellence Strategy ‚Äì EXC-2075 - 390740016 (the Stuttgart Cluster of Excellence
SimTech). MSacknowledgestravelsupportfromtheEuropeanUnion‚ÄôsHorizon2020researchand
innovationprogrammeundergrantagreementsNo951847(ELISE)andNo101070617(ELSA),and
theAaltoScience-ITproject.CLandLAweresupportedbytheResearchCouncilofFinland(grants
number 356498 and 358980 to LA). AV acknowledges the Research Council of Finland Flagship
program: FinnishCenterforArtificialIntelligence,andAcademyofFinlandproject340721.
References
[1] Paul-Christian Bu¬®rkner, Maximilian Scholz, and Stefan T. Radev. Some models are useful,
but how do we know which ones? Towards a unified Bayesian model taxonomy. Statistics
Surveys,17,2023.
[2] Colin Caprani. Generalized Extreme Value Distribution. https://www.pymc.io/
projects/examples/case_studies/GEV.html.
[3] Bob Carpenter, Andrew Gelman, Matthew D Hoffman, Daniel Lee, Ben Goodrich, Michael
Betancourt,MarcusBrubaker,JiqiangGuo,PeterLi,andAllenRiddell. Stan: Aprobabilistic
programminglanguage. Journalofstatisticalsoftware,76(1),2017.
[4] MaximilianDax,StephenR.Green,JonathanGair,MichaelPu¬®rrer,JonasWildberger,JakobH.
Macke,AlessandraBuonanno,andBernhardScho¬®lkopf.Neuralimportancesamplingforrapid
andreliablegravitational-waveinference. Phys.Rev.Lett.,130:171403,Apr2023.
[5] Joshua V. Dillon, Ian Langmore, Dustin Tran, Eugene Brevdo, Srinivas Vasudevan, Dave
Moore, Brian Patton, Alex Alemi, Matt Hoffman, and Rif A. Saurous. TensorFlow distri-
butions,2017.
[6] Andrew Gelman, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B
Rubin. BayesianDataAnalysis. Chapman&Hall/CRC,Philadelphia,PA,3edition,2013.
[7] AndrewGelman,AkiVehtari,DanielSimpson,etal.Bayesianworkflow.arXivpreprint,2020.
[8] AGretton, K.Borgwardt, MalteRasch, BernhardScho¬®lkopf, andAJSmola. AKernelTwo-
SampleTest. TheJournalofMachineLearningResearch,13:723‚Äì773,2012.
[9] MatthewHoffman,AlexeyRadul,andPavelSountsov.Anadaptive-MCMCschemeforsetting
trajectorylengthsinHamiltonianMonteCarlo.InArindamBanerjeeandKenjiFukumizu,edi-
tors,ProceedingsofThe24thInternationalConferenceonArtificialIntelligenceandStatistics,
volume130ofProceedingsofMachineLearningResearch,pages3907‚Äì3915.PMLR,13‚Äì15
Apr2021.
[10] MatthewD.HoffmanandAndrewGelman. TheNo-u-TurnSampler: AdaptivelySettingPath
LengthsinHamiltonianMonteCarlo. JournalofMachineLearningResearch,15(47):1593‚Äì
1623,2014.
[11] Daolang Huang, Ayush Bharti, Amauri Souza, Luigi Acerbi, and Samuel Kaski. Learning
robuststatisticsforsimulation-basedinferenceundermodelmisspecification,2023.
[12] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Interna-
tionalConferenceonLearningRepresentations(ICLR),SanDiega,CA,USA,2015.
[13] YaronLipman,RickyT.Q.Chen,HeliBen-Hamu,MaximilianNickel,andMatthewLe. Flow
matching for generative modeling. In The Eleventh International Conference on Learning
Representations,2023.
[14] CharlesC.Margossian, MatthewD.Hoffman, PavelSountsov, LionelRiou-Durand, AkiVe-
htari, and Andrew Gelman. Nested R(cid:98): Assessing the Convergence of Markov Chain Monte
CarloWhenRunningManyShortChains. BayesianAnalysis,pages1‚Äì28,2024.
5[15] Abril-Pla Oriol, Andreani Virgile, Carroll Colin, Dong Larry, Fonnesbeck Christopher J.,
KochurovMaxim,KumarRavin,LaoJupeng,LuhmannChristianC.,MartinOsvaldoA.,Os-
thege Michael, Vieira Ricardo, Wiecki Thomas, and Zinkov Robert. PyMC: A modern and
comprehensive probabilistic programming framework in Python. PeerJ Computer Science,
9:e1516,2023.
[16] StefanT.Radev,MarvinSchmitt,LukasSchumacher,LasseElsemu¬®ller,ValentinPratz,Yannik
Scha¬®lte, Ullrich Ko¬®the, and Paul-Christian Bu¬®rkner. BayesFlow: Amortized Bayesian work-
flowswithneuralnetworks. JournalofOpenSourceSoftware,8(89):5702,2023.
[17] DaniloRezendeandShakirMohamed. Variationalinferencewithnormalizingflows. InFran-
cis Bach and David Blei, editors, Proceedings of the 32nd International Conference on Ma-
chineLearning,volume37ofProceedingsofMachineLearningResearch,pages1530‚Äì1538,
Lille,France,07‚Äì09Jul2015.PMLR.
[18] Donald B. Rubin. Using the SIR algorithm to simulate posterior distributions. In Bayesian
statistics 3. Proceedings of the third Valencia international meeting, 1-5 June 1987, pages
395‚Äì402.ClarendonPress,1988.
[19] Teemu Sa¬®ilynoja, Paul-Christian Bu¬®rkner, and Aki Vehtari. Graphical test for discrete uni-
formity and its applications in goodness-of-fit evaluation and multiple sample comparison.
StatisticsandComputing,32(2):1‚Äì21,2022.
[20] Marvin Schmitt, Paul-Christian Bu¬®rkner, and Ko¬®the. Detecting model misspecification in
amortizedBayesianinferencewithneuralnetworks. ProceedingsoftheGermanConference
onPatternRecognition(GCPR),2023.
[21] SeanTalts,MichaelBetancourt,DanielSimpson,AkiVehtari,andAndrewGelman.Validating
bayesianinferencealgorithmswithsimulation-basedcalibration. arXivpreprint,2018.
[22] AkiVehtari,DanielSimpson,AndrewGelman,YulingYao,andJonahGabry.Paretosmoothed
importancesampling. arXivpreprint,2015.
[23] DanielWard,PatrickCannon,MarkBeaumont,MatteoFasiolo,andSebastianSchmon.Robust
neural posterior estimation and statistical model criticism. Advances in Neural Information
ProcessingSystems,35:33845‚Äì33859,2022.
[24] YulingYao,AkiVehtari,DanielSimpson,andAndrewGelman. Yes,butdiditwork?: Eval-
uatingvariationalinference. InJenniferDyandAndreasKrause, editors, Proceedingsofthe
35th International Conference on Machine Learning, volume 80 of Proceedings of Machine
LearningResearch,pages5581‚Äì5590.PMLR,10‚Äì15Jul2018.
[25] ManzilZaheer,SatwikKottur,SiamakRavanbakhsh,BarnabasPoczos,RuslanSalakhutdinov,
andAlexanderSmola. Deepsets,2017.
6A Closed-worlddiagnostics
Inthefollowing,letŒ∏ÀÜ(j),...,Œ∏ÀÜ(j) ‚àºq (Œ∏|y(j))beS drawsfromtheamortizedposteriorq (¬∑).
1 S œï œï
A.1 Normalizedrootmean-squarederror
Asameasureofposteriorbiasandvariance,weassesstherecoveryoftheground-truthparameters,
forexampleviatheaveragenormalizedrootmeansquarederror(RMSE)overthetestset,
(cid:118)
J (cid:117) S
NRMSE=
1 (cid:88) 1 (cid:117) (cid:116)1 (cid:88)(cid:16) Œ∏(j)‚àíŒ∏ÀÜ(j)(cid:17)2
, (2)
‚àó s
J range(Œ∏ ) S
‚àó
j=1 s=1
whererange(Œ∏ )=max(Œ∏(k))‚àímin(Œ∏(k)).
‚àó ‚àó ‚àó
k k
A.2 Simulation-basedcalibrationchecking
Simulation-based calibration (SBC; [19, 21]) checking evaluates the uncertainty calibration of the
amortizedposterior. Forthetrueposteriorp(Œ∏|y),allintervalsU (Œ∏|y)arewell-calibratedforany
q
quantileq ‚àà(0,1)[1],
(cid:90)(cid:90)
q = I[Œ∏ ‚ààU (Œ∏|y)]p(y|Œ∏ )p(Œ∏ )dŒ∏ dy, (3)
‚àó q ‚àó ‚àó ‚àó
with indicator function I[¬∑]. Insufficient calibration of the posterior manifests itself as violations
of Eq. 3. To quantify these violations, we report the expected calibration error of the amortized
posterior,computedasmedianSBCerrorof20posteriorcredibleintervalswithincreasingcentered
quantilesfrom0.5%to99.5%,averagedacrosstheJ examplesinthetestset.
B Testingforatypicalityinstep1
Inspiredbyanout-of-distributioncheckingmethodforamortizedinferenceundermodelmisspeci-
fication[20],weuseasampling-basedhypothesistesttoflagatypicaldatasetswherethetrustwor-
thinessofamortizedinferencemightbeimpeded. Concretely,weusethesampling-basedestimator
forthemaximummeandiscrepancy(MMD;[8]),
MMD2(p||q)=E [Œ∫(x,x‚Ä≤)]+E [Œ∫(x,x‚Ä≤)]‚àí2E [Œ∫(x,x‚Ä≤)], (4)
x,x‚Ä≤‚àºp(x) x,x‚Ä≤‚àºq(x) x‚àºp(x),x‚Ä≤‚àºq(x)
whereŒ∫(¬∑,¬∑)isapositivedefinitekernelandweaimtoquantifythedistancebetweenthedistribu-
tionsp,qbasedonsamples.
Inourcaseofatypicalitydetectioninstep1,p
Training samples (null distribution)
isthedistributionoftrainingdatayusedduring 3.0
Test samples
simulation-based training, and q is the opaque 2.5 MMD2 cut-off
distribution behind the observed test data sets. 2.0
We construct a hypothesis test, where the null
1.5
hypothesis states that p = q. For M train-
ing data sets {y(m)}M and K test data sets 1.0
m=1
{y(k)}K , we first compute the sampling dis- 0.5
k=1
tribution of MMDs from M MMD estimates 0.0
0.4 0.6 0.8 1.0 1.2
based on training samples y vs. y(m). This MMD2
quantifies the natural sampling distribution for
Figure 5: Illustration of our sampling-based hy-
M-vs.-1 MMD estimates where both samples
pothesis test that flags atypical data sets where
stem from the training set. We then compute
amortizedinferencehasnoaccuracyguarantees.
theŒ± = 95%percentile, whichmarksthecut-
offforthe5%mostatypicaltrainingexamples,anddenotethisthresholdasMMD2. FortheKdata
Œ±
setsinthetestsample,wethencomputetheMMDestimateofallM trainingsamplesagainsteach
ofthek =1,...,K testsamples,heredenotedasMMD2. Then,weputitalltogetherandflagdata
k
setsasatypicalwhenMMD2 ‚â•MMD2. Thetype-Ierrorrateofthistestcanbesetrelativelyhigh
k Œ±
toobtainaconservativetestthatwillflagmanydatasetsfordetailedinvestigationinfurtherstepsof
ourworkflow.
7
ytisneD1.0
4.2 R2 = 0.961 R2 = 0.984 0.4 R2 = 0.724
r = 0.981 0.8 r = 0.992 r = 0.853
4.0 0.2
0.6
3.8 0.0
0.4
3.6 0.2
0.2
3.4 0.4
0.0
3.4 3.6 3.8 4.0 4.2 0.0 0.2 0.4 0.6 0.8 1.0 0.4 0.2 0.0 0.2 0.4
Ground truth Ground truth Ground truth
(a)Theparameterrecoveryisexcellentfortheparameters¬µ,œÉandgoodfor
theshapeparameterŒæ.
0.15 0.15 0.15
Rank ECDF
0.10 0.10 95% Confidence Bands 0.10
0.05 0.05 0.05
Rank ECDF Rank ECDF
0.00 95% Confidence Bands 0.00 0.00 95% Confidence Bands
0.05 0.05 0.05
0.10 0.10 0.10
0.150.0 0.2 0.4 0.6 0.8 1.0 0.150.0 0.2 0.4 0.6 0.8 1.0 0.150.0 0.2 0.4 0.6 0.8 1.0
Fractional rank statistic Fractional rank statistic Fractional rank statistic
(b)Simulation-basedcalibrationcheckingindicatesexcellentcalibrationfor
allparameters.
Figure6: Theclosed-worlddiagnosticsindicateacceptableconvergenceoftheamortizedposterior.
Note. Inthecasestudyofthispaper,weperformtheabovetestinthesummaryspace,thatis,we
replacealloccurencesofywiththelearnedneuralsummarystatisticsh (y),whereh isaDeepSet
œà œà
thatlearnsan8-dimensionalrepresentationofthedata(seebelowfordetails).
C Experimentdetails
In this section, we provide experiment details for parameter inference of the generalized extreme
value(GEV)distribution.
C.1 Problemdescription
FollowingCapranietal.[2],thepriordistributionisdefinedas:
¬µ‚àºN(3.8,0.04)
œÉ ‚àºHalf-Normal(0,0.09) (5)
Œæ ‚àºTruncated-Normal(0,0.04)withbounds[‚àí0.6,0.6].
C.2 Simulation-basedtraining
Forthesimulation-basedtrainingstage, wesimulate10000tuplesofparametersandobservations
from the parameter priors and the corresponding GEV distributions. Each data set contains 65
i.i.d. observations from the GEV distribution. The validation set, generated in the same manner,
consists of 1000 samples from the joint model. The neural density estimator uses flow matching
[13]asagenerativeneuralnetworkbackbone.Theinternalnetworkisamultilayerperception(MLP)
with 5 layers of 128 units each, residual connections, and 5% dropout. Before entering the flow
matchingnetworkasconditioningvariables,wepre-processtheobservationsy =(y ,...,y )with
1 65
aDeepSet[25]thatjointlylearnsan8-dimensionalembeddingoftheobservationswhileaccounting
for the permutation-invariant structure of the data. The DeepSet has a depth of 1, uses a mish
activation, max inner pooling layers, 64 units in the equivariant and invariant modules, and 5%
dropout. In accordance with common practice in computational Bayesian statistics (e.g., PyMC
orStan), theamortizedneuralapproximatorlearnstoestimatetheparametersinanunconstrained
parameterspace.
Optimization. TheneuralnetworkisoptimizedviatheAdamoptimizer[12],withacosinedecay
applied to the learning rate (initial learning rate of 10‚àí4, a warmup target of 10‚àí3, Œ± = 10‚àí3) as
8
detamitsE
ecnereffid
FDCEwellasaglobalclipnormof1.0. Thebatchsizeissetto512andthenumberoftrainingepochsis
300.
Diagnostics. Theclosed-worldrecovery(Figure6a)andsimulation-basedcalibration(Figure6b)
indicate that the neural network training has successfully converged to a trustworthy posterior ap-
proximatorwithinthescopeofthetrainingset.
Inference data sets In order to emulate distribution shifts that arise in real-world applications
while preserving the controlled experimental environment, we simulate the ‚Äúobserved‚Äù data sets
fromajointmodelwithapriorthathas4√óthedispersionofthemodelusedduringtraining. More
specifically,thepriorisspecifiedas:
¬µ‚àºN(3.8,0.16)
œÉ ‚àºHalf-Normal(0,0.36) (6)
Œæ ‚àºTruncated-Normal(0,0.16)withbounds[‚àí1.2,1.2].
C.3 ChEES-HMC
WeuseS = 16superchainsandL = 128subchains, resultinginatotalnumberofS ¬∑L = 2048
chains.Theinitialstepsizeissetto0.1.Thenumberofwarmupiterationsissetto200.Thenumber
ofsamplingiterationsis1,resultinginatotalnumberof2048post-warmupMCMCdraws.
9