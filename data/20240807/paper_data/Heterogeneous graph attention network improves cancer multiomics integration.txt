Heterogeneous graph attention network improves cancer
multiomics integration
Sina Tabakhi1,2, Charlotte Vandermeulen3, Ian Sudbery3, and Haiping Lu1,2*
1
SchoolofComputerScience,TheUniversityofSheffield,Sheffield,UK
2
CentreforMachineIntelligence,TheUniversityofSheffield,Sheffield,UK
3
SchoolofBiosciences,TheUniversityofSheffield,Sheffield,UK
*
correspondingauthor: HaipingLu(h.lu@sheffield.ac.uk)
ABSTRACT
Theincreaseinhigh-dimensionalmultiomicsdatademandsadvancedintegrationmodelstocapturethecomplexityofhuman
diseases. Graph-baseddeeplearningintegrationmodels,despitetheirpromise,strugglewithsmallpatientcohortsandhigh-
dimensionalfeatures,oftenapplyingindependentfeatureselectionwithoutmodelingrelationshipsamongomics. Furthermore,
conventionalgraph-basedomicsmodelsfocusonhomogeneousgraphs,lackingmultipletypesofnodesandedgestocapture
diversestructures.WeintroduceaHeterogeneousGraphATtentionnetworkforomicsintegration(HeteroGATomics)toimprove
cancerdiagnosis. HeteroGATomicsperformsjointfeatureselectionthroughamulti-agentsystem,creatingdedicatednetworks
offeatureandpatientsimilarityforeachomicmodality. Thesenetworksarethencombinedintooneheterogeneousgraph
forlearningholisticomic-specificrepresentationsandintegratingpredictionsacrossmodalities. Experimentsonthreecancer
multiomicsdatasetsdemonstrateHeteroGATomicsâ€™superiorperformanceincancerdiagnosis. Moreover,HeteroGATomics
enhancesinterpretabilitybyidentifyingimportantbiomarkerscontributingtothediagnosisoutcomes.
Introduction
Recentadvancementsinsequencingtechnologieshavesignificantlyacceleratedthegenerationofmultimodalbiologicaldata,
collectivelyknownasmultiomics. Thisprogressenablespersonalizedmedicinebyconstructingcomprehensivepatientprofiles
across multiple omic modalities1,2. While each omic modality contains valuable information, their collective integration
enables new insights into the fundamental aspects of human disease biology, particularly in cancer research3,4. Research
initiatives developing integrative multiomics models2,5,6 leverage the unique and complementary characteristics of each
modalitytoconstructmultimodalmodelsthataremoreaccurateandinterpretablethanunimodalmodels,therebyenhancing
biologicalpredictionsandfacilitatingbiomarkerdiscovery3,6,7. Therearethreemainmodalityfusionstrategies2,8. Earlyfusion
concatenatesfeaturesfromdifferentinputmodalities9,combiningallmodalitiesattherawfeaturelevel. Jointorintermediate
fusionprocesseseachmodalityindependentlybeforeintegratingtheirlow-levelrepresentations5,10,enablingmoreeffective
interactionsamongmodalitiesatalowerdimensionality. Latefusiondevelopsseparatemodelsforeachmodalityandmerges
theirpredictions11,leveragingunimodalstrengthsandaddressingmultiomicsheterogeneity.
Morerecently,deeplearningongraphs(ornetworks),referredtoasgraphneuralnetworks(GNNs)12,hasbeenincreasingly
utilized for multiomics integration4,7,13,14. GNNs offer more accurate models with improved decision-making power by
effectivelycapturingboththeintra-andinter-omicstructureswithinthedata. Modelingeachomicmodalityasagraph,where
biologicalentitiesarenodesandtheirinteractionsareedges,facilitatesadeeperunderstandingofentityinteractions7. Graph
attentionnetworks(GATs)areaclassofGNNsthatextendthiscapabilitybyusinganattentionmechanismtolearnvarying
importancefordifferentinteractions15. Thisapproachenhancesthemodelâ€™sabilitytofocusonthemostrelevantbiological
relationshipswithinmultiomicsdatasets16.
GNNsinmultiomicsanalysis,whilepromising,stillfacetwokeychallenges. Thefirstchallengeislearningfromhigh-
dimensionaldata,whereeachomicsuffersfromhavingalargenumberoffeaturescomparedtoasmallpatientcohort1,17. This
issuehinderstheabilityofGNNstolearnmeaningfulrepresentations,reducingperformanceinbiomedicalapplications5. Most
currentstudiesapplyfeatureselectionstrategiesindependentlytoeachomicmodality4,8,withoutaccountingforrelationships
amongthem,whichcancompromiseinterpretabilityandmodelperformance. Afewstudieshaveexploredjointfeatureselection
acrossallomics18,19,yettheseofteninvolveeitherasingle-iterationgreedyprocessorcreatingfullyconnectedgraphsrather
thansparsegraphsinfeaturespace,leadingtoreducedpredictivecapabilityorhighcomputationaldemands. Therefore,thereis
acleargapinthedevelopmentofbettermethodsthateffectivelyaccountforintra-andinter-omicrelationshipsinmultiomics.
ThesecondchallengeisthelimitedexpressivepowerofconventionalGNNsdevelopedforhomogeneousgraphs. Inthese
models4,6,13,thelearningprocessincorporatesonlypatientorfeaturesimilaritynetworkswithasingletypeofnodeandedge.
4202
guA
5
]GL.sc[
1v54820.8042:viXraRepresentingmultipleinputmodalitiesasahomogeneousgraphlosescrucialstructuralinformationinherentinthedata,failsto
accountforthediversenatureofthedata,andlimitsthemodelâ€™sabilitytocapturecomplexbiologicalinteractions. Incontrast,
heterogeneousgraphsofferasolutiontotheselimitationsbymodelingmultipletypesofnodesandedgestocapturethediversity
of the data. While some methods have extended learning to heterogeneous graphs16,20,21, they often rely on pre-existing
knowledgegraphstorepresentsemanticrelationshipsbetweendifferententities,suchasgenes,patients,anddiseases. However,
such pre-existing knowledge graphs may not always be available, and creating them often requires domain knowledge or
expertiseandcanbecostly22.
Here,wepresentHeteroGATomics,anovelframeworkemployingheterogeneousGATforintegratingmultiomicsdatafor
cancerdiagnosis. HeteroGATomicsoperatesintwodistinctstages: jointfeatureselectionandheterogeneousgraphlearning.
Unlikepreviousfeatureselectionmethods,HeteroGATomicsimplementsamulti-agentsystem(MAS)forajointfeatureselection
onsparsegraphs,constructedacrossthefeaturespacesofallomics. Thisapproachcreatesafeaturesimilaritynetworkforeach
modality,representingoneviewoftheinputdata. Theproposedjointfeatureselectionstrategynotonlyachievescompetitive
performancebutalsocapturesstructuralfeaturesarisingfromMAS.Moreover,foreachomicmodality,apatientsimilarity
networkisbuilt,formingtheseconddataview. Weproposeadual-viewapproachtoautomaticallyconstructmodality-specific
heterogeneousgraphsbyconnectingfeatureandpatientsimilaritynetworks,followedbyrepresentationlearningwithGAT
encoderstogeneratepredictions. ThisheterogeneousgraphconstructionimprovestheexpressivepowerofGATsbycapturing
diversestructuralinformation. Leveraginglatefusionforfinaldecision-makinginHeteroGATomicsintegratespredictionsfrom
allmodalitiesinasupervisedmannerformultiomicsintegration4.
WeconductcomprehensiveexperimentstoevaluateHeteroGATomicsâ€™diagnosisperformanceonthreecancermultiomics
datasets. The results show that HeteroGATomics consistently outperforms baseline methods, highlighting the benefits of
integratingdiverseomicsdata. Additionally,weshowthenecessityofeachmoduleofHeteroGATomicsviaaseriesofablation
studies. WefurtherexploreHeteroGATomicsâ€™interpretabilitythroughabiomarkeridentificationprocess,revealingitsability
toidentifycancer-relatedbiomarkers. Bypinpointinginteractingbiomarkernetworksandhighlightingkeycancer-related
functions,italsoidentifiespotentialtherapeutictargets.
Results
HeteroGATomicsarchitecture
HeteroGATomicsperformssupervisedmultiomicsintegrationwithtwomainmodules: anMASfordimensionalityreductionof
preprocessedomicsandaGATarchitectureforheterogeneousgraphrepresentationlearning,asshowninFig. 1.
HeteroGATomicsfirstrepresentseachpreprocessedomicasasparsefeaturesimilaritynetwork,whereeachnodecorresponds
toanindividualfeatureandeachedgeindicatesthecorrelationbetweenapairoffeatures(Fig. 1aandSupplementaryFig. S6).
Then,itusestheMASalgorithmtojointlyselectfeaturesfromallomicmodalities,leveragingbothintra-andcross-modality
interactionsatthefeaturelevel(seeMethods)toutilizecomplementaryinformationinmultiomicsdatasets.
Afterjointfeatureselection,HeteroGATomicscreatesapatientsimilaritynetworkforeachomic,wherenodesrepresent
patients and edges represent correlations between their features. Next, it constructs a heterogeneous graph for each omic
modalitybyconnectingthepatientandfeaturesimilaritynetworks,connectingfeaturenodestoallpatientnodes(Fig. 1b).
Thishelpscapturepatient-levelandfeature-levelrelationshipsinaunifiedrepresentation,providingacomprehensiveview
of the dataset. Then, a heterogeneous GAT model encodes the structures inherent in each input heterogeneous graph and
learnsmeaningfulnoderepresentations(Fig. 1c). Afterward,asingle-layerfullyconnectedneuralnetworktakesthelearned
noderepresentationsasinputtopredictcancer. Finally,alatefusionstrategyconsolidatespredictionsacrossmodalitiesby
aggregatingthegeneratedpredictionsandfeedingthemintoaviewcorrelationdiscoverynetwork(VCDN)4forfinalprediction.
ThemodelarchitectureandimplementationdetailsareprovidedinMethodsandSupplementarySectionS4.3,respectively.
Tothebestofourknowledge,HeteroGATomicsisthefirstmethodtoexplorecross-modalityinteractionsatboththefeature
level,usingtheMASalgorithm,andthelabellevel,employingalatefusionstrategy. Moreover,thejointfeatureselection
algorithminHeteroGATomicsnotonlyreducesfeaturedimensionalitybutalsoprovidesmorestructuralinformationforthe
heterogeneousgraph,benefitingdownstreamtasks.
Datasets
WeevaluateHeteroGATomicsperformanceacrossthreemultiomicsdatasetsderivedfromTheCancerGenomeAtlas(TCGA)
cohort,fortwodownstreamtasks,includingbladderurothelialcarcinoma(BLCA)gradeclassification,brainlowergradeglioma
(LGG)gradeclassification,andrenalcellcarcinoma(RCC)subtypeclassification. WedownloadalldatasetsfromtheTCGA
cohortviatheUCSCXenaplatform23, whichincludesDNAmethylation(DNA),geneexpressionRNAseq(mRNA),and
miRNAmaturestrandexpressionRNAseq(miRNA).Ouranalysisretainsonlypatientswithavailableinformationinallomic
modalities. Eachomicmodalityineverydatasetundergoesindividualpreprocessingtoaddressmissingvalues,normalize
features,andeliminatelow-variancefeatures(seeMethods). Table1summarizesthedatasetcharacteristicsforeachphase.
2/29a
Preprocessed omics Joint feature selection Selected features grH ae pt he r co og ne sn tre uo cu tis o n emP ba eti de dn it n g NS Nin g pl re e- dla icy te or r preIn di it cia til o n Late fusion Down ins tt ere rpa rm et ata tis ok ns and
DNA methylation DNA methylation
Class probabilities Cancer diagnosis
stneitaP stneitaP
enG cA odT
er
stneitaP
Biomarker identification
mRNA expression mRNA expression
Class probabilities
stneitaP stneitaP
enG cA odT
er
stneitaP
VCDN
GO enrichment analysis
Term 1 -log(p-value)
Term 2
Term 3
Term 4
miRNA expression miRNA expression Class probabilities 0 10 2 H0 i t s ( % 3 )0 40 50
stneitaP stneitaP enG cA odT
er
stneitaP Biomarker interaction analysis
b c
Patient similarity network
Build patient similarity network Patient similarity network GAT encoder
Selected features
Feature similarity network Ã—ğ¿
stneitaP
corr corr
c ro er lr N Noo dde
e
c reo lr er ve ala nt cio en
Feature-patient network â€œpatientG -sA imT i lafo r-r patientâ€ Final embedding
ğœğœ ğ‘£ğ‘’ E Nd og de
e
d de es si ir ra ab bi il li it ty
y
ğ‘’
ğ‘£
â€œfeatureG -atA trT
ib
ufo ter
-patientâ€
Activation stneitaP
relğœğ‘£ â€œfeatureG -sA imT i lafo r-r featureâ€ Activation Size of embedding
Patient Feature
Ã—ğ¿
Similar Feature similarity network Ã—ğ¿
corrğœğ‘’
ğœre ğ‘£l ğœrree ğ‘£ll Similar
Build feature similarity network Attribute
Fig.1. HeteroGATomicsarchitecture. a,HeteroGATomicsintegratesjointfeatureselectionandheterogeneousgraph
learninginsixsteps. (1)HeteroGATomicsrepresentsthepreprocessedomicsasfeaturesimilaritynetworks,whereeach
networkrepresentsaspecificomicwithnodescorrespondingtofeaturesandedgesdenotingtheircorrelations. Allomic
modalitiesareinterconnectedattherawfeatureleveltocapturecross-modalityinteractions. (2)AnMASperformsjointfeature
selectiononthesenetworkstoselectinformativefeatures,consideringbothintra-andcross-modalityinteractions. (3)
HeteroGATomicsbuildsapatientsimilaritynetworkforeachomicandcombinesitwiththefeaturesimilaritynetworkto
constructaheterogeneousgraph. (4)GATencoderslearntherepresentationsofeachindividualheterogeneousgraph. (5)A
single-layerneuralnetworkpredictspatientlabelsfromthelearnedrepresentations. (6)Alatefusioncombinespredictedlabels
fromallmodalitiesandfeedsthemintoaVCDNnetworktoperformdownstreamtasks. b,Theheterogeneousgraph
constructioncombinesfeatureandpatientsimilaritynetworksthroughfeature-patientrelations. c,MultiplestackedGATlayers
(denotedbyL)encodestheheterogeneousgraphintohiddenrepresentationsforeachnodetype. EachlayerusesthreeGATsto
learnthethreerelationswithinthegraph,updatingnoderepresentationsbyaggregatingrelation-specificinformation.
BLCAisthemostcommontypeofbladdercancer,moreprevalentinmenthanwomen,andcanbegroupedintolow-grade
andhigh-gradecases24. LGGisatypeofprimarybraintumorthatincludesgradesIIandIIIforclassificationpurposes25. RCC
isthemostprevalenttypeofkidneycancerinadults,whichhaskidneychromophobe(KICH),kidneyclearcellcarcinoma
(KIRC),andkidneypapillarycellcarcinoma(KIRP)asthemostfrequenthistologicalsubtypes26.
Evaluationstrategiesandmetrics
We evaluate the classification performance on the three datasets using stratified 10-fold cross-validation. This approach
ensuresrobustperformanceevaluationbysplittingeachdatasetintotrainingandtestsetswhilemaintainingabalancedclass
representation. Ineachfold,ninesetsareusedfortraining,furthersplitintotrainingandvalidationsetsata9:1ratio,while
3/29Table1. Asummaryofmultiomicsdatacharacteristicsateachpreprocessingstage.
Numberof Numberoforiginalfeatures Number of features after Numberoffeaturesafter
Dataset Categories
patients missingvalueremoval variancefiltering
DNA mRNA miRNA DNA mRNA miRNA DNA mRNA miRNA
BLCA High-grade:397,Low-grade:21 418 485,577 20,530 2,210 382,545 20,530 249 7,999 2,373 249
LGG GradeII:254,GradeIII:268 522 485,577 20,530 2,157 370,278 20,530 287 8,277 1,166 287
RCC KICH:65,KIRC:201,KIRP:294 560 485,577 20,530 1,847 377,787 20,530 238 4,107 2,456 238
theremainingsetisusedfortesting. Thisprocessisrepeatedtentimes,ensuringeachsetisusedfortestingexactlyonce. We
reportthemeanandthestandarddeviationoftheevaluationmetricscalculatedonthetestsetsacrossexperiments. Forthe
hyperparameterconfigurationofHeteroGATomics,wereportthemeanoftheevaluationmetricscalculatedonthevalidation
sets. Toensureafaircomparisonacrossdifferentmethods,wemaintainidenticalsplitsforallevaluations. Detailsoftheoptimal
hyperparameterconfigurationareprovidedinSupplementarySectionS5.
Toevaluatemodelperformanceforbinaryclassificationtasks,weusesixmetrics,includingareaunderthereceiveroperating
characteristiccurve(AUROC),accuracy,negativepredictivevalues(NPVs),positivepredictivevalues(PPVs),sensitivity,
andspecificity. Formulti-classclassification,weusesixmetrics,includingaccuracy,macro-averagedF1score(MacroF1),
micro-averagedF1score(MicroF1),weighted-averagedF1score(WeightedF1),precision,andrecall.
Classificationperformancecomparison
We compare the classification performance of HeteroGATomics with that of eight multiomics integration methods. We
adoptearlyfusionusingfiveclassifiersâ€”ğ‘˜-nearestneighbors(KNN)27,multilayerperceptron(MLP)27,randomforest(RF)28,
Ridgeregression(Ridge)29,gradienttreeboosting(XGBoost)30â€”concatenating100featuresfromeachmodalityselectedby
mutualinformation(MI)27 (seeSupplementarySectionS2). Wealsoutilizejointfeatureselectiontechniquesbyminimal-
redundancyâ€“maximal-relevancemulti-view(mRMR-mv)18andthemulti-agentarchitectureformulti-omics(MAgentOmics)19,
eachselecting300featurescollectivelyfromallmodalitiesbasedontheirrespectivestrategies. Moreover,weselectmulti-omics
graphconvolutionalnetworks(MOGONET)4,asupervisedlatefusionmethod,incorporating100selectedfeaturespermodality
usingMIforafaircomparison. Table2presentsthedetailedclassificationcomparisonsfortheBLCA,LGG,andRCCdatasets.
From Table 2, we observe that HeteroGATomics outperforms baseline multiomics integration methods for the binary
classification task on BLCA and LGG in terms of AUROC, accuracy, NPV, PPV, sensitivity, and specificity, except for
specificity in BLCA, and NPV and sensitivity in LGG. HeteroGATomics still achieves the second-best in NPV for LGG.
Furthermore,Table2demonstratesHeteroGATomicsâ€™superiorityforthemulti-classclassificationtaskonRCC,excellinginall
theevaluatedmetrics.
TheoutstandingperformanceofHeteroGATomicsindicatesthatthecombinedpowerofitsmulti-agentfeatureselection
module(thatis,HeteroGATomics )andGATmodule(thatis,HeteroGATomics )trainedongeneratedheterogeneous
MAS GAT
graphssignificantlyenhancesthecapabilitiesofadeeplearningmodelformultiomicsintegration. Weshowacomprehensive
performancestudyofthestandalonefeatureselectionmoduleofHeteroGATomicsinSupplementarySectionS2.
Ablationstudies
WeconductablationstudiestoexaminetheimpactofindividualmoduleswithinHeteroGATomicsandassessitseffectiveness
inintegratingdifferentmodalities. First,wehighlightthecrucialroleofHeteroGATomics inaugmentingthepredictive
GAT
capabilitiesofHeteroGATomicsarchitectureforclassificationtasks,beyondwhatitsHeteroGATomics canachieve. Figure
MAS
2comparesthewholeHeteroGATomicspipelineagainstHeteroGATomics ontheBLCA,LGG,andRCCdatasets. Weshow
MAS
HeteroGATomics â€™sperformanceusingKNN,MLP,RF,Ridge,andXGBoostclassifiers. Figure2showstheadditionofthe
MAS
heterogeneousGATmodule(HeteroGATomics )significantlyboostsHeteroGATomicsâ€™sperformancewithanimprovement
GAT
of 16.7%, 5.7%, and 0.4% in AUROC on BLCA, LGG, and RCC, respectively. These results highlight the value of the
heterogeneousGATmoduleinHeteroGATomicstoenhanceitsmultiomicsintegrationcapabilities.
WenextdemonstratetheeffectivenessofheterogeneousgraphsandtheirimpactonGATperformance. Weconductseveral
modifications: removingthefeaturesimilaritynetworktosimulateahomogeneousgraphscenario(denotedasHomogeneous),
removingcorrelationandedgedesirabilityderivedfromtheMASmoduleasedgeattributes(denotedasHetero ),and
Feature
excludingrelevanceandnodedesirabilityderivedfromthesamemoduleasnodeattributes(denotedasHetero ). Werefer
Edge
tothefullHeteroGATomicsarchitecture,incorporatingbothnodeandedgeattributes,asHetero . Theresultsof
Feature+Edge
thiscomparativestudyonLGGinFig. 3showthatHeteroGATomics,whenleveragingheterogeneousgraphs,outperformsits
homogeneousgraphcounterpart,achievingimprovementsof2.3%,1.6%,2.3%,and2.4%inaccuracy,AUROC,sensitivity,and
specificity,respectively. Furthermore,theenhancementinHeteroGATomicsâ€™performancecomesnotonlyfromthefeature
similaritynetworkbutalsofromthecontributionsofeachindividualnetworkelement,includingfeatureandedgeattributes.
4/29Table2. ClassificationperformancecomparisonwithmeanÂ±standarddeviationover10-foldcross-validation.
Dataset Metric KNN27 MLP27 RF28 Ridge29 XGBoost30 mRMR-mv18 MAgentOmics19 MOGONET4 HeteroGATomics
BLCA AUROC 0.779Â±0.191 0.744Â±0.194 0.684Â±0.149 0.720Â±0.129 0.760Â±0.175 0.683Â±0.146 0.572Â±0.114 0.884Â±0.160 0.961Â±0.065
Accuracy 0.955Â±0.027 0.962Â±0.026 0.955Â±0.022 0.962Â±0.016 0.964Â±0.016 0.952Â±0.018 0.952Â±0.015 0.948Â±0.023 0.964Â±0.027
NPV 0.978Â±0.020 0.973Â±0.023 0.968Â±0.016 0.971Â±0.018 0.976Â±0.019 0.968Â±0.015 0.957Â±0.014 0.961Â±0.019 0.983Â±0.016
PPV 0.517Â±0.329 0.583Â±0.417 0.600Â±0.436 0.650Â±0.391 0.650Â±0.369 0.500Â±0.387 0.250Â±0.403 0.292Â±0.407 0.673Â±0.360
Sensitivity 0.583Â±0.382 0.500Â±0.387 0.383Â±0.299 0.450Â±0.269 0.533Â±0.356 0.383Â±0.299 0.150Â±0.229 0.250Â±0.335 0.667Â±0.316
Specificity 0.975Â±0.020 0.987Â±0.017 0.985Â±0.020 0.990Â±0.017 0.987Â±0.013 0.982Â±0.020 0.995Â±0.010 0.985Â±0.023 0.980Â±0.027
LGG AUROC 0.670Â±0.052 0.697Â±0.043 0.704Â±0.055 0.650Â±0.049 0.679Â±0.078 0.687Â±0.051 0.685Â±0.035 0.716Â±0.050 0.766Â±0.046
Accuracy 0.667Â±0.053 0.695Â±0.044 0.703Â±0.056 0.649Â±0.049 0.678Â±0.078 0.686Â±0.053 0.684Â±0.035 0.674Â±0.060 0.711Â±0.042
NPV 0.630Â±0.056 0.673Â±0.050 0.686Â±0.071 0.634Â±0.048 0.657Â±0.076 0.670Â±0.069 0.666Â±0.042 0.674Â±0.073 0.675Â±0.054
PPV 0.737Â±0.066 0.726Â±0.043 0.735Â±0.058 0.671Â±0.059 0.715Â±0.108 0.716Â±0.047 0.711Â±0.048 0.681Â±0.057 0.783Â±0.067
Sensitivity 0.552Â±0.116 0.653Â±0.084 0.664Â±0.118 0.631Â±0.073 0.638Â±0.107 0.645Â±0.126 0.653Â±0.078 0.689Â±0.102 0.619Â±0.120
Specificity 0.788Â±0.077 0.740Â±0.050 0.745Â±0.083 0.670Â±0.078 0.721Â±0.114 0.729Â±0.072 0.718Â±0.068 0.657Â±0.079 0.808Â±0.088
RCC Accuracy 0.946Â±0.028 0.954Â±0.024 0.950Â±0.026 0.954Â±0.024 0.955Â±0.022 0.954Â±0.021 0.950Â±0.024 0.952Â±0.025 0.961Â±0.019
MacroF1 0.944Â±0.025 0.953Â±0.024 0.950Â±0.020 0.949Â±0.025 0.955Â±0.019 0.953Â±0.018 0.948Â±0.021 0.953Â±0.022 0.957Â±0.026
MicroF1 0.946Â±0.028 0.954Â±0.024 0.950Â±0.026 0.954Â±0.024 0.955Â±0.022 0.954Â±0.021 0.950Â±0.024 0.952Â±0.025 0.961Â±0.019
WeightedF1 0.947Â±0.028 0.953Â±0.025 0.950Â±0.026 0.954Â±0.024 0.955Â±0.022 0.954Â±0.022 0.950Â±0.024 0.952Â±0.026 0.961Â±0.019
Precision 0.949Â±0.027 0.958Â±0.021 0.953Â±0.025 0.956Â±0.024 0.959Â±0.020 0.956Â±0.021 0.953Â±0.023 0.956Â±0.023 0.964Â±0.019
Recall 0.946Â±0.028 0.954Â±0.024 0.950Â±0.026 0.953Â±0.024 0.955Â±0.021 0.954Â±0.021 0.950Â±0.023 0.952Â±0.025 0.961Â±0.019
Thebestperformanceforeachmetricineachdatasetisdenotedinbold,withthesecond-bestresultsunderlined.
BLCA dataset LGG dataset RCC dataset
1 0.85 1
0.9 0.98
0.75
0.96
e0.8 e e
u u u
la la la0.94
v c0.7 v c0.65 v
c
irte irte irte0.92
M0.6 M M
0.9
0.55
0.5 0.88
0.4 0.45 0.86
AUROC Accuracy AUROC Accuracy Weighted F1 Accuracy
HGerateprhoGOAmTiocms_icFseat+_ KKNNNN HGerateprhoGOAmTiocms_icFseat+_ MMLLPP HGertaeprohGOAmTiocms_icFseat+_ RRFF HGertaeprohGOAmTiocms_icFseat+_ RRiiddggee HGerateprhoGOAmTiocms_icFseat+_ XXGGBBoooosstt HGertaeprohGOAmToicmsics
MAS MAS MAS MAS MAS
Fig.2. PerformancecomparisonofHeteroGATomicswithitsfeatureselectionmoduleacrossfiveclassifiers(meanand
standarddeviationover10-foldcross-validation). Theverticalbarsshowthemean,theblacklinesrepresenterrorbars
indicatingplus/minusonestandarddeviation,andeachdotisamodelâ€™sperformanceoneachfold. HeteroGATomics +
MAS
[classifier]denotestheresultsofthefeatureselectionmodulewithinHeteroGATomicsforaclassifier,whileHeteroGATomics
representstheresultsderivedfromtheentireHeteroGATomicsarchitecture.
ToevaluatetheimpactofdifferentomicmodalitiesonHeteroGATomicsâ€™performanceandtodeterminethebenefitof
integratingmultipleomics,wetrainHeteroGATomicsusingsevenmodalitycombinations: individualmodalitieswithoutthe
VCDNmodule(DNA,mRNA,andmiRNA),combinationsoftwomodalities(DNA+mRNA,DNA+miRNA,mRNA+miRNA),
and all three modalities together (DNA+mRNA+miRNA). The performance of these configurations is assessed on LGG
in AUROC, accuracy, sensitivity, and specificity. The results in Fig. 4 show that integrating additional omic modalities
withHeteroGATomicsenhancesitsperformanceacrossvariousevaluationmetrics,exceptforspecificity. Inthecontextof
single-modalitylearning,mRNAcontributessignificantlytotheperformance,particularlyinAUROCandaccuracy. Notably,
integratingallthreemodalitiesoutperformssingleordual-modalitycombinations,furtherhighlightingthebenefitsofmultiomics
integrationviaHeteroGATomics. WealsoreportanexecutiontimeanalysisfortrainingHeteroGATomicswithallmodality
combinationsinSupplementarySectionS6.
Analysisofidentifiedbiomarkersforcancerdiagnosis
Tounderstandthedecision-makingprocesswithinHeteroGATomics,weutilizeabiomarkerimportanceextractiontechnique
(seeSupplementarySectionS4.2)toidentifyandanalyzethekeybiomarkersthatsignificantlyinfluencetheclassification
results. Table3presentsthe30mostimportantbiomarkersidentifiedbyHeteroGATomicsonBLCAandLGG.RCCisexcluded
5/290.95
0.85
0.75
e
u
la
v c0.65
irte
M
0.55
0.45
0.35
AUROC Accuracy Sensitivity Specificity
Homogeneous HHeetteerroo_Edge HHeetteerroo_Feature HHeetteerroo_Feature+Edge
Edge Feature Feature+Edge
Fig.3. ComparisonofHeteroGATomicsperformancewithandwithoutheterogeneousgraphsontheLGGdataset
(meanandstandarddeviationover10-foldcross-validation). Theverticalbarsshowthemean,theblacklinesrepresent
errorbarsindicatingplus/minusonestandarddeviation,andeachdotisamodelâ€™sperformanceoneachfold. Homogeneous
referstoHeteroGATomicswithoutthefeaturesimilaritynetwork,Hetero removesedgeattributes(correlation,edge
Feature
desirability),Hetero excludesnodeattributes(relevance,nodedesirability),andHetero representsthefull
Edge Feature+Edge
HeteroGATomicssetup.
fromfurtherbiomarkeridentification,servingonlyasaproof-of-conceptformulti-classclassificationtasks4.
ToprankingbiomarkersforLGGconsistof16DNAmethylationfeatures,13mRNAs,and1miRNA.BLCAconsistsof
14mRNAfeatures,11DNAmethylationfeatures,and5miRNAs. Geneontology(GO)enrichmentanalysisonthetop30
DNAandmRNAbiomarkershighlightstermsrelatedtosynapticandsignaltransductionforLGG(GO:0097060,ğ‘=0.009and
GO:0007165,ğ‘=0.012,seeSupplementaryFig. S3a). BelongingtothosecategoriesisPTPRA,aproteintyrosinephosphatases
withknownrolesintumorigenesis31. CHRNDandKCNC2,ionchannelsgenes,alsobelongtobothcategories. Numerous
ionchannelsaredysregulatedingliomaandsignificantlyimpactprognosis32. Xuetal. havepreviouslyidentifiedKCNC2as
downregulatedinmalignantgliomas33,whileCHRNDhasbeenidentifiedasabiomarkerfortreatmentandprognosisofhead
andneckcellcarcinomas34.
GOtermsrelatedtothetopBLCAbiomarkersincludeseveraldevelopmentalprocesses(e.g. Regionalization,ğ‘=0.008,see
SupplementaryFig. S3b). ThisemphasisestopbiomarkersthatareTranscriptionFactors(TFs),essentialregulatorsofgene
expression: YBX2,HOXB2and3,FOXH1,FOXA3,DMRTA2,TEX15andMAGEA10. Thesehavediversefunctions: DNA
repair,celldifferentiationandmigration,cellcycleandorganogenesistociteafew,allrelevantinthecontextofcancer. Among
them,TFsoftheFoxsuperfamilyFOXH1andFOXA3areidentifiedasmRNAbiomarkers. FOXfamilyproteinshavebeen
showntobeinvolvedinbladderdevelopmentandcancerprogression,forinstanceFOXA1expressionhasbeencorrelatedto
poorsurvival35. ForDNAmethylationfeatures,HOXB2hasrecentlybeenshowntobeupregulatedinsomesubtypesofBLCA
andtoactasatumorpromoter36. AllofthefollowinggenesidentifiedbyHeteroGATomicshavebeenpreviouslyflaggedas
potentialbiomarkersforBLCA:YBX237,DMRTA238,TEX1539andMAGEA1040.
Notably, the top 5 biomarkers of BLCA are all miRNAs, small RNAs known for regulating gene expression post-
transcriptionally by binding target mRNAs and preventing their translation via degradation or translational silencing. As
suchtheyplayacentralroleincellmaintenanceandintumorigenesis. Numerousstudieshavepointedouttheimportanceof
miRNAsinbladdercancerandtheirpotentialuseincancerdiagnosisandprognosis41,42. All5miRNAshavebeenstudiedin
thecontextofothercancers,forexamplepancreasandliver43 orbreast44. Threeofourfive(hsa-mir-1-3p,hsa-mir-708-5p
andhsa-mir-16-2-3p),havebeenpreviouslylinkedtobladdercancer45â€“47. Zhangetal. demonstratedthathsa-mir-1-3pis
downregulatedinbladdercancertissuesandisabletoinhibitcancerproliferationandtumorigenesisinvivo48. HeteroGATomics
isabletonotonlyidentifyknownmiRNAsrelatedtobladdercancerbutalsoidentifynewpotentialmiRNAs,hsa-mir-1976and
hsa-mir-24-3p,involvedinoncogenesis.
Wefurtherinvestigatetheinteractionnetworkofthetopbiomarkers,includingprotein-bindingpartnersofproteincoding
biomarkersandtargetsofmiRNAsbiomarkers(Fig. 5andSupplementaryFigs. S4andS5). Interestingly,theBLCAmiRNA
6/291
0.9
0.8
e0.7
u
la
v
c
irte
M0.6
0.5
0.4
0.3
AUROC Accuracy Sensitivity Specificity
DNA mRNA miRNA DNA+mRNA DNA+miRNA mRNA+miRNA DNA+mRNA+miRNA
Fig.4. PerformancecomparisonofHeteroGATomicsacrossdifferentcombinationsofmodalitiesontheLGGdataset
(meanandstandarddeviationover10-foldcross-validation). Theverticalbarsshowthemean,theblacklinesrepresent
errorbarsindicatingplus/minusonestandarddeviation,andeachdotisamodelâ€™sperformanceoneachfold. DNA,mRNA,and
miRNArefertothesingle-modalityclassificationperformanceonDNAmethylation,geneexpressionRNAse,andmiRNA
maturestrandexpressionRNAseq,respectively. Two-modalitycombinationsrefertoDNA+mRNA,DNA+miRNA,and
mRNA+miRNA,whileDNA+mRNA+miRNAreferstotheclassificationperformanceacrossthreemodalities. Ineachcase,
300featuresareselectedanddividedequallyamongthemodalities.
biomarkerhsa-mir-708-5ptargetsfouroftheprotein-codingbiomarkers,whilehsa-mir-1-3ptargetsthree. Thisincludespartners
suchasHOXB2andYBX2,suggestingapossibleregulationbetweenthem(Fig. 5a). Examiningtheprotein-proteininteractions
oftheLGGbiomarkersshowsthatRAD9Ahasnumerousproteinpartnersandmanyareknowngenesrelatedtocancer(Fig.
5bandSupplementaryFig. S5). RAD9AitselfisinvolvedinDNArepair,interactswithseveralcomponentsoftheDNA
damageresponsepathwaysthatistargetedforglioblastomatreatment49. Forinstance,RAD9AinteractswithATRtomediate
DNArepairandseveralATRinhibitordrugshavebeendevelopedfortreatingGlioblastoma49,50. RAD9Aalsointeractswith
HDAC1,amediatorofchromatincompaction,knowntobefrequentlyoverexpressedinLGGandalsotargetedfortherapy51.
Interestingly,anotherbiomarker,MIDEAS,alsointeractswithHDAC1,aswellaswithHDAC2(Fig. 5b),formingpartofthe
mitoticdeacetylase(MiDAC)complex,whichisimportantforneuronaldevelopment52.
ThehomeoboxTFCUX1isanotherimportantcomponentofLGG.LikeMIDEAS,CUX1isalsoatargetofthemiRNA
biomarkerhsa-mir-363-3p(Fig. 5b). Moreover,CUX1hasbeenpreviouslyidentifiedaswidelyexpressedinglioma. CUX1
seemstopromotetumorigenesisviatheWnt/b-Cateninpathway53. Anotherbiomarker,RBMS3,isanRNAbindingprotein
thatregulatescrucialcellularprocessessuchastranscription,cellapoptosisorcellcycleprogression. Itsexpressioncorrelates
withgoodorpoorprognosisdependingoncancertype54. Ruanetal. recentlydiscoveredthatRBMS3downregulationleadsto
increasedproliferationofglioblastomacellsbyinteractingwithcircHECTD1. SubsequentlyincreasingVE-cadherinlevelsand
promotingvasculogenicmimicry,whichhasadeleteriouseffectonanti-vasculartherapy55. HeteroGATomicsalsohighlights
deletionofBRINP1,alsoknownasDBC1fordeletedinbladdercancer1. Silencingof,ordeletionson,chromosome9are
knowninthecontextofbladdercancerandincludesilencingofBRINP1. BRINP1hasbeenshowntosuppresscellcycle
progressionandtobeacandidatetumorsupressor56.
Discussion
Thedevelopmentofcancerinvolvesmultiplebiologicallayers. Theavailabilityofdiversebiologicaldata,multiomics,offers
detailed insights into various cancer mechanisms. However, integrating multiple heterogeneous omic datasets for cancer
diagnosisandbiomarkeridentificationremainsasignificantchallenge,especiallyinsmallpatientcohortswithhigh-dimensional
7/29Table3. Top30rankedbiomarkersidentifiedbyHeteroGATomicsintheBLCAandLGGdatasets.
BLCA LGG
Rank BiomarkerID Biomarkername Omic Rank BiomarkerID Biomarkername Omic
1 MIMAT0000416 hsa-mir-1-3p miRNA 1 cg15024277 BEX3 DNA
2 MIMAT0004926 hsa-mir-708-5p miRNA 2 cg20371266 CHRND DNA
3 MIMAT0004518 hsa-mir-16-2-3p miRNA 3 cg22373770 N/A DNA
4 MIMAT0009451 hsa-mir-1976 miRNA 4 cg05165025 MIDEAS,RP5-1021I20.1 DNA
5 MIMAT0000080 hsa-mir-24-3p miRNA 5 cg16503259 N/A DNA
6 DBC1 BRINP1 mRNA 6 cg20253855 CUX1 DNA
7 cg12676289 CTD-2201E9.2,SEMA5A DNA 7 cg17237063 RBMS3-AS3,RBMS3 DNA
8 cg22777724 HOXB2,HOXB-AS1 DNA 8 cg15275625 N/A DNA
9 cg26681383 CACNA2D3 DNA 9 RNF126P1 RNF126P1 mRNA
10 cg09313705 HOXB2,HOXB-AS1 DNA 10 TTTY14 TTTY14 mRNA
11 cg20152430 HOXB-AS3,HOXB3 DNA 11 C4orf45 SPMIP2 mRNA
12 LGALS2 LGALS2 mRNA 12 SGCZ SGCZ mRNA
13 MAGEA10 MAGEA10 mRNA 13 NAA11 NAA11 mRNA
14 MDH1B MDH1B mRNA 14 cg00661753 PTPRA DNA
15 FOXH1 FOXH1 mRNA 15 BET3L TRAPPC3L mRNA
16 YBX2 YBX2 mRNA 16 ZDHHC1 ZDHHC1 mRNA
17 PCDHAC2 PCDHAC2 mRNA 17 G6PC G6PC1 mRNA
18 LOC644172 LOC644172 mRNA 18 GPR52 GPR52 mRNA
19 CTTNBP2 CTTNBP2 mRNA 19 cg12472597 CTC-1337H24.4,CLCF1,RAD9A,AP003419.11 DNA
20 DMRTA2 DMRTA2 mRNA 20 cg11867599 ABHD18,MFSD8 DNA
21 TEX15 TEX15 mRNA 21 CCL3L1 CCL3L1 mRNA
22 SYBU SYBU mRNA 22 cg00020474 N/A DNA
23 BICC1 BICC1 mRNA 23 cg14302471 LINC00689 DNA
24 FOXA3 FOXA3 mRNA 24 ENC1 ENC1 mRNA
25 cg27452922 N/A DNA 25 PRR5-ARHGAP8 PRR5-ARHGAP8 mRNA
26 cg11241756 H2BP2 DNA 26 cg14985891 CASQ2 DNA
27 cg20197814 HECW2 DNA 27 cg07971493 MAP3K15 DNA
28 cg00334056 LEMD2 DNA 28 cg08316083 ATP8B3 DNA
29 cg22968622 DND1P1 DNA 29 MIMAT0000707 hsa-mir-363-3p miRNA
30 cg08836615 N/A DNA 30 KCNC2 KCNC2 mRNA
N/AindicatesthebiomarkernameforthecorrespondingIDisnotavailable.
a b
F pri og t. e5 in. -K prn oo tw
e i
n
n
ip na ter rt an ce tr is ono sf as
r
e el e rc et ce od vt eo rep db fi oo rm Da Nrk Aer as n. da m,R Re Nsu Alts omfo ir ct sh .e FB orL tC hA emda iRt a
N
s e At. ob m, R
i c
e
s
s ,u kl nts of wo nrt mhe RL NG AG tad ra gt ea ts se at. reDire c t
r
g
G
e
r
ec
e
no
e
ev
n
e L(r me
i s
d
R
t ,
f
N
aro
nA
m
d
)
t
a
s
h
n
t
e
a dr NB
o er
a
a
ts wne
g
o57
e
r.
k(
T
m
C
h
i
a
Re
nN
cd ei Aff
r
)e
G
.
r Ke
e
n nnt
oo
mo wm eni ac
c ra
ec na cct ie
e
rg
r
c-o
lr
er
e
di le
a
is
t
nef dr ro
eg
dm
e 5n
8w
e â€“s
6h 0fi .c roh mth te heb i
C
o m
a
na
c
r
e
k re Grs
e
o
n
r
e
i g Cin ea nt
s
e
u
sa r
d
e ai tn ad bi ac sa et ,e Od na cs ob Klu
B
e
â„¢
( D
C
N
a
A
n
c) ,
e r
f de aa
t
t
a
u fr oe rs
c
p
a
a nc ce es r. dO iu
a g
r
n
H
o
e
s
t
i
e sr .o TG oA cT oo nm
st
ri c
u
s
c
tis tha eG seA hT e- tb ea rose gd enm eoe uth so gd rae pn hh sa ,n wce ed ew mi pth
l o
h
y
e ate
n
r o
o
vg ee ln deo
u
u
a l
s -vg ir ea wph rs epto rei sn ete ng tar ta it oe nm
l e
u
v
l et i ro
a
m
g
ii nc gs
featureandpatientsimilarity n e t works. HeteroGATomicsutilizesajointfeatureselectionapproachusingamulti-agentsys t e m ,
effectivelyaddressingthehighdimen s i onalityofthefeaturespace.
Experimental results demonstrate that the standalone joint feature selection module of HeteroGATomics consistently
8/29outperformsbaselinefeatureselectionmethodsandachievescompetitiveperformanceintheremainingcases(Supplementary
SectionS2). Thissuggeststhatemployinganeffectivejointfeatureselectionstrategyacrossmultiplemodalitiescanoutperform
independentfeatureselectionforeachmodality. AnotherkeyinnovationofHeteroGATomicsistheconstructionofheterogeneous
graphsthroughourproposeddual-viewrepresentation. Leveragingtheseheterogeneousgraphshassignificantlyenhanced
theperformanceofHeteroGATomicsoverthefeatureselectionmoduleacrossalldatasetsintheexperiments,particularlyin
termsofAUROC.Furthermore,experimentsshowthat,onaverage,HeteroGATomicsoutperformsbothconventionaland
state-of-the-artmultiomicsintegrationmethodsincancerclassificationtasksacrosssixevaluationmetrics.
Ablation studies demonstrate that each component of the heterogeneous graphs positively impacts HeteroGATomicsâ€™
performancecomparedtohomogeneousgraphs. Thishighlightstheimportanceofleveragingauxiliaryinformationinherentin
multiomicsdatasetsforcancerclassificationandHeteroGATomicsâ€™superioritywhenutilizingthisinformationcomparedto
othermethods. Additionally,ablationstudiesrevealtheadvantageoftrainingHeteroGATomicswithmultipleomicsoverfewer
omics,reflectingthecomplementaryinformationeachomicprovidestothemodel. HeteroGATomicsisflexible,enablingthe
integrationofadditionalomicsthatcontributetounderstandingcancerprogression.
Interpretability is another crucial aspect of this study, essential for building trust in HeteroGATomics. We enhance
interpretabilitythroughabiomarkeridentificationprocessthatexplainswhichgenesandfeatureshavethemostsignificant
impactontheclassificationofBLCAandLGGcancers. HeteroGATomicssuccessfullypredictsknownbiomarkersineach
cohort, including known genes involved in tumorigenesis, diagnosis and/or treatment. We show via interaction networks
thatseveralbiomarkersareassociatedandhighlightimportantfunctionsthatareorcouldbetargetedfortherapy(e.g. DNA
damagerepairpathwyasinLGG).HeteroGATomicsalsoidentifiesgenesthatwerenotpreviouslystudiedinLGGorBLCA,
withseveralknownoncogenesinothercancers. ExamplesofnoveltherapytargetcandidatesforLGGincludeionchannels
genesCHRNDandKCNC2. ForBLCA,thetopfivemiRNAsbiomarkerscanprogressmiRNApoolsusedfordiagnosisand
prognosis. Wehighlighttwonetworkclustersofeitherinterconnectedmarkers,ormarkersthatsharecommoninteractors.
Thesemaywellbehighlightingkeyregulatoryprocesses,whereasingleprocesscanbedisruptedinmultiplewaytoachieve
oncogenisity. HeteroGATomicsalsouncoversnonproteincodinggenesofinterestlikepseudogenesincludinglongnoncoding
RNAs(lncRNAs,e.g. RNF126P1andTTTY14inLGG).Theirrelevanceincancerhasbeenmorerecentlyinvestigated. For
instancedysregulationoflncRNAshasbeenshowntoimpactgliomadevelopment61.
FutureworkcanleveragetheflexiblearchitectureofHeteroGATomicstoincorporateadditionalmodalitiesbeyondbiological
omics,suchasmedicalimagingandelectronichealthrecords. Thesecanserveasattributesinpatientsimilaritynetworks,
allowingthemodeltolearntheinterconnectedstructureofmultiplemodalitiesandpotentiallyfurtherboostitsperformance.
Moreover, the dual-view representation concept in HeteroGATomics is broadly applicable, extending beyond the specific
problemanddatasetsusedinthisstudy. Thisapproachcanbeadaptedtotabular-structureddatasetsandappliedacrossvarious
fieldsbeyondcancergenomics,whereverexplicit/implicitmeaningfulrelationshipsamongfeaturesexist. HeteroGATomics,
similartomanystudies,requirespatientstohaveallomicsavailableandcannothandlepatientswithoneormoreomicsmissing.
EnablingHeteroGATomicstolearnfrommissingomicswillimproveitsperformanceinmultiomicsdatasets.
Methods
Notations
TheimportantnotationsusedinthispaperareprovidedinSupplementaryTableS1.
Datacollectionandpreprocessing
WeincorporateDNAmethylationmeasuredfromtheIlluminaInfiniumHumanMethylation450BeadChipplatformintoour
analysis,with90%oftheprobesfromtheHumanMethylation27datapresent. ForgeneexpressionRNAseq,weselectthe
IlluminaHiSeqpancannormalizedversion. Inthismodality,valuesweretransformedusingğ¿ğ‘œğ‘”2mean-normalizedpergene
acrossallTCGApatients. Then,onlytheconverteddataspecifictothecohortofinterestwasextracted. Moreover,weinclude
miRNAobtainedfromtheIlluminaHiseqsystem,wherevalueswereğ¿ğ‘œğ‘”2-transformed. MoredetailscanbefoundattheUCSC
Xenaplatform23.
Aftercollectingthedatasets,weperformfourpreprocessingstepstocleanandpreparethedataformachinelearningmodels.
First,onlypatientswithinformationinallomicmodalitiesareretained. Second,featureswithmissingvaluesineachomicare
removed. Third,allfeaturesineachomicarenormalizedtotherange[0,1]usingmin-maxscaling62. Fourth,featureswith
littlediscriminatorypowerareeliminatedbyfilteringoutthosewithvariancebelowaspecificthreshold. Thethresholdissetat
0.04forDNAandmRNA,whilemiRNAisexemptfromfilteringduetoitslimitednumberoffeatures. Alldatasetsinthe
experimentsusethisvariancethreshold. Table1showsthenumberoffeaturesforeachdatasetandomicmodalityafterthe
completionofeachphase.
9/29Jointfeatureselection
Thehighdimensionalityofmultiomicsdatasetsresultsinmanyirrelevantandredundantfeatures,challengingGNNstolearn
meaningfulrepresentationsandperformclassificationtasks. Thus,afeatureselectionmethodisneededtoidentifyrepresentative
features. Weproposeajointfeatureselectionstrategytomitigatethecurseofdimensionalitybymodelingintra-andcross-omic
interactions,insteadofapplyingseparatefeatureselectiontoeachomicmodality.
HeteroGATomicsemploystheantcolonyoptimizationalgorithm(ACO),arobustmulti-agentframework,forconducting
jointfeatureselection. TherationaleforselectingACOoverotherMASisdrivenbyseveralfactors: (1)leveragingglobal
communicationthroughadistributedlong-termmemorysystemtofacilitateinformationexchangeamongagentsandenhance
thedecision-makingprocess, (2)theinherentlyparallelnatureofitsimplementation, leadingtoasubstantialreductionin
computationaltime,and(3)itsbalancedglobalandlocalsearchcapabilities,supportingefficientexplorationandtheadoption
ofgreedyexploitationapproaches63,64.
Multiomicsdatarepresentation. Theinputomicscanberepresentedasinterconnectedgraphs,witheachgraphcorresponding
toadistinctomic,asillustratedinSupplementaryFig. S6.
Consideralabelledomicîˆ°ğ‘š =<ğ—ğ‘š,ğ˜>,whereğ—ğ‘š âˆˆâ„ğ‘Ã—ğ‘‘
ğ‘š
representsamatrixofğ‘ patientswithğ‘‘
ğ‘š
features,and
ğ˜âˆˆâ„ğ‘Ã—ğ¶denotespatientlabelsforğ¶classes,representedusingone-hotencoding. Formally,eachomiccanbeformulatedasan
undirectedweightedgraphîˆ³ğ‘š =(î‰‚ğ‘š,îˆ±ğ‘š,ğ‘ ),whereî‰‚ğ‘šisasetofğ‘‘ nodesindicatingfeaturesinomicğ‘š,andîˆ±ğ‘š âˆˆî‰‚ğ‘šÃ—î‰‚ğ‘š
ğ‘š ğ‘š
isasetofedgesconnectingthesefeatures. Additionally,îˆ³includesğ‘ ,denotingtherelativeimportanceofomicğ‘š. Graph
ğ‘š
weightsarecalculatedbytheabsolutevalueofthePearsoncorrelationcoefficient27betweenpairsofnodes. Duetothehigh
dimensionality and numerous correlated features within omics, utilizing a sparse graph in the feature selection algorithm
acceleratestraining,reducesmemoryusage,andenhancescomputationalefficiency. Therefore,weretainapercentageofedges
withweightsbelowthethresholdğœƒ . Furthermore,therelevanceofeachfeatureisassessedusingANOVAandassignedtothe
ğ‘“
correspondinggraphnode.
TheACOalgorithmreliesondesirability,characterizedbypheromonelevels,thatreflectstheattractivenessofsolutionsand
guidesthealgorithmtowardsnear-optimalsolutions. Weusetwokeydesirabilityvalues: (1)thenodedesirabilityvalueğœğ‘š,
ğ‘£
indicatingthesignificanceoffeatureğ‘£relativetootherfeaturesinomicğ‘š;and(2)theedgedesirabilityvalueğœğ‘š,showingthe
ğ‘’
importanceoftheedgeğ‘’betweentwofeatureswithinomicğ‘š. Thesevaluesareinitializedtosmallconstantvaluesğ‘ andğ‘ ,
î‰‚ îˆ±
andareassignedtoeachnodeandedge,respectively.
ACOforjointfeatureselection. Followingdatarepresentation,weuseACOforjointfeatureselection(seeSupplementary
Algorithm 1), involving an iterative improvement process with several key steps in each iteration. First, ğ‘ agents are
ğ´
randomlydistributedacrossdifferentgraphnodeswithineachomic. Then,eachagentindependentlyconstructsitssolutionby
traversinginterconnectedgraphsusingiterativeâ€œstatetransitionrulesâ€. Theserulesguideagentstoselectunchosenfeatures
probabilisticallyorgreedily,biasedbydesirabilitystrengthsandtherelevanceandcorrelationvaluesoftargetnodesandedges.
Followingtheconstructionstep,solutionsareevaluatedusingaproposedâ€œfitnessfunctionâ€. Thehighest-qualitysolutioninthe
currentiterationisretainedasthebest-foundsolution.
Onceallsolutionsareevaluated,wemodifydesirabilityvaluesonnodesandedgesusingtheâ€œdesirabilityupdatingrulesâ€.
Thisinvolvesreducingthestrengthsofdesirabilityvaluesbyaconstantparameteranddepositingadditionalvalueonpromising
nodesandedges, basedontheirattractivenessduringsolutionconstruction. Furthermore, therelativeimportanceofeach
omic,denotedasğ‘ ,isupdatedusinganâ€œomicimportanceupdatingruleâ€,whichallocateshigherprobabilitytoomicswhose
ğ‘š
featurescontributedmoretotheagentsâ€™solutions. Thesestepsrepeatforapredefinednumberofiterations. Finally,toconstruct
reduced-dimensionalitymultiomics,weretainthetopğµfeaturesselectedbyaweightedcombinationofnodedesirabilityand
relevancevalue.
Statetransitionrules. Eachagentconstructsasolutionbynavigatinginterconnectedgraphsandselectingfeaturesusingeither
aprobabilisticorgreedyrule. Inthegreedyrule,thetransitionfromfeatureğ‘–tofeatureğ‘—withinomicğ‘šforagentğ‘isdefinedas:
[ ]
ğ‘“ğ‘š =argmax ğœ‚ ( ğ‘“ğ‘š) +ğœğ‘š+ğœğ‘šâˆ’ ğœ‚ ( ğ‘“ğ‘š) ifğ‘ â‰¤ğ‘ , (1)
ğ‘— 1 ğ‘— ğ‘— ğ‘–ğ‘— 2 ğ‘— 0
ğ‘—âˆˆîˆ¶ğ‘š(ğ‘)
ğ‘–
whereîˆ¶ğ‘š(ğ‘)representsthesetoffeasiblefeaturesyettobeselectedbyagentğ‘inomicğ‘š,ğœğ‘šisthedesirabilityvalueofnode
ğ‘– ğ‘—
ğ‘— inomicğ‘š,ğœğ‘š isthedesirabilityvalueontheedgebetweennodesğ‘–andğ‘— inomicğ‘š,ğ‘isarandomnumberintheinterval
ğ‘–ğ‘—
[0,1],andğ‘ âˆˆ[0,1]isaconstantparameter. Inequation(1),ğœ‚ (.)assessesfeaturerelevance,whileğœ‚ (.)measurestheaverage
0 1 2
correlationbetweenanewfeatureandthosepreviouslyselectedbyagentğ‘. Alowerğœ‚ (.)valueincreasesthelikelihoodof
2
selectingapromisingfeature.
10/29In the probabilistic rule, used when ğ‘ > ğ‘ , an agent is allowed to probabilistically explore other omics to select any
0
featurebasedonitsprobabilityvalue. Giventhatanagentğ‘iscurrentlyplacedinomicğ‘š,thenextomicğ‘šâ€²,whichcanbe
equaltothecurrentomic,israndomlyselectedfromthesetofomicsîˆ¹19. Thisselectionisbasedonthesetofprobabilities
îˆ¼ = {ğ‘ ,ğ‘ ,â‹¯,ğ‘ }, indicating the relative importance of each omic. Once the next omic is chosen, the probability of
1 2 ğ‘€
transitioningtofeatureğ‘— fromomicğ‘šâ€²isgivenby:
ğœ‚ ( ğ‘“ğ‘šâ€²) +ğœğ‘šâ€² âˆ’ ğœ‚ ( ğ‘“ğ‘šâ€²)
Pr( ğ‘“ ğ‘—ğ‘šâ€² |ğ‘“ ğ‘–ğ‘š) =
âˆ‘
ğ‘£âˆˆîˆ¶ğ‘šâ€²1 (ğ‘)[ğ‘—
ğœ‚
1(
ğ‘“
ğ‘£ğ‘šâ€²ğ‘—
)
+ğœ
ğ‘£ğ‘šâ€²2 âˆ’ğ‘—
ğœ‚
2(
ğ‘“
ğ‘£ğ‘šâ€²)]. (2)
ğ‘–
Inequation(2),theexclusionofedgedesirabilityvaluessimplifiesthemodelandreducescomputationtime.
Fitnessfunction. Thefitnessfunctionevaluatesthequalityofsolutions,reflectingtheirproximitytodesiredobjectives. To
evaluatethequalityofsolutionîˆ¿(ğ‘)constructedbyagentğ‘,weproposethefollowingquantitativemeasure:
1
fitness(îˆ¿(ğ‘))= [ğ‘„(îˆ¿(ğ‘))+ğ‘…(îˆ¿(ğ‘))], (3)
3
where
( ) ( )
ğ‘…(îˆ¿(ğ‘))=mean âˆ‘ rel( ğ‘“ ) âˆ’ mean âˆ‘ |corr( ğ‘“ ,ğ‘“ )| , (4)
ğ‘£ | ğ‘£ ğ‘¢ |
| |
ğ‘£ğœ–îˆ¿ î‰‚(ğ‘) (ğ‘£,ğ‘¢)âˆˆîˆ¿ îˆ±(ğ‘)
ğ‘„(îˆ¿(ğ‘)) quantifies the classifierâ€™s performance on the subset of selected features îˆ¿(ğ‘), îˆ¿ î‰‚(ğ‘) is the subset of all features
selectedbyagentğ‘initssolutionîˆ¿(ğ‘),andîˆ¿ îˆ±(ğ‘)isthesubsetofedgeswithintheagentâ€™ssolution. InEquation(3),ğ‘…(.)isa
regularizationtermthatpenalizessolutionswithirrelevantandredundantfeatures,encouragingagentstofindmoreinformative
andrelevantsubsets.
Desirabilityupdatingrules. Theserulesaimtoenhancethedesirabilityvaluesassociatedwithnodesandedgesidentifiedin
high-qualitysolutions. Theupdateprocessfornodeandedgedesirabilityvaluesoccursafterallagentshaveconstructedtheir
solutionsandarecalculatedbythefollowingequations:
ğœ ğ‘–ğ‘š =( 1âˆ’ğœŒ î‰‚) ğœ ğ‘–ğ‘š+ğœŒ
î‰‚[co cou un ntî‰‚ tî‰‚({ (ğ‘“
îˆ¿ğ‘–
î‰‚ğ‘š )})
+[ Î”ğœ
ğ‘–ğ‘š]best]
, (5)
ğœ ğ‘–ğ‘š
ğ‘—
=( 1âˆ’ğœŒ îˆ±) ğœ ğ‘–ğ‘š
ğ‘—
+ğœŒ îˆ±[ coun ct oîˆ± u( n{( tğ‘“ îˆ±(ğ‘–ğ‘š îˆ¿, îˆ±ğ‘“ )ğ‘—ğ‘š)}) +[ Î”ğœ ğ‘–ğ‘š ğ‘—]best] , (6)
whereparametersğœŒ î‰‚,ğœŒ
îˆ±
âˆˆ(0,1]arethedecaycoefficientsfornodeandedgedesirabilityvalues,respectively,thefunctions
countî‰‚(.) and countîˆ±(.) determine the number of times a subset of features and edges has been selected, respectively, îˆ¿
î‰‚
denotesallselectedfeaturesinthecurrentiteration,andîˆ¿ representsallselectededgesinthecurrentiteration. Inequations(5)
îˆ±
and(6),[ Î”ğœğ‘š]best and[ Î”ğœğ‘š]best addthefitnessvalueofthebest-foundsolutioninthecurrentiterationiftherespectivefeature
ğ‘– ğ‘–ğ‘—
oredgeisselectedinthatsolution;otherwise,theyarezero. Thedesirabilityupdatingrulesoperatesimilarlytoareinforcement
learningscheme,wherebettersolutionsreceivehigherreinforcement63.
Omicimportanceupdatingrule. Thisruleenhancesthesignificanceofomicscontaininginformativefeaturesforagentsin
subsequentiterationsandisadaptedfromref.19.
GATarchitectureforheterogeneousgraphs
Afterfeatureselectionreducesfeaturedimensionality,weconstructaheterogeneousgraphforeachomic. Thisgraphisauto-
maticallygenerated,incorporatingextensivestructuralinformationinherentintabularomicsfordownstreamtasks. Following
this,aGATencodeseachheterogeneousgraph,effectivelyrepresentingnodeinformation. Thepowerfulattentionmechanism
intheGATarchitectureprioritizesimportantnodesandedges,whichisbeneficialforomicsdatawherespecificgenesinfluence
11/29biologicalprocessesordiseasemechanisms. ThisfocusonkeyelementsinGATenhancesperformancecomparedtoother
GNNarchitectures13,15,65. Afterencodingeachheterogeneousgraph,asingle-layerneuralnetworkperformslabelprediction.
Wecombinepredictionsfrommultipleomicsintoatensorrepresentingcross-omicslabelcorrelations,whichisthenprocessed
throughaVCDNforfinalprediction. SupplementaryAlgorithm2presentsthepseudo-codefortheproposedarchitecture.
Heterogeneousgraphconstruction. Foreachomic,weconstructaheterogeneousgraphbycombiningafeaturesimilarity
networkwithapatientsimilaritynetwork(seeFig. 1b). Thefeaturesimilaritynetwork,derivingfromthefeatureselection
phase,consistsofnodesrepresentingselectedfeaturesandedgesdenotingthecorrelationsbetweenthem. Nodeattributesare
definedbytheirrelevance,desirability,andcorrespondingvaluesfromtheinputomics,whileedgeweightsareassignedbased
onthedesirabilityandcorrelationbetweennodes. Complementingthis,weconstructthepatientsimilaritynetworkwherenodes
representindividualpatients,andedgesdenotecorrelationsbetweenthem. Thesecorrelations,quantifiedusingtheabsolute
Pearsoncorrelationcoefficient,serveasedgeweights. Onlyedgeswithweightsaboveaspecifiedthreshold,ğœƒ ,aremaintained,
ğ‘ 
whichfiltersforthemostsignificantpatientcorrelationsandresultsinamoremanageableandrelevantgraphstructure.
Thesetwonetworks,indicatingtwodistinctnodetypes(patientsandfeatures),areinterconnectedtoformacomprehensive
heterogeneousgraphencompassingthreespecificrelations: â€œpatient-similar-patientâ€,â€œfeature-similar-featureâ€,andâ€œfeature-
attribute-patientâ€. Eachrelationintheheterogeneousgraphoffersuniqueinsights: â€œpatient-similar-patientâ€revealsshared
diseasecharacteristicsamongpatients;â€œfeature-similar-featureâ€highlightsthecorrelateddynamicsoffeaturesinbiological
processes;andâ€œfeature-attribute-patientâ€provideskeyunderstandingofhowindividualfeaturesimpactpatientoutcomes. This
approachofrelation-awarerepresentationinthegraphallowsforcapturingmoredetailedinformation,reflectingthediverse
characteristicsofthetargetnodesinomicsdatasets.
Formally,aheterogeneousgraphisdefinedasîˆ³ğ‘š =(î‰‚ğ‘š,îˆ±ğ‘š,îˆ»,îˆ¾). Here,î‰‚ğ‘šrepresentsthesetofnodes,eachmappedto
ğ»
anodetypeviathefunctionğœ™(ğœˆ)â†’îˆ»forğœˆ âˆˆî‰‚ğ‘š. Thesetofedgesîˆ±ğ‘šisdenotedwithacorrespondingedgetypemapping
ğ‘– ğ‘–
functionğœ“(ğœˆ, ğ‘¢ )â†’îˆ¾foreachedge(ğœˆ,ğ‘¢ )âˆˆîˆ±ğ‘šandrelationğ‘Ÿâˆˆîˆ¾65. îˆ»denotesthesetofnodetypes,andîˆ¾denotesthe
ğ‘– ğ‘— ğ‘– ğ‘—
setofedgetypesorrelations.
Representationlearningandlabelprediction. HeteroGATomicsemploysmultipleGATlayerstoencodeomic-specific
heterogeneousgraphs,whereeachGATwithinalayeristailoredtoaspecificrelationtype(asillustratedinFig. 1c). Foragiven
heterogeneousgraphîˆ³ğ‘š,thegoalofrepresentationlearningistodevelopfunctionsğ‘“ âˆ¶î‰‚ğ‘š âŸ¶â„ğ‘‘ â„,ğ‘“ âˆ¶î‰‚ğ‘š âŸ¶â„ğ‘‘ â„,and
ğ» 1 1 2 1
ğ‘“
3
âˆ¶î‰‚ 2ğ‘š âŸ¶â„ğ‘‘ â„ whichmapthenodescorrespondingtoeachofthethreerelationsintoağ‘‘ â„-dimensionalembeddingspace.
Nodetypesaresplitintotwodisjointsets,î‰‚ğ‘š = î‰‚ğ‘šâˆªî‰‚ğ‘š,whereî‰‚ğ‘šâˆ©î‰‚ğ‘š = âˆ…. Whenanodeisthedestinationofseveral
1 2 1 2
relations,theircorrespondingrepresentationsareaggregated. TheHeteroGATomicsencoderstacksmultiplelayersofthree
individualGATs,eachencodingsourcenodesforaspecificrelationğ‘Ÿ,asfollows:
ğ‡(ğ‘™+1) =ğ€(ğ‘™)ğ‡(ğ‘™)ğ–(ğ‘™)âŠ¤ , (7)
ğ‘Ÿ ğ‘Ÿ ğ‘Ÿ ğ‘Ÿ
whereğ‡( ğ‘Ÿğ‘™) âˆˆâ„ğ‘ ğ‘ŸÃ—ğ‘‘ ğ‘Ÿ(ğ‘™) isthesourcenoderepresentationmatrixintheğ‘™thlayerforrelationğ‘Ÿ,ğ‘ ğ‘Ÿdenotesthenumberofsource
nodesinrelationğ‘Ÿ,ğ‘‘(ğ‘™)isthehiddendimensionalsizeofeachsourcenodeinğ‘™thlayer,andğ€(ğ‘™)istheattentionscorematrix
ğ‘Ÿ ğ‘Ÿ
forrelationğ‘Ÿ. Inequation(7),ğ–( ğ‘Ÿğ‘™) âˆˆâ„ğ‘‘ ğ‘Ÿ(ğ‘™+1)Ã—ğ‘‘ ğ‘Ÿ(ğ‘™) isthelearnableweightmatrix,whereğ‘‘ ğ‘Ÿ(ğ‘™+1)representsthehiddendimension
inlayerğ‘™+1,and(.)âŠ¤ indicatestransposition. Noderepresentationsinitiallyoriginatefromtheinputnodeattributematrix
ğ‡( ğ‘Ÿ0) =ğ— ğ‘Ÿ,whereğ—
ğ‘Ÿ
âˆˆâ„ğ‘ ğ‘ŸÃ—ğ‘‘ ğ‘Ÿ(0),andğ‘‘ ğ‘Ÿ(0)isthedimensionalityofeachinputsourcenode. TheGATcalculatesthenormalized
attentionscoresğ›¼(ğ‘™) oftheattentionscorematrixğ€(ğ‘™)betweeneachpairofnodesğ‘¢andğ‘£inrelationğ‘Ÿasfollows:
ğ‘Ÿğ‘¢ğ‘£ ğ‘Ÿ
( ( ))
exp ğœ ğš(ğ‘™)âŠ¤ ğ–(ğ‘™)ğ¡(ğ‘™)+ğš(ğ‘™)âŠ¤ ğ–(ğ‘™)ğ¡(ğ‘™)+ğš(ğ‘™)âŠ¤ ğ–(ğ‘™)ğ
ğ‘Ÿğ‘  ğ‘Ÿğ‘  ğ‘Ÿğ‘¢ ğ‘Ÿğ‘‘ ğ‘Ÿğ‘‘ ğ‘Ÿğ‘£ ğ‘Ÿğ‘’ ğ‘Ÿğ‘’ ğ‘Ÿğ‘¢ğ‘£
ğ›¼(ğ‘™) = , (8)
ğ‘Ÿğ‘¢ğ‘£ âˆ‘ exp( ğœ( ğš(ğ‘™)âŠ¤ ğ–(ğ‘™)ğ¡(ğ‘™)+ğš(ğ‘™)âŠ¤ ğ–(ğ‘™)ğ¡(ğ‘™)+ğš(ğ‘™)âŠ¤ ğ–(ğ‘™)ğ ))
ğ‘˜âˆˆîˆº(ğ‘¢) ğ‘Ÿğ‘  ğ‘Ÿğ‘  ğ‘Ÿğ‘¢ ğ‘Ÿğ‘‘ ğ‘Ÿğ‘‘ ğ‘Ÿğ‘˜ ğ‘Ÿğ‘’ ğ‘Ÿğ‘’ ğ‘Ÿğ‘¢ğ‘˜
whereğ¡( ğ‘Ÿğ‘™ ğ‘¢) âˆˆâ„ğ‘‘ ğ‘Ÿ(ğ‘™) andğ¡( ğ‘Ÿğ‘™ ğ‘£) âˆˆâ„ğ‘‘ ğ‘Ÿ(ğ‘™) denotetherepresentationsofnodesğ‘¢andğ‘£inlayerğ‘™,respectively,ğ ğ‘Ÿğ‘¢ğ‘£indicatestheedge
attributesbetweennodesğ‘¢andğ‘£inrelationğ‘Ÿ,ğš(ğ‘™),ğš(ğ‘™),andğš(ğ‘™)arethetrainableattentionvectorstoweighsource,destination,
ğ‘Ÿğ‘  ğ‘Ÿğ‘‘ ğ‘Ÿğ‘’
andedgeattributes,correspondingly,andîˆº(ğ‘¢)indicatesthedirectneighborsetofnodeğ‘¢inthegraph. Inequation(8),ğœ(.)
representsLeakyReLUnon-linearityfunction,andexp(.)denotesthestandardexponentialfunction.
Tostabilizetheattentionmechanismlearningprocess,multi-headattention15 iswidelyutilized. Thisschemeinvolves
combiningtheoutputsofğ¾ distinctattentionmechanismstoformthefinalnoderepresentations,asfollows:
12/29ğ¾
ğ‡(ğ‘™+1) = 1 âˆ‘ ğ€(ğ‘™)ğ‡(ğ‘™)ğ–(ğ‘™)âŠ¤ . (9)
ğ‘Ÿ ğ¾ ğ‘Ÿğ‘˜ ğ‘Ÿ ğ‘Ÿğ‘˜
ğ‘˜=1
Onceeachheterogeneousgraphismappedintonodeembeddingsthroughattentionlayers,asingle-layerneuralnetworkuses
themforomic-specificlabelprediction. Weoptimizetrainableparametersviabackpropagationtominimizethecross-entropy
lossfunctionacrossalltrainingpatients,asdefined:
âˆ‘
îˆ¸ = CE (ğ²,ğ²Ì‚ğ‘š), (10)
ğ‘š ğ‘š ğ‘– ğ‘–
(ğ± ğ‘–ğ‘š,ğ²ğ‘–)âˆˆîˆ°ğ‘š
ğ‘¡ğ‘Ÿ
where
CE
(ğ²,ğ²Ì‚ğ‘š)=âˆ’âˆ‘ğ¶
y log
exp( yÌ‚ ğ‘–ğ‘š ğ‘)
, (11)
ğ‘š ğ‘– ğ‘–
ğ‘=1
ğ‘–ğ‘ âˆ‘ğ¶ exp( yÌ‚ğ‘š)
ğ‘—=1 ğ‘–ğ‘—
îˆ°ğ‘š representsallthetrainingpatientsinomicğ‘š,ğ±ğ‘šistheğ‘–thtrainingpatientwithitscorrespondinglabelğ²,ğ²Ì‚ğ‘šindicatesthe
ğ‘¡ğ‘Ÿ ğ‘– ğ‘– ğ‘–
classprobabilitiespredictedbytheGATmodel,andfunctionCE (.)denotesthecross-entropyloss. Inequation(11),ğ¶ isthe
ğ‘š
numberofclasses,andyÌ‚ğ‘š representstheğ‘thelementinthepredictedprobabilityvector.
ğ‘–ğ‘
WeutilizeVCDN,whichintegratesdifferentomic-specificlabelpredictions,toperformfinalprediction. Thisnetwork
excelsatlearningbothintra-andcross-omiccorrelationswithinthelabelspace,therebyenhancingperformanceacrossseveral
tasks4,66. Foreachpatient,wecreateacross-omicdiscoverytensorbyintegratingpredictedclassprobabilitiesfromvarious
omics. Thistensoristhenreshapedintoavectorofdimensionğ¶ğ‘€. VCDN,afullyconnectednetwork,usesthisvectorasinput
tomakethefinalprediction. Thecross-entropylossfunctionisemployedfortrainingVCDN4.
Data availability
Thethreedatasetsusedinthisstudy,BLCA,LGG,andRCC,areallpubliclyaccessiblethroughtheUCSCXenaplatform
(https://xenabrowser.net/datapages/). Tofacilitatereproducibility,theprocesseddatasetsareavailableintheGitHubrepository
(https://github.com/SinaTabakhi/HeteroGATomics/tree/main/raw_data).
Code availability
ThesourcecodeandimplementationdetailsofHeteroGATomicsarepubliclyavailableintheGitHubrepository(https://github.
com/SinaTabakhi/HeteroGATomics)andarearchivedintheZenodorepository67 (https://doi.org/10.5281/zenodo.13119631)
undertheMITLicense. AninteractiveGoogleColabdemonstrationisavailableat: https://colab.research.google.com/github/
SinaTabakhi/HeteroGATomics/blob/main/HeteroGATomics_demo.ipynb.
Acknowledgements
S.T.issupportedbytheUniversityofSheffieldFacultyofEngineeringResearchScholarship(grantnumber199256787). I.S.
andC.V.aresupportedbytheMedicalResearchCouncil(MRC)grantMR/V010948/1.
Author contributions
S.T.andH.L.conceivedanddesignedthestudy. S.T.developedthemodelsandperformedtheexperimentsunderthesupervision
ofH.L.S.T.implementedthebiomarkeridentificationalgorithm. C.V.designedthebiologicalinterpretationoftheresultsunder
theguidanceofI.S.S.T.andC.V.wrotethemanuscript. H.L.performedcriticalrevisionsofthearticle. Allauthorsreviewed
andeditedthemanuscript.
Competing interests
Theauthorsdeclarenocompetinginterests.
13/29References
1. Steyaert,S.etal. Multimodaldatafusionforcancerbiomarkerdiscoverywithdeeplearning. Nat.Mach.Intell.5,351â€“362
(2023).
2. Acosta,J.N.,Falcone,G.J.,Rajpurkar,P.&Topol,E.J. MultimodalbiomedicalAI. Nat.Med.28,1773â€“1784(2022).
3. Karczewski,K.J.&Snyder,M.P. Integrativeomicsforhealthanddisease. Nat.Rev.Genet.19,299â€“310(2018).
4. Wang,T.etal. MOGONETintegratesmulti-omicsdatausinggraphconvolutionalnetworksallowingpatientclassification
andbiomarkeridentification. Nat.Commun.12,3445(2021).
5. Cantini, L. et al. Benchmarking joint multi-omics dimensionality reduction approaches for the study of cancer. Nat.
Commun.12,124(2021).
6. Schulte-Sasse,R.,Budach,S.,Hnisz,D.&Marsico,A. Integrationofmultiomicsdatawithgraphconvolutionalnetworks
toidentifynewcancergenesandtheirassociatedmolecularmechanisms. Nat.Mach.Intell.3,513â€“526(2021).
7. Li,M.M.,Huang,K.&Zitnik,M. Graphrepresentationlearninginbiomedicineandhealthcare. Nat.Biomed.Eng.6,
1353â€“1369(2022).
8. Picard,M.,Scott-Boyer,M.-P.,Bodein,A.,PÃ©rin,O.&Droit,A. Integrationstrategiesofmulti-omicsdataformachine
learninganalysis. Comput.Struct.Biotechnol.J.19,3735â€“3746(2021).
9. Peng, C., Zheng, Y. & Huang, D.-S. Capsule network based modeling of multi-omics data for discovery of breast
cancer-relatedgenes. IEEE/ACMTrans.Comput.Biol.Bioinform.17,1605â€“1612(2019).
10. Rappoport, N. & Shamir, R. NEMO: cancer subtyping by integration of partial multi-omic data. Bioinformatics 35,
3348â€“3356(2019).
11. Sun,D.,Wang,M.&Li,A. Amultimodaldeepneuralnetworkforhumanbreastcancerprognosispredictionbyintegrating
multi-dimensionaldata. IEEE/ACMTrans.Comput.Biol.Bioinform.16,841â€“850(2018).
12. Hamilton, W. L., Ying, R. & Leskovec, J. Representation learning on graphs: methods and applications. Preprint at
https://arxiv.org/abs/1709.05584(2018).
13. Forster,D.T.etal. BIONIC:biologicalnetworkintegrationusingconvolutions. Nat.Methods19,1250â€“1261(2022).
14. Ektefaie,Y.,Dasoulas,G.,Noori,A.,Farhat,M.&Zitnik,M. Multimodallearningwithgraphs. Nat.Mach.Intell.5,
340â€“350(2023).
15. VeliÄkoviÄ‡,P.etal. Graphattentionnetworks. InInternationalConferenceonLearningRepresentations(ICLR,2018).
16. Zitnik,M.etal. Currentandfuturedirectionsinnetworkbiology. Preprintathttps://arxiv.org/abs/2309.08478(2023).
17. Tabakhi,S.,Suvon,M.N.I.,Ahadian,P.&Lu,H. Multimodallearningformulti-omics: asurvey. WorldSci.Annu.Rev.
Artif.Intell.1,2250004(2023).
18. El-Manzalawy,Y.,Hsieh,T.-Y.,Shivakumar,M.,Kim,D.&Honavar,V. Min-redundancyandmax-relevancemulti-view
featureselectionforpredictingovariancancersurvivalusingmulti-omicsdata. BMCMed.Genom.11,19â€“31(2018).
19. Tabakhi,S.&Lu,H. Multi-agentfeatureselectionforintegrativemulti-omicsanalysis. InAnnualInternationalConference
oftheIEEEEngineeringinMedicineandBiologySociety,1638â€“1642(IEEE,2022).
20. Ruiz,C.,Ren,H.,Huang,K.&Leskovec,J. Highdimensional,tabulardeeplearningwithanauxiliaryknowledgegraph.
InAdvancesinNeuralInformationProcessingSystems(NeurIPS,2023).
21. Xu,H.etal. GripNet: graphinformationpropagationonsupergraphforheterogeneousgraphs. PatternRecognit.133,
108973(2023).
22. Chandak,P.,Huang,K.&Zitnik,M. Buildingaknowledgegraphtoenableprecisionmedicine. Sci.Data10,67(2023).
23. Goldman, M.J.etal. VisualizingandinterpretingcancergenomicsdataviatheXenaplatform. Nat.Biotechnol.38,
675â€“678(2020).
24. TheCancerGenomeAtlasResearchNetwork. Comprehensivemolecularcharacterizationofurothelialbladdercarcinoma.
Nature507,315(2014).
25. TheCancerGenomeAtlasResearchNetwork. Comprehensive,integrativegenomicanalysisofdiffuselower-gradegliomas.
N.Engl.J.Med.372,2481â€“2498(2015).
26. Chen,F.etal. Multilevelgenomics-basedtaxonomyofrenalcellcarcinoma. CellRep.14,2476â€“2489(2016).
27. Theodoridis,S.&Koutroumbas,K. PatternRecognition(ElsevierScience,2008).
14/2928. Ho,T.K. Randomdecisionforests. InProceedingsoftheInternationalConferenceonDocumentAnalysisandRecognition,
vol.1,278â€“282(IEEE,1995).
29. Hoerl,A.E.&Kennard,R.W. Ridgeregression: biasedestimationfornonorthogonalproblems. Technometrics12,55â€“67
(1970).
30. Chen,T.&Guestrin,C. XGBoost: ascalabletreeboostingsystem. InProceedingsoftheACMSIGKDDInternational
ConferenceonKnowledgeDiscoveryandDataMining,785â€“794(ACM,2016).
31. Lv,Z.,Wang,T.,Cao,X.,Sun,M.&Qu,Y. Theroleofreceptor-typeproteintyrosinephosphatasesincancer. Precis.Med.
Sci.12,57â€“66(2023).
32. Griffin,M.,Khan,R.,Basu,S.&Smith,S. Ionchannelsastherapeutictargetsinhighgradegliomas. Cancers12,3068
(2020).
33. Xu,Y.etal. Screeningcriticalgenesassociatedwithmalignantgliomausingbioinformaticsanalysis. Mol.Med.Rep.16,
6580â€“6589(2017).
34. Li,J.etal. Identificationofthenerve-cancercross-talk-relatedprognosticgenemodelinheadandnecksquamouscell
carcinoma. Front.Oncol.11,788671(2021).
35. Yamashita,H.etal. OnaFOXhunt: functionsofFOXtranscriptionalregulatorsinbladdercancer. Nat.Rev.Urol.14,
98â€“106(2017).
36. Liu,J.etal. HOXB2isaputativetumourpromotorinhumanbladdercancer. Anticancer.Res.39,6915â€“6921(2019).
37. Yuan,Z.etal. Comprehensivepan-canceranalysisofYBXfamilyrevealsYBX2asapotentialbiomarkerinlivercancer.
Front.Immunol.15,1382520(2024).
38. Deng,L.etal. AnovelandsensitiveDNAmethylationmarkerfortheurine-basedliquidbiopsiestodetectbladdercancer.
BMCCancer22,510(2022).
39. Mantere,T.etal. Case-controlanalysisoftruncatingmutationsinDNAdamageresponsegenesconnectsTEX15and
FANCD2withhereditarybreastcancersusceptibility. Sci.Rep.7,681(2017).
40. Verma,S.etal. MelanomaantigenfamilyA(MAGEA)aspromisingbiomarkersandtherapeutictargetsinbladdercancer.
Cancers16,246(2024).
41. Das,S.,Hayden,J.,Sullivan,T.&Rieger-Christ,K. TherolesofmiRNAsinpredictingbladdercancerrecurrenceand
resistancetotreatment. Int.J.Mol.Sci.24,964(2023).
42. Sequeira,J.P.etal. OncoUroMiR:circulatingmiRNAsfordetectionanddiscriminationofthemainurologicalcancers
usingaddPCR-basedapproach. Int.J.Mol.Sci.24,13890(2023).
43. Lee,T.-Y.etal. Anti-microRNA-1976asanovelapproachtoenhancechemosensitivityinXAF1+pancreaticandliver
cancer. Biomedicines11,1136(2023).
44. Khodadadi-Jamayran,A.etal. Prognosticroleofelevatedmir-24-3pinbreastcanceranditsassociationwiththemetastatic
process. Oncotarget9,12868(2018).
45. Tan,Z.etal. DysregulationandprometastaticfunctionofglycosyltransferaseC1GALT1modulatedbycHP1BP3/miR-1-3p
axisinbladdercancer. J.Exp.&Clin.CancerRes.41,228(2022).
46. Song,T.etal. miR-708promotesthedevelopmentofbladdercarcinomaviadirectrepressionofCaspase-2. J.CancerRes.
Clin.Oncol.139,1189â€“1198(2013).
47. Ware,A.P.,Kabekkodu,S.P.,Chawla,A.,Paul,B.&Satyamoorthy,K. Diagnosticandprognosticpotentialclustered
mirnasinbladdercancer. 3Biotech12,173(2022).
48. Zhang,J.etal. miR-1-3pcontributestocellproliferationandinvasionbytargetingglutaminaseinbladdercancercells.
Cell.Physiol.Biochem.51,513â€“527(2018).
49. Ferri,A.,Stagni,V.&BarilÃ ,D. TargetingtheDNAdamageresponsetoovercomecancerdrugresistanceinglioblastoma.
Int.J.Mol.Sci.21,4910(2020).
50. Biswas,H.,Makinwa,Y.&Zou,Y.Novelcellularfunctionsofatrfortherapeutictargeting: embryogenesistotumorigenesis.
Int.J.Mol.Sci.24,11684(2023).
51. Cascio,C.L.etal. Nonredundant,isoform-specificrolesofHDAC1ingliomastemcells. JCIInsight6(2021).
52. Mondal,B.etal. ThehistonedeacetylasecomplexMiDACregulatesaneurodevelopmentalgeneexpressionprogramto
controlneuriteoutgrowth. Elife9,e57519(2020).
15/2953. Feng,F.etal. CUX1facilitatesthedevelopmentofoncogenicpropertiesviaactivatingWnt/ğ›½-cateninsignalingpathwayin
glioma. Front.Mol.Biosci.8,705008(2021).
54. GÃ³rnicki,T.etal. RoleofRBMS3novelpotentialregulatoroftheEMTphenomenoninphysiologicalandpathological
processes. Int.J.Mol.Sci.23,10875(2022).
55. Ruan,X.etal. RBMS3-inducedcircHECTD1encodedanovelproteintosuppressthevasculogenicmimicryformationin
glioblastomamultiforme. CellDeath&Dis.14,745(2023).
56. Nishiyama,H.,Gill,J.H.,Pitt,E.,Kennedy,W.&Knowles,M.A.NegativeregulationofG(1)/Stransitionbythecandidate
bladdertumoursuppressorgeneDBCCR1. Oncogene20,2956â€“2964(2001).
57. Li, J.-H., Liu, S., Zhou, H., Qu, L.-H.&Yang, J.-H. starBasev2.0: decodingmiRNA-ceRNA,miRNA-ncRNAand
proteinâ€“RNAinteractionnetworksfromlarge-scaleCLIP-Seqdata. NucleicAcidsRes.42,D92â€“D97(2014).
58. Sondka,Z.etal. COSMIC:acurateddatabaseofsomaticvariantsandclinicaldataforcancer. NucleicAcidsRes.52,
D1210â€“D1217(2024).
59. Chakravarty,D.etal. OncoKB:aprecisiononcologyknowledgebase. JCOPrecis.Oncol.2017,PO.17.00011(2017).
60. Repana,D.etal. TheNetworkofCancerGenes(NCG):acomprehensivecatalogueofknownandcandidatecancergenes
fromcancersequencingscreens. GenomeBiol.20,1â€“12(2019).
61. Wu, X. et al. The involvement of long non-coding RNAs in glioma: from early detection to immunotherapy. Front.
Immunol.13,897754(2022).
62. You,J.,Ma,X.,Ding,Y.,Kochenderfer,M.J.&Leskovec,J. Handlingmissingdatawithgraphrepresentationlearning. In
AdvancesinNeuralInformationProcessingSystems(NeurIPS,2020).
63. Dorigo,M.&Gambardella,L.M. Antcolonysystem: acooperativelearningapproachtothetravelingsalesmanproblem.
IEEETrans.Evol.Comput.1,53â€“66(1997).
64. Dorigo,M.&Blum,C. Antcolonyoptimizationtheory: asurvey. Theor.Comput.Sci.344,243â€“278(2005).
65. Hamilton,W.L. GraphRepresentationLearning(Morgan&ClaypoolPublishers,2020).
66. Wang,L.,Ding,Z.,Tao,Z.,Liu,Y.&Fu,Y. Generativemulti-viewhumanactionrecognition. InProceedingsofthe
IEEE/CVFInternationalConferenceonComputerVision,6212â€“6221(IEEE,2019).
67. Tabakhi,S.,Vandermeulen,C.,Sudbery,I.&Lu,H. HeteroGATomicsv1.0.0. Zenodohttps://doi.org/10.5281/zenodo.
13119631(2024).
16/29Supplementary Information
S1 Notations
TableS1. Notationsanddescriptions.
Notation Description
ğš(ğ‘™),ğš(ğ‘™),ğš(ğ‘™) Attentionvectorstoweighsource,destination,andedgeattributesforrelationğ‘Ÿinğ‘™thlayer
ğ‘Ÿğ‘  ğ‘Ÿğ‘‘ ğ‘Ÿğ‘’
ğ€(ğ‘™) Attentionscorematrixforrelationğ‘Ÿinğ‘™thlayer
ğ‘Ÿ
ğ‘ ,ğ‘ Initialconstantvaluesfornodeandedgedesirabilities
î‰‚ îˆ±
îˆ°ğ‘š=<ğ—ğ‘š,ğ˜> Labelledomicdatasetwithpatientsğ—ğ‘šâˆˆâ„ğ‘Ã—ğ‘‘ğ‘š andlabelsğ˜âˆˆâ„ğ‘Ã—ğ¶
ğ Edgeattributesbetweennodesğ‘¢andğ‘£inrelationğ‘Ÿ
ğ‘Ÿğ‘¢ğ‘£
ğœ‚ , ğœ‚ Heuristicinformationforfeaturerelevanceandaveragefeaturecorrelation
1 2
îˆ³ğ‘š=(î‰‚ğ‘š,îˆ±ğ‘š,ğ‘ ) Undirectedweightedgraphwithnodesî‰‚ğ‘š,edgesîˆ±ğ‘š,andomicimportanceğ‘
ğ‘š ğ‘š
îˆ³ğ‘š =(î‰‚ğ‘š,îˆ±ğ‘š,îˆ»,îˆ¾) Heterogeneousgraphwithnodesî‰‚ğ‘š,edgesîˆ±ğ‘š,andcorrespondingtypesîˆ»,îˆ¾
ğ»
ğ‡(ğ‘™) Sourcenoderepresentationsforrelationğ‘Ÿinğ‘™thlayer
ğ‘Ÿ
îˆ¶ğ‘š(ğ‘) Feasiblefeaturestobeselectedbyagentğ‘inomicğ‘š
ğ‘–
îˆ¹ Setofomics
îˆº(ğ‘£) Neighborsofnodeğ‘£
îˆ¼ ={ğ‘ ,ğ‘ ,â‹¯,ğ‘ } Setofomicimportancevalues
1 2 ğ‘€
ğ‘,ğ‘ âˆˆ[0,1] Randomnumberandcontrolparameterintheprobabilistic/greedyrules
0
ğœŒ ,ğœŒ ,ğœŒ âˆˆ(0,1] Node,edge,andomicimportancedecaycoefficients
î‰‚ îˆ± îˆ¹
îˆ¿ ,îˆ¿ Selectedfeaturesandedgesinthecurrentiteration
î‰‚ îˆ±
îˆ¿(ğ‘) Solutionconstructedbyagentğ‘
îˆ¿ (ğ‘),îˆ¿ (ğ‘) Selectedfeaturesandedgesbyagentğ‘withinitssolutionîˆ¿(ğ‘)
î‰‚ îˆ±
ğœğ‘š,ğœğ‘š=ğœğ‘š Desirabilityvaluesfornodeğ‘£andedgeğ‘’=(ğ‘£,ğ‘¢)inomicğ‘š
ğ‘£ ğ‘’ ğ‘£ğ‘¢
ğœƒ ,ğœƒ Thresholdstodiscardedgesinfeatureandpatientsimilaritynetworks
ğ‘“ ğ‘ 
ğ–(ğ‘™) Weightmatrixforrelationğ‘Ÿinğ‘™thlayer
ğ‘Ÿ
ğ— ğ‘Ÿâˆˆâ„ğ‘ğ‘ŸÃ—ğ‘‘ğ‘Ÿ(0) Inputnodeattributesforrelationğ‘Ÿ
ğ²Ì‚ğ‘š ClassprobabilitiespredictedbytheGATmodelinomicğ‘š
ğ‘–
Vectorsaredenotedbylowercaseboldfaceletters,matricesbyuppercaseboldface,andsetsbycalligraphicletters.
17/29S2 Featureselectionperformancecomparison
WecomparethefeatureselectionmoduleofHeteroGATomics(HeteroGATomics )withfivebaselinefeatureselection
MAS
methods: mutualinformation(MI)1,recursivefeatureelimination(RFE)2,minimal-redundancyâ€“maximal-relevance(mRMR)3,
minimal-redundancyâ€“maximal-relevancemulti-view(mRMR-mv)4,andmulti-agentarchitectureformulti-omics(MAgen-
tOmics)5. Notably, mRMR-mv and MAgentOmics are specifically designed for joint feature selection within multiomics
datasets. ToevaluatetheperformanceofMI,RFE,andmRMR,weconcatenatetheselectedfeaturesfromeachmodalityto
serveastheinputforaclassifier.
FigureS1presentstheclassificationresultsofdifferentfeatureselectionmethodsonLGGusingarandomforest(RF)6
classifier,withlogarithmicallyspacedselectedfeaturesizes. HeteroGATomics hasconsistentlyoutperformedothermethods
MAS
intermsofAUROCandaccuracy. MI,aunivariatemethod,achievesthesecond-highestperformance,evenagainstmultivariate
methods. This suggests that LGG may contain individual features with significant independent predictive power, and the
complexinteractionsidentifiedbymultivariatemethodsmaynotsignificantlyenhanceperformance. Thisfindinghighlightsthe
effectivenessofHeteroGATomics inidentifyingdiscriminativefeaturesdespiteitsmultivariatenature. Interestingly,both
MAS
AUROCandaccuracymetricsyieldremarkablysimilartrendsacrossallmethods,indicatingawell-balancedtrade-offbetween
trueandfalsepositiverates.
FigureS2furthervalidatesthegeneralizabilityofHeteroGATomics bycomparingitsperformanceacrossthreedatasets.
MAS
The figure compares results for 100 selected features from each modality, evaluated with two classifiers, RF and Ridge
regression (Ridge)7. On BLCA, HeteroGATomics outperforms all baselines across both evaluation criteria with both
MAS
classifiers,surpassingthebest-reportedbaselineby2.8%withRFand4.2%withRidgeinAUROC(Fig. S2a). ForLGG,
HeteroGATomics continuestoexcelinidentifyinghigh-qualityfeatures,leadingtosuperiorevaluationmetricswithRF
MAS
(Fig. S2b). While MI slightly outperforms HeteroGATomics by less than 0.5% in AUROC and accuracy with Ridge,
MAS
HeteroGATomics remains the top performer in both metrics when using RF, even surpassing Ridgeâ€™s results. RCC,
MAS
knownforitsrelativelystraightforwardnatureintheclassificationtask8,seesallmethodsachievinghighperformanceinboth
metricswithbothclassifiers(Fig. S2c). HeteroGATomics remainscompetitiveonRCCwhenusingRF,withmRMR
MAS
onlyoutperformingitunderRidge. Additionally,weobservethattheefficacyofagivenfeatureselectiontechniqueishighly
dependentonthedataset. mRMR,forexample,isthesuperiormethodforRCC,yetitsignificantlyunderperformscomparedto
baselinesforBLCAwhenRidgeisused.
These analyses highlight HeteroGATomics â€™s ability to effectively identify discriminative features across different
MAS
datasetsandclassifiers.
0.72 0.72
0.7 0.7
C y c
O a
R0.68 ru0.68
U c
A c A
0.66 MI RFE 0.66 MI RFE
mRMR mRMR-mv mRMR mRMR-mv
MAgentOmics HHeetteerrooGGAATToommiiccssM_AMSAS MAgentOmics HHeetteerrooGGAATToommiiccssM_AMSAS
0.64 0.64
1520 35 55 100 1520 35 55 100
#features #features
Fig.S1. PerformancecomparisonoffeatureselectionmethodsforrandomforestclassificationontheLGGdataset. The
averagedvaluesfrom10-foldcross-validationarereportedforeachmetric. Thex-axisrepresentslogarithmicallyspaced
selectedfeaturesizesforeachmodality,whilethey-axisdisplaysAUROC(left)andaccuracy(right). HeteroGATomics
MAS
denotesthefeatureselectionmodulewithinHeteroGATomics.
18/29a
1 1
0.9
0.98
0.8
C y c0.96
O a
R0.7 ru
U c
A c A0.94
0.6
0.92
0.5
0.4 0.9
RF Ridge RF Ridge
MI RFE mRMR mRMR-mv MAgentOmics HGerateprhoOGmATicosm_Ficesat
MAS
b
0.85 0.85
0.8 0.8
0.75 0.75
C 0.7 y c 0.7
O a
R ru
U c
A0.65 c A0.65
0.6 0.6
0.55 0.55
0.5 0.5
RF Ridge RF Ridge
MI RFE mRMR mRMR-mv MAgentOmics HGerateprhoOGmATicosm_Ficesat
MAS
c
1 1
0.98 0.98
0.96 0.96
10.94 0.94
F
d e th
g
ie0.92
y
c a ru
c c
A0.92
W 0.9 0.9
0.88 0.88
0.86 0.86
0.84 0.84
RF Ridge RF Ridge
MI RFE mRMR mRMR-mv MAgentOmics HGerateprhoOGmATicosm_Ficesat
MAS
Fig.S2. PerformancecomparisonoffeatureselectionmethodsforrandomforestandRidgeclassification(meanand
standarddeviationover10-foldcross-validation). a,ResultsfortheBLCAdataset. b,ResultsfortheLGGdataset. c,Results
fortheRCCdataset. Theresultsarepresentedbasedon100selectedfeaturesforeachmodality. Theverticalbarsshowthe
mean,theblacklinesrepresenterrorbarsindicatingplus/minusonestandarddeviation,andeachdotisamodelâ€™sperformance
oneachfold. HeteroGATomics denotesthefeatureselectionmodulewithinHeteroGATomics.
MAS
19/29S3 Additionalanalysisofidentifiedbiomarkers
a
b
Fig.S3. GOenrichmentanalysisofthetop30biomarkersfromtheDNAandmRNAomicsmodalities. a,Resultsforthe
LGGdataset. b,ResultsfortheBLCAdataset. They-axisshowsthetop10mostsignificantGOcategoryterms,whilethe
x-axisrepresentsthepercentageofbiomarkersbelongingtoeachGOcategory.
20/29TEX11
MIXL1
SMAD2 HOXA1
DRAP1 TEX15
PA2G4 CTNNB1 DARS2 GRB2 CPSF6 HDAC2 UBL4B
NUP107
SOX2 NANOG SMAD3 TCF3 FOXA1 SLC6A17
LEFTY2 FOXH1 EOMES TLE1 FOXA3 MAP2K3
NKX2-5 FOXD2 PRF1
TBXT NODAL GATA4
TBPL2 POU5F1 RPA2 SMPDL3A
PIK3R1 RCC1 HNF1A
CRX ALX4
TTR BRINP1
FOXG1 SMAD4
CIAO1
CACNB2 CACNB1 SIRT1
FAM3B MOB4 CCT3 CACNG2
CAMK2A CACNA1S
STK25 STK24 CACNG1
PDCD10 CTTNBP2NLSTRN3 STRN4 STK26 CTTN CACNG6CACNA1D CACNB3 CHD7 GAL
STRIP2 SLMAP CACNA1E CACNA2D3 CACNA1G CACNB4
PPP2R1A CTTNBP2 STRN LGALS2
STRIP1
CCT8 CACNA1ACACNA2D2
CACNA2D1
CAMK2B
APPL1 PPP2CB CCT5 PPP2R1B CACNA1C CACNA1H PAICS LTA
CWC15 TCP1 CACNA1F CACNA1B
HCLS1
CCT6A PPP2CA
CCT2
CTAG1B MAGEA10
STXBP5 STX1A ARRDC1 LHX8 RPS2
BICD1 BSN AMOTL1 SOHLH1
ANKS3
CLASP1
HECW2 YBX2
SYBU HMOX1 FIGLA
BICC1
KIF5B SMPD2
hsa-mir-24-3p
NOBOX
PCDHAC2 PPHLN1
hsa-mir-1-3p
TAS2R1
DMRTA2
CDH9 hsa-mir-708-5p
FH
PLXNA3 SEMA5A
SEMA5B
PKNOX2
PLXNB3 CHMP7 ANKLE2
PLXNA1 MDH1B
CDH10 PLXNB1 HOXB2 PKNOX1 LMNA IST1 GOT2
CS
EGR2 BANF2 LEMD2 SYNE4
HOXB1
PBX1 MEIS1 EMD LMNB1
BANF1 ASPH
DNA mRNA
HOXB3
miRNA Cancer
EZH2
Fig.S4. Interactionnetworkoftop30biomarkerswithknownpartnersfortheBLCAdataset. Onlyknowndirect
interactionsfromprotein-proteininteractiondatabasesarerecoveredforDNAandmRNAomics. FormiRNAomics,known
mRNAtargetsarerecoveredfromstarBase9. Thedifferentomicscategoriesfromwhichthebiomarkersoriginateareindicated
asblue(DNA),green(mRNA)andorange(miRNA).Knowncancer-relatedgenesareencircledinred.
21/29CHEK2 HUS1B TP53BP1
RPA2 H2AC18 CRB2 RAD51 TIPIN FEN1
RAD9B BRIP1 TOPBP1 RPA3 DNA2 SIRT6 TLK1H3-4 BRCA1 TRERF1 DNTTIP1 STAT3 RB1 SPP2 BANP
CLSPNMRE11 RHNO1 SF3B3 H3C13 ATM BCL2 XRCC5 MIDEAS GOLGA5 SOX2
BLM RFC4 H3C12 RAD9A MUTYH RAD51CRBBP8 HDAC1 hsa-mir-363-3p CUX1 EOMES
ERCC4CDC4 A5 TRRFC2 RAD1N 7BN
H2AX
HUS1 CHER KF 1C3
WRN
ATAD5
HDAC2
SATB2 TBR BC1
L11B
BCL2L1 MDC1 SMC6 H3-3B RAD52 H3-7 CCNA1 CCNA2EWSR1
RPA1 MSH2 H3-5 ATRIP AR H2AC20 LIG1
SMC5 BRCA2 EXO1
RAD1 RFC5
TKTL1 G6PD
SLC37A4 SLC2A4
HLA-DQA1 DNAJC5 KCTD7 ROR2EGFR PCDHG 7RB2 PTS MARM KA 2PK1 FYN GLB1 PP PG AM R2 GC1ATKTS TKLC TL2 2A2 HPY KG DCB 1 PC FOXO P1 PARGPCK1 ALDOA
CC LT NS 5F
CLN6
PM PTF 1SD8
CLN8
CTC SL DN3 TM PTE PM R5 S1 PTPS RR DC
KCC NY BB
2561P ST LP CR 6A
M A1A 5RK3 PT MK B2
PPT PP TR PE
RG
P PC PH AKK HR21
KA
2PY GA G
6
HG L
P
6L
C P3
DFOG TX AA O INLL 3
D
SM
O1 LA CD
TG PG6P KC P1 FKMGPID FE
G
OR F
C
XOA
K
OX 4O SR6
EA
BKP HFRY
1
K1G 3BM
1 G6A
PG
L
CL
D
2Y OC CTK
SCD FBP1 GCG ALDOB
SGCA AKR1B10
SGCD CHRNA3 CHRNA9
SGCB COLQ ALPI COL4A3
DAG1 CHRNE
SGCZ SGCE CHRNG CHRNA4
CHRNA6 CUL3 KBTBD8
SSPN RAPSN DOK7 CHRND KLHL21 KLHL13 KLHL12
DMD DSG1 CHRNB3 CHRNB1 CHRNB2CHRNA1 CHRNB4 KLHL42 GANKCTD10 KLHL2 KLHL8 GLMN KLHS LP 9OP
CHRNA7 CHRNA2 LZTR1 KLHL3 KLHL40 KEAP1
YWHAE HRAS NGFR MUSK SPOPL PDCD6
KBTBD7
ENC1 K KB LHTB L4D 16 KCTD17
TCEAL6 BEX3 NGF
TRAPPC8TRAPPC2B
TRAPPC10
ZSWIM8KCTD13
KLHL24
NFE2L2 KLH HE LX 25B KLHL22KLHL20
TRAPPC14TRAPPC12 RAB1B SQSTM1 TNFAIP1
HSP90AA1
TRAPPC1 PEF1 KLHL7
TCEAL1 TCEAL7 TRAPPC6A RBX1
CASP2 TRAPPC3L TRAPPC11
TRAPPC6B
TRAPPC3 TRAPPC9TRAPPC2L
RAB1A
TRAPPC5
KCNAB3 TRAPPC4 TRAPPC2 XCR1 CCR9 CXCL10
CXCR4
SCN1B FAU CXCR6 CCR7 CCR3 CCR1
KCNC2 NAA50 NAA60 NAA30 CXCL8 CCR10 CXCL2 CCL3
KCNAB2 KCNC1 NAA25 HYPK TNF CXCR3 CCL3L1 CCL20 CXCR1
KCNAB1 NAA40 NAA11 NAA35 CCR2 ACKR2 CCR5 CCR8CXCR2
CCL5 CXCL1
CX3CR1 IL1B
CNTF CTF1 NAA10 NAA16 CCR6 IL1A CXCR5
NAA15 NAA38
CRLF1 CLCF1 IL6ST CALM3
GTF3C2 SGO2
AGPAT3 GNG2 CASQ1 GTF3C1
CALM1
CNTFR LIFR GTF3C3 WDR12 PES1 RYR3
GPR88 GPR52 GNB1 PPP1R9B SULF2 FKBP1B ASPH
TMEM30B ATP8B3 TMEM30A GNAS IGHV3-16 RYR1 KCN DJ N2 AJC3 CASQ2 DDXC 51ACNA1C RPP38
RHO BOP1 PRPF3 RPS15 TRDN
NOP53 RYR2
PRR5-ARHGAP8 ARHGAP8 DAXX SENP5
DNA mRNA miRNA Cancer
Fig.S5. Interactionnetworkoftop30biomarkerswithknownpartnersfortheLGGdataset. Onlyknowndirect
interactionsfromprotein-proteininteractiondatabasesarerecoveredforDNAandmRNAomics. FormiRNAomics,known
mRNAtargetsarerecoveredfromstarBase9. Thedifferentomicscategoriesfromwhichthebiomarkersoriginateareindicated
asblue(DNA),green(mRNA)andorange(miRNA).Knowncancer-relatedgenesareencircledinred.
22/29S4 Materialsandmethods
S4.1 Algorithmsandextendedarchitecture
ToexplaintheHeteroGATomicsarchitecture,detailedpseudo-codeforeachmoduleisprovided. Specifically,Algorithm1
presentsthefeatureselectionmodule,whileAlgorithm2presentstheGATmoduleofHeteroGATomics. Furthermore,Fig. S6
illustratesthefeaturespacerepresentationofmultiomicsdataemployedbyMASwithinHeteroGATomicsforjointfeature
selection.
ğ‘ğ‘š miRNA expression ğ‘ğ‘š mRNA expression
corr Node correlation
rel ğœğ‘£ rel ğœğ‘£
rel Node relevance
ğœğ‘’ Edge desirability ğ‘’
rel ğœğ‘£ rel ğœğ‘£ rel ğœğ‘£ rel ğœğ‘£ ğœğ‘£ Node desirability ğ‘£
ğœğ‘’ rroc ğ‘ğ‘š Omic importance
rroc ğ‘’ğœ
rel ğœğ‘£ rel ğœğ‘£
rel ğœğ‘£ rel ğœğ‘£
ğ‘ğ‘š DNA methylation
rel ğœğ‘£ corr ğœğ‘’ rel ğœğ‘£
ğœğ‘’ rroc
rroc ğ‘’ğœ
rel ğœğ‘£ corr ğœğ‘’ rel ğœğ‘£
Fig.S6. Multiomicsrepresentationforjointfeatureselection. Eachgraphrepresentsaspecificomicmodality. Nodeswithin
thegraphrepresentindividualfeatures,andedgesindicatethesimilaritybetweenpairsofthesefeatures. Allomicsare
connectedtogethertoenableinteractionsacrossdifferentomics.
23/29Algorithm1HeteroGATomicsâ€“JointFeatureSelectionModule.
Input
îˆ°=<(ğ—1,ğ—2,...,ğ—ğ‘€),ğ˜>:multiomicsdatasetwithğ‘€omics
ğ‘‡:predefinednumberofiterations
ğ‘ :thenumberofagentspermodality
ğ´
Output
îˆ°â€²=<(ğ™1,ğ™2,â€¦,ğ™ğ‘€),ğ˜>:multiomicsdatasetwithreducedfeaturedimensions
{ğœğ‘š,ğœğ‘š}ğ‘€ :nodeandedgedesirabilities
ğ‘£ ğ‘£ğ‘¢ ğ‘š=1
1: forğ‘š=1toğ‘€do
2: Computenoderelevancerel(ğ‘“ğ‘š)
ğ‘£
3: Computenodepaircorrelationcorr(ğ‘“ğ‘š,ğ‘“ğ‘š)
ğ‘£ ğ‘¢
4: Initializenodedesirabilityğœ ğ‘£ğ‘š(0)â†ğ‘î‰‚
5: Initializeedgedesirabilityğœ ğ‘£ğ‘š ğ‘¢(0)â†ğ‘îˆ±
6: Initializeomicimportanceğ‘ â† 1
7: Buildasparsegraphbyretaiğ‘š ningeğ‘€dgeswithweightsbelowthethresholdğœƒ
ğ‘“
8: endfor
9: forğ‘¡=1toğ‘‡ do
10: forğ‘š=1toğ‘€do
11: forğ‘=1toğ‘ do
ğ´
12: Placeagentğ‘randomlyonauniquenode
13: BuildasolutionbyiterativelyapplyingstatetransitionrulesfromEqs.(1)and(2)
14: EvaluatethesolutionwiththefitnessfunctioninEq.(3)
15: endfor
16: endfor
17: Retainthesolutionwiththehighestfitnessasthebest-foundîˆ¿(best)initerationğ‘¡
18: ApplydesirabilityupdatingrulestonodesandedgesaccordingtoEqs.(5)and(6)
19: Applyomicimportanceupdatingrule
20: endfor
21: Selectthetopğµfeaturesusingtheweightedsumofnodedesirabilityandrelevancevalue
22: Buildmultiomicsdatasetîˆ°â€²withthetopğµfeatures
Algorithm2HeteroGATomicsâ€“GraphAttentionNetworkModule.
Input
îˆ°â€²=<(ğ™1,ğ™2,â€¦,ğ™ğ‘€),ğ˜>:multiomicsdatasetwithğ‘€omicsandreducedfeaturedimensions
{ğœğ‘š,ğœğ‘š}ğ‘€ :nodeandedgedesirabilities
ğ‘‡pğ‘£ re:tğ‘£ hğ‘¢ enğ‘šu=m1berofepochsforpre-trainingmodels
ğ‘‡train:thenumberofepochsfortrainingmodels
Output
ğ²Ì‚ âˆˆâ„ğ‘:finalpredictedlabels
1: forğ‘š=1toğ‘€do
2: Constructpatientsimilaritynetworkfromğ™ğ‘š
3: Constructfeaturesimilaritynetworkusingğœğ‘š,ğœğ‘š,andğ™ğ‘š
ğ‘£ ğ‘£ğ‘¢
4: Constructheterogeneousgraphîˆ³ğ‘š bycombiningfeatureandpatientsimilaritynetworks
ğ»
5: endfor
6: forğ‘¡=1toğ‘‡predo
7: forğ‘š=1toğ‘€do
8: ApplyGATforrepresentationlearningonthegraphîˆ³ğ‘š viaEq.(9)
ğ»
9: Predictomic-specificlabelsviaasingle-layerneuralnetworkonlearnedrepresentations
10: Optimizeomic-specificmodelparametersbyminimizingthecross-entropylossaccordingtoEq.(10)
11: endfor
12: endfor
13: forğ‘¡=1toğ‘‡traindo
14: forğ‘š=1toğ‘€do
15: ApplyGATforrepresentationlearningonthegraphîˆ³ğ‘š viaEq.(9)
ğ»
16: Predictomic-specificlabelsviaasingle-layerneuralnetworkonlearnedrepresentations
17: endfor
18: Createacross-omicdiscoverytensorforeachpatient
19: Predictfinallabelsğ²Ì‚withVCDNfromthecross-modalitydiscoverytensor
20: OptimizeVCDNparametersbyminimizingthecross-entropyloss
21: forğ‘š=1toğ‘€do
22: Optimizeomic-specificmodelparametersbyminimizingthecross-entropylossaccordingtoEq.(10)
23: endfor
24: endfor
24/29S4.2 BiomarkeridentificationwithHeteroGATomics
HeteroGATomicsfacilitatestheidentificationofkeycancerbiomarkers,enhancingourunderstandingofitsdecision-making
process. Thisprocessisessentialforinterpretingthearchitectureâ€™seffectivenessandpinpointingthemostinformativefeatures
servingascancerbiomarkers. Weleverageanablationapproachcommonlyusedindeeplearning-basedmethodsforbiomarker
selection8,10,11. Thisapproachinvolvessystematicallyremovingeachfeaturetoobserveitsimpactonthemodelâ€™sperformance.
Specifically,foreachfeaturewithinagivenomic,wetemporarilyremovethefeaturebysettingitsvalueanditsattributes(i.e.,
noderelevanceanddesirability)tozeroinboththefeatureandpatientsimilaritynetworks. Then,weevaluatethemodelâ€™s
classificationperformanceonthetestsetwithoutthisfeature. Featureswhoseremovalleadstothemostsignificantdecrease
inclassificationperformanceareconsideredtopbiomarkers. Thisdecreaseindicatesthefeatureâ€™ssubstantialimpactonthe
model,highlightingitsimportance. Weapplya10-foldcross-validationstrategy,indicatingthatthesetofinputfeaturesto
theGATmodulemayvaryacrossdifferentfolds. Therefore,weassessthemodelâ€™sclassificationperformanceforeachfeature
ineveryfold. Torankfeaturesfromeachomicmodality,wemeasurethecumulativereductioninclassificationperformance,
whichisthennormalizedaccordingtothefrequencyoftheiroccurrencesacrossallfolds. Toevaluatetheperformanceof
HeteroGATomics,weuseAUROCforbinaryclassificationtasksintheBLCAandLGGdatasets.
GO enrichment analyses are performed with GOseq in R, using GO biological process (GO BP), molecular function
(MF),andcellularcomponent(CC).Thetop30biomarkersformRNAandDNAomiccategoriesareusedasenrichmentsets
withtheremaining300biomarkersasthebackgroundset. Protein-proteininteractionnetworksaregeneratedinCytoscape,
usingstring-db12 andConsensusPathway13 databasesforknownphysicalinteractions. Onlydirecttwo-by-twointeractionsare
used,withaninteractionconfidenceof>=7forstring-dband>=9.5forConsensusPathway(reportedashighconfidence
interactions). Knowncancer-relatedgenesarefetchedfromtheCancerGeneCensusdatabase14,OncoKBâ„¢CancerGene
List15,andtheNetworkCancerGenome16. TargetmRNAsformiRNAbiomarkersareinferredfromstarBase9,keepingonly
targetswithatleastoneCLIPexperimentevidenceandpredictedbyatleasttwomiRNAtargetpredictortools(e.g. miRanda
and/orTargetScan).
S4.3 Experimentalsetting
Implementation.
HeteroGATomicshasbeendevelopedusingPython3.10andPyTorchGeometric2.4.0(ref.17),incorporating
essentialfunctionalitiesfromPyTorch2.1.0(ref.18),scikit-learn1.3.0(ref.19),NumPy1.26.0(ref.20),pandas2.1.1(ref.21),and
SciPy1.11.3(ref.22). ThetrainingprocessfortheGATmoduleandVCDNutilizesthePyTorchLightning2.1.3(ref.23). Forthe
trainingofomic-specificencodersusingtheGATmoduleandtheVCDN,theAdamoptimizer24isemployedwiththeStepLR
learningrateschedulerstrategy,whichreducesthelearningratebyafactorof0.8every20epochs. Eachomic-specificencoder
comprisesathree-layerGATmodelwithhiddendimensionssetto[100,100,50],incorporatingLeakyReLUnonlinearitywith
anegativeslopeof0.01aftereachlayer. Thedecodersforeachomicstypeutilizeasingle-layerfullyconnectedneuralnetwork
tomapthefinal50-neuronhiddenlayertotheoutputlabels. Theomic-specificencoder-decoderpairsispre-trainedfor500
epochs,followedbyafulltrainingoftheentirearchitectureforanadditional500epochs. Hyperparameteroptimizationis
guidedby10-foldcross-validation,withvalidationsetperformanceinformingtheselectionofoptimalparameters. Detailed
hyperparameterconfigurationsareavailableinSectionS5,TablesS2andS3,andFig. S7. Wealsoconductanexecutiontime
analysispresentedinSectionS6.
Baselines. WecomparetheperformanceoffeatureselectionmoduleofHeteroGATomicswithfivebaselinemethods: (1)MI1
quantifiesthedependencybetweentworandomvariables,yieldinganon-negativevaluethatisoftenusedtoselectfeatureswith
thehighestinformationsharedwiththetargetclass;(2)RFE2 recursivelyremovestheleastimportantfeaturesbasedonan
estimatorâ€™sweights,startingwithallfeaturesandstoppingatthedesirednumber;(3)mRMR3selectsfeaturesthathavethe
highestrelevancewiththetargetclassandareminimallyredundantwitheachother,balancingthetrade-offbetweenrelevance
andredundancy;(4)mRMR-mv4 isanadaptionofmRMRtomultiomicsintegrationsetting;(5)MAgentOmics5 isaniterative
improvementmethodthatextendstheACOalgorithmtoworkwithmultiomicsdata.
When performing baseline feature selection methods, we remove five features at each iteration in RFE, employ the
recommendedhyperparametervaluesformRMR-mvasspecifiedinitsoriginalpaper,andusethevalueslistedinTableS3for
MAgentOmics,ensuringauniformcomparisonwithHeteroGATomicsâ€™featureselectionmodule. Weutilizethescikit-feature
package25forimplementingmRMR,andscikit-learnforimplementingMIandRFE.
Formultiomicsclassification,wecompareHeteroGATomicsagainsteightbaselinemethods. Fordirectfeatureconcatenation
acrossallomicsmodalities,machinelearningapproachesincludingKNN1,MLP1,RF6,Ridge7,andXGBoost26 areemployed.
mRMR-mvandMAgentOmicsfocusonjointfeatureselection,specificallytailoredformultiomicsdataintegration. MOGONET8,
asupervisedmultiomicsintegrationframeworkforclassificationtasks,leveragesGCNforomic-specificpatientclassification
andemploysVCDNtocombineinitialpredictionsfromeachomicsmodalityintoafinallabelprediction.
Forcomparativeanalysis,weusescikit-learnforKNN,MLP,RF,andRidgeimplementations,keepingtotheirdefault
settings. Specifically,theMLPmodelisconfiguredwith500epochsinscikit-learn,whileotherparametersremainattheir
25/29defaultvalues. TheXGBoostclassifierisimplementedusingtheXGBoostpackage26,withitsdefaultconfigurations. For
MOGONET, we follow the hyperparameter recommendations from its original publication. To ensure a fair comparison,
MOGONETisrunfor500epochsofpre-trainingforeachomic-specificGCN,andthenforanadditional500epochsfortraining
theentirearchitecture,similartotheHeteroGATomicssetup.
S5 Hyperparametersetting
WeevaluatesixhyperparametersoftheGATmodulewithinHeteroGATomicsacrossvariousdatasets,withresultsprovidedin
Fig. S7. Thisanalysisusestheaverageofevaluationmetricsfroma10-foldcross-validationacrosstheentiredataset,where,in
eachfold,thetrainingsetissplitintotrainingandvalidationsetsata9:1ratio. Theresultspresentedaretheaveragevaluesof
theevaluationmetricsderivedfromthevalidationsets. ForbinaryclassificationtasksintheBLCAandLGGdatasets,weutilize
AUROC,whileWeightedF1isusedformulti-classclassificationintheRCCdataset. Thesixevaluatedhyperparametersinclude
thenumberofattentionheads,sparsityrate,dropoutrate,pre-traininglearningrate(pre-traininglr),traininglearningrate
(traininglr),andVCDNlearningrate(VCDNlr). TableS2summarizestherangeofpossiblevaluesforeachhyperparameterand
highlightstheoptimalvaluesidentifiedthroughtheoptimizationprocess. Toassesstheimpactofindividualhyperparameters,
eachoneisvariedatatimewhilekeepingtheothersconstant.
FortheHeteroGATomics module,weprimarilyadoptthehyperparametervaluesrecommendedbythefoundational
MAS
ACOalgorithmpapers27â€“29,establishedthroughextensivestudies. Furthermore,thesparsityrateforeachmodalitywithinthe
featureselectionmoduleiscarefullychosentoguaranteeenoughedgesinthegraph,enablingeffectivetraversalbytheagents.
ThecommonhyperparametersettingsappliedacrossalldatasetsareoutlinedinTableS3.
TableS2. Dataset-specifichyperparameterconfigurationsforHeteroGATomics.
Dataset Numberofheads Sparsityrate Dropoutrate Pre-traininglr Traininglr VCDNlr
{2,3,4} {0.80,0.85,0.90} {0.0,0.1,0.2,0.3} {0.050,0.010,0.001} {0.050,0.010,0.001} {0.050,0.010,0.001}
BLCA 3 0.90 0.0 0.010 0.001 0.05
LGG 2 0.85 0.3 0.001 0.001 0.05
RCC 2 0.80 0.0 0.001 0.001 0.05
Valuesinsetspresentthepotentialoptionsforeachhyperparameter,withtheboldedvaluewithineachsetmarkingthepredeterminedchoiceforthat
hyperparameterwhenvaryinganother.
TableS3. CommonhyperparameterconfigurationsforHeteroGATomicsacrossdatasets.
Module Hyperparameter Value
HeteroGATomics Numberofiterations 50
MAS
Numberofagentsperomic 10
Initialnodedesirability(ğ‘ î‰‚) 0.2
Initialedgedesirability(ğ‘ îˆ±) 0.2
Nodedecaycoefficient(ğœŒ î‰‚) 0.1
Edgedecaycoefficient(ğœŒ îˆ±) 0.1
Omicimportancedecaycoefficient(ğœŒ îˆ¹) 0.1
Numberofselectedfeaturesineachiteration 30
Controlparameterğ‘ 0.8
0
Sparsityrateforeachomicinfeaturesimilaritynetwork(DNA,mRNA,miRNA) [0.9,0.9,0.8]
HeteroGATomics Numberofepochsforpre-trainingmodel 500
GAT
Numberofepochsfortrainingmodel 500
Numberoflayers 3
Hiddennodedimensionsforeachlayer [100,100,50]
26/29a
0.95 0.95 0.96
0.90 0.90 0.92
C C C
O O O
R0.85 R0.85 R0.88
U A U A U A Dropout rate = 0.0
0.80 Heads = 2 0.80 Sparsity rate = 0.80 0.84 Dropout rate = 0.1
Heads = 3 Sparsity rate = 0.85 Dropout rate = 0.2
Heads = 4 Sparsity rate = 0.90 Dropout rate = 0.3
0.75 0.75 0.80
0 100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500
#epochs #epochs #epochs
0.95 1.00 1.00
0.90 0.90
0.90
0.80 0.80
C C C
O O O
R0.85 R0.70 R0.70
U U U
A A0.60 A0.60
0.80 Pre-train learning rate = 0.050 Train learning rate = 0.050 VCDN learning rate = 0.050
Pre-train learning rate = 0.010 0.50 Train learning rate = 0.010 0.50 VCDN learning rate = 0.010
Pre-train learning rate = 0.001 Train learning rate = 0.001 VCDN learning rate = 0.001
0.75 0.40 0.40
0 100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500
#epochs #epochs #epochs
b
0.80 0.80 0.80
0.75
0.75
C O0.70 C
O
C O0.75
R R0.70 R
U A0.65 U
A
U
A0.70 Dropout rate = 0.0
0.60 H He ea ad ds s = = 2 3 0.65 S Spp aar rs si itty y r ra at te e = = 0 0. .8 80 5 D Dr ro op po ou ut t r ra at te e = = 0 0. .1 2
Heads = 4 Sparsity rate = 0.90 Dropout rate = 0.3
0.55 0.60 0.65
0 100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500
#epochs #epochs #epochs
0.80 0.80 0.80
0.75 0.75
0.75 0.70 0.70
C C C
O O0.65 O0.65
R0.70 R R
U U0.60 U0.60
A A A
0.65 Pre-train learning rate = 0.050 0.55 Train learning rate = 0.050 0.55 VCDN learning rate = 0.050
Pre-train learning rate = 0.010 0.50 Train learning rate = 0.010 0.50 VCDN learning rate = 0.010
Pre-train learning rate = 0.001 Train learning rate = 0.001 VCDN learning rate = 0.001
0.60 0.45 0.45
0 100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500
#epochs #epochs #epochs
c
0.96 0.96 0.96
1 F0.92 1 F0.92 1 F0.92
d d d
e e e
th th th
g g g
ie W0.88
Heads = 2
ie W0.88
Sparsity rate = 0.80
ie W0.88 D Dr ro op po ou ut
t
r ra at te
e
=
=
0 0. .0
1
Heads = 3 Sparsity rate = 0.85 Dropout rate = 0.2
Heads = 4 Sparsity rate = 0.90 Dropout rate = 0.3
0.84 0.84 0.84
0 100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500
#epochs #epochs #epochs
0.96 1.00 0.95
0.90 0.90
1 F0.92 1 F 1 F
d e th
g ie W0.88 Pre-train learning rate = 0.050
d e th
g ie
W00 .. 78 00
Train learning rate = 0.050
d e th
g ie
W00 .. 88 05
VCDN learning rate = 0.050
Pre-train learning rate = 0.010 0.60 Train learning rate = 0.010 0.75 VCDN learning rate = 0.010
Pre-train learning rate = 0.001 Train learning rate = 0.001 VCDN learning rate = 0.001
0.84 0.50 0.70
0 100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500
#epochs #epochs #epochs
Fig.S7. HeteroGATomicsclassificationperformanceacrossdatasetswithdifferenthyperparameterconfigurations. a,
ResultsfortheBLCAdatasetwithAUROC.b,ResultsfortheLGGdatasetwithAUROC.c,ResultsfortheRCCdatasetwith
WeightedF1. Averagedvaluesfrom10-foldcross-validationarepresented. Eachfolddividesthetrainingsetintotrainingand
validationsets,withtherespectiveevaluationmetricreportedforthevalidationset. Thex-axisrepresentsepochs,whilethe
y-axisrepresentsspecificmetricmentionedforeachdataset.
27/29S6 Executiontimeanalysis
WemeasuretheexecutiontimeoftwomoduleswithinHeteroGATomics: theHeteroGATomics andHeteroGATomics
MAS GAT
modules. IntheHeteroGATomics module,weexclusivelyevaluatethetimerequiredforfeatureselection,independent
MAS
of the final classifier used. In the case of the HeteroGATomics , the execution time involves various stages, including
GAT
thecreationofheterogeneousgraphs,pre-trainingofeachomic-specificGATmodel,trainingeachomic-specificGATwith
theVCDNmodule(inactiveforsinglemodality),andtestingtheentirearchitecture. WeutilizeaCPUwith20coresonthe
High-PerformanceComputecluster,Stanage,atTheUniversityofSheffieldforthefeatureselectionmoduleandevaluatethe
GATmoduleusinganNVIDIAGeForceRTX4090GPU.WeadoptthehyperparameterconfigurationsasdetailedinTablesS2
andS3fortheseevaluations,withtheresultspresentedinFig. S8.
FigureS8ademonstratesthattheexecutiontimeoftheHeteroGATomics remainsrelativelyconstantwhenvaryingthe
MAS
numberofselectedfeatures. ThisbehaviorarisesfromthenatureoftheHeteroGATomics asafeature-rankingtechnique2,
MAS
whereselectingadditionalfeaturesdoesnotincuradditionalexecutiontime. However,thefigurealsoindicatesthatthetotal
numberoffeaturesinthedatasetinfluencesexecutiontime,withhigherfeaturecountsleadingtolongerexecutiontimes.
InFig. S8b,theexecutiontimeoftheHeteroGATomics isdepictedacrossdifferentcombinationsofomicmodalities. It
GAT
isobservedthatHeteroGATomicsutilizingallomicmodalitiesrequiresonly84seconds,demonstratinghighefficiency. The
figurefurtherrevealsthatminimaldifferencesareobservedbetweenleveragingtwoorthreeomicmodalities,suggestingthat
addingmoreomicmodalitiesslightlyincreasesexecutiontime. Theonlyexceptionisthesingleomiccase,wheretheVCDN
moduleremainsinactiveduringtraining,leadingtotheexpecteddecreaseinexecutiontime.
a b
3 90
80
2.6 )s d70
n
o
)s
ru
o
h
n2.2
c
e s
n
i(
e56 00
i(
e m1.8 BLCA
m iT40
iT LGG 30
1.4 RCC 20
1
15 20 35 55 100
#features
Fig.S8. ExecutiontimeanalysisofHeteroGATomics. a,PerformanceoftheHeteroGATomics MASmoduleintermsof
executiontimewithvaryingselectedfeaturesizesacrossthreedatasets. b,PerformanceoftheHeteroGATomics GATmodulein
termsofexecutiontimefordifferentcombinationsofomicmodalitiesontheLGGdataset. Averagedexecutiontimesfrom
10-foldcross-validationarepresented.
References
1. Theodoridis,S.&Koutroumbas,K. PatternRecognition(ElsevierScience,2008).
2. Guyon,I.,Weston,J.,Barnhill,S.&Vapnik,V. Geneselectionforcancerclassificationusingsupportvectormachines.
Mach.Learn.46,389â€“422(2002).
3. Peng,H.,Long,F.&Ding,C. Featureselectionbasedonmutualinformationcriteriaofmax-dependency,max-relevance,
andmin-redundancy. IEEETrans.PatternAnal.Mach.Intell.27,1226â€“1238(2005).
4. El-Manzalawy,Y.,Hsieh,T.-Y.,Shivakumar,M.,Kim,D.&Honavar,V. Min-redundancyandmax-relevancemulti-view
featureselectionforpredictingovariancancersurvivalusingmulti-omicsdata. BMCMed.Genom.11,19â€“31(2018).
5. Tabakhi,S.&Lu,H. Multi-agentfeatureselectionforintegrativemulti-omicsanalysis. InAnnualInternationalConference
oftheIEEEEngineeringinMedicineandBiologySociety,1638â€“1642(IEEE,2022).
6. Ho,T.K. Randomdecisionforests. InProceedingsoftheInternationalConferenceonDocumentAnalysisandRecognition,
vol.1,278â€“282(IEEE,1995).
28/297. Hoerl,A.E.&Kennard,R.W. Ridgeregression: biasedestimationfornonorthogonalproblems. Technometrics12,55â€“67
(1970).
8. Wang,T.etal. MOGONETintegratesmulti-omicsdatausinggraphconvolutionalnetworksallowingpatientclassification
andbiomarkeridentification. Nat.Commun.12,3445(2021).
9. Li, J.-H., Liu, S., Zhou, H., Qu, L.-H.&Yang, J.-H. starBasev2.0: decodingmiRNA-ceRNA,miRNA-ncRNAand
proteinâ€“RNAinteractionnetworksfromlarge-scaleCLIP-Seqdata. NucleicAcidsRes.42,D92â€“D97(2014).
10. Setiono,R.&Liu,H. Neural-networkfeatureselector. IEEETrans.NeuralNetw.8,654â€“662(1997).
11. Amjad,R.A.,Liu,K.&Geiger,B.C. Understandingneuralnetworksandindividualneuronimportanceviainformation-
orderedcumulativeablation. IEEETrans.NeuralNetw.Learn.Syst.33,7842â€“7852(2022).
12. Szklarczyk,D.etal. TheSTRINGdatabasein2023: proteinâ€“proteinassociationnetworksandfunctionalenrichment
analysesforanysequencedgenomeofinterest. NucleicAcidsRes.51,D638â€“D646(2023).
13. Kamburov,A.&Herwig,R. ConsensusPathDB2022: molecularinteractionsupdateasaresourcefornetworkbiology.
NucleicAcidsRes.50,D587â€“D595(2022).
14. Sondka,Z.etal. COSMIC:acurateddatabaseofsomaticvariantsandclinicaldataforcancer. NucleicAcidsRes.52,
D1210â€“D1217(2024).
15. Chakravarty,D.etal. OncoKB:aprecisiononcologyknowledgebase. JCOPrecis.Oncol.2017,PO.17.00011(2017).
16. Repana,D.etal. TheNetworkofCancerGenes(NCG):acomprehensivecatalogueofknownandcandidatecancergenes
fromcancersequencingscreens. GenomeBiol.20,1â€“12(2019).
17. Fey,M.&Lenssen,J.E. FastgraphrepresentationlearningwithPyTorchGeometric. InICLRWorkshoponRepresentation
LearningonGraphsandManifolds(2019).
18. Paszke,A.etal. PyTorch: animperativestyle,high-performancedeeplearninglibrary. InAdvancesinNeuralInformation
ProcessingSystems,vol.32(NeurIPS,2019).
19. Pedregosa,F.etal. Scikit-learn: machinelearninginPython. J.Mach.Learn.Res.12,2825â€“2830(2011).
20. Harris,C.R.etal. ArrayprogrammingwithNumPy. Nature585,357â€“362(2020).
21. Thepandasdevelopmentteam. pandas-dev/pandas: Pandas2.1.1. Zenodohttps://doi.org/10.5281/zenodo.8364959(2023).
22. Virtanen,P.etal. SciPy1.0: fundamentalalgorithmsforscientificcomputinginPython. Nat.Methods17,261â€“272(2020).
23. Falcon,W.&ThePyTorchLightningteam. PyTorchLightning2.1.3. Zenodohttps://doi.org/10.5281/zenodo.10419201
(2023).
24. Kingma,D.P.&Ba,J. Adam: amethodforstochasticoptimization. InInternationalConferenceforLearningRepresenta-
tions(ICLR,2015).
25. Li,J.etal. Featureselection: adataperspective. ACMComput.Surv.50,94(2018).
26. Chen,T.&Guestrin,C. XGBoost: ascalabletreeboostingsystem. InProceedingsoftheACMSIGKDDInternational
ConferenceonKnowledgeDiscoveryandDataMining,785â€“794(ACM,2016).
27. Dorigo,M.&Gambardella,L.M. Antcolonysystem: acooperativelearningapproachtothetravelingsalesmanproblem.
IEEETrans.Evol.Comput.1,53â€“66(1997).
28. Dorigo,M.&Blum,C. Antcolonyoptimizationtheory: asurvey. Theor.Comput.Sci.344,243â€“278(2005).
29. Dorigo,M.,DiCaro,G.&Gambardella,L.M. Antalgorithmsfordiscreteoptimization. Artif.life5,137â€“172(1999).
29/29