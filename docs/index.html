
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Tracking Patterns in Toxicity and Antisocial Behavior Over User Lifetimes on Large Social Media Platforms</h3>
                <p>Authors: Katy BlumerJon Kleinberg</p>
                <p><a href="http://arxiv.org/abs/2407.09365v1">Link to paper</a></p>
                <p>An increasing amount of attention has been devoted to the problem of toxicor antisocial behavior on social media. In this paper we analyze such behaviorat very large scales: we analyze toxicity over a 14-year time span on nearly500 million comments from Reddit and Wikipedia grounded in two differentproxies for toxicity.  At the individual level we analyze users toxicity levels over the course oftheir time on the site and find a striking reversal in trends: both Reddit andWikipedia users tended to become less toxic over their life cycles on the sitein the early pre-2013 history of the site but more toxic over their lifecycles in the later post-2013 history of the site. We also find that toxicityon Reddit and Wikipedia differ in a key way with the most toxic behavior onReddit exhibited in aggregate by the most active users and the most toxicbehavior on Wikipedia exhibited in aggregate by the least active users.Finally we consider the toxicity of discussion around widely-shared pieces ofcontent and find that the trends for toxicity in discussion about content bearinteresting similarities with the trends for toxicity in discussion by users.</p>
                <p>Last Updated: 2024-07-12 15:45:02 UTC</p>
                <button class="interpret-button" data-id="2407.09365v1">Interpret</button>
                <div id="interpretation-2407.09365v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Is Contrasting All You Need? Contrastive Learning for the Detection and Attribution of AI-generated Text</h3>
                <p>Authors: Lucio La CavaDavide CostaAndrea Tagarelli</p>
                <p><a href="http://arxiv.org/abs/2407.09364v1">Link to paper</a></p>
                <p>The significant progress in the development of Large Language Models hascontributed to blurring the distinction between human and AI-generated text.The increasing pervasiveness of AI-generated text and the difficulty indetecting it poses new challenges for our society. In this paper we tackle theproblem of detecting and attributing AI-generated text by proposing WhosAI atriplet-network contrastive learning framework designed to predict whether agiven input text has been generated by humans or AI and to unveil theauthorship of the text. Unlike most existing approaches our proposed frameworkis conceived to learn semantic similarity representations from multiplegenerators at once thus equally handling both detection and attribution tasks.Furthermore WhosAI is model-agnostic and scalable to the release of new AItext-generation models by incorporating their generated instances into theembedding space learned by our framework. Experimental results on theTuringBench benchmark of 200K news articles show that our proposed frameworkachieves outstanding results in both the Turing Test and Authorship Attributiontasks outperforming all the methods listed in the TuringBench benchmarkleaderboards.</p>
                <p>Last Updated: 2024-07-12 15:44:56 UTC</p>
                <button class="interpret-button" data-id="2407.09364v1">Interpret</button>
                <div id="interpretation-2407.09364v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Good Intentions, Risky Inventions: A Method for Assessing the Risks and Benefits of AI in Mobile and Wearable Uses</h3>
                <p>Authors: Marios ConstantinidesEdyta BoguckaSanja ScepanovicDaniele Quercia</p>
                <p><a href="http://arxiv.org/abs/2407.09322v1">Link to paper</a></p>
                <p>Integrating Artificial Intelligence AI into mobile and wearables offersnumerous benefits at individual societal and environmental levels. Yet italso spotlights concerns over emerging risks. Traditional assessments of risksand benefits have been sporadic and often require costly expert analysis. Wedeveloped a semi-automatic method that leverages Large Language Models LLMsto identify AI uses in mobile and wearables classify their risks based on theEU AI Act and determine their benefits that align with globally recognizedlong-term sustainable development goals a manual validation of our method bytwo experts in mobile and wearable technologies a legal and compliance expertand a cohort of nine individuals with legal backgrounds who were recruited fromProlific confirmed its accuracy to be over 85. We uncovered that specificapplications of mobile computing hold significant potential in improvingwell-being safety and social equality. However these promising uses arelinked to risks involving sensitive data vulnerable groups and automateddecision-making. To avoid rejecting these risky yet impactful mobile andwearable uses we propose a risk assessment checklist for the Mobile HCIcommunity.</p>
                <p>Last Updated: 2024-07-12 14:58:56 UTC</p>
                <button class="interpret-button" data-id="2407.09322v1">Interpret</button>
                <div id="interpretation-2407.09322v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Prompts First, Finally</h3>
                <p>Authors: Brent N. ReevesJames PratherPaul DennyJuho LeinonenStephen MacNeilBrett A. BeckerAndrew Luxton-Reilly</p>
                <p><a href="http://arxiv.org/abs/2407.09231v1">Link to paper</a></p>
                <p>Generative AI GenAI and large language models in particular are disruptingComputer Science Education. They are proving increasingly capable at more andmore challenges. Some educators argue that they pose a serious threat tocomputing education and that we should ban their use in the classroom. Whilethere are serious GenAI issues that remain unsolved it may be useful in thepresent moment to step back and examine the overall trajectory of ComputerScience writ large. Since the very beginning our discipline has sought toincrease the level of abstraction in each new representation. We haveprogressed from hardware dip switches through special purpose languages andvisual representations like flow charts all the way now to naturallanguage. With the advent of GenAI students can finally change theabstraction level of a problem to the language theyve been problemsolving with all their lives. In this paper we argue that our programmingabstractions were always headed here -- to natural language. Now is the time toadopt a Prompts First approach to Computer Science Education.</p>
                <p>Last Updated: 2024-07-12 12:50:28 UTC</p>
                <button class="interpret-button" data-id="2407.09231v1">Interpret</button>
                <div id="interpretation-2407.09231v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>AI-Powered Immersive Assistance for Interactive Task Execution in Industrial Environments</h3>
                <p>Authors: Tomislav DuricicPeter MüllnerNicole WeidingerNeven ElSayedDominik KowaldEduardo Veas</p>
                <p><a href="http://arxiv.org/abs/2407.09147v1">Link to paper</a></p>
                <p>Many industrial sectors rely on well-trained employees that are able tooperate complex machinery. In this work we demonstrate an AI-powered immersiveassistance system that supports users in performing complex tasks in industrialenvironments. Specifically our system leverages a VR environment thatresembles a juice mixer setup. This digital twin of a physical setup simulatescomplex industrial machinery used to mix preparations or liquids e.g. similarto the pharmaceutical industry and includes various containers sensorspumps and flow controllers. This setup demonstrates our systems capabilitiesin a controlled environment while acting as a proof-of-concept for broaderindustrial applications. The core components of our multimodal AI assistant area large language model and a speech-to-text model that process a video andaudio recording of an expert performing the task in a VR environment. The videoand speech input extracted from the experts video enables it to providestep-by-step guidance to support users in executing complex tasks. Thisdemonstration showcases the potential of our AI-powered assistant to reducecognitive load increase productivity and enhance safety in industrialenvironments.</p>
                <p>Last Updated: 2024-07-12 10:30:45 UTC</p>
                <button class="interpret-button" data-id="2407.09147v1">Interpret</button>
                <div id="interpretation-2407.09147v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>Weight Block Sparsity: Training, Compilation, and AI Engine Accelerators</h3>
                <p>Authors: Paolo D'AlbertoTaehee JeongAkshai JainShreyas ManjunathMrinal SarmahSamuel Hsu Yaswanth RapartiNitesh Pipralia</p>
                <p><a href="http://arxiv.org/abs/2407.09453v1">Link to paper</a></p>
                <p>Nowadays increasingly larger Deep Neural Networks DNNs are beingdeveloped trained and utilized. These networks require significantcomputational resources putting a strain on both advanced and limited devices.Our solution is to implement em weight block sparsity which is a structuredsparsity that is friendly to hardware. By zeroing certain sections of theconvolution and fully connected layers parameters of pre-trained DNN models wecan efficiently speed up the DNNs inference process. This results in a smallermemory footprint faster communication and fewer operations.  Our work presents a vertical system that allows for the training ofconvolution and matrix multiplication weights to exploit 8x8 block sparsity ona single GPU within a reasonable amount of time. Compilers recognize thissparsity and use it for both data compaction and computation splitting intothreads. Blocks like these take full advantage of both spatial and temporallocality paving the way for fast vector operations and memory reuse. By usingthis system on a Resnet50 model we were able to reduce the weight by half withminimal accuracy loss resulting in a two-times faster inference speed. We willpresent performance estimates using accurate and complete code generation forAIE2 configuration sets AMD Versal FPGAs with Resnet50 Inception V3 andVGG16 to demonstrate the necessary synergy between hardware overlay designs andsoftware stacks for compiling and executing machine learning applications.</p>
                <p>Last Updated: 2024-07-12 17:37:49 UTC</p>
                <button class="interpret-button" data-id="2407.09453v1">Interpret</button>
                <div id="interpretation-2407.09453v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Human-like Episodic Memory for Infinite Context LLMs</h3>
                <p>Authors: Zafeirios FountasMartin A BenfeghoulAdnan OomerjeeFenia ChristopoulouGerasimos LampourasHaitham Bou-AmmarJun Wang</p>
                <p><a href="http://arxiv.org/abs/2407.09450v1">Link to paper</a></p>
                <p>Large language models LLMs have shown remarkable capabilities but stillstruggle with processing extensive contexts limiting their ability to maintaincoherence and accuracy over long sequences. In contrast the human brain excelsat organising and retrieving episodic experiences across vast temporal scalesspanning a lifetime. In this work we introduce EM-LLM a novel approach thatintegrates key aspects of human episodic memory and event cognition into LLMsenabling them to effectively handle practically infinite context lengths whilemaintaining computational efficiency. EM-LLM organises sequences of tokens intocoherent episodic events using a combination of Bayesian surprise andgraph-theoretic boundary refinement in an on-line fashion. When needed theseevents are retrieved through a two-stage memory process combiningsimilarity-based and temporally contiguous retrieval for efficient andhuman-like access to relevant information. Experiments on the LongBench datasetdemonstrate EM-LLMs superior performance outperforming the state-of-the-artInfLLM model with an overall relative improvement of 4.3 across various tasksincluding a 33 improvement on the PassageRetrieval task. Furthermore ouranalysis reveals strong correlations between EM-LLMs event segmentation andhuman-perceived events suggesting a bridge between this artificial system andits biological counterpart. This work not only advances LLM capabilities inprocessing extended contexts but also provides a computational framework forexploring human memory mechanisms opening new avenues for interdisciplinaryresearch in AI and cognitive science.</p>
                <p>Last Updated: 2024-07-12 17:34:03 UTC</p>
                <button class="interpret-button" data-id="2407.09450v1">Interpret</button>
                <div id="interpretation-2407.09450v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>ASTPrompter: Weakly Supervised Automated Language Model Red-Teaming to Identify Likely Toxic Prompts</h3>
                <p>Authors: Amelia F. HardyHoujun LiuBernard LangeMykel J. Kochenderfer</p>
                <p><a href="http://arxiv.org/abs/2407.09447v1">Link to paper</a></p>
                <p>Typical schemes for automated red-teaming large language models LLMs focuson discovering prompts that trigger a frozen language model the defender togenerate toxic text. This often results in the prompting model the adversaryproducing text that is unintelligible and unlikely to arise. Here we propose areinforcement learning formulation of the LLM red-teaming task which allows usto discover prompts that both 1 trigger toxic outputs from a frozen defenderand 2 have low perplexity as scored by the defender. We argue these cases aremost pertinent in a red-teaming setting because of their likelihood to ariseduring normal use of the defender model. We solve this formulation through anovel online and weakly supervised variant of Identity Preference OptimizationIPO on GPT-2 and GPT-2 XL defenders. We demonstrate that our policy iscapable of generating likely prompts that also trigger toxicity. Finally wequalitatively analyze learned strategies trade-offs of likelihood andtoxicity and discuss implications. Source code is available for this projectat: https://github.com/sisl/ASTPrompter/.</p>
                <p>Last Updated: 2024-07-12 17:33:34 UTC</p>
                <button class="interpret-button" data-id="2407.09447v1">Interpret</button>
                <div id="interpretation-2407.09447v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Open (Clinical) LLMs are Sensitive to Instruction Phrasings</h3>
                <p>Authors: Alberto Mario Ceballos ArroyoMonica MunnangiJiuding SunKaren Y. C. ZhangDenis Jered McInerneyByron C. WallaceSilvio Amir</p>
                <p><a href="http://arxiv.org/abs/2407.09429v1">Link to paper</a></p>
                <p>Instruction-tuned Large Language Models LLMs can perform a wide range oftasks given natural language instructions to do so but they are sensitive tohow such instructions are phrased. This issue is especially concerning inhealthcare as clinicians are unlikely to be experienced prompt engineers andthe potential consequences of inaccurate outputs are heightened in this domain.  This raises a practical question: How robust are instruction-tuned LLMs tonatural variations in the instructions provided for clinical NLP tasks Wecollect prompts from medical doctors across a range of tasks and quantify thesensitivity of seven LLMs -- some general others specialized -- to naturali.e. non-adversarial instruction phrasings. We find that performance variessubstantially across all models and that -- perhaps surprisingly --domain-specific models explicitly trained on clinical data are especiallybrittle compared to their general domain counterparts. Further arbitraryphrasing differences can affect fairness e.g. valid but distinct instructionsfor mortality prediction yield a range both in overall performance and interms of differences between demographic groups.</p>
                <p>Last Updated: 2024-07-12 17:00:44 UTC</p>
                <button class="interpret-button" data-id="2407.09429v1">Interpret</button>
                <div id="interpretation-2407.09429v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Mitigating Entity-Level Hallucination in Large Language Models</h3>
                <p>Authors: Weihang SuYichen TangQingyao AiChangyue WangZhijing WuYiqun Liu</p>
                <p><a href="http://arxiv.org/abs/2407.09417v1">Link to paper</a></p>
                <p>The emergence of Large Language Models LLMs has revolutionized how usersaccess information shifting from traditional search engines to directquestion-and-answer interactions with LLMs. However the widespread adoption ofLLMs has revealed a significant challenge known as hallucination wherein LLMsgenerate coherent yet factually inaccurate responses. This hallucinationphenomenon has led to users distrust in information retrieval systems based onLLMs. To tackle this challenge this paper proposes Dynamic RetrievalAugmentation based on hallucination Detection DRAD as a novel method todetect and mitigate hallucinations in LLMs. DRAD improves upon traditionalretrieval augmentation by dynamically adapting the retrieval process based onreal-time hallucination detection. It features two main components: Real-timeHallucination Detection RHD for identifying potential hallucinations withoutexternal models and Self-correction based on External Knowledge SEK forcorrecting these errors using external knowledge. Experiment results show thatDRAD demonstrates superior performance in both detecting and mitigatinghallucinations in LLMs. All of our code and data are open-sourced athttps://github.com/oneal2000/EntityHallucination.</p>
                <p>Last Updated: 2024-07-12 16:47:34 UTC</p>
                <button class="interpret-button" data-id="2407.09417v1">Interpret</button>
                <div id="interpretation-2407.09417v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>GNN with Model-based RL for Multi-agent Systems</h3>
                <p>Authors: Hanxiao Chen</p>
                <p><a href="http://arxiv.org/abs/2407.09249v1">Link to paper</a></p>
                <p>Multi-agent systems MAS constitute a significant role in exploring machineintelligence and advanced applications. In order to deeply investigatecomplicated interactions within MAS scenarios we originally propose GNN forMBRL model which utilizes a state-spaced Graph Neural Networks withModel-based Reinforcement Learning to address specific MAS missions e.g.Billiard-Avoidance Autonomous Driving Cars. In detail we firstly used GNNmodel to predict future states and trajectories of multiple agents thenapplied the Cross-Entropy Method CEM optimized Model Predictive Control toassist the ego-agent planning actions and successfully accomplish certain MAStasks.</p>
                <p>Last Updated: 2024-07-12 13:21:35 UTC</p>
                <button class="interpret-button" data-id="2407.09249v1">Interpret</button>
                <div id="interpretation-2407.09249v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Decentralized multi-agent reinforcement learning algorithm using a cluster-synchronized laser network</h3>
                <p>Authors: Shun KotokuTakatomo MihanaAndré RöhmRyoichi Horisaki</p>
                <p><a href="http://arxiv.org/abs/2407.09124v1">Link to paper</a></p>
                <p>Multi-agent reinforcement learning MARL studies crucial principles that areapplicable to a variety of fields including wireless networking and autonomousdriving. We propose a photonic-based decision-making algorithm to address oneof the most fundamental problems in MARL called the competitive multi-armedbandit CMAB problem. Our numerical simulations demonstrate that chaoticoscillations and cluster synchronization of optically coupled lasers alongwith our proposed decentralized coupling adjustment efficiently balanceexploration and exploitation while facilitating cooperative decision-makingwithout explicitly sharing information among agents. Our study demonstrates howdecentralized reinforcement learning can be achieved by exploiting complexphysical processes controlled by simple algorithms.</p>
                <p>Last Updated: 2024-07-12 09:38:47 UTC</p>
                <button class="interpret-button" data-id="2407.09124v1">Interpret</button>
                <div id="interpretation-2407.09124v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Review of Nine Physics Engines for Reinforcement Learning Research</h3>
                <p>Authors: Michael KaupCornelius WolffHyerim HwangJulius MayerElia Bruni</p>
                <p><a href="http://arxiv.org/abs/2407.08590v1">Link to paper</a></p>
                <p>We present a review of popular simulation engines and frameworks used inreinforcement learning RL research aiming to guide researchers in selectingtools for creating simulated physical environments for RL and training setups.It evaluates nine frameworks Brax Chrono Gazebo MuJoCo ODE PhysXPyBullet Webots and Unity based on their popularity feature range qualityusability and RL capabilities. We highlight the challenges in selecting andutilizing physics engines for RL research including the need for detailedcomparisons and an understanding of each frameworks capabilities. Key findingsindicate MuJoCo as the leading framework due to its performance andflexibility despite usability challenges. Unity is noted for its ease of usebut lacks scalability and simulation fidelity. The study calls for furtherdevelopment to improve simulation engines usability and performance andstresses the importance of transparency and reproducibility in RL research.This review contributes to the RL community by offering insights into theselection process for simulation engines facilitating informeddecision-making.</p>
                <p>Last Updated: 2024-07-11 15:13:28 UTC</p>
                <button class="interpret-button" data-id="2407.08590v1">Interpret</button>
                <div id="interpretation-2407.08590v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility</h3>
                <p>Authors: Yuchen XiaJize ZhangNasser JazdiMichael Weyrich</p>
                <p><a href="http://dx.doi.org/10.51202/9783181024379">Link to paper</a></p>
                <p>This paper introduces a novel approach to integrating large language modelLLM agents into automated production systems aimed at enhancing taskautomation and flexibility. We organize production operations within ahierarchical framework based on the automation pyramid. Atomic operationfunctionalities are modeled as microservices which are executed throughinterface invocation within a dedicated digital twin system. This allows for ascalable and flexible foundation for orchestrating production processes. Inthis digital twin system low-level hardware-specific data is semanticallyenriched and made interpretable for LLMs for production planning and controltasks. Large language model agents are systematically prompted to interpretthese production-specific data and knowledge. Upon receiving a user request oridentifying a triggering event the LLM agents generate a process plan. Thisplan is then decomposed into a series of atomic operations executed asmicroservices within the real-world automation system. We implement thisoverall approach on an automated modular production facility at our laboratorydemonstrating how the LLMs can handle production planning and control tasksthrough a concrete case study. This results in an intuitive production facilitywith higher levels of task automation and flexibility. Finally we reveal theseveral limitations in realizing the full potential of the large languagemodels in autonomous systems and point out promising benefits. Demos of thisseries of ongoing research series can be accessed at:https://github.com/YuchenXia/GPT4IndustrialAutomation</p>
                <p>Last Updated: 2024-07-11 14:34:43 UTC</p>
                <button class="interpret-button" data-id="2407.08550v1">Interpret</button>
                <div id="interpretation-2407.08550v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>United We Stand: Decentralized Multi-Agent Planning With Attrition</h3>
                <p>Authors: Nhat NguyenDuong NguyenGianluca RizzoHung Nguyen</p>
                <p><a href="http://arxiv.org/abs/2407.08254v1">Link to paper</a></p>
                <p>Decentralized planning is a key element of cooperative multi-agent systemsfor information gathering tasks. However despite the high frequency of agentfailures in realistic large deployment scenarios current approaches performpoorly in the presence of failures by not converging at all and/or by makingvery inefficient use of resources e.g. energy. In this work we proposeAttritable MCTS A-MCTS a decentralized MCTS algorithm capable of timely andefficient adaptation to changes in the set of active agents. It is based on theuse of a global reward function for the estimation of each agents localcontribution and regret matching for coordination. We evaluate itseffectiveness in realistic data-harvesting problems under different scenarios.We show both theoretically and experimentally that A-MCTS enables efficientadaptation even under high failure rates. Results suggest that in the presenceof frequent failures our solution improves substantially over the bestexisting approaches in terms of global utility and scalability.</p>
                <p>Last Updated: 2024-07-11 07:55:50 UTC</p>
                <button class="interpret-button" data-id="2407.08254v1">Interpret</button>
                <div id="interpretation-2407.08254v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>Adaptive Prediction Ensemble: Improving Out-of-Distribution Generalization of Motion Forecasting</h3>
                <p>Authors: Jinning LiJiachen LiSangjae BaeDavid Isele</p>
                <p><a href="http://arxiv.org/abs/2407.09475v1">Link to paper</a></p>
                <p>Deep learning-based trajectory prediction models for autonomous driving oftenstruggle with generalization to out-of-distribution OOD scenarios sometimesperforming worse than simple rule-based models. To address this limitation wepropose a novel framework Adaptive Prediction Ensemble APE which integratesdeep learning and rule-based prediction experts. A learned routing functiontrained concurrently with the deep learning model dynamically selects the mostreliable prediction based on the input scenario. Our experiments on large-scaledatasets including Waymo Open Motion Dataset WOMD and Argoverse demonstrateimprovement in zero-shot generalization across datasets. We show that ourmethod outperforms individual prediction models and other variantsparticularly in long-horizon prediction and scenarios with a high proportion ofOOD data. This work highlights the potential of hybrid approaches for robustand generalizable motion prediction in autonomous driving.</p>
                <p>Last Updated: 2024-07-12 17:57:00 UTC</p>
                <button class="interpret-button" data-id="2407.09475v1">Interpret</button>
                <div id="interpretation-2407.09475v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Beyond Euclid: An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structures</h3>
                <p>Authors: Sophia SanbornJohan MatheMathilde PapillonDomas BuracasHansen J LillemarkChristian ShewmakeAbby BerticsXavier PennecNina Miolane</p>
                <p><a href="http://arxiv.org/abs/2407.09468v1">Link to paper</a></p>
                <p>The enduring legacy of Euclidean geometry underpins classical machinelearning which for decades has been primarily developed for data lying inEuclidean space. Yet modern machine learning increasingly encounters richlystructured data that is inherently nonEuclidean. This data can exhibitintricate geometric topological and algebraic structure: from the geometry ofthe curvature of space-time to topologically complex interactions betweenneurons in the brain to the algebraic transformations describing symmetries ofphysical systems. Extracting knowledge from such non-Euclidean datanecessitates a broader mathematical perspective. Echoing the 19th-centuryrevolutions that gave rise to non-Euclidean geometry an emerging line ofresearch is redefining modern machine learning with non-Euclidean structures.Its goal: generalizing classical methods to unconventional data types withgeometry topology and algebra. In this review we provide an accessiblegateway to this fast-growing field and propose a graphical taxonomy thatintegrates recent advances into an intuitive unified framework. We subsequentlyextract insights into current challenges and highlight exciting opportunitiesfor future development in this field.</p>
                <p>Last Updated: 2024-07-12 17:48:36 UTC</p>
                <button class="interpret-button" data-id="2407.09468v1">Interpret</button>
                <div id="interpretation-2407.09468v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Weight Block Sparsity: Training, Compilation, and AI Engine Accelerators</h3>
                <p>Authors: Paolo D'AlbertoTaehee JeongAkshai JainShreyas ManjunathMrinal SarmahSamuel Hsu Yaswanth RapartiNitesh Pipralia</p>
                <p><a href="http://arxiv.org/abs/2407.09453v1">Link to paper</a></p>
                <p>Nowadays increasingly larger Deep Neural Networks DNNs are beingdeveloped trained and utilized. These networks require significantcomputational resources putting a strain on both advanced and limited devices.Our solution is to implement em weight block sparsity which is a structuredsparsity that is friendly to hardware. By zeroing certain sections of theconvolution and fully connected layers parameters of pre-trained DNN models wecan efficiently speed up the DNNs inference process. This results in a smallermemory footprint faster communication and fewer operations.  Our work presents a vertical system that allows for the training ofconvolution and matrix multiplication weights to exploit 8x8 block sparsity ona single GPU within a reasonable amount of time. Compilers recognize thissparsity and use it for both data compaction and computation splitting intothreads. Blocks like these take full advantage of both spatial and temporallocality paving the way for fast vector operations and memory reuse. By usingthis system on a Resnet50 model we were able to reduce the weight by half withminimal accuracy loss resulting in a two-times faster inference speed. We willpresent performance estimates using accurate and complete code generation forAIE2 configuration sets AMD Versal FPGAs with Resnet50 Inception V3 andVGG16 to demonstrate the necessary synergy between hardware overlay designs andsoftware stacks for compiling and executing machine learning applications.</p>
                <p>Last Updated: 2024-07-12 17:37:49 UTC</p>
                <button class="interpret-button" data-id="2407.09453v1">Interpret</button>
                <div id="interpretation-2407.09453v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Human-like Episodic Memory for Infinite Context LLMs</h3>
                <p>Authors: Zafeirios FountasMartin A BenfeghoulAdnan OomerjeeFenia ChristopoulouGerasimos LampourasHaitham Bou-AmmarJun Wang</p>
                <p><a href="http://arxiv.org/abs/2407.09450v1">Link to paper</a></p>
                <p>Large language models LLMs have shown remarkable capabilities but stillstruggle with processing extensive contexts limiting their ability to maintaincoherence and accuracy over long sequences. In contrast the human brain excelsat organising and retrieving episodic experiences across vast temporal scalesspanning a lifetime. In this work we introduce EM-LLM a novel approach thatintegrates key aspects of human episodic memory and event cognition into LLMsenabling them to effectively handle practically infinite context lengths whilemaintaining computational efficiency. EM-LLM organises sequences of tokens intocoherent episodic events using a combination of Bayesian surprise andgraph-theoretic boundary refinement in an on-line fashion. When needed theseevents are retrieved through a two-stage memory process combiningsimilarity-based and temporally contiguous retrieval for efficient andhuman-like access to relevant information. Experiments on the LongBench datasetdemonstrate EM-LLMs superior performance outperforming the state-of-the-artInfLLM model with an overall relative improvement of 4.3 across various tasksincluding a 33 improvement on the PassageRetrieval task. Furthermore ouranalysis reveals strong correlations between EM-LLMs event segmentation andhuman-perceived events suggesting a bridge between this artificial system andits biological counterpart. This work not only advances LLM capabilities inprocessing extended contexts but also provides a computational framework forexploring human memory mechanisms opening new avenues for interdisciplinaryresearch in AI and cognitive science.</p>
                <p>Last Updated: 2024-07-12 17:34:03 UTC</p>
                <button class="interpret-button" data-id="2407.09450v1">Interpret</button>
                <div id="interpretation-2407.09450v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The $μ\mathcal{G}$ Language for Programming Graph Neural Networks</h3>
                <p>Authors: Matteo BelenchiaFlavio CorradiniMichela QuadriniMichele Loreti</p>
                <p><a href="http://arxiv.org/abs/2407.09441v1">Link to paper</a></p>
                <p>Graph neural networks form a class of deep learning architecturesspecifically designed to work with graph-structured data. As such they sharethe inherent limitations and problems of deep learning especially regardingthe issues of explainability and trustworthiness. We propose mumathcalGan original domain-specific language for the specification of graph neuralnetworks that aims to overcome these issues. The languages syntax isintroduced and its meaning is rigorously defined by a denotational semantics.An equivalent characterization in the form of an operational semantics is alsoprovided and together with a type system is used to prove the type soundnessof mumathcalG. We show how mumathcalG programs can be representedin a more user-friendly graphical visualization and provide examples of itsgenerality by showing how it can be used to define some of the most populargraph neural network models or to develop any custom graph processingapplication.</p>
                <p>Last Updated: 2024-07-12 17:27:43 UTC</p>
                <button class="interpret-button" data-id="2407.09441v1">Interpret</button>
                <div id="interpretation-2407.09441v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>Adaptive Prediction Ensemble: Improving Out-of-Distribution Generalization of Motion Forecasting</h3>
                <p>Authors: Jinning LiJiachen LiSangjae BaeDavid Isele</p>
                <p><a href="http://arxiv.org/abs/2407.09475v1">Link to paper</a></p>
                <p>Deep learning-based trajectory prediction models for autonomous driving oftenstruggle with generalization to out-of-distribution OOD scenarios sometimesperforming worse than simple rule-based models. To address this limitation wepropose a novel framework Adaptive Prediction Ensemble APE which integratesdeep learning and rule-based prediction experts. A learned routing functiontrained concurrently with the deep learning model dynamically selects the mostreliable prediction based on the input scenario. Our experiments on large-scaledatasets including Waymo Open Motion Dataset WOMD and Argoverse demonstrateimprovement in zero-shot generalization across datasets. We show that ourmethod outperforms individual prediction models and other variantsparticularly in long-horizon prediction and scenarios with a high proportion ofOOD data. This work highlights the potential of hybrid approaches for robustand generalizable motion prediction in autonomous driving.</p>
                <p>Last Updated: 2024-07-12 17:57:00 UTC</p>
                <button class="interpret-button" data-id="2407.09475v1">Interpret</button>
                <div id="interpretation-2407.09475v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>StyleSplat: 3D Object Style Transfer with Gaussian Splatting</h3>
                <p>Authors: Sahil JainAvik KuthialaPrabhdeep Singh SethiPrakanshul Saxena</p>
                <p><a href="http://arxiv.org/abs/2407.09473v1">Link to paper</a></p>
                <p>Recent advancements in radiance fields have opened new avenues for creatinghigh-quality 3D assets and scenes. Style transfer can enhance these 3D assetswith diverse artistic styles transforming creative expression. Howeverexisting techniques are often slow or unable to localize style transfer tospecific objects. We introduce StyleSplat a lightweight method for stylizing3D objects in scenes represented by 3D Gaussians from reference style images.Our approach first learns a photorealistic representation of the scene using 3DGaussian splatting while jointly segmenting individual 3D objects. We then usea nearest-neighbor feature matching loss to finetune the Gaussians of theselected objects aligning their spherical harmonic coefficients with the styleimage to ensure consistency and visual appeal. StyleSplat allows for quickcustomizable style transfer and localized stylization of multiple objectswithin a scene each with a different style. We demonstrate its effectivenessacross various 3D scenes and styles showcasing enhanced control andcustomization in 3D creation.</p>
                <p>Last Updated: 2024-07-12 17:55:08 UTC</p>
                <button class="interpret-button" data-id="2407.09473v1">Interpret</button>
                <div id="interpretation-2407.09473v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Let Me DeCode You: Decoder Conditioning with Tabular Data</h3>
                <p>Authors: Tomasz SzczepańskiMichal K. GrzeszczykSzymon PłotkaArleta AdamowiczPiotr FudalejPrzemysław KorzeniowskiTomasz TrzcińskiArkadiusz Sitek</p>
                <p><a href="http://arxiv.org/abs/2407.09437v1">Link to paper</a></p>
                <p>Training deep neural networks for 3D segmentation tasks can be challengingoften requiring efficient and effective strategies to improve modelperformance. In this study we introduce a novel approach DeCode thatutilizes label-derived features for model conditioning to support the decoderin the reconstruction process dynamically aiming to enhance the efficiency ofthe training process. DeCode focuses on improving 3D segmentation performancethrough the incorporation of conditioning embedding with learned numericalrepresentation of 3D-label shape features. Specifically we develop anapproach where conditioning is applied during the training phase to guide thenetwork toward robust segmentation. When labels are not available duringinference our model infers the necessary conditioning embedding directly fromthe input data thanks to a feed-forward network learned during the trainingphase. This approach is tested using synthetic data and cone-beam computedtomography CBCT images of teeth. For CBCT three datasets are used: onepublicly available and two in-house. Our results show that DeCode significantlyoutperforms traditional unconditioned models in terms of generalization tounseen data achieving higher accuracy at a reduced computational cost. Thiswork represents the first of its kind to explore conditioning strategies in 3Ddata segmentation offering a novel and more efficient method for leveragingannotated data. Our code pre-trained models are publicly available athttps://github.com/SanoScience/DeCode .</p>
                <p>Last Updated: 2024-07-12 17:14:33 UTC</p>
                <button class="interpret-button" data-id="2407.09437v1">Interpret</button>
                <div id="interpretation-2407.09437v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Rethinking temporal self-similarity for repetitive action counting</h3>
                <p>Authors: Yanan LuoJinhui YiYazan Abu FarhaMoritz WolterJuergen Gall</p>
                <p><a href="http://arxiv.org/abs/2407.09431v1">Link to paper</a></p>
                <p>Counting repetitive actions in long untrimmed videos is a challenging taskthat has many applications such as rehabilitation. State-of-the-art methodspredict action counts by first generating a temporal self-similarity matrixTSM from the sampled frames and then feeding the matrix to a predictornetwork. The self-similarity matrix however is not an optimal input to anetwork since it discards too much information from the frame-wise embeddings.We thus rethink how a TSM can be utilized for counting repetitive actions andpropose a framework that learns embeddings and predicts action startprobabilities at full temporal resolution. The number of repeated actions isthen inferred from the action start probabilities. In contrast to currentapproaches that have the TSM as an intermediate representation we propose anovel loss based on a generated reference TSM which enforces that theself-similarity of the learned frame-wise embeddings is consistent with theself-similarity of repeated actions. The proposed framework achievesstate-of-the-art results on three datasets i.e. RepCount UCFRep andCountix.</p>
                <p>Last Updated: 2024-07-12 17:03:14 UTC</p>
                <button class="interpret-button" data-id="2407.09431v1">Interpret</button>
                <div id="interpretation-2407.09431v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers</h3>
                <p>Authors: Shraman PramanickRama ChellappaSubhashini Venugopalan</p>
                <p><a href="http://arxiv.org/abs/2407.09413v1">Link to paper</a></p>
                <p>Seeking answers to questions within long scientific research articles is acrucial area of study that aids readers in quickly addressing their inquiries.However existing question-answering QA datasets based on scientific papersare limited in scale and focus solely on textual content. To address thislimitation we introduce SPIQA Scientific Paper Image Question Answering thefirst large-scale QA dataset specifically designed to interpret complex figuresand tables within the context of scientific research articles across variousdomains of computer science. Leveraging the breadth of expertise and ability ofmultimodal large language models MLLMs to understand figures we employautomatic and manual curation to create the dataset. We craft aninformation-seeking task involving multiple images that cover a wide variety ofplots charts tables schematic diagrams and result visualizations. SPIQAcomprises 270K questions divided into training validation and three differentevaluation splits. Through extensive experiments with 12 prominent foundationalmodels we evaluate the ability of current multimodal systems to comprehend thenuanced aspects of research articles. Additionally we propose aChain-of-Thought CoT evaluation strategy with in-context retrieval thatallows fine-grained step-by-step assessment and improves model performance. Wefurther explore the upper bounds of performance enhancement with additionaltextual information highlighting its promising potential for future researchand the datasets impact on revolutionizing how we interact with scientificliterature.</p>
                <p>Last Updated: 2024-07-12 16:37:59 UTC</p>
                <button class="interpret-button" data-id="2407.09413v1">Interpret</button>
                <div id="interpretation-2407.09413v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>Adaptive Prediction Ensemble: Improving Out-of-Distribution Generalization of Motion Forecasting</h3>
                <p>Authors: Jinning LiJiachen LiSangjae BaeDavid Isele</p>
                <p><a href="http://arxiv.org/abs/2407.09475v1">Link to paper</a></p>
                <p>Deep learning-based trajectory prediction models for autonomous driving oftenstruggle with generalization to out-of-distribution OOD scenarios sometimesperforming worse than simple rule-based models. To address this limitation wepropose a novel framework Adaptive Prediction Ensemble APE which integratesdeep learning and rule-based prediction experts. A learned routing functiontrained concurrently with the deep learning model dynamically selects the mostreliable prediction based on the input scenario. Our experiments on large-scaledatasets including Waymo Open Motion Dataset WOMD and Argoverse demonstrateimprovement in zero-shot generalization across datasets. We show that ourmethod outperforms individual prediction models and other variantsparticularly in long-horizon prediction and scenarios with a high proportion ofOOD data. This work highlights the potential of hybrid approaches for robustand generalizable motion prediction in autonomous driving.</p>
                <p>Last Updated: 2024-07-12 17:57:00 UTC</p>
                <button class="interpret-button" data-id="2407.09475v1">Interpret</button>
                <div id="interpretation-2407.09475v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3</h3>
                <p>Authors: Georgios MakridisAthanasios OikonomouVasileios Koukos</p>
                <p><a href="http://arxiv.org/abs/2407.09467v1">Link to paper</a></p>
                <p>In the diverse world of AI-driven storytelling there is a unique opportunityto engage young audiences with customized and personalized narratives. Thispaper introduces FairyLandAI an innovative Large Language Model LLM developedthrough OpenAIs API specifically crafted to create personalized fairytalesfor children. The distinctive feature of FairyLandAI is its dual capability: itnot only generates stories that are engaging age-appropriate and reflectiveof various traditions but also autonomously produces imaginative promptssuitable for advanced image generation tools like GenAI and Dalle-3 therebyenriching the storytelling experience. FairyLandAI is expertly tailored toresonate with the imaginative worlds of children providing narratives that areboth educational and entertaining and in alignment with the moral valuesinherent in different ages. Its unique strength lies in customizing stories tomatch individual childrens preferences and cultural backgrounds heralding anew era in personalized storytelling. Further its integration with imagegeneration technology offers a comprehensive narrative experience thatstimulates both verbal and visual creativity. Empirical evaluations ofFairyLandAI demonstrate its effectiveness in crafting captivating stories forchildren which not only entertain but also embody the values and teachings ofdiverse traditions. This model serves as an invaluable tool for parents andeducators supporting them in imparting meaningful moral lessons throughengaging narratives. FairyLandAI represents a pioneering step in using LLMsparticularly through OpenAIs API for educational and cultural enrichmentmaking complex moral narratives accessible and enjoyable for young imaginativeminds.</p>
                <p>Last Updated: 2024-07-12 17:46:58 UTC</p>
                <button class="interpret-button" data-id="2407.09467v1">Interpret</button>
                <div id="interpretation-2407.09467v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Human-like Episodic Memory for Infinite Context LLMs</h3>
                <p>Authors: Zafeirios FountasMartin A BenfeghoulAdnan OomerjeeFenia ChristopoulouGerasimos LampourasHaitham Bou-AmmarJun Wang</p>
                <p><a href="http://arxiv.org/abs/2407.09450v1">Link to paper</a></p>
                <p>Large language models LLMs have shown remarkable capabilities but stillstruggle with processing extensive contexts limiting their ability to maintaincoherence and accuracy over long sequences. In contrast the human brain excelsat organising and retrieving episodic experiences across vast temporal scalesspanning a lifetime. In this work we introduce EM-LLM a novel approach thatintegrates key aspects of human episodic memory and event cognition into LLMsenabling them to effectively handle practically infinite context lengths whilemaintaining computational efficiency. EM-LLM organises sequences of tokens intocoherent episodic events using a combination of Bayesian surprise andgraph-theoretic boundary refinement in an on-line fashion. When needed theseevents are retrieved through a two-stage memory process combiningsimilarity-based and temporally contiguous retrieval for efficient andhuman-like access to relevant information. Experiments on the LongBench datasetdemonstrate EM-LLMs superior performance outperforming the state-of-the-artInfLLM model with an overall relative improvement of 4.3 across various tasksincluding a 33 improvement on the PassageRetrieval task. Furthermore ouranalysis reveals strong correlations between EM-LLMs event segmentation andhuman-perceived events suggesting a bridge between this artificial system andits biological counterpart. This work not only advances LLM capabilities inprocessing extended contexts but also provides a computational framework forexploring human memory mechanisms opening new avenues for interdisciplinaryresearch in AI and cognitive science.</p>
                <p>Last Updated: 2024-07-12 17:34:03 UTC</p>
                <button class="interpret-button" data-id="2407.09450v1">Interpret</button>
                <div id="interpretation-2407.09450v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The $μ\mathcal{G}$ Language for Programming Graph Neural Networks</h3>
                <p>Authors: Matteo BelenchiaFlavio CorradiniMichela QuadriniMichele Loreti</p>
                <p><a href="http://arxiv.org/abs/2407.09441v1">Link to paper</a></p>
                <p>Graph neural networks form a class of deep learning architecturesspecifically designed to work with graph-structured data. As such they sharethe inherent limitations and problems of deep learning especially regardingthe issues of explainability and trustworthiness. We propose mumathcalGan original domain-specific language for the specification of graph neuralnetworks that aims to overcome these issues. The languages syntax isintroduced and its meaning is rigorously defined by a denotational semantics.An equivalent characterization in the form of an operational semantics is alsoprovided and together with a type system is used to prove the type soundnessof mumathcalG. We show how mumathcalG programs can be representedin a more user-friendly graphical visualization and provide examples of itsgenerality by showing how it can be used to define some of the most populargraph neural network models or to develop any custom graph processingapplication.</p>
                <p>Last Updated: 2024-07-12 17:27:43 UTC</p>
                <button class="interpret-button" data-id="2407.09441v1">Interpret</button>
                <div id="interpretation-2407.09441v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Let Me DeCode You: Decoder Conditioning with Tabular Data</h3>
                <p>Authors: Tomasz SzczepańskiMichal K. GrzeszczykSzymon PłotkaArleta AdamowiczPiotr FudalejPrzemysław KorzeniowskiTomasz TrzcińskiArkadiusz Sitek</p>
                <p><a href="http://arxiv.org/abs/2407.09437v1">Link to paper</a></p>
                <p>Training deep neural networks for 3D segmentation tasks can be challengingoften requiring efficient and effective strategies to improve modelperformance. In this study we introduce a novel approach DeCode thatutilizes label-derived features for model conditioning to support the decoderin the reconstruction process dynamically aiming to enhance the efficiency ofthe training process. DeCode focuses on improving 3D segmentation performancethrough the incorporation of conditioning embedding with learned numericalrepresentation of 3D-label shape features. Specifically we develop anapproach where conditioning is applied during the training phase to guide thenetwork toward robust segmentation. When labels are not available duringinference our model infers the necessary conditioning embedding directly fromthe input data thanks to a feed-forward network learned during the trainingphase. This approach is tested using synthetic data and cone-beam computedtomography CBCT images of teeth. For CBCT three datasets are used: onepublicly available and two in-house. Our results show that DeCode significantlyoutperforms traditional unconditioned models in terms of generalization tounseen data achieving higher accuracy at a reduced computational cost. Thiswork represents the first of its kind to explore conditioning strategies in 3Ddata segmentation offering a novel and more efficient method for leveragingannotated data. Our code pre-trained models are publicly available athttps://github.com/SanoScience/DeCode .</p>
                <p>Last Updated: 2024-07-12 17:14:33 UTC</p>
                <button class="interpret-button" data-id="2407.09437v1">Interpret</button>
                <div id="interpretation-2407.09437v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Meta-Analysis with Untrusted Data</h3>
                <p>Authors: Shiva KaulGeoffrey J. Gordon</p>
                <p><a href="http://arxiv.org/abs/2407.09387v1">Link to paper</a></p>
                <p>See paper for full abstract Meta-analysis is a crucial tool for answeringscientific questions. It is usually conducted on a relatively small amount oftrusted data -- ideally from randomized controlled trials -- which allowcausal effects to be reliably estimated with minimal assumptions. We show howto answer causal questions much more precisely by making two changes. First weincorporate untrusted data drawn from large observational databases relatedscientific literature and practical experience -- without sacrificing rigor orintroducing strong assumptions. Second we train richer models capable ofhandling heterogeneous trials addressing a long-standing challenge inmeta-analysis. Our approach is based on conformal prediction whichfundamentally produces rigorous prediction intervals but doesnt handleindirect observations: in meta-analysis we observe only noisy effects due tothe limited number of participants in each trial. To handle noise we develop asimple efficient version of fully-conformal kernel ridge regression based ona novel condition called idiocentricity. We introduce noise-correcting terms inthe residuals and analyze their interaction with a variance shavingtechnique. In multiple experiments on healthcare datasets our algorithmsdeliver tighter sounder intervals than traditional ones. This paper charts anew course for meta-analysis and evidence-based medicine where heterogeneityand untrusted data are embraced for more nuanced and precise predictions.</p>
                <p>Last Updated: 2024-07-12 16:07:53 UTC</p>
                <button class="interpret-button" data-id="2407.09387v1">Interpret</button>
                <div id="interpretation-2407.09387v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Graph Neural Network Causal Explanation via Neural Causal Models</h3>
                <p>Authors: Arman BehnamBinghui Wang</p>
                <p><a href="http://arxiv.org/abs/2407.09378v1">Link to paper</a></p>
                <p>Graph neural network GNN explainers identify the important subgraph thatensures the prediction for a given graph. Until now almost all GNN explainersare based on association which is prone to spurious correlations. We proposename a GNN causal explainer via causal inference. Our explainer is based onthe observation that a graph often consists of a causal underlying subgraph.name includes three main steps: 1 It builds causal structure and thecorresponding structural causal model SCM for a graph which enables thecause-effect calculation among nodes. 2 Directly calculating the cause-effectin real-world graphs is computationally challenging. It is then enlightened bythe recent neural causal model NCM a special type of SCM that is trainableand design customized NCMs for GNNs. By training these GNN NCMs thecause-effect can be easily calculated. 3 It uncovers the subgraph thatcausally explains the GNN predictions via the optimized GNN-NCMs. Evaluationresults on multiple synthetic and real-world graphs validate that namesignificantly outperforms existing GNN explainers in exact groundtruthexplanation identification</p>
                <p>Last Updated: 2024-07-12 15:56:33 UTC</p>
                <button class="interpret-button" data-id="2407.09378v1">Interpret</button>
                <div id="interpretation-2407.09378v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>HiPPO-Prophecy: State-Space Models can Provably Learn Dynamical Systems in Context</h3>
                <p>Authors: Federico Arangath JosephKilian HaefeliNoah LinigerCaglar Gulcehre</p>
                <p><a href="http://arxiv.org/abs/2407.09375v1">Link to paper</a></p>
                <p>This work explores the in-context learning capabilities of State Space ModelsSSMs and presents to the best of our knowledge the first theoreticalexplanation of a possible underlying mechanism. We introduce a novel weightconstruction for SSMs enabling them to predict the next state of any dynamicalsystem after observing previous states without parameter fine-tuning. This isaccomplished by extending the HiPPO framework to demonstrate that continuousSSMs can approximate the derivative of any input signal. Specifically we findan explicit weight construction for continuous SSMs and provide an asymptoticerror bound on the derivative approximation. The discretization of thiscontinuous SSM subsequently yields a discrete SSM that predicts the next state.Finally we demonstrate the effectiveness of our parameterization empirically.This work should be an initial step toward understanding how sequence modelsbased on SSMs learn in context.</p>
                <p>Last Updated: 2024-07-12 15:56:11 UTC</p>
                <button class="interpret-button" data-id="2407.09375v1">Interpret</button>
                <div id="interpretation-2407.09375v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Learning Distances from Data with Normalizing Flows and Score Matching</h3>
                <p>Authors: Peter SorrensonDaniel Behrend-UriarteChristoph SchnörrUllrich Köthe</p>
                <p><a href="http://arxiv.org/abs/2407.09297v1">Link to paper</a></p>
                <p>Density-based distances DBDs offer an elegant solution to the problem ofmetric learning. By defining a Riemannian metric which increases withdecreasing probability density shortest paths naturally follow the datamanifold and points are clustered according to the modes of the data. We showthat existing methods to estimate Fermat distances a particular choice of DBDsuffer from poor convergence in both low and high dimensions due to iinaccurate density estimates and ii reliance on graph-based paths which areincreasingly rough in high dimensions. To address these issues we proposelearning the densities using a normalizing flow a generative model withtractable density estimation and employing a smooth relaxation method using ascore model initialized from a graph-based proposal. Additionally we introducea dimension-adapted Fermat distance that exhibits more intuitive behavior whenscaled to high dimensions and offers better numerical properties. Our workpaves the way for practical use of density-based distances especially inhigh-dimensional spaces.</p>
                <p>Last Updated: 2024-07-12 14:30:41 UTC</p>
                <button class="interpret-button" data-id="2407.09297v1">Interpret</button>
                <div id="interpretation-2407.09297v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Variational Inference via Smoothed Particle Hydrodynamics</h3>
                <p>Authors: Yongchao Huang</p>
                <p><a href="http://arxiv.org/abs/2407.09186v1">Link to paper</a></p>
                <p>A new variational inference method SPH-ParVI based on smoothed particlehydrodynamics SPH is proposed for sampling partially known densities e.g.up to a constant or sampling using gradients. SPH-ParVI simulates the flow ofa fluid under external effects driven by the target density transient orsteady state of the fluid approximates the target density. The continuum fluidis modelled as an interacting particle system IPS via SPH where eachparticle carries smoothed properties interacts and evolves as per theNavier-Stokes equations. This mesh-free Lagrangian simulation method offersfast flexible scalable and deterministic sampling and inference for a classof probabilistic models such as those encountered in Bayesian inference andgenerative modelling.</p>
                <p>Last Updated: 2024-07-12 11:38:41 UTC</p>
                <button class="interpret-button" data-id="2407.09186v1">Interpret</button>
                <div id="interpretation-2407.09186v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-07-15</p>
        </div>
    
        </div>
    </body>
    </html>
    