
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning</h3>
                <p>Authors: Greg d'EonNeil NewmanKevin Leyton-Brown</p>
                <p><a href="http://arxiv.org/abs/2402.19420v1">Link to paper</a></p>
                <p>Iterative combinatorial auctions are widely used in high stakes settings suchas spectrum auctions. Such auctions can be hard to understand analyticallymaking it difficult for bidders to determine how to behave and for designers tooptimize auction rules to ensure desirable outcomes such as high revenue orwelfare. In this paper we investigate whether multi-agent reinforcementlearning MARL algorithms can be used to understand iterative combinatorialauctions given that these algorithms have recently shown empirical success inseveral other domains. We find that MARL can indeed benefit auction analysisbut that deploying it effectively is nontrivial. We begin by describingmodelling decisions that keep the resulting game tractable without sacrificingimportant features such as imperfect information or asymmetry between bidders.We also discuss how to navigate pitfalls of various MARL algorithms how toovercome challenges in verifying convergence and how to generate and interpretmultiple equilibria. We illustrate the promise of our resulting approach byusing it to evaluate a specific rule change to a clock auction findingsubstantially different auction outcomes due to complex changes in biddersbehavior.</p>
                <p>Last Updated: 2024-02-29 18:16:13 UTC</p>
                <button class="interpret-button" data-id="2402.19420v1">Interpret</button>
                <div id="interpretation-2402.19420v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>ARMCHAIR: integrated inverse reinforcement learning and model predictive control for human-robot collaboration</h3>
                <p>Authors: Angelo Caregnato-NetoLuciano Cavalcante SiebertArkady ZgonnikovMarcos Ricardo Omena de Albuquerque MaximoRubens Junqueira Magalhães Afonso</p>
                <p><a href="http://arxiv.org/abs/2402.19128v1">Link to paper</a></p>
                <p>One of the key issues in human-robot collaboration is the development ofcomputational models that allow robots to predict and adapt to human behavior.Much progress has been achieved in developing such models as well as controltechniques that address the autonomy problems of motion planning anddecision-making in robotics. However the integration of computational modelsof human behavior with such control techniques still poses a major challengeresulting in a bottleneck for efficient collaborative human-robot teams. Inthis context we present a novel architecture for human-robot collaboration:Adaptive Robot Motion for Collaboration with Humans using Adversarial InverseReinforcement learning ARMCHAIR. Our solution leverages adversarial inversereinforcement learning and model predictive control to compute optimaltrajectories and decisions for a mobile multi-robot system that collaborateswith a human in an exploration task. During the mission ARMCHAIR operateswithout human intervention autonomously identifying the necessity to supportand acting accordingly. Our approach also explicitly addresses the networkconnectivity requirement of the human-robot team. Extensive simulation-basedevaluations demonstrate that ARMCHAIR allows a group of robots to safelysupport a simulated human in an exploration scenario preventing collisions andnetwork disconnections and improving the overall performance of the task.</p>
                <p>Last Updated: 2024-02-29 13:06:14 UTC</p>
                <button class="interpret-button" data-id="2402.19128v1">Interpret</button>
                <div id="interpretation-2402.19128v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Facility Location Games with Scaling Effects</h3>
                <p>Authors: Yu HeAlexander LamMinming Li</p>
                <p><a href="http://arxiv.org/abs/2402.18908v1">Link to paper</a></p>
                <p>We take the classic facility location problem and consider a variation inwhich each agents individual cost function is equal to their distance from thefacility multiplied by a scaling factor which is determined by the facilityplacement. In addition to the general class of continuous scaling functions wealso provide results for piecewise linear scaling functions which caneffectively approximate or model the scaling of many real world scenarios. Wefocus on the objectives of total and maximum cost describing the computationof the optimal solution. We then move to the approximate mechanism designsetting observing that the agents preferences may no longer be single-peaked.Consequently we characterize the conditions on scaling functions which ensurethat agents have single-peaked preferences. Under these conditions we findresults on the total and maximum cost approximation ratios achievable bystrategyproof and anonymous mechanisms.</p>
                <p>Last Updated: 2024-02-29 07:08:18 UTC</p>
                <button class="interpret-button" data-id="2402.18908v1">Interpret</button>
                <div id="interpretation-2402.18908v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>ELA: Exploited Level Augmentation for Offline Learning in Zero-Sum Games</h3>
                <p>Authors: Shiqi LeiKanghoon LeeLinjing LiJinkyoo ParkJiachen Li</p>
                <p><a href="http://arxiv.org/abs/2402.18617v1">Link to paper</a></p>
                <p>Offline learning has become widely used due to its ability to deriveeffective policies from offline datasets gathered by expert demonstratorswithout interacting with the environment directly. Recent research has exploredvarious ways to enhance offline learning efficiency by considering thecharacteristics e.g. expertise level or multiple demonstrators of thedataset. However a different approach is necessary in the context of zero-sumgames where outcomes vary significantly based on the strategy of the opponent.In this study we introduce a novel approach that uses unsupervised learningtechniques to estimate the exploited level of each trajectory from the offlinedataset of zero-sum games made by diverse demonstrators. Subsequently weincorporate the estimated exploited level into the offline learning to maximizethe influence of the dominant strategy. Our method enables interpretableexploited level estimation in multiple zero-sum games and effectivelyidentifies dominant strategy data. Also our exploited level augmented offlinelearning significantly enhances the original offline learning algorithmsincluding imitation learning and offline reinforcement learning for zero-sumgames.</p>
                <p>Last Updated: 2024-02-28 17:44:02 UTC</p>
                <button class="interpret-button" data-id="2402.18617v1">Interpret</button>
                <div id="interpretation-2402.18617v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning</h3>
                <p>Authors: Zeyang LiuLipeng WanXinrui YangZhuoran ChenXingyu ChenXuguang Lan</p>
                <p><a href="http://arxiv.org/abs/2402.17978v1">Link to paper</a></p>
                <p>Effective exploration is crucial to discovering optimal strategies formulti-agent reinforcement learning MARL in complex coordination tasks.Existing methods mainly utilize intrinsic rewards to enable committedexploration or use role-based learning for decomposing joint action spacesinstead of directly conducting a collective search in the entireaction-observation space. However they often face challenges obtainingspecific joint action sequences to reach successful states in long-horizontasks. To address this limitation we propose Imagine Initialize and ExploreIIE a novel method that offers a promising solution for efficientmulti-agent exploration in complex scenarios. IIE employs a transformer modelto imagine how the agents reach a critical state that can influence eachothers transition functions. Then we initialize the environment at this stateusing a simulator before the exploration phase. We formulate the imagination asa sequence modeling problem where the states observations prompts actionsand rewards are predicted autoregressively. The prompt consists oftimestep-to-go return-to-go influence value and one-shot demonstrationspecifying the desired state and trajectory as well as guiding the actiongeneration. By initializing agents at the critical states IIE significantlyincreases the likelihood of discovering potentially important under-exploredregions. Despite its simplicity empirical results demonstrate that our methodoutperforms multi-agent exploration baselines on the StarCraft Multi-AgentChallenge SMAC and SMACv2 environments. Particularly IIE shows improvedperformance in the sparse-reward SMAC tasks and produces more effectivecurricula over the initialized states than other generative methods such asCVAE-GAN and diffusion models.</p>
                <p>Last Updated: 2024-02-28 01:45:01 UTC</p>
                <button class="interpret-button" data-id="2402.17978v1">Interpret</button>
                <div id="interpretation-2402.17978v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?</h3>
                <p>Authors: Alex GuWen-Ding LiNaman JainTheo X. OlaussonCeline LeeKoushik SenArmando Solar-Lezama</p>
                <p><a href="http://arxiv.org/abs/2402.19475v1">Link to paper</a></p>
                <p>While language models are increasingly more proficient at code generationthey still frequently generate incorrect programs. Many of these programs areobviously wrong but others are more subtle and pass weaker correctness checkssuch as being able to compile. In this work we focus on these counterfeitsamples: programs sampled from a language model that 1 have a high enoughlog-probability to be generated at a moderate temperature and 2 pass weakcorrectness checks. Overall we discover that most models have a very shallowunderstanding of counterfeits through three clear failure modes. First modelsmistakenly classify them as correct. Second models are worse at reasoningabout the execution behaviour of counterfeits and often predict their executionresults as if they were correct. Third when asking models to fix counterfeitsthe likelihood of a model successfully repairing a counterfeit is often evenlower than that of sampling a correct program from scratch. Counterfeits alsohave very unexpected properties: first counterfeit programs for problems thatare easier for a model to solve are not necessarily easier to detect and onlyslightly easier to execute and repair. Second counterfeits from a given modelare just as confusing to the model itself as they are to other models. Finallyboth strong and weak models are able to generate counterfeit samples thatequally challenge all models. In light of our findings we recommend that careand caution be taken when relying on models to understand their own samplesespecially when no external feedback is incorporated.</p>
                <p>Last Updated: 2024-02-29 18:59:25 UTC</p>
                <button class="interpret-button" data-id="2402.19475v1">Interpret</button>
                <div id="interpretation-2402.19475v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling</h3>
                <p>Authors: Gabriel GrandValerio PepeJacob AndreasJoshua B. Tenenbaum</p>
                <p><a href="http://arxiv.org/abs/2402.19471v1">Link to paper</a></p>
                <p>Questions combine our mastery of language with our remarkable facility forreasoning about uncertainty. How do people navigate vast hypothesis spaces topose informative questions given limited cognitive resources We study thesetradeoffs in a classic grounded question-asking task based on the board gameBattleship. Our language-informed program sampling LIPS model uses largelanguage models LLMs to generate natural language questions translate theminto symbolic programs and evaluate their expected information gain. We findthat with a surprisingly modest resource budget this simple Monte Carlooptimization strategy yields informative questions that mirror humanperformance across varied Battleship board scenarios. In contrast LLM-onlybaselines struggle to ground questions in the board state notably GPT-4Vprovides no improvement over non-visual baselines. Our results illustrate howBayesian models of question-asking can leverage the statistics of language tocapture human priors while highlighting some shortcomings of pure LLMs asgrounded reasoners.</p>
                <p>Last Updated: 2024-02-29 18:58:15 UTC</p>
                <button class="interpret-button" data-id="2402.19471v1">Interpret</button>
                <div id="interpretation-2402.19471v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning</h3>
                <p>Authors: Kate SandersNathaniel WeirBenjamin Van Durme</p>
                <p><a href="http://arxiv.org/abs/2402.19467v1">Link to paper</a></p>
                <p>It is challenging to perform question-answering over complex multimodalcontent such as television clips. This is in part because currentvideo-language models rely on single-modality reasoning have loweredperformance on long inputs and lack interpetability. We propose TV-TREES thefirst multimodal entailment tree generator. TV-TREES serves as an approach tovideo understanding that promotes interpretable joint-modality reasoning byproducing trees of entailment relationships between simple premises directlyentailed by the videos and higher-level conclusions. We then introduce the taskof multimodal entailment tree generation to evaluate the reasoning quality ofsuch methods. Our methods experimental results on the challenging TVQA datasetdemonstrate intepretable state-of-the-art zero-shot performance on full videoclips illustrating a best of both worlds contrast to black-box methods.</p>
                <p>Last Updated: 2024-02-29 18:57:01 UTC</p>
                <button class="interpret-button" data-id="2402.19467v1">Interpret</button>
                <div id="interpretation-2402.19467v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models</h3>
                <p>Authors: Chen QianJie ZhangWei YaoDongrui LiuZhenfei YinYu QiaoYong LiuJing Shao</p>
                <p><a href="http://arxiv.org/abs/2402.19465v1">Link to paper</a></p>
                <p>Ensuring the trustworthiness of large language models LLMs is crucial. Moststudies concentrate on fully pre-trained LLMs to better understand and improveLLMs trustworthiness. In this paper to reveal the untapped potential ofpre-training we pioneer the exploration of LLMs trustworthiness during thisperiod focusing on five key dimensions: reliability privacy toxicityfairness and robustness. To begin with we apply linear probing to LLMs. Thehigh probing accuracy suggests that textitLLMs in early pre-training canalready distinguish concepts in each trustworthiness dimension. Therefore tofurther uncover the hidden possibilities of pre-training we extract steeringvectors from a LLMs pre-training checkpoints to enhance the LLMstrustworthiness. Finally inspired bycitetchoi2023understanding that mutualinformation estimation is bounded by linear probing accuracy we also probeLLMs with mutual information to investigate the dynamics of trustworthinessduring pre-training. We are the first to observe a similar two-phasephenomenon: fitting and compressioncitepshwartz2017opening. This researchprovides an initial exploration of trustworthiness modeling during LLMpre-training seeking to unveil new insights and spur further developments inthe field. We will make our code publicly accessible aturlhttps://github.com/ChnQ/TracingLLM.</p>
                <p>Last Updated: 2024-02-29 18:55:06 UTC</p>
                <button class="interpret-button" data-id="2402.19465v1">Interpret</button>
                <div id="interpretation-2402.19465v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Curiosity-driven Red-teaming for Large Language Models</h3>
                <p>Authors: Zhang-Wei HongIdan ShenfeldTsun-Hsuan WangYung-Sung ChuangAldo ParejaJames GlassAkash SrivastavaPulkit Agrawal</p>
                <p><a href="http://arxiv.org/abs/2402.19464v1">Link to paper</a></p>
                <p>Large language models LLMs hold great potential for many natural languageapplications but risk generating incorrect or toxic content. To probe when anLLM generates unwanted content the current paradigm is to recruit atextitred team of human testers to design input prompts i.e. test casesthat elicit undesirable responses from LLMs. However relying solely on humantesters is expensive and time-consuming. Recent works automate red teaming bytraining a separate red team LLM with reinforcement learning RL to generatetest cases that maximize the chance of eliciting undesirable responses from thetarget LLM. However current RL methods are only able to generate a smallnumber of effective test cases resulting in a low coverage of the span ofprompts that elicit undesirable responses from the target LLM. To overcome thislimitation we draw a connection between the problem of increasing the coverageof generated test cases and the well-studied approach of curiosity-drivenexploration that optimizes for novelty. Our method of curiosity-driven redteaming CRT achieves greater coverage of test cases while mantaining orincreasing their effectiveness compared to existing methods. Our method CRTsuccessfully provokes toxic responses from LLaMA2 model that has been heavilyfine-tuned using human preferences to avoid toxic outputs. Code is available aturlhttps://github.com/Improbable-AI/curiosity_redteam</p>
                <p>Last Updated: 2024-02-29 18:55:03 UTC</p>
                <button class="interpret-button" data-id="2402.19464v1">Interpret</button>
                <div id="interpretation-2402.19464v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks</h3>
                <p>Authors: Bálint MucsányiMichael KirchhofSeong Joon Oh</p>
                <p><a href="http://arxiv.org/abs/2402.19460v1">Link to paper</a></p>
                <p>Uncertainty quantification once a singular task has evolved into a spectrumof tasks including abstained prediction out-of-distribution detection andaleatoric uncertainty quantification. The latest goal is disentanglement: theconstruction of multiple estimators that are each tailored to one and only onetask. Hence there is a plethora of recent advances with different intentions -that often entirely deviate from practical behavior. This paper conducts acomprehensive evaluation of numerous uncertainty estimators across diversetasks on ImageNet. We find that despite promising theoretical endeavorsdisentanglement is not yet achieved in practice. Additionally we reveal whichuncertainty estimators excel at which specific tasks providing insights forpractitioners and guiding future research toward task-centric and disentangleduncertainty estimation methods. Our code is available athttps://github.com/bmucsanyi/bud.</p>
                <p>Last Updated: 2024-02-29 18:52:56 UTC</p>
                <button class="interpret-button" data-id="2402.19460v1">Interpret</button>
                <div id="interpretation-2402.19460v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Listening to the Noise: Blind Denoising with Gibbs Diffusion</h3>
                <p>Authors: David Heurtel-DepeigesCharles C. MargossianRuben OhanaBruno Régaldo-Saint Blancard</p>
                <p><a href="http://arxiv.org/abs/2402.19455v1">Link to paper</a></p>
                <p>In recent years denoising problems have become intertwined with thedevelopment of deep generative models. In particular diffusion models aretrained like denoisers and the distribution they model coincide with denoisingpriors in the Bayesian picture. However denoising through diffusion-basedposterior sampling requires the noise level and covariance to be knownpreventing blind denoising. We overcome this limitation by introducing GibbsDiffusion GDiff a general methodology addressing posterior sampling of boththe signal and the noise parameters. Assuming arbitrary parametric Gaussiannoise we develop a Gibbs algorithm that alternates sampling steps from aconditional diffusion model trained to map the signal prior to the family ofnoise distributions and a Monte Carlo sampler to infer the noise parameters.Our theoretical analysis highlights potential pitfalls guides diagnosticusage and quantifies errors in the Gibbs stationary distribution caused by thediffusion model. We showcase our method for 1 blind denoising of naturalimages involving colored noises with unknown amplitude and spectral index and2 a cosmology problem namely the analysis of cosmic microwave backgrounddata where Bayesian inference of noise parameters means constraining modelsof the evolution of the Universe.</p>
                <p>Last Updated: 2024-02-29 18:50:11 UTC</p>
                <button class="interpret-button" data-id="2402.19455v1">Interpret</button>
                <div id="interpretation-2402.19455v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models</h3>
                <p>Authors: Frederik KunstnerRobin YadavAlan MilliganMark SchmidtAlberto Bietti</p>
                <p><a href="http://arxiv.org/abs/2402.19449v1">Link to paper</a></p>
                <p>Adam has been shown to outperform gradient descent in optimizing largelanguage transformers empirically and by a larger margin than on other tasksbut it is unclear why this happens. We show that the heavy-tailed classimbalance found in language modeling tasks leads to difficulties in theoptimization dynamics. When training with gradient descent the loss associatedwith infrequent words decreases slower than the loss associated with frequentones. As most samples come from relatively infrequent words the average lossdecreases slowly with gradient descent. On the other hand Adam and sign-basedmethods do not suffer from this problem and improve predictions on all classes.To establish that this behavior is indeed caused by class imbalance we showempirically that it persist through different architectures and data types onlanguage transformers vision CNNs and linear models. We further study thisphenomenon on a linear classification with cross-entropy loss showing thatheavy-tailed class imbalance leads to ill-conditioning and that thenormalization used by Adam can counteract it.</p>
                <p>Last Updated: 2024-02-29 18:47:52 UTC</p>
                <button class="interpret-button" data-id="2402.19449v1">Interpret</button>
                <div id="interpretation-2402.19449v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality</h3>
                <p>Authors: Siyu ChenHeejune SheenTianhao WangZhuoran Yang</p>
                <p><a href="http://arxiv.org/abs/2402.19442v1">Link to paper</a></p>
                <p>We study the dynamics of gradient flow for training a multi-head softmaxattention model for in-context learning of multi-task linear regression. Weestablish the global convergence of gradient flow under suitable choices ofinitialization. In addition we prove that an interesting task allocationphenomenon emerges during the gradient flow dynamics where each attention headfocuses on solving a single task of the multi-task model. Specifically weprove that the gradient flow dynamics can be split into three phases -- awarm-up phase where the loss decreases rather slowly and the attention headsgradually build up their inclination towards individual tasks an emergencephase where each head selects a single task and the loss rapidly decreases anda convergence phase where the attention parameters converge to a limit.Furthermore we prove the optimality of gradient flow in the sense that thelimiting model learned by gradient flow is on par with the best possiblemulti-head softmax attention model up to a constant factor. Our analysis alsodelineates a strict separation in terms of the prediction accuracy of ICLbetween single-head and multi-head attention models. The key technique for ourconvergence analysis is to map the gradient flow dynamics in the parameterspace to a set of ordinary differential equations in the spectral domain wherethe relative magnitudes of the semi-singular values of the attention weightsdetermines task allocation. To our best knowledge our work provides the firstconvergence result for the multi-head softmax attention model.</p>
                <p>Last Updated: 2024-02-29 18:43:52 UTC</p>
                <button class="interpret-button" data-id="2402.19442v1">Interpret</button>
                <div id="interpretation-2402.19442v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series</h3>
                <p>Authors: Rui HuangSikun YangHeinz Koeppl</p>
                <p><a href="http://arxiv.org/abs/2402.18995v1">Link to paper</a></p>
                <p>Modeling count-valued time series has been receiving increasing attentionsince count time series naturally arise in physical and social domains. Poissongamma dynamical systems PGDSs are newly-developed methods which can wellcapture the expressive latent transition structure and bursty dynamics behindcount sequences. In particular PGDSs demonstrate superior performance in termsof data imputation and prediction compared with canonical linear dynamicalsystem LDS based methods. Despite these advantages PGDS cannot capture theheterogeneous overdispersed behaviours of the underlying dynamic processes. Tomitigate this defect we propose a negative-binomial-randomized gamma Markovprocess which not only significantly improves the predictive performance ofthe proposed dynamical system but also facilitates the fast convergence of theinference algorithm. Moreover we develop methods to estimate bothfactor-structured and graph-structured transition dynamics which enable us toinfer more explainable latent structure compared with PGDSs. Finally wedemonstrate the explainable latent structure learned by the proposed methodand show its superior performance in imputing missing data and forecastingfuture observations compared with the related models.</p>
                <p>Last Updated: 2024-02-29 09:46:47 UTC</p>
                <button class="interpret-button" data-id="2402.18995v1">Interpret</button>
                <div id="interpretation-2402.18995v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling</h3>
                <p>Authors: Gabriel GrandValerio PepeJacob AndreasJoshua B. Tenenbaum</p>
                <p><a href="http://arxiv.org/abs/2402.19471v1">Link to paper</a></p>
                <p>Questions combine our mastery of language with our remarkable facility forreasoning about uncertainty. How do people navigate vast hypothesis spaces topose informative questions given limited cognitive resources We study thesetradeoffs in a classic grounded question-asking task based on the board gameBattleship. Our language-informed program sampling LIPS model uses largelanguage models LLMs to generate natural language questions translate theminto symbolic programs and evaluate their expected information gain. We findthat with a surprisingly modest resource budget this simple Monte Carlooptimization strategy yields informative questions that mirror humanperformance across varied Battleship board scenarios. In contrast LLM-onlybaselines struggle to ground questions in the board state notably GPT-4Vprovides no improvement over non-visual baselines. Our results illustrate howBayesian models of question-asking can leverage the statistics of language tocapture human priors while highlighting some shortcomings of pure LLMs asgrounded reasoners.</p>
                <p>Last Updated: 2024-02-29 18:58:15 UTC</p>
                <button class="interpret-button" data-id="2402.19471v1">Interpret</button>
                <div id="interpretation-2402.19471v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning</h3>
                <p>Authors: Kate SandersNathaniel WeirBenjamin Van Durme</p>
                <p><a href="http://arxiv.org/abs/2402.19467v1">Link to paper</a></p>
                <p>It is challenging to perform question-answering over complex multimodalcontent such as television clips. This is in part because currentvideo-language models rely on single-modality reasoning have loweredperformance on long inputs and lack interpetability. We propose TV-TREES thefirst multimodal entailment tree generator. TV-TREES serves as an approach tovideo understanding that promotes interpretable joint-modality reasoning byproducing trees of entailment relationships between simple premises directlyentailed by the videos and higher-level conclusions. We then introduce the taskof multimodal entailment tree generation to evaluate the reasoning quality ofsuch methods. Our methods experimental results on the challenging TVQA datasetdemonstrate intepretable state-of-the-art zero-shot performance on full videoclips illustrating a best of both worlds contrast to black-box methods.</p>
                <p>Last Updated: 2024-02-29 18:57:01 UTC</p>
                <button class="interpret-button" data-id="2402.19467v1">Interpret</button>
                <div id="interpretation-2402.19467v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models</h3>
                <p>Authors: Chen QianJie ZhangWei YaoDongrui LiuZhenfei YinYu QiaoYong LiuJing Shao</p>
                <p><a href="http://arxiv.org/abs/2402.19465v1">Link to paper</a></p>
                <p>Ensuring the trustworthiness of large language models LLMs is crucial. Moststudies concentrate on fully pre-trained LLMs to better understand and improveLLMs trustworthiness. In this paper to reveal the untapped potential ofpre-training we pioneer the exploration of LLMs trustworthiness during thisperiod focusing on five key dimensions: reliability privacy toxicityfairness and robustness. To begin with we apply linear probing to LLMs. Thehigh probing accuracy suggests that textitLLMs in early pre-training canalready distinguish concepts in each trustworthiness dimension. Therefore tofurther uncover the hidden possibilities of pre-training we extract steeringvectors from a LLMs pre-training checkpoints to enhance the LLMstrustworthiness. Finally inspired bycitetchoi2023understanding that mutualinformation estimation is bounded by linear probing accuracy we also probeLLMs with mutual information to investigate the dynamics of trustworthinessduring pre-training. We are the first to observe a similar two-phasephenomenon: fitting and compressioncitepshwartz2017opening. This researchprovides an initial exploration of trustworthiness modeling during LLMpre-training seeking to unveil new insights and spur further developments inthe field. We will make our code publicly accessible aturlhttps://github.com/ChnQ/TracingLLM.</p>
                <p>Last Updated: 2024-02-29 18:55:06 UTC</p>
                <button class="interpret-button" data-id="2402.19465v1">Interpret</button>
                <div id="interpretation-2402.19465v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Curiosity-driven Red-teaming for Large Language Models</h3>
                <p>Authors: Zhang-Wei HongIdan ShenfeldTsun-Hsuan WangYung-Sung ChuangAldo ParejaJames GlassAkash SrivastavaPulkit Agrawal</p>
                <p><a href="http://arxiv.org/abs/2402.19464v1">Link to paper</a></p>
                <p>Large language models LLMs hold great potential for many natural languageapplications but risk generating incorrect or toxic content. To probe when anLLM generates unwanted content the current paradigm is to recruit atextitred team of human testers to design input prompts i.e. test casesthat elicit undesirable responses from LLMs. However relying solely on humantesters is expensive and time-consuming. Recent works automate red teaming bytraining a separate red team LLM with reinforcement learning RL to generatetest cases that maximize the chance of eliciting undesirable responses from thetarget LLM. However current RL methods are only able to generate a smallnumber of effective test cases resulting in a low coverage of the span ofprompts that elicit undesirable responses from the target LLM. To overcome thislimitation we draw a connection between the problem of increasing the coverageof generated test cases and the well-studied approach of curiosity-drivenexploration that optimizes for novelty. Our method of curiosity-driven redteaming CRT achieves greater coverage of test cases while mantaining orincreasing their effectiveness compared to existing methods. Our method CRTsuccessfully provokes toxic responses from LLaMA2 model that has been heavilyfine-tuned using human preferences to avoid toxic outputs. Code is available aturlhttps://github.com/Improbable-AI/curiosity_redteam</p>
                <p>Last Updated: 2024-02-29 18:55:03 UTC</p>
                <button class="interpret-button" data-id="2402.19464v1">Interpret</button>
                <div id="interpretation-2402.19464v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Accelerating materials discovery for polymer solar cells: Data-driven insights enabled by natural language processing</h3>
                <p>Authors: Pranav ShettyAishat AdeboyeSonakshi GuptaChao ZhangRampi Ramprasad</p>
                <p><a href="http://arxiv.org/abs/2402.19462v1">Link to paper</a></p>
                <p>We present a natural language processing pipeline that was used to extractpolymer solar cell property data from the literature and simulate variousactive learning strategies. While data-driven methods have been wellestablished to discover novel materials faster than Edisonian trial-and-errorapproaches their benefits have not been quantified. Our approach demonstratesa potential reduction in discovery time by approximately 75  equivalent to a15 year acceleration in material innovation. Our pipeline enables us to extractdata from more than 3300 papers which is 5 times larger than similar data setsreported by others. We also trained machine learning models to predict thepower conversion efficiency and used our model to identify promisingdonor-acceptor combinations that are as yet unreported. We thus demonstrate aworkflow that goes from published literature to extracted material propertydata which in turn is used to obtain data-driven insights. Our insights includeactive learning strategies that can simultaneously optimize the material systemand train strong predictive models of material properties. This work provides avaluable framework for research in material science.</p>
                <p>Last Updated: 2024-02-29 18:54:46 UTC</p>
                <button class="interpret-button" data-id="2402.19462v1">Interpret</button>
                <div id="interpretation-2402.19462v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>#PoetsOfInstagram: Navigating The Practices And Challenges Of Novice Poets On Instagram</h3>
                <p>Authors: Ankolika DeZhicong Lu</p>
                <p><a href="http://dx.doi.org/10.1145/1122445.1122456">Link to paper</a></p>
                <p>Commencing as a photo-sharing platform Instagram has since becomemultifaceted accommodating diverse art forms with poetry emerging as aprominent one. However the academic understanding of Instagrams poetrycommunity is limited yet its significance emerges from its distinctiveutilization of a primarily visual social media platform guided byrecommendation algorithms for disseminating poetry further characterized by apredominantly novice creative population. We employ qualitative analysis toexplore motivations experiences and algorithmic influence within Instagramspoetry community. We demonstrate that participants prioritize conforming toalgorithmic constraints for visibility yet maintain their communitys valuesof integrity and originality illustrating the tension between algorithmicgrowth and participant authenticity. We introduce the concept ofAlgorithmically Mediated Creative Labor a phenomenon specific tonon-monetizing creative users who are impacted by the prioritization ofprofessional creators and continually adapt their creative endeavors to alignwith platform logic thereby affecting their motivation and creative outputs.</p>
                <p>Last Updated: 2024-02-29 16:55:44 UTC</p>
                <button class="interpret-button" data-id="2402.19347v1">Interpret</button>
                <div id="interpretation-2402.19347v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Seeking Soulmate via Voice: Understanding Promises and Challenges of Online Synchronized Voice-Based Mobile Dating</h3>
                <p>Authors: Chenxinran ShenYan XuRay LCZhicong Lu</p>
                <p><a href="http://dx.doi.org/10.1145/3613904.3642860">Link to paper</a></p>
                <p>Online dating has become a popular way for individuals to connect withpotential romantic partners. Many dating apps use personal profiles thatinclude a headshot and self-description allowing users to present themselvesand search for compatible matches. However this traditional model often haslimitations. In this study we explore a non-traditional voice-based dating appcalled Soul. Unlike traditional platforms that rely heavily on profileinformation Soul facilitates user interactions through voice-basedcommunication. We conducted semi-structured interviews with 18 dedicated Soulusers to investigate how they engage with the platform and perceive themselvesand others in this unique dating environment. Our findings indicate that therole of voice as a moderator influences impression management and shapesperceptions between the sender and the receiver of the voice. Additionally thesynchronous voice-based and community-based dating model offers benefits tousers in the Chinese cultural context. Our study contributes to understandingthe affordances introduced by voice-based interactions in online dating inChina.</p>
                <p>Last Updated: 2024-02-29 16:30:07 UTC</p>
                <button class="interpret-button" data-id="2402.19328v1">Interpret</button>
                <div id="interpretation-2402.19328v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>DISCERN: Designing Decision Support Interfaces to Investigate the Complexities of Workplace Social Decision-Making With Line Managers</h3>
                <p>Authors: Pranav KhadpeLindy LeKate NowakShamsi T. IqbalJina Suh</p>
                <p><a href="http://dx.doi.org/10.1145/3613904.3642685">Link to paper</a></p>
                <p>Line managers form the first level of management in organizations and mustmake complex decisions while maintaining relationships with those impacted bytheir decisions. Amidst growing interest in technology-supporteddecision-making at work their needs remain understudied. Further mostexisting design knowledge for supporting social decision-making comes fromdomains where decision-makers are more socially detached from those they decidefor. We conducted iterative design research with line managers within atechnology organization investigating decision-making practices andopportunities for technological support. Through formative researchdevelopment of a decision-representation tool -- DISCERN -- and userenactments we identify their communication and analysis needs that lackadequate support. We found they preferred tools for externalizing reasoningrather than tools that replace interpersonal interactions and they wantedtools to support a range of intuitive and calculative decision-making. Wediscuss how design of social decision-making supports especially in theworkplace can more explicitly support highly interactional socialdecision-making.</p>
                <p>Last Updated: 2024-02-29 16:24:17 UTC</p>
                <button class="interpret-button" data-id="2402.19318v1">Interpret</button>
                <div id="interpretation-2402.19318v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>CAPTURE-24: A large dataset of wrist-worn activity tracker data collected in the wild for human activity recognition</h3>
                <p>Authors: Shing ChanHang YuanCatherine TongAidan AcquahAbram SchonfeldtJonathan GershunyAiden Doherty</p>
                <p><a href="http://arxiv.org/abs/2402.19229v1">Link to paper</a></p>
                <p>Existing activity tracker datasets for human activity recognition aretypically obtained by having participants perform predefined activities in anenclosed environment under supervision. This results in small datasets with alimited number of activities and heterogeneity lacking the mixed and nuancedmovements normally found in free-living scenarios. As such models trained onlaboratory-style datasets may not generalise out of sample. To address thisproblem we introduce a new dataset involving wrist-worn accelerometerswearable cameras and sleep diaries enabling data collection for over 24 hoursin a free-living setting. The result is CAPTURE-24 a large activity trackerdataset collected in the wild from 151 participants amounting to 3883 hours ofaccelerometer data of which 2562 hours are annotated. CAPTURE-24 is two tothree orders of magnitude larger than existing publicly available datasetswhich is critical to developing accurate human activity recognition models.</p>
                <p>Last Updated: 2024-02-29 15:04:34 UTC</p>
                <button class="interpret-button" data-id="2402.19229v1">Interpret</button>
                <div id="interpretation-2402.19229v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool</h3>
                <p>Authors: Liudmila ZavolokinaKilian SprenkampZoya KatashinskayaDaniel Gordon JonesGerhard Schwabe</p>
                <p><a href="http://dx.doi.org/10.1145/3613904.3642805">Link to paper</a></p>
                <p>In todays digital age characterized by rapid news consumption andincreasing vulnerability to propaganda fostering citizens critical thinkingis crucial for stable democracies. This paper introduces the design ofClarifAI a novel automated propaganda detection tool designed to nudge readerstowards more critical news consumption by activating the analytical mode ofthinking following Kahnemans dual-system theory of cognition. Using LargeLanguage Models ClarifAI detects propaganda in news articles and providescontext-rich explanations enhancing users understanding and criticalthinking. Our contribution is threefold: first we propose the design ofClarifAI second in an online experiment we demonstrate that this designeffectively encourages news readers to engage in more critical reading andthird we emphasize the value of explanations for fostering critical thinking.The study thus offers both a practical tool and useful design knowledge formitigating propaganda in digital news.</p>
                <p>Last Updated: 2024-02-29 13:12:31 UTC</p>
                <button class="interpret-button" data-id="2402.19135v1">Interpret</button>
                <div id="interpretation-2402.19135v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?</h3>
                <p>Authors: Alex GuWen-Ding LiNaman JainTheo X. OlaussonCeline LeeKoushik SenArmando Solar-Lezama</p>
                <p><a href="http://arxiv.org/abs/2402.19475v1">Link to paper</a></p>
                <p>While language models are increasingly more proficient at code generationthey still frequently generate incorrect programs. Many of these programs areobviously wrong but others are more subtle and pass weaker correctness checkssuch as being able to compile. In this work we focus on these counterfeitsamples: programs sampled from a language model that 1 have a high enoughlog-probability to be generated at a moderate temperature and 2 pass weakcorrectness checks. Overall we discover that most models have a very shallowunderstanding of counterfeits through three clear failure modes. First modelsmistakenly classify them as correct. Second models are worse at reasoningabout the execution behaviour of counterfeits and often predict their executionresults as if they were correct. Third when asking models to fix counterfeitsthe likelihood of a model successfully repairing a counterfeit is often evenlower than that of sampling a correct program from scratch. Counterfeits alsohave very unexpected properties: first counterfeit programs for problems thatare easier for a model to solve are not necessarily easier to detect and onlyslightly easier to execute and repair. Second counterfeits from a given modelare just as confusing to the model itself as they are to other models. Finallyboth strong and weak models are able to generate counterfeit samples thatequally challenge all models. In light of our findings we recommend that careand caution be taken when relying on models to understand their own samplesespecially when no external feedback is incorporated.</p>
                <p>Last Updated: 2024-02-29 18:59:25 UTC</p>
                <button class="interpret-button" data-id="2402.19475v1">Interpret</button>
                <div id="interpretation-2402.19475v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress</h3>
                <p>Authors: Ameya PrabhuVishaal UdandaraoPhilip TorrMatthias BethgeAdel BibiSamuel Albanie</p>
                <p><a href="http://arxiv.org/abs/2402.19472v1">Link to paper</a></p>
                <p>Standardized benchmarks drive progress in machine learning. However withrepeated testing the risk of overfitting grows as algorithms over-exploitbenchmark idiosyncrasies. In our work we seek to mitigate this challenge bycompiling ever-expanding large-scale benchmarks called Lifelong Benchmarks. Asexemplars of our approach we create Lifelong-CIFAR10 and Lifelong-ImageNetcontaining for now 1.69M and 1.98M test samples respectively. While reducingoverfitting lifelong benchmarks introduce a key challenge: the high cost ofevaluating a growing number of models across an ever-expanding sample set. Toaddress this challenge we also introduce an efficient evaluation framework:Sort  Search SS which reuses previously evaluated models by leveragingdynamic programming algorithms to selectively rank and sub-select test samplesenabling cost-effective lifelong benchmarking. Extensive empirical evaluationsacross 31000 models demonstrate that SS achieves highly-efficient approximateaccuracy measurement reducing compute cost from 180 GPU days to 5 GPU hours1000x reduction on a single A100 GPU with low approximation error. As suchlifelong benchmarks offer a robust practical solution to the benchmarkexhaustion problem.</p>
                <p>Last Updated: 2024-02-29 18:58:26 UTC</p>
                <button class="interpret-button" data-id="2402.19472v1">Interpret</button>
                <div id="interpretation-2402.19472v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Humanoid Locomotion as Next Token Prediction</h3>
                <p>Authors: Ilija RadosavovicBike ZhangBaifeng ShiJathushan RajasegaranSarthak KamatTrevor DarrellKoushil SreenathJitendra Malik</p>
                <p><a href="http://arxiv.org/abs/2402.19469v1">Link to paper</a></p>
                <p>We cast real-world humanoid control as a next token prediction problem akinto predicting the next word in language. Our model is a causal transformertrained via autoregressive prediction of sensorimotor trajectories. To accountfor the multi-modal nature of the data we perform prediction in amodality-aligned way and for each input token predict the next token from thesame modality. This general formulation enables us to leverage data withmissing modalities like video trajectories without actions. We train our modelon a collection of simulated trajectories coming from prior neural networkpolicies model-based controllers motion capture data and YouTube videos ofhumans. We show that our model enables a full-sized humanoid to walk in SanFrancisco zero-shot. Our model can transfer to the real world even when trainedon only 27 hours of walking data and can generalize to commands not seenduring training like walking backward. These findings suggest a promising pathtoward learning challenging real-world control tasks by generative modeling ofsensorimotor trajectories.</p>
                <p>Last Updated: 2024-02-29 18:57:37 UTC</p>
                <button class="interpret-button" data-id="2402.19469v1">Interpret</button>
                <div id="interpretation-2402.19469v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Curiosity-driven Red-teaming for Large Language Models</h3>
                <p>Authors: Zhang-Wei HongIdan ShenfeldTsun-Hsuan WangYung-Sung ChuangAldo ParejaJames GlassAkash SrivastavaPulkit Agrawal</p>
                <p><a href="http://arxiv.org/abs/2402.19464v1">Link to paper</a></p>
                <p>Large language models LLMs hold great potential for many natural languageapplications but risk generating incorrect or toxic content. To probe when anLLM generates unwanted content the current paradigm is to recruit atextitred team of human testers to design input prompts i.e. test casesthat elicit undesirable responses from LLMs. However relying solely on humantesters is expensive and time-consuming. Recent works automate red teaming bytraining a separate red team LLM with reinforcement learning RL to generatetest cases that maximize the chance of eliciting undesirable responses from thetarget LLM. However current RL methods are only able to generate a smallnumber of effective test cases resulting in a low coverage of the span ofprompts that elicit undesirable responses from the target LLM. To overcome thislimitation we draw a connection between the problem of increasing the coverageof generated test cases and the well-studied approach of curiosity-drivenexploration that optimizes for novelty. Our method of curiosity-driven redteaming CRT achieves greater coverage of test cases while mantaining orincreasing their effectiveness compared to existing methods. Our method CRTsuccessfully provokes toxic responses from LLaMA2 model that has been heavilyfine-tuned using human preferences to avoid toxic outputs. Code is available aturlhttps://github.com/Improbable-AI/curiosity_redteam</p>
                <p>Last Updated: 2024-02-29 18:55:03 UTC</p>
                <button class="interpret-button" data-id="2402.19464v1">Interpret</button>
                <div id="interpretation-2402.19464v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks</h3>
                <p>Authors: Bálint MucsányiMichael KirchhofSeong Joon Oh</p>
                <p><a href="http://arxiv.org/abs/2402.19460v1">Link to paper</a></p>
                <p>Uncertainty quantification once a singular task has evolved into a spectrumof tasks including abstained prediction out-of-distribution detection andaleatoric uncertainty quantification. The latest goal is disentanglement: theconstruction of multiple estimators that are each tailored to one and only onetask. Hence there is a plethora of recent advances with different intentions -that often entirely deviate from practical behavior. This paper conducts acomprehensive evaluation of numerous uncertainty estimators across diversetasks on ImageNet. We find that despite promising theoretical endeavorsdisentanglement is not yet achieved in practice. Additionally we reveal whichuncertainty estimators excel at which specific tasks providing insights forpractitioners and guiding future research toward task-centric and disentangleduncertainty estimation methods. Our code is available athttps://github.com/bmucsanyi/bud.</p>
                <p>Last Updated: 2024-02-29 18:52:56 UTC</p>
                <button class="interpret-button" data-id="2402.19460v1">Interpret</button>
                <div id="interpretation-2402.19460v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models</h3>
                <p>Authors: Muyang LiTianle CaiJiaxin CaoQinsheng ZhangHan CaiJunjie BaiYangqing JiaMing-Yu LiuKai LiSong Han</p>
                <p><a href="http://arxiv.org/abs/2402.19481v1">Link to paper</a></p>
                <p>Diffusion models have achieved great success in synthesizing high-qualityimages. However generating high-resolution images with diffusion models isstill challenging due to the enormous computational costs resulting in aprohibitive latency for interactive applications. In this paper we proposeDistriFusion to tackle this problem by leveraging parallelism across multipleGPUs. Our method splits the model input into multiple patches and assigns eachpatch to a GPU. However naively implementing such an algorithm breaks theinteraction between patches and loses fidelity while incorporating such aninteraction will incur tremendous communication overhead. To overcome thisdilemma we observe the high similarity between the input from adjacentdiffusion steps and propose displaced patch parallelism which takes advantageof the sequential nature of the diffusion process by reusing the pre-computedfeature maps from the previous timestep to provide context for the currentstep. Therefore our method supports asynchronous communication which can bepipelined by computation. Extensive experiments show that our method can beapplied to recent Stable Diffusion XL with no quality degradation and achieveup to a 6.1times speedup on eight NVIDIA A100s compared to one. Our code ispublicly available at https://github.com/mit-han-lab/distrifuser.</p>
                <p>Last Updated: 2024-02-29 18:59:58 UTC</p>
                <button class="interpret-button" data-id="2402.19481v1">Interpret</button>
                <div id="interpretation-2402.19481v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers</h3>
                <p>Authors: Tsai-Shien ChenAliaksandr SiarohinWilli MenapaceEkaterina DeynekaHsiang-wei ChaoByung Eun JeonYuwei FangHsin-Ying LeeJian RenMing-Hsuan YangSergey Tulyakov</p>
                <p><a href="http://arxiv.org/abs/2402.19479v1">Link to paper</a></p>
                <p>The quality of the data and annotation upper-bounds the quality of adownstream model. While there exist large text corpora and image-text pairshigh-quality video-text data is much harder to collect. First of all manuallabeling is more time-consuming as it requires an annotator to watch an entirevideo. Second videos have a temporal dimension consisting of several scenesstacked together and showing multiple actions. Accordingly to establish avideo dataset with high-quality captions we propose an automatic approachleveraging multimodal inputs such as textual video description subtitles andindividual video frames. Specifically we curate 3.8M high-resolution videosfrom the publicly available HD-VILA-100M dataset. We then split them intosemantically consistent video clips and apply multiple cross-modality teachermodels to obtain captions for each video. Next we finetune a retrieval modelon a small subset where the best caption of each video is manually selected andthen employ the model in the whole dataset to select the best caption as theannotation. In this way we get 70M videos paired with high-quality textcaptions. We dub the dataset as Panda-70M. We show the value of the proposeddataset on three downstream tasks: video captioning video and text retrievaland text-driven video generation. The models trained on the proposed data scoresubstantially better on the majority of metrics across all the tasks.</p>
                <p>Last Updated: 2024-02-29 18:59:50 UTC</p>
                <button class="interpret-button" data-id="2402.19479v1">Interpret</button>
                <div id="interpretation-2402.19479v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Learning a Generalized Physical Face Model From Data</h3>
                <p>Authors: Lingchen YangGaspard ZossPrashanth ChandranMarkus GrossBarbara SolenthalerEftychios SifakisDerek Bradley</p>
                <p><a href="http://arxiv.org/abs/2402.19477v1">Link to paper</a></p>
                <p>Physically-based simulation is a powerful approach for 3D facial animation asthe resulting deformations are governed by physical constraints allowing toeasily resolve self-collisions respond to external forces and performrealistic anatomy edits. Todays methods are data-driven where the actuationsfor finite elements are inferred from captured skin geometry. Unfortunatelythese approaches have not been widely adopted due to the complexity ofinitializing the material space and learning the deformation model for eachcharacter separately which often requires a skilled artist followed by lengthynetwork training. In this work we aim to make physics-based facial animationmore accessible by proposing a generalized physical face model that we learnfrom a large 3D face dataset in a simulation-free manner. Once trained ourmodel can be quickly fit to any unseen identity and produce a ready-to-animatephysical face model automatically. Fitting is as easy as providing a single 3Dface scan or even a single face image. After fitting we offer intuitiveanimation controls as well as the ability to retarget animations acrosscharacters. All the while the resulting animations allow for physical effectslike collision avoidance gravity paralysis bone reshaping and more.</p>
                <p>Last Updated: 2024-02-29 18:59:31 UTC</p>
                <button class="interpret-button" data-id="2402.19477v1">Interpret</button>
                <div id="interpretation-2402.19477v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The All-Seeing Project V2: Towards General Relation Comprehension of the Open World</h3>
                <p>Authors: Weiyun WangYiming RenHaowen LuoTiantong LiChenxiang YanZhe ChenWenhai WangQingyun LiLewei LuXizhou ZhuYu QiaoJifeng Dai</p>
                <p><a href="http://arxiv.org/abs/2402.19474v1">Link to paper</a></p>
                <p>We present the All-Seeing Project V2: a new model and dataset designed forunderstanding object relations in images. Specifically we propose theAll-Seeing Model V2 ASMv2 that integrates the formulation of text generationobject localization and relation comprehension into a relation conversationReC task. Leveraging this unified task our model excels not only inperceiving and recognizing all objects within the image but also in graspingthe intricate relation graph between them diminishing the relationhallucination often encountered by Multi-modal Large Language Models MLLMs.To facilitate training and evaluation of MLLMs in relation understanding wecreated the first high-quality ReC dataset AS-V2 which is aligned with theformat of standard instruction tuning data. In addition we design a newbenchmark termed Circular-based Relation Probing Evaluation CRPE forcomprehensively evaluating the relation comprehension capabilities of MLLMs.Notably our ASMv2 achieves an overall accuracy of 52.04 on this relation-awarebenchmark surpassing the 43.14 of LLaVA-1.5 by a large margin. We hope thatour work can inspire more future research and contribute to the evolutiontowards artificial general intelligence. Our project is released athttps://github.com/OpenGVLab/all-seeing.</p>
                <p>Last Updated: 2024-02-29 18:59:17 UTC</p>
                <button class="interpret-button" data-id="2402.19474v1">Interpret</button>
                <div id="interpretation-2402.19474v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Retrieval-Augmented Generation for AI-Generated Content: A Survey</h3>
                <p>Authors: Penghao ZhaoHailin ZhangQinhan YuZhengren WangYunteng GengFangcheng FuLing YangWentao ZhangBin Cui</p>
                <p><a href="http://arxiv.org/abs/2402.19473v1">Link to paper</a></p>
                <p>The development of Artificial Intelligence Generated Content AIGC has beenfacilitated by advancements in model algorithms scalable foundation modelarchitectures and the availability of ample high-quality datasets. While AIGChas achieved remarkable performance it still faces challenges such as thedifficulty of maintaining up-to-date and long-tail knowledge the risk of dataleakage and the high costs associated with training and inference.Retrieval-Augmented Generation RAG has recently emerged as a paradigm toaddress such challenges. In particular RAG introduces the informationretrieval process which enhances AIGC results by retrieving relevant objectsfrom available data stores leading to greater accuracy and robustness. In thispaper we comprehensively review existing efforts that integrate RAG techniqueinto AIGC scenarios. We first classify RAG foundations according to how theretriever augments the generator. We distill the fundamental abstractions ofthe augmentation methodologies for various retrievers and generators. Thisunified perspective encompasses all RAG scenarios illuminating advancementsand pivotal technologies that help with potential future progress. We alsosummarize additional enhancements methods for RAG facilitating effectiveengineering and implementation of RAG systems. Then from another view wesurvey on practical applications of RAG across different modalities and tasksoffering valuable references for researchers and practitioners. Furthermore weintroduce the benchmarks for RAG discuss the limitations of current RAGsystems and suggest potential directions for future research. Project:https://github.com/hymie122/RAG-Survey</p>
                <p>Last Updated: 2024-02-29 18:59:01 UTC</p>
                <button class="interpret-button" data-id="2402.19473v1">Interpret</button>
                <div id="interpretation-2402.19473v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-03-03</p>
        </div>
    
        </div>
    </body>
    </html>
    