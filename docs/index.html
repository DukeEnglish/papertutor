
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Accelerated Inference for Partially Observed Markov Processes using Automatic Differentiation</h3>
                <p>Authors: Kevin TanGiles HookerEdward L. Ionides</p>
                <p><a href="http://arxiv.org/abs/2407.03085v1">Link to paper</a></p>
                <p>Automatic differentiation AD has driven recent advances in machinelearning including deep neural networks and Hamiltonian Markov Chain MonteCarlo methods. Partially observed nonlinear stochastic dynamical systems haveproved resistant to AD techniques because widely used particle filteralgorithms yield an estimated likelihood function that is discontinuous as afunction of the model parameters. We show how to embed two existing AD particlefilter methods in a theoretical framework that provides an extension to a newclass of algorithms. This new class permits a bias/variance tradeoff and hencea mean squared error substantially lower than the existing algorithms. Wedevelop likelihood maximization algorithms suited to the Monte Carlo propertiesof the AD gradient estimate. Our algorithms require only a differentiablesimulator for the latent dynamic system by contrast most previous approachesto AD likelihood maximization for particle filters require access to thesystems transition probabilities. Numerical results indicate that a hybridalgorithm that uses AD to refine a coarse solution from an iterated filteringalgorithm show substantial improvement on current state-of-the-art methods fora challenging scientific benchmark problem.</p>
                <p>Last Updated: 2024-07-03 13:06:46 UTC</p>
                <button class="interpret-button" data-id="2407.03085v1">Interpret</button>
                <div id="interpretation-2407.03085v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Stable Heterogeneous Treatment Effect Estimation across Out-of-Distribution Populations</h3>
                <p>Authors: Yuling ZhangAnpeng WuKun KuangLiang DuZixun SunZhi Wang</p>
                <p><a href="http://arxiv.org/abs/2407.03082v1">Link to paper</a></p>
                <p>Heterogeneous treatment effect HTE estimation is vital for understandingthe change of treatment effect across individuals or subgroups. Most existingHTE estimation methods focus on addressing selection bias induced by imbalanceddistributions of confounders between treated and control units but ignoredistribution shifts across populations. Thereby their applicability has beenlimited to the in-distribution ID population which shares a similardistribution with the training dataset. In real-world applications wherepopulation distributions are subject to continuous changes there is an urgentneed for stable HTE estimation across out-of-distribution OOD populationswhich however remains an open problem. As pioneers in resolving this problemwe propose a novel Stable Balanced Representation Learning withHierarchical-Attention Paradigm SBRL-HAP framework which consists of 1Balancing Regularizer for eliminating selection bias 2 IndependenceRegularizer for addressing the distribution shift issue 3Hierarchical-Attention Paradigm for coordination between balance andindependence. In this way SBRL-HAP regresses counterfactual outcomes using IDdata while ensuring the resulting HTE estimation can be successfullygeneralized to out-of-distribution scenarios thereby enhancing the modelsapplicability in real-world settings. Extensive experiments conducted onsynthetic and real-world datasets demonstrate the effectiveness of our SBRL-HAPin achieving stable HTE estimation across OOD populations with an average 10reduction in the error metric PEHE and 11 decrease in the ATE bias comparedto the SOTA methods.</p>
                <p>Last Updated: 2024-07-03 13:03:51 UTC</p>
                <button class="interpret-button" data-id="2407.03082v1">Interpret</button>
                <div id="interpretation-2407.03082v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Warm-up Free Policy Optimization: Improved Regret in Linear Markov Decision Processes</h3>
                <p>Authors: Asaf CasselAviv Rosenberg</p>
                <p><a href="http://arxiv.org/abs/2407.03065v1">Link to paper</a></p>
                <p>Policy Optimization PO methods are among the most popular ReinforcementLearning RL algorithms in practice. Recently Sherman et al. 2023a proposeda PO-based algorithm with rate-optimal regret guarantees under the linearMarkov Decision Process MDP model. However their algorithm relies on acostly pure exploration warm-up phase that is hard to implement in practice.This paper eliminates this undesired warm-up phase replacing it with a simpleand efficient contraction mechanism. Our PO algorithm achieves rate-optimalregret with improved dependence on the other parameters of the problem horizonand function approximation dimension in two fundamental settings: adversariallosses with full-information feedback and stochastic losses with banditfeedback.</p>
                <p>Last Updated: 2024-07-03 12:36:24 UTC</p>
                <button class="interpret-button" data-id="2407.03065v1">Interpret</button>
                <div id="interpretation-2407.03065v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>FairJob: A Real-World Dataset for Fairness in Online Systems</h3>
                <p>Authors: Mariia VladimirovaFederico PavoneEustache Diemert</p>
                <p><a href="http://arxiv.org/abs/2407.03059v1">Link to paper</a></p>
                <p>We introduce a fairness-aware dataset for job recommendation in advertisingdesigned to foster research in algorithmic fairness within real-worldscenarios. It was collected and prepared to comply with privacy standards andbusiness confidentiality. An additional challenge is the lack of access toprotected user attributes such as gender for which we propose a solution toobtain a proxy estimate. Despite being anonymized and including a proxy for asensitive attribute our dataset preserves predictive power and maintains arealistic and challenging benchmark. This dataset addresses a significant gapin the availability of fairness-focused resources for high-impact domains likeadvertising -- the actual impact being having access or not to preciousemployment opportunities where balancing fairness and utility is a commonindustrial challenge. We also explore various stages in the advertising processwhere unfairness can occur and introduce a method to compute a fair utilitymetric for the job recommendations in online systems case from a biaseddataset. Experimental evaluations of bias mitigation techniques on the releaseddataset demonstrate potential improvements in fairness and the associatedtrade-offs with utility.</p>
                <p>Last Updated: 2024-07-03 12:30:39 UTC</p>
                <button class="interpret-button" data-id="2407.03059v1">Interpret</button>
                <div id="interpretation-2407.03059v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Implementation and Analysis of GPU Algorithms for Vecchia Approximation</h3>
                <p>Authors: Zachary JamesJoseph Guinness</p>
                <p><a href="http://arxiv.org/abs/2407.02740v1">Link to paper</a></p>
                <p>Gaussian Processes have become an indispensable part of the spatialstatisticians toolbox but are unsuitable for analyzing large dataset becauseof the significant time and memory needed to fit the associated model exactly.Vecchia Approximation is widely used to reduce the computational complexity andcan be calculated with embarrassingly parallel algorithms. While multi-coresoftware has been developed for Vecchia Approximation such as the GpGp Rpackage software designed to run on graphics processing units GPU islacking despite the tremendous success GPUs have had in statistics and machinelearning. We compare three different ways to implement Vecchia Approximation ona GPU: two of which are similar to methods used for other Gaussian Processapproximations and one that is new. The impact of memory type on performance isinvestigated and the final method is optimized accordingly. We show that ournew method outperforms the other two and then present it in the GpGpU Rpackage. We compare GpGpU to existing multi-core and GPU-accelerated softwareby fitting Gaussian Process models on various datasets including a largespatial-temporal dataset of n106 points collected from an earth-observingsatellite. Our results show that GpGpU achieves faster runtimes and betterpredictive accuracy.</p>
                <p>Last Updated: 2024-07-03 01:24:44 UTC</p>
                <button class="interpret-button" data-id="2407.02740v1">Interpret</button>
                <div id="interpretation-2407.02740v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Eyes on the Game: Deciphering Implicit Human Signals to Infer Human Proficiency, Trust, and Intent</h3>
                <p>Authors: Nikhil HulleSt√©phane Aroca-OuelletteAnthony J. RiesJake BrawerKatharina von der WenseAlessandro Roncone</p>
                <p><a href="http://arxiv.org/abs/2407.03298v1">Link to paper</a></p>
                <p>Effective collaboration between humans and AIs hinges on transparentcommunication and alignment of mental models. However explicit verbalcommunication is not always feasible. Under such circumstances human-humanteams often depend on implicit nonverbal cues to glean important informationabout their teammates such as intent and expertise thereby bolstering teamalignment and adaptability. Among these implicit cues two of the most salientand fundamental are a humans actions in the environment and their visualattention. In this paper we present a novel method to combine eye gaze dataand behavioral data and evaluate their respective predictive power for humanproficiency trust and intent. We first collect a dataset of paired eye gazeand gameplay data in the fast-paced collaborative Overcooked environment. Wethen train models on this dataset to compare how the predictive powers differbetween gaze data gameplay data and their combination. We additionallycompare our method to prior works that aggregate eye gaze data and demonstratehow these aggregation methods can substantially reduce the predictive abilityof eye gaze. Our results indicate that while eye gaze data and gameplay dataexcel in different situations a model that integrates both types consistentlyoutperforms all baselines. This work paves the way for developing intuitive andresponsive agents that can efficiently adapt to new teammates.</p>
                <p>Last Updated: 2024-07-03 17:37:19 UTC</p>
                <button class="interpret-button" data-id="2407.03298v1">Interpret</button>
                <div id="interpretation-2407.03298v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>VCHAR:Variance-Driven Complex Human Activity Recognition framework with Generative Representation</h3>
                <p>Authors: Yuan SunNavid Salami PargooTaqiya EhsanZhao Zhang Jorge Ortiz</p>
                <p><a href="http://arxiv.org/abs/2407.03291v1">Link to paper</a></p>
                <p>Complex human activity recognition CHAR remains a pivotal challenge withinubiquitous computing especially in the context of smart environments. Existingstudies typically require meticulous labeling of both atomic and complexactivities a task that is labor-intensive and prone to errors due to thescarcity and inaccuracies of available datasets. Most prior research hasfocused on datasets that either precisely label atomic activities or atminimum their sequence approaches that are often impractical in real worldsettings.In response we introduce VCHAR Variance-Driven Complex HumanActivity Recognition a novel framework that treats the outputs of atomicactivities as a distribution over specified intervals. Leveraging generativemethodologies VCHAR elucidates the reasoning behind complex activityclassifications through video-based explanations accessible to users withoutprior machine learning expertise. Our evaluation across three publiclyavailable datasets demonstrates that VCHAR enhances the accuracy of complexactivity recognition without necessitating precise temporal or sequentiallabeling of atomic activities. Furthermore user studies confirm that VCHARsexplanations are more intelligible compared to existing methods facilitating abroader understanding of complex activity recognition among non-experts.</p>
                <p>Last Updated: 2024-07-03 17:24:36 UTC</p>
                <button class="interpret-button" data-id="2407.03291v1">Interpret</button>
                <div id="interpretation-2407.03291v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>EDPNet: An Efficient Dual Prototype Network for Motor Imagery EEG Decoding</h3>
                <p>Authors: Can HanChen LiuCrystal CaiJun WangDahong Qian</p>
                <p><a href="http://arxiv.org/abs/2407.03177v1">Link to paper</a></p>
                <p>Motor imagery electroencephalograph MI-EEG decoding plays a crucial role indeveloping motor imagery brain-computer interfaces MI-BCIs. However decodingintentions from MI remains challenging due to the inherent complexity of EEGsignals relative to the small-sample size. In this paper we propose anEfficient Dual Prototype Network EDPNet to enable accurate and fast MIdecoding. EDPNet employs a lightweight adaptive spatial-spectral fusion modulewhich promotes more efficient information fusion between multiple EEGelectrodes. Subsequently a parameter-free multi-scale variance pooling moduleextracts more comprehensive temporal features. Furthermore we introduce dualprototypical learning to optimize the feature space distribution and trainingprocess thereby improving the models generalization ability on small-sampleMI datasets. Our experimental results show that the EDPNet outperformsstate-of-the-art models with superior classification accuracy and kappa values84.11 and 0.7881 for dataset BCI competition IV 2a 86.65 and 0.7330 fordataset BCI competition IV 2b. Additionally we use the BCI competition IIIIVa dataset with fewer training data to further validate the generalizationability of the proposed EDPNet. We also achieve superior performance with82.03 classification accuracy. Benefiting from the lightweight parameters andsuperior decoding accuracy our EDPNet shows great potential for MI-BCIapplications. The code is publicly available athttps://github.com/hancan16/EDPNet.</p>
                <p>Last Updated: 2024-07-03 14:57:22 UTC</p>
                <button class="interpret-button" data-id="2407.03177v1">Interpret</button>
                <div id="interpretation-2407.03177v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>GMM-ResNext: Combining Generative and Discriminative Models for Speaker Verification</h3>
                <p>Authors: Hui YanZhenchun LeiChanghong LiuYong Zhou</p>
                <p><a href="http://dx.doi.org/10.1109/ICASSP48485.2024.10447141">Link to paper</a></p>
                <p>With the development of deep learning many different network architectureshave been explored in speaker verification. However most network architecturesrely on a single deep learning architecture and hybrid networks combiningdifferent architectures have been little studied in ASV tasks. In this paperwe propose the GMM-ResNext model for speaker verification. Conventional GMMdoes not consider the score distribution of each frame feature over allGaussian components and ignores the relationship between neighboring speechframes. So we extract the log Gaussian probability features based on the rawacoustic features and use ResNext-based network as the backbone to extract thespeaker embedding. GMM-ResNext combines Generative and Discriminative Models toimprove the generalization ability of deep learning models and allows one tomore easily specify meaningful priors on model parameters. A two-pathGMM-ResNext model based on two gender-related GMMs has also been proposed. TheExperimental results show that the proposed GMM-ResNext achieves relativeimprovements of 48.1 and 11.3 in EER compared with ResNet34 and ECAPA-TDNNon VoxCeleb1-O test set.</p>
                <p>Last Updated: 2024-07-03 14:14:18 UTC</p>
                <button class="interpret-button" data-id="2407.03135v1">Interpret</button>
                <div id="interpretation-2407.03135v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Design of a UE5-based digital twin platform</h3>
                <p>Authors: Shaoqiu LyuMuzhi WangSunrui ZhangShengzhi Wang</p>
                <p><a href="http://arxiv.org/abs/2407.03107v1">Link to paper</a></p>
                <p>Aiming at the current mainstream 3D scene engine learning and building costis too high this thesis proposes a digital twin platform design program basedon Unreal Engine 5 UE5. It aims to provide a universal platform constructiondesign process to effectively reduce the learning cost of large-scale sceneconstruction. Taking an actual project of a unit as an example the overallcycle work of platform building is explained and the digital twin and datavisualization technologies and applications based on UE5 are analyzed. Bysummarizing the project implementation into a process approach thestandardization and operability of the process pathway is improved.</p>
                <p>Last Updated: 2024-07-03 13:46:20 UTC</p>
                <button class="interpret-button" data-id="2407.03107v1">Interpret</button>
                <div id="interpretation-2407.03107v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output</h3>
                <p>Authors: Pan ZhangXiaoyi DongYuhang ZangYuhang CaoRui QianLin ChenQipeng GuoHaodong DuanBin WangLinke OuyangSongyang ZhangWenwei ZhangYining LiYang GaoPeng SunXinyue ZhangWei LiJingwen LiWenhai WangHang YanConghui HeXingcheng ZhangKai ChenJifeng DaiYu QiaoDahua LinJiaqi Wang</p>
                <p><a href="http://arxiv.org/abs/2407.03320v1">Link to paper</a></p>
                <p>We present InternLM-XComposer-2.5 IXC-2.5 a versatile large-visionlanguage model that supports long-contextual input and output. IXC-2.5 excelsin various text-image comprehension and composition applications achievingGPT-4V level capabilities with merely 7B LLM backend. Trained with 24Kinterleaved image-text contexts it can seamlessly extend to 96K long contextsvia RoPE extrapolation. This long-context capability allows IXC-2.5 to excel intasks requiring extensive input and output contexts. Compared to its previous2.0 version InternLM-XComposer-2.5 features three major upgrades invision-language comprehension: 1 Ultra-High Resolution Understanding 2Fine-Grained Video Understanding and 3 Multi-Turn Multi-Image Dialogue. Inaddition to comprehension IXC-2.5 extends to two compelling applications usingextra LoRA parameters for text-image composition: 1 Crafting Webpages and 2Composing High-Quality Text-Image Articles. IXC-2.5 has been evaluated on 28benchmarks outperforming existing open-source state-of-the-art models on 16benchmarks. It also surpasses or competes closely with GPT-4V and Gemini Pro on16 key tasks. The InternLM-XComposer-2.5 is publicly available athttps://github.com/InternLM/InternLM-XComposer.</p>
                <p>Last Updated: 2024-07-03 17:59:21 UTC</p>
                <button class="interpret-button" data-id="2407.03320v1">Interpret</button>
                <div id="interpretation-2407.03320v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations</h3>
                <p>Authors: Zhantao YangRuili FengKeyu YanHuangji WangZhicai WangShangwen ZhuHan ZhangJie XiaoPingyu WuKai ZhuJixuan ChenChen-Wei XieChaojie MaoYue YangHongyang ZhangYu LiuFan Cheng</p>
                <p><a href="http://arxiv.org/abs/2407.03314v1">Link to paper</a></p>
                <p>This paper presents Bag-of-Concept Graph BACON to gift models with limitedlinguistic abilities to taste the privilege of Vision Language Models VLMsand boost downstream tasks such as detection visual question answering VQAand image generation. Since the visual scenes in physical worlds are structuredwith complex relations between objects BACON breaks down annotations intobasic minimum elements and presents them in a graph structure. Element-wisestyle enables easy understanding and structural composition liberatesdifficult locating. Careful prompt design births the BACON captions with thehelp of public-available VLMs and segmentation methods. In this way we gathera dataset with 100K annotated images which endow VLMs with remarkablecapabilities such as accurately generating BACON transforming prompts intoBACON format envisioning scenarios in the style of BACONr and dynamicallymodifying elements within BACON through interactive dialogue and more. Widerepresentative experiments including detection VQA and image generationtasks tell BACON as a lifeline to achieve previous out-of-reach tasks or excelin their current cutting-edge solutions.</p>
                <p>Last Updated: 2024-07-03 17:55:27 UTC</p>
                <button class="interpret-button" data-id="2407.03314v1">Interpret</button>
                <div id="interpretation-2407.03314v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>HoloHisto: End-to-end Gigapixel WSI Segmentation with 4K Resolution Sequential Tokenization</h3>
                <p>Authors: Yucheng TangYufan HeVishwesh NathPengfeig GuoRuining DengTianyuan YaoQuan LiuCan CuiMengmeng YinZiyue XuHolger RothDaguang XuHaichun YangYuankai Huo</p>
                <p><a href="http://arxiv.org/abs/2407.03307v1">Link to paper</a></p>
                <p>In digital pathology the traditional method for deep learning-based imagesegmentation typically involves a two-stage process: initially segmentinghigh-resolution whole slide images WSI into smaller patches e.g. 256x256512x512 1024x1024 and subsequently reconstructing them to their originalscale. This method often struggles to capture the complex details and vastscope of WSIs. In this paper we propose the holistic histopathologyHoloHisto segmentation method to achieve end-to-end segmentation on gigapixelWSIs whose maximum resolution is above 80000times70000 pixels. HoloHistofundamentally shifts the paradigm of WSI segmentation to an end-to-end learningfashion with 1 a large 4K resolution base patch for elevated visualinformation inclusion and efficient processing and 2 a novel sequentialtokenization mechanism to properly model the contextual relationships andefficiently model the rich information from the 4K input. To our bestknowledge HoloHisto presents the first holistic approach for gigapixelresolution WSI segmentation supporting direct I/O of complete WSI and theircorresponding gigapixel masks. Under the HoloHisto platform we unveil a random4K sampler that transcends ultra-high resolution delivering 31 and 10 timesmore pixels than standard 2D and 3D patches respectively for advancingcomputational capabilities. To facilitate efficient 4K resolution denseprediction we leverage sequential tokenization utilizing a pre-trained imagetokenizer to group image features into a discrete token grid. To assess theperformance our team curated a new kidney pathology image segmentation KPIsdataset with WSI-level glomeruli segmentation from whole mouse kidneys. Fromthe results HoloHisto-4K delivers remarkable performance gains over previousstate-of-the-art models.</p>
                <p>Last Updated: 2024-07-03 17:49:31 UTC</p>
                <button class="interpret-button" data-id="2407.03307v1">Interpret</button>
                <div id="interpretation-2407.03307v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Smart City Surveillance Unveiling Indian Person Attributes in Real Time</h3>
                <p>Authors: Shubham KaleShashank SharmaAbhilash Khuntia</p>
                <p><a href="http://arxiv.org/abs/2407.03305v1">Link to paper</a></p>
                <p>This project focuses on creating a smart surveillance system for Indiancities that can identify and analyze peoples attributes in real time. Usingadvanced technologies like artificial intelligence and machine learning thesystem can recognize attributes such as upper body color what the person iswearing accessories they are wearing headgear etc. and analyze behaviorthrough cameras installed around the city.</p>
                <p>Last Updated: 2024-07-03 17:47:59 UTC</p>
                <button class="interpret-button" data-id="2407.03305v1">Interpret</button>
                <div id="interpretation-2407.03305v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents</h3>
                <p>Authors: Yilun XuGabriele CorsoTommi JaakkolaArash VahdatKarsten Kreis</p>
                <p><a href="http://arxiv.org/abs/2407.03300v1">Link to paper</a></p>
                <p>Diffusion models DMs have revolutionized generative learning. They utilizea diffusion process to encode data into a simple Gaussian distribution.However encoding a complex potentially multimodal data distribution into asingle continuous Gaussian distribution arguably represents an unnecessarilychallenging learning problem. We propose Discrete-Continuous Latent VariableDiffusion Models DisCo-Diff to simplify this task by introducingcomplementary discrete latent variables. We augment DMs with learnable discretelatents inferred with an encoder and train DM and encoder end-to-end.DisCo-Diff does not rely on pre-trained networks making the frameworkuniversally applicable. The discrete latents significantly simplify learningthe DMs complex noise-to-data mapping by reducing the curvature of the DMsgenerative ODE. An additional autoregressive transformer models thedistribution of the discrete latents a simple step because DisCo-Diff requiresonly few discrete variables with small codebooks. We validate DisCo-Diff on toydata several image synthesis tasks as well as molecular docking and find thatintroducing discrete latents consistently improves model performance. Forexample DisCo-Diff achieves state-of-the-art FID scores on class-conditionedImageNet-64/128 datasets with ODE sampler.</p>
                <p>Last Updated: 2024-07-03 17:42:46 UTC</p>
                <button class="interpret-button" data-id="2407.03300v1">Interpret</button>
                <div id="interpretation-2407.03300v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages</h3>
                <p>Authors: Max ZuoFrancisco Piedrahita VelezXiaochen LiMichael L. LittmanStephen H. Bach</p>
                <p><a href="http://arxiv.org/abs/2407.03321v1">Link to paper</a></p>
                <p>Many recent works have explored using language models for planning problems.One line of research focuses on translating natural language descriptions ofplanning tasks into structured planning languages such as the planning domaindefinition language PDDL. While this approach is promising accuratelymeasuring the quality of generated PDDL code continues to pose significantchallenges. First generated PDDL code is typically evaluated using planningvalidators that check whether the problem can be solved with a planner. Thismethod is insufficient because a language model might generate valid PDDL codethat does not align with the natural language description of the task. Secondexisting evaluation sets often have natural language descriptions of theplanning task that closely resemble the ground truth PDDL reducing thechallenge of the task. To bridge this gap we introduce benchmarkName abenchmark designed to evaluate language models ability to generate PDDL codefrom natural language descriptions of planning tasks. We begin by creating aPDDL equivalence algorithm that rigorously evaluates the correctness of PDDLcode generated by language models by flexibly comparing it against a groundtruth PDDL. Then we present a dataset of 132037 text-to-PDDL pairs across13 different tasks with varying levels of difficulty. Finally we evaluateseveral API-access and open-weight language models that reveal this taskscomplexity. For example 87.6 of the PDDL problem descriptions generated byGPT-4o are syntactically parseable 82.2 are valid solve-able problemsbut only 35.1 are semantically correct highlighting the need for a morerigorous benchmark for this problem.</p>
                <p>Last Updated: 2024-07-03 17:59:53 UTC</p>
                <button class="interpret-button" data-id="2407.03321v1">Interpret</button>
                <div id="interpretation-2407.03321v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Value-Penalized Auxiliary Control from Examples for Learning without Rewards or Demonstrations</h3>
                <p>Authors: Trevor AblettBryan ChanJayce Haoran WangJonathan Kelly</p>
                <p><a href="http://arxiv.org/abs/2407.03311v1">Link to paper</a></p>
                <p>Learning from examples of success is an appealing approach to reinforcementlearning that eliminates many of the disadvantages of using hand-crafted rewardfunctions or full expert-demonstration trajectories both of which can bedifficult to acquire biased or suboptimal. However learning from examplesalone dramatically increases the exploration challenge especially for complextasks. This work introduces value-penalized auxiliary control from examplesVPACE we significantly improve exploration in example-based control byadding scheduled auxiliary control and examples of auxiliary tasks.Furthermore we identify a value-calibration problem where policy valueestimates can exceed their theoretical limits based on successful data. Weresolve this problem which is exacerbated by learning auxiliary tasks throughthe addition of an above-success-level value penalty. Across three simulatedand one real robotic manipulation environment and 21 different main tasks weshow that our approach substantially improves learning efficiency. Videoscode and datasets are available at https://papers.starslab.ca/vpace.</p>
                <p>Last Updated: 2024-07-03 17:54:11 UTC</p>
                <button class="interpret-button" data-id="2407.03311v1">Interpret</button>
                <div id="interpretation-2407.03311v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method</h3>
                <p>Authors: Sijie XuShenyan ZongChang-Sheng MeiGuofeng ShenYueran ZhaoHe Wang</p>
                <p><a href="http://arxiv.org/abs/2407.03308v1">Link to paper</a></p>
                <p>Proton resonance frequency PRF based MR thermometry is essential forfocused ultrasound FUS thermal ablation therapies. This work aims to enhancetemporal resolution in dynamic MR temperature map reconstruction using animproved deep learning method. The training-optimized methods and fiveclassical neural networks were applied on the 2-fold and 4-fold under-samplingk-space data to reconstruct the temperature maps. The enhanced training modulesincluded offline/online data augmentations knowledge distillation and theamplitude-phase decoupling loss function. The heating experiments wereperformed by a FUS transducer on phantom and ex vivo tissues respectively.These data were manually under-sampled to imitate acceleration procedures andtrained in our method to get the reconstruction model. The additional dozen orso testing datasets were separately obtained for evaluating the real-timeperformance and temperature accuracy. Acceleration factors of 1.9 and 3.7 werefound for 2 times and 4 times k-space under-sampling strategies and theResUNet-based deep learning reconstruction performed exceptionally well. In2-fold acceleration scenario the RMSE of temperature map patches provided thevalues of 0.888 degree centigrade and 1.145 degree centigrade on phantom and exvivo testing datasets. The DICE value of temperature areas enclosed by 43degree centigrade isotherm was 0.809 and the Bland-Altman analysis showed abias of -0.253 degree centigrade with the apart of plus or minus 2.16 degreecentigrade. In 4 times under-sampling case these evaluating values decreasedby approximately 10. This study demonstrates that deep learning-basedreconstruction can significantly enhance the accuracy and efficiency of MRthermometry for clinical FUS thermal therapies.</p>
                <p>Last Updated: 2024-07-03 17:49:38 UTC</p>
                <button class="interpret-button" data-id="2407.03308v1">Interpret</button>
                <div id="interpretation-2407.03308v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents</h3>
                <p>Authors: Yilun XuGabriele CorsoTommi JaakkolaArash VahdatKarsten Kreis</p>
                <p><a href="http://arxiv.org/abs/2407.03300v1">Link to paper</a></p>
                <p>Diffusion models DMs have revolutionized generative learning. They utilizea diffusion process to encode data into a simple Gaussian distribution.However encoding a complex potentially multimodal data distribution into asingle continuous Gaussian distribution arguably represents an unnecessarilychallenging learning problem. We propose Discrete-Continuous Latent VariableDiffusion Models DisCo-Diff to simplify this task by introducingcomplementary discrete latent variables. We augment DMs with learnable discretelatents inferred with an encoder and train DM and encoder end-to-end.DisCo-Diff does not rely on pre-trained networks making the frameworkuniversally applicable. The discrete latents significantly simplify learningthe DMs complex noise-to-data mapping by reducing the curvature of the DMsgenerative ODE. An additional autoregressive transformer models thedistribution of the discrete latents a simple step because DisCo-Diff requiresonly few discrete variables with small codebooks. We validate DisCo-Diff on toydata several image synthesis tasks as well as molecular docking and find thatintroducing discrete latents consistently improves model performance. Forexample DisCo-Diff achieves state-of-the-art FID scores on class-conditionedImageNet-64/128 datasets with ODE sampler.</p>
                <p>Last Updated: 2024-07-03 17:42:46 UTC</p>
                <button class="interpret-button" data-id="2407.03300v1">Interpret</button>
                <div id="interpretation-2407.03300v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Improved Noise Schedule for Diffusion Training</h3>
                <p>Authors: Tiankai HangShuyang Gu</p>
                <p><a href="http://arxiv.org/abs/2407.03297v1">Link to paper</a></p>
                <p>Diffusion models have emerged as the de facto choice for generating visualsignals. However training a single model to predict noise across variouslevels poses significant challenges necessitating numerous iterations andincurring significant computational costs. Various approaches such as lossweighting strategy design and architectural refinements have been introducedto expedite convergence. In this study we propose a novel approach to designthe noise schedule for enhancing the training of diffusion models. Our keyinsight is that the importance sampling of the logarithm of the Signal-to-Noiseratio logSNR theoretically equivalent to a modified noise schedule isparticularly beneficial for training efficiency when increasing the samplefrequency around log textSNR0. We empirically demonstrate thesuperiority of our noise schedule over the standard cosine schedule.Furthermore we highlight the advantages of our noise schedule design on theImageNet benchmark showing that the designed schedule consistently benefitsdifferent prediction targets.</p>
                <p>Last Updated: 2024-07-03 17:34:55 UTC</p>
                <button class="interpret-button" data-id="2407.03297v1">Interpret</button>
                <div id="interpretation-2407.03297v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages</h3>
                <p>Authors: Max ZuoFrancisco Piedrahita VelezXiaochen LiMichael L. LittmanStephen H. Bach</p>
                <p><a href="http://arxiv.org/abs/2407.03321v1">Link to paper</a></p>
                <p>Many recent works have explored using language models for planning problems.One line of research focuses on translating natural language descriptions ofplanning tasks into structured planning languages such as the planning domaindefinition language PDDL. While this approach is promising accuratelymeasuring the quality of generated PDDL code continues to pose significantchallenges. First generated PDDL code is typically evaluated using planningvalidators that check whether the problem can be solved with a planner. Thismethod is insufficient because a language model might generate valid PDDL codethat does not align with the natural language description of the task. Secondexisting evaluation sets often have natural language descriptions of theplanning task that closely resemble the ground truth PDDL reducing thechallenge of the task. To bridge this gap we introduce benchmarkName abenchmark designed to evaluate language models ability to generate PDDL codefrom natural language descriptions of planning tasks. We begin by creating aPDDL equivalence algorithm that rigorously evaluates the correctness of PDDLcode generated by language models by flexibly comparing it against a groundtruth PDDL. Then we present a dataset of 132037 text-to-PDDL pairs across13 different tasks with varying levels of difficulty. Finally we evaluateseveral API-access and open-weight language models that reveal this taskscomplexity. For example 87.6 of the PDDL problem descriptions generated byGPT-4o are syntactically parseable 82.2 are valid solve-able problemsbut only 35.1 are semantically correct highlighting the need for a morerigorous benchmark for this problem.</p>
                <p>Last Updated: 2024-07-03 17:59:53 UTC</p>
                <button class="interpret-button" data-id="2407.03321v1">Interpret</button>
                <div id="interpretation-2407.03321v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output</h3>
                <p>Authors: Pan ZhangXiaoyi DongYuhang ZangYuhang CaoRui QianLin ChenQipeng GuoHaodong DuanBin WangLinke OuyangSongyang ZhangWenwei ZhangYining LiYang GaoPeng SunXinyue ZhangWei LiJingwen LiWenhai WangHang YanConghui HeXingcheng ZhangKai ChenJifeng DaiYu QiaoDahua LinJiaqi Wang</p>
                <p><a href="http://arxiv.org/abs/2407.03320v1">Link to paper</a></p>
                <p>We present InternLM-XComposer-2.5 IXC-2.5 a versatile large-visionlanguage model that supports long-contextual input and output. IXC-2.5 excelsin various text-image comprehension and composition applications achievingGPT-4V level capabilities with merely 7B LLM backend. Trained with 24Kinterleaved image-text contexts it can seamlessly extend to 96K long contextsvia RoPE extrapolation. This long-context capability allows IXC-2.5 to excel intasks requiring extensive input and output contexts. Compared to its previous2.0 version InternLM-XComposer-2.5 features three major upgrades invision-language comprehension: 1 Ultra-High Resolution Understanding 2Fine-Grained Video Understanding and 3 Multi-Turn Multi-Image Dialogue. Inaddition to comprehension IXC-2.5 extends to two compelling applications usingextra LoRA parameters for text-image composition: 1 Crafting Webpages and 2Composing High-Quality Text-Image Articles. IXC-2.5 has been evaluated on 28benchmarks outperforming existing open-source state-of-the-art models on 16benchmarks. It also surpasses or competes closely with GPT-4V and Gemini Pro on16 key tasks. The InternLM-XComposer-2.5 is publicly available athttps://github.com/InternLM/InternLM-XComposer.</p>
                <p>Last Updated: 2024-07-03 17:59:21 UTC</p>
                <button class="interpret-button" data-id="2407.03320v1">Interpret</button>
                <div id="interpretation-2407.03320v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations</h3>
                <p>Authors: Zhantao YangRuili FengKeyu YanHuangji WangZhicai WangShangwen ZhuHan ZhangJie XiaoPingyu WuKai ZhuJixuan ChenChen-Wei XieChaojie MaoYue YangHongyang ZhangYu LiuFan Cheng</p>
                <p><a href="http://arxiv.org/abs/2407.03314v1">Link to paper</a></p>
                <p>This paper presents Bag-of-Concept Graph BACON to gift models with limitedlinguistic abilities to taste the privilege of Vision Language Models VLMsand boost downstream tasks such as detection visual question answering VQAand image generation. Since the visual scenes in physical worlds are structuredwith complex relations between objects BACON breaks down annotations intobasic minimum elements and presents them in a graph structure. Element-wisestyle enables easy understanding and structural composition liberatesdifficult locating. Careful prompt design births the BACON captions with thehelp of public-available VLMs and segmentation methods. In this way we gathera dataset with 100K annotated images which endow VLMs with remarkablecapabilities such as accurately generating BACON transforming prompts intoBACON format envisioning scenarios in the style of BACONr and dynamicallymodifying elements within BACON through interactive dialogue and more. Widerepresentative experiments including detection VQA and image generationtasks tell BACON as a lifeline to achieve previous out-of-reach tasks or excelin their current cutting-edge solutions.</p>
                <p>Last Updated: 2024-07-03 17:55:27 UTC</p>
                <button class="interpret-button" data-id="2407.03314v1">Interpret</button>
                <div id="interpretation-2407.03314v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Review of the Applications of Deep Learning-Based Emergent Communication</h3>
                <p>Authors: Brendon BoldtDavid Mortensen</p>
                <p><a href="http://arxiv.org/abs/2407.03302v1">Link to paper</a></p>
                <p>Emergent communication or emergent language is the field of research whichstudies how human language-like communication systems emerge de novo in deepmulti-agent reinforcement learning environments. The possibilities ofreplicating the emergence of a complex behavior like language have strongintuitive appeal yet it is necessary to complement this with clear notions ofhow such research can be applicable to other fields of science technology andengineering. This paper comprehensively reviews the applications of emergentcommunication research across machine learning natural language processinglinguistics and cognitive science. Each application is illustrated with adescription of its scope an explication of emergent communications uniquerole in addressing it a summary of the extant literature working towards theapplication and brief recommendations for near-term research directions.</p>
                <p>Last Updated: 2024-07-03 17:43:54 UTC</p>
                <button class="interpret-button" data-id="2407.03302v1">Interpret</button>
                <div id="interpretation-2407.03302v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LLM Internal States Reveal Hallucination Risk Faced With a Query</h3>
                <p>Authors: Ziwei JiDelong ChenEtsuko IshiiSamuel CahyawijayaYejin BangBryan WiliePascale Fung</p>
                <p><a href="http://arxiv.org/abs/2407.03282v1">Link to paper</a></p>
                <p>The hallucination problem of Large Language Models LLMs significantlylimits their reliability and trustworthiness. Humans have a self-awarenessprocess that allows us to recognize what we dont know when faced with queries.Inspired by this our paper investigates whether LLMs can estimate their ownhallucination risk before response generation. We analyze the internalmechanisms of LLMs broadly both in terms of training data sources and across 15diverse Natural Language Generation NLG tasks spanning over 700 datasets.Our empirical analysis reveals two key insights: 1 LLM internal statesindicate whether they have seen the query in training data or not and 2 LLMinternal states show they are likely to hallucinate or not regarding the query.Our study explores particular neurons activation layers and tokens that playa crucial role in the LLM perception of uncertainty and hallucination risk. Bya probing estimator we leverage LLM self-assessment achieving an averagehallucination estimation accuracy of 84.32 at run time.</p>
                <p>Last Updated: 2024-07-03 17:08:52 UTC</p>
                <button class="interpret-button" data-id="2407.03282v1">Interpret</button>
                <div id="interpretation-2407.03282v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages</h3>
                <p>Authors: Max ZuoFrancisco Piedrahita VelezXiaochen LiMichael L. LittmanStephen H. Bach</p>
                <p><a href="http://arxiv.org/abs/2407.03321v1">Link to paper</a></p>
                <p>Many recent works have explored using language models for planning problems.One line of research focuses on translating natural language descriptions ofplanning tasks into structured planning languages such as the planning domaindefinition language PDDL. While this approach is promising accuratelymeasuring the quality of generated PDDL code continues to pose significantchallenges. First generated PDDL code is typically evaluated using planningvalidators that check whether the problem can be solved with a planner. Thismethod is insufficient because a language model might generate valid PDDL codethat does not align with the natural language description of the task. Secondexisting evaluation sets often have natural language descriptions of theplanning task that closely resemble the ground truth PDDL reducing thechallenge of the task. To bridge this gap we introduce benchmarkName abenchmark designed to evaluate language models ability to generate PDDL codefrom natural language descriptions of planning tasks. We begin by creating aPDDL equivalence algorithm that rigorously evaluates the correctness of PDDLcode generated by language models by flexibly comparing it against a groundtruth PDDL. Then we present a dataset of 132037 text-to-PDDL pairs across13 different tasks with varying levels of difficulty. Finally we evaluateseveral API-access and open-weight language models that reveal this taskscomplexity. For example 87.6 of the PDDL problem descriptions generated byGPT-4o are syntactically parseable 82.2 are valid solve-able problemsbut only 35.1 are semantically correct highlighting the need for a morerigorous benchmark for this problem.</p>
                <p>Last Updated: 2024-07-03 17:59:53 UTC</p>
                <button class="interpret-button" data-id="2407.03321v1">Interpret</button>
                <div id="interpretation-2407.03321v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Value-Penalized Auxiliary Control from Examples for Learning without Rewards or Demonstrations</h3>
                <p>Authors: Trevor AblettBryan ChanJayce Haoran WangJonathan Kelly</p>
                <p><a href="http://arxiv.org/abs/2407.03311v1">Link to paper</a></p>
                <p>Learning from examples of success is an appealing approach to reinforcementlearning that eliminates many of the disadvantages of using hand-crafted rewardfunctions or full expert-demonstration trajectories both of which can bedifficult to acquire biased or suboptimal. However learning from examplesalone dramatically increases the exploration challenge especially for complextasks. This work introduces value-penalized auxiliary control from examplesVPACE we significantly improve exploration in example-based control byadding scheduled auxiliary control and examples of auxiliary tasks.Furthermore we identify a value-calibration problem where policy valueestimates can exceed their theoretical limits based on successful data. Weresolve this problem which is exacerbated by learning auxiliary tasks throughthe addition of an above-success-level value penalty. Across three simulatedand one real robotic manipulation environment and 21 different main tasks weshow that our approach substantially improves learning efficiency. Videoscode and datasets are available at https://papers.starslab.ca/vpace.</p>
                <p>Last Updated: 2024-07-03 17:54:11 UTC</p>
                <button class="interpret-button" data-id="2407.03311v1">Interpret</button>
                <div id="interpretation-2407.03311v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Universal Length Generalization with Turing Programs</h3>
                <p>Authors: Kaiying HouDavid BrandfonbrenerSham KakadeSamy JelassiEran Malach</p>
                <p><a href="http://arxiv.org/abs/2407.03310v1">Link to paper</a></p>
                <p>Length generalization refers to the ability to extrapolate from shorttraining sequences to long test sequences and is a challenge for current largelanguage models. While prior work has proposed some architecture or data formatchanges to achieve length generalization these proposals typically apply to alimited set of tasks. Building on prior scratchpad and Chain-of-Thought CoTtechniques we propose Turing Programs a novel CoT strategy that decomposes analgorithmic task into steps mimicking the computation of a Turing Machine. Thisframework is both universal as it can accommodate any algorithmic task andsimple requiring only copying text from the context with small modifications.We show that by using Turing Programs we obtain robust length generalizationon a range of algorithmic tasks: addition multiplication and in-context SGD.We then demonstrate that transformers achieve length generalization on randomTuring Programs suggesting that length generalization is possible for anyalgorithmic task. Finally we theoretically prove that transformers canimplement Turing Programs constructing a simple RASP Weiss et al. programthat simulates an arbitrary Turing machine.</p>
                <p>Last Updated: 2024-07-03 17:53:44 UTC</p>
                <button class="interpret-button" data-id="2407.03310v1">Interpret</button>
                <div id="interpretation-2407.03310v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents</h3>
                <p>Authors: Yilun XuGabriele CorsoTommi JaakkolaArash VahdatKarsten Kreis</p>
                <p><a href="http://arxiv.org/abs/2407.03300v1">Link to paper</a></p>
                <p>Diffusion models DMs have revolutionized generative learning. They utilizea diffusion process to encode data into a simple Gaussian distribution.However encoding a complex potentially multimodal data distribution into asingle continuous Gaussian distribution arguably represents an unnecessarilychallenging learning problem. We propose Discrete-Continuous Latent VariableDiffusion Models DisCo-Diff to simplify this task by introducingcomplementary discrete latent variables. We augment DMs with learnable discretelatents inferred with an encoder and train DM and encoder end-to-end.DisCo-Diff does not rely on pre-trained networks making the frameworkuniversally applicable. The discrete latents significantly simplify learningthe DMs complex noise-to-data mapping by reducing the curvature of the DMsgenerative ODE. An additional autoregressive transformer models thedistribution of the discrete latents a simple step because DisCo-Diff requiresonly few discrete variables with small codebooks. We validate DisCo-Diff on toydata several image synthesis tasks as well as molecular docking and find thatintroducing discrete latents consistently improves model performance. Forexample DisCo-Diff achieves state-of-the-art FID scores on class-conditionedImageNet-64/128 datasets with ODE sampler.</p>
                <p>Last Updated: 2024-07-03 17:42:46 UTC</p>
                <button class="interpret-button" data-id="2407.03300v1">Interpret</button>
                <div id="interpretation-2407.03300v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Vertex Exchange Method for a Class of Quadratic Programming Problems</h3>
                <p>Authors: Ling LiangKim-Chuan TohHaizhao Yang</p>
                <p><a href="http://arxiv.org/abs/2407.03294v1">Link to paper</a></p>
                <p>A vertex exchange method is proposed for solving the strongly convexquadratic program subject to the generalized simplex constraint. We conductrigorous convergence analysis for the proposed algorithm and demonstrate itsessential roles in solving some important classes of constrained convexoptimization. To get a feasible initial point to execute the algorithm we alsopresent and analyze a highly efficient semismooth Newton method for computingthe projection onto the generalized simplex. The excellent practicalperformance of the proposed algorithms is demonstrated by a set of extensivenumerical experiments. Our theoretical and numerical results further motivatethe potential applications of the considered model and the proposed algorithms.</p>
                <p>Last Updated: 2024-07-03 17:28:17 UTC</p>
                <button class="interpret-button" data-id="2407.03294v1">Interpret</button>
                <div id="interpretation-2407.03294v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>A multi-objective combinatorial optimisation framework for large scale hierarchical population synthesis</h3>
                <p>Authors: Imran MahmoodNicholas BishopAnisoara CalinescuMichael WooldridgeIoannis Zachos</p>
                <p><a href="http://arxiv.org/abs/2407.03180v1">Link to paper</a></p>
                <p>In agent-based simulations synthetic populations of agents are commonly usedto represent the structure behaviour and interactions of individuals.However generating a synthetic population that accurately reflects realpopulation statistics is a challenging task particularly when performed atscale. In this paper we propose a multi objective combinatorial optimisationtechnique for large scale population synthesis. We demonstrate theeffectiveness of our approach by generating a synthetic population for selectedregions and validating it on contingency tables from real population data. Ourapproach supports complex hierarchical structures between individuals andhouseholds is scalable to large populations and achieves minimal contigencytable reconstruction error. Hence it provides a useful tool for policymakersand researchers for simulating the dynamics of complex populations.</p>
                <p>Last Updated: 2024-07-03 15:01:12 UTC</p>
                <button class="interpret-button" data-id="2407.03180v1">Interpret</button>
                <div id="interpretation-2407.03180v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Wildfire Autonomous Response and Prediction Using Cellular Automata (WARP-CA)</h3>
                <p>Authors: Abdelrahman Ramadan</p>
                <p><a href="http://arxiv.org/abs/2407.02613v1">Link to paper</a></p>
                <p>Wildfires pose a severe challenge to ecosystems and human settlementsexacerbated by climate change and environmental factors. Traditional wildfiremodeling while useful often fails to adapt to the rapid dynamics of suchevents. This report introduces the Wildfire Autonomous Response and PredictionUsing Cellular Automata WARP-CA model a novel approach that integratesterrain generation using Perlin noise with the dynamism of Cellular AutomataCA to simulate wildfire spread. We explore the potential of Multi-AgentReinforcement Learning MARL to manage wildfires by simulating autonomousagents such as UAVs and UGVs within a collaborative framework. Ourmethodology combines world simulation techniques and investigates emergentbehaviors in MARL focusing on efficient wildfire suppression and consideringcritical environmental factors like wind patterns and terrain features.</p>
                <p>Last Updated: 2024-07-02 19:01:59 UTC</p>
                <button class="interpret-button" data-id="2407.02613v1">Interpret</button>
                <div id="interpretation-2407.02613v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Impact of the Network Size and Frequency of Information Receipt on Polarization in Social Networks</h3>
                <p>Authors: Sudhakar KrisharaoShaja Arul Selvamani</p>
                <p><a href="http://dx.doi.org/10.1155/2024/4742401">Link to paper</a></p>
                <p>Opinion Dynamics is an interdisciplinary area of research. Psychology andSociology have proposed models of how individuals form opinions and how socialinteractions influence this process. Socio-Physicists have interpreted patternsin opinion formation as arising from non-linearity in the underlying processshaping the models. Agent-based modeling has offered a platform to study theOpinion Dynamics of large groups. This paper recasts recent models in opinionformation into a proper dynamical system injecting the idea of clock time intoevolving opinions. The time interval between successive receipts of newinformation frequency of information receipts becomes a factor to study.Social media has shrunk time intervals between information receipts increasingtheir frequency. The recast models show that shorter intervals and largernetworks increase an individuals propensity for polarization defined as aninability to hold a neutral opinion. A Polarization number based onsociological parameters is proposed with critical values beyond whichindividuals are prone to polarization depending on psychological parameters.Reduced time intervals and larger interacting groups can push the Polarizationnumber to critical values contributing to polarization. The Extent ofPolarization is defined as the width of the region around neutral within whichan individual cannot hold an opinion. Results are reported for model parametersfound in the literature. The findings offer an opportunity to adjust modelparameters to align with empirical evidence aiding the study of OpinionDynamics in large social networks using Agent-Based Modeling.</p>
                <p>Last Updated: 2024-07-01 20:30:04 UTC</p>
                <button class="interpret-button" data-id="2407.01788v1">Interpret</button>
                <div id="interpretation-2407.01788v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Distributed Instruments for Planetary Surface Science: Scientific Opportunities and Technology Feasibility</h3>
                <p>Authors: Federico RossiRobert C. AndersonSaptarshi BandyopadhyayErik BrandonAshish GoelJoshua Vander HookMichael MischnaMichaela VillarrealMark Wronkiewicz</p>
                <p><a href="http://arxiv.org/abs/2407.01757v1">Link to paper</a></p>
                <p>In this paper we assess the scientific promise and technology feasibility ofdistributed instruments for planetary science. A distributed instrument is aninstrument designed to collect spatially and temporally correlated data frommultiple networked geographically distributed point sensors. Distributedinstruments are ubiquitous in Earth science where they are routinely employedfor weather and climate science seismic studies and resource prospecting anddetection of industrial emissions. However to date their adoption inplanetary surface science has been minimal. It is natural to ask whether thislack of adoption is driven by low potential to address high-priority questionsin planetary science immature technology or both. To address this questionwe survey high-priority planetary science questions that are uniquelywell-suited to distributed instruments. We identify four areas of researchwhere distributed instruments hold promise to unlock answers that are largelyinaccessible to monolithic sensors namely weather and climate studies ofMars localization of seismic events on rocky and icy bodies localization oftrace gas emissions primarily on Mars and magnetometry studies of internalcomposition. Next we survey enabling technologies for distributed sensors andassess their maturity. We identify sensor placement including descent andlanding on planetary surfaces power and instrument autonomy as three keyareas requiring further investment to enable future distributed instruments.Overall this work shows that distributed instruments hold great promise forplanetary science and paves the way for follow-on studies of futuredistributed instruments for Solar System in-situ science.</p>
                <p>Last Updated: 2024-07-01 19:41:41 UTC</p>
                <button class="interpret-button" data-id="2407.01757v1">Interpret</button>
                <div id="interpretation-2407.01757v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Online Learning of Temporal Dependencies for Sustainable Foraging Problem</h3>
                <p>Authors: John PayneAishwaryaprajnaPeter R. Lewis</p>
                <p><a href="http://arxiv.org/abs/2407.01501v1">Link to paper</a></p>
                <p>The sustainable foraging problem is a dynamic environment testbed forexploring the forms of agent cognition in dealing with social dilemmas in amulti-agent setting. The agents need to resist the temptation of individualrewards through foraging and choose the collective long-term goal ofsustainability. We investigate methods of online learning in Neuro-Evolutionand Deep Recurrent Q-Networks to enable agents to attempt the problem one-shotas is often required by wicked social problems. We further explore if learningtemporal dependencies with Long Short-Term Memory may be able to aid the agentsin developing sustainable foraging strategies in the long term. It was foundthat the integration of Long Short-Term Memory assisted agents in developingsustainable strategies for a single agent however failed to assist agents inmanaging the social dilemma that arises in the multi-agent scenario.</p>
                <p>Last Updated: 2024-07-01 17:47:31 UTC</p>
                <button class="interpret-button" data-id="2407.01501v1">Interpret</button>
                <div id="interpretation-2407.01501v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-07-05</p>
        </div>
    
        </div>
    </body>
    </html>
    